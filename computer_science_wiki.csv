Topic,Summary,Full Content,Page ID,URL
Computer science,"Computer science is the study of computation, information, and automation. Computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to applied disciplines (including the design and implementation of hardware and software). Though more often considered an academic discipline, computer science is closely related to computer programming.Algorithms and data structures are central to computer science.
The theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. The fields of cryptography and computer security involve studying the means for secure communication and for preventing security vulnerabilities. Computer graphics and computational geometry address the generation of images. Programming language theory considers different ways to describe computational processes, and database theory concerns the management of repositories of data. Human–computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. Areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. Computer architecture describes the construction of computer components and computer-operated equipment. Artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. Within artificial intelligence, computer vision aims to understand and process image and video data, while natural language processing aims to understand and process textual and linguistic data.
The fundamental concern of computer science is determining what can and cannot be automated. The Turing Award is generally recognized as the highest distinction in computer science.","Computer science is the study of computation, information, and automation. Computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to applied disciplines (including the design and implementation of hardware and software). Though more often considered an academic discipline, computer science is closely related to computer programming.Algorithms and data structures are central to computer science.
The theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. The fields of cryptography and computer security involve studying the means for secure communication and for preventing security vulnerabilities. Computer graphics and computational geometry address the generation of images. Programming language theory considers different ways to describe computational processes, and database theory concerns the management of repositories of data. Human–computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. Areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. Computer architecture describes the construction of computer components and computer-operated equipment. Artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. Within artificial intelligence, computer vision aims to understand and process image and video data, while natural language processing aims to understand and process textual and linguistic data.
The fundamental concern of computer science is determining what can and cannot be automated. The Turing Award is generally recognized as the highest distinction in computer science.

History
The earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.Wilhelm Schickard designed and constructed the first working mechanical calculator in 1623. In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner. Leibniz may be considered the first computer scientist and information theorist, because of various reasons, including the fact that he documented the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. Charles Babbage started the design of the first automatic mechanical calculator, his Difference Engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his Analytical Engine. He started developing this machine in 1834, and ""in less than two years, he had sketched out many of the salient features of the modern computer"". ""A crucial step was the adoption of a punched card system derived from the Jacquard loom"" making it infinitely programmable. In 1843, during the translation of a French article on the Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an algorithm to compute the Bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer. Around 1885, Herman Hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of IBM. Following Babbage, although unaware of his earlier work, Percy Ludgate in 1909 published the 2nd of the only two designs for mechanical analytical engines in history. In 1914, the Spanish engineer Leonardo Torres Quevedo published his Essays on Automatics, and designed, inspired by Babbage, a theoretical electromechanical calculating machine which was to be controlled by a read-only program. The paper also introduced the idea of floating-point arithmetic. In 1920, to celebrate the 100th anniversary of the invention of the arithmometer, Torres presented in Paris the Electromechanical Arithmometer, a prototype that demonstrated the feasibility of an electromechanical analytical engine, on which commands could be typed and the results printed automatically. In 1937, one hundred years after Babbage's impossible dream, Howard Aiken convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used cards and a central computing unit. When the machine was finished, some hailed it as ""Babbage's dream come true"".
During the 1940s, with the development of new and more powerful computing machines such as the Atanasoff–Berry computer and ENIAC, the term computer came to refer to the machines rather than their human predecessors. As it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. In 1945, IBM founded the Watson Scientific Computing Laboratory at Columbia University in New York City. The renovated fraternity house on Manhattan's West Side was IBM's first laboratory devoted to pure science. The lab is the forerunner of IBM's Research Division, which today operates research facilities around the world. Ultimately, the close relationship between IBM and Columbia University was instrumental in the emergence of a new scientific discipline, with Columbia offering one of the first academic-credit courses in computer science in 1946. Computer science began to be established as a distinct academic discipline in the 1950s and early 1960s. The world's first computer science degree program, the Cambridge Diploma in Computer Science, began at the University of Cambridge Computer Laboratory in 1953. The first computer science department in the United States was formed at Purdue University in 1962. Since practical computers became available, many applications of computing have become distinct areas of study in their own rights.

Etymology and scope
Although first proposed in 1956, the term ""computer science"" appears in a 1959 article in Communications of the ACM,
in which Louis Fein argues for the creation of a Graduate School in Computer Sciences analogous to the creation of Harvard Business School in 1921. Louis justifies the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.
His efforts, and those of others such as numerical analyst George Forsythe, were rewarded: universities went on to create such departments, starting with Purdue in 1962. Despite its name, a significant amount of computer science does not involve the study of computers themselves. Because of this, several alternative names have been proposed. Certain departments of major universities prefer the term computing science, to emphasize precisely that difference. Danish scientist Peter Naur suggested the term datalogy, to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. The first scientific institution to use the term was the Department of Datalogy at the University of Copenhagen, founded in 1969, with Peter Naur being the first professor in datalogy. The term is used mainly in the Scandinavian countries. An alternative term, also proposed by Naur, is data science; this is now used for a multi-disciplinary field of data analysis, including statistics and databases.
In the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the Communications of the ACM—turingineer, turologist, flow-charts-man, applied meta-mathematician, and applied epistemologist. Three months later in the same journal, comptologist was suggested, followed next year by hypologist. The term computics has also been suggested. In Europe, terms derived from contracted translations of the expression ""automatic information"" (e.g. ""informazione automatica"" in Italian) or ""information and mathematics"" are often used, e.g. informatique (French), Informatik (German), informatica (Italian, Dutch), informática (Spanish, Portuguese), informatika (Slavic languages and Hungarian) or pliroforiki (πληροφορική, which means informatics) in Greek. Similar words have also been adopted in the UK (as in the School of Informatics, University of Edinburgh). ""In the U.S., however, informatics is linked with applied computing, or computing in the context of another domain.""A folkloric quotation, often attributed to—but almost certainly not first formulated by—Edsger Dijkstra, states that ""computer science is no more about computers than astronomy is about telescopes."" The design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. For example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. However, there has been exchange of ideas between the various computer-related disciplines. Computer science research also often intersects other disciplines, such as cognitive science, linguistics, mathematics, physics, biology, Earth science, statistics, philosophy, and logic.
Computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science. Early computer science was strongly influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.The relationship between computer science and software engineering is a contentious issue, which is further muddied by disputes over what the term ""software engineering"" means, and how computer science is defined. David Parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.The academic, political, and funding aspects of computer science tend to depend on whether a department is formed with a mathematical emphasis or with an engineering emphasis. Computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. Both types of departments tend to make efforts to bridge the field educationally if not across all research.

Philosophy
Epistemology of computer science
Despite the word science in its name, there is debate over whether or not computer science is a discipline of science, mathematics, or engineering. Allen Newell and Herbert A. Simon argued in 1975, Computer science is an empirical discipline. We would have called it an experimental science, but like astronomy, economics, and geology, some of its unique forms of observation and experience do not fit a narrow stereotype of the experimental method. Nonetheless, they are experiments. Each new machine that is built is an experiment. Actually constructing the machine poses a question to nature; and we listen for the answer by observing the machine in operation and analyzing it by all analytical and measurement means available. It has since been argued that computer science can be classified as an empirical science since it makes use of empirical testing to evaluate the correctness of programs, but a problem remains in defining the laws and theorems of computer science (if any exist) and defining the nature of experiments in computer science. Proponents of classifying computer science as an engineering discipline argue that the reliability of computational systems is investigated in the same way as bridges in civil engineering and airplanes in aerospace engineering. They also argue that while empirical sciences observe what presently exists, computer science observes what is possible to exist and while scientists discover laws from observation, no proper laws have been found in computer science and it is instead concerned with creating phenomena.Proponents of classifying computer science as a mathematical discipline argue that computer programs are physical realizations of mathematical entities and programs can be deductively reasoned through mathematical formal methods. Computer scientists Edsger W. Dijkstra and Tony Hoare regard instructions for computer programs as mathematical sentences and interpret formal semantics for programming languages as mathematical axiomatic systems.

Paradigms of computer science
A number of computer scientists have argued for the distinction of three separate paradigms in computer science. Peter Wegner argued that those paradigms are science, technology, and mathematics. Peter Denning's working group argued that they are theory, abstraction (modeling), and design. Amnon H. Eden described them as the ""rationalist paradigm"" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the ""technocratic paradigm"" (which might be found in engineering approaches, most prominently in software engineering), and the ""scientific paradigm"" (which approaches computer-related artifacts from the empirical perspective of natural sciences, identifiable in some branches of artificial intelligence).
Computer science focuses on methods involved in design, specification, programming, verification, implementation and testing of human-made computing systems.

Fields
As a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.CSAB, formerly called Computing Sciences Accreditation Board—which is made up of representatives of the Association for Computing Machinery (ACM), and the IEEE Computer Society (IEEE CS)—identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. In addition to these four areas, CSAB also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.

Theoretical computer science
Theoretical Computer Science is mathematical and abstract in spirit, but it derives its motivation from the practical and everyday computation. Its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies.

Theory of computation
According to Peter Denning, the fundamental question underlying computer science is, ""What can be automated?"" Theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. In an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. The second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.
The famous P = NP? problem, one of the Millennium Prize Problems, is an open problem in the theory of computation.

Information and coding theory
Information theory, closely related to probability and statistics, is related to the quantification of information. This was developed by Claude Shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data.
Coding theory is the study of the properties of codes (systems for converting information from one form to another) and their fitness for a specific application. Codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. Codes are studied for the purpose of designing efficient and reliable data transmission methods.

Data structures and algorithms
Data structures and algorithms are the studies of commonly used computational methods and their computational efficiency.

Programming language theory and formal methods
Programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. It is an active research area, with numerous dedicated academic journals.
Formal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. They form an important theoretical underpinning for software engineering, especially where safety or security is involved. Formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. For industrial use, tool support is required. However, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.

Applied computer science
Computer graphics and visualization
Computer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. The study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.

Image and sound processing
Information can take the form of images, sound, video or other multimedia. Bits of information can be streamed via signals. Its processing is the central notion of informatics, the European view on computing, which studies information processing algorithms independently of the type of information carrier – whether it is electrical, mechanical or biological. This field plays important role in information theory, telecommunications, information engineering and has applications in medical image computing and speech synthesis, among others. What is the lower bound on the complexity of fast Fourier transform algorithms? is one of unsolved problems in theoretical computer science.

Computational science, finance and engineering
Scientific computing (or computational science) is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. A major usage of scientific computing is simulation of various processes, including computational fluid dynamics, physical, electrical, and electronic systems and circuits, as well as societies and social situations (notably war games) along with their habitats, among many others. Modern computers enable optimization of such designs as complete aircraft. Notable in electrical and electronic circuit design are SPICE, as well as software for physical realization of new (or modified) designs. The latter includes essential design software for integrated circuits.

Social computing and human–computer interaction
Social computing is an area that is concerned with the intersection of social behavior and computational systems. Human–computer interaction research develops theories, principles, and guidelines for user interface designers.

Software engineering
Software engineering is the study of designing, implementing, and modifying the software in order to ensure it is of high quality, affordable, maintainable, and fast to build. It is a systematic approach to software design, involving the application of engineering practices to software. Software engineering deals with the organizing and analyzing of software—it does not just deal with the creation or manufacture of new software, but its internal arrangement and maintenance. For example software testing, systems engineering, technical debt and software development processes.

Artificial intelligence
Artificial intelligence (AI) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. From its origins in cybernetics and in the Dartmouth Conference (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. AI is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. The starting point in the late 1940s was Alan Turing's question ""Can computers think?"", and the question remains effectively unanswered, although the Turing test is still used to assess computer output on the scale of human intelligence. But the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.

Computer systems
Computer architecture and organization
Computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. It focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory. Computer engineers study computational logic and design of computer hardware, from individual processor components, microcontrollers, personal computers to supercomputers and embedded systems. The term ""architecture"" in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks Jr., members of the Machine Organization department in IBM's main research center in 1959.

Concurrent, parallel and distributed computing
Concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. A number of mathematical models have been developed for general concurrent computation including Petri nets, process calculi and the Parallel Random Access Machine model. When multiple computers are connected in a network while using concurrency, this is known as a distributed system. Computers within that distributed system have their own private memory, and information can be exchanged to achieve common goals.

Computer networks
This branch of computer science aims to manage networks between computers worldwide.

Computer security and cryptography
Computer security is a branch of computer technology with the objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users.
Historical cryptography is the art of writing and deciphering secret messages. Modern cryptography is the scientific study of problems relating to distributed computations that can be attacked. Technologies studied in modern cryptography include symmetric and asymmetric encryption, digital signatures, cryptographic hash functions, key-agreement protocols, blockchain, zero-knowledge proofs, and garbled circuits.

Databases and data mining
A database is intended to organize, store, and retrieve large amounts of data easily. Digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages. Data mining is a process of discovering patterns in large data sets.

Discoveries
The philosopher of computing Bill Rapaport noted three Great Insights of Computer Science:
Gottfried Wilhelm Leibniz's, George Boole's, Alan Turing's, Claude Shannon's, and Samuel Morse's insight: there are only two objects that a computer has to deal with in order to represent ""anything"".All the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as ""on/off"", ""magnetized/de-magnetized"", ""high-voltage/low-voltage"", etc.).
Alan Turing's insight: there are only five actions that a computer has to perform in order to do ""anything"".Every algorithm can be expressed in a language for a computer consisting of only five basic instructions:move left one location;
move right one location;
read symbol at current location;
print 0 at current location;
print 1 at current location.
Corrado Böhm and Giuseppe Jacopini's insight: there are only three ways of combining these actions (into more complex ones) that are needed in order for a computer to do ""anything"".Only three rules are needed to combine any set of basic instructions into more complex ones:
sequence: first do this, then do that;
 selection: IF such-and-such is the case, THEN do this, ELSE do that;
repetition: WHILE such-and-such is the case, DO this.
The three rules of Boehm's and Jacopini's insight can be further simplified with the use of goto (which means it is more elementary than structured programming).

Programming paradigms
Programming languages can be used to accomplish different tasks in different ways. Common programming paradigms include:

Functional programming, a style of building the structure and elements of computer programs that treats computation as the evaluation of mathematical functions and avoids state and mutable data. It is a declarative programming paradigm, which means programming is done with expressions or declarations instead of statements.
Imperative programming, a programming paradigm that uses statements that change a program's state. In much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. Imperative programming focuses on describing how a program operates.
Object-oriented programming, a programming paradigm based on the concept of ""objects"", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. A feature of objects is that an object's procedures can access and often modify the data fields of the object with which they are associated. Thus object-oriented computer programs are made out of objects that interact with one another.
Service-oriented programming, a programming paradigm that uses ""services"" as the unit of computer work, to design and implement integrated business applications and mission critical software programsMany languages offer support for multiple paradigms, making the distinction more a matter of style than of technical capabilities.

Research
Conferences are important events for computer science research. During these conferences, researchers from the public and private sectors present their recent work and meet. Unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications. One proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.

Education
Computer Science, known by its near synonyms, Computing, Computer Studies, has been taught in UK schools since the days of batch processing, mark sensitive cards and paper tape but usually to a select few students. In 1981, the BBC produced a micro-computer and classroom network and Computer Studies became common for GCE O level students (11–16-year-old), and Computer Science to A level students. Its importance was recognised, and it became a compulsory part of the National Curriculum, for Key Stage 3 & 4. In September 2014 it became an entitlement for all pupils over the age of 4.In the US, with 14,000 school districts deciding the curriculum, provision was fractured. According to a 2010 report by the Association for Computing Machinery (ACM) and Computer Science Teachers Association (CSTA), only 14 out of 50 states have adopted significant education standards for high school computer science. According to a 2021 report, only 51% of high schools in the US offer computer science.Israel, New Zealand, and South Korea have included computer science in their national secondary education curricula, and several others are following.

See also
Notes
References
Further reading
External links

DBLP Computer Science Bibliography
Association for Computing Machinery
Institute of Electrical and Electronics Engineers",5323,https://en.wikipedia.org/wiki/Computer_science
Glossary of computer science,"This glossary of computer science is a list of definitions of terms and concepts used in computer science, its sub-disciplines, and related fields, including terms relevant to software, data science, and computer programming.","This glossary of computer science is a list of definitions of terms and concepts used in computer science, its sub-disciplines, and related fields, including terms relevant to software, data science, and computer programming.

A
abstract data type (ADT)
A mathematical model for data types in which a data type is defined by its behavior (semantics) from the point of view of a user of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations. This contrasts with data structures, which are concrete representations of data from the point of view of an implementer rather than a user.

abstract method
One with only a signature and no implementation body. It is often used to specify that a subclass must provide an implementation of the method. Abstract methods are used to specify interfaces in some computer languages.

abstraction
1.  In software engineering and computer science, the process of removing physical, spatial, or temporal details or attributes in the study of objects or systems in order to more closely attend to other details of interest; it is also very similar in nature to the process of generalization.
2.  The result of this process: an abstract concept-object created by keeping common features or attributes to various concrete objects or systems of study.

agent architecture
A blueprint for software agents and intelligent control systems depicting the arrangement of components. The architectures implemented by intelligent agents are referred to as cognitive architectures.

agent-based model (ABM)
A class of computational models for simulating the actions and interactions of autonomous agents (both individual or collective entities such as organizations or groups) with a view to assessing their effects on the system as a whole. It combines elements of game theory, complex systems, emergence, computational sociology, multi-agent systems, and evolutionary programming. Monte Carlo methods are used to introduce randomness.

aggregate function
In database management, a function in which the values of multiple rows are grouped together to form a single value of more significant meaning or measurement, such as a sum, count, or max.

agile software development
An approach to software development under which requirements and solutions evolve through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, early delivery, and continual improvement, and it encourages rapid and flexible response to change.

algorithm
An unambiguous specification of how to solve a class of problems. Algorithms can perform calculation, data processing, and automated reasoning tasks. They are ubiquitous in computing technologies.

algorithm design
A method or mathematical process for problem-solving and for engineering algorithms. The design of algorithms is part of many solution theories of operation research, such as dynamic programming and divide-and-conquer. Techniques for designing and implementing algorithm designs are also called algorithm design patterns, such as the template method pattern and decorator pattern.

algorithmic efficiency
A property of an algorithm which relates to the number of computational resources used by the algorithm. An algorithm must be analyzed to determine its resource usage, and the efficiency of an algorithm can be measured based on usage of different resources. Algorithmic efficiency can be thought of as analogous to engineering productivity for a repeating or continuous process.

American Standard Code for Information Interchange (ASCII)
A character encoding standard for electronic communications. ASCII codes represent text in computers, telecommunications equipment, and other devices. Most modern character-encoding schemes are based on ASCII, although they support many additional characters.

application programming interface (API)
A set of subroutine definitions, communication protocols, and tools for building software. In general terms, it is a set of clearly defined methods of communication among various components. A good API makes it easier to develop a computer program by providing all the building blocks, which are then put together by the programmer.

application software
Also simply application or app.
Computer software designed to perform a group of coordinated functions, tasks, or activities for the benefit of the user. Common examples of applications include word processors, spreadsheets, accounting applications, web browsers, media players, aeronautical flight simulators, console games, and photo editors. This contrasts with system software, which is mainly involved with managing the computer's most basic running operations, often without direct input from the user. The collective noun application software refers to all applications collectively.

array data structure
Also simply array.
A data structure consisting of a collection of elements (values or variables), each identified by at least one array index or key. An array is stored such that the position of each element can be computed from its index tuple by a mathematical formula. The simplest type of data structure is a linear array, also called a one-dimensional array.

artifact
One of many kinds of tangible by-products produced during the development of software. Some artifacts (e.g. use cases, class diagrams, and other Unified Modeling Language (UML) models, requirements, and design documents) help describe the function, architecture, and design of software. Other artifacts are concerned with the process of development itself—such as project plans, business cases, and risk assessments.

artificial intelligence (AI)
Also machine intelligence.
Intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and other animals. In computer science, AI research is defined as the study of ""intelligent agents"": devices capable of perceiving their environment and taking actions that maximize the chance of successfully achieving their goals. Colloquially, the term ""artificial intelligence"" is applied when a machine mimics ""cognitive"" functions that humans associate with other human minds, such as ""learning"" and ""problem solving"".

ASCII
See American Standard Code for Information Interchange.

assertion
In computer programming, a statement that a predicate (Boolean-valued function, i.e. a true–false expression) is always true at that point in code execution. It can help a programmer read the code, help a compiler compile it, or help the program detect its own defects. For the latter, some programs check assertions by actually evaluating the predicate as they run and if it is not in fact true – an assertion failure – the program considers itself to be broken and typically deliberately crashes or throws an assertion failure exception.

associative array
An associative array, map, symbol table, or dictionary is an abstract data type composed of a collection of (key, value) pairs, such that each possible key appears at most once in the collection.

Operations associated with this data type allow:the addition of a pair to the collection
the removal of a pair from the collection
the modification of an existing pair
the lookup of a value associated with a particular key

automata theory
The study of abstract machines and automata, as well as the computational problems that can be solved using them. It is a theory in theoretical computer science and discrete mathematics (a subject of study in both mathematics and computer science).

automated reasoning
An area of computer science and mathematical logic dedicated to understanding different aspects of reasoning. The study of automated reasoning helps produce computer programs that allow computers to reason completely, or nearly completely, automatically. Although automated reasoning is considered a sub-field of artificial intelligence, it also has connections with theoretical computer science, and even philosophy.

B
bandwidth
The maximum rate of data transfer across a given path. Bandwidth may be characterized as network bandwidth, data bandwidth, or digital bandwidth.

Bayesian programming
A formalism and a methodology for having a technique to specify probabilistic models and solve problems when less than the necessary information is available.

benchmark
The act of running a computer program, a set of programs, or other operations, in order to assess the relative performance of an object, normally by running a number of standard tests and trials against it. The term benchmark is also commonly utilized for the purposes of elaborately designed benchmarking programs themselves.

best, worst and average case
Expressions of what the resource usage is at least, at most, and on average, respectively, for a given algorithm. Usually the resource being considered is running time, i.e. time complexity, but it could also be memory or some other resource. Best case is the function which performs the minimum number of steps on input data of n elements; worst case is the function which performs the maximum number of steps on input data of size n; average case is the function which performs an average number of steps on input data of n elements.

big data
A term used to refer to data sets that are too large or complex for traditional data-processing application software to adequately deal with. Data with many cases (rows) offer greater statistical power, while data with higher complexity (more attributes or columns) may lead to a higher false discovery rate.

big O notation
A mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity. It is a member of a family of notations invented by Paul Bachmann, Edmund Landau, and others, collectively called Bachmann–Landau notation or asymptotic notation.

binary number
In mathematics and digital electronics, a number expressed in the base-2 numeral system or binary numeral system, which uses only two symbols: typically 0 (zero) and 1 (one).

binary search algorithm
Also simply binary search, half-interval search, logarithmic search, or binary chop.
A search algorithm that finds the position of a target value within a sorted array.

binary tree
A tree data structure in which each node has at most two children, which are referred to as the left child and the right child. A recursive definition using just set theory notions is that a (non-empty) binary tree is a tuple (L, S, R), where L and R are binary trees or the empty set and S is a singleton set. Some authors allow the binary tree to be the empty set as well.

bioinformatics
An interdisciplinary field that combines biology, computer science, information engineering, mathematics, and statistics to develop methods and software tools for analyzing and interpreting biological data. Bioinformatics is widely used for in silico analyses of biological queries using mathematical and statistical techniques.

bit
A basic unit of information used in computing and digital communications; a portmanteau of binary digit. A binary digit can have one of two possible values, and may be physically represented with a two-state device. These state values are most commonly represented as either a 0or1.

bit rate (R)

Also bitrate.
In telecommunications and computing, the number of bits that are conveyed or processed per unit of time.

blacklist
Also block list.
In computing, a basic access control mechanism that allows through all elements (email addresses, users, passwords, URLs, IP addresses, domain names, file hashes, etc.), except those explicitly mentioned in a list of prohibited elements. Those items on the list are denied access. The opposite is a whitelist, which means only items on the list are allowed through whatever gate is being used while all other elements are blocked. A greylist contains items that are temporarily blocked (or temporarily allowed) until an additional step is performed.

BMP file format
Also bitmap image file, device independent bitmap (DIB) file format, or simply bitmap.
A raster graphics image file format used to store bitmap digital images independently of the display device (such as a graphics adapter), used especially on Microsoft Windows and OS/2 operating systems.

Boolean data type
A data type that has one of two possible values (usually denoted true and false), intended to represent the two truth values of logic and Boolean algebra. It is named after George Boole, who first defined an algebraic system of logic in the mid-19th century. The Boolean data type is primarily associated with conditional statements, which allow different actions by changing control flow depending on whether a programmer-specified Boolean condition evaluates to true or false. It is a special case of a more general logical data type (see probabilistic logic)—i.e. logic need not always be Boolean.

Boolean expression
An expression used in a programming language that returns a Boolean value when evaluated, that is one of true or false. A Boolean expression may be composed of a combination of the Boolean constants true or false, Boolean-typed variables, Boolean-valued operators, and Boolean-valued functions.

Boolean algebra
In mathematics and mathematical logic, the branch of algebra in which the values of the variables are the truth values true and false, usually denoted 1 and 0, respectively. Contrary to elementary algebra, where the values of the variables are numbers and the prime operations are addition and multiplication, the main operations of Boolean algebra are the conjunction and (denoted as ∧), the disjunction or (denoted as ∨), and the negation not (denoted as ¬). It is thus a formalism for describing logical relations in the same way that elementary algebra describes numeric relations.

byte
A unit of digital information that most commonly consists of eight bits, representing a binary number. Historically, the byte was the number of bits used to encode a single character of text in a computer and for this reason it is the smallest addressable unit of memory in many computer architectures.

booting
The procedures implemented in starting up a computer or computer appliance until it can be used. It can be initiated by hardware such as a button press or by a software command. After the power is switched on, the computer is relatively dumb and can read only part of its storage called read-only memory. There, a small program is stored called firmware. It does power-on self-tests and, most importantly, allows access to other types of memory like a hard disk and main memory. The firmware loads bigger programs into the computer's main memory and runs it.

C
callback
Also a call-after function.
Any executable code that is passed as an argument to other code that is expected to ""call back"" (execute) the argument at a given time. This execution may be immediate, as in a synchronous callback, or it might happen at a later time, as in an asynchronous callback.

central processing unit (CPU)
The electronic circuitry within a computer that carries out the instructions of a computer program by performing the basic arithmetic, logic, controlling, and input/output (I/O) operations specified by the instructions. The computer industry has used the term ""central processing unit"" at least since the early 1960s. Traditionally, the term ""CPU"" refers to a processor, more specifically to its processing unit and control unit (CU), distinguishing these core elements of a computer from external components such as main memory and I/O circuitry.

character
A unit of information that roughly corresponds to a grapheme, grapheme-like unit, or symbol, such as in an alphabet or syllabary in the written form of a natural language.

cipher
Also cypher.
In cryptography, an algorithm for performing encryption or decryption—a series of well-defined steps that can be followed as a procedure.

class
In object-oriented programming, an extensible program-code-template for creating objects, providing initial values for state (member variables) and implementations of behavior (member functions or methods). In many languages, the class name is used as the name for the class (the template itself), the name for the default constructor of the class (a subroutine that creates objects), and as the type of objects generated by instantiating the class; these distinct concepts are easily conflated.

class-based programming
Also class-orientation.
A style of object-oriented programming (OOP) in which inheritance occurs via defining ""classes"" of objects, instead of via the objects alone (compare prototype-based programming).

client
A piece of computer hardware or software that accesses a service made available by a server. The server is often (but not always) on another computer system, in which case the client accesses the service by way of a network. The term applies to the role that programs or devices play in the client–server model.

cleanroom software engineering
A software development process intended to produce software with a certifiable level of reliability. The cleanroom process was originally developed by Harlan Mills and several of his colleagues including Alan Hevner at IBM. The focus of the cleanroom process is on defect prevention, rather than defect removal.

closure
Also lexical closure or function closure.
A technique for implementing lexically scoped name binding in a language with first-class functions. Operationally, a closure is a record storing a function together with an environment.

cloud computing
Shared pools of configurable computer system resources and higher-level services that can be rapidly provisioned with minimal management effort, often over the Internet.  Cloud computing relies on sharing of resources to achieve coherence and economies of scale, similar to a public utility.

code library
A collection of non-volatile resources used by computer programs, often for software development. These may include configuration data, documentation, help data, message templates, pre-written code and subroutines, classes, values or type specifications. In IBM's OS/360 and its successors they are referred to as partitioned data sets.

coding
Computer programming is the process of designing and building an executable computer program for accomplishing a specific computing task. Programming involves tasks such as analysis, generating algorithms, profiling algorithms' accuracy and resource consumption, and the implementation of algorithms in a chosen programming language (commonly referred to as coding). The source code of a program is written in one or more programming languages. The purpose of programming is to find a sequence of instructions that will automate the performance of a task for solving a given problem. The process of programming thus often requires expertise in several different subjects, including knowledge of the application domain, specialized algorithms, and formal logic.

coding theory
The study of the properties of codes and their respective fitness for specific applications. Codes are used for data compression, cryptography, error detection and correction, data transmission and data storage. Codes are studied by various scientific disciplines—such as information theory, electrical engineering, mathematics, linguistics, and computer science—for the purpose of designing efficient and reliable data transmission methods. This typically involves the removal of redundancy and the correction or detection of errors in the transmitted data.

cognitive science
The interdisciplinary, scientific study of the mind and its processes. It examines the nature, the tasks, and the functions of cognition (in a broad sense). Cognitive scientists study intelligence and behavior, with a focus on how nervous systems represent, process, and transform information. Mental faculties of concern to cognitive scientists include language, perception, memory, attention, reasoning, and emotion; to understand these faculties, cognitive scientists borrow from fields such as linguistics, psychology, artificial intelligence, philosophy, neuroscience, and anthropology.

collection
A collection or container is a grouping of some variable number of data items (possibly zero) that have some shared significance to the problem being solved and need to be operated upon together in some controlled fashion.  Generally, the data items will be of the same type or, in languages supporting inheritance, derived from some common ancestor type. A collection is a concept applicable to abstract data types, and does not prescribe a specific implementation as a concrete data structure, though often there is a conventional choice (see Container for type theory discussion).

comma-separated values (CSV)
A delimited text file that uses a comma to separate values. A CSV file stores tabular data (numbers and text) in plain text.  Each line of the file is a data record.  Each record consists of one or more fields, separated by commas. The use of the comma as a field separator is the source of the name for this file format.

compiler
A computer program that transforms computer code written in one programming language (the source language) into another programming language (the target language). Compilers are a type of translator that support digital devices, primarily computers. The name compiler is primarily used for programs that translate source code from a high-level programming language to a lower-level language (e.g. assembly language, object code, or machine code) to create an executable program.

computability theory
also known as recursion theory, is a branch of mathematical logic, of computer science, and of the theory of computation that originated in the 1930s with the study of computable functions and Turing degrees. The field has since expanded to include the study of generalized computability and definability. In these areas, recursion theory overlaps with proof theory and effective descriptive set theory.

computation
Any type of calculation that includes both arithmetical and non-arithmetical steps and follows a well-defined model, e.g. an algorithm. The study of computation is paramount to the discipline of computer science.

computational biology
Involves the development and application of data-analytical and theoretical methods, mathematical modelling and computational simulation techniques to the study of biological, ecological, behavioural, and social systems. The field is broadly defined and includes foundations in biology, applied mathematics, statistics, biochemistry, chemistry, biophysics, molecular biology, genetics, genomics, computer science, and evolution.  Computational biology is different from biological computing, which is a subfield of computer science and computer engineering using bioengineering and biology to build computers.

computational chemistry
A branch of chemistry that uses computer simulation to assist in solving chemical problems. It uses methods of theoretical chemistry, incorporated into efficient computer programs, to calculate the structures and properties of molecules and solids.

computational complexity theory
A subfield of computational science which focuses on classifying computational problems according to their inherent difficulty, and relating these classes to each other. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm.

computational model
A mathematical model in computational science that requires extensive computational resources to study the behavior of a complex system by computer simulation.

computational neuroscience
Also theoretical neuroscience or mathematical neuroscience.
A branch of neuroscience which employs mathematical models, theoretical analysis, and abstractions of the brain to understand the principles that govern the development, structure, physiology, and cognitive abilities of the nervous system.

computational physics
Is the study and implementation of numerical analysis to solve problems in physics for which a quantitative theory already exists. Historically, computational physics was the first application of modern computers in science, and is now a subset of computational science.

computational science
Also scientific computing and scientific computation (SC).
An interdisciplinary field that uses advanced computing capabilities to understand and solve complex problems. It is an area of science which spans many disciplines, but at its core it involves the development of computer models and simulations to understand complex natural systems.

computational steering
Is the practice of manually intervening with an otherwise autonomous computational process, to change its outcome.

computer
A device that can be instructed to carry out sequences of arithmetic or logical operations automatically via computer programming. Modern computers have the ability to follow generalized sets of operations, called programs. These programs enable computers to perform an extremely wide range of tasks.

computer architecture
A set of rules and methods that describe the functionality, organization, and implementation of computer systems. Some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. In other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation.

computer data storage
Also simply storage or memory.
A technology consisting of computer components and recording media that are used to retain digital data. Data storage is a core function and fundamental component of all modern computer systems.: 15–16 

computer ethics
A part of practical philosophy concerned with how computing professionals should make decisions regarding professional and social conduct.

computer graphics
Pictures and films created using computers. Usually, the term refers to computer-generated image data created with the help of specialized graphical hardware and software. It is a vast and recently developed area of computer science.

computer network
Also data network.
A digital telecommunications network which allows nodes to share resources. In computer networks, computing devices exchange data with each other using connections (data links) between nodes. These data links are established over cable media such as wires or optic cables, or wireless media such as Wi-Fi.

computer program
Is a collection of instructions that can be executed by a computer to perform a specific task. 

computer programming
The process of designing and building an executable computer program for accomplishing a specific computing task. Programming involves tasks such as analysis, generating algorithms, profiling algorithms' accuracy and resource consumption, and the implementation of algorithms in a chosen programming language (commonly referred to as coding). The source code of a program is written in one or more programming languages. The purpose of programming is to find a sequence of instructions that will automate the performance of a task for solving a given problem. The process of programming thus often requires expertise in several different subjects, including knowledge of the application domain, specialized algorithms, and formal logic.

computer science
The theory, experimentation, and engineering that form the basis for the design and use of computers. It involves the study of algorithms that process, store, and communicate digital information. A computer scientist specializes in the theory of computation and the design of computational systems.

computer scientist
A person who has acquired the knowledge of computer science, the study of the theoretical foundations of information and computation and their application.

computer security
Also cybersecurity or information technology security (IT security).
The protection of computer systems from theft or damage to their hardware, software, or electronic data, as well as from disruption or misdirection of the services they provide.

computer vision
An interdisciplinary scientific field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do.

computing
Is any goal-oriented activity requiring, benefiting from, or creating computing machinery. It includes study of algorithmic processes and development of both hardware and software. It has scientific, engineering, mathematical, technological and social aspects. Major computing fields include computer engineering, computer science, cybersecurity, data science, information systems, information technology and software engineering.

concatenation
In formal language theory and computer programming, string concatenation  is the operation of joining character strings end-to-end.  For example, the concatenation of ""snow"" and ""ball"" is ""snowball"". In certain formalisations of concatenation theory, also called string theory, string concatenation is a primitive notion.

Concurrency
The ability of different parts or units of a program, algorithm, or problem to be executed out-of-order or in partial order, without affecting the final outcome.  This allows for parallel execution of the concurrent units, which can significantly improve overall speed of the execution in multi-processor and multi-core systems. In more technical terms, concurrency refers to the decomposability property of a program, algorithm, or problem into order-independent or partially-ordered components or units.

conditional
Also conditional statement, conditional expression, and conditional construct.
A feature of a programming language which performs different computations or actions depending on whether a programmer-specified Boolean condition evaluates to true or false. Apart from the case of branch predication, this is always achieved by selectively altering the control flow based on some condition.

container
Is a class, a data structure, or an abstract data type (ADT) whose instances are collections of other objects. In other words, they store objects in an organized way that follows specific access rules. The size of the container depends on the number of objects (elements) it contains. Underlying (inherited) implementations of various container types may vary in size and complexity, and provide flexibility in choosing the right implementation for any given scenario.

continuation-passing style (CPS)
A style of functional programming in which control is passed explicitly in the form of a continuation. This is contrasted with direct style, which is the usual style of programming. Gerald Jay Sussman and Guy L. Steele, Jr. coined the phrase in AI Memo 349 (1975), which sets out the first version of the Scheme programming language.

control flow
Also flow of control.
The order in which individual statements, instructions or function calls of an imperative program are executed or evaluated. The emphasis on explicit control flow distinguishes an imperative programming language from a declarative programming language.

Creative Commons (CC)
An American non-profit organization devoted to expanding the range of creative works available for others to build upon legally and to share. The organization has released several copyright-licenses, known as Creative Commons licenses, free of charge to the public.

cryptography
Or cryptology,  is the practice and study of techniques for secure communication in the presence of third parties called adversaries. More generally, cryptography is about constructing and analyzing protocols that prevent third parties or the public from reading private messages; various aspects in information security such as data confidentiality, data integrity, authentication, and non-repudiation are central to modern cryptography. Modern cryptography exists at the intersection of the disciplines of mathematics, computer science, electrical engineering, communication science, and physics. Applications of cryptography include electronic commerce, chip-based payment cards, digital currencies, computer passwords, and military communications.

CSV
See comma-separated values.

cyberbullying
Also cyberharassment or online bullying.
A form of bullying or harassment using electronic means.

cyberspace
Widespread, interconnected digital technology.

D
daemon
In multitasking computer operating systems, a daemon ( or ) is a computer program that runs as a background process, rather than being under the direct control of an interactive user. Traditionally, the process names of a daemon end with the letter d, for clarification that the process is in fact a daemon, and for differentiation between a daemon and a normal computer program. For example, syslogd is a daemon that implements system logging facility, and sshd is a daemon that serves incoming SSH connections.

Data

data center
Also data centre.
A dedicated space used to house computer systems and associated components, such as telecommunications and data storage systems. It generally includes redundant or backup components and infrastructure for power supply, data communications connections, environmental controls (e.g. air conditioning and fire suppression) and various security devices.

database
An organized collection of data, generally stored and accessed electronically from a computer system. Where databases are more complex, they are often developed using formal design and modeling techniques.

data mining
Is a process of discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems. Data mining is an interdisciplinary subfield of computer science and statistics with an overall goal to extract information (with intelligent methods) from a data set and transform the information into a comprehensible structure for further use. Data mining is the analysis step of the ""knowledge discovery in databases"" process, or KDD. Aside from the raw analysis step, it also involves database and data management aspects, data pre-processing, model and inference considerations, interestingness metrics, complexity considerations, post-processing of discovered structures, visualization, and online updating. 

data science
An interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from data in various forms, both structured and unstructured, similar to data mining. Data science is a ""concept to unify statistics, data analysis, machine learning and their related methods"" in order to ""understand and analyze actual phenomena"" with data. It employs techniques and theories drawn from many fields within the context of mathematics, statistics, information science, and computer science.

data structure
A data organization, management, and storage format that enables efficient access and modification. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data.

data type
Also simply type.
An attribute of data which tells the compiler or interpreter how the programmer intends to use the data. Most programming languages support common data types of real, integer, and Boolean. A data type constrains the values that an expression, such as a variable or a function, might take. This data type defines the operations that can be done on the data, the meaning of the data, and the way values of that type can be stored. A type of value from which an expression may take its value.

debugging
The process of finding and resolving defects or problems within a computer program that prevent correct operation of computer software or the system as a whole. Debugging tactics can involve interactive debugging, control flow analysis, unit testing, integration testing, log file analysis, monitoring at the application or system level, memory dumps, and profiling.

declaration
In computer programming, a language construct that specifies properties of an identifier: it declares what a word (identifier) ""means"". Declarations are most commonly used for functions, variables, constants, and classes, but can also be used for other entities such as enumerations and type definitions. Beyond the name (the identifier itself) and the kind of entity (function, variable, etc.), declarations typically specify the data type (for variables and constants), or the type signature (for functions); types may also include dimensions, such as for arrays. A declaration is used to announce the existence of the entity to the compiler; this is important in those strongly typed languages that require functions, variables, and constants, and their types, to be specified with a declaration before use, and is used in forward declaration. The term ""declaration"" is frequently contrasted with the term ""definition"", but meaning and usage varies significantly between languages.

digital data
In information theory and information systems, the discrete, discontinuous representation of information or works. Numbers and letters are commonly used representations.

digital signal processing (DSP)
The use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations.  The signals processed in this manner are a sequence of numbers that represent samples of a continuous variable in a domain such as time, space, or frequency.

discrete event simulation (DES)
A model of the operation of a system as a discrete sequence of events in time. Each event occurs at a particular instant in time and marks a change of state in the system. Between consecutive events, no change in the system is assumed to occur; thus the simulation can directly jump in time from one event to the next.

disk storage
(Also sometimes called drive storage) is a general category of storage mechanisms where data is recorded by various electronic, magnetic, optical, or mechanical changes to a surface layer of one or more rotating disks. A disk drive is a device implementing such a storage mechanism. Notable types are the hard disk drive (HDD) containing a non-removable disk, the  floppy disk drive (FDD) and its removable floppy disk, and various optical disc drives (ODD) and associated optical disc media.

distributed computing
A field of computer science that studies distributed systems. A distributed system is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another. The components interact with one another in order to achieve a common goal. Three significant characteristics of distributed systems are: concurrency of components, lack of a global clock, and independent failure of components. Examples of distributed systems vary from SOA-based systems to massively multiplayer online games to peer-to-peer applications.

divide and conquer algorithm
An algorithm design paradigm based on multi-branched recursion. A divide-and-conquer algorithm works by recursively breaking down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem.

DNS
See Domain Name System.

documentation
Written text or illustration that accompanies computer software or is embedded in the source code. It either explains how it operates or how to use it, and may mean different things to people in different roles.

domain
Is the targeted subject area of a computer program. It is a term used in software engineering. Formally it represents the target subject of a specific programming project, whether narrowly or broadly defined.

Domain Name System (DNS)
A hierarchical and decentralized naming system for computers, services, or other resources connected to the Internet or to a private network. It associates various information with domain names assigned to each of the participating entities. Most prominently, it translates more readily memorized domain names to the numerical IP addresses needed for locating and identifying computer services and devices with the underlying network protocols. By providing a worldwide, distributed directory service, the Domain Name System has been an essential component of the functionality of the Internet since 1985.

double-precision floating-point format
A computer number format. It represents a wide dynamic range of numerical values by using a floating radix point.

download
In computer networks, to receive data from a remote system, typically a server such as a web server, an FTP server, an email server, or other similar systems. This contrasts with uploading, where data is sent to a remote server. A download is a file offered for downloading or that has been downloaded, or the process of receiving such a file.

E
edge device
A device which provides an entry point into enterprise or service provider core networks. Examples include routers, routing switches, integrated access devices (IADs), multiplexers, and a variety of metropolitan area network (MAN) and wide area network (WAN) access devices.  Edge devices also provide connections into carrier and service provider networks. An edge device that connects a local area network to a high speed switch or backbone (such as an ATM switch) may be called an edge concentrator.

encryption
In cryptography, encryption is the process of encoding information. This process converts the original representation of the information, known as plaintext, into an alternative form known as ciphertext. Ideally, only authorized parties can decipher a ciphertext back to plaintext and access the original information. Encryption does not itself prevent interference but denies the intelligible content to a would-be interceptor. For technical reasons, an encryption scheme usually uses a pseudo-random encryption key generated by an algorithm. It is possible to decrypt the message without possessing the key, but, for a well-designed encryption scheme, considerable computational resources and skills are required. An authorized recipient can easily decrypt the message with the key provided by the originator to recipients but not to unauthorized users. Historically, various forms of encryption have been used to aid in cryptography. Early encryption techniques were often utilized in military messaging. Since then, new techniques have emerged and become commonplace in all areas of modern computing. Modern encryption schemes utilize the concepts of public-key and symmetric-key. Modern encryption techniques ensure security because modern computers are inefficient at cracking the encryption.

event
An action or occurrence recognized by software, often originating asynchronously from the external environment, that may be handled by the software. Because an event is an entity which encapsulates the action and the contextual variables triggering the action, the acrostic mnemonic ""Execution Variable Encapsulating Named Trigger"" is often used to clarify the concept.

event-driven programming
A programming paradigm in which the flow of the program is determined by events such as user actions (mouse clicks, key presses), sensor outputs, or messages from other programs or threads. Event-driven programming is the dominant paradigm used in graphical user interfaces and other applications (e.g. JavaScript web applications) that are centered on performing certain actions in response to user input. This is also true of programming for device drivers (e.g. P in USB device driver stacks).

evolutionary computing
A family of algorithms for global optimization inspired by biological evolution, and the subfield of artificial intelligence and soft computing studying these algorithms. In technical terms, they are a family of population-based trial-and-error problem-solvers with a metaheuristic or stochastic optimization character.

executable
Also executable code, executable file, executable program, or simply executable.
Causes a computer ""to perform indicated tasks according to encoded instructions,"" as opposed to a data file that must be parsed by a program to be meaningful. The exact interpretation depends upon the use - while ""instructions"" is traditionally taken to mean machine code instructions for a physical CPU, in some contexts a file containing bytecode or scripting language instructions may also be considered executable.

executable module

execution
In computer and software engineering is the process by which a computer or  virtual machine executes the instructions of a computer program. Each instruction of a program is a description of a particular 
action which to be carried out in order for a specific problem to be solved; as instructions of a program and therefore the actions they describe are being carried out by an executing machine, specific effects are produced in accordance to the semantics of the instructions being executed. 

exception handling
The process of responding to the occurrence, during computation, of exceptions – anomalous or exceptional conditions requiring special processing – often disrupting the normal flow of program execution. It is provided by specialized programming language constructs, computer hardware mechanisms like interrupts, or operating system IPC facilities like signals.

Existence detection
An existence check before reading a file can catch and/or prevent a fatal error.

expression
In a programming language, a combination of one or more constants, variables, operators, and functions that the programming language interprets (according to its particular rules of precedence and of association) and computes to produce (""to return"", in a stateful environment) another value. This process, as for mathematical expressions, is called evaluation.

external library

F
fault-tolerant computer system
A system designed around the concept of fault tolerance. In essence, they must be able to continue working to a level of satisfaction in the presence of errors or breakdowns.

feasibility study
An investigation which aims to objectively and rationally uncover the strengths and weaknesses of an existing business or proposed venture, opportunities and threats present in the natural environment, the resources required to carry through, and ultimately the prospects for success. In its simplest terms, the two criteria to judge feasibility are cost required and value to be attained.

field
Data that has several parts, known as a record, can be divided into fields. Relational databases arrange data as sets of database records, so called rows. Each record consists of several fields; the fields of all records form the columns.
Examples of fields: name, gender, hair colour. 

filename extension
An identifier specified as a suffix to the name of a computer file. The extension indicates a characteristic of the file contents or its intended use.

filter (software)
A computer program or subroutine to process a stream, producing another stream. While a single filter can be used individually, they are frequently strung together to form a pipeline.

floating point arithmetic
In computing, floating-point arithmetic (FP) is arithmetic using formulaic representation of real numbers as an approximation to support a trade-off between range and precision. For this reason, floating-point computation is often found in systems which include very small and very large real numbers, which require fast processing times. A number is, in general, represented approximately to a fixed number of significant digits (the significand) and scaled using an exponent in some fixed base; the base for the scaling is normally two, ten, or sixteen. A number that can be represented exactly is of the following form:
significand×baseexponent,{\displaystyle {\text{significand}}\times {\text{base}}^{\text{exponent}},}
where significand is an integer, base is an integer greater than or equal to two, and exponent is also an integer.
For example:
1.2345=12345⏟significand×10⏟base−4⏞exponent.{\displaystyle 1.2345=\underbrace {12345} _{\text{significand}}\times \underbrace {10} _{\text{base}}\!\!\!\!\!\!^{\overbrace {-4} ^{\text{exponent}}}.}for loop
Also for-loop. 
A control flow statement for specifying iteration, which allows code to be executed repeatedly. Various keywords are used to specify this statement: descendants of ALGOL use ""for"", while descendants of Fortran use ""do"". There are also other possibilities, e.g. COBOL uses ""PERFORM VARYING"".

formal methods
A set of mathematically based techniques for the specification, development, and verification of software and hardware systems. The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design.

formal verification
The act of proving or disproving the correctness of intended algorithms underlying a system with respect to a certain formal specification or property, using formal methods of mathematics.

functional programming
A programming paradigm—a style of building the structure and elements of computer programs–that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. It is a declarative programming paradigm in that programming is done with expressions or declarations instead of statements.

G
game theory
The study of mathematical models of strategic interaction between rational decision-makers. It has applications in all fields of social science, as well as in logic and computer science. Originally, it addressed zero-sum games, in which each participant's gains or losses are exactly balanced by those of the other participants. Today, game theory applies to a wide range of behavioral relations, and is now an umbrella term for the science of logical decision making in humans, animals, and computers.

garbage in, garbage out (GIGO)
A term used to describe the concept that flawed or nonsense input data produces nonsense output or ""garbage"". It can also refer to the unforgiving nature of programming, in which a poorly written program might produce nonsensical behavior.

Graphics Interchange Format

gigabyte
A multiple of the unit byte for digital information. The prefix giga means 109 in the International System of Units (SI). Therefore, one gigabyte is 1000000000bytes.  The unit symbol for the gigabyte is GB.

global variable
In computer programming, a variable with global scope, meaning that it is visible (hence accessible) throughout the program, unless shadowed. The set of all global variables is known as the global environment or global state. In compiled languages, global variables are generally static variables, whose extent (lifetime) is the entire runtime of the program, though in interpreted languages (including command-line interpreters), global variables are generally dynamically allocated when declared, since they are not known ahead of time.

graph theory
In mathematics, the study of graphs, which are mathematical structures used to model pairwise relations between objects. A graph in this context is made up of vertices (also called nodes or points) which are connected by edges (also called links or lines). A distinction is made between undirected graphs, where edges link two vertices symmetrically, and directed graphs, where edges link two vertices asymmetrically.

H
handle
In computer programming, a handle is an abstract reference to a resource that is used when application software references blocks of memory or objects that are managed by another system like a database or an operating system.

hard problem
Computational complexity theory focuses on classifying computational problems according to their inherent difficulty, and relating these classes to each other. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm.

hash function
Any function that can be used to map data of arbitrary size to data of a fixed size. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes. Hash functions are often used in combination with a hash table, a common data structure used in computer software for rapid data lookup. Hash functions accelerate table or database lookup by detecting duplicated records in a large file.

hash table
In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index into an array of buckets or slots, from which the desired value can be found.

heap
A specialized tree-based data structure which is essentially an almost complete tree that satisfies the heap property: if P is a parent node of C, then the key (the value) of P is either greater than or equal to (in a max heap) or less than or equal to (in a min heap) the key of C. The node at the ""top"" of the heap (with no parents) is called the root node.

heapsort
A comparison-based sorting algorithm. Heapsort can be thought of as an improved selection sort: like that algorithm, it divides its input into a sorted and an unsorted region, and it iteratively shrinks the unsorted region by extracting the largest element and moving that to the sorted region. The improvement consists of the use of a heap data structure rather than a linear-time search to find the maximum.

human-computer interaction (HCI)
Researches the design and use of computer technology, focused on the interfaces between people (users) and computers. Researchers in the field of HCI both observe the ways in which humans interact with computers and design technologies that let humans interact with computers in novel ways. As a field of research, human–computer interaction is situated at the intersection of computer science, behavioral sciences, design, media studies, and several other fields of study.

I
identifier
In computer languages, identifiers are tokens (also called symbols) which name language entities. Some of the kinds of entities an identifier might denote include variables, types, labels, subroutines,  and packages.

IDE
Integrated development environment.

image processing

imperative programming
A programming paradigm that uses statements that change a program's state. In much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. Imperative programming focuses on describing how a program operates.

incremental build model
A method of software development where the product is designed, implemented and tested incrementally (a little more is added each time) until the product is finished. It involves both development and maintenance. The product is defined as finished when it satisfies all of its requirements. This model combines the elements of the waterfall model with the iterative philosophy of prototyping.

information space analysis
A deterministic method, enhanced by machine intelligence, for locating and assessing resources for team-centric efforts.

information visualization

inheritance
In object-oriented programming, the mechanism of basing an object or class upon another object (prototype-based inheritance) or class (class-based inheritance), retaining similar implementation. Also defined as deriving new classes (sub classes) from existing ones (super class or base class) and forming them into a hierarchy of classes.

input/output (I/O)
Also informally io or IO. 
The communication between an information processing system, such as a computer, and the outside world, possibly a human or another information processing system. Inputs are the signals or data received by the system and outputs are the signals or data sent from it. The term can also be used as part of an action; to ""perform I/O"" is to perform an input or output operation.

insertion sort
A simple sorting algorithm that builds the final sorted array (or list) one item at a time.

instruction cycle
Also fetch–decode–execute cycle or simply fetch-execute cycle.
The cycle which the central processing unit (CPU) follows from boot-up until the computer has shut down in order to process instructions. It is composed of three main stages: the fetch stage, the decode stage, and the execute stage.

integer
A datum of integral data type, a data type that represents some range of mathematical integers. Integral data types may be of different sizes and may or may not be allowed to contain negative values. Integers are commonly represented in a computer as a group of binary digits (bits). The size of the grouping varies so the set of integer sizes available varies between different types of computers. Computer hardware, including virtual machines, nearly always provide a way to represent a processor register or memory address as an integer.

integrated development environment (IDE)
A software application that provides comprehensive facilities to computer programmers for software development. An IDE normally consists of at least a source code editor, build automation tools, and a debugger.

integration testing
(sometimes called integration and testing, abbreviated I&T) is the phase in software testing in which individual software modules are combined and tested as a group. Integration testing is conducted to evaluate the compliance of a system or component with specified functional requirements. It occurs after unit testing and before validation testing. Integration testing takes as its input modules that have been unit tested, groups them in larger aggregates, applies tests defined in an integration test plan to those aggregates, and delivers as its output the integrated system ready for system testing.

intellectual property (IP)
A category of legal property that includes intangible creations of the human intellect. There are many types of intellectual property, and some countries recognize more than others. The most well-known types are copyrights, patents, trademarks, and trade secrets.

intelligent agent
In artificial intelligence, an intelligent agent (IA) refers to an autonomous entity which acts, directing its activity towards achieving goals (i.e. it is an agent), upon an environment using observation through sensors and consequent actuators (i.e. it is intelligent). Intelligent agents may also learn or use knowledge to achieve their goals. They may be very simple or very complex. A reflex machine, such as a thermostat, is considered an example of an intelligent agent.

interface
A shared boundary across which two or more separate components of a computer system exchange information. The exchange can be between software, computer hardware, peripheral devices, humans, and combinations of these. Some computer hardware devices, such as a touchscreen, can both send and receive data through the interface, while others such as a mouse or microphone may only provide an interface to send data to a given system.

internal documentation
Computer software is said to have Internal Documentation if the notes on how and why various parts of code operate is included within the source code as comments.  It is often combined with meaningful variable names with the intention of providing potential future programmers a means of understanding the workings of the code. This contrasts with external documentation, where programmers keep their notes and explanations in a separate document.

internet
The global system of interconnected computer networks that use the Internet protocol suite (TCP/IP) to link devices worldwide. It is a network of networks that consists of private, public, academic, business, and government networks of local to global scope, linked by a broad array of electronic, wireless, and optical networking technologies.

internet bot
Also web robot, robot, or simply bot.
A software application that runs automated tasks (scripts) over the Internet. Typically, bots perform tasks that are both simple and structurally repetitive, at a much higher rate than would be possible for a human alone. The largest use of bots is in web spidering (web crawler), in which an automated script fetches, analyzes and files information from web servers at many times the speed of a human.

interpreter
A computer program that directly executes instructions written in a programming or scripting language, without requiring them to have been previously compiled into a machine language program.

invariant
One can encounter invariants that can be relied upon to be true during the execution of a program, or during some portion of it. It is a logical assertion that is always held to be true during a certain phase of execution. For example, a loop invariant is a condition that is true at the beginning and the end of every execution of a loop.

iteration
Is the repetition of a process in order to generate an outcome. The sequence will approach some end point or end value. Each repetition of the process is a single iteration, and the outcome of each iteration is then the starting point of the next iteration.  In mathematics and computer science, iteration (along with the related technique of recursion) is a standard element of algorithms.

J
Java
A general-purpose programming language that is class-based, object-oriented(although not a pure OO language), and designed to have as few implementation dependencies as possible. It is intended to let application developers ""write once, run anywhere"" (WORA), meaning that compiled Java code can run on all platforms that support Java without the need for recompilation.

K
kernel
The first section of an operating system to load into memory. As the center of the operating system, the kernel needs to be small, efficient, and loaded into a protected area in the memory so that it cannot be overwritten. It may be responsible for such essential tasks as disk drive management, file management, memory management, process management, etc.

L
library (computing)
A collection of non-volatile resources used by computer programs, often for software development. These may include configuration data, documentation, help data, message templates, pre-written code and subroutines, classes, values, or type specifications.

linear search
Also sequential search.
A method for finding an element within a list. It sequentially checks each element of the list until a match is found or the whole list has been searched.

linked list
A linear collection of data elements, whose order is not given by their physical placement in memory. Instead, each element points to the next. It is a data structure consisting of a collection of nodes which together represent a sequence.

linker
 or link editor, is a computer utility program that takes one or more object files generated by a compiler or an assembler and combines them into a single executable file, library file, or another 'object' file.  A simpler version that writes its output directly to memory is called the loader, though loading is typically considered a separate process.

list
An abstract data type that represents a countable number of ordered values, where the same value may occur more than once. An instance of a list is a computer representation of the mathematical concept of a finite sequence; the (potentially) infinite analog of a list is a stream.: §3.5  Lists are a basic example of containers, as they contain other values. If the same value occurs multiple times, each occurrence is considered a distinct item.

loader
The part of an operating system that is responsible for loading programs and libraries. It is one of the essential stages in the process of starting a program, as it places programs into memory and prepares them for execution. Loading a program involves reading the contents of the executable file containing the program instructions into memory, and then carrying out other required preparatory tasks to prepare the executable for running. Once loading is complete, the operating system starts the program by passing control to the loaded program code.

logic error
In computer programming, a bug in a program that causes it to operate incorrectly, but not to terminate abnormally (or crash). A logic error produces unintended or undesired output or other behaviour, although it may not immediately be recognized as such.

logic programming
A type of programming paradigm which is largely based on formal logic. Any program written in a logic programming language is a set of sentences in logical form, expressing facts and rules about some problem domain.  Major logic programming language families include Prolog, answer set programming (ASP), and Datalog.

M
machine learning (ML)
The scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to perform the task.

machine vision (MV)
The technology and methods used to provide imaging-based automatic inspection and analysis for such applications as automatic inspection, process control, and robot guidance, usually in industry. Machine vision refers to many technologies, software and hardware products, integrated systems, actions, methods and expertise. Machine vision as a systems engineering discipline can be considered distinct from computer vision, a form of computer science. It attempts to integrate existing technologies in new ways and apply them to solve real world problems. The term is the prevalent one for these functions in industrial automation environments but is also used for these functions in other environments such as security and vehicle guidance.

mathematical logic
A subfield of mathematics exploring the applications of formal logic to mathematics.  It bears close connections to metamathematics, the foundations of mathematics, and theoretical computer science. The unifying themes in mathematical logic include the study of the expressive power of formal systems and the deductive power of formal proof systems.

matrix
In mathematics, a matrix, (plural matrices), is a rectangular array (see irregular matrix) of numbers, symbols, or expressions, arranged in rows and columns.

memory
Computer data storage, often called storage, is a technology consisting of computer components and recording media that are used to retain digital data. It is a core function and fundamental component of computers.: 15–16 

merge sort
Also mergesort.
An efficient, general-purpose, comparison-based sorting algorithm. Most implementations produce a stable sort, which means that the order of equal elements is the same in the input and output. Merge sort is a divide and conquer algorithm that was invented by John von Neumann in 1945. A detailed description and analysis of bottom-up mergesort appeared in a report by Goldstine and von Neumann as early as 1948.

method
In object-oriented programming (OOP), a procedure associated with a message and an object. An object consists of data and behavior. The data and behavior comprise an interface, which specifies how the object may be utilized by any of various consumers of the object.

methodology
In software engineering, a software development process is the process of dividing software development work into distinct phases to improve design, product management, and project management. It is also known as a software development life cycle (SDLC). The methodology may include the pre-definition of specific deliverables and artifacts that are created and completed by a project team to develop or maintain an application.

modem
Portmanteau of modulator-demodulator.
A hardware device that converts data into a format suitable for a transmission medium so that it can be transmitted from one computer to another (historically along telephone wires). A modem modulates one or more carrier wave signals to encode digital information for transmission and demodulates signals to decode the transmitted information. The goal is to produce a signal that can be transmitted easily and decoded reliably to reproduce the original digital data. Modems can be used with almost any means of transmitting analog signals from light-emitting diodes to radio. A common type of modem is one that turns the digital data of a computer into modulated electrical signal for transmission over telephone lines and demodulated by another modem at the receiver side to recover the digital data.

N
natural language processing (NLP)
A subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.  Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.

node
Is a basic unit of a data structure, such as a linked list or tree data structure. Nodes contain data and also may link to other nodes. Links between nodes are often implemented by pointers.

number theory
A branch of pure mathematics devoted primarily to the study of the integers and integer-valued functions.

numerical analysis
The study of algorithms that use numerical approximation (as opposed to symbolic manipulations) for the problems of mathematical analysis (as distinguished from discrete mathematics).

numerical method
In numerical analysis, a numerical method is a mathematical tool designed to solve numerical problems. The implementation of a numerical method with an appropriate convergence check in a programming language is called a numerical algorithm.

O
object
An object can be a variable, a data structure, a function, or a method, and as such, is a value in memory referenced by an identifier.  In the class-based object-oriented programming paradigm, object refers to a particular instance of a class, where the object can be a combination of variables, functions, and data structures.  In relational database management, an object can be a table or column, or an association between data and a database entity (such as relating a person's age to a specific person).

object code
Also object module.
The product of a compiler. In a general sense object code is a sequence of statements or instructions in a computer language, usually a machine code language (i.e., binary) or an intermediate language such as register transfer language (RTL). The term indicates that the code is the goal or result of the compiling process, with some early sources referring to source code as a ""subject program.""

object-oriented analysis and design (OOAD)
A technical approach for analyzing and designing an application, system, or business by applying object-oriented programming, as well as using visual modeling throughout the software development process to guide stakeholder communication and product quality.

object-oriented programming (OOP)
A programming paradigm based on the concept of ""objects"", which can contain data, in the form of fields (often known as attributes or properties), and code, in the form of procedures (often known as methods). A feature of objects is an object's procedures that can access and often modify the data fields of the object with which they are associated (objects have a notion of ""this"" or ""self""). In OOP, computer programs are designed by making them out of objects that interact with one another. OOP languages are diverse, but the most popular ones are class-based, meaning that objects are instances of classes, which also determine their types.

open-source software (OSS)
A type of computer software in which source code is released under a license in which the copyright holder grants users the rights to study, change, and distribute the software to anyone and for any purpose. Open-source software may be developed in a collaborative public manner. Open-source software is a prominent example of open collaboration.

operating system (OS)
System software that manages computer hardware, software resources, and provides common services for computer programs.

optical fiber
A flexible, transparent fiber made by drawing glass (silica) or plastic to a diameter slightly thicker than that of a human hair. Optical fibers are used most often as a means to transmit light between the two ends of the fiber and find wide usage in fiber-optic communications, where they permit transmission over longer distances and at higher bandwidths (data rates) than electrical cables. Fibers are used instead of metal wires because signals travel along them with less loss; in addition, fibers are immune to electromagnetic interference, a problem from which metal wires suffer.

P
pair programming
An agile software development technique in which two programmers work together at one workstation. One, the driver, writes code while the other, the observer or navigator, reviews each line of code as it is typed in. The two programmers switch roles frequently.

parallel computing
A type of computation in which many calculations or the execution of processes are carried out simultaneously. Large problems can often be divided into smaller ones, which can then be solved at the same time. There are several different forms of parallel computing: bit-level, instruction-level, data, and task parallelism.

parameter
Also formal argument.
In computer programming, a special kind of variable, used in a subroutine to refer to one of the pieces of data provided as input to the subroutine. These pieces of data are the values of the arguments (often called actual arguments or actual parameters) with which the subroutine is going to be called/invoked. An ordered list of parameters is usually included in the definition of a subroutine, so that, each time the subroutine is called, its arguments for that call are evaluated, and the resulting values can be assigned to the corresponding parameters.

peripheral
Any auxiliary or ancillary device connected to or integrated within a computer system and used to send information to or retrieve information from the computer. An input device sends data or instructions to the computer; an output device provides output from the computer to the user; and an input/output device performs both functions.

pointer
Is an object in many programming languages that stores a memory address. This can be that of another value located in computer memory, or in some cases, that of memory-mapped computer hardware. A pointer references a location in memory, and obtaining the value stored at that location is known as dereferencing the pointer. As an analogy, a page number in a book's index could be considered a pointer to the corresponding page; dereferencing such a pointer would be done by flipping to the page with the given page number and reading the text found on that page. The actual format and content of a pointer variable is dependent on the underlying computer architecture.

postcondition
In computer programming, a condition or predicate that must always be true just after the execution of some section of code or after an operation in a formal specification. Postconditions are sometimes tested using assertions within the code itself. Often, postconditions are simply included in the documentation of the affected section of code.

precondition
In computer programming, a condition or predicate that must always be true just prior to the execution of some section of code or before an operation in a formal specification.  If a precondition is violated, the effect of the section of code becomes undefined and thus may or may not carry out its intended work.  Security problems can arise due to incorrect preconditions.

primary storage
(Also known as main memory, internal memory or prime memory), often referred to simply as memory, is the only one directly accessible to the CPU. The CPU continuously reads instructions stored there and executes them as required. Any data actively operated on is also stored there in uniform manner.

primitive data type

priority queue
An abstract data type which is like a regular queue or stack data structure, but where additionally each element has a ""priority"" associated with it. In a priority queue, an element with high priority is served before an element with low priority. In some implementations, if two elements have the same priority, they are served according to the order in which they were enqueued, while in other implementations, ordering of elements with the same priority is undefined.

procedural programming

procedure
In computer programming, a subroutine is a sequence of program instructions that performs a specific task, packaged as a unit. This unit can then be used in programs wherever that particular task should be performed.  Subroutines may be defined within programs, or separately in libraries that can be used by many programs.  In different programming languages, a subroutine may be called a routine, subprogram, function, method, or procedure. Technically, these terms all have different definitions. The generic, umbrella term  callable unit is sometimes used.

program lifecycle phase
Program lifecycle phases are the stages a computer program undergoes, from initial creation to deployment and execution. The phases are edit time, compile time, link time, distribution time, installation time, load time, and run time.

programming language
A formal language, which comprises a set of instructions that produce various kinds of output. Programming languages are used in computer programming to implement algorithms.

programming language implementation
Is a system for executing computer programs. There are two general approaches to programming language implementation: interpretation and compilation.

programming language theory
(PLT) is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and of their individual features.  It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, linguistics and even cognitive science.  It has become a well-recognized branch of computer science, and an active research area, with results published in numerous journals dedicated to PLT, as well as in general computer science and engineering publications.

Prolog
Is a logic programming language associated with artificial intelligence and computational linguistics.  Prolog has its roots in first-order logic, a formal logic, and unlike many other programming languages, Prolog is intended primarily as a declarative programming language: the program logic is expressed in terms of relations, represented as facts and rules.  A computation is initiated by running a query over these relations.

Python
Is an interpreted, high-level and general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.

Q
quantum computing
The use of quantum-mechanical phenomena such as superposition and entanglement to perform computation. A quantum computer is used to perform such computation, which can be implemented theoretically or physically.: I-5 

queue
A collection in which the entities in the collection are kept in order and the principal (or only) operations on the collection are the addition of entities to the rear terminal position, known as enqueue, and removal of entities from the front terminal position, known as dequeue.

quicksort
Also partition-exchange sort.
An efficient sorting algorithm which serves as a systematic method for placing the elements of a random access file or an array in order.

R
R programming language
R is a programming language and free software environment for statistical computing and graphics supported by the R Foundation for Statistical Computing. The R language is widely used among statisticians and data miners for developing statistical software and data analysis.

radix
Also base.
In digital numeral systems, the number of unique digits, including the digit zero, used to represent numbers in a positional numeral system. For example, in the decimal/denary system (the most common system in use today) the radix (base number) is ten, because it uses the ten digits from 0 through 9, and all other numbers are uniquely specified by positional combinations of these ten base digits; in the binary system that is the standard in computing, the radix is two, because it uses only two digits, 0 and 1, to uniquely specify each number.

record
A record (also called a structure,  struct, or compound data) is a basic data structure. Records in a database or spreadsheet are usually called ""rows"".

recursion
Occurs when a thing is defined in terms of itself or of its type. Recursion is used in a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, where a function being defined is applied within its own definition. While this apparently defines an infinite number of instances (function values), it is often done in such a way that no infinite loop or infinite chain of references can occur.

reference
Is a value that enables a program to indirectly access a particular datum, such as a variable's value or a record, in the computer's memory or in some other storage device.  The reference is said to refer to the datum, and accessing the datum is called dereferencing the reference.

reference counting
A programming technique of storing the number of references, pointers, or handles to a resource, such as an object, a block of memory, disk space, and others. In garbage collection algorithms, reference counts may be used to deallocate objects which are no longer needed.

relational database
Is a digital database based on the relational model of data, as proposed by E. F. Codd in 1970.
A software system used to maintain relational databases is a relational database management system (RDBMS). Many relational database systems have an option of using the SQL (Structured Query Language) for querying and maintaining the database.

reliability engineering
A sub-discipline of systems engineering that emphasizes dependability in the lifecycle management of a product. Reliability describes the ability of a system or component to function under stated conditions for a specified period of time. Reliability is closely related to availability, which is typically described as the ability of a component or system to function at a specified moment or interval of time.

regression testing
(rarely non-regression testing) is re-running functional and non-functional tests to ensure that previously developed and tested software still performs after a change. If not, that would be called a regression. Changes that may require regression testing include bug fixes, software enhancements, configuration changes, and even substitution of electronic components. As regression test suites tend to grow with each found defect, test automation is frequently involved. Sometimes a change impact analysis is performed to determine an appropriate subset of tests (non-regression analysis).

requirements analysis
In systems engineering and software engineering, requirements analysis focuses on the tasks that determine the needs or conditions to meet the new or altered product or project, taking account of the possibly conflicting requirements of the various stakeholders, analyzing, documenting, validating and managing software or system requirements.

robotics
An interdisciplinary branch of engineering and science that includes mechanical engineering, electronic engineering, information engineering, computer science, and others. Robotics involves design, construction, operation, and use of robots, as well as computer systems for their perception, control, sensory feedback, and information processing. The goal of robotics is to design intelligent machines that can help and assist humans in their day-to-day lives and keep everyone safe.

round-off error
Also rounding error.
The difference between the result produced by a given algorithm using exact arithmetic and the result produced by the same algorithm using finite-precision, rounded arithmetic. Rounding errors are due to inexactness in the representation of real numbers and the arithmetic operations done with them. This is a form of quantization error. When using approximation equations or algorithms, especially when using finitely many digits to represent real numbers (which in theory have infinitely many digits), one of the goals of numerical analysis is to estimate computation errors. Computation errors, also called numerical errors, include both truncation errors and roundoff errors.

router
A networking device that forwards data packets between computer networks. Routers perform the traffic directing functions on the Internet.  Data sent through the internet, such as a web page or email, is in the form of data packets.   A packet is typically forwarded from one router to another router through the networks that constitute an internetwork (e.g. the Internet) until it reaches its destination node.

routing table
In computer networking a routing table, or routing information base (RIB), is a data table stored in a router or a network host that lists the routes to particular network destinations, and in some cases, metrics (distances) associated with those routes. The routing table contains information about the topology of the network immediately around it.

run time
Runtime, run time, or execution time is the final phase of a computer program's life cycle, in which the code is being executed on the computer's central processing unit (CPU) as machine code. In other words, ""runtime"" is the running phase of a program.

run time error
A runtime error is detected after or during the execution (running state) of a program, whereas a compile-time error is detected by the compiler before the program is ever executed. Type checking, register allocation, code generation, and code optimization are typically done at compile time, but may be done at runtime depending on the particular language and compiler. Many other runtime errors exist and are handled differently by different programming languages, such as division by zero errors, domain errors, array subscript out of bounds errors, arithmetic underflow errors, several types of underflow and overflow errors, and many other runtime errors generally considered as software bugs which may or may not be caught and handled by any particular computer language.

S
search algorithm
Any algorithm which solves the search problem, namely, to retrieve information stored within some data structure, or calculated in the search space of a problem domain, either with discrete or continuous values.

secondary storage
Also known as external memory or auxiliary storage, differs from primary storage in that it is not directly accessible by the CPU. The computer usually uses its input/output channels to access secondary storage and transfer the desired data to primary storage. Secondary storage is non-volatile (retaining data when power is shut off). Modern computer systems typically have two orders of magnitude more secondary storage than primary storage because secondary storage is less expensive.

selection sort
Is an in-place comparison sorting algorithm. It has an O(n2) time complexity, which makes it inefficient on large lists, and generally performs worse than the similar insertion sort. Selection sort is noted for its simplicity and has performance advantages over more complicated algorithms in certain situations, particularly where auxiliary memory is limited.

semantics
In programming language theory, semantics is the field concerned with the rigorous mathematical study of the meaning of programming languages. It does so by evaluating the meaning of syntactically valid strings defined by a specific programming language, showing the computation involved. In such a case that the evaluation would be of syntactically invalid strings, the result would be non-computation. Semantics describes the processes a computer follows when executing a program in that specific language. This can be shown by describing the relationship between the input and output of a program, or an explanation of how the program will be executed on a certain platform, hence creating a model of computation.

sequence
In mathematics, a sequence is an enumerated collection of objects in which repetitions are allowed and order does matter.  Like a set, it contains members (also called elements, or terms).  The number of elements (possibly infinite) is called the length of the sequence.  Unlike a set, the same elements can appear multiple times at different positions in a sequence, and order does matter.  Formally, a sequence can be defined as a function whose domain is either the set of the natural numbers (for infinite sequences) or the set of the first n natural numbers (for a sequence of finite length n).

The position of an element in a sequence is its rank or index; it is the natural number for which the element is the image. The first element has index 0 or 1, depending on the context or a specific convention.  When a symbol is used to denote a sequence, the nth element of the sequence is denoted by this symbol with n as subscript; for example, the nth element of the Fibonacci sequence F is generally denoted Fn.

For example, (M, A, R, Y) is a sequence of letters with the letter 'M' first and 'Y' last.  This sequence differs from (A, R, M, Y).  Also, the sequence (1, 1, 2, 3, 5, 8), which contains the number 1 at two different positions, is a valid sequence.  Sequences can be finite, as in these examples, or infinite, such as the sequence of all even positive integers (2, 4, 6, ...).  In computing and computer science, finite sequences are sometimes called strings, words or lists, the different names commonly corresponding to different ways to represent them in computer memory; infinite sequences are called streams.  The empty sequence ( ) is included in most notions of sequence, but may be excluded depending on the context.

serializability
In concurrency control of databases, transaction processing (transaction management), and various transactional applications (e.g., transactional memory and software transactional memory), both centralized and distributed, a transaction schedule is serializable if its outcome (e.g., the resulting database state) is equal to the outcome of its transactions executed serially, i.e. without overlapping in time. Transactions are normally executed concurrently (they overlap), since this is the most efficient way. Serializability is the major correctness criterion for concurrent transactions' executions. It is considered the highest level of isolation between transactions, and plays an essential role in concurrency control. As such it is supported in all general purpose database systems. Strong strict two-phase locking (SS2PL) is a popular serializability mechanism utilized in most of the database systems (in various variants) since their early days in the 1970s.

serialization
Is the process of translating data structures or object state into a format that can be stored (for example, in a file or memory buffer) or transmitted (for example, across a network connection link) and reconstructed later (possibly in a different computer environment). When the resulting series of bits is reread according to the serialization format, it can be used to create a semantically identical clone of the original object. For many complex objects, such as those that make extensive use of references, this process is not straightforward. Serialization of object-oriented objects does not include any of their associated methods with which they were previously linked.

This process of serializing an object is also called marshalling an object in some situations.[1][2] The opposite operation, extracting a data structure from a series of bytes, is deserialization, (also called unserialization or unmarshalling).

service level agreement
(SLA), is a commitment between a service provider and a client. Particular aspects of the service – quality, availability, responsibilities – are agreed between the service provider and the service user. The most common component of an SLA is that the services should be provided to the customer as agreed upon in the contract. As an example, Internet service providers and telcos will commonly include service level agreements within the terms of their contracts with customers to define the level(s) of service being sold in plain language terms. In this case the SLA will typically have a technical definition in  mean time between failures (MTBF), mean time to repair or mean time to recovery (MTTR); identifying which party is responsible for reporting faults or paying fees; responsibility for various data rates; throughput; jitter; or similar measurable details.

set
Is an abstract data type that can store unique values, without any particular order. It is a computer implementation of the mathematical concept of a finite set. Unlike most other collection types, rather than retrieving a specific element from a set, one typically tests a value for membership in a set.

singleton variable
A variable that is referenced only once. May be used as a dummy argument in a function call, or when its address is assigned to another variable which subsequently accesses its allocated storage. Singleton variables sometimes occur because a mistake has been made – such as assigning a value to a variable and forgetting to use it later, or mistyping one instance of the variable name. Some compilers and lint-like tools flag occurrences of singleton variables.

soft computing

software
Computer software, or simply software, is a collection of data or computer instructions that tell the computer how to work. This is in contrast to physical hardware, from which the system is built and actually performs the work. In computer science and software engineering, computer software is all information processed by computer systems, programs and data. Computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. Computer hardware and software require each other and neither can be realistically used on its own.

software agent
Is a computer program that acts for a user or other program in a relationship of agency, which derives from the Latin agere (to do): an agreement to act on one's behalf. Such ""action on behalf of"" implies the authority to decide which, if any, action is appropriate. Agents are colloquially known as bots, from robot. They may be embodied, as when execution is paired with a robot body, or  as software such as a chatbot
executing on a phone (e.g. Siri)  or other computing device.  Software agents may be autonomous or work together with other agents or people.  Software agents interacting with people (e.g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo).

software construction
Is a software engineering discipline. It is the detailed creation of working meaningful software through a combination of coding, verification, unit testing, integration testing, and debugging. It is linked to all the other software engineering disciplines, most strongly to software design and software testing.

software deployment
Is all of the activities that make a software system available for use.

software design
Is the process by which an agent creates a specification of a software artifact, intended to accomplish goals, using a set of primitive components and subject to constraints. Software design may refer to either ""all the activity involved in conceptualizing, framing, implementing, commissioning, and ultimately modifying complex systems"" or ""the activity following requirements specification and before programming, as ... [in] a stylized software engineering process.""

software development
Is the process of conceiving, specifying, designing, programming, documenting, testing, and bug fixing involved in creating and maintaining applications, frameworks, or other software components. Software development is a process of writing and maintaining the source code, but in a broader sense, it includes all that is involved between the conception of the desired software through to the final manifestation of the software, sometimes in a planned and structured process. Therefore, software development may include research, new development, prototyping, modification, reuse, re-engineering, maintenance, or any other activities that result in software products.

software development process
In software engineering, a software development process is the process of dividing software development work into distinct phases to improve design, product management, and project management.  It is also known as a software development life cycle (SDLC).  The methodology may include the pre-definition of specific deliverables and artifacts that are created and completed by a project team to develop or maintain an application.  Most modern development processes can be vaguely described as agile. Other methodologies include waterfall, prototyping, iterative and incremental development, spiral development, rapid application development, and extreme programming.

software engineering
Is the systematic application of engineering approaches to the development of software. Software engineering is a computing discipline.

software maintenance
In software engineering is the modification of a software product after delivery to correct faults, to improve performance or other attributes.

software prototyping
Is the activity of creating prototypes of software applications, i.e., incomplete versions of the software program being developed. It is an activity that can occur in software development and is comparable to prototyping as known from other fields, such as mechanical engineering or manufacturing.  A prototype typically simulates only a few aspects of, and may be completely different from, the final product. 

software requirements specification
(SRS), is a description of a software system to be  developed. The software requirements specification lays out functional and non-functional requirements, and it may include a set of use cases that describe user interactions that the software must provide to the user for perfect interaction.

software testing
Is an investigation conducted to provide stakeholders with information about the quality of the software product or service under test. Software testing can also provide an objective, independent view of the software to allow the business to appreciate and understand the risks of software implementation. Test techniques include the process of executing a program or application with the intent of finding software bugs (errors or other defects), and verifying that the software product is fit for use. 

sorting algorithm
Is an algorithm that puts elements of a list in a certain order. The most frequently used orders are numerical order and lexicographical order. Efficient sorting is important for optimizing the efficiency of other algorithms (such as search and merge algorithms) that require input data to be in sorted lists. Sorting is also often useful for canonicalizing data and for producing human-readable output. More formally, the output of any sorting algorithm must satisfy two conditions:

The output is in nondecreasing order (each element is no smaller than the previous element according to the desired total order);
The output is a permutation (a reordering, yet retaining all of the original elements) of the input.

Further, the input data is often stored in an array, which allows random access, rather than a list, which only allows sequential access; though many algorithms can be applied to either type of data after suitable modification.

source code
In computing, source code is any collection of code, with or without comments, written using a human-readable programming language, usually as plain text. The source code of a program is specially designed to facilitate the work of computer programmers, who specify the actions to be performed by a computer mostly by writing source code. The source code is often transformed by an assembler or compiler into binary machine code that can be executed by the computer. The machine code might then be stored for execution at a later time. Alternatively, source code may be interpreted and thus immediately executed.

spiral model
Is a risk-driven software development process model. Based on the unique risk patterns of a given project, the spiral model guides a team to adopt elements of one or more process models, such as incremental, waterfall, or evolutionary prototyping.

stack
Is an abstract data type that serves as a collection of elements, with two main principal operations:
push, which adds an element to the collection, and
pop, which removes the most recently added element that was not yet removed.
The order in which elements come off a stack gives rise to its alternative name, LIFO (last in, first out). Additionally, a peek operation may give access to the top without modifying the stack. The name ""stack"" for this type of structure comes from the analogy to a set of physical items stacked on top of each other. This structure makes it easy to take an item off the top of the stack, while getting to an item deeper in the stack may require taking off multiple other items first.

state
In information technology and computer science, a system is described as stateful if it is designed to remember preceding events or user interactions; the remembered information is called the state of the system.

statement
In computer programming, a statement is a syntactic unit of an imperative programming language that expresses some action to be carried out. A program written in such a language is formed by a sequence of one or more statements. A statement may have internal components (e.g., expressions).

storage
Computer data storage is a technology consisting of computer components and recording media that are used to retain digital data. It is a core function and fundamental component of computers.: 15–16 

stream
Is a sequence of data elements made available over time. A stream can be thought of as items on a conveyor belt being processed one at a time rather than in large batches.

string
In computer programming, a string is traditionally a sequence of characters, either as a literal constant or as some kind of variable. The latter may allow its elements to be mutated and the length changed, or it may be fixed (after creation). A string is generally considered as a data type and is often implemented as an array data structure of bytes (or words) that stores a sequence of elements, typically characters, using some character encoding. String may also denote more general arrays or other sequence (or list) data types and structures.

structured storage
A NoSQL (originally referring to ""non-SQL"" or ""non-relational"") database provides a mechanism for storage and retrieval of data that is modeled in means other than the tabular relations used in relational databases. Such databases have existed since the late 1960s, but the name ""NoSQL"" was only coined in the early 21st century, triggered by the needs of Web 2.0 companies. NoSQL databases are increasingly used in big data and real-time web applications.  NoSQL systems are also sometimes called ""Not only SQL"" to emphasize that they may support SQL-like query languages or sit alongside SQL databases in polyglot-persistent architectures.

subroutine
In computer programming, a subroutine is a sequence of program instructions that performs a specific task, packaged as a unit. This unit can then be used in programs wherever that particular task should be performed.  Subroutines may be defined within programs, or separately in libraries that can be used by many programs.  In different programming languages, a subroutine may be called a routine, subprogram, function, method, or procedure. Technically, these terms all have different definitions. The generic, umbrella term  callable unit is sometimes used.

symbolic computation
In mathematics and computer science, computer algebra, also called symbolic computation or algebraic computation, is a scientific area that refers to the study and development of algorithms and software for manipulating mathematical expressions and other mathematical objects. Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols.

syntax
The syntax of a computer language is the set of rules that defines the combinations of symbols that are considered to be correctly structured statements or expressions in that language. This applies both to programming languages, where the document represents source code, and to markup languages, where the document represents data.

syntax error
Is an error in the syntax of a sequence of characters or tokens that is intended to be written in compile-time. A program will not compile until all syntax errors are corrected. For interpreted languages, however, a syntax error may be detected during program execution, and an interpreter's error messages might not differentiate syntax errors from errors of other kinds. There is some disagreement as to just what errors are ""syntax errors"". For example, some would say that the use of an uninitialized variable's value in Java code is a syntax error, but many others would disagree and would classify this as a (static) semantic error.

system console
The system console, computer console, root console, operator's console, or simply console is the text entry and display device for system administration messages, particularly those from the BIOS or boot loader, the kernel, from the init system and from the system logger. It is a physical device consisting of a keyboard and a screen, and traditionally is a text terminal, but may also be a graphical terminal. System consoles are generalized to computer terminals, which are abstracted respectively by virtual consoles and terminal emulators. Today communication with system consoles is generally done abstractly, via the standard streams (stdin, stdout, and stderr), but there may be system-specific interfaces, for example those used by the system kernel.

T
technical documentation
In engineering, any type of documentation that describes handling, functionality, and architecture of a technical product or a product under development or use. The intended recipient for product technical documentation is both the (proficient) end user as well as the administrator/service or maintenance technician. In contrast to a mere ""cookbook"" manual, technical documentation aims at providing enough information for a user to understand inner and outer dependencies of the product at hand.

third-generation programming language
A third-generation programming language (3GL) is a high-level computer programming language that tends to be more machine-independent and programmer-friendly than the machine code of the first-generation and assembly languages of the second-generation, while having a less specific focus to the fourth and fifth generations. Examples of common and historical third-generation programming languages are ALGOL, BASIC, C, COBOL, Fortran, Java, and Pascal.

top-down and bottom-up design

tree
A widely used abstract data type (ADT) that simulates a hierarchical tree structure, with a root value and subtrees of children with a parent node, represented as a set of linked nodes.

type theory
In mathematics, logic, and computer science, a type theory is any of a class of formal systems, some of which can serve as alternatives to set theory as a foundation for all mathematics. In type theory, every ""term"" has a ""type"" and operations are restricted to terms of a certain type.

U
upload
In computer networks, to send data to a remote system such as a server or another client so that the remote system can store a copy. Contrast download.

Uniform Resource Locator (URL)
Colloquially web address.
A reference to a web resource that specifies its location on a computer network and a mechanism for retrieving it. A URL is a specific type of Uniform Resource Identifier (URI), although many people use the two terms interchangeably. URLs occur most commonly to reference web pages (http), but are also used for file transfer (ftp), email (mailto), database access (JDBC), and many other applications.

user
Is a person who utilizes a computer or network service. Users of computer systems and software products generally lack the technical expertise required to fully understand how they work. Power users use advanced features of programs, though they are not necessarily capable of computer programming and system administration.

user agent
Software (a software agent) that acts on behalf of a user, such as a web browser that ""retrieves, renders and facilitates end user interaction with Web content"". An email reader is a mail user agent.

user interface (UI)
The space where interactions between humans and machines occur. The goal of this interaction is to allow effective operation and control of the machine from the human end, whilst the machine simultaneously feeds back information that aids the operators' decision-making process. Examples of this broad concept of user interfaces include the interactive aspects of computer operating systems, hand tools, heavy machinery operator controls, and process controls. The design considerations applicable when creating user interfaces are related to or involve such disciplines as ergonomics and psychology.

user interface design
Also user interface engineering.
The design of user interfaces for machines and software, such as computers, home appliances, mobile devices, and other electronic devices, with the focus on maximizing usability and the user experience. The goal of user interface design is to make the user's interaction as simple and efficient as possible, in terms of accomplishing user goals (user-centered design).

V
variable
In computer programming, a variable, or scalar, is a storage location (identified by a memory address) paired with an associated symbolic name (an identifier), which contains some known or unknown quantity of information referred to as a value. The variable name is the usual way to reference the stored value, in addition to referring to the variable itself, depending on the context. This separation of name and content allows the name to be used independently of the exact information it represents. The identifier in computer source code can be bound to a value during run time, and the value of the variable may therefore change during the course of program execution.

virtual machine (VM)
An emulation of a computer system. Virtual machines are based on computer architectures and attempt to provide the same functionality as a physical computer. Their implementations may involve specialized hardware, software, or a combination of both.

V-Model
A software development process that may be considered an extension of the waterfall model, and is an example of the more general V-model. Instead of moving down in a linear way, the process steps are bent upwards after the coding phase, to form the typical V shape. The V-Model demonstrates the relationships between each phase of the development life cycle and its associated phase of testing. The horizontal and vertical axes represent time or project completeness (left-to-right) and level of abstraction (coarsest-grain abstraction uppermost), respectively.

W
waterfall model
A breakdown of project activities into linear sequential phases, where each phase depends on the deliverables of the previous one and corresponds to a specialisation of tasks.  The approach is typical for certain areas of engineering design. In software development, it tends to be among the less iterative and flexible approaches, as progress flows in largely one direction (""downwards"" like a waterfall) through the phases of conception, initiation, analysis, design, construction, testing, deployment and maintenance.

Waveform Audio File Format
Also WAVE or WAV due to its filename extension.
An audio file format standard, developed by Microsoft and IBM, for storing an audio bitstream on PCs. It is an application of the Resource Interchange File Format (RIFF) bitstream format method for storing data in ""chunks"", and thus is also close to the 8SVX and the AIFF format used on Amiga and Macintosh computers, respectively. It is the main format used on Microsoft Windows systems for raw and typically uncompressed audio. The usual bitstream encoding is the linear pulse-code modulation (LPCM) format.

web crawler
Also spider, spiderbot, or simply crawler.
An Internet bot that systematically browses the World Wide Web, typically for the purpose of Web indexing (web spidering).

Wi-Fi
A family of wireless networking technologies, based on the IEEE 802.11 family of standards, which are commonly used for local area networking of devices and Internet access. Wi‑Fi is a trademark of the non-profit Wi-Fi Alliance, which restricts the use of the term Wi-Fi Certified to products that successfully complete interoperability certification testing.

X
XHTML
Abbreviaton of eXtensible HyperText Markup Language.
Part of the family of XML markup languages. It mirrors or extends versions of the widely used HyperText Markup Language (HTML), the language in which web pages are formulated.

See also
Outline of computer science

References
Works cited


== Notes ==",57143357,https://en.wikipedia.org/wiki/Glossary_of_computer_science
Agnostic (data),"In computing, a device or software program is said to be agnostic or data agnostic if the method or format of data transmission is irrelevant to the device or program's function. This means that the device or program can receive data in multiple formats or from multiple sources, and still process that data effectively.","In computing, a device or software program is said to be agnostic or data agnostic if the method or format of data transmission is irrelevant to the device or program's function. This means that the device or program can receive data in multiple formats or from multiple sources, and still process that data effectively.

Definition
Many devices or programs need data to be presented in a specific format to process the data. For example, Apple Inc devices generally require applications to be downloaded from their App Store. This is a non data-agnostic method, as it uses a specified file type, downloaded from a specific location, and does not function unless those requirements are met.
Non data-agnostic devices and programs can present problems. For example, if your file contains the right type of data (such as text), but in the wrong format, you may have to create a new file and enter the text manually in the proper format in order to use that program. Various file conversion programs exist because people need to convert their files to a different format in order to use them effectively.

Implementation
Data agnostic devices and programs work to solve these problems in a variety of ways. Devices can treat files in the same way whether they are downloaded over the internet or transferred over a USB or other cable.
Devices and programs can become more data-agnostic by using a generic storage format to create, read, update, and delete files. Formats like XML and JSON can store information in a data agnostic manner. For example, XML is data agnostic in that it can save any type of information. However, if you use Data Transform Definitions (DTD) or XML Schema Definitions (XSD) to define what data should be placed where, it becomes non-data agnostic; it produces an error if the wrong type of data is placed in a field.
Once you have your data saved in a generic storage format, this source can act as an entity synchronization layer. The generic storage format can interface with a variety of different programs, with the data extraction method formatting the data in a way that the specific program can understand. This allows two programs that require different data formats to access the same data. Multiple devices and programs can create, read, update, and delete (CRUD) the same information from the same storage location without formatting errors.
When multiple programs are accessing the same records, they may have different defined fields for the same type of concept. Where the fields are differently labelled but contain the same data, the program pulling the information can ensure the correct data is used. If one program contains fields and information that another does not, those fields can be saved to the record and pulled for that program, but ignored by other programs. As the entity synchronization layer is data agnostic, additional fields can be added without worrying about recoding the whole database, and concepts created in other programs (that do not contain that field) are fine.
Since the information formatting is imposed on the data by the program extracting it, the format can be customized to the device or program extracting and displaying that data. The information extracted from the entity synchronization layer can therefore be dynamically rendered to display on the user's device, regardless of the device or program being used.
Having data agnostic devices and programs allows you to transfer data easily between them, without having to convert that data. Companies like Great Ideaz provide data agnostic services by storing the data in an entity synchronization layer. This acts as a compatibility layer, as TSQL statements can retrieve, update, sort, and write data regardless of the format employed. It also allows you to synchronize data between multiple applications, as the applications can all pull data from the same location. This prevents compatibility problems between different programs that have to access the same data, as well as reducing data replication.

Benefits
Keeping your devices and programs as data agnostic as possible has some clear advantages.
Since the data is stored in an agnostic format, developers do not need to hard-code ways to deal with all different kinds of data. A table with information about dogs and one with information about cats can be treated in the same way; extract the field definitions and the field content from the data agnostic storage format and display it based on the field definitions. Using the same code for the different concepts to CRUD, the amount of code is significantly reduced, and what remains is tested with each concept you extract from the entity synchronization layer.
The field definitions and formatting can be stored in the entity synchronization layer with the data they are acting on. Allows fields and formatting to change, without having to hardcode and compile programs. The data and formatting are then generated dynamically by the code used to extract the data and the formatting information.
The data itself only needs to be distinguished when it is being acted on or displayed in a specific way. If the data is being transferred between devices or databases, it does not need to be interpreted as a specific object. Whenever the data can be treated as agnostic, the coding is simplified, as it only has to deal with one case (the data agnostic case) rather than multiple (png, pdf, etc.). When the data must be displayed or acted on, then it is interpreted based on the field definitions and formatting information, and returned to a data agnostic format as soon as possible to reduce the number of individual cases that must be accounted for.

Risks
There are, however, a few problems introduced when attempting to make a device or program data agnostic.
Since only one piece of code is being used for CRUD operations (regardless of the type of concept), there is a single point of failure. If that code breaks down, the whole system is broken. This risk is mitigated because the code is tested so many times (as it is used every time a record is stored or retrieved).
Additionally, data agnostic storage mediums can increase load speed, as the code has to search for the field definitions and display format as well as the specific data to be displayed. The load speed can be improved by pre-shredding the data. This uses a copy of the record with the data already extracted to index the fields, instead of having to extract the fields and formatting information at the same time as the data. While this improves the speed, it adds a non-data agnostic element to the process; however, it can be created easily through code generation.


== References ==",61776737,https://en.wikipedia.org/wiki/Agnostic_(data)
Boolean,"Any kind of logic, function, expression, or theory based on the work of George Boole is considered Boolean.  
Related to this, ""Boolean"" may refer to:

Boolean data type, a form of data with only two possible values (usually ""true"" and ""false"")
Boolean algebra, a logical calculus of truth values or set membership
Boolean algebra (structure), a set with operations resembling logical ones
Boolean domain, a set consisting of exactly two elements whose interpretations include false and true
Boolean circuit, a mathematical model for digital logical circuits.
Boolean expression, an expression in a programming language that produces a Boolean value when evaluated
Boolean function, a function that determines Boolean values or operators
Boolean model (probability theory), a model in stochastic geometry
Boolean network, a certain network consisting of a set of Boolean variables whose state is determined by other variables in the network
Boolean processor, a 1-bit variable computing unit
Boolean ring, a mathematical ring for which x2 = x for every element x
Boolean satisfiability problem,  the problem of determining if there exists an interpretation that satisfies a given Boolean formula
Boolean prime ideal theorem, a theorem which states that ideals in a Boolean algebra can be extended to prime ideals","Any kind of logic, function, expression, or theory based on the work of George Boole is considered Boolean.  
Related to this, ""Boolean"" may refer to:

Boolean data type, a form of data with only two possible values (usually ""true"" and ""false"")
Boolean algebra, a logical calculus of truth values or set membership
Boolean algebra (structure), a set with operations resembling logical ones
Boolean domain, a set consisting of exactly two elements whose interpretations include false and true
Boolean circuit, a mathematical model for digital logical circuits.
Boolean expression, an expression in a programming language that produces a Boolean value when evaluated
Boolean function, a function that determines Boolean values or operators
Boolean model (probability theory), a model in stochastic geometry
Boolean network, a certain network consisting of a set of Boolean variables whose state is determined by other variables in the network
Boolean processor, a 1-bit variable computing unit
Boolean ring, a mathematical ring for which x2 = x for every element x
Boolean satisfiability problem,  the problem of determining if there exists an interpretation that satisfies a given Boolean formula
Boolean prime ideal theorem, a theorem which states that ideals in a Boolean algebra can be extended to prime ideals

See also
Binary (disambiguation)",212335,https://en.wikipedia.org/wiki/Boolean
Computational social choice,"Computational social choice is a field at the intersection of social choice theory, theoretical computer science, and the analysis of multi-agent systems. It consists of the analysis of problems arising from the aggregation of preferences of a group of agents from a computational perspective. In particular, computational social choice is concerned with the efficient computation of outcomes of voting rules, with the computational complexity of various forms of manipulation, and issues arising from the problem of representing and eliciting preferences in combinatorial settings.","Computational social choice is a field at the intersection of social choice theory, theoretical computer science, and the analysis of multi-agent systems. It consists of the analysis of problems arising from the aggregation of preferences of a group of agents from a computational perspective. In particular, computational social choice is concerned with the efficient computation of outcomes of voting rules, with the computational complexity of various forms of manipulation, and issues arising from the problem of representing and eliciting preferences in combinatorial settings.

Winner determination
The usefulness of a particular voting system can be severely limited if it takes a very long time to calculate the winner of an election. Therefore, it is important to design fast algorithms that can evaluate a voting rule when given ballots as input. As is common in computational complexity theory, an algorithm is thought to be efficient if it takes polynomial time. Many popular voting rules can be evaluated in polynomial time in a straightforward way (i.e., counting), such as the Borda count, approval voting, or the plurality rule. For rules such as the Schulze method or ranked pairs, more sophisticated algorithms can be used to show polynomial runtime. Certain voting systems, however, are computationally difficult to evaluate. In particular, winner determination for the Kemeny-Young method, Dodgson's method, and Young's method are all NP-hard problems. This has led to the development of approximation algorithms and fixed-parameter tractable algorithms to improve the theoretical calculation of such problems.

Hardness of manipulation
By the Gibbard-Satterthwaite theorem, all non-trivial voting rules can be manipulated in the sense that voters can sometimes achieve a better outcome by misrepresenting their preferences, that is, they submit a non-truthful ballot to the voting system. Social choice theorists have long considered ways to circumvent this issue, such as the proposition by Bartholdi, Tovey, and Trick in 1989 based on computational complexity theory. They considered the second-order Copeland rule (which can be evaluated in polynomial time), and proved that it is NP-complete for a voter to decide, given knowledge of how everyone else has voted, whether it is possible to manipulate in such a way as to make some favored candidate the winner. The same property holds for single transferable vote.Hence, assuming the widely believed hypothesis that P ≠ NP, there are instances where polynomial time is not enough to establish whether a beneficial manipulation is possible. Because of this, the voting rules that come with an NP-hard manipulation problem are ""resistant"" to manipulation. One should note that these results only concern the worst-case: it might well be possible that a manipulation problem is usually easy to solve, and only requires superpolynomial time on very unusual inputs.

Other topics
Tournament solutions
A tournament solution is a rule that assigns to every tournament a set of winners. Since a preference profile induces a tournament through its majority relation, every tournament solution can also be seen as a voting rule which only uses information about the outcomes of pairwise majority contests. Many tournament solutions have been proposed, and computational social choice theorists have studied the complexity of the associated winner determination problems.

Preference restrictions
Restricted preference domains, such as single-peaked or single-crossing preferences, are an important area of study in social choice theory, since preferences from these domains avoid the Condorcet paradox and thus can circumvent impossibility results like Arrow's theorem and the Gibbard-Satterthwaite theorem. From a computational perspective, such domain restrictions are useful to speed up winner determination problems, both computationally hard single-winner and multi-winner rules can be computed in polynomial time when preferences are structured appropriately. On the other hand, manipulation problem also tend to be easy on these domains, so complexity shields against manipulation are less effective. Another computational problem associated with preference restrictions is that of recognizing when a given preference profile belongs to some restricted domain. This task is polynomial time solvable in many cases, including for single-peaked and single-crossing preferences, but can be hard for more general classes.

Multiwinner elections
While most traditional voting rules focus on selecting a single winner, many situations require selecting multiple winners. This is the case when a fixed-size parliament or a committee is to be elected, though multiwinner voting rules can also be used to select a set of recommendations or facilities or a shared bundle of items. Work in computational social choice has focused on defining such voting rules, understanding their properties, and studying the complexity of the associated winner determination problems. See multiwinner voting.

See also
Algocracy
Algorithmic game theory
Algorithmic mechanism design
Cake-cutting
Fair division
Hedonic games

References
External links
The COMSOC website, offering a collection of materials related to computational social choice, such as academic workshops, PhD theses, and a mailing list.",51245349,https://en.wikipedia.org/wiki/Computational_social_choice
Computer science in sport,"Computer science in sport is an interdisciplinary discipline that has its goal in combining the theoretical as well as practical aspects and methods of the areas of informatics and sport science. The main emphasis of the interdisciplinarity is placed on the application and use of computer-based, but also mathematical techniques in sport science, aiming in this way at the support and advancement of theory and practice in sports. The reason computer science has become an important partner for sport science is mainly connected with ""the fact that the use of data and media, the design of models, the analysis of systems etc. increasingly requires the support of suitable tools and concepts which are developed and available in computer science"".","Computer science in sport is an interdisciplinary discipline that has its goal in combining the theoretical as well as practical aspects and methods of the areas of informatics and sport science. The main emphasis of the interdisciplinarity is placed on the application and use of computer-based, but also mathematical techniques in sport science, aiming in this way at the support and advancement of theory and practice in sports. The reason computer science has become an important partner for sport science is mainly connected with ""the fact that the use of data and media, the design of models, the analysis of systems etc. increasingly requires the support of suitable tools and concepts which are developed and available in computer science"".

Historical background
Going back in history, computers in sports were used for the first time in the 1960s, when the main purpose was to accumulate sports information. Databases were created and expanded in order to launch documentation and dissemination of publications like articles or books that contain any kind of knowledge related to sports science. Until the mid-1970s also the first organization in this area called IASI (International Association for Sports Information) was formally established. Congresses and meetings were organized more often with the aim of standardization and rationalization of sports documentation. Since at that time this area was obviously less computer-oriented, specialists talk about sports information rather than sports informatics when mentioning the beginning of this field of science.
Based on the progress of computer science and the invention of more powerful computer hardware in the 1970s, also the real history of computer science in sport began. This was as well the first time when this term was officially used and the initiation of a very important evolution in sports science.
In the early stages of this area statistics on biomechanical data, like different kinds of forces or rates, played a major role. Scientists started to analyze sports games by collecting and looking at such values and features in order to interpret them. Later on, with the continuous improvement of computer hardware — in particular microprocessor speed – many new scientific and computing paradigms were introduced, which were also integrated in computer science in sport. Specific examples are modeling as well as simulation, but also pattern recognition, and design.
As another result of this development, the term 'computer science in sport' has been added in the encyclopedia of sports science in 2004.

Areas of research
The importance and strong influence of computer science as an interdisciplinary partner for sport and sport science is mainly proven by the research activities in computer science in sport. The following IT concepts are thereby of particular interest:

Data acquisition and data processing
Databases and expert systems
Modelling (mathematical, IT based, biomechanical, physiological)
Simulation (interactive, animation etc.)
PresentationBased on the fields from above, the main areas of research in computer science in sport include amongst others:

Training and coaching
Biomechanics
Sports equipment and technology
Computer-aided applications (software, hardware) in sports
Ubiquitous computing in sports
Multimedia and Internet
Documentation
Education

Research communities
A clear demonstration for the evolution and propagation towards computer science in sport is also the fact that nowadays people do research in this area all over the world. Since the 1990s, many new national and international organizations regarding the topic of computer science in sport were established. These associations are regularly organizing congresses and workshops with the aim of dissemination as well as exchange of scientific knowledge and information on all sort of topics regarding the interdisciplinary discipline.

Historical survey
As a first example, in Australia and New Zealand scientists have built up the MathSport group of ANZIAM (Australia and New Zealand Industrial and Applied Mathematics), which since 1992 organizes biennial meetings, initially under the name ""Mathematics and Computers in Sport Conferences"", and now ""MathSport"". Main topics are mathematical models and computer applications in sports, as well as coaching and teaching methods based on informatics.
The European community was also amongst the leading motors of the emergence of the field. Some workshops on this topic were successfully organized in Germany since the late 1980s. In 1997 the first international meeting on computer science in sport was held in Cologne. The main aim was to spread out and share applications, ideas and concepts of the use of computers in sports, which should also make a contribution to the creation of internationalization and thus to boost research work in this area.
Since then, such international symposia took place every two years all over Europe. As the first conferences were a raving success, it was decided to go even further and the foundation of an organization was the logical consequence. This step was accomplished in 2003, when the International Association of Computer Science in Sport (IACSS) was established during the 4th international symposium in Barcelona, when Prof. Jürgen Perl was also chosen as the first president. A few years earlier, the first international e-journal on this topic (International Journal of Computer Science in Sport) was released already. The internationalization is confirmed moreover by the fact that three conferences already took place outside of Europe - in Calgary (Canada) in 2007, Canberra (Australia) in 2009 and Shanghai (China) in 2011. During the symposium in Calgary additionally, the president position changed - it has been assigned to Prof. Arnold Baca, who has been re-elected in 2009 and 2011. The following Symposia on Computer Science in Sport took place in Europe again, in Istanbul (Turkey) in 2013 and in Loughborough (UK) in 2015. In 2017 the 11th Symposium of Computer Science in Sport took place in Constance (Germany). During the conference in Istanbul Prof. Martin Lames was elected as president of the IACSS. He was re-elected in 2015, 2017 and 2019.
The 12th International Symposium of Computer Science in Sports was held in Moscow (Russia) from 8 to 10 July 2019: https://iacss2019.ru/

National organizations
In addition to the international associations from above, currently the following national associations on computer science in sport exist (if available, the web addresses are also given):

Austrian Association of Computer Science in Sport - http://www.sportinformatik.at
British Association of Computer Science in Sport and Exercise
Chinese Association of Computer Science in Sport
Croatian Association of Computer Science in Sport
Section Computer Science in Sport of the German Association of Sport Science - http://www.dvs-sportinformatik.de (in German)
Swiss Association of Computer Science in Sport SACSS - http://sacss.org
Indian Federation of Computer Science in Sport - http://www.ifcss.in
Portuguese Association of Computer Science in Sport
Turkish Association of Computer Science in Sport
Russian Association of Computer Science in Sport - https://www.racss.ru/

References
Further reading
Baca, A. (2015). Computer Science in Sport - Research and practice, Routledge. ISBN 978-1-315-88178-2

External links
MathSport - ANZIAM (Australia and New Zealand Industrial and Applied Mathematics)
ECSS (European College of Sport Science)
Havuz Ekipmanları
ISEA (International Sports Engineering Association)
IACSS (International Association of Computer Science in Sport)",25852537,https://en.wikipedia.org/wiki/Computer_science_in_sport
Critical code studies,"Critical code studies (CCS) is an emerging academic subfield, related to software studies, digital humanities, cultural studies, computer science, human–computer interface, and the do-it-yourself maker culture. Its primary focus is on the cultural significance of computer code, without excluding or focusing solely upon the code's functional purpose. According to Mark C. Marino, it is an approach that applies critical hermeneutics to the interpretation of computer code, program architecture, and documentation within a socio-historical context. CCS holds that lines of code are not value-neutral and can be analyzed using the theoretical approaches applied to other semiotic systems in addition to particular interpretive methods developed particularly for the discussions of programs.
As introduced by Marino, critical code studies was initially a method by which scholars ""can read and explicate code the way we might explicate a work of literature"", but the concept also draws upon Espen Aarseth's conception of a cybertext as a ""mechanical device for the production and consumption of verbal signs"", arguing that in order to understand a digital artifact we must also understand the constraints and capabilities of the authoring tools used by the creator of the artifact, as well as the memory storage and interface required for the user to experience the digital artifact.
Evidence that critical code studies has gained momentum since 2006 include an article by Matthew Kirschenbaum in The Chronicle of Higher Education, CCS sessions at the Modern Language Association in 2011 that were ""packed"" with attendees, several academic conferences devoted wholly to critical code studies, and a book devoted to the explication of a single line of computer code, titled 10 PRINT CHR$(205.5+RND(1)); : GOTO 10.","Critical code studies (CCS) is an emerging academic subfield, related to software studies, digital humanities, cultural studies, computer science, human–computer interface, and the do-it-yourself maker culture. Its primary focus is on the cultural significance of computer code, without excluding or focusing solely upon the code's functional purpose. According to Mark C. Marino, it is an approach that applies critical hermeneutics to the interpretation of computer code, program architecture, and documentation within a socio-historical context. CCS holds that lines of code are not value-neutral and can be analyzed using the theoretical approaches applied to other semiotic systems in addition to particular interpretive methods developed particularly for the discussions of programs.
As introduced by Marino, critical code studies was initially a method by which scholars ""can read and explicate code the way we might explicate a work of literature"", but the concept also draws upon Espen Aarseth's conception of a cybertext as a ""mechanical device for the production and consumption of verbal signs"", arguing that in order to understand a digital artifact we must also understand the constraints and capabilities of the authoring tools used by the creator of the artifact, as well as the memory storage and interface required for the user to experience the digital artifact.
Evidence that critical code studies has gained momentum since 2006 include an article by Matthew Kirschenbaum in The Chronicle of Higher Education, CCS sessions at the Modern Language Association in 2011 that were ""packed"" with attendees, several academic conferences devoted wholly to critical code studies, and a book devoted to the explication of a single line of computer code, titled 10 PRINT CHR$(205.5+RND(1)); : GOTO 10.

See also
Critical legal studies
Critical theory
Hermeneutics

References
Footnotes
Bibliography


== Further reading ==",34549363,https://en.wikipedia.org/wiki/Critical_code_studies
Information and computer science,"Information and computer science (ICS) or computer and information science (CIS) (plural forms, i.e., sciences, may also be used) is a field that emphasizes both computing and informatics, upholding the strong association between the fields of information sciences and computer sciences and treating computers as a tool rather than a field.
Information science is one with a long history, unlike the relatively very young field of computer science, and is primarily concerned with gathering, storing, disseminating, sharing and protecting any and all forms of information. It is a broad field, covering a myriad of different areas but is often referenced alongside computer science because of the incredibly useful nature of computers and computer programs in helping those studying and doing research in the field – particularly in helping to analyse data and in spotting patterns too broad for a human to intuitively perceive. While information science is sometimes confused with information theory, the two have vastly different subject matter. Information theory focuses on one particular mathematical concept of information while information science is focused on all aspects of the processes and techniques of information.
Computer science, in contrast, is less focused on information and its different states, but more, in a very broad sense, on the use of computers – both in theory and practice – to design and implement algorithms in order to aid the processing of information during the different states described above. It has strong foundations in the field of mathematics, as the very first recognised practitioners of the field were renowned mathematicians such as Alan Turing.
Information science and computing began to converge in the 1950s and 1960s, as information scientists started to realize the many ways computers would improve information storage and retrieval.","Information and computer science (ICS) or computer and information science (CIS) (plural forms, i.e., sciences, may also be used) is a field that emphasizes both computing and informatics, upholding the strong association between the fields of information sciences and computer sciences and treating computers as a tool rather than a field.
Information science is one with a long history, unlike the relatively very young field of computer science, and is primarily concerned with gathering, storing, disseminating, sharing and protecting any and all forms of information. It is a broad field, covering a myriad of different areas but is often referenced alongside computer science because of the incredibly useful nature of computers and computer programs in helping those studying and doing research in the field – particularly in helping to analyse data and in spotting patterns too broad for a human to intuitively perceive. While information science is sometimes confused with information theory, the two have vastly different subject matter. Information theory focuses on one particular mathematical concept of information while information science is focused on all aspects of the processes and techniques of information.
Computer science, in contrast, is less focused on information and its different states, but more, in a very broad sense, on the use of computers – both in theory and practice – to design and implement algorithms in order to aid the processing of information during the different states described above. It has strong foundations in the field of mathematics, as the very first recognised practitioners of the field were renowned mathematicians such as Alan Turing.
Information science and computing began to converge in the 1950s and 1960s, as information scientists started to realize the many ways computers would improve information storage and retrieval.

Terminology
Due to the distinction between computers and computing, some of the research groups refer to computing or datalogy. The French refer to computer science as the term informatique. The term information and communications technology (ICT), refers to how humans communicate with using machines and computers, making a distinction from information and computer science, which is how computers use and gain information.
Informatics is also distinct from computer science, which encompasses the study of logic and low-level computing issues.

Education
Universities may confer degrees of ICS and CIS, not to be confused with a more specific Bachelor of Computer Science or respective graduate computer science degrees.
The QS World University Rankings is one of the most widely recognised and distinguished university comparisons. They ranked the top 10 universities for computer science and information systems in 2015. 
They are:

Massachusetts Institute of Technology (MIT)
Stanford University
University of Oxford
Carnegie Mellon University
Harvard University
University of California, Berkeley (UCB)
University of Cambridge
The Hong Kong University of Science and Technology
Swiss Federal Institute of Technology (ETH Zurich)
Princeton UniversityA Computer Information Science degree gives students both network and computing knowledge which is needed to design, develop, and assist information systems which helps to solve business problems and to support business problems and to support business operations and decision making at a managerial level also.

Areas of information and computer science
Due to the nature of this field, many topics are also shared with computer science and information systems.
The discipline of Information and Computer Science spans a vast range of areas from basic computer science theory (algorithms and computational logic)  to in depth analysis of data manipulation and use within technology.

Programming theory
The process of taking a given algorithm and encoding it into a language that can be understood and executed by a computer. There are many different types of programming languages and various different types of computers, however, they all have the same goal: to turn algorithms into machine code.Popular programming languages used within the academic study of CIS include, but are not limited to: Java, Python, C#, C++, Perl, Ruby, Pascal, Swift, Visual Basic.

Information and information systems
The academic study of software and hardware systems that process large quantities and data, support large scale data management and how data can be used. This is where the field is unique from the standard study of computer science. The area of information systems focuses on the networks of hardware and software that are required to process, manipulate and distribute such data.

Computer systems and organisations
The process of analysing computer architecture and various logic circuits. This involves looking at low level computer processes at bit level computation. This is an in-depth look into the hardware processing of a computational system, involving looking at the basic structure of a computer and designing such systems. This can also involve evaluating complex circuit diagrams, and being able to construct these to solve a main problem.
The main purpose behind this area of study is to achieve an understanding of how computers function on a basic level, often through tracing machine operations.

Machines, languages, and computation
This is the study into fundamental computer algorithms, which are the basis to computer programs. Without algorithms, no computer programs would exist. This also involves the process of looking into various mathematical functions behind computational algorithms, basic theory and functional (low level) programming.
In an academic setting, this area would introduce the fundamental mathematical theorems and functions behind theoretical computer science which are the building blocks for other areas in the field. Complex topics such as; proofs, algebraic functions and sets will be introduced during studies of CIS.

Developments
Information and computer science is a field that is rapidly developing with job prospects for students being extremely promising with 75.7% of graduates gaining employment. Also the IT industry employs one in twenty of the workforce with it predicted to increase nearly five times faster than the average of the UK and between 2012 and 2017 more than half a million people will be needed within the industry and the fact that nine out of ten tech firms are suffering from candidate shortages which is having a negative impact on their business as it delays the creation and development of new products, and it's predicted in the US that in the next decade there will be more than one million jobs in the technology sector than computer science graduates to fill them. Because of this programming is now being taught at an earlier age with an aim to interest students from a young age into computer and information science hopefully leading more children to study this at a higher level. For example, children in England will now be exposed to computer programming at the age of 5 due to an updated national curriculum.

Employment
Due to the wide variety of jobs that now involve computer and information science related tasks, it is difficult to provide a comprehensive list of possible jobs in this area, but some of the key areas are artificial intelligence, software engineering and computer networking and communication. Work in this area also tends to require sufficient understanding of mathematics and science. Moreover, jobs that having a CIS degree can lead to, include: systems analyst, network administrator, system architect, information systems developer, web programmer, or software developer.
The earning potential for CIS graduates is quite promising. A 2013 survey from the National Association of Colleges and Employers (NACE) found that the average starting salary for graduates who earned a degree in a computer related field was $59,977, up 4.3% from the prior year. This is higher than other popular degrees such as business ($54,234), education ($40,480) and math and sciences ($42,724). Furthermore, Payscale ranked 129 college degrees based on their graduates earning potential with engineering, math, science, and technology fields dominating the ranking. With eight computer related degrees appearing among the top 30. With the lowest starting salary for these jobs being $49,900. A Rasmussen College article describes various jobs CIS graduates may obtain with software applications developers at the top making a median income of  $98,260.According to the National Careers Service an Information Scientist can expect to earn £24,000+ per year as a starting salary.


== References ==",8431748,https://en.wikipedia.org/wiki/Information_and_computer_science
List of abstractions (computer science),"Abstractions are fundamental building blocks of computer science, enabling complex systems and ideas to be simplified into more manageable and relatable concepts.","Abstractions are fundamental building blocks of computer science, enabling complex systems and ideas to be simplified into more manageable and relatable concepts.

General Programming Abstractions
General programming abstractions are foundational concepts that underlie virtually all of the programming tasks that software developers engage in. By providing a layer of separation from the specifics of the underlying hardware and system details, these abstractions allow for the creation of complex logic in a more approachable and manageable form. They emerge as a consensus on best practices for expressing and solving programming problems in efficient and logically sound ways. From the simplicity of a variable to the structured flow of control structures, these abstractions are the building blocks that constitute high-level programming languages and give rise to detailed software implementations.

Data Structures
In the context of data structures, the term ""abstraction"" refers to the way in which a data structure represents and organizes data. Each data structure provides a particular way of organizing data in memory so that it can be accessed and modified according to specific rules. The data structure itself is an abstraction because it hides the details of how the data is stored in memory and provides a set of operations or interfaces for working with the data (e.g., push and pop for a stack, insert and delete for a binary search tree).

Functional Programming Abstractions
In the world of functional programming, abstraction is not just a tool but a core principle that influences the entire programming model. The abstractions used in functional programming are designed to enhance expressiveness, provide greater modularity, and enable transformative operations that are both concise and predictable. By treating computation as the evaluation of mathematical functions, functional programming moves away from the mutable state and side effects that are typical in imperative programming, presenting a declarative approach to problem-solving.

Concurrency Models
Concurrency models are critical abstractions in computer science that facilitate the management of multiple processes or threads executing simultaneously. These models provide the architectural framework needed to handle concurrent operations efficiently and safely in applications ranging from operating systems to high-throughput data processing and network servers. The key challenge they address is the coordination of computational tasks that can potentially interfere with one another, ensuring data integrity and optimizing resource usage without sacrificing performance.

Design Patterns
Design patterns in computer science represent abstract solutions to common software design problems. While they are not abstractions in the same sense as data structures or mathematical concepts, design patterns provide a high-level language for software developers to communicate and implement solutions in a consistent and recognizable way.
Each design pattern abstracts the complexity of a particular design scenario or problem by providing a tested, proven development paradigm.

Programming Paradigms
Programming paradigms constitute the theoretical frameworks that shape the way software constructs are created and executed. Each paradigm embodies a unique approach to organizing and structuring programming logic, often promoting particular forms of abstraction and compositional structures that align with their underlying principles.

Software Engineering Abstractions
Software engineering abstractions are conceptual tools that simplify the complex reality of software systems, enabling developers to focus on high-level problems and manage software complexity. These abstractions are often about hiding the underlying implementation details through encapsulation, defining clear interfaces, and establishing interaction protocols.

Notes
References

Textbook reference:

Keller, Robert M. [Computer Science: Abstraction to Implementation]. Harvey Mudd College, September 2001.",46814283,https://en.wikipedia.org/wiki/List_of_abstractions_(computer_science)
Outline of computer science,"Computer science (also called computing science) is the study of the theoretical foundations of information and computation and their implementation and application in computer systems. One well known subject classification system for computer science is the ACM Computing Classification System devised by the Association for Computing Machinery.
Computer science can be described as all of the following:

Academic discipline
Science
Applied science","Computer science (also called computing science) is the study of the theoretical foundations of information and computation and their implementation and application in computer systems. One well known subject classification system for computer science is the ACM Computing Classification System devised by the Association for Computing Machinery.
Computer science can be described as all of the following:

Academic discipline
Science
Applied science

Subfields
Mathematical foundations
Coding theory – Useful in networking, programming, system development, and other areas where computers communicate with each other.
Game theory – Useful in artificial intelligence and cybernetics.
Discrete mathematics - Study of discrete structures. Used in digital computer systems.
Graph theory – Foundations for data structures and searching algorithms.
Mathematical logic – Boolean logic and other ways of modeling logical queries; the uses and limitations of formal proof methods
Number theory – Theory of the integers.  Used in cryptography as well as a test domain in artificial intelligence.

Algorithms and data structures
Algorithms – Sequential and parallel computational procedures for solving a wide range of problems.
Data structures – The organization and manipulation of data.

Artificial intelligence
Outline of artificial intelligence

Artificial intelligence – The implementation and study of systems that exhibit an autonomous intelligence or behavior of their own.
Automated reasoning – Solving engines, such as used in Prolog, which produce steps to a result given a query on a fact and rule database, and automated theorem provers that aim to prove mathematical theorems with some assistance from a programmer.
Computer vision – Algorithms for identifying three-dimensional objects from a two-dimensional picture.
Soft computing, the use of inexact solutions for otherwise extremely difficult problems:
Machine learning - Development of models that are able to learn and adapt without following explicit instructions, by using algorithms and statistical models to analyse and draw inferences from patterns in data.
Evolutionary computing - Biologically inspired algorithms.
Natural language processing - Building systems and algorithms that analyze, understand, and generate natural (human) languages.
Robotics – Algorithms for controlling the behaviour of robots.

Communication and security
Networking – Algorithms and protocols for reliably communicating data across different shared or dedicated media, often including error correction.
Computer security – Practical aspects of securing computer systems and computer networks.
Cryptography – Applies results from complexity, probability, algebra and number theory to invent and break codes, and analyze the security of cryptographic protocols.

Computer architecture
Computer architecture – The design, organization, optimization and verification of a computer system, mostly about CPUs and Memory subsystem (and the bus connecting them).
Operating systems – Systems for managing computer programs and providing the basis of a usable system.

Computer graphics
Computer graphics – Algorithms both for generating visual images synthetically, and for integrating or altering visual and spatial information sampled from the real world.
Image processing – Determining information from an image through computation.
Information visualization – Methods for representing and displaying abstract data to facilitate human interaction for exploration and understanding.

Concurrent, parallel, and distributed systems
Parallel computing - The theory and practice of simultaneous computation; data safety in any multitasking or multithreaded environment.
Concurrency (computer science) – Computing using multiple concurrent threads of execution, devising algorithms for solving problems on various processors to achieve maximal speed-up compared to sequential execution.
Distributed computing – Computing using multiple computing devices over a network to accomplish a common objective or task and thereby reducing the latency involved in single processor contributions for any task.

Databases
Outline of databases

Relational databases – the set theoretic and algorithmic foundation of databases.
Structured Storage - non-relational databases such as NoSQL databases.
Data mining – Study of algorithms for searching and processing information in documents and databases; closely related to information retrieval.

Programming languages and compilers
Compiler theory – Theory of compiler design, based on Automata theory.
Programming language pragmatics – Taxonomy of programming languages, their strength and weaknesses. Various programming paradigms, such as object-oriented programming.
Programming language theory - Theory of programming language design
Formal semantics – rigorous mathematical study of the meaning of programs.
Type theory – Formal analysis of the types of data, and the use of these types to understand properties of programs — especially program safety.

Scientific computing
Computational science – constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems.
Numerical analysis – Approximate numerical solution of mathematical problems such as root-finding, integration, the solution of ordinary differential equations; the approximation of special functions.
Symbolic computation – Manipulation and solution of expressions in symbolic form, also known as Computer algebra.
Computational physics – Numerical simulations of large non-analytic systems
Computational chemistry – Computational modelling of theoretical chemistry in order to determine chemical structures and properties
Bioinformatics and Computational biology – The use of computer science to maintain, analyse, store biological data and to assist in solving biological problems such as Protein folding, function prediction and Phylogeny.
Computational neuroscience – Computational modelling of neurophysiology.
Computational linguistics
Computational logic
Computational engineering

Software engineering
Outline of software engineering

Formal methods – Mathematical approaches for describing and reasoning about software design.
Software engineering – The principles and practice of designing, developing, and testing programs, as well as proper engineering practices.
Algorithm design – Using ideas from algorithm theory to creatively design solutions to real tasks.
Computer programming – The practice of using a programming language to implement algorithms.
Human–computer interaction – The study and design of computer interfaces that people use.
Reverse engineering – The application of the scientific method to the understanding of arbitrary existing software.

Theory of computation
Automata theory – Different logical structures for solving problems.
Computability theory – What is calculable with the current models of computers. Proofs developed by Alan Turing and others provide insight into the possibilities of what may be computed and what may not.
List of unsolved problems in computer science
Computational complexity theory – Fundamental bounds (especially time and storage space) on classes of computations.
Quantum computing theory – Explores computational models involving quantum superposition of bits.

History
History of computer science
List of pioneers in computer science

Professions
Programmer (Software developer)
Teacher/Professor
Software engineer
Software architect
Software tester
Hardware engineer
Data analyst
Interaction designer
Network administrator
Data scientist

Data and data structures
Data structure
Data type
Associative array and Hash table
Array
List
Tree
String
Matrix (computer science)
Database

Programming paradigms
Imperative programming/Procedural programming
Functional programming
Logic programming
Object oriented programming
Class
Inheritance
Object

See also
Abstraction
Big O notation
Closure
Compiler
Cognitive science

External links

Outline of computer science at Curlie
ACM report on a recommended computer science curriculum (2008) (PDF)
Directory of free university lectures in Computer Science (archived 12 May 2008)
Collection of Computer Science Bibliographies
Photographs of computer scientists (Bertrand Meyer's gallery)",169633,https://en.wikipedia.org/wiki/Outline_of_computer_science
Prefetching,"Prefetching in computer science is a technique for speeding up fetch operations by beginning a fetch operation whose result is expected to be needed soon.  Usually this is before it is known to be needed, so there is a risk of wasting time by prefetching data that will not be used.  The technique can be applied in several circumstances:

Cache prefetching, a speedup technique used by computer processors where instructions or data are fetched before they are needed
Prefetch input queue (PIQ), in computer architecture, pre-loading machine code from memory
Link prefetching, a web mechanism for prefetching links
Prefetcher technology in modern releases of Microsoft Windows
Prefetch instructions, for example provided by
PREFETCH, an X86 instruction in computing
Prefetch buffer, a feature of DDR SDRAM memory
Swap prefetch, in computer operating systems, anticipatory paging","Prefetching in computer science is a technique for speeding up fetch operations by beginning a fetch operation whose result is expected to be needed soon.  Usually this is before it is known to be needed, so there is a risk of wasting time by prefetching data that will not be used.  The technique can be applied in several circumstances:

Cache prefetching, a speedup technique used by computer processors where instructions or data are fetched before they are needed
Prefetch input queue (PIQ), in computer architecture, pre-loading machine code from memory
Link prefetching, a web mechanism for prefetching links
Prefetcher technology in modern releases of Microsoft Windows
Prefetch instructions, for example provided by
PREFETCH, an X86 instruction in computing
Prefetch buffer, a feature of DDR SDRAM memory
Swap prefetch, in computer operating systems, anticipatory paging

See also
 The dictionary definition of prefetching at Wiktionary",1806683,https://en.wikipedia.org/wiki/Prefetching
Psychoinformatics,"Psychoinformatics is an emerging interdisciplinary field that uses principles from computer science for the acquisition, organization, and synthesis of data collected from psychology to reveal information about psychological traits such as personality and mood. The term may also be used in context of affective computing or character computing.
Psychology has historically relied on experiments and questionnaires in order to collect data. These methods face several disadvantages, namely that experiments often consist of a small quantity of users (who must be incentivized to participate) and self-reported questionnaires and interviews are subject to bias and unreliable memory. Psychoinformatics solves these problems by storing Big Data related to psychology (such as communications on smartphones or social media websites) and then data mining for relevant psychological information.","Psychoinformatics is an emerging interdisciplinary field that uses principles from computer science for the acquisition, organization, and synthesis of data collected from psychology to reveal information about psychological traits such as personality and mood. The term may also be used in context of affective computing or character computing.
Psychology has historically relied on experiments and questionnaires in order to collect data. These methods face several disadvantages, namely that experiments often consist of a small quantity of users (who must be incentivized to participate) and self-reported questionnaires and interviews are subject to bias and unreliable memory. Psychoinformatics solves these problems by storing Big Data related to psychology (such as communications on smartphones or social media websites) and then data mining for relevant psychological information.

See also
affective computing
Bioinformatics
Neuroinformatics
Psychometrics
Quantitative psychology


== References ==",66760902,https://en.wikipedia.org/wiki/Psychoinformatics
Technology transfer in computer science,"Technology transfer in computer science refers to the transfer of technology developed in computer science or applied computing research, from universities and governments to the private sector. These technologies may be abstract, such as algorithms and data structures, or concrete, such as open source software packages.","Technology transfer in computer science refers to the transfer of technology developed in computer science or applied computing research, from universities and governments to the private sector. These technologies may be abstract, such as algorithms and data structures, or concrete, such as open source software packages.

Examples
Notable examples of technology transfer in computer science include:


== References ==",44409131,https://en.wikipedia.org/wiki/Technology_transfer_in_computer_science
Transition (computer science),"Transition refers to a computer science paradigm in the context of communication systems which describes the change of communication mechanisms, i.e., functions of a communication system, in particular, service and protocol components. In a transition, communication mechanisms within a system are replaced by functionally comparable mechanisms with the aim to ensure the highest possible quality, e.g., as captured by the quality of service.

Transitions enable communication systems to adapt to changing conditions during runtime. This change in conditions can, for example, be a rapid increase in the load on a certain service that may be caused, e.g., by large gatherings of people with mobile devices. A transition often impacts multiple mechanisms at different communication layers of a layered architecture.
Mechanisms are given as conceptual elements of a networked communication system and are linked to specific functional units, for example, as a service or protocol component. In some cases, a mechanism can also comprise an entire protocol. For example on the transmission layer, LTE can be regarded as such a mechanism. Following this definition, there exist numerous communication mechanisms that are partly equivalent in their basic functionality, such as Wi-Fi, Bluetooth and Zigbee for local wireless networks and UMTS and LTE for broadband wireless connections. For example, LTE and Wi-Fi have equivalent basic functionality, but they are technologically significantly different in their design and operation. Mechanisms affected by transitions are often components of a protocol or service. For example, in case of video streaming/transmission, the use of different video data encoding can be carried out depending on the available data transmission rate. These changes are controlled and implemented by transitions; A research example is a context-aware video adaptation service to support mobile video applications. Through analyzing the current processes in a communication system, it is possible to determine which transitions need to be executed at which communication layer in order to meet the quality requirements. In order for communication systems to adapt to the respective framework conditions, architectural approaches of self-organizing, adaptive systems can be used, such as the MAPE cycle  (Monitor-Analyze-Plan-Execute). This central concept of Autonomic Computing can be used to determine the state of the communication system, to analyze the monitoring data and to plan and execute the necessary transition(s). A central goal is that users do not consciously perceive a transition while running applications and that the functionality of the used services is perceived as smooth and fluid.","Transition refers to a computer science paradigm in the context of communication systems which describes the change of communication mechanisms, i.e., functions of a communication system, in particular, service and protocol components. In a transition, communication mechanisms within a system are replaced by functionally comparable mechanisms with the aim to ensure the highest possible quality, e.g., as captured by the quality of service.

Transitions enable communication systems to adapt to changing conditions during runtime. This change in conditions can, for example, be a rapid increase in the load on a certain service that may be caused, e.g., by large gatherings of people with mobile devices. A transition often impacts multiple mechanisms at different communication layers of a layered architecture.
Mechanisms are given as conceptual elements of a networked communication system and are linked to specific functional units, for example, as a service or protocol component. In some cases, a mechanism can also comprise an entire protocol. For example on the transmission layer, LTE can be regarded as such a mechanism. Following this definition, there exist numerous communication mechanisms that are partly equivalent in their basic functionality, such as Wi-Fi, Bluetooth and Zigbee for local wireless networks and UMTS and LTE for broadband wireless connections. For example, LTE and Wi-Fi have equivalent basic functionality, but they are technologically significantly different in their design and operation. Mechanisms affected by transitions are often components of a protocol or service. For example, in case of video streaming/transmission, the use of different video data encoding can be carried out depending on the available data transmission rate. These changes are controlled and implemented by transitions; A research example is a context-aware video adaptation service to support mobile video applications. Through analyzing the current processes in a communication system, it is possible to determine which transitions need to be executed at which communication layer in order to meet the quality requirements. In order for communication systems to adapt to the respective framework conditions, architectural approaches of self-organizing, adaptive systems can be used, such as the MAPE cycle  (Monitor-Analyze-Plan-Execute). This central concept of Autonomic Computing can be used to determine the state of the communication system, to analyze the monitoring data and to plan and execute the necessary transition(s). A central goal is that users do not consciously perceive a transition while running applications and that the functionality of the used services is perceived as smooth and fluid.

Recent research
The study of new and fundamental design methods, models and techniques that enable automated, coordinated and cross-layer transitions between functionally similar mechanisms within a communication system is the main goal of a collaborative research center funded by the German research foundation (DFG). The DFG collaborative research center 1053 MAKI - Multi-mechanism Adaptation for the future Internet - focuses on research questions in the following areas: (i) Fundamental research on transition methods, (ii) Techniques for adapting transition-capable communication systems on the basis of achieved and targeted quality, and (iii) specific and exemplary transitions in communication systems as regarded from different technical perspectives.
A formalization of the concept of transitions that captures the features and relations within a communication system to express and optimize the decision making process that is associated with such a system is given in. The associated building blocks comprise (i) Dynamic Software Product Lines, (ii) Markov Decision Processes and (iii) Utility Design. While Dynamic Software Product Lines provide a method to concisely capture a large configuration space and to specify run time variability of adaptive systems, Markov Decision Processes provide a mathematical tool to define and plan transitions between available communication mechanisms. Finally, utility functions quantify the performance of individual configurations of the transition-based communication system and provide the means to optimize the performance in such a system.
Applications of the idea of transitions have found their way to wireless sensor networks and mobile networks, distributed reactive programming, WiFi firmware modification, planning of autonomic computing systems, analysis of CDNs, flexible extensions of the ISO OSI stack, 5G mmWave vehicular communications, the analysis of MapReduce-like parallel systems, scheduling of Multipath TCP, adaptivity for beam training in 802.11ad, operator placement in dynamic user environments, DASH video player analysis, adaptive bitrate streaming and complex event processing on mobile devices.

References
External links
MAKI",53650506,https://en.wikipedia.org/wiki/Transition_(computer_science)
"School of Computational Sciences, Swami Ramanand Teerth Marathwada University",The School of Computational Sciences is a institute affiliated to Swami Ramanand Teerth Marathwada University (SRTMU) in Nanded in the Indian state of Maharashtra. Srtmun college NAC committee given by A grade .,"The School of Computational Sciences is a institute affiliated to Swami Ramanand Teerth Marathwada University (SRTMU) in Nanded in the Indian state of Maharashtra. Srtmun college NAC committee given by A grade .

About School
About the School of Computational Sciences. The need of this school was for awareness of education in computational sciences in
the region and assisting in the development of potential manpower of computer professionals
from this area.
General Introduction of the School
The School of Computational Sciences is having almost 100% off campus placement record
in the Marathwada region and the feat is all set to maintain the same. The faculty of the
School is young and dynamic with diverse academic background and invaluable practical
experience. The School has the courses related to the latest trends and technologies associated
with the computers. The School has well equipped laboratories with state of the art allied
facilities.
Academics of the school are highly innovative and provide lot of practical flexibility. The
evaluation of student consists of continuous internal evaluation and opens to the students as
in well known institutes. Faculty members and students of the School participated and
initiated several projects, attended conferences with the research related activities.

History
It was established with the inception of Swami Ramanand Teerth Marathwada University (1994). This school provides education in computational/computer sciences.

Curriculum
Courses Offered by the institute are :

·Ph.D. (Computer Science)
·M.Phil. (Computer Science)
M. Sc. (Computer Science)
M. Sc. (Computer Application)
M. Sc. (Computer Network) The course is of 2 year/4 semester duration
Master of Computer Application. (M.C.A.) The course is 3 years/6 semesters duration

References
External links
Computational Sciences, Swami Ramanand Teerth Marathwada University",52322744,"https://en.wikipedia.org/wiki/School_of_Computational_Sciences,_Swami_Ramanand_Teerth_Marathwada_University"
ABC (programming language),"ABC is an imperative general-purpose programming language and integrated development environment (IDE) developed at Centrum Wiskunde & Informatica (CWI), Netherlands by Leo Geurts, Lambert Meertens, and Steven Pemberton. It is interactive, structured, high-level, and intended to be used instead of BASIC, Pascal, or AWK. It is intended for teaching or prototyping, but not as a systems-programming language.
ABC had a major influence on the design of the language Python, developed by Guido van Rossum, who formerly worked for several years on the ABC system in the mid-1980s.","ABC is an imperative general-purpose programming language and integrated development environment (IDE) developed at Centrum Wiskunde & Informatica (CWI), Netherlands by Leo Geurts, Lambert Meertens, and Steven Pemberton. It is interactive, structured, high-level, and intended to be used instead of BASIC, Pascal, or AWK. It is intended for teaching or prototyping, but not as a systems-programming language.
ABC had a major influence on the design of the language Python, developed by Guido van Rossum, who formerly worked for several years on the ABC system in the mid-1980s.

Features
Its designers claim that ABC programs are typically around a quarter the size of the equivalent Pascal or C programs, and more readable. Key features include:

Only five basic data types
No required variable declarations
Explicit support for top-down programming
Statement nesting is indicated by indentation, via the off-side rule
Infinite precision arithmetic, unlimited-sized lists and strings, and other features supporting orthogonality and ease of use by novicesABC was originally a monolithic implementation, leading to an inability to adapt to new requirements, such as creating a graphical user interface (GUI). ABC could not directly access the underlying file system and operating system.
The full ABC system includes a programming environment with a structure editor (syntax-directed editor), suggestions, static variables (persistent), and multiple workspaces, and is available as an interpreter–compiler. As of 2020, the latest version is 1.05.02, and it is ported to Unix, DOS, Atari, and Apple MacOS.

Example
An example function to collect the set of all words in a document:

HOW TO RETURN words document:
   PUT {} IN collection
   FOR line IN document:
      FOR word IN split line:
         IF word not.in collection:
            INSERT word IN collection
   RETURN collection

References
External links
ABC Programmer's Handbook",147585,https://en.wikipedia.org/wiki/ABC_(programming_language)
Amoeba (operating system),Amoeba is a distributed operating system developed by Andrew S. Tanenbaum and others at the Vrije Universiteit Amsterdam. The aim of the Amoeba project was to build a timesharing system that makes an entire network of computers appear to the user as a single machine.  Development at the Vrije Universiteit was stopped: the source code of the latest version (5.3) was last modified on 30 July 1996.The Python programming language was originally developed for this platform.,"Amoeba is a distributed operating system developed by Andrew S. Tanenbaum and others at the Vrije Universiteit Amsterdam. The aim of the Amoeba project was to build a timesharing system that makes an entire network of computers appear to the user as a single machine.  Development at the Vrije Universiteit was stopped: the source code of the latest version (5.3) was last modified on 30 July 1996.The Python programming language was originally developed for this platform.

Overview
The goal of the Amoeba project was to construct an operating system for networks of computers that would present the network to the user as if it were a single machine. An Amoeba network consists of a number of workstations connected to a ""pool"" of processors, and executing a program from a terminal causes it to run on any of the available processors, with the operating system providing load balancing. Unlike the contemporary Sprite, Amoeba does not support process migration.
The workstations would typically function as networked terminals only. Aside from workstations and processors, additional machines operate as servers for files, directory services, TCP/IP communications etc.Amoeba is a microkernel-based operating system. It offers multithreaded programs and a remote procedure call (RPC) mechanism for communication between threads, potentially across the network; even kernel-threads use this RPC mechanism for communication. Each thread is assigned a 48-bit number called its ""port"", which serves as its unique, network-wide ""address"" for communication.The user interface and APIs of Amoeba were modeled after Unix and compliance with the POSIX standard was partially implemented; some of the Unix emulation code consists of utilities ported over from Tanenbaum's other operating system, MINIX. Early versions used a ""homebrew"" window system, which the Amoeba authors considered ""faster ... in our view, cleaner ... smaller and much easier to understand"", but version 4.0 uses the X Window System (and allows X terminals as terminals).
The system uses FLIP as a network protocol.

See also
Distributed computing
Multikernel
Plan 9 from Bell Labs

References
External links
Amoeba home page (static page, ftp links are dead)
FSD-Amoeba page at Sourceforge (file downloads give 403 errors)
ArchiveOS mirror of Amoeba 5.3",440784,https://en.wikipedia.org/wiki/Amoeba_(operating_system)
Amsterdam Compiler Kit,"The Amsterdam Compiler Kit (ACK) is a retargetable compiler suite and toolchain written by Andrew Tanenbaum and Ceriel Jacobs, since 2005 maintained by David Given. It has frontends for the following programming languages: C, Pascal, Modula-2, Occam, and BASIC.","The Amsterdam Compiler Kit (ACK) is a retargetable compiler suite and toolchain written by Andrew Tanenbaum and Ceriel Jacobs, since 2005 maintained by David Given. It has frontends for the following programming languages: C, Pascal, Modula-2, Occam, and BASIC.

History
The ACK's notability stems from the fact that in the early 1980s it was one of the first portable compilation systems designed to support multiple source languages and target platforms.The ACK was known as MINIX's native compiler toolchain until the MINIX userland was largely replaced by that of NetBSD (MINIX 3.2.0) and Clang was adopted as the system compiler.
It was originally closed-source software (that allowed binaries to be distributed for MINIX as a special case), but in April 2003 it was released under the BSD licenses.

Working principle
Maximum portability is achieved by using an intermediate language using bytecode, called EM. Each language front-end produces EM object files, which are then processed through several generic optimisers before being translated by a back-end into native machine code.
ACK comes with a generic linker and librarian capable of manipulating files in the ACK's own a.out-based format; it will work on files containing EM code as well as native machine code. However, EM code cannot be linked to native machine code without translating the EM binary first.

Target processors
ACK backends can produce native machine code for a wide range of CPUs, even starting with small 8 bit CPUs. 

6502
6800 (assembler only)
6805 (assembler only)
6809 (assembler only)
ARM
8080*
Z80
Z8000
Intel 8086*
i386
68000
68020
68040
NS32016
S2650 (assembler only)
SPARC
VAX4
PDP-11
Broadcom VideoCore IV (BCM2708)** Version 6.0

See also
Portable C compiler

References
External links
Official website 
Official sourcecode repository, including changelog (GitHub)",5931431,https://en.wikipedia.org/wiki/Amsterdam_Compiler_Kit
Electrologica X1,"The Electrologica X1 was a digital computer designed and manufactured in the Netherlands from 1958 to 1965. About thirty were produced and sold in the Netherlands and abroad.The X1 was designed by the Mathematical Centre in Amsterdam, an academic organization that had been involved in computer design since 1947, and manufactured by Electrologica NV, a company formed expressly for the purpose of producing the machine.
The X1 was a solid-state binary computer (""completely transistorized"") with magnetic core memory. Word-length was 27 bits and peripherals included punched and magnetic tape. It was one of the first European computers to have an interrupt facility.
The X1 was the subject of Edsger Dijkstra's Ph.D. dissertation, and the target of the first complete working ALGOL 60 compiler, completed by Dijkstra and Jaap Zonneveld. In 1965, the X1 was superseded by the X8. Electrologica was taken over by Philips a few years later.","The Electrologica X1 was a digital computer designed and manufactured in the Netherlands from 1958 to 1965. About thirty were produced and sold in the Netherlands and abroad.The X1 was designed by the Mathematical Centre in Amsterdam, an academic organization that had been involved in computer design since 1947, and manufactured by Electrologica NV, a company formed expressly for the purpose of producing the machine.
The X1 was a solid-state binary computer (""completely transistorized"") with magnetic core memory. Word-length was 27 bits and peripherals included punched and magnetic tape. It was one of the first European computers to have an interrupt facility.
The X1 was the subject of Edsger Dijkstra's Ph.D. dissertation, and the target of the first complete working ALGOL 60 compiler, completed by Dijkstra and Jaap Zonneveld. In 1965, the X1 was superseded by the X8. Electrologica was taken over by Philips a few years later.

Instruction set
The X1 allowed conditional execution of every instruction, not just branches as is the case in most computers.  A similar capability existed in the Zuse Z22 and the ZEBRA, and much later in the ARM architecture.  The approach used in the X1 is more flexible than these others: it makes execution conditional on the current state of the condition flag that is set by a previous instruction if it includes a modifier for that purpose, but untouched otherwise.  As a result, conditional execution can be based on tests made some number of lines earlier, rather than being conditional only based on the result of the most recent arithmetic operation.  This allowed for compact expression of programs. The following example demonstrates the loading of the value of memory at n into the accumulator A, calling a subroutine (which presumably uses that value in A), and finally setting A to be the absolute value of the number read:

   2A n P   // copy [n] to A, set condition flag to ""yes"" if positive
   6T fn 0  // call the function at fn, which will return with the condition flag preserved
 N 5P AA    // if condition flag is ""no"", copy -A to A

The X1 arithmetic operators used binary ones' complement arithmetic.

Assembler
The X1 included a simple assembler in its  read-only memory. It has rather basic features: symbolic addresses may be defined, but symbols are only two letters long.  Instructions are named by a combination of a digit representing the operation, and a letter designating the register to be operated on, or one or two letters indicating an operation class.  For example, ""0A"" means ""add memory content to accumulator A"", and ""5P"" means ""set an accumulator to the negative of another accumulator"".  The normal use of symbolic addresses is to name ""paragraphs"", i.e., related blocks of code or data.  The symbolic addresses would be modified by a ""line number"" (a numeric offset) and a ""page number"" (a number in the range 0 to 31).  For example, ""3 FE 6"" is line number 3, page number 6, representing an offset of 195 (6 * 32 + 3) from the start of paragraph FE.  This address notation is a peculiarity of the assembler; the hardware addressing simply uses 15 bit addresses.

References
Loopstra, B. J. (1 January 1959). ""The X--1 Computer"". The Computer Journal. 2 (1): 39–43. doi:10.1093/comjnl/2.1.39. ISSN 0010-4620. Abstract: This article describes a small, fast, transistorized computer, designed basically for commercial data-processing, developed by the staff of the Mathematical Centre, Amsterdam. The article is based on a talk given by the author to a Colloquium at the University Mathematical Laboratory, Cambridge, on 27 November 1958.
""Reference Information: Survey of European Computers, Part 3 (Concluding Part) - N.V. Electrologica: X 1"" (PDF). Computers and Automation. 9 (4): 25. Apr 1960. Retrieved 2020-09-05.

External links
 Media related to Electrologica X1 at Wikimedia Commons",2600128,https://en.wikipedia.org/wiki/Electrologica_X1
Electrologica X8,"The Electrologica X8 (or EL X8) was a digital computer designed as a successor to the Electrologica X1 and manufactured in the Netherlands by Electrologica NV between 1964 and 1968.
Like its predecessor, the X1, the X8 system included core memory, 27-bit word length, and drum memory as secondary storage (not as primary storage).  The memory address was increased from 15 to 18 bits, for a theoretical maximum memory size of 256k words.  The X8 included an independent peripheral processor called CHARON (Centraal Hulporgaan Autonome Regeling Overdracht Nevenapparatuur, or Central Coprocessor Autonomous Regulation Transfer Peripherals) which handled I/O.  Other features included up to 48 input/output channels designed for low speed devices such as paper tape, plotters and printers. Unlike the X1, the arithmetic unit of the X8 included floating point arithmetic, with a 41-bit mantissa and 12-bit exponent (which adds up to 53 bits rather than 54; the reason is that there are two copies of the mantissa sign bit).
The system is most notable as the target processor for Edsger Dijkstra's implementation of the THE multiprogramming system.  This includes the invention of semaphores, enabled by a specific instruction in the X8 instruction set.  Semaphores were used not only as a synchronization mechanism within the THE operating system, but also in the request and response data structures for I/O requests processed by the CHARON coprocessor.","The Electrologica X8 (or EL X8) was a digital computer designed as a successor to the Electrologica X1 and manufactured in the Netherlands by Electrologica NV between 1964 and 1968.
Like its predecessor, the X1, the X8 system included core memory, 27-bit word length, and drum memory as secondary storage (not as primary storage).  The memory address was increased from 15 to 18 bits, for a theoretical maximum memory size of 256k words.  The X8 included an independent peripheral processor called CHARON (Centraal Hulporgaan Autonome Regeling Overdracht Nevenapparatuur, or Central Coprocessor Autonomous Regulation Transfer Peripherals) which handled I/O.  Other features included up to 48 input/output channels designed for low speed devices such as paper tape, plotters and printers. Unlike the X1, the arithmetic unit of the X8 included floating point arithmetic, with a 41-bit mantissa and 12-bit exponent (which adds up to 53 bits rather than 54; the reason is that there are two copies of the mantissa sign bit).
The system is most notable as the target processor for Edsger Dijkstra's implementation of the THE multiprogramming system.  This includes the invention of semaphores, enabled by a specific instruction in the X8 instruction set.  Semaphores were used not only as a synchronization mechanism within the THE operating system, but also in the request and response data structures for I/O requests processed by the CHARON coprocessor.

References
E.W.Dijkstra, Documentatie over de communicatie apparatuur aan de EL X8, EWD140, undated.  [1]
E.W.Dijkstra, Globale beschrijving van de drijvende arithmetiek van de EL X8, EWD145, 6 December 1965. [2]
E.W. Dijkstra, ""The structure of the 'THE' multiprogramming system"", Communications of the ACM 11(5):341–346, 1968. Dijkstra's manuscript EWD196 Full text (subscription)

External links
 Media related to Electrologica X8 at Wikimedia Commons
The Electrologica X1 and X8 computers",6654038,https://en.wikipedia.org/wiki/Electrologica_X8
Minix,"MINIX (from mini-Unix) is a Unix-like operating system based on a microkernel architecture. Since version 2.0, it has been Portable Operating System Interface (POSIX) compliant.Early versions of MINIX were created by Andrew S. Tanenbaum for educational purposes. Starting with MINIX 3, the primary aim of development shifted from education to the creation of a highly reliable and self-healing microkernel OS. MINIX 3 was developed as open-source software.
MINIX was first released in 1987, with its complete source code made available to universities for study in courses and research. It has been free and open-source software since it was relicensed under the BSD-3-Clause license in April 2000.","MINIX (from mini-Unix) is a Unix-like operating system based on a microkernel architecture. Since version 2.0, it has been Portable Operating System Interface (POSIX) compliant.Early versions of MINIX were created by Andrew S. Tanenbaum for educational purposes. Starting with MINIX 3, the primary aim of development shifted from education to the creation of a highly reliable and self-healing microkernel OS. MINIX 3 was developed as open-source software.
MINIX was first released in 1987, with its complete source code made available to universities for study in courses and research. It has been free and open-source software since it was relicensed under the BSD-3-Clause license in April 2000.

Implementation
MINIX 1.0
Andrew S. Tanenbaum created MINIX at Vrije Universiteit in Amsterdam to exemplify the principles conveyed in his textbook, Operating Systems: Design and Implementation (1987). (Despite sharing a name, it has no relation to the older MINIX from Digital Systems House, Inc. based on AT&T Unix code.)
An abridged 12,010 lines of the C source code of the kernel, memory manager, and file system of MINIX 1.0 are printed in the book. Prentice-Hall also released MINIX source code and binaries on floppy disk with a reference manual. MINIX 1 was system-call compatible with Seventh Edition Unix.Tanenbaum originally developed MINIX for compatibility with the IBM PC and IBM PC/AT 8088 microcomputers available at the time.

MINIX 1.5
MINIX 1.5, released in 1991, included support for MicroChannel IBM PS/2 systems and was also ported to the Motorola 68000 and SPARC architectures, supporting the Atari ST, Amiga, Macintosh, and Sun SPARCstation computer platforms. There were also unofficial ports to Intel 386 PC compatibles (in 32-bit protected mode), National Semiconductor NS32532, ARM and Inmos transputer processors. Meiko Scientific used an early version of MINIX as the basis for the MeikOS operating system for its transputer-based Computing Surface parallel computers.

MINIX 2.0
Demand for the 68k-architectures waned, however, and MINIX 2.0, released in 1997, was only available for the x86 and Solaris-hosted SPARC architectures. It was the subject of the second edition of Tanenbaum's textbook, cowritten with Albert Woodhull and was distributed on a CD-ROM included with the book. MINIX 2.0 added POSIX.1 compliance, support for 386 and later processors in 32-bit mode and replaced the Amoeba network protocols included in MINIX 1.5 with a TCP/IP stack.  A version of MINIX running as a user process under SunOS and Solaris was also available, a simulator named SMX (operating system) or just SMX for short.Version 2.0.3 was released in May 2001. It was the first version after MINIX had been relicensed under the BSD-3-Clause license, which was retroactively applied to all previous versions.

Minix-vmd
Minix-vmd is a variant of MINIX 2.0 for Intel IA-32-compatible processors, created by two Vrije Universiteit researchers, which adds virtual memory and support for the X Window System.

MINIX 3
MINIX 3 was publicly announced on 24 October 2005 by Tanenbaum during his keynote speech at the Association for Computing Machinery (ACM) Symposium on Operating Systems Principles (SOSP). Although it still serves as an example for the new edition of Tanenbaum's textbook, coauthored by Albert S. Woodhull, it is comprehensively redesigned to be ""usable as a serious system on resource-limited and embedded computers and for applications requiring high reliability.""MINIX 3 currently supports IA-32 and ARM architecture systems. It is available in a live CD format that allows it to be used on a computer without installing it on the hard drive, and in versions compatible with hardware emulating and virtualizing systems, including Bochs, QEMU, VMware Workstation and Fusion, VirtualBox, and Microsoft Virtual PC.
Version 3.1.2 was released on 18 April 2006. It was the first version after MINIX had been relicensed under the BSD-3-Clause license with a new fourth clause.Version 3.1.5 was released on 5 November 2009. It contains X11, emacs, vi, cc, gcc, perl, python, ash, bash, zsh, ftp, ssh, telnet, pine, and over 400 other common Unix utility programs. With the addition of X11, this version marks the transition away from a text-only system. In many cases it can automatically restart a crashed driver without affecting running processes. In this way, MINIX is self-healing and can be used in applications demanding high reliability. MINIX 3 also has support for virtual memory management, making it suitable for desktop OS use. Desktop applications such as Firefox and OpenOffice.org are not yet available for MINIX 3 however.
As of version 3.2.0, the userland was mostly replaced by that of NetBSD and support from pkgsrc became possible, increasing the available software applications that MINIX can use. Clang replaced the prior compiler (with GCC now having to be manually compiled), and GDB, the GNU debugger, was ported.MINIX 3.3.0, released in September 2014, brought ARM support.
MINIX 3.4.0RC, Release Candidates became available in January 2016. However, a stable release of MINIX 3.4.0 is yet to be announced, and MINIX development has been dormant since 2018.MINIX supports many programming languages, including C, C++, FORTRAN, Modula-2, Pascal, Perl, Python, and Tcl.
Over 50 people attended MINIXCon 2016, a conference to discuss the history and future of MINIX.All Intel chipsets post-2015 are running MINIX 3 internally as the software component of the Intel Management Engine.

Relationship with Linux
Early influence
Linus Torvalds used and appreciated MINIX, but his design deviated from the MINIX architecture in significant ways, most notably by employing a monolithic kernel instead of a microkernel. This was disapproved of by Tanenbaum in the Tanenbaum–Torvalds debate. Tanenbaum explained again his rationale for using a microkernel in May 2006.Early Linux kernel development was done on a MINIX host system, which led to Linux inheriting various features from MINIX, such as the MINIX file system. Eric Raymond claimed that Linus hasn't actually written Linux from scratch, but rather reused source code of MINIX itself to have working codebase. As the development progressed, MINIX code was gradually phased out completely.

Samizdat claims
In May 2004, Kenneth Brown of the Alexis de Tocqueville Institution made the accusation that major parts of the Linux kernel had been copied from the MINIX codebase, in a book named Samizdat. These accusations were rebutted universally—most prominently by Tanenbaum, who strongly criticised Brown and published a long rebuttal on his own personal Web site, also claiming that Brown was funded by Microsoft.

Licensing
At the time of MINIX's original development, its license was relatively liberal. Its licensing fee was very small ($69) relative to those of other operating systems. Tanenbaum wished for MINIX to be as accessible as possible to students, but his publisher was unwilling to offer material (such as the source code) that could be copied freely, so a restrictive license requiring a nominal fee (included in the price of Tanenbaum's book) was applied as a compromise. This prevented the use of MINIX as the basis for a freely distributed software system.
When free and open-source Unix-like operating systems such as Linux and 386BSD became available in the early 1990s, many volunteer software developers abandoned MINIX in favor of these. In April 2000, MINIX became free and open-source software under the BSD-3-Clause license, which was retroactively applied to all previous versions.  However, by this time other operating systems had surpassed its capabilities, and it remained primarily an operating system for students and hobbyists. In late 2005, MINIX was relicensed with a fourth clause added to the BSD-3-Clause license.

See also
MINIX file system
Redox, an operating system in Rust using a MINIX-like kernel
Xinu
xv6

Notes
References
External links

Official website
Stichting-MINIX-Research-Foundation on GitHub
The Minix Operating System (Minix 2 support)
History of MINIX from Andrew Tanenbaum
MINIX 3: a Modular, Self-Healing POSIX-compatible Operating System on YouTube
Minix at Curlie",18977,https://en.wikipedia.org/wiki/Minix
Minix 3,"Minix 3 is a small, Unix-like operating system. It is published under a BSD-3-Clause license and is a successor project to the earlier versions, Minix 1 and 2.The project's main goal is for the system to be fault-tolerant by detecting and repairing its faults on the fly, with no user intervention. The main uses of the system are envisaged to be embedded systems and education.As of 2017, Minix 3 supports IA-32 and ARM architecture processors. It can also run on emulators or virtual machines, such as Bochs, VMware Workstation, Microsoft Virtual PC, Oracle VirtualBox, and QEMU. A port to PowerPC architecture is in development. The distribution comes on a live CD and does not support live USB installation. The project has been dormant since 2018, and the latest release is 3.4.0 rc6 from 2017, although the Minix 3 discussion group is still active.Minix 3 is believed to have inspired the Intel Management Engine (ME) OS found in Intel's Platform Controller Hub, starting with the introduction of ME 11, which is used with Skylake and Kaby Lake processors. It was debated that Minix could have been the most widely used OS on x86/AMD64 processors, with more installations than Microsoft Windows, Linux, or macOS, because of its use in the Intel ME.","Minix 3 is a small, Unix-like operating system. It is published under a BSD-3-Clause license and is a successor project to the earlier versions, Minix 1 and 2.The project's main goal is for the system to be fault-tolerant by detecting and repairing its faults on the fly, with no user intervention. The main uses of the system are envisaged to be embedded systems and education.As of 2017, Minix 3 supports IA-32 and ARM architecture processors. It can also run on emulators or virtual machines, such as Bochs, VMware Workstation, Microsoft Virtual PC, Oracle VirtualBox, and QEMU. A port to PowerPC architecture is in development. The distribution comes on a live CD and does not support live USB installation. The project has been dormant since 2018, and the latest release is 3.4.0 rc6 from 2017, although the Minix 3 discussion group is still active.Minix 3 is believed to have inspired the Intel Management Engine (ME) OS found in Intel's Platform Controller Hub, starting with the introduction of ME 11, which is used with Skylake and Kaby Lake processors. It was debated that Minix could have been the most widely used OS on x86/AMD64 processors, with more installations than Microsoft Windows, Linux, or macOS, because of its use in the Intel ME.

Goals of the project
Reflecting on the nature of monolithic kernel based systems, where a driver (which has, according to Minix creator Tanenbaum, approximately 3–7 times as many bugs as a usual program) can bring down the whole system, Minix 3 aims to create an operating system that is a ""reliable, self-healing, multiserver Unix clone"".To achieve that, the code running in kernel must be minimal, with the file server, process server, and each device driver running as separate user-mode processes. Each driver is carefully monitored by a part of the system named the reincarnation server. If a driver fails to respond to pings from this server, it is shut down and replaced by a fresh copy of the driver.
In a monolithic system, a bug in a driver can easily crash the whole kernel. This is far less likely to occur in Minix 3.

History
Minix 3 was publicly announced on 24 October 2005 by Andrew Tanenbaum during his keynote speech on top of the Association for Computing Machinery (ACM) Symposium Operating Systems Principles conference. Although it still serves as an example for the new edition of Tanenbaum and Woodhull's textbook, it is comprehensively redesigned to be ""usable as a serious system on resource-limited and embedded computers and for applications requiring high reliability.""
Initially released under the same BSD-3-Clause license that Minix was licensed under since 2000. In late 2005, the copyright owner was changed and a fourth clause was added.

Reliability policies
One of the main goals of Minix 3 is reliability. Below, some of the more important principles that enhance its reliability are discussed.

Reduce kernel size
Monolithic operating systems such as Linux and FreeBSD and hybrids like Windows have millions of lines of kernel code. In contrast, Minix 3 has about 6,000 lines of executable kernel code, which can make problems easier to find in the code.

Cage the bugs
In monolithic kernels, device drivers reside in the kernel. Thus, when a new peripheral is installed, unknown, untrusted code is inserted in the kernel. One bad line of code in a driver can bring down the system.
Instead, in Minix 3, each device driver is a separate user-mode process. Drivers cannot execute privileged instructions, change the page tables, perform arbitrary input/output (I/O), or write to absolute memory. They must make kernel calls for these services and the kernel checks each call for authority.

Limit drivers' memory access
In monolithic kernels, a driver can write to any word of memory and thus accidentally corrupt user programs.
In Minix 3, when a user expects data from, for example, the file system, it builds a descriptor telling who has access and at what addresses. It then passes an index to this descriptor to the file system, which may pass it to a driver. The file system or driver then asks the kernel to write via the descriptor, making it impossible for them to write to addresses outside the buffer.

Survive bad pointers
Dereferencing a bad pointer within a driver will crash the driver process, but will have no effect on the system as a whole. The reincarnation server will restart the crashed driver automatically. Users will not notice recovery for some drivers (e.g., disk and network) but for others (e.g., audio and printer), they might. In monolithic kernels, dereferencing a bad pointer in a driver normally leads to a system crash.

Tame infinite loops
If a driver gets into an infinite loop, the scheduler will gradually lower its priority until it becomes idle. Eventually the reincarnation server will see that it is not responding to status requests, so it will kill and restart the looping driver. In a monolithic kernel, a looping driver could hang the system.

Limit damage from buffer overflows
Minix 3 uses fixed-length messages for internal communication, which eliminates certain buffer overflows and buffer management problems. Also, many exploits work by overrunning a buffer to trick the program into returning from a function call using an overwritten stack return address pointing into attacker controlled memory, usually the overrun buffer. In Minix 3, this attack is mitigated because instruction and data space are split and only code in (read-only) instruction space can be executed, termed executable space protection. However, attacks which rely on running legitimately executable memory in a malicious way (return-to-libc, return-oriented programming) are not prevented by this mitigation.

Restrict access to kernel functions
Device drivers obtain kernel services (such as copying data to users' address spaces) by making kernel calls. The Minix 3 kernel has a bit map for each driver specifying which calls it is authorized to make. In monolithic kernels, every driver can call every kernel function, authorized or not.

Restrict access to I/O ports
The kernel also maintains a table telling which I/O ports each driver may access. Thus, a driver can only touch its own I/O ports. In monolithic kernels, a buggy driver can access I/O ports belonging to another device.

Restrict communication with OS components
Not every driver and server needs to communicate with every other driver and server. Accordingly, a per-process bit map determines which destinations each process may send to.

Reincarnate dead or sick drivers
A special process, called the reincarnation server, periodically pings each device driver. If the driver dies or fails to respond correctly to pings, the reincarnation server automatically replaces it with a fresh copy. Detecting and replacing non-functioning drivers is automatic, with no user action needed. This feature does not work for disk drivers at present, but in the next release the system will be able to recover even disk drivers, which will be shadowed in random-access memory (RAM). Driver recovery does not affect running processes.

Integrate interrupts and messages
When an interrupt occurs, it is converted at a low level to a notification sent to the appropriate driver. If the driver is waiting for a message, it gets the interrupt immediately; otherwise it gets the notification the next time it does a RECEIVE to get a message. This scheme eliminates nested interrupts and makes driver programming easier.

Architecture
As can be seen, at the bottom level is the microkernel, which is about 4,000 lines of code (mostly in C, plus a small amount of assembly language). It handles interrupts, scheduling, and message passing. It also supports an application programming interface (API) of about 30 kernel calls that authorized servers and drivers can make. User programs cannot make these calls. Instead, they can issue POSIX system calls which send messages to the servers. The kernel calls perform functions such as setting interrupts and copying data between address spaces.
At the next level up, there are the device drivers, each one running as a separate userland process. Each one controls some I/O device, such as a disk or printer. The drivers do not have access to the I/O port space and cannot issue I/O instructions directly. Instead, they must make kernel calls giving a list of I/O ports to write to and the values to be written. While there is a small amount of overhead in doing this (typically 500 ns), this scheme makes it possible for the kernel to check authorization, so that, for example, the audio driver cannot write on the disk.
At the next level there are the servers. This is where nearly all the operating system functionality is located. User processes obtain file service, for example, by sending messages to the file server to open, close, read, and write files. In turn, the file server gets disk I/O performed by sending messages to the disk driver, which controls the disk.
One of the key servers is the reincarnation server. Its job is to poll all the other servers and drivers to check on their health periodically. If a component fails to respond correctly, or exits, or gets into an infinite loop, the reincarnation server (which is the parent process of the drivers and servers) kills the faulty component and replaces it with a fresh copy. In this way the system is automatically made self-healing without interfering with running programs.
Currently the reincarnation server, the process server, and the microkernel are part of the trusted computing base.  If any of them fail, the system crashes. Nevertheless, reducing the trusted computing base from 3-5 million lines of code, as in Linux and Windows systems, to about 20,000 lines greatly enhances system reliability.

Differences between Minix 3 and prior versions
Minix 1.0, 1.5, and 2.0 were developed as tools to help people learn about the design of operating systems.
Minix 1.0, released in 1987, was 12,000 lines of C and some x86 assembly language. Source code of the kernel, memory manager, and file system of Minix 1.0 are printed in the book. Tanenbaum originally developed Minix for compatibility with the IBM PC and IBM PC/AT microcomputers available at the time.
Minix 1.5, released in 1991, included support for MicroChannel IBM PS/2 systems and was also ported to the Motorola 68000 and SPARC architectures, supporting the Atari ST, Commodore Amiga, Apple Macintosh and Sun Microsystems SPARCstation computer platforms. A version of Minix running as a user process under SunOS was also available.
Minix 2.0, released in 1997, was only available for the x86 and Solaris-hosted SPARC architectures. Minix-vmd was created by two Vrije Universiteit researchers, and added virtual memory and support for the X Window System.
Minix 3 does the same, and provides a modern operating system with many newer tools and many Unix applications. Prof. Tanenbaum once said:

Please be aware that MINIX 3 is not your grandfather's MINIX ... MINIX 1 was written as an educational tool ... MINIX 3 is that plus a start at building a highly reliable, self-healing, bloat-free operating system ... MINIX 1 and MINIX 3 are related in the same way as Windows 3.1 and Windows XP are: same first name.
Many improvements have also been made in the structure of the kernel since the Minix 2 release, making the system more reliable. Minix version 3.1.5 was released 5 Nov 2009. It contains X11, Emacs, vi, cc, GCC, Perl, Python, Almquist shell, Bash, Z shell, FTP client, SSH client, Telnet client, Pine, and over 400 other common Unix utility programs. With the addition of X11, this version marks the transition away from a text-only system.  Another feature of this version, which will be improved in future ones, is the ability of the system to withstand device driver crashes, and in many cases having them automatically replaced without affecting running processes. In this way, Minix is self-healing and can be used in applications demanding high reliability.
Minix 3.2.0 was released in February 2012. This version has many new features, including the Clang compiler, experimental symmetric multiprocessing support, procfs and ext2fs filesystem support, and GNU Debugger (GDB). Several parts of NetBSD are also integrated in the release, including the bootloader, libc and various utilities and other libraries.Minix 3.3.0 was released in September 2014. This release is the first version to support the ARM architecture in addition to x86. It also supports a NetBSD userland, with thousands of NetBSD packages running right out of the box.

Mascot
Rocky Raccoon is the mascot of Minix 3.

MINIXCon
MINIXCon is a conference on sharing talks, efforts and researches related to Minix.
It was held once in 2016. MINIXCon2017 was cancelled due to lack of talks submitted.

See also
MINIX file system
Xinu
xv6
Comparison of operating system kernels
List of computing mascots
Category:Computing mascots

Notes
References
Further reading
External links

Official website
Stichting-MINIX-Research-Foundation on GitHub",5574880,https://en.wikipedia.org/wiki/Minix_3
Python (programming language),"Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a ""batteries included"" language due to its comprehensive standard library.Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0. Python 2.0 was released in 2000. Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python 2.7.18, released in 2020, was the last release of Python 2.Python consistently ranks as one of the most popular programming languages, and has gained widespread use in the machine learning community.","Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a ""batteries included"" language due to its comprehensive standard library.Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0. Python 2.0 was released in 2000. Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python 2.7.18, released in 2020, was the last release of Python 2.Python consistently ranks as one of the most popular programming languages, and has gained widespread use in the machine learning community.

History
Python was conceived in the late 1980s by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC programming language, which was inspired by SETL, capable of exception handling and interfacing with the Amoeba operating system. Its implementation began in December 1989. Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his ""permanent vacation"" from his responsibilities as Python's ""benevolent dictator for life"", a title the Python community bestowed upon him to reflect his long-term commitment as the project's chief decision-maker. In January 2019, active Python core developers elected a five-member Steering Council to lead the project.Python 2.0 was released on 16 October 2000, with many major new features such as list comprehensions, cycle-detecting garbage collection, reference counting, and Unicode support. Python 3.0, released on 3 December 2008, with many of its major features backported to Python 2.6.x and 2.7.x. Releases of Python 3 include the 2to3 utility, which automates the translation of Python 2 code to Python 3.Python 2.7's end-of-life was initially set for 2015, then postponed to 2020 out of concern that a large body of existing code could not easily be forward-ported to Python 3. No further security patches or other improvements will be released for it. Currently only 3.8 and later are supported (2023 security issues were fixed in e.g. 3.7.17, the final 3.7.x release). While Python 2.7 and older is officially unsupported, a different unofficial Python implementation, PyPy, continues to support Python 2, i.e. ""2.7.18+"" (plus 3.9 and 3.10), with the plus meaning (at least some) ""backported security updates"".In 2021 (and again twice in 2022), security updates were expedited, since all Python versions were insecure (including 2.7) because of security issues leading to possible remote code execution and web-cache poisoning. In 2022, Python 3.10.4 and 3.9.12 were expedited and 3.8.13, because of many security issues. When Python 3.9.13 was released in May 2022, it was announced that the 3.9 series (joining the older series 3.8 and 3.7) would only receive security fixes in the future. On 7 September 2022, four new releases were made due to a potential denial-of-service attack: 3.10.7, 3.9.14, 3.8.14, and 3.7.14.As of October 2023, Python 3.12 is the stable release, and 3.12 and 3.11 are the only versions with active (as opposed to just security) support. Notable changes in 3.11 from 3.10 include increased program execution speed and improved error reporting.Python 3.12 adds syntax (and in fact every Python since at least 3.5 adds some syntax) to the language, the new (soft) keyword type (recent releases have added a lot of typing support e.g. new type union operator in 3.10), and 3.11 for exception handling, and 3.10 the match and case (soft) keywords, for structural pattern matching statements. Python 3.12 also drops outdated modules and functionality, and future versions will too, see below in Development section.
Python 3.11 claims to be between 10 and 60% faster than Python 3.10, and Python 3.12 adds another 5% on top of that. It also has improved error messages, and many other changes.
Since 27 June 2023, Python 3.8 is the oldest supported version of Python (albeit in the 'security support' phase), due to Python 3.7 reaching end-of-life.

Design philosophy and features
Python is a multi-paradigm programming language. Object-oriented programming and structured programming are fully supported, and many of their features support functional programming and aspect-oriented programming (including metaprogramming and metaobjects). Many other paradigms are supported via extensions, including design by contract and logic programming.Python uses dynamic typing and a combination of reference counting and a cycle-detecting garbage collector for memory management. It uses dynamic name resolution (late binding), which binds method and variable names during program execution.
Its design offers some support for functional programming in the Lisp tradition. It has filter,mapandreduce functions; list comprehensions, dictionaries, sets, and generator expressions. The standard library has two modules (itertools and functools) that implement functional tools borrowed from Haskell and Standard ML.Its core philosophy is summarized in the Zen of Python (PEP 20), which includes aphorisms such as:
Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Readability counts.However, Python features regularly violate these principles and received criticism for adding unnecessary language bloat. Responses to these criticisms are that the Zen of Python is a guideline rather than a rule. The addition of some new features had been so controversial that Guido van Rossum resigned as Benevolent Dictator for Life following vitriol over the addition of the assignment expression operator in Python 3.8.Nevertheless, rather than building all of its functionality into its core, Python was designed to be highly extensible via modules. This compact modularity has made it particularly popular as a means of adding programmable interfaces to existing applications. Van Rossum's vision of a small core language with a large standard library and easily extensible interpreter stemmed from his frustrations with ABC, which espoused the opposite approach.Python claims to strive for a simpler, less-cluttered syntax and grammar while giving developers a choice in their coding methodology. In contrast to Perl's ""there is more than one way to do it"" motto, Python embraces a ""there should be one—and preferably only one—obvious way to do it.""  philosophy. In practice, however, Python provides many ways to achieve the same task. There are, for example, at least three ways to format a string literal, with no certainty as to which one a programmer should use. Alex Martelli, a Fellow at the Python Software Foundation and Python book author, wrote: ""To describe something as 'clever' is not considered a compliment in the Python culture.""Python's developers usually strive to avoid premature optimization and reject patches to non-critical parts of the CPython reference implementation that would offer marginal increases in speed at the cost of clarity. Execution speed can be improved by moving speed-critical functions to extension modules written in languages such as C, or by using a just-in-time compiler like PyPy. It is also possible to cross-compile to other languages, but it either doesn't provide the full speed-up that might be expected, since Python is a very dynamic language, or a restricted subset of Python is compiled, and possibly semantics are slightly changed.Python's developers aim for it to be fun to use. This is reflected in its name—a tribute to the British comedy group Monty Python—and in occasionally playful approaches to tutorials and reference materials, such as the use of the terms ""spam"" and ""eggs"" (a reference to a Monty Python sketch) in examples, instead of the often-used ""foo"" and ""bar"".A common neologism in the Python community is pythonic, which has a wide range of meanings related to program style. ""Pythonic"" code may use Python idioms well, be natural or show fluency in the language, or conform with Python's minimalist philosophy and emphasis on readability. Code that is difficult to understand or reads like a rough transcription from another programming language is called unpythonic.

Syntax and semantics
Python is meant to be an easily readable language. Its formatting is visually uncluttered and often uses English keywords where other languages use punctuation. Unlike many other languages, it does not use curly brackets to delimit blocks, and semicolons after statements are allowed but rarely used. It has fewer syntactic exceptions and special cases than C or Pascal.

Indentation
Python uses whitespace indentation, rather than curly brackets or keywords, to delimit blocks. An increase in indentation comes after certain statements; a decrease in indentation signifies the end of the current block. Thus, the program's visual structure accurately represents its semantic structure. This feature is sometimes termed the off-side rule. Some other languages use indentation this way; but in most, indentation has no semantic meaning. The recommended indent size is four spaces.

Statements and control flow
Python's statements include:

The assignment statement, using a single equals sign =
The if statement, which conditionally executes a block of code, along with else and elif (a contraction of else-if)
The for statement, which iterates over an iterable object, capturing each element to a local variable for use by the attached block
The while statement, which executes a block of code as long as its condition is true
The try statement, which allows exceptions raised in its attached code block to be caught and handled by except clauses (or new syntax except* in Python 3.11 for exception groups); it also ensures that clean-up code in a finally block is always run regardless of how the block exits
The raise statement, used to raise a specified exception or re-raise a caught exception
The class statement, which executes a block of code and attaches its local namespace to a class, for use in object-oriented programming
The def statement, which defines a function or method
The with statement, which encloses a code block within a context manager (for example, acquiring a lock before it is run, then releasing the lock; or opening and closing a file), allowing resource-acquisition-is-initialization (RAII)-like behavior and replacing a common try/finally idiom
The break statement, which exits a loop
The continue statement, which skips the rest of the current iteration and continues with the next
The del statement, which removes a variable—deleting the reference from the name to the value, and producing an error if the variable is referred to before it is redefined
The pass statement, serving as a NOP, syntactically needed to create an empty code block
The assert statement, used in debugging to check for conditions that should apply
The yield statement, which returns a value from a generator function (and also an operator); used to implement coroutines
The return statement, used to return a value from a function
The import and from statements, used to import modules whose functions or variables can be used in the current programThe assignment statement (=) binds a name as a reference to a separate, dynamically allocated object. Variables may subsequently be rebound at any time to any object. In Python, a variable name is a generic reference holder without a fixed data type; however, it always refers to some object with a type. This is called dynamic typing—in contrast to statically-typed languages, where each variable may contain only a value of a certain type.
Python does not support tail call optimization or first-class continuations, and, according to Van Rossum, it never will. However, better support for coroutine-like functionality is provided by extending Python's generators. Before 2.5, generators were lazy iterators; data was passed unidirectionally out of the generator. From Python 2.5 on, it is possible to pass data back into a generator function; and from version 3.3, it can be passed through multiple stack levels.

Expressions
Python's expressions include:

The +, -, and * operators for mathematical addition, subtraction, and multiplication are similar to other languages, but the behavior of division differs. There are two types of divisions in Python: floor division (or integer division) // and floating-point/division. Python uses the ** operator for exponentiation.
Python uses the + operator for string concatenation. Python uses the * operator for duplicating a string a specified number of times.
The @ infix operator. It is intended to be used by libraries such as NumPy for matrix multiplication.
The syntax :=, called the ""walrus operator"", was introduced in Python 3.8. It assigns values to variables as part of a larger expression.
In Python, == compares by value. Python's is operator may be used to compare object identities (comparison by reference), and comparisons may be chained—for example, a <= b <= c.
Python uses and, or, and not as Boolean operators.
Python has a type of expression called a list comprehension, as well as a more general expression called a generator expression.
Anonymous functions are implemented using lambda expressions; however, there may be only one expression in each body.
Conditional expressions are written as x if c else y (different in order of operands from the c ? x : y operator common to many other languages).
Python makes a distinction between lists and tuples. Lists are written as [1, 2, 3], are mutable, and cannot be used as the keys of dictionaries (dictionary keys must be immutable in Python). Tuples, written as (1, 2, 3), are immutable and thus can be used as keys of dictionaries, provided all of the tuple's elements are immutable. The + operator can be used to concatenate two tuples, which does not directly modify their contents, but produces a new tuple containing the elements of both. Thus, given the variable t initially equal to (1, 2, 3), executing t = t + (4, 5) first evaluates t + (4, 5), which yields (1, 2, 3, 4, 5), which is then assigned back to t—thereby effectively ""modifying the contents"" of t while conforming to the immutable nature of tuple objects. Parentheses are optional for tuples in unambiguous contexts.
Python features sequence unpacking where multiple expressions, each evaluating to anything that can be assigned (to a variable, writable property, etc.) are associated in an identical manner to that forming tuple literals—and, as a whole, are put on the left-hand side of the equal sign in an assignment statement. The statement expects an iterable object on the right-hand side of the equal sign that produces the same number of values as the provided writable expressions; when iterated through them, it assigns each of the produced values to the corresponding expression on the left.
Python has a ""string format"" operator % that functions analogously to printf format strings in C—e.g. ""spam=%s eggs=%d"" % (""blah"", 2) evaluates to ""spam=blah eggs=2"". In Python 2.6+ and 3+, this was supplemented by the format() method of the str class, e.g. ""spam={0} eggs={1}"".format(""blah"", 2). Python 3.6 added ""f-strings"": spam = ""blah""; eggs = 2; f'spam={spam} eggs={eggs}'.
Strings in Python can be concatenated by ""adding"" them (with the same operator as for adding integers and floats), e.g. ""spam"" + ""eggs"" returns ""spameggs"". If strings contain numbers, they are added as strings rather than integers, e.g. ""2"" + ""2"" returns ""22"".
Python has various string literals:
Delimited by single or double quotes; unlike in Unix shells, Perl, and Perl-influenced languages, single and double quotes work the same. Both use the backslash (\) as an escape character. String interpolation became available in Python 3.6 as ""formatted string literals"".
Triple-quoted (beginning and ending with three single or double quotes), which may span multiple lines and function like here documents in shells, Perl, and Ruby.
Raw string varieties, denoted by prefixing the string literal with r. Escape sequences are not interpreted; hence raw strings are useful where literal backslashes are common, such as regular expressions and Windows-style paths. (Compare ""@-quoting"" in C#.)
Python has array index and array slicing expressions in lists, denoted as a[key], a[start:stop] or a[start:stop:step]. Indexes are zero-based, and negative indexes are relative to the end. Slices take elements from the start index up to, but not including, the stop index. The third slice parameter called step or stride, allows elements to be skipped and reversed. Slice indexes may be omitted—for example, a[:] returns a copy of the entire list. Each element of a slice is a shallow copy.In Python, a distinction between expressions and statements is rigidly enforced, in contrast to languages such as Common Lisp, Scheme, or Ruby. This leads to duplicating some functionality. For example:

List comprehensions vs. for-loops
Conditional expressions vs. if blocks
The eval() vs. exec() built-in functions (in Python 2, exec is a statement); the former is for expressions, the latter is for statementsStatements cannot be a part of an expression—so list and other comprehensions or lambda expressions, all being expressions, cannot contain statements. A particular case is that an assignment statement such as a = 1 cannot form part of the conditional expression of a conditional statement. This has the advantage of avoiding a classic C error of mistaking an assignment operator = for an equality operator == in conditions: if (c = 1) { ... } is syntactically valid (but probably unintended) C code, but if c = 1: ... causes a syntax error in Python.

Methods
Methods on objects are functions attached to the object's class; the syntax instance.method(argument) is, for normal methods and functions, syntactic sugar for Class.method(instance, argument). Python methods have an explicit self parameter to access instance data, in contrast to the implicit self (or this) in some other object-oriented programming languages (e.g., C++, Java, Objective-C, Ruby). Python also provides methods, often called dunder methods (due to their names beginning and ending with double-underscores), to allow user-defined classes to modify how they are handled by native operations including length, comparison, in arithmetic operations and type conversion.

Typing
Python uses duck typing and has typed objects but untyped variable names. Type constraints are not checked at compile time; rather, operations on an object may fail, signifying that it is not of a suitable type. Despite being dynamically typed, Python is strongly typed, forbidding operations that are not well-defined (for example, adding a number to a string) rather than silently attempting to make sense of them.
Python allows programmers to define their own types using classes, most often used for object-oriented programming. New instances of classes are constructed by calling the class (for example, SpamClass() or EggsClass()), and the classes are instances of the metaclass type (itself an instance of itself), allowing metaprogramming and reflection.
Before version 3.0, Python had two kinds of classes (both using the same syntax): old-style and new-style, current Python versions only support the semantics new style.
Python supports optional type annotations. These annotations are not enforced by the language, but may be used by external tools such as mypy to catch errors. Mypy also supports a Python compiler called mypyc, which leverages type annotations for optimization.

Arithmetic operations
Python has the usual symbols for arithmetic operators (+, -, *, /), the floor division operator // and the modulo operation % (where the remainder can be negative,  e.g. 4 % -3 == -2). It also has ** for exponentiation, e.g. 5**3 == 125 and 9**0.5 == 3.0, and a matrix‑multiplication operator @ . These operators work like in traditional math; with the same precedence rules, the operators infix (+ and - can also be unary to represent positive and negative numbers respectively).
The division between integers produces floating-point results. The behavior of division has changed significantly over time:
Current Python (i.e. since 3.0) changed / to always be floating-point division, e.g. 5/2 == 2.5.
The floor division // operator was introduced. So 7//3 == 2, -7//3 == -3, 7.5//3 == 2.0 and -7.5//3 == -3.0. Adding from __future__ import division causes a module used in Python 2.7 to use Python 3.0 rules for division (see above).In Python terms, / is true division (or simply division), and // is floor division. / before version 3.0 is classic division.Rounding towards negative infinity, though different from most languages, adds consistency. For instance, it means that the equation (a + b)//b == a//b + 1 is always true. It also means that the equation b*(a//b) + a%b == a is valid for both positive and negative values of a. However, maintaining the validity of this equation means that while the result of a%b is, as expected, in the half-open interval [0, b), where b is a positive integer, it has to lie in the interval (b, 0] when b is negative.Python provides a round function for rounding a float to the nearest integer. For tie-breaking, Python 3 uses round to even: round(1.5) and round(2.5) both produce 2. Versions before 3 used round-away-from-zero: round(0.5) is 1.0, round(-0.5) is −1.0.Python allows Boolean expressions with multiple equality relations in a manner that is consistent with general use in mathematics. For example, the expression a < b < c tests whether a is less than b and b is less than c. C-derived languages interpret this expression differently: in C, the expression would first evaluate a < b, resulting in 0 or 1, and that result would then be compared with c.Python uses arbitrary-precision arithmetic for all integer operations. The Decimal type/class in the decimal module provides decimal floating-point numbers to a pre-defined arbitrary precision and several rounding modes. The Fraction class in the fractions module provides arbitrary precision for rational numbers.Due to Python's extensive mathematics library, and the third-party library NumPy that further extends the native capabilities, it is frequently used as a scientific scripting language to aid in problems such as numerical data processing and manipulation.

Programming examples
""Hello, World!"" program:

Program to calculate the factorial of a positive integer:

Libraries
Python's large standard library provides tools suited to many tasks and is commonly cited as one of its greatest strengths. For Internet-facing applications, many standard formats and protocols such as MIME and HTTP are supported. It includes modules for creating graphical user interfaces, connecting to relational databases, generating pseudorandom numbers, arithmetic with arbitrary-precision decimals, manipulating regular expressions, and unit testing.
Some parts of the standard library are covered by specifications—for example, the Web Server Gateway Interface (WSGI) implementation wsgiref follows PEP 333—but most are specified by their code, internal documentation, and test suites. However, because most of the standard library is cross-platform Python code, only a few modules need altering or rewriting for variant implementations.
As of 17 March 2024, the Python Package Index (PyPI), the official repository for third-party Python software, contains over 523,000 packages with a wide range of functionality, including:

Development environments
Most Python implementations (including CPython) include a read–eval–print loop (REPL), permitting them to function as a command line interpreter for which users enter statements sequentially and receive results immediately.
Python also comes with an Integrated development environment (IDE) called IDLE, which is more beginner-oriented.
Other shells, including IDLE and IPython, add further abilities such as improved auto-completion, session state retention, and syntax highlighting.
As well as standard desktop integrated development environments including PyCharm, IntelliJ Idea, Visual Studio Code etc, there are web browser-based IDEs, including SageMath, for developing science- and math-related programs; PythonAnywhere, a browser-based IDE and hosting environment; and Canopy IDE, a commercial IDE emphasizing scientific computing.

Implementations
Reference implementation
CPython is the reference implementation of Python. It is written in C, meeting the C89 standard (Python 3.11 uses C11) with several select C99 features. CPython includes its own C extensions, but third-party extensions are not limited to older C versions—e.g. they can be implemented with C11 or C++.) It compiles Python programs into an intermediate bytecode which is then executed by its virtual machine. CPython is distributed with a large standard library written in a mixture of C and native Python, and is available for many platforms, including Windows (starting with Python 3.9, the Python installer deliberately fails to install on Windows 7 and 8; Windows XP was supported until Python 3.5) and most modern Unix-like systems, including macOS (and Apple M1 Macs, since Python 3.9.1, with experimental installer) and unofficial support for e.g. VMS. Platform portability was one of its earliest priorities. (During Python 1 and 2 development, even OS/2 and Solaris were supported, but support has since been dropped for many platforms.)

Other implementations
PyPy is a fast, compliant interpreter of Python 2.7 and 3.8. Its just-in-time compiler often brings a significant speed improvement over CPython but some libraries written in C cannot be used with it.
Stackless Python is a significant fork of CPython that implements microthreads; it does not use the call stack in the same way, thus allowing massively concurrent programs. PyPy also has a stackless version.
MicroPython and CircuitPython are Python 3 variants optimized for microcontrollers, including Lego Mindstorms EV3.
Pyston is a variant of the Python runtime that uses just-in-time compilation to speed up the execution of Python programs.
Cinder is a performance-oriented fork of CPython 3.8 that contains a number of optimizations, including bytecode inline caching, eager evaluation of coroutines, a method-at-a-time JIT, and an experimental bytecode compiler.
Snek Embedded Computing Language (supporting e.g. 8-bit AVR microcontrollers such as ATmega 328P-based Arduino, and larger ones that are MicroPython can also support) ""is Python-inspired, but it is not Python. It is possible to write Snek programs that run under a full Python system, but most Python programs will not run under Snek."" It's an imperative language not including OOP/classes unlike Python, and simplifying to one number type (like JavaScript, except using smaller) 32-bit single-precision ""Integer values of less than 24 bits can be represented exactly in these floating point values"".

Unsupported implementations
Other just-in-time Python compilers have been developed, but are now unsupported:

Google began a project named Unladen Swallow in 2009, with the aim of speeding up the Python interpreter fivefold by using the LLVM, and of improving its multithreading ability to scale to thousands of cores, while ordinary implementations suffer from the global interpreter lock.
Psyco is a discontinued just-in-time specializing compiler that integrates with CPython and transforms bytecode to machine code at runtime. The emitted code is specialized for certain data types and is faster than the standard Python code. Psyco does not support Python 2.7 or later.
PyS60 was a Python 2 interpreter for Series 60 mobile phones released by Nokia in 2005. It implemented many of the modules from the standard library and some additional modules for integrating with the Symbian operating system. The Nokia N900 also supports Python with GTK widget libraries, enabling programs to be written and run on the target device.

Cross-compilers to other languages
There are several compilers/transpilers to high-level object languages, with either unrestricted Python, a restricted subset of Python, or a language similar to Python as the source language:

Brython, Transcrypt and Pyjs (latest release in 2012) compile Python to JavaScript.
Codon compiles a subset of statically typed Python to machine code (via LLVM) and supports native multithreading.
Cython compiles (a superset of) Python  to C. The resulting code is also usable with Python via direct C-level API calls into the Python interpreter.
PyJL compiles/transpiles a subset of Python to ""human-readable, maintainable, and high-performance Julia source code"". Despite claiming high performance, no tool can claim to do that for arbitrary Python code; i.e. it's known not possible to compile to a faster language or machine code. Unless semantics of Python are changed, but in many cases speedup is possible with few or no changes in the Python code. The faster Julia source code can then be used from Python, or compiled to machine code, and based that way.
Nuitka compiles Python into C.
Numba uses LLVM to compile a subset of Python to machine code.
Pythran compiles a subset of Python 3 to C++ (C++11).
RPython can be compiled to C, and is used to build the PyPy interpreter of Python.
The Python → 11l → C++ transpiler compiles a subset of Python 3 to C++ (C++17).Specialized:

MyHDL is a Python-based hardware description language (HDL), that converts MyHDL code to Verilog or VHDL code.Older projects (or not to be used with Python 3.x and latest syntax):

Google's Grumpy (latest release in 2017) transpiles Python 2 to Go.
IronPython  allows running Python 2.7 programs (and an alpha, released in 2021, is also available for ""Python 3.4, although features and behaviors from later versions may be included"") on the .NET Common Language Runtime.
Jython compiles Python 2.7 to Java bytecode, allowing the use of the Java libraries from a Python program.
Pyrex (latest release in 2010) and Shed Skin (latest release in 2013) compile to C and C++ respectively.

Performance
Performance comparison of various Python implementations on a non-numerical (combinatorial) workload was presented at EuroSciPy '13. Python's performance compared to other programming languages is also benchmarked by The Computer Language Benchmarks Game.

Development
Python's development is conducted largely through the Python Enhancement Proposal (PEP) process, the primary mechanism for proposing major new features, collecting community input on issues, and documenting Python design decisions. Python coding style is covered in PEP 8. Outstanding PEPs are reviewed and commented on by the Python community and the steering council.Enhancement of the language corresponds with the development of the CPython reference implementation. The mailing list python-dev is the primary forum for the language's development. Specific issues were originally discussed in the Roundup bug tracker hosted at by the foundation. In 2022, all issues and discussions were migrated to GitHub. Development originally took place on a self-hosted source-code repository running Mercurial, until Python moved to GitHub in January 2017.CPython's public releases come in three types, distinguished by which part of the version number is incremented:

Backward-incompatible versions, where code is expected to break and needs to be manually ported. The first part of the version number is incremented. These releases happen infrequently—version 3.0 was released 8 years after 2.0. According to Guido van Rossum, a version 4.0 is very unlikely to ever happen.
Major or ""feature"" releases are largely compatible with the previous version but introduce new features. The second part of the version number is incremented. Starting with Python 3.9, these releases are expected to happen annually. Each major version is supported by bug fixes for several years after its release.
Bugfix releases, which introduce no new features, occur about every 3 months and are made when a sufficient number of bugs have been fixed upstream since the last release. Security vulnerabilities are also patched in these releases. The third and final part of the version number is incremented.Many alpha, beta, and release-candidates are also released as previews and for testing before final releases. Although there is a rough schedule for each release, they are often delayed if the code is not ready. Python's development team monitors the state of the code by running the large unit test suite during development.The major academic conference on Python is PyCon. There are also special Python mentoring programs, such as PyLadies.
Python 3.12 removed wstr meaning Python extensions need to be modified, and 3.10 added pattern matching to the language.Python 3.12 dropped some outdated modules, and more will be dropped in the future, deprecated as of 3.13; already deprecated array 'u' format code will emit DeprecationWarning since 3.13 and will be removed in Python 3.16. The 'w' format code should be used instead. Part of ctypes is also deprecated and http.server.CGIHTTPRequestHandler will emit a DeprecationWarning, and will be removed in 3.15. Using that code already has a high potential for both security and functionality bugs. Parts of the typing module are deprecated, e.g. creating a typing.NamedTuple class using keyword arguments to denote the fields and such (and more) will be disallowed in Python 3.15.

API documentation generators
Tools that can generate documentation for Python API include pydoc (available as part of the standard library), Sphinx, Pdoc and its forks, Doxygen and Graphviz, among others.

Naming
Python's name is derived from the British comedy group Monty Python, whom Python creator Guido van Rossum enjoyed while developing the language. Monty Python references appear frequently in Python code and culture; for example, the metasyntactic variables often used in Python literature are spam and eggs instead of the traditional foo and bar. The official Python documentation also contains various references to Monty Python routines. Users of Python are sometimes referred to as ""Pythonistas"".The prefix Py- is used to show that something is related to Python. Examples of the use of this prefix in names of Python applications or libraries include Pygame, a binding of SDL to Python (commonly used to create games); PyQt and PyGTK, which bind Qt and GTK to Python respectively; and PyPy, a Python implementation originally written in Python.

Popularity
Since 2003, Python has consistently ranked in the top ten most popular programming languages in the TIOBE Programming Community Index where as of December 2022 it was the most popular language (ahead of C, C++, and Java). It was selected Programming Language of the Year (for ""the highest rise in ratings in a year"") in 2007, 2010, 2018, and 2020 (the only language to have done so four times as of 2020).
An empirical study found that scripting languages, such as Python, are more productive than conventional languages, such as C and Java, for programming problems involving string manipulation and search in a dictionary, and determined that memory consumption was often ""better than Java and not much worse than C or C++"".Large organizations that use Python include Wikipedia, Google, Yahoo!, CERN, NASA, Facebook, Amazon, Instagram, Spotify, and some smaller entities like ILM and ITA. The social news networking site Reddit was written mostly in Python.

Uses
Python can serve as a scripting language for web applications, e.g. via mod_wsgi for the Apache webserver. With Web Server Gateway Interface, a standard API has evolved to facilitate these applications. Web frameworks like Django, Pylons, Pyramid, TurboGears, web2py, Tornado, Flask, Bottle, and Zope support developers in the design and maintenance of complex applications. Pyjs and IronPython can be used to develop the client-side of Ajax-based applications. SQLAlchemy can be used as a data mapper to a relational database. Twisted is a framework to program communications between computers, and is used (for example) by Dropbox.
Libraries such as NumPy, SciPy and Matplotlib allow the effective use of Python in scientific computing, with specialized libraries such as Biopython and Astropy providing domain-specific functionality. SageMath is a computer algebra system with a notebook interface programmable in Python: its library covers many aspects of mathematics, including algebra, combinatorics, numerical mathematics, number theory, and calculus. OpenCV has Python bindings with a rich set of features for computer vision and image processing.Python is commonly used in artificial intelligence projects and machine learning projects with the help of libraries like TensorFlow, Keras, Pytorch, scikit-learn and the Logic language ProbLog. As a scripting language with a modular architecture, simple syntax, and rich text processing tools, Python is often used for natural language processing.The combination of Python and Prolog has proved to be particularly useful for AI applications, with Prolog providing knowledge representation and reasoning capablities. The Janus system, in particular, exploits the similarites between these two languages,
in part because of their use of dynamic typing, and the simple recursive nature of their
data structures. Typical applications of this combination include  natural language processing, visual query
answering, geospatial reasoning, and handling of semantic web data.
The Natlog system, implemented in Python, uses Definite Clause Grammars (DCGs) as prompt generators for text-to-text generators like GPT3 and text-to-image generators like DALL-E or Stable Diffusion.Python can also be used for graphical user interface (GUI) by using libraries like Tkinter.Python can also be used to create games, with libraries such as Pygame, which can make 2D games.
Python has been successfully embedded in many software products as a scripting language, including in finite element method software such as Abaqus, 3D parametric modelers like FreeCAD, 3D animation packages such as 3ds Max, Blender, Cinema 4D, Lightwave, Houdini, Maya, modo, MotionBuilder, Softimage, the visual effects compositor Nuke, 2D imaging programs like GIMP, Inkscape, Scribus and Paint Shop Pro, and musical notation programs like scorewriter and capella. GNU Debugger uses Python as a pretty printer to show complex structures such as C++ containers. Esri promotes Python as the best choice for writing scripts in ArcGIS. It has also been used in several video games, and has been adopted as first of the three available programming languages in Google App Engine, the other two being Java and Go.Many operating systems include Python as a standard component. It ships with most Linux distributions, AmigaOS 4 (using Python 2.7), FreeBSD (as a package), NetBSD, and OpenBSD (as a package) and can be used from the command line (terminal). Many Linux distributions use installers written in Python: Ubuntu uses the Ubiquity installer, while Red Hat Linux and Fedora Linux use the Anaconda installer. Gentoo Linux uses Python in its package management system, Portage.
Python is used extensively in the information security industry, including in exploit development.Most of the Sugar software for the One Laptop per Child XO, developed at Sugar Labs as of 2008, is written in Python. The Raspberry Pi single-board computer project has adopted Python as its main user-programming language.
LibreOffice includes Python and intends to replace Java with Python. Its Python Scripting Provider is a core feature since Version 4.0 from 7 February 2013.

Languages influenced by Python
Python's design and philosophy have influenced many other programming languages:

Boo uses indentation, a similar syntax, and a similar object model.
Cobra uses indentation and a similar syntax, and its Acknowledgements document lists Python first among languages that influenced it.
CoffeeScript, a programming language that cross-compiles to JavaScript, has Python-inspired syntax.
ECMAScript/JavaScript borrowed iterators and generators from Python.
GDScript, a scripting language very similar to Python, built-in to the Godot game engine.
Go is designed for the ""speed of working in a dynamic language like Python"" and shares the same syntax for slicing arrays.
Groovy was motivated by the desire to bring the Python design philosophy to Java.
Julia was designed to be ""as usable for general programming as Python"".
Mojo is currently a non-strict (aims to be a strict) superset of Python (e.g. still missing classes, and adding e.g. struct), and is up to 35,000x faster for some code (mandelbrot, since it is embarrassingly parallel), where static typing helps (and MLIR it is implemented with), and, e.g. 4000 times faster for matrix multiplication.
Nim uses indentation and similar syntax.
Ruby's creator, Yukihiro Matsumoto, has said: ""I wanted a scripting language that was more powerful than Perl, and more object-oriented than Python. That's why I decided to design my own language.""
Swift, a programming language developed by Apple, has some Python-inspired syntax.Python's development practices have also been emulated by other languages. For example, the practice of requiring a document describing the rationale for, and issues surrounding, a change to the language (in Python, a PEP) is also used in Tcl, Erlang, and Swift.

See also
Python syntax and semantics
pip (package manager)
List of programming languages
History of programming languages
Comparison of programming languages

References
Sources
""Python for Artificial Intelligence"". Python Wiki. 19 July 2012. Archived from the original on 1 November 2012. Retrieved 3 December 2012.
Paine, Jocelyn, ed. (August 2005). ""AI in Python"". AI Expert Newsletter. Amzi!. Archived from the original on 26 March 2012. Retrieved 11 February 2012.
""PyAIML 0.8.5 : Python Package Index"". Pypi.python.org. Retrieved 17 July 2013.
Russell, Stuart J. & Norvig, Peter (2009). Artificial Intelligence: A Modern Approach (3rd ed.). Upper Saddle River, NJ: Prentice Hall. ISBN 978-0-13-604259-4.

Further reading
Downey, Allen B. (May 2012). Think Python: How to Think Like a Computer Scientist (version 1.6.6 ed.). Cambridge University Press. ISBN 978-0-521-72596-5.
Hamilton, Naomi (5 August 2008). ""The A-Z of Programming Languages: Python"". Computerworld. Archived from the original on 29 December 2008. Retrieved 31 March 2010.
Lutz, Mark (2013). Learning Python (5th ed.). O'Reilly Media. ISBN 978-0-596-15806-4.
Summerfield, Mark (2009). Programming in Python 3 (2nd ed.). Addison-Wesley Professional. ISBN 978-0-321-68056-3.
Ramalho, Luciano (May 2022). Fluent Python. O'Reilly Media. ISBN 978-1-4920-5632-4.

External links

Official website",23862,https://en.wikipedia.org/wiki/Python_(programming_language)
Schoonschip,"Schoonschip was one of the first computer algebra systems, developed in 1963 by Martinus J. G. Veltman, for use in particle physics.
""Schoonschip"" refers to the Dutch expression ""schoon schip maken"": to make a clean sweep, to clean/clear things up (literally: to make the ship clean). The name was chosen ""among others to annoy everybody, who could not speak Dutch"". 
Veltman initially developed the program to compute the quadrupole moment of the W boson, the computation of which involved ""a monstrous expression involving in the order of 50,000 terms in intermediate stages"" The initial version, dating to December 1963, ran on an IBM 7094 mainframe.  In 1966 it was ported to the CDC 6600 mainframe, and later to most of the rest of Control Data's CDC line.  In 1983 it was ported to the Motorola 68000 microprocessor, allowing its use on a number of 68000-based systems running variants of Unix.FORM can be regarded, in a sense, as the successor to Schoonschip.
Contacts with Veltman about Schoonschip have been important for Stephen Wolfram in building Mathematica.","Schoonschip was one of the first computer algebra systems, developed in 1963 by Martinus J. G. Veltman, for use in particle physics.
""Schoonschip"" refers to the Dutch expression ""schoon schip maken"": to make a clean sweep, to clean/clear things up (literally: to make the ship clean). The name was chosen ""among others to annoy everybody, who could not speak Dutch"". 
Veltman initially developed the program to compute the quadrupole moment of the W boson, the computation of which involved ""a monstrous expression involving in the order of 50,000 terms in intermediate stages"" The initial version, dating to December 1963, ran on an IBM 7094 mainframe.  In 1966 it was ported to the CDC 6600 mainframe, and later to most of the rest of Control Data's CDC line.  In 1983 it was ported to the Motorola 68000 microprocessor, allowing its use on a number of 68000-based systems running variants of Unix.FORM can be regarded, in a sense, as the successor to Schoonschip.
Contacts with Veltman about Schoonschip have been important for Stephen Wolfram in building Mathematica.

See also
Comparison of computer algebra systems

References
External links
Documentation
Schoonschip program files, documentation, and examples

Further reading
Close, Frank (2011) The Infinity Puzzle. Oxford University Press. Describes the historical context of and rationale for 'Schoonschip' (Chapter 11: ""And Now I Introduce Mr 't Hooft"")",24536975,https://en.wikipedia.org/wiki/Schoonschip
Tanenbaum–Torvalds debate,"The Tanenbaum–Torvalds debate was a written debate between Andrew S. Tanenbaum and Linus Torvalds, regarding the Linux kernel and kernel architecture in general. Tanenbaum, the creator of Minix, began the debate in 1992 on the Usenet discussion group comp.os.minix, arguing that microkernels are superior to monolithic kernels and therefore Linux was, even in 1992, obsolete.
The debate has sometimes been considered a flame war.","The Tanenbaum–Torvalds debate was a written debate between Andrew S. Tanenbaum and Linus Torvalds, regarding the Linux kernel and kernel architecture in general. Tanenbaum, the creator of Minix, began the debate in 1992 on the Usenet discussion group comp.os.minix, arguing that microkernels are superior to monolithic kernels and therefore Linux was, even in 1992, obsolete.
The debate has sometimes been considered a flame war.

The debate
While the debate initially started out as relatively moderate, with both parties involved making only banal statements about kernel design, it grew progressively more detailed and sophisticated with every round of posts. Besides just kernel design, the debate branched into several other topics, such as which microprocessor architecture would win out over others in the future. Besides Tanenbaum and Torvalds, several other people joined the debate, including Peter MacDonald, an early Linux kernel developer and creator of one of the first distributions, Softlanding Linux System; David S. Miller, one of the core developers of the Linux kernel; and Theodore Ts'o, the first North American Linux kernel developer.The debate opened on January 29, 1992, when Tanenbaum first posted his criticism on the Linux kernel to comp.os.minix, noting how the monolithic design was detrimental to its abilities, in a post titled ""LINUX is obsolete"".  While he initially did not go into great technical detail to explain why he felt that the microkernel design was better, he did suggest that it was mostly related to portability, arguing that the Linux kernel was too closely tied to the x86 line of processors to be of any use in the future, as this architecture would be superseded by then. To put things into perspective, he mentioned how writing a monolithic kernel in 1991 is ""a giant step back into the 1970s"".
Since the criticism was posted in a public newsgroup, Torvalds was able to respond to it directly. He did so a day later, arguing that MINIX has inherent design flaws (naming the lack of multithreading as a specific example), while acknowledging that he finds the microkernel kernel design to be superior ""from a theoretical and aesthetical"" point of view. He also claimed that since he was developing the Linux kernel in his spare time and giving it away for free (Tanenbaum's MINIX was not free at that time), Tanenbaum should not object to his efforts. Furthermore, he mentioned how he developed Linux specifically for the Intel 80386 because it was partly intended as a learning exercise for Torvalds himself; while he conceded that this made the kernel itself less portable than MINIX, he asserted that this was an acceptable design principle, as it made the application programming interface simpler and more portable. For this reason, he stated, ""linux is more portable than minix.""
Following Linus' reply, Tanenbaum argued that the limitations of MINIX relate to him being a professor, stating the requirement for the system to be able to run on the rather limited hardware of the average student, which he noted was an Intel 8088-based computer, sometimes even without a hard drive.
Linux was, at that time, specifically built for the Intel 386, a significantly more powerful (and expensive) processor. Tanenbaum also specifically states ""... as of about 1 year ago, there were two versions [of MINIX], one for the PC (360K diskettes) and one for the 286/386 (1.2M). The PC version was outselling the 286/386 version by 2 to 1."" He noted that even though Linux was free, it wouldn't be a viable choice for his students, as they would not be able to afford the expensive hardware required to run it, and that MINIX could be used on ""a regular 4.77 MHz PC with no hard disk."" To this, Kevin Brown, another user of the Usenet group, replied that Tanenbaum should not complain about Linux's ties to the 386 architecture, as it was the result of a conscious choice rather than lack of knowledge about operating system design, stating ""... an explicit design goal of Linux was to take advantage of the special features of the 386 architecture. So what exactly is your point? Different design goals get you different designs.""
He also stated that designing a system specifically for cheap hardware would cause it to have portability problems in the future. Despite the fact that MINIX did not fully support the newer hardware, Tanenbaum argued that since the x86 architecture would be outdone by other architecture designs in the future, he did not need to address the issue, noting ""Of course 5 years from now that will be different, but 5 years from now everyone will be running free GNU on their 200 MIPS, 64M SPARCstation-5."" He stated that the Linux kernel would eventually fall out of style as hardware progressed, due to it being so closely tied to the 386 architecture.Torvalds attempted to end the discussion at that point, stating that he felt he should not have overreacted to Tanenbaum's initial statements, and that he was composing a personal email to him to apologise. However, he would continue the debate at a later time.

Aftermath
Despite this debate, Torvalds and Tanenbaum appear to be on good speaking terms; Torvalds wants it understood that he holds no animosity towards Tanenbaum, and Tanenbaum underlines that disagreements about ideas or technical issues should not be interpreted as personal feuds.

Early 1990s perspectives
When the issue and full initial debate were published in the O'Reilly Media book Open Sources: Voices from the Open Source Revolution in 1999, it stated that the debate exemplified ""the way the world was thinking about OS design at the time"".The 386 processor was then the most widespread chip ""by several times"", according to participant Kevin Brown, with the 486 used in high-end computers, the 286 almost obsolete, and the World Wide Web not yet widely used. One of Tanenbaum's arguments against Linux was that it was too closely tied to the x86 architecture and instruction set, which he regarded as a mistake. Modern Linux now has a more portable codebase and has been ported to many other processor architectures.
Another recurring topic in the debate discusses alternatives to Linux and MINIX, such as GNU (Hurd) and 4.4BSD. Tanenbaum suggested the former in his first post, stating that unlike Linux, it was a ""modern"" system"". In his second post, he mentioned that ""... 5 years from now everyone will be running free GNU on their 200 MIPS, 64M SPARCstation-5"". Several debaters disagreed that GNU was a suitable alternative. Kevin Brown called it vaporware, and stated that Linux would likely benefit from the x86 architecture which would continue to be common and become more accessible to a general audience. Theodore Ts'o, an early Linux contributor, said that while a microkernel approach would have benefits, ""... Linux is here, and GNU isn't—and people have been working on Hurd for a lot longer than Linus has been working on Linux"".
Torvalds, aware of GNU's efforts to create a kernel, stated ""If the GNU kernel had been ready last spring, I'd not have bothered to even start my project: the fact is that it wasn't and still isn't.""4.4BSD-Lite would not be available until two years later due to the USL v. BSDi lawsuit, filed by AT&T's subsidiary Unix System Laboratories against Berkeley Software Design, which pertained to the intellectual property related to UNIX. The lawsuit slowed development of the free-software descendants of BSD for nearly two years while their legal status was in question. As Linux did not have such legal ambiguity, systems based on it gained greater support.  A settlement between USL v. BSDi was reached in January 1994, and 4.4BSD was released in June. (While the final release was in 1995, several free versions based on this version have been maintained since, including FreeBSD, DragonFly BSD, OpenBSD and NetBSD.)

The Samizdat incident
On March 23, 2004, Kenneth Brown, president of the Alexis de Tocqueville Institution, interviewed Tanenbaum.  This was a prelude to the pending publication of a book by Brown titled Samizdat: And Other Issues Regarding the 'Source' of Open Source Code.  The book claims that Linux was initially illegally copied from MINIX.  Tanenbaum published a strong rebuttal, defending Torvalds, and stated at that time:

I would like to close by clearing up a few misconceptions and also correcting a couple of errors. First, I REALLY am not angry with Linus. HONEST. He's not angry with me either. I am not some kind of ""sore loser"" who feels he has been eclipsed by Linus. MINIX was only a kind of fun hobby for me. I am a professor. I teach and do research and write books and go to conferences and do things professors do. I like my job and my students and my university. ...  I wrote MINIX because I wanted my students to have hands-on experience playing with an operating system. After AT&T forbade teaching from John Lions' book, I decided to write a UNIX-like system for my students to play with. ... I was not trying to replace GNU/HURD or Berkeley UNIX. Heaven knows, I have said this enough times. I just wanted to show my students and other students how you could write a UNIX-like system using modern technology. A lot of other people wanted a free production UNIX with lots of bells and whistles and wanted to convert MINIX into that. I was dragged along in the maelstrom for a while, but when Linux came along, I was actually relieved that I could go back to professoring. ... Linus seems to be doing excellent work and I wish him much success in the future.
While writing MINIX was fun, I don't really regard it as the most important thing I have ever done. It was more of a distraction than anything else. The most important thing I have done is produce a number of incredibly good students, especially Ph.D. students. See my home page for the list. They have done great things. I am as proud as a mother hen. To the extent that Linus can be counted as my student, I'm proud of him, too. Professors like it when their students go on to greater glory.

Continued dialogue
This subject was revisited in 2006 after Tanenbaum wrote a cover story for Computer magazine titled ""Can We Make Operating Systems Reliable and Secure?"".
While Tanenbaum himself has mentioned that he did not write the article to renew the debate on kernel design,
the juxtaposition of the article and an archived copy of the 1992 debate on the technology site Slashdot caused the subject to be rekindled.
Torvalds posted a rebuttal of Tanenbaum's arguments via an online discussion forum,
and several technology news sites began reporting the issue.
This prompted Jonathan Shapiro (primary developer of the EROS microkernel) to respond that most of the field-proven reliable and secure computer systems use a more microkernel-like approach.

Intel Management Engine revelations
In 2017, it was revealed that Intel was running MINIX inside the Management Engine, a separate processor incorporated in Intel processor chipsets since 2008. As a response to this, Tanenbaum wrote an open letter to Intel claiming MINIX to be ""the most widely used computer operating system in the world"".

References
External links
""Appendix A - The Tanenbaum-Torvalds Debate"". Open Sources: Voices from the Open Source Revolution. O'Reilly Media. 1999. ISBN 978-1-56592-582-3.
""Torvalds on the Microkernel Debate"". Slashdot. May 10, 2006.
Andrew S. Tanenbaum (May 12, 2006). ""Tanenbaum-Torvalds Debate: Part II"". Archived from the original on June 3, 2023. Retrieved June 14, 2023.
""Link to the debate on Google Groups Newsreader"".",5087911,https://en.wikipedia.org/wiki/Tanenbaum%E2%80%93Torvalds_debate
THE multiprogramming system,"The THE multiprogramming system or THE OS was a computer operating system designed by a team led  by Edsger W. Dijkstra, described in monographs in 1965-66 and published in 1968.
Dijkstra never named the system; ""THE"" is simply the abbreviation of ""Technische Hogeschool Eindhoven"", then the name (in Dutch) of the Eindhoven University of Technology of the Netherlands. The THE system was primarily a batch system that supported multitasking; it was not designed as a multi-user operating system. It was much like the SDS 940, but ""the set of processes in the THE system was static"".The THE system apparently introduced the first forms of software-based paged virtual memory (the Electrologica X8 did not support hardware-based memory management), freeing programs from being forced to use physical locations on the drum memory. It did this by using a modified ALGOL compiler (the only programming language supported by Dijkstra's system) to ""automatically generate calls to system routines, which made sure the requested information was in memory, swapping if necessary"". Paged virtual memory was also used for buffering input/output (I/O) device data, and for a significant portion of the operating system code, and nearly all the ALGOL 60 compiler. In this system, semaphores were used as a programming construct for the first time.","The THE multiprogramming system or THE OS was a computer operating system designed by a team led  by Edsger W. Dijkstra, described in monographs in 1965-66 and published in 1968.
Dijkstra never named the system; ""THE"" is simply the abbreviation of ""Technische Hogeschool Eindhoven"", then the name (in Dutch) of the Eindhoven University of Technology of the Netherlands. The THE system was primarily a batch system that supported multitasking; it was not designed as a multi-user operating system. It was much like the SDS 940, but ""the set of processes in the THE system was static"".The THE system apparently introduced the first forms of software-based paged virtual memory (the Electrologica X8 did not support hardware-based memory management), freeing programs from being forced to use physical locations on the drum memory. It did this by using a modified ALGOL compiler (the only programming language supported by Dijkstra's system) to ""automatically generate calls to system routines, which made sure the requested information was in memory, swapping if necessary"". Paged virtual memory was also used for buffering input/output (I/O) device data, and for a significant portion of the operating system code, and nearly all the ALGOL 60 compiler. In this system, semaphores were used as a programming construct for the first time.

Design
The design of the THE multiprogramming system is significant for its use of a layered structure, in which ""higher"" layers depend on ""lower"" layers only:

Layer 0 was responsible for the multiprogramming aspects of the operating system. It decided which process was allocated to the central processing unit (CPU), and accounted for processes that were blocked on semaphores. It dealt with interrupts and performed the context switches when a process change was needed. This is the lowest level. In modern terms, this was the scheduler.
Layer 1 was concerned with allocating memory to processes. In modern terms, this was the pager.
Layer 2 dealt with communication between the operating system and the system console.
Layer 3 managed all I/O between the devices attached to the computer. This included buffering information from the various devices.
Layer 4 consisted of user programs. There were 5 processes: in total, they handled the compiling, executing, and printing of user programs. When finished, they passed control back to the schedule queue, which was priority-based, favoring recently started processes and ones that blocked because of I/O.
Layer 5 was the user; as Dijkstra notes, ""not implemented by us"".The constraint that higher layers can only depend on lower layers was imposed by the designers in order to make reasoning about the system (using quasi-formal methods) more tractable, and also to facilitate building and testing the system incrementally. The layers were implemented in order, layer 0 first, with thorough testing of the abstractions provided by each layer in turn. This division of the kernel into layers was similar in some ways to Multics' later ring-segmentation model. Several subsequent operating systems have used layering to some extent, including Windows NT and macOS, although usually with fewer layers.
The code of the system was written in assembly language for the Dutch Electrologica X8 computer. This computer had a word size of 27 bits, 48 kilowords of core memory, 512 kilowords of drum memory providing backing store for the LRU cache algorithm, paper tape readers, paper tape punches, plotters, and printers.

See also
RC 4000 Multiprogramming System
Ring (computer security)
Timeline of operating systems
Source code is available at http://archive.computerhistory.org/resources/text/Knuth_Don_X4100/PDF_index/k-1-pdf/k-1-C1063.6-source-THE-os.pdf


== References ==",1525837,https://en.wikipedia.org/wiki/THE_multiprogramming_system
Vim (text editor),"Vim ( ; vi improved) is a free and open-source, screen-based text editor program. It is an improved clone of Bill Joy's vi. Vim's author, Bram Moolenaar, derived Vim from a port of the Stevie editor for Amiga and released a version to the public in 1991. Vim is designed for use both from a command-line interface and as a standalone application in a graphical user interface.
Since its release for the Amiga, cross-platform development has made it available on many other systems. In 2018, it was voted the most popular editor amongst Linux Journal readers; in 2015 the Stack Overflow developer survey found it to be the third most popular text editor, and in 2019 the fifth most popular development environment.","Vim ( ; vi improved) is a free and open-source, screen-based text editor program. It is an improved clone of Bill Joy's vi. Vim's author, Bram Moolenaar, derived Vim from a port of the Stevie editor for Amiga and released a version to the public in 1991. Vim is designed for use both from a command-line interface and as a standalone application in a graphical user interface.
Since its release for the Amiga, cross-platform development has made it available on many other systems. In 2018, it was voted the most popular editor amongst Linux Journal readers; in 2015 the Stack Overflow developer survey found it to be the third most popular text editor, and in 2019 the fifth most popular development environment.

History
Vim's forerunner, Stevie (ST Editor for VI Enthusiasts), was created by Tim Thompson for the Atari ST in 1987 and further developed by Tony Andrews and G.R. (Fred) Walter. It was one of the first popularized clones of Vi, and did not use Vi's source code. The source code for Vi used the Ed text editor developed under AT&T, and therefore Vi could only be used by those with an AT&T source license. Basing Vim on the source code for Stevie meant the program could be distributed without requiring the AT&T source license.
Basing his work on Stevie, Bram Moolenaar began working on Vim for the Amiga computer in 1988, with the first public release (Vim v1.14) in 1991.At the time of its first release, the name ""Vim"" was an acronym for ""Vi IMitation"", but this changed to ""'Vi IMproved"" late in 1993.

Release history
License
Vim is released under the Vim license, which includes some charityware clauses that encourage users who enjoy the software to consider donating to children in Uganda. The Vim license is compatible with the GNU General Public License through a special clause allowing distribution of modified copies under the GNU GPL version 2.0 or later.

Interface
Like vi, Vim's interface is not based on menus or icons but on commands given in a text user interface; its GUI mode, gVim, adds menus and toolbars for commonly used commands but the full functionality is still expressed through its command line mode. Vi (and by extension Vim) tends to allow a typist to keep their fingers on the home row, which can be an advantage for a touch typist.Vim has a built-in tutorial for beginners called vimtutor, which is usually installed along with Vim, but is a separate executable and can be run with a shell command. The Vim Users' Manual details Vim's features and can be read from within Vim, or found online.Vim also has a built-in help facility (using the :help command) which allows users to query and navigate through commands and features.

Registers
Vim features various special memory entries called registers (not to be confused with hardware or processor registers). When cutting, deleting, copying, or pasting text the user can choose to store the manipulated text in a register. There are 36 general-purpose registers associated with letters and numbers ([a-z0-9]) and a range of special ones that either contain special values (current filename, last command, etc.) or serve a special purpose.: 85

Modes
Like vi, vim supports multiple editing modes. Depending on the mode, typed characters are interpreted either as sequences of commands or are inserted as text. In Vim there are 14 editing modes, 7 basic modes and 7 variants:
Normal mode – used for editor commands. This is generally the default mode and by default hitting ESC returns the editor to this mode.
Insert mode – used for typing text in a way similar to most modern editors. In this mode, opened text in buffers can be modified with the text entered from the keyboard.: 12 
Visual mode – used to select areas of text. Commands can be run on the selected area – moving, editing, filtering via built-in or external command, etc.
Visual linewise, a subtype of visual mode which selects one or more whole lines
Visual blockwise, another subtype which selects a rectangular block of text across one or more lines
Select mode – similar to visual, but the commands are not interpreted, instead, highlighted text is directly replaced by input from the keyboard; similar to the selection mode used in editors on Microsoft Windows platforms
Command-line or Cmdline mode – provides a single line input at the bottom of the Vim window. Commands (beginning with :) and some other keys for specific actions (including pattern search and the filter command) activate this mode. On completion of the command, Vim returns to the previous mode.: 12 
Ex mode mode – accepts a sequence of commands.
Terminal-Job mode - Interacting with a job in a terminal window.

Customization
Vim is highly customizable and extensible, making it an attractive tool for users who demand a large amount of control and flexibility over their text editing environment. Text input is facilitated by a variety of features designed to increase keyboard efficiency. Users can execute complex commands with ""key bindings,"" which can be customized and extended. The ""recording"" feature allows for the creation of macros to automate sequences of keystrokes and call internal or user-defined functions and mappings. Abbreviations, similar to macros and key mappings, facilitate the expansion of short strings of text into longer ones and can also be used to correct mistakes. Vim also features an ""easy"" mode for users looking for a simpler text editing solution.There are many plugins available that extend or add new functionality to Vim. These plugins are usually written in Vim's internal scripting language, vimscript (also known as VimL), but can be written in other languages as well.
There are projects bundling together complex scripts and customizations and aimed at turning Vim into a tool for a specific task or adding a major flavour to its behaviour. Examples include Cream, which makes Vim behave like a click-and-type editor, or VimOutliner, which provides a comfortable outliner for users of Unix-like systems.

Features and improvements over vi
Vim has a vi compatibility mode, but when that mode is not used, Vim has many enhancements over vi. However even in compatibility mode, Vim is not entirely compatible with vi as defined in the Single Unix Specification and POSIX (e.g., Vim does not support vi's open mode, only visual mode). Vim's developers state that it is ""very much compatible with Vi"".Some of Vim's enhancements include completion functions, comparison and merging of files (known as vimdiff), a comprehensive integrated help system, extended regular expressions, scripting languages (both native and through alternative scripting interpreters such as Perl, Python, Ruby, Tcl, etc.) including support for plugins, a graphical user interface (gvim), limited integrated development environment-like features, mouse interaction (both with and without the GUI), folding, editing of compressed or archived files in gzip, bzip2, zip, and tar format and files over network protocols such as SSH, FTP, and HTTP, session state preservation, spell checking, split (horizontal and vertical) and tabbed windows, Unicode and other multi-language support, syntax highlighting, trans-session command, search and cursor position histories, multiple level and branching undo/redo history which can persist across editing sessions, and visual mode.While running, Vim saves the user's changes in a swap file with the "".swp"" extension. This file can be used to recover after a crash. If a user tries to open a file and a swap file already exists, Vim will warn the user, and if the user proceeds, Vim will use a swap file with the extension "".swo"" (or, if there is already more than one swap file, "".swn"", "".swm"", etc.). The feature can be disabled.

Vim script
Vim script (also called Vimscript or VimL) is the scripting language built into Vim. Based on the ex editor language of the original vi editor, early versions of Vim added commands for control flow and function definitions. Since version 7, Vim script also supports more advanced data types such as lists and dictionaries and a simple form of object-oriented programming. Built-in functions such as map() and filter() allow a basic form of functional programming, and Vim script has lambda since version 8.0. Vim script is mostly written in an imperative programming style.
Vim macros can contain a sequence of normal-mode commands, but can also invoke ex commands or functions written in Vim script for more complex tasks. Almost all extensions (called plugins or more commonly scripts) of the core Vim functionality are written in Vim script, but plugins can also utilize other languages like Perl, Python, Lua, Ruby, Tcl,  or Racket. These plugins can be installed manually, or through a plugin manager such as Vundle, Pathogen, or Vim-Plug.
Vim script files are stored as plain text, similarly to other code, and the filename extension is usually .vim. One notable exception to that is Vim's config file, .vimrc.

Examples
Availability
While vi was originally available only on Unix operating systems, Vim has been ported to many operating systems including AmigaOS (the initial target platform), Atari MiNT, BeOS, DOS, Windows starting from Windows NT 3.1, OS/2, OS/390, MorphOS, OpenVMS, QNX, RISC OS, Linux, BSD, and Classic Mac OS.  Also, Vim is shipped with Apple macOS.Independent ports of Vim are available for Android and iOS.

Neovim
Neovim is a fork of Vim that strives to improve the extensibility and maintainability of Vim. Some features of the fork include built-in Language Server Protocol (LSP) support, support for asynchronous I/O, and support for Lua scripting using luaJIT language interpreter. The project is free software and its source code is available on GitHub.Neovim has the same configuration syntax as Vim prior to vim9script; thus the same configuration file can be used with both editors, although there are minor differences in details of options. If the added features of Neovim are not used, Neovim is compatible with almost all of Vim's features.The Neovim project was started in 2014, after a patch to Vim supporting multi-threading was rejected. Neovim had a successful fundraising in March 2014, supporting at least one full-time developer.Several frontends are under development which make use of Neovim's capabilities.With the 0.5 release of Neovim on 2 July 2021, it gained built-in support for the LSP, Tree-sitter, and more complete Lua support – including the support for configuration scripts written in Lua instead of VimL.

Gallery
See also
Learning the vi and Vim Editors, a tutorial book for vi and vim, published by O'Reilly Media
Editor war – the rivalry between users of the Emacs and vi (Vim) text editors
List of text editors
Comparison of text editors
Vimperator

Notes
References
External links

Official website 
TechTalk by Bram Moolenaar held on 25th Anniversary of first vim release on YouTube",32478,https://en.wikipedia.org/wiki/Vim_(text_editor)
British Colloquium for Theoretical Computer Science,"The British Colloquium for Theoretical Computer Science (BCTCS) is an organisation, founded in 1985, that represents the interests of Theoretical Computer Science in the UK, e.g. through representation on academic boards and providing commentary and evidence in response to consultations from public bodies. The BCTCS operates under the direction of an Organising Committee, with an Executive consisting of a President, Secretary and Treasurer. The current President is Barnaby Martin.
The purpose of BCTCS is:

to provide a platform from which the interests and future well-being of British theoretical computer science may be advanced;
to offer a forum in which UK-based researchers in all aspects of theoretical computer science can meet, present research findings, and discuss recent developments in the field; and
to foster an environment within which PhD students undertaking research in theoretical computer science may gain experience in presenting their work in a formal arena, broaden their outlook on the subject, and benefit from contact with established researchers in the community.In pursuit of these aims, the BCTCS organises an annual Conference for UK-based researchers in theoretical computer science. A central aspect of the annual BCTCS Conference is the training of PhD students. The scope of the annual BCTCS Conference includes all aspects of theoretical computer science, including algorithms, complexity, semantics, formal methods, concurrency, types, languages and logics.  An emphasis on breadth, together with the inherently mathematical nature of theoretical computer science, means that BCTCS always actively solicits both computer scientists and mathematicians as participants at its annual Conference, and offers an environment within which the two communities can meet and exchange ideas.
The Annual BCTCS Conference is primarily for the benefit of UK-based researchers.  However, to promote British theoretical computer science in the wider community, participants from outside of the UK are welcome to attend, and the programme of invited talks every year includes high-profile researchers from abroad.","The British Colloquium for Theoretical Computer Science (BCTCS) is an organisation, founded in 1985, that represents the interests of Theoretical Computer Science in the UK, e.g. through representation on academic boards and providing commentary and evidence in response to consultations from public bodies. The BCTCS operates under the direction of an Organising Committee, with an Executive consisting of a President, Secretary and Treasurer. The current President is Barnaby Martin.
The purpose of BCTCS is:

to provide a platform from which the interests and future well-being of British theoretical computer science may be advanced;
to offer a forum in which UK-based researchers in all aspects of theoretical computer science can meet, present research findings, and discuss recent developments in the field; and
to foster an environment within which PhD students undertaking research in theoretical computer science may gain experience in presenting their work in a formal arena, broaden their outlook on the subject, and benefit from contact with established researchers in the community.In pursuit of these aims, the BCTCS organises an annual Conference for UK-based researchers in theoretical computer science. A central aspect of the annual BCTCS Conference is the training of PhD students. The scope of the annual BCTCS Conference includes all aspects of theoretical computer science, including algorithms, complexity, semantics, formal methods, concurrency, types, languages and logics.  An emphasis on breadth, together with the inherently mathematical nature of theoretical computer science, means that BCTCS always actively solicits both computer scientists and mathematicians as participants at its annual Conference, and offers an environment within which the two communities can meet and exchange ideas.
The Annual BCTCS Conference is primarily for the benefit of UK-based researchers.  However, to promote British theoretical computer science in the wider community, participants from outside of the UK are welcome to attend, and the programme of invited talks every year includes high-profile researchers from abroad.

Past officers of the BCTCS
Presidents
John V. Tucker (1985–1992)
Alan Gibbons (1992–1998)
Iain Stewart (1998–1999)
Paul Dunne (1999–2001)
Chris Tofts (2001–2004)
Faron Moller (2004–2019)
Barnaby Martin (2019-)

Secretaries
Mark Jerrum (1989–1992)
Paul Dunne (1992–1999)
Julian Bradfield (1999–2005)
Graham Hutton (2005–2011)
David Manlove (2011-2020)
Michele Zito (2020-2023)
Oana Andrei (2023-)

Treasurers
David Rydeheard (1989–1996)
Chris Tofts (1996–2001)
Faron Moller (2001–2004)
Stephan Reiff-Marganiec (2004–2018)
Matthew Hague (2018-2021)
Olga Petrovska (2021-)

Postgraduate representatives
Savita Chauhan (1995-1997)
Billy Duckworth (1997-1998)
Richard Gault (1998-1999)
Mei Lin Hui (1999-2000)
Paul Sant (2000-2003)
Corinna Elsenbroich (2003-2004)
Vladimir Aleksic (2004-2005)
Joel Wright (2005-2006)
Joachim Baran (2006-2007)
Temesghen Kahsai Azene (2007–2008)
Haris Aziz (2008–2009)
Julian Gutierrez (2009–2010)
Radhakrishnan Delhibabu (2010–2011)
Laurence E. Day (2011-2012)
Andy Lawrence (2012-2013)
Augustine Kwanashie (2013-2014)
Pavan Sangha (2014-2015)
Bram Geron (2015-2016)
Thomas van Binsbergen (2016-2017)
Frances Cooper (2017-2018)
Sofiat Olaosebikan (2018-2019)
Karl Southern (2019-2020)
Filippos Pantekis (2020-2021)
Michael McKay (2021-2022)
Peace Ayegba (2022-2023)
David Kutner (2023-)

BCTCS Conferences
1985 – BTCSC 1 – University of Leeds, 1–3 April 1985 (Organisers: John Tucker and Stan Wainer)
1986 – BTCSC 2 – University of Warwick, 24–26 March 1986 (Organisers: Meurig Beynon and Steve Matthews)
1987 – BCTCS 3 – University of Leicester, 13–15 April 1987 (Organiser: Derek Andrews)
1988 – BCTCS 4 – University of Edinburgh, 28–31 March 1988 (Organiser: Mark Jerrum)
1989 – BCTCS 5 – Royal Holloway and Bedford New College, 11–13 April 1989 (Organisers: Costas Iliopolous and John Shaw-Taylor)
1990 – BCTCS 6 – University of Manchester, 28–30 March 1990 (Organiser: David Rydeheard)
1991 – BCTCS 7 – University of Liverpool, 26–28 March 1991 (Organiser: Paul Dunne)
1992 – BCTCS 8 – University of Newcastle, 24–26 March 1992 (Organiser: Iain Stewart)
1993 – BCTCS 9 – University of York, 28–31 March 1993 (Organiser: Hussein Zedan)
1994 – BCTCS 10 – University of Bristol, 28–30 March 1994 (Organiser: Brian Stonebridge)
1995 – BCTCS 11 – University of Wales Swansea, 2–5 April 1995 (Organiser: Chris Tofts)
1996 – BCTCS 12 – University of Kent at Canterbury, 1–4 April 1996 (Organiser: Simon Thompson)
1997 – BCTCS 13 – University of Sheffield, 23–26 March 1997 (Organisers: Mike Holcombe and Matt Fairtlough)
1998 – BCTCS 14 – University of St. Andrews, 31 March – 2 April 1998 (Organiser: Tom Kelsey)
1999 – BCTCS 15 – Keele University 14–16 April 1999 (Organiser: John Stell)
2000 – BCTCS 16 – University of Liverpool 10–12 April 2000 (Organiser: Martyn Amos)
2001 – BCTCS 17 – University of Glasgow, 9–12 April 2001 (Organiser: Stephan Reiff-Marganiec)
2002 – BCTCS 18 – HP Laboratories Bristol, 7–10 April 2002 (Organiser: Chris Tofts)
2003 – BCTCS 19 – University of Leicester, 7–9 April 2003 (Organiser: Neil Ghani)
2004 – BCTCS 20 – University of Stirling, 5–8 April 2004 (Organiser: Stephan Reiff-Marganiec and Carron Shankland)
2005 – BCTCS 21 – University of Nottingham, 21–24 March 2005 (Organiser: Graham Hutton)
2006 – BCTCS 22 – Swansea University, 4–7 April 2006 (Organisers: Faron Moller and Markus Roggenbach)
2007 – BCTCS 23 – Oxford University, 2–5 April 2007 (Organisers: Sharon Curtis and Jeremy Gibbons)
2008 – BCTCS 24 – Durham University, 7–10 April 2008 (Organisers: Hajo Broersma, Tom Friedetzky and Daniel Paulusma)
2009 – BCTCS 25 – Warwick University, 6–9 April 2009 (Organisers: Artur Czumaj, Sara Kalvala and Steve Matthews)
2010 – BCTCS 26 – Edinburgh University, 6–9 April 2010 (Organisers: Julian Bradfield and Mary Cryan)
2011 – BCTCS 27 – Birmingham University, 18–21 April 2011 (Organisers: Achim Jung and Paul Levi)
2012 – BCTCS 28 – Manchester University, 2–5 April 2012 (Organiser: Ian Pratt-Hartmann)
2013 – BCTCS 29 – University of Bath, 24–27 March 2013 (Organisers: James Davenport, Guy McCusker)
2014 – BCTCS 30 – Loughborough University, 9–11 April 2014 (Organisers: Paul Bell and Daniel Reidenbach)
2015 – BCTCS 31 – Middlesex University, 14–18 September 2015 (Organisers: Barnaby Martin, Guiseppe Primero and Rajagopal Nagarajan)
2016 – BCTCS 32 – Queen’s University Belfast, 22–24 March 2016 (Organisers: Amitabh Trehan, Pooya Farshim, Peter Robinson and Alan Stewart)
2017 – BCTCS 33 – University of St Andrews, 26–28 April 2017 (Organiser: Markus Pfeiffer)
2018 – BCTCS 34 – Royal Holloway University of London, 26–28 March 2018 (Organiser: Matthew Hague)
2019 – BCTCS 35 – Durham University, 15–17 April 2019 (Organisers: Matthew Johnson, Barnaby Martin, George Mertzios and Daniël Paulusma.)
2020 – BCTCS 36 – Swansea University, 6–8 April 2020 (Organisers: Ulrich Berger, Faron Moller, Markus Roggenbach, Monika Seisenberger, Olga Petrovska and Liam O’Reilly)
2021 – BCTCS 37 – University of Liverpool, 29–31 March 2021 (Organisers: Patrick Totzke and Michele Zito)
2022 – BCTCS 38 – Swansea University, 11–13 April 2022 (Organisers: Monika Seisenberger and Olga Petrovska)
2023 – BCTCS 39 – University of Glasgow, 3–4 April 2023 (Organiser: Ciaran McCreesh)
2024 – BCTCS 40 – University of Bath, 4–5 April 2024 (Organisers: James Davenport and Thomas Powell)

See also
Formal Aspects of Computing Science, a British Computer Society Specialist Group.

External links
The British Colloquium for Theoretical Computer Science website",7628891,https://en.wikipedia.org/wiki/British_Colloquium_for_Theoretical_Computer_Science
BT Research,"BT Research is the research arm of BT Group, formerly part of the British Post Office. The company was first established in 1921 as the Post Office Research Station at Dollis Hill, London. In 1968 BT moved of its research to the new site at Martlesham Heath based on part of the old Royal Air Force Station at Martlesham Heath near Ipswich in the English county of Suffolk, which was later renamed[ Adastral Park].","BT Research is the research arm of BT Group, formerly part of the British Post Office. The company was first established in 1921 as the Post Office Research Station at Dollis Hill, London. In 1968 BT moved of its research to the new site at Martlesham Heath based on part of the old Royal Air Force Station at Martlesham Heath near Ipswich in the English county of Suffolk, which was later renamed[ Adastral Park].

Location
BT's main research facility is located in the United Kingdom at Adastral Park, near Ipswich in the county of Suffolk. The Adastral Park site was first planned around 1968 as the Martlesham Heath Post Office Laboratories and after completion in 1971 has grown since then to a facility today which has around 4,000 research and development people from both BT and some of its partner companies. Globally, BT has additional research labs in Beijing, Boston MA and Abu Dhabi. The focus of research at BT is Information and Communications Technology (ICT).
The Royal Air Force were the original residents of the site in Suffolk at RAF Martlesham Heath. Experimental aircraft test flights flew from the airfield and the name (Adastral Park) is intended to reflect the history of experimentation and innovation, which is the continuing focus for the Park. The initial models and plans created by the MPBW [successor to the MOW] would appear to indicate the influence of the Thunderbirds TV series of the 1960s.

Activities
Current research themes
Major theme areas are;

IT Services, software and systems
Internet of Things (IoT)
Big Data
Future of the Internet and network transformation
Mobility and convergence
Future of the Web and semantic intelligence
Information and security systems
Customer service and systems
The digital home and sociable communications

Academic research partners
BT works closely with both academics and students in over 20 institutions globally and has strong partnerships with the University of Cambridge in the UK, the Massachusetts Institute of Technology (MIT) in the USA and Tsinghua University in China. BT also leads the India-UK Advanced Technology Centre, a consortium of 22 Indian and UK industry and academic partners conducting research into current and next generation fixed and wireless communications.

History
Research in the company was first established in 1921 at the Post Office Research Station at Dollis Hill, London. In 1968 BT began the move of its research to the new site at Martlesham Heath in Suffolk. By late 1969 small teams of researchers were working at Martlesham. The first new research building was formally opened on 21 November 1975 by Queen Elizabeth II of the United Kingdom. The architect was Mr Stanislaw Spielrein ARIBA of the Ministry of Public Buildings and Works [MPBW]. The new building housed 1,700 people.

Patents
By the turn of the twentieth century, the site had produced over 10,000 patents.

Innovations from BT Research
2006 [October] – BT implemented the world's first fully automated 'spam buster' system to track down and tackle professional spammers and 'botnet' infected customers on the BT broadband network.
2002 [June] – Research and development teams designed and deployed a suite of new business systems allowing the launch of the UK's first commercial broadband internet access service.
1999 [July] – BT announced that it had pushed commercial optical fibre transmission to 80Gbit/s. BT labs demonstrated the world's fastest regenerator – a photonic digital network component.
1995 [June] – BT research designed and developed a video on demand service, which was trialled in the local area [Ipswich – Colchester], with 2,500 customers. It used asymmetric data on a subscriber's line (asymmetric digital subscriber line) over copper cables, with a decoder supplied by Apple. – article on trial
1987 [August] – the world's first instantaneous translation of speech by computer was unveiled by BT's research laboratories.
1982 [April] – Europe's first satellite transmission service was launched with Adastral Park's satellite dishes beaming television signals to the Orbital Test Satellite, run by Eutelsat, allowing Finnish and Norwegian viewers to receive the (English language) signals.
1979 [September] – GPO launched Prestel, the world's first viewdata network.

References
External links
BT Technology Journal
BT Group
Adastral Park",20120454,https://en.wikipedia.org/wiki/BT_Research
Central Computer and Telecommunications Agency,The Central Computer and Telecommunications Agency (CCTA) was a UK government agency providing computer and telecoms support to government departments.,"The Central Computer and Telecommunications Agency (CCTA) was a UK government agency providing computer and telecoms support to government departments.

History
Formation
In 1957, the UK government formed the Technical Support Unit (TSU) within HM Treasury to evaluate and advise on computers, initially based around engineers from the telecommunications service. As this unit evolved, it morphed into the Central Computer and Telecommunications Agency, which also had responsibilities as a central procurement body for government technological equipment.
CCTA's work during the 1970s, 1980s and 1990s was primarily to (a) develop central government IT professionalism, (b) create a body of knowledge and experience in the successful development and implementation of IS/IT within UK central government (c) to brief Government Ministers on the opportunities for use of IS/IT to support policy initiatives (e.g. ""Citizen's Charter"" / ""e-government"") and (d) to encourage and assist UK private sector companies to develop and offer products and services aligned to government needs.
Over the 3 decades, CCTA's focus shifted from hardware to a business oriented systems approach with strong emphasis on business led IS/IT Strategies which crossed Departmental (Ministry) boundaries encompassing several ""Departments"" (e.g.  CCCJS – Computerisation of the Central Criminal Justice System). This inter-departmental approach (first mooted in the mid to late 1980s) was revolutionary and met considerable political and departmental opposition.
In October 1994, MI5 took over its work on computer security from hacking into the government's (usually the Treasury) network. In November 1994, CCTA launched its website. In February 1998 it built and ran the government's secure intranet. The MoD was connected to a separate network. In December 1998, the DfEE moved its server from CCTA at Norwich to NISS (National Information Services and Systems) in Bath when it relaunched its website.Between 1989 and 1992, CCTA's ""Strategic Programmes"" Division undertook research on exploiting Information Systems as a medium for improving the relationship between citizens, businesses and government. This parallelled the launch of the ""Citizen's Charter"" by the then Prime Minister, John Major, and the creation within the Cabinet Office of the ""Citizen's Charter Unit"" (CCTA had at this point been moved from HM Treasury to the Cabinet Office).  The research and work focused on identifying ways of simplifying the interaction between citizens and government through the use of IS/IT. Two major TV documentaries were produced by CCTA – ""Information and the Citizen"" and ""Hymns Ancient and Modern"" which explored the business and political issues associated with what was to become ""e-government"". These were aimed at widening the understanding of senior civil servants (the Whitehall Mandarins) of the significant impact of the ""Information Age"" and identifying wider social and economic issues likely to arise from e-government.

Merger
During the late 1990s, its strategic role was eroded by the Cabinet Office's Central IT Unit (CITU – created by Michael Heseltine in November 1995), and in 2000 CCTA was fully subsumed into the Office of Government Commerce (OGC).

Successors
Since then, the non-procurement IT / Telecommunications co-ordination role has remained in the Cabinet Office, under a number of successive guises:

The Office of the E-Envoy (OeE)
The eGovernment Unit (eGU)
The Transformational Government (TG) Group
The Government Digital Service

Activities
CCTA was the sponsor of a number of methodologies, including:

Structured Systems Analysis and Design Method (SSADM)
PRojects IN Controlled Environments (PRINCE, PRINCE2), which is an evolution of PROMPT, a project management method created by Simpact Systems Ltd in 1975 that was adopted by CCTA in 1979 for Government information system projects
Information Technology Infrastructure Library (ITIL), which has largely evolved through BS15000 into the ISO20000 series
The CCTA Risk Analysis and Management Method (CRAMM), developed at the request of the Cabinet Office in 1985The CCTA Security Group created the first UK Government National Information Security Policy, and developed the early approaches to structured information security for commercial organisations which saw wider use in the DTI Security Code of Practice, BS 7799 and eventually ISO/IEC 27000
CCTA also promoted the use of emerging IT standards in UK government and in the EU, such as OSI and BS5750 (Quality Management) which led to the publishing of the Quality Management Library and the inception of the TickIT assessment scheme with DTI, MOD and participation of software development companies.
In addition to the development of methodologies, CCTA produced a comprehensive set of managerial guidance covering the development of Information Systems under 5 major headings:  A. – Management and Planning of IS;  B. – Systems Development;  C. – Service Management;  D – Office Users;  E. – IS Services Industry.  The guidance consisted of 27 individual guides and were published commercially as ""The Information Systems Guides"" (ISBN 0-471-92556-X) by John Wiley and Sons.  The publication is no longer available.  This guidance was developed from the practical experience and lessons learned from many UK Government Departments in planning, designing, implementing and monitoring Information Systems and was highly regarded as ""best practice"".  Some parts were translated into other European languages and adopted as national standards.
It also was involved in technical developments, for instance as the sponsor of Project SPACE in the mid 1980s.  Under Project SPACE, the ICL Defence Technology Centre (DTC), working closely with technical staff from CCTA and key security-intensive projects in the Ministry of Defence (such as OPCON CCIS) and in other sensitive departments, developed an enhanced security variant of VME.
It managed (ran the servers) of UK national government websites, including those such as the Royal Family's and www.open.gov.uk.

Structure
CCTA's headquarters were in London at Riverwalk House, Vauxhall Bridge Road, SW1, since used by the Government Office for London.  This housed the main divisions with a satellite office in Norwich which focused on IS/IT Procurement – a function which had been taken over from HMSO (the Stationery Office) when CCTA was formed.
The office in Norwich was in the east of the city, off the former A47 (now A1042), just west of the present A47 interchange near the former St Andrew's Hospital. The site is now used by the OGC.
The HQ in London had four divisions:

Project support – major IT programmes – software engineering
Specialist support – evaluation of individual items of hardware and software
Strategic Planning and Promotion – project management and office technology (hardware and office automation)
Advance Technology – telecommunications and advanced technology (latest generation of computers)


== References ==",12986427,https://en.wikipedia.org/wiki/Central_Computer_and_Telecommunications_Agency
The Computer Journal,"The Computer Journal is a peer-reviewed  scientific journal covering computer science and information systems. Established in 1958, it is one of the oldest computer science research journals. It is published by Oxford University Press on behalf of BCS, The Chartered Institute for IT. The authors of the best paper in each annual volume receive the Wilkes Award from BCS, The Chartered Institute for IT.","The Computer Journal is a peer-reviewed  scientific journal covering computer science and information systems. Established in 1958, it is one of the oldest computer science research journals. It is published by Oxford University Press on behalf of BCS, The Chartered Institute for IT. The authors of the best paper in each annual volume receive the Wilkes Award from BCS, The Chartered Institute for IT.

Editors-in-chief
The following people have been editor-in-chief:

1958–1969 Eric N. Mutch
1969–1992 Peter Hammersley
1993–2000 C. J. van Rijsbergen
2000–2008 Fionn Murtagh
2008–2012 Erol Gelenbe
2012–2016 Fionn Murtagh
2016–2020 Steve Furber
2021–present Tom Crick

References
External links
Official website
History of the journal
Wilkes Award",2741628,https://en.wikipedia.org/wiki/The_Computer_Journal
Computer Science Ontology,"The Computer Science Ontology (CSO) is an automatically generated taxonomy of research topics in the field of Computer Science. It was produced by the Open University in collaboration with Springer Nature by running an information extraction system over a large corpus of scientific articles. Several branches were manually improved by domain experts. The current version (CSO 3.2) includes about 14K research topics and 160K semantic relationships.CSO is available in OWL, Turtle, and N-Triples.
It is aligned with several other knowledge graphs, including DBpedia, Wikidata, YAGO, Freebase, and Cyc. New versions of CSO are regularly released on the CSO Portal.CSO is mostly used to characterise scientific papers and other documents according to their research areas, in order to enable different kinds of analytics. The CSO Classifier is an open-source python tool for automatically annotating documents with CSO.","The Computer Science Ontology (CSO) is an automatically generated taxonomy of research topics in the field of Computer Science. It was produced by the Open University in collaboration with Springer Nature by running an information extraction system over a large corpus of scientific articles. Several branches were manually improved by domain experts. The current version (CSO 3.2) includes about 14K research topics and 160K semantic relationships.CSO is available in OWL, Turtle, and N-Triples.
It is aligned with several other knowledge graphs, including DBpedia, Wikidata, YAGO, Freebase, and Cyc. New versions of CSO are regularly released on the CSO Portal.CSO is mostly used to characterise scientific papers and other documents according to their research areas, in order to enable different kinds of analytics. The CSO Classifier is an open-source python tool for automatically annotating documents with CSO.

Applications
Recommender Systems.
Computing the semantic similarity of documents.
Extracting metadata from video lecture subtitles.
Performing bibliometrics analysis.

See also
References
External links
Official website",62794442,https://en.wikipedia.org/wiki/Computer_Science_Ontology
Computer Weekly,"Computer Weekly is a digital magazine and website for IT professionals in the United Kingdom. It was formerly published as a weekly print magazine by Reed Business Information for over 50 years. Topics covered within the magazine include outsourcing, security, data centres, information management, cloud computing, and mobile computing to computer hacking and strategy for IT management.","Computer Weekly is a digital magazine and website for IT professionals in the United Kingdom. It was formerly published as a weekly print magazine by Reed Business Information for over 50 years. Topics covered within the magazine include outsourcing, security, data centres, information management, cloud computing, and mobile computing to computer hacking and strategy for IT management.

History
Computer Weekly Issue 1 was published on 22 September 1966, billed as the first ever weekly technology publication. The editor for the first ten years was Chris Hipwell. John Lamb was editor in the 1980s and 1990s. Tony Collins was executive editor from 1989-2010.The newspaper was available free to IT professionals who met the circulation requirements. A small minority of issues were sold in retail outlets, with the bulk of revenue received from display and recruitment advertising. During the 1990s there were often as many as 100 pages of advertisements per issue. The circulation figure was 135,035 according to the publisher's statement in August 2007. The last print edition came off the presses in April 2011 and the publication was transferred to a digital only edition, following TechTarget's acquisition of the Computer Weekly website and events business. On September 22, 2016, the magazine celebrated its 50th anniversary. At the time, its circulation figure was 200,000 magazines per week, and 400,000 magazines once monthly and quarterly regional editions were counted.The magazine is still available free as a PDF digital edition. Bryan Glick is the editor-in-chief, having joined in November 2009.Computer Weekly won the UK Periodical Publishers Association (PPA) ""Campaign of the Year"" Award five times in seven years as it was involved in IT-related campaigns such as the costs of the NHS computer system, websites for disabled people and the Chinook crash on Mull of Kintyre. More recently, its role in highlighting the Post Office Horizon scandal, with coverage beginning in 2008, has been widely highlighted.On 28 July 2021, Computer Weekly launched the voting for its Most Influential Woman in UK Technology awards.

Website
The website, ComputerWeekly.com, provides users with IT news and analysis, white papers, and case studies. ComputerWeekly.com also provides information via webinars, podcasts, blogs, desktop alerts, and RSS feeds.
The site also features the ""Downtime"" is a section of the magazine that included a daily 2 column Dilbert comic strip.

Webinars
Webinars are presented on the site, lasting 45 minutes, beginning with a 5-minute introduction from the chair followed by presentations from an analyst and a specific case study. Viewers can email the panel with their questions throughout the webinar.
Users are required to register for each webinar and this is then viewed using an interface that allows users to watch the video of the webinar alongside supporting PowerPoint presentation slides.
The interface allows the user to enlarge and download slides, view speaker information, and support case studies.  When viewed on-demand, the user can also pause, skip and select specific sections from the webinar to view.

Podcasts
Podcasts are audio downloads provided in an MP3 format which are available on-demand. They are generated by the ComputerWeekly.com editorial team.

Blogs
The blogs cover key issues facing IT decision-makers and bloggers include David Lacey, Cliff Saran, Karl Flinders, Matt Scott, Adrian Bridgwater, and Caroline Baldwin.

Computer Weekly CW500 club
The Computer Weekly CW500 Club is a forum for senior IT directors in UK organizations. The club was launched in 1993 and was set up to provide business inspiration and networking opportunities for heads of IT.  Membership is by invitation only, and members meet once a month in London to hear their peers talk on topical IT management issues.

UKtech50
In 2010, Computer Weekly launched the UKtech50 – a list of the 50 most influential people in the UK IT. The list is composed annually and announced at an event, typically in late November or early December. Past winners of UKtech50 are Philip Clarke, then the CIO of Tesco and now its CEO; Mike Lynch, founder and then-CEO of Autonomy; and Warren East, CEO of ARM.

References
External links
Official website",2626998,https://en.wikipedia.org/wiki/Computer_Weekly
Computing (magazine),"Computing is an online magazine published by The Channel Company for IT managers and professionals in the United Kingdom. The brand announced plans to launch in North America and Germany in 2023.
As of December 2006, Computing's circulation was verified by BPA Worldwide as 115,431.","Computing is an online magazine published by The Channel Company for IT managers and professionals in the United Kingdom. The brand announced plans to launch in North America and Germany in 2023.
As of December 2006, Computing's circulation was verified by BPA Worldwide as 115,431.

History
Originally launched in 1973 as the official magazine of the British Computer Society and published by Haymarket Publishing, Computing is the longest continuously published magazine for IT professionals in the UK.
In print it was largely a controlled circulation publication, mailed without charge to members of the British Computer Society and other accredited workers in the field of computing. A small minority of issues were sold on newsstands, with the bulk of funding for production arising from advertising.
It was one of two magazines (the other being Accountancy Age) purchased in the 1970s by Dutch publisher VNU Business Media to launch their business in the UK. VNU Business Publications was acquired by Incisive Media in 2007. In April 2022, The Channel Company acquired CRN UK, Computing, and Channel Partner Insight from Incisive Media.Along with Computer Weekly (and formerly IT Week), Computing is the mainstay of the UK computer industry trade press. Historically, Computing was aimed at business-focused readers, with Computer Weekly catering for readers seeking more technical coverage.  This distinction blurred and dissolved in the late 1980s, with IT Week filling the gap left in technology-focused business coverage from 1998. In recent years Computing has pursued both a technical- and business-oriented agenda.
The Computing web site was relaunched with new video and audio content and a focus on extensive reader interactivity in early 2007. About a dozen regular bloggers were introduced to create dynamic content for the online version of the magazine, some of these blogs also being carried in the print title.
The print edition of Computing changed from a weekly to bi-weekly magazine from 10th June 2010. The print edition of the magazine ended publication in the mid-2010s.  
The long-term editor of Computing, Bryan Glick, left the title in November 2009 to pursue a new role as editor-in-chief of Computer Weekly. He was replaced in January 2010 by Abigail Warakar, who resigned in January 2012; Chris Middleton, a former editor of Computer Business Review (and deputy editor of Computing in 2001) returned as interim editor. Stuart Sumner became editor of Computing in July 2012. Tom Allen, former deputy editor of Display Daily and who had been with Computing since 2017, took over as editor in October 2022. Computing is available online.

References
External links
computing.co.uk
Audited circulation statement 2005 (PDF)",3628919,https://en.wikipedia.org/wiki/Computing_(magazine)
IBM Hursley,"IBM Hursley is a research and development laboratory belonging to International Business Machines in the village of Hursley, Hampshire, England. Established in Hursley House, an 18th-century Queen Anne style mansion in 1958, the facility has been instrumental in the development of IBM's software technologies since the 1950s. It is still the home of development for CICS and MQ technology. Among the software developed by IBM Hursley is the Customer Information Control System (CICS), used in ATMs, which was the first Hursley product with a billion dollars in annual revenue.Initially, IBM just used the House and its grounds. In 1963 it purchased 100 acres (405,000 m2) of land surrounding the house and has since erected a large modern office complex employing over 1500 people.
The facility is host to the IBM Client Centre, which offers potential clients a secure environment where they can test company software and work with staff experts on best practices, proof of concept, and proof of technology.
Hursley House itself, a Grade II* listed building, is still used as an Executive Briefing Centre. The lower ground floor of the house is home to the IBM Hursley Museum, a computing museum that covers the history of IBM Hursley Park, IBM United Kingdom, and IBM Corporation.","IBM Hursley is a research and development laboratory belonging to International Business Machines in the village of Hursley, Hampshire, England. Established in Hursley House, an 18th-century Queen Anne style mansion in 1958, the facility has been instrumental in the development of IBM's software technologies since the 1950s. It is still the home of development for CICS and MQ technology. Among the software developed by IBM Hursley is the Customer Information Control System (CICS), used in ATMs, which was the first Hursley product with a billion dollars in annual revenue.Initially, IBM just used the House and its grounds. In 1963 it purchased 100 acres (405,000 m2) of land surrounding the house and has since erected a large modern office complex employing over 1500 people.
The facility is host to the IBM Client Centre, which offers potential clients a secure environment where they can test company software and work with staff experts on best practices, proof of concept, and proof of technology.
Hursley House itself, a Grade II* listed building, is still used as an Executive Briefing Centre. The lower ground floor of the house is home to the IBM Hursley Museum, a computing museum that covers the history of IBM Hursley Park, IBM United Kingdom, and IBM Corporation.

References
External links
IBM Hursley Site

IBM Hursley Labs Flickr Galleries
IBM Hursley Labs Pinterest Pins
IBM Hursley Labs YouTube Channel
IBM Hursley Museum",26152234,https://en.wikipedia.org/wiki/IBM_Hursley
IET Information Security,"IET Information Security is a bimonthly peer-reviewed scientific journal covering information security and cryptography. It was established in 2005 as IEE Proceedings - Information Security, obtaining its current name in 2007. It is published by the Institution of Engineering and Technology and the editor-in-chief is Yvo Desmedt (University College London).","IET Information Security is a bimonthly peer-reviewed scientific journal covering information security and cryptography. It was established in 2005 as IEE Proceedings - Information Security, obtaining its current name in 2007. It is published by the Institution of Engineering and Technology and the editor-in-chief is Yvo Desmedt (University College London).

Abstracting and indexing
The journal is abstracted and indexed in:

According to the Journal Citation Reports, the journal has a 2017 impact factor of 0.890.

References
External links
Official website",59613436,https://en.wikipedia.org/wiki/IET_Information_Security
IET Software,"IET Software is a peer-reviewed scientific journal on software engineering and related issues, published by the Institution of Engineering and Technology (IET) in the United Kingdom.The journal was previously published under the following titles:

Software & Microsystems (1982–1986, Online ISSN 2053-9096, Print ISSN 0261-3182)
Software Engineering Journal (1986–1996, Online ISSN 2053-910X, Print ISSN 0268-6961)
 IEE Proceedings - Software (1997–2006. Online ISSN 1463-9831, Print ISSN 1462-5970)The journal is listed on the online IEEE Xplore Digital Library. It is indexed by DBLP, EBSCO, Ei Compendex, IET Inspec, ProQuest, Science Citation Index Expanded (SCI-E), SCImago, and Scopus.","IET Software is a peer-reviewed scientific journal on software engineering and related issues, published by the Institution of Engineering and Technology (IET) in the United Kingdom.The journal was previously published under the following titles:

Software & Microsystems (1982–1986, Online ISSN 2053-9096, Print ISSN 0261-3182)
Software Engineering Journal (1986–1996, Online ISSN 2053-910X, Print ISSN 0268-6961)
 IEE Proceedings - Software (1997–2006. Online ISSN 1463-9831, Print ISSN 1462-5970)The journal is listed on the online IEEE Xplore Digital Library. It is indexed by DBLP, EBSCO, Ei Compendex, IET Inspec, ProQuest, Science Citation Index Expanded (SCI-E), SCImago, and Scopus.

See also
IEEE Software magazine
IEEE Transactions on Software Engineering journal

References
External links
IET Software home page",52075391,https://en.wikipedia.org/wiki/IET_Software
The Imaging Science Journal,"The Imaging Science Journal, formerly The Journal of Photographic Science, is a bimonthly peer-reviewed scientific journal covering both fundamental and applied aspects of imaging, including conventional, analogue chemical, electronic, digital and hybrid imaging systems. It is an official journal of the Royal Photographic Society and published by Taylor & Francis, previously published by Maney Publishing. The journal was established in 1953. The current editor-in-chief is Professor Ricardo Vardasca, from ISLA Santarém, Portugal.","The Imaging Science Journal, formerly The Journal of Photographic Science, is a bimonthly peer-reviewed scientific journal covering both fundamental and applied aspects of imaging, including conventional, analogue chemical, electronic, digital and hybrid imaging systems. It is an official journal of the Royal Photographic Society and published by Taylor & Francis, previously published by Maney Publishing. The journal was established in 1953. The current editor-in-chief is Professor Ricardo Vardasca, from ISLA Santarém, Portugal.

History
The Photographic Society of London, which became the Royal Photographic Society in 1894, was formed in 1853 ‘to promote the art and science of photography’ and it delivered on this through its membership, external engagement, public exhibitions, meetings and a printed journal.  In the nineteenth century the RPS’s Journal reported on developments in new chemistry usually from amateur experimenters, and in areas such as optics and technology. Later in the century, as the Society itself moved away from art photography and gave a greater focus on photographic science, through the influence of a series of ‘science’ orientated Presidents, the Journal grew as a means of reporting on developments in this area. 

 After the second world war, as the RPS’s membership grew and became more general in its interests, there was a perceived need to separate the scientific content from the more general papers in the main Journal. In 1944 the decision was taken to separate the scientific matter into a new Section B of the Journal, with the first number appearing from Jan/Feb 1945. Section A continued to publish more general features on pictorial photography, reports of members’ meetings, and Society business. An editorial note in the first issue of Section B stated: For some time it has been apparent that the inclusion in The Photographic Journal of purely scientific papers with papers of pictorial or general interest is unsatisfactory both to the pictorial photographer and to the photographic technologist. It has therefore been decided to divide the Journal into two parts: Section A which will contain articles on pictorial and general subjects, and Section B which will contain papers and other matter of purely scientific and technical application. Section B became a separate publication and was renamed the Journal of Photographic Science in 1953, published by the RPS. This remained the case until the 1990s when the Society subcontracted publication to a third party. Today, this role is undertaken by Taylor and Francis, coincidentally the original printer of the RPS’s 1853 Journal.The RPS maintains a run of the Imaging Science Journal and its predecessors at its headquarters in Bristol which are available for public consultation. The Imaging Science Journal has been digitised and is available to subscribers.

References
External links
Official website
Print: ISSN 1368-2199
Online: ISSN 1743-131X",28106767,https://en.wikipedia.org/wiki/The_Imaging_Science_Journal
Journal of Functional Programming,"The Journal of Functional Programming is a peer-reviewed scientific journal covering the design, implementation, and application of functional programming languages, spanning the range from mathematical theory to industrial practice. Topics covered include functional languages and extensions, implementation techniques, reasoning and proof, program transformation and synthesis, type systems, type theory, language-based security, memory management, parallelism and applications. The journal is of interest to computer scientists, software engineers, programming language researchers, and mathematicians interested in the logical foundations of programming. Philip Wadler was editor-in-chief from 1990 to 2004. The journal is indexed in Zentralblatt MATH.
As of 2022, the journal is published as open access: the journal articles are available online without a subscription. Author's institutions are expected to cover the journal costs: as of 2022, the article processing charge is GBP 1,250 per article.","The Journal of Functional Programming is a peer-reviewed scientific journal covering the design, implementation, and application of functional programming languages, spanning the range from mathematical theory to industrial practice. Topics covered include functional languages and extensions, implementation techniques, reasoning and proof, program transformation and synthesis, type systems, type theory, language-based security, memory management, parallelism and applications. The journal is of interest to computer scientists, software engineers, programming language researchers, and mathematicians interested in the logical foundations of programming. Philip Wadler was editor-in-chief from 1990 to 2004. The journal is indexed in Zentralblatt MATH.
As of 2022, the journal is published as open access: the journal articles are available online without a subscription. Author's institutions are expected to cover the journal costs: as of 2022, the article processing charge is GBP 1,250 per article.

See also
International Conference on Functional Programming
Higher-Order and Symbolic Computation

References
External links
Official website",11136078,https://en.wikipedia.org/wiki/Journal_of_Functional_Programming
Probability in the Engineering and Informational Sciences,Probability in the Engineering and Informational Sciences is an international journal published by  Cambridge University Press. The founding Editor-in-chief is  Sheldon M. Ross.,"Probability in the Engineering and Informational Sciences is an international journal published by  Cambridge University Press. The founding Editor-in-chief is  Sheldon M. Ross.

Editors
1987– Sheldon M. Ross.


== References ==",37216377,https://en.wikipedia.org/wiki/Probability_in_the_Engineering_and_Informational_Sciences
The Register,"The Register is a British technology news website co-founded in 1994 by Mike Magee and John Lettice. The online newspaper's masthead sublogo is ""Biting the hand that feeds IT."" The publication's primary focus is information technology news and opinions.
Situation Publishing Ltd is the site's publisher. Drew Cullen is an owner and Linus Birtles is the managing director. Andrew Orlowski was the executive editor before leaving the website in May 2019.","The Register is a British technology news website co-founded in 1994 by Mike Magee and John Lettice. The online newspaper's masthead sublogo is ""Biting the hand that feeds IT."" The publication's primary focus is information technology news and opinions.
Situation Publishing Ltd is the site's publisher. Drew Cullen is an owner and Linus Birtles is the managing director. Andrew Orlowski was the executive editor before leaving the website in May 2019.

History
The Register was founded in London as an email newsletter called Chip Connection. In 1998 The Register became a daily online news source. Magee left in 2001 to start competing publications The Inquirer, and later the IT Examiner and TechEye.In 2002, The Register expanded to have a presence in London and San Francisco, creating The Register USA at theregus.com through a joint venture with Tom's Hardware. In 2003, that site moved to theregister.com. That content was later merged onto theregister.co.uk. The Register carries syndicated content including Simon Travaglia's BOFH stories.In 2010 The Register supported the successful launch of the Paper Aircraft Released into Space, a project they announced in 2009 that released a paper plane in the extreme upper atmosphere.The Register also ran the websites Register Hardware and Channel Register, which merged into The Register.

Readership and content
In 2011 it was read daily by over 350,000 users according to the Audit Bureau of Circulations, rising to 468,000 daily and nearly 9.5 million monthly in 2013. In November 2011 the UK and US each accounted for approximately 42% and 34% of page impressions respectively, with Canada being the next most significant origin of page hits at 3%. In 2012 the UK and US accounted for approximately 41% and 28% of page impressions respectively, with Canada at 3.61%.Channel Register covers computer business and trade news, which includes business press releases. News and articles for computer hardware and consumer electronics are covered by Reg Hardware. Reg Research is an in-depth resource on technologies and how they relate to business.Their stories are cited by major news sources and also used for backup information. Stories in other periodicals were based on their exposés. For instance, InformationWeek ran a story about The Register's story, as used as the source for a New York Times article.In September 2018, the Alexa ranking was #7,194.National Archives and Records Administration has  archived part of the Web site.

Writers
The Register has an editorial staff of 16 writers and production experts. Chris Williams is editor-in-chief. Paul Kunert is UK editor, Iain Thomson is US news editor and Simon Sharwood is Asia-Pacific editor. Columnists include Mark Pesce and Rupert Goodwins.

Intel chips flaw investigation
On 6 February 2017, The Register was the first news outlet to accurately trace a recently discovered flaw in Cisco (and other makers) gear to a serious defect on Intel's Atom C2000 series processors.

Around 3 January 2018, The Register broke news about Google's long-ongoing investigation into Intel's processor design, which revealed that a serious flaw in the design of their chips would require Microsoft, Apple, and Linux developers to release patches for their operating systems.

Criticism
On 12 October 2010 Martin Robbins of The Guardian accused The Register of misunderstanding climate science and misrepresenting a paper from the journal Nature in a manner that deliberately minimized the climate impact of human emissions. The Register published its ""amusingly put-out 'response'"" the same day.

References
External links
Official website 
""Archive of articles about Wikipedia"". The Register.",47089,https://en.wikipedia.org/wiki/The_Register
UK & Ireland SAP Users Group,The UK and Ireland SAP Users Group is an independent not-for-profit organisation for users of the SAP ERP software.,"The UK and Ireland SAP Users Group is an independent not-for-profit organisation for users of the SAP ERP software.

History
The group was formed in 1988 by a small group of enthusiastic SAP users from organisations based in the UK and Ireland who wanted to share and exchange experiences gained while implementing and using software sold by SAP AG. Since it was established it has grown from representing less than 20 organisations to well over 620.
In 2002, under the leadership of its then Chairman, Glynn Lowth, it appointed its first full-time employed member of staff, and began to put in place a new infrastructure to support its membership. In 2004 a new website was launched that for the first time allowed members to collaborate and work together on line. In 2005 the User Group set up a full-time office in Billingham, Teesside where there are now 10 full-time employees.
After a gap of around 10 years, in 2006, it held a new annual conference in Birmingham attended by over 600 users. Further conferences were held in 2007 (Birmingham) and 2008 (London). In 2009 the group took its annual conference to Manchester for the first time, which was the largest independent SAP conference to date. For 2010, Manchester was again the venue and the conference was a three-day event for the first time. In 2012, the Business Objects User Group in the UK merged with it.
In 2013, Alan Bowling, Chairman for 6 years, stood down after leading the organisation through a period of sustained growth and influence, to be succeeded by Philip Adams, the first Chairman from an Irish member organisation. In 2013, the conference returned to Birmingham to celebrate 25 years as a voluntary organisation, with the event attended by over 1,000 people, including the Co-CEO of SAP, Jim Snabe. In 2014, the conference is hosted at the Birmingham ICC. In 2007, the UK & Ireland SAP User Group was one of the founding User Group of SUGEN (SAP User Group Executive Network), and now forms an active part of SUGEN  activities. It is the recognised official group representing all SAP product Users within the United Kingdom and Ireland.

Key Aims of the User Group
•To facilitate networking and knowledge exchange amongst members,
•To provide an independent voice for SAP users in the UK and Ireland,
•To maintain and develop our close and influential relationship with SAP
•To add value to individuals and organisations, as a member of the user group

Facts and Figures
Over 620 member organisations based in UK and Ireland.
Over 5500 individuals from member organisations attended meetings in 2013.
Organisations come from private, public and charitable sectors.
17 Special Interest Groups which each meet at least three times a year:
Audit Control & Security (ACS),
Business One,
Business Intelligence/Business Warehouse (BI/BW),
Customer Relationship Management (CRM),
Finance,
Human Resources,
IE (Irish) Payroll,
Implementation & Support,
Ireland,
Maintenance & Service Management (MSM),
Payroll,
Project Systems,
Retail,
Supply Chain Management (SCM),
Scotland,
Testing,
Training.


== References ==",21719542,https://en.wikipedia.org/wiki/UK_%26_Ireland_SAP_Users_Group
UKUUG,"UKUUG is the UK's Unix and Open Systems User Group a non-profit organization and technical forum for the advocacy of open systems, particularly Unix and Unix-like operating systems, the promotion of Free and Open Source Software (FOSS), and the advancement of open programming standards and networking protocols.
In 2010 the name has been changed to FLOSS UK, along with a change of web domain.","UKUUG is the UK's Unix and Open Systems User Group a non-profit organization and technical forum for the advocacy of open systems, particularly Unix and Unix-like operating systems, the promotion of Free and Open Source Software (FOSS), and the advancement of open programming standards and networking protocols.
In 2010 the name has been changed to FLOSS UK, along with a change of web domain.

See also
EFF
FSF
Online Rights Canada

External links
Official website


== References ==",3431130,https://en.wikipedia.org/wiki/UKUUG
Computational neuroaesthetics,"Computational neuroaesthetics is the discipline that connects neuromarketing, psychology and computer science. It represents the evolution of neuroaesthetics and computational aesthetics and investigates the brain processes of human beings involved during the aesthetic experience.
In pursuing this research objective it uses a methodology that integrates the methods and techniques which are typical of neuroscience with those typical of computational science. The visual stimuli observed by people, such as images, are computationally processed to obtain a numerical value of the aesthetic features, such as brightness and hues, which are related to the brain processes of the subjects. In doing so, computational neuroaesthetics overcomes the limits of computational aesthetics, which uses only classical measuring instruments, such as self report scales, to assess the positive emotions experienced by individuals.","Computational neuroaesthetics is the discipline that connects neuromarketing, psychology and computer science. It represents the evolution of neuroaesthetics and computational aesthetics and investigates the brain processes of human beings involved during the aesthetic experience.
In pursuing this research objective it uses a methodology that integrates the methods and techniques which are typical of neuroscience with those typical of computational science. The visual stimuli observed by people, such as images, are computationally processed to obtain a numerical value of the aesthetic features, such as brightness and hues, which are related to the brain processes of the subjects. In doing so, computational neuroaesthetics overcomes the limits of computational aesthetics, which uses only classical measuring instruments, such as self report scales, to assess the positive emotions experienced by individuals.

Areas of application
The results that emerge from computational neuroaesthetics research can be applied in several areas. The privileged one is the field of marketing and communication, since it is possible to know which aesthetic characteristics an advertising stimulus should have to be appreciated at a deep and implicit level by consumers. These positive reactions are a factor that influences the orientation of people towards the products and the brands that are promoted.Another area of application is design and user experience design. In fact, the aesthetics of products and phygital interfaces is a fundamental component for user experience. Computational neuroaesthetics offers useful knowledge to develop a design that respects those aesthetic parameters which are able to improve user experience. Products and services with good UX levels are perceived as better and easier to use by consumers.In the fields of health and well-being psychology, the knowledge of this discipline represents a potential tool able to build positive and transformative aesthetic experiences which could promote patients' engagement.

Origins
Aesthetics is a discipline that, within the psychological field, has been studied over the decades by different approaches, including the gestalt and cognitivist ones. In 2005, Chatterjee, stressed the need to use a research approach able to integrate neuroaesthetics with an analytical description of the features of visual stimuli in order to obtain quantifiable parameters.


== References ==",66105247,https://en.wikipedia.org/wiki/Computational_neuroaesthetics
Computational politics,"Computational politics is the intersection between computer science and political science. The area involves the usage of computational methods, such as analysis tools and prediction methods, to present the solutions to political sciences questions. Researchers in this area use large sets of data to study user behavior. Common examples of such works are building a classifier to predict users' political bias in social media or finding political bias in the news. This discipline is closely related with digital sociology. However, the main focus of computational politics is on political related problems and analysis.
Computational politics is often used in political campaigns to target individuals for advertising purposes.","Computational politics is the intersection between computer science and political science. The area involves the usage of computational methods, such as analysis tools and prediction methods, to present the solutions to political sciences questions. Researchers in this area use large sets of data to study user behavior. Common examples of such works are building a classifier to predict users' political bias in social media or finding political bias in the news. This discipline is closely related with digital sociology. However, the main focus of computational politics is on political related problems and analysis.
Computational politics is often used in political campaigns to target individuals for advertising purposes.

Methods and applications
While there is no clearly defined data source for research done in computational politics, the most common sources are social networking websites and political debate transcripts. Various methods are used to computationally model the behavior of agents. Social network analysis is often used to model and analyze data from social networking sites, with nodes on a graph representing individual users and edges representing varying forms of interaction between users. Natural language processing methods are used for text-based data, such as text from social media posts and political debate transcripts. For example, sentiment analysis, where algorithms are used to classify a piece of text as positive, negative, or neutral in sentiment, can be used to predict social media users' opinions on political parties or candidates. Various other machine learning algorithms are used to predict political bias in news sources, political affiliation of users of social networks, and whether political news articles are fake news or not. Computational models are often used to examine cognitive behavior associated with political contexts, including the connection between the brain and polarization or ideological thinking.

Usage in political campaigns
The discipline of computational politics has emerged with growing use of social media and recent breakthroughs in computational methods. Social media has provided scientific researchers and campaign strategists with an unprecedented scale of latent, user-generated data, and there have been recent developments in computer science to store and manage large collections of data. Computational politics represents a large shift in political science research, as lots of information can be efficiently collected on individuals rather than aggregates. This information can be used to effectively target likely voters. One of the first political campaigns to use computational politics was Barack Obama's 2012 campaign. An example of a data source used in the campaign was user data from a Facebook App created for it. The campaign developed a ""likelihood of turnout"" index to focus turning out voters who were already likely to prefer Obama. Since then, there has been a growing number of political data firms, which are private companies that sell voter registration tied to consumer data. One such data firm is i360, which is funded by the Koch brothers. Numerous clients of i360 saw victories in the 2014 United States Midterm Elections.

Criticism
Campaign strategies relating to computational politics have been met with criticism. Some researchers raise concerns about voter privacy that come with new methods of targeting individual voters, as there is a lack of regulation surrounding protection of consumer data in the United States. They highlight the information asymmetry that comes with the large amount of data that campaigns have concerning individual voters, while the voters don't know exactly what the campaigns are doing with their information. According to these researchers, the black box nature of the algorithms that handle voter data exacerbate this issue, as it is difficult to understand how data is being processed by the algorithms. Zeynep Tufekci, professor and sociologist, believes the information asymmetry caused by recent developments in computational politics will harm political discourse in the public sphere, particularly in interactions between political campaigns and voters, as ideas may be weighted less heavily for their own merit and more heavily based on who presents the idea, given the information political campaigns have on their potential voters. These researchers also address the issues of discrimination that are rising with computational politics, as individuals who are predicted by models to be less likely to vote could be ignored in political marketing and outreach entirely. Tufecki states that political campaigns can present different advertisements based on which messages the potential voter is likely to be sympathetic to, allowing politicians to base their platform off of small issues that will efficiently mobilize niche groups of voters, while less focus may be spent on larger, more broadly important issues. Kwame Akosah, a voting rights advocate, writes that algorithms can be used to discriminate against protected classes. Additionally, he states that the knowledge of individuals being tracked by data brokers can create a chilling effect in political discourse. Interdisciplinary researcher Ashu M.G. Solo points out that a positive aspect of computational politics is that it will lead to a more efficient use of spending in political campaigns. Polarisation and privacy have been well-discussed issues in this domain, however, the massive adaptability of social media platforms has attracted the organised use of social media for opinion engineering during crisis, as seen in Russia-Ukraine 2022 or natural crisis like COVID-19 pandemic. Such use of social media is associated with Information warfare and has raised questions on the ethics and regulation of data ownership, fair algorithms, and the use of jury based methods for the content moderation.


== References ==",61580753,https://en.wikipedia.org/wiki/Computational_politics
Creative computing,"Creative computing covers the interdisciplinary area at the cross-over of the creative arts and computing. Issues of creativity include knowledge discovery, for example.","Creative computing covers the interdisciplinary area at the cross-over of the creative arts and computing. Issues of creativity include knowledge discovery, for example.

Overview
The International Journal of Creative Computing describes creative computing as follows:
Creative computing refers to a meta-technology to coalesce knowledge in computing and other disciplines.  People use computers as aids to creativity and creative-computing topics may reshape the world as we know it. Applications are seen in arts, entertainment/games, mobile applications, multimedia, product/web design and other interactive systems.
Creative computing is interdisciplinary in nature and topics relating to it include applications, development method, evaluation, modeling, philosophy, principles, support environment, and theory.The term ""creative computing"" is used both in the United Kingdom and the United States (e.g., at Harvard University and MIT).

Degree programmes
A number of university degree (Bachelor's degree) programmes in Creative Computing exist, for example at:

University of the Arts London
Queen's University
University of West London
St. Pölten University of Applied Sciences
Bath Spa University
Falmouth University
Goldsmiths, University of London
Queen Mary, University of London
Wrexham Glyndŵr University
Dún Laoghaire Institute of Art, Design and Technology
Leeds Beckett University, the programme is named as BSc (Hons) Creative Media Technology
University of Portsmouth, the programme is named as BSc (Hons) Creative Media Technologies
City University of Hong Kong, the programme is named as Bachelor of Science in Creative Media, jointly offered by the School of Creative Media and the Department of Computer Science
Technological and Higher Education Institute of Hong Kong, the programme is named as Bachelor of Science (Honours) Multimedia Technology and Innovation
Hong Kong Metropolitan University, the programme is named as Bachelor of Arts with Honours in Computing and Interactive Entertainment
Caritas Institute of Higher Education, the programme is named as Bachelor of Science (Honours) in Digital Entertainment Technology
Sogang University, (Seoul), the programme is offered by Department of Art & TechnologyMaster's degree programmes:

City University of Hong Kong, the programme is named as Master of Arts in Creative Media (MACM)
Hong Kong Polytechnic University, the programme is named as Multimedia & Entertainment Technology (MSc)
The Hong Kong University of Science and Technology, the programme is named as Master of Philosophy and Doctor of Philosophy Programs in Computational Media and Arts
Sogang University, (Seoul), the programme is offered by Department of Art & Technology

Journal
The International Journal of Creative Computing is a quarterly peer-reviewed scientific journal published by Inderscience Publishers, covering creativity in computing and the other way around. The editor-in-chief is Andy M. Connor  (Auckland University of Technology).
The journal was established in 2013 and is abstracted and indexed in CSA, ProQuest, and DBLP databases. The journal is currently in the process of recruiting a new Editorial Board for re-launch in 2021.

See also
Creative coding
Computer art


== References ==",49870344,https://en.wikipedia.org/wiki/Creative_computing
Developer relations,"Developer relations, abbreviated as DevRel, is an umbrella term within the realm of software engineering, covering the strategies for building mutually beneficial relationships between organizations and developers as the primary users, and often influencers on purchases, of a product. Developer relations is a form of platform evangelism and the activities involved are sometimes referred to as a developer program or DevRel program. A DevRel program may comprise a framework built around some or all of the following aspects:
Developer marketing: Outreach and engagement activities to create awareness and convert developers to use a product.
Developer education: Product documentation and education resources to aid learning and build affinity with a product and community.
Developer experience: Resources like a developer portal, product, and documentation, to activate the developer with the least friction.
Developer success: Activities to nurture and retain developers as they build and scale with a product.
Community: Nourishes a community to maintain a sustainable program.","Developer relations, abbreviated as DevRel, is an umbrella term within the realm of software engineering, covering the strategies for building mutually beneficial relationships between organizations and developers as the primary users, and often influencers on purchases, of a product. Developer relations is a form of platform evangelism and the activities involved are sometimes referred to as a developer program or DevRel program. A DevRel program may comprise a framework built around some or all of the following aspects:
Developer marketing: Outreach and engagement activities to create awareness and convert developers to use a product.
Developer education: Product documentation and education resources to aid learning and build affinity with a product and community.
Developer experience: Resources like a developer portal, product, and documentation, to activate the developer with the least friction.
Developer success: Activities to nurture and retain developers as they build and scale with a product.
Community: Nourishes a community to maintain a sustainable program.

History and roots
Apple is considered to have created the first DevRel program in the 1980s, starting with Mike Murray, who coined the term software evangelist to persuade third-party developers to develop software and applications for the Macintosh platform. Mike Boich was Apple's first Software Evangelist for the Macintosh project  and hired Guy Kawasaki who would become Apple's Chief Evangelist and popularize their DevRel program.
DevRel started becoming more mainstream in 2013, with companies like New Relic, Twilio, EngineYard, and SendGrid popularizing a Developer-First approach.

Organizational roles
Roles and job titles
DevRel theoretically intersects engineering, marketing, product management, and community management.There are several different types of roles/job titles in DevRel including:

Developer Advocates (aka Developer Evangelists): Focus on getting the word out (i.e., evangelizing) through various means such as speaking at conferences, attending meetups, hosting hackathons, creating code samples, building webinars, hosting virtual office hours and/or advocating by acting as a liaison between the community and internal product teams. They likely have coding experience and may collect feedback, create demos/code samples, or find solutions to issues with the product.
Developer Experience (DX) Practitioners: Own user experience initiatives for products developers use. DX encompasses both products and documentation, and DX practitioners may deal with SDK or API design, onboarding flows, and documentation.
Technical Community Managers: Community managers who focus on conversations of a technical nature, about technical aspects of a product. They may identify and track opportunities for Developer Advocacy teams to educate and inspire their peer developers.
Developer Marketers: Target and capture software developers' attention to grow awareness, adoption and advocacy of tools, solutions, and platforms. They focus on solving real-world problems by providing solutions to help developers improve their workflows and increase development efficiency. They also facilitate developer advocacy by empowering and evangelizing developers to champion a target product.
Technical Writers: Technical writers produce content such as online help, manuals, white papers, etc. A technical writer is often considered a DevRel role.

Report structure
DevRel practitioners may report to different groups within an organization – both technical and non-technical. A survey in 2021, showed that the report structure of companies was marketing: 26.2%, combined non-technical departments (marketing, sales, and business development): 30.7%, and combined technical departments (product, engineering, and CTO): 44.1%.

Salary structure
Annual salaries for DevRel practitioners vary from less than US$50,000 to over $250,000 in some cases. A survey from 2021 indicates that the largest segment of annual salaries was between $100,000 and $150,000.

Companies practicing DevRel
Developer-first versus developer-plus companies
Organizations which practice DevRel may be Developer-first or Developer-plus (aka Dev +) depending on their primary business model. Developer-First companies (e.g., Stripe, Camunda, PerceptiLabs, Unity, and Twilio) have a business-to-developer model (B2D) focused on selling products specifically designed to be used by developers. Developer-Plus companies (e.g., Slack, Spotify, Apple, Qualcomm, and Santander) tend to be business-to-business (B2B) or business-to-consumer (B2C). While the primary focus of Developer-Plus companies is to create and sell products for businesses or consumers, they also make products or services available to developers which benefit or enhance their strategy including: opening new market channels, creating new use cases, contributing to innovation strategies, or optimizing/enhancing existing products.In 2021, a survey showed that 63.6% of organizations with DevRel programs were Developer-Plus, and 36.4% were Developer-First.

Developer influence and market sizing
Regardless of Developer-Plus or Developer-First, companies are recognizing the growing power developers have in influencing purchasing decisions. This includes new companies focused on making tools for developers, and existing companies whose primary focus was elsewhere, which are now recognizing the developer opportunity. Thus, business leaders are now involved in starting new DevRel programs at their companies or increasing the impact of their existing programs.Products or services targeted at developers comprise an estimated $49 billion (in 2021) Developer-Led landscape that spans many categories including:
Software Delivery Lifecycle (SDLC): SDLC solutions for processes such as designing, developing, and testing software.
Dev Tools: Tools for building software.
Dev Infrastructure: Hardware and software that support the distributed, repeatable construction of software.
Dev Platforms: Developer-interfacing, code-first, and API-only runtimes.Twilio, is an example of a Developer-First company, and more specifically an API-first company, that helped to shape the API economy (business models and practices designed around APIs), popularize DevRel programs, and became known for platform evangelism. Notably, their three-word billboard in Silicon Valley that simply said: ""Ask Your Developer"", followed by the Twilio logo, is credited with having started conversations between executives and developers in strategic decision making.

Breakdown by region
DevRel initiatives are practiced by organizations around the globe. In 2021, the breakdown of companies practicing DevRel globally were primarily in North America (Canada and the US – 61.5%) and Europe (Eastern Europe, Western Europe, and the UK – 21.6%). Other countries/regions include Australia/New Zealand, China, India, and the Middle East.

Breakdown by industries
While DevRel is primarily prevalent in IT/IS it is also used in other industries. The general breakdown in 2021 was:
Information Technology/Services 44.6%
SaaS 20.5%
Telecom 6.2%
Financial services 7.7%

Professional events
DevRelCon is an annual DevRel event that has been hosted by hoopy.io since 2015. It covers DevRel, DX, community, and developer marketing, and has been held in various cities around the world including London, Tokyo, and San Francisco.DevRelCon's DevRel Awards celebrate the best of developer relations by highlighting individuals, teams, and initiatives driving developer advocacy, marketing, community, education, and experience.


== References ==",50468959,https://en.wikipedia.org/wiki/Developer_relations
Reactive synthesis,"Reactive synthesis (or temporal synthesis) is the field of computer science that studies automatic generation of state machines (e.g. Moore machines) from high-level specifications (e.g. formulas in linear temporal logic). ""Reactivity"" highlights the fact that the synthesized machine interacts with the user, reading an input and producing an output, and never stops its operation.
The synthesis problem was introduced by Alonzo Church in 1962, with specifications being formulas in monadic second-order logic and state machines in the form of digital circuits.","Reactive synthesis (or temporal synthesis) is the field of computer science that studies automatic generation of state machines (e.g. Moore machines) from high-level specifications (e.g. formulas in linear temporal logic). ""Reactivity"" highlights the fact that the synthesized machine interacts with the user, reading an input and producing an output, and never stops its operation.
The synthesis problem was introduced by Alonzo Church in 1962, with specifications being formulas in monadic second-order logic and state machines in the form of digital circuits.

See also
Program synthesis
Model checking


== References ==",60078637,https://en.wikipedia.org/wiki/Reactive_synthesis
Spatial computing,"Spatial computing is any of various human–computer interaction techniques that are perceived by users as taking place in the real world, in and around their natural bodies and physical environments, instead of constrained to and perceptually behind computer screens. This concept inverts the long-standing practice of teaching people to interact with computers in digital environments, and instead teaches computers to better understand and interact with people more naturally in the human world. This concept overlaps with others including extended reality, augmented reality, mixed reality, natural user interface, contextual computing, affective computing, and ubiquitous computing. The usage for labeling and discussing these adjacent technologies is imprecise.Spatial computers typically include sensors—such as RGB cameras, depth cameras, 3D trackers, inertial measurement units, or other tools—to sense and track nearby human bodies (including hands, arms, eyes, legs, mouths) during ordinary interactions with people and computers in a 3D space. They further use computer vision (AI / ML) to attempt to understand real world scenes, such as rooms, streets or stores, to read labels, to recognize objects, create 3D maps, and more. Quite often they also use XR and MR to superimpose virtual 3D graphics and virtual 3D audio onto the human visual and auditory system as a way of providing information more naturally and contextually than traditional 2D screens.
Spatial computing does not technically require any visual output. For example, an advanced pair of headphones, using an inertial measurement unit and other contextual cues could qualify as spatial computing, if the device made contextual audio information available spatially, as if the sounds consistently existed in the space around the headphones' wearer. Smaller internet of things devices, like a robot floor cleaner, would be unlikely to be referred to as a spatial computing device because it lacks the more advanced human-computer interactions described above.
Spatial computing often refers to personal computing devices like headsets and headphones, but other human-computer interactions that leverage real-time spatial positioning for displays, like projection mapping or cave automatic virtual environment displays, can also be considered spatial computing if they leverage human-computer input for the participants.","Spatial computing is any of various human–computer interaction techniques that are perceived by users as taking place in the real world, in and around their natural bodies and physical environments, instead of constrained to and perceptually behind computer screens. This concept inverts the long-standing practice of teaching people to interact with computers in digital environments, and instead teaches computers to better understand and interact with people more naturally in the human world. This concept overlaps with others including extended reality, augmented reality, mixed reality, natural user interface, contextual computing, affective computing, and ubiquitous computing. The usage for labeling and discussing these adjacent technologies is imprecise.Spatial computers typically include sensors—such as RGB cameras, depth cameras, 3D trackers, inertial measurement units, or other tools—to sense and track nearby human bodies (including hands, arms, eyes, legs, mouths) during ordinary interactions with people and computers in a 3D space. They further use computer vision (AI / ML) to attempt to understand real world scenes, such as rooms, streets or stores, to read labels, to recognize objects, create 3D maps, and more. Quite often they also use XR and MR to superimpose virtual 3D graphics and virtual 3D audio onto the human visual and auditory system as a way of providing information more naturally and contextually than traditional 2D screens.
Spatial computing does not technically require any visual output. For example, an advanced pair of headphones, using an inertial measurement unit and other contextual cues could qualify as spatial computing, if the device made contextual audio information available spatially, as if the sounds consistently existed in the space around the headphones' wearer. Smaller internet of things devices, like a robot floor cleaner, would be unlikely to be referred to as a spatial computing device because it lacks the more advanced human-computer interactions described above.
Spatial computing often refers to personal computing devices like headsets and headphones, but other human-computer interactions that leverage real-time spatial positioning for displays, like projection mapping or cave automatic virtual environment displays, can also be considered spatial computing if they leverage human-computer input for the participants.

History
The term apparently originated in the field of GIS around 1985 or earlier to describe computations on large-scale geospatial information. This is somewhat related to the modern use, but on the scale of continents, cities, and neighborhoods. Modern spatial computing is more centered on the human scale of interaction, around the size of a living room or smaller. But it is not limited to that scale in the aggregate.
In the early 1990s, as field of Virtual reality was beginning to be commercialized beyond academic and military labs, a startup called Worldesign in Seattle used the term Spatial Computing to describe the interaction between individual people and 3D spaces, operating more at the human end of the scale than previous GIS examples may have contemplated. The company built a CAVE-like environment it called the Virtual Environment Theater, whose 3D experience was of a virtual flyover of the Giza Plateau, circa 3000 BC. Robert Jacobson, CEO of Worldesign, attributes the origins of the term to experiments at the Human Interface Technology Lab, at the University of Washington, under the direction of Thomas A. Furness III. Jacobson was a co-founder of that lab before spinning off this early VR startup.
In 1997, an academic publication by T. Caelli, Peng Lam, and H. Bunke called ""Spatial Computing: Issues in Vision, Multimedia and Visualization Technologies"" introduced the term more broadly for academic audiences.The specific term ""spatial computing"" was later referenced again in 2003 by Simon Greenwold, as ""human interaction with a machine in which the machine retains and manipulates referents to real objects and spaces"". MIT Media Lab alumnus John Underkoffler gave a TED talk in 2010 giving a live demo of the multi-screen, multi-user spatial computing systems being developed by Oblong Industries, which sought to bring to life the futuristic interfaces conceptualized by Underkoffler in the films Minority Report and Iron Man.

Products
Apple announced Apple Vision Pro, a device it markets as a “spatial computer” on June 5, 2023. It features several features such as Spatial Audio, two 4K micro-OLED displays, the Apple R1 chip and eye tracking, and released in the United States on February 2, 2024. In announcing the platform, Apple invoked its history of popularizing 2D graphical user interfaces that supplanted prior human-computer interface mechanisms such as the command line. Apple suggests the introduction of spatial computing as a new category of interactive device, on the same level of importance as the introduction of the 2D GUI.
Magic Leap had also previously used the term “spatial computing” to describe its own devices, starting with the Magic Leap 1. Their use seems consistent with Apple's, although the company did not continue using the term in the long term.Meta Platforms famously used the term “metaverse” to describe its future plans. The key difference between that and spatial computing is that the latter does not imply the vast inter-networking of sites into a common fabric, akin to a 3D version of the internet. Spatial computing can be conducted by one person, two people, or a small number of people with their local computer systems without regard to the greater network of other users and spaces. As such, it may serve to minimize (but not completely eliminate) many of the negative aspects found in large-scale on-line social interactions such as Griefing and other harassment by adding social accountability and better social perception in known groups.

Understanding Key Ideas
3D Thinking: Spatial computing involves visualizing and manipulating information within three-dimensional space. Instead of working with flat files and interfaces, users can interact with digital models, simulations, and virtual environments that feel almost tangible.
The Environment as Interface: Cameras, sensors, and advanced software allow spatial computing systems to understand the real world. Users' movements, the layout of a room, and even the objects around them can be incorporated into the digital experience.
Breaking Input Boundaries: Keyboards and mice give way to natural gestures, voice commands, eye-tracking, and controllers that sense their position within space.

Technologies That Make It Possible
Spatial computing isn't about a single device, but a convergence of different technologies:

Augmented Reality (AR): Overlays digital content on the real world through devices like smartphones or specialized headsets.
Virtual Reality (VR): Creates fully immersive digital environments, often through headsets.
Mixed Reality (MR): A more advanced blending of AR and VR where digital objects interact realistically with the physical environment.
Computer Vision and Sensors: Enable devices to 'see' and understand the world around them.
Artificial Intelligence (AI): Helps process spatial data, recognize objects, and make real-time adaptations in a spatial computing experience.

Where Spatial Computing Is Making a Difference
This field is still evolving, but its potential is vast:

Industry: Design, manufacturing, and training are transformed with 3D models and spatial instructions.
Retail: Interactive product experiences and location-based guidance enhance shopping
Medicine: Spatial models improve surgical planning, and rehabilitation can become more engaging.
Architecture: Virtual tours of buildings, and real-time on-site collaboration become possible.
Education: Immersive environments provide new ways to learn through simulations and exploration.
Entertainment: Gaming grows more interactive, and storytelling can take on an entirely new dimension.

Challenges and Future Directions
Technical Limitations: Improvements in hardware performance, power efficiency, and sensor technology are needed for wider adoption and unhindered user experiences.
Hardware Needs: More powerful, lightweight, and less expensive devices are key for widespread adoption.
User Experience (UX): Designing intuitive and seamless spatial computing experiences remains a challenge.
Accessibility: Ensuring that people with disabilities can fully benefit from spatial computing technologies.
Privacy and Security: Addressing concerns related to data collection and potential misuse of information about a user and their surroundings.
Spatial computing is poised to change how we work, learn, and connect. As the technology matures, expect to see it reshape industries and bring even more seamless interactions between ourselves and the digital world.


== References ==",62638470,https://en.wikipedia.org/wiki/Spatial_computing
List of terms relating to algorithms and data structures,"The NIST Dictionary of Algorithms and Data Structures is a reference work maintained by the U.S. National Institute of Standards and Technology. It defines a large number of terms relating to algorithms and data structures. For algorithms and data structures not necessarily mentioned here, see list of algorithms and list of data structures.
This list of terms was originally derived from the index of that document, and is in the public domain, as it was compiled by a Federal Government employee as part of a Federal Government work. Some of the terms defined are:","The NIST Dictionary of Algorithms and Data Structures is a reference work maintained by the U.S. National Institute of Standards and Technology. It defines a large number of terms relating to algorithms and data structures. For algorithms and data structures not necessarily mentioned here, see list of algorithms and list of data structures.
This list of terms was originally derived from the index of that document, and is in the public domain, as it was compiled by a Federal Government employee as part of a Federal Government work. Some of the terms defined are:

A
absolute performance guarantee
abstract data type (ADT)
abstract syntax tree (AST)
(a,b)-tree
accepting state
Ackermann's function
active data structure
acyclic directed graph
adaptive heap sort
adaptive Huffman coding
adaptive k-d tree
adaptive sort
address-calculation sort
adjacency list representation
adjacency matrix representation
adversary
algorithm
algorithm BSTW
algorithm FGK
algorithmic efficiency
algorithmically solvable
algorithm V
all pairs shortest path
alphabet
Alpha Skip Search algorithm
alternating path
alternating Turing machine
alternation
American flag sort
amortized cost
ancestor
and
American National Standards Institute (ANSI)
antichain
antisymmetric relation
AP
Apostolico–Crochemore
Apostolico–Giancarlo algorithm
approximate string matching
approximation algorithm
arborescence
arithmetic coding
array
array index
array merging
array search
articulation point
A* search algorithm
assignment problem
association list
associative
associative array
asymptotically tight bound
asymptotic bound
asymptotic lower bound
asymptotic space complexity
asymptotic time complexity
asymptotic upper bound
augmenting path
automaton
average case
average-case cost
AVL tree
axiomatic semantics

B
backtracking
bag
Baillie–PSW primality test
balanced binary search tree
balanced binary tree
balanced k-way merge sort
balanced merge sort
balanced multiway merge
balanced multiway tree
balanced quicksort
balanced tree
balanced two-way merge sort
BANG file
Batcher sort
Baum Welch algorithm
BB α tree
BDD
BD-tree
Bellman–Ford algorithm
Benford's law
best case
best-case cost
best-first search
biconnected component
biconnected graph
bidirectional bubble sort
big-O notation
binary function
binary fuse filter
binary GCD algorithm
binary heap
binary insertion sort
binary knapsack problem
binary priority queue
binary relation
binary search
binary search tree
binary tree
binary tree representation of trees
bingo sort
binomial heap
binomial tree
bin packing problem
bin sort
bintree
bipartite graph
bipartite matching
bisector
bitonic sort
bit vector
Bk tree
bdk tree (not to be confused with k-d-B-tree)
block
block addressing index
blocking flow
block search
Bloom filter
blossom (graph theory)
bogosort
boogol
boolean
boolean expression
boolean function
bottleneck traveling salesman
bottom-up tree automaton
boundary-based representation
bounded error probability in polynomial time
bounded queue
bounded stack
Bounding volume hierarchy, also referred to as bounding volume tree (BV-tree, BVT)
Boyer–Moore string-search algorithm
Boyer–Moore–Horspool algorithm
bozo sort
B+ tree
BPP (complexity)
Bradford's law
branch (as in control flow)
branch (as in revision control)
branch and bound
breadth-first search
Bresenham's line algorithm
brick sort
bridge
British Museum algorithm
brute-force attack
brute-force search
brute-force string search
brute-force string search with mismatches
BSP-tree
B*-tree
B-tree
bubble sort
bucket
bucket array
bucketing method
bucket sort
bucket trie
buddy system
buddy tree
build-heap
Burrows–Wheeler transform (BWT)
busy beaver
Byzantine generals

C
cactus stack
Calculus of Communicating Systems (CCS)
calendar queue
candidate consistency testing
candidate verification
canonical complexity class
capacitated facility location
capacity
capacity constraint
Cartesian tree
cascade merge sort
caverphone
Cayley–Purser algorithm
C curve
cell probe model
cell tree
cellular automaton
centroid
certificate
chain (order theory)
chaining (algorithm)
child
Chinese postman problem
Chinese remainder theorem
Christofides algorithm
Christofides heuristic
chromatic index
chromatic number
Church–Turing thesis
circuit
circuit complexity
circuit value problem
circular list
circular queue
clique
clique problem
clustering (see hash table)
clustering free
coalesced hashing
coarsening
cocktail shaker sort
codeword
coding tree
collective recursion
collision
collision resolution scheme
Colussi
combination
comb sort
Communicating Sequential Processes
commutative
compact DAWG
compact trie
comparison sort
competitive analysis
competitive ratio
complement
complete binary tree
complete graph
completely connected graph
complete tree
complexity
complexity class
computable
concave function
concurrent flow
concurrent read, concurrent write
concurrent read, exclusive write
configuration
confluently persistent data structure
conjunction
connected components
connected graph
co-NP
constant function
continuous knapsack problem
Cook reduction
Cook's theorem
counting sort
covering
CRCW
Crew (algorithm)
critical path problem
CSP (communicating sequential processes)
CSP (constraint satisfaction problem)
CTL
cuckoo hashing
cuckoo filter
cut (graph theory)
cut (logic programming)
cutting plane
cutting stock problem
cutting theorem
cut vertex
cycle sort
cyclic redundancy check (CRC)

D
D-adjacent
DAG shortest paths
Damerau–Levenshtein distance
data structure
decidable
decidable language
decimation
decision problem
decision tree
decomposable searching problem
degree
dense graph
depoissonization
depth
depth-first search (DFS)
deque
derangement
descendant (see tree structure)
deterministic
deterministic algorithm
deterministic finite automata string search
deterministic finite automaton (DFA)
deterministic finite state machine
deterministic finite tree automaton
deterministic pushdown automaton (DPDA)
deterministic tree automaton
Deutsch–Jozsa algorithm
DFS forest
DFTA
diagonalization argument
diameter
dichotomic search
dictionary (data structure)
diet (see discrete interval encoding tree below)
difference (set theory)
digital search tree
digital tree
digraph
Dijkstra's algorithm
diminishing increment sort
dining philosophers
direct chaining hashing
directed acyclic graph (DAG)
directed acyclic word graph (DAWG)
directed graph
discrete interval encoding tree
discrete p-center
disjoint set
disjunction
distributed algorithm
distributional complexity
distribution sort
divide-and-conquer algorithm
divide and marriage before conquest
division method
data domain
don't-care term
Doomsday rule
double-direction bubble sort
double-ended priority queue
double hashing
double left rotation
Double Metaphone
double right rotation
double-ended queue
doubly linked list
dragon curve
dual graph
dual linear program
dyadic tree
dynamic array
dynamic data structure
dynamic hashing
dynamic programming
dynamization transformation

E
edge
eb tree (elastic binary tree)
edge coloring
edge connectivity
edge crossing
edge-weighted graph
edit distance
edit operation
edit script
8 queens
elastic-bucket trie
element uniqueness
end-of-string
epidemic algorithm
Euclidean algorithm
Euclidean distance
Euclidean Steiner tree
Euclidean traveling salesman problem
Euclid's algorithm
Euler cycle
Eulerian graph
Eulerian path
exact string matching
EXCELL (extendible cell)
exchange sort
exclusive or
exclusive read, concurrent write (ERCW)
exclusive read, exclusive write (EREW)
exhaustive search
existential state
expandable hashing
expander graph
exponential
extended binary tree
extended Euclidean algorithm
extended k-d tree
extendible hashing
external index
external memory algorithm
external memory data structure
external merge
external merge sort
external node
external quicksort
external radix sort
external sort
extrapolation search
extremal
extreme point

F
facility location
factor (see substring)
factorial
fast Fourier transform (FFT)
fathoming
feasible region
feasible solution
feedback edge set
feedback vertex set
Ferguson–Forcade algorithm
Fibonacci number
Fibonacci search
Fibonacci tree
Fibonacci heap
Find
find kth least element
finitary tree
finite Fourier transform (discrete Fourier transform)
finite state automaton
finite-state machine
finite state machine minimization
finite-state transducer
first come, first served
first-in, first-out (FIFO)
fixed-grid method
flash sort
flow
flow conservation
flow function
flow network
Floyd–Warshall algorithm
Ford–Bellman algorithm
Ford–Fulkerson algorithm
forest
forest editing problem
formal language
formal methods
formal verification
forward index
fractal
fractional knapsack problem
fractional solution
free edge
free list
free tree
free vertex
frequency count heuristic
full array
full binary tree
full inverted index
fully dynamic graph problem
fully persistent data structure
fully polynomial approximation scheme
function (programming)
function (mathematics)
functional data structure

G
Galil–Giancarlo
Galil–Seiferas
gamma function
GBD-tree
geometric optimization problem
global optimum
gnome sort
goobi
graph
graph coloring
graph concentration
graph drawing
graph isomorphism
graph partition
Gray code
greatest common divisor (GCD)
greedy algorithm
greedy heuristic
grid drawing
grid file
Grover's algorithm

H
halting problem
Hamiltonian cycle
Hamiltonian path
Hamming distance
Harter–Highway dragon
hash function
hash heap
hash table
hash table delete
Hausdorff distance
hB-tree
head
heap
heapify
heap property
heapsort
heaviest common subsequence
height
height-balanced binary search tree
height-balanced tree
heuristic
hidden Markov model
highest common factor
Hilbert curve
histogram sort
homeomorphic
horizontal visibility map
Huffman encoding
Hungarian algorithm
hybrid algorithm
hyperedge
hypergraph

I
Identity function
ideal merge
implication
implies
implicit data structure
in-branching
inclusion–exclusion principle
inclusive or
incompressible string
incremental algorithm
in-degree
independent set (graph theory)
index file
information theoretic bound
in-place algorithm
in-order traversal
in-place sort
insertion sort
instantaneous description
integer linear program
integer multi-commodity flow
integer polyhedron
interactive proof system
interface
interior-based representation
internal node
internal sort
interpolation search
interpolation-sequential search
interpolation sort
intersection (set theory)
interval tree
intractable
introsort
introspective sort
inverse Ackermann function
inverted file index
inverted index
irreflexive
isomorphic
iteration

J
Jaro–Winkler distance
Johnson's algorithm
Johnson–Trotter algorithm
jump list
jump search

K
Karmarkar's algorithm
Karnaugh map
Karp–Rabin string-search algorithm
Karp reduction
k-ary heap
k-ary Huffman encoding
k-ary tree
k-clustering
k-coloring
k-connected graph
k-d-B-tree (not to be confused with bdk tree)
k-dimensional
K-dominant match
k-d tree
key
KMP
KmpSkip Search
knapsack problem
knight's tour
Knuth–Morris–Pratt algorithm
Königsberg bridges problem
Kolmogorov complexity
Kraft's inequality
Kripke structure
Kruskal's algorithm
kth order Fibonacci numbers
kth shortest path
kth smallest element
KV diagram
k-way merge
k-way merge sort
k-way tree

L
labeled graph
language
last-in, first-out (LIFO)
Las Vegas algorithm
lattice (group)
layered graph
LCS
leaf
least common multiple (LCM)
leftist tree
left rotation
left-child right-sibling binary tree also termed first-child next-sibling binary tree, doubly chained tree, or filial-heir chain
Lempel–Ziv–Welch (LZW)
level-order traversal
Levenshtein distance
lexicographical order
linear
linear congruential generator
linear hash
linear insertion sort
linear order
linear probing
linear probing sort
linear product
linear program
linear quadtree
linear search
link
linked list
list
list contraction
little-o notation
Lm distance
load factor (computer science)
local alignment
local optimum
logarithm, logarithmic scale
longest common subsequence
longest common substring
Lotka's law
lower bound
lower triangular matrix
lowest common ancestor
l-reduction

M
Malhotra–Kumar–Maheshwari blocking flow (ru.)
Manhattan distance
many-one reduction
Markov chain
marriage problem (see assignment problem)
Master theorem (analysis of algorithms)
matched edge
matched vertex
matching (graph theory)
matrix
matrix-chain multiplication problem
max-heap property
maximal independent set
maximally connected component
Maximal Shift
maximum bipartite matching
maximum-flow problem
MAX-SNP
Mealy machine
mean
median
meld (data structures)
memoization
merge algorithm
merge sort
Merkle tree
meromorphic function
metaheuristic
metaphone
midrange
Miller–Rabin primality test
min-heap property
minimal perfect hashing
minimum bounding box (MBB)
minimum cut
minimum path cover
minimum spanning tree
minimum vertex cut
mixed integer linear program
mode
model checking
model of computation
moderately exponential
MODIFIND
monotone priority queue
monotonically decreasing
monotonically increasing
Monte Carlo algorithm
Moore machine
Morris–Pratt
move (finite-state machine transition)
move-to-front heuristic
move-to-root heuristic
multi-commodity flow
multigraph
multilayer grid file
multiplication method
multiprefix
multiprocessor model
multiset
multi suffix tree
multiway decision
multiway merge
multiway search tree
multiway tree
Munkres' assignment algorithm

N
naive string search
NAND
n-ary function
NC
NC many-one reducibility
nearest neighbor search
negation
network flow (see flow network)
network flow problem
next state
NIST
node
nonbalanced merge
nonbalanced merge sort
nondeterministic
nondeterministic algorithm
nondeterministic finite automaton
nondeterministic finite-state machine (NFA)
nondeterministic finite tree automaton (NFTA)
nondeterministic polynomial time
nondeterministic tree automaton
nondeterministic Turing machine
nonterminal node
nor
not
Not So Naive
NP
NP-complete
NP-complete language
NP-hard
n queens
nullary function
null tree
New York State Identification and Intelligence System (NYSIIS)

O
objective function
occurrence
octree
odd–even sort
offline algorithm
offset (computer science)
omega
omicron
one-based indexing
one-dimensional
online algorithm
open addressing
optimal
optimal cost
optimal hashing
optimal merge
optimal mismatch
optimal polygon triangulation problem
optimal polyphase merge
optimal polyphase merge sort
optimal solution
optimal triangulation problem
optimal value
optimization problem
or
oracle set
oracle tape
oracle Turing machine
orders of approximation
ordered array
ordered binary decision diagram (OBDD)
ordered linked list
ordered tree
order preserving hash
order preserving minimal perfect hashing
oriented acyclic graph
oriented graph
oriented tree
orthogonal drawing
orthogonal lists
orthogonally convex rectilinear polygon
oscillating merge sort
out-branching
out-degree
overlapping subproblems

P
packing (see set packing)
padding argument
pagoda
pairing heap
PAM (point access method)
parallel computation thesis
parallel prefix computation
parallel random-access machine (PRAM)
parametric searching
parent
partial function
partially decidable problem
partially dynamic graph problem
partially ordered set
partially persistent data structure
partial order
partial recursive function
partition (set theory)
passive data structure
patience sorting
path (graph theory)
path cover
path system problem
Patricia tree
pattern
pattern element
P-complete
PCP theorem
Peano curve
Pearson's hashing
perfect binary tree
perfect hashing
perfect k-ary tree
perfect matching
perfect shuffle
performance guarantee
performance ratio
permutation
persistent data structure
phonetic coding
pile (data structure)
pipelined divide and conquer
planar graph
planarization
planar straight-line graph
PLOP-hashing
point access method
pointer jumping
pointer machine
poissonization
polychotomy
polyhedron
polylogarithmic
polynomial
polynomial-time approximation scheme (PTAS)
polynomial hierarchy
polynomial time
polynomial-time Church–Turing thesis
polynomial-time reduction
polyphase merge
polyphase merge sort
polytope
poset
postfix traversal
Post machine (see Post–Turing machine)
postman's sort
postorder traversal
Post correspondence problem
potential function (see potential method)
predicate
prefix
prefix code
prefix computation
prefix sum
prefix traversal
preorder traversal
primary clustering
primitive recursive
Prim's algorithm
principle of optimality
priority queue
prisoner's dilemma
PRNG
probabilistic algorithm
probabilistically checkable proof
probabilistic Turing machine
probe sequence
Procedure (computer science)
process algebra
proper (see proper subset)
proper binary tree
proper coloring
proper subset
property list
prune and search
pseudorandom number generator
pth order Fibonacci numbers
P-tree
purely functional language
pushdown automaton (PDA)
pushdown transducer
p-way merge sort

Q
qm sort
qsort
quadratic probing
quadtree
quadtree complexity theorem
quad trie
quantum computation
queue
quicksort

R
Rabin–Karp string-search algorithm
radix quicksort
radix sort
ragged matrix
Raita algorithm
random-access machine
random number generation
randomization
randomized algorithm
randomized binary search tree
randomized complexity
randomized polynomial time
randomized rounding
randomized search tree
Randomized-Select
random number generator
random sampling
range (function)
range sort
Rank (graph theory)
Ratcliff/Obershelp pattern recognition
reachable
rebalance
recognizer
rectangular matrix
 rectilinear
rectilinear Steiner tree
recurrence equations
recurrence relation
recursion
recursion termination
recursion tree
recursive (computer science)
recursive data structure
recursive doubling
recursive language
recursively enumerable language
recursively solvable
red–black tree
reduced basis
reduced digraph
reduced ordered binary decision diagram (ROBDD)
reduction
reflexive relation
regular decomposition
rehashing
relation (mathematics)
relational structure
relative performance guarantee
relaxation
relaxed balance
rescalable
restricted universe sort
result cache
Reverse Colussi
Reverse Factor
R-file
Rice's method
right rotation
right-threaded tree
root
root balance
rooted tree
rotate left
rotate right
rotation
rough graph
RP
R+-tree
R*-tree
R-tree
run time

S
saguaro stack
saturated edge
SBB tree
scan
scapegoat tree
search algorithm
search tree
search tree property
secant search
secondary clustering
memory segment
select algorithm
select and partition
selection problem
selection sort
select kth element
select mode
self-loop
self-organizing heuristic
self-organizing list
self-organizing sequential search
semidefinite programming
separate chaining hashing
separator theorem
sequential search
set
set cover
set packing
shadow heap
shadow merge
shadow merge insert
shaker sort
Shannon–Fano coding
shared memory
Shell sort
Shift-Or
Shor's algorithm
shortcutting
shortest common supersequence
shortest common superstring
shortest path
shortest spanning tree
shuffle
shuffle sort
sibling
Sierpiński curve
Sierpinski triangle
sieve of Eratosthenes
sift up
signature
Simon's algorithm
simple merge
simple path
simple uniform hashing
simplex communication
simulated annealing
simulation theorem
single-destination shortest-path problem
single-pair shortest-path problem
single program multiple data
single-source shortest-path problem
singly linked list
singularity analysis
sink
sinking sort
skd-tree
skew-symmetry
skip list
skip search
slope selection
Smith algorithm
Smith–Waterman algorithm
smoothsort
solvable problem
sort algorithm
sorted array
sorted list
sort in-place
sort merge
soundex
space-constructible function
spanning tree
sparse graph
sparse matrix
sparsification
sparsity
spatial access method
spectral test
splay tree
SPMD
square matrix
square root
SST (shortest spanning tree)
stable
stack (data structure)
stack tree
star-shaped polygon
start state
state
state machine
state transition
static data structure
static Huffman encoding
s-t cut
st-digraph
Steiner minimum tree
Steiner point
Steiner ratio
Steiner tree
Steiner vertex
Steinhaus–Johnson–Trotter algorithm
Stirling's approximation
Stirling's formula
stooge sort
straight-line drawing
strand sort
strictly decreasing
strictly increasing
strictly lower triangular matrix
strictly upper triangular matrix
string
string editing problem
string matching
string matching on ordered alphabets
string matching with errors
string matching with mismatches
string searching
strip packing
strongly connected component
strongly connected graph
strongly NP-hard
subadditive ergodic theorem
subgraph isomorphism
sublinear time algorithm
subsequence
subset
substring
subtree
succinct data structure
suffix
suffix array
suffix automaton
suffix tree
superimposed code
superset
supersink
supersource
symmetric relation
symmetrically linked list
symmetric binary B-tree
symmetric set difference
symmetry breaking
symmetric min max heap

T
tail
tail recursion
tango tree
target
temporal logic
terminal (see Steiner tree)
terminal node
ternary search
ternary search tree (TST)
text searching
theta
threaded binary tree
threaded tree
three-dimensional
three-way merge sort
three-way radix quicksort
time-constructible function
time/space complexity
top-down radix sort
top-down tree automaton
top-node
topological order
topological sort
topology tree
total function
totally decidable language
totally decidable problem
totally undecidable problem
total order
tour
tournament
towers of Hanoi
tractable problem
transducer
transition (see finite-state machine)
transition function (of a finite-state machine or Turing machine)
transitive relation
transitive closure
transitive reduction
transpose sequential search
travelling salesman problem (TSP)
treap
tree
tree automaton
tree contraction
tree editing problem
tree sort
tree transducer
tree traversal
triangle inequality
triconnected graph
trie
trinary function
tripartition
Turbo-BM
Turbo Reverse Factor
Turing machine
Turing reduction
Turing transducer
twin grid file
two-dimensional
two-level grid file
2–3 tree
2–3–4 tree
Two Way algorithm
two-way linked list
two-way merge sort

U
unary function
unbounded knapsack problem (UKP)
uncomputable function
uncomputable problem
undecidable language
undecidable problem
undirected graph
uniform circuit complexity
uniform circuit family
uniform hashing
uniform matrix
union
union of automata
universal hashing
universal state
universal Turing machine
universe
unsolvable problem
unsorted list
upper triangular matrix

V
van Emde Boas priority queue
vehicle routing problem
Veitch diagram
Venn diagram
vertex
vertex coloring
vertex connectivity
vertex cover
vertical visibility map
virtual hashing
visibility map
visible (geometry)
Viterbi algorithm
VP-tree
VRP (vehicle routing problem)

W
walk
weak cluster
weak-heap
weak-heap sort
weight-balanced tree
weighted, directed graph
weighted graph
window
witness
work-depth model
work-efficient
work-preserving
worst case
worst-case cost
worst-case minimum access
Wu's line algorithm

X
Xiaolin Wu's line algorithm
xor
Xor filter

Y
Yule–Simon distribution

Z
Zeller's congruence
0-ary function
0-based indexing
0/1 knapsack problem
Zhu–Takaoka string matching algorithm
Zipfian distribution
Zipf's law
Zipper (data structure)
Zip tree
ZPP


== References ==",723738,https://en.wikipedia.org/wiki/List_of_terms_relating_to_algorithms_and_data_structures
Proof of space,"Proof of space (PoS) is a type of consensus algorithm achieved by demonstrating one's legitimate interest in a service (such as sending an email) by allocating a non-trivial amount of memory or disk space to solve a challenge presented by the service provider. The concept was formulated in 2013 by Dziembowski et al. and (with a different formulation) by Ateniese et al..
Proofs of space are very similar to proofs of work (PoW), except that instead of computation, storage is used to earn cryptocurrency. Proof-of-space is different from memory-hard functions in that the bottleneck is not in the number of memory access events, but in the amount of memory required.
After the release of Bitcoin, alternatives to its PoW mining mechanism were researched, and PoS was studied in the context of cryptocurrencies. Proofs of space are seen as a fairer and greener alternative by blockchain enthusiasts due to the general-purpose nature of storage and the lower energy cost required by storage.
In 2014, Signum (formerly Burstcoin) became the first practical implementation of a PoS (initially as proof of capacity) blockchain technology and is still actively developed. Other than Signum, several theoretical and practical implementations of PoS have been released and discussed, such as SpaceMint and Chia, but some were criticized for increasing demand and shortening the life of storage devices due to greater disc reading requirements than Signum.","Proof of space (PoS) is a type of consensus algorithm achieved by demonstrating one's legitimate interest in a service (such as sending an email) by allocating a non-trivial amount of memory or disk space to solve a challenge presented by the service provider. The concept was formulated in 2013 by Dziembowski et al. and (with a different formulation) by Ateniese et al..
Proofs of space are very similar to proofs of work (PoW), except that instead of computation, storage is used to earn cryptocurrency. Proof-of-space is different from memory-hard functions in that the bottleneck is not in the number of memory access events, but in the amount of memory required.
After the release of Bitcoin, alternatives to its PoW mining mechanism were researched, and PoS was studied in the context of cryptocurrencies. Proofs of space are seen as a fairer and greener alternative by blockchain enthusiasts due to the general-purpose nature of storage and the lower energy cost required by storage.
In 2014, Signum (formerly Burstcoin) became the first practical implementation of a PoS (initially as proof of capacity) blockchain technology and is still actively developed. Other than Signum, several theoretical and practical implementations of PoS have been released and discussed, such as SpaceMint and Chia, but some were criticized for increasing demand and shortening the life of storage devices due to greater disc reading requirements than Signum.

Concept description
A proof-of-space is a piece of data that a prover sends to a verifier to prove that the prover has reserved a certain amount of space. For practicality, the verification process needs to be efficient, namely, consume a small amount of space and time. For security, it should be hard for the prover to pass the verification if it does not actually reserve the claimed amount of space.
One way of implementing PoS is by using hard-to-pebble graphs. The verifier asks the prover to build a labeling of a hard-to-pebble graph. The prover commits to the labeling. The verifier then asks the prover to open several random locations in the commitment.

Proof of storage
A proof of storage (also proof of retrievability, proof of data possession) is related to a proof-of-space, but instead of showing that space is available for solving a puzzle, the prover shows that space is actually used to store a piece of data correctly at the time of proof.
Cryptocurrencies intended to assign value to store data use some form of this system; examples include Chives, Storj, Sia, Filecoin, and Arweave.

Proof of capacity
A proof of capacity is a system where miners are allowed to pre-calculate (""plot"") PoW functions and store them onto the HDD. The first implementation of proof of capacity was Signum (formerly burstcoin).

Conditional proof of capacity
The Proof of Capacity (PoC) consensus algorithm is used in some cryptocurrencies. Conditional Proof of Capacity (CPOC) is an improved version of PoC. It has a work, stake, and capacity system that works like the PoW, PoS, and PoC algorithms. By pledging their digital assets, users receive a higher income as a reward. Additionally, CPOC has designed a new reward measure for top users. In this algorithm, miners add a conditional component to the proof by ensuring that their plot file contains specific data related to the previous block. This additional condition enhances the security and decentralization of the consensus mechanism beyond traditional proof-of-capacity algorithms.

Proof of space-time
A proof of space-time (PoST) is a proof that shows the prover has spent an amount of time keeping the reserved space unchanged. Its creators reason that the cost of storage is inextricably linked not only to its capacity, but to the time in which that capacity is used. It is related to a proof-of-storage (but without necessarily storing any useful data), although the Moran-Orlov construction also allows a tradeoff between space and time. The first implementation of PoST is with the Chia blockchain.

Uses
Proofs of space could be used as an alternative to proofs of work in the traditional client puzzle applications, such as anti-spam measures and denial of service attack prevention. Proof-of-Space has also been used for malware detection, by determining whether the L1 cache of a processor is empty (e.g., has enough space to evaluate the PoS routine without cache misses) or contains a routine that resisted being evicted.Proofs of space have been developed further in several concept papers and in one live cryptocurrency implementation.

Signum (formerly Burstcoin)
The first blockchain to use hard disk based blockchain validation, established in 2014. Signum Proof of Capacity consumes disk space rather than computing resources to mine a block. Unlike PoW, where the miners keep changing the block header and hash to find the solution, proof of capacity (as implemented by Burstcoin, and developed further by Signum) generates random solutions, also called plots, using the Shabal cryptographic algorithm in advance and stores it on hard drives. This stage is called plotting, and it may take days or even weeks depending on the storage capacity of the drive. In the next stage - mining, miners match their solutions to the most recent puzzle and the node with the fastest solution gets to mine the next block.

SpaceMint
In 2015, a paper proposed a cryptocurrency called SpaceMint. It attempts to solve some of the practical design problems associated with the pebbling-based PoS schemes. In using PoS for decentralized cryptocurrency, the protocol has to be adapted to work in a non-interactive protocol since each individual in the network has to behave as a verifier.

Chia
In 2018, a proposed cryptocurrency Chia presented two papers presenting a new protocol based on proof of space and proof of time.In February 2021, Chia published a white paper outlining its business and has since launched its mainnet and Chia coin (XCH) using the Proof of Space Time concept. The spacetime model of Chia also depends on ""plotting"" (generation of proof-of-space files) to the storage medium to solve a puzzle.Unlike many proof-of-storage cryptocurrencies, Chia plots do not store any useful data. Also, Chia's proof-of-time method for plotting has raised concerns over shortened lifespans of solid-state drives due to the intensity of write activity involved in plot generation (typically, plotting occurs on an SSD and then the finished plots are transferred to a hard disk drive for long-term storage).

Spacemesh
In 2019, a paper was released by Tal Moran and Ilan Orlov proposing a new protocol based on proof of space-time.
Spacemesh is unique due to its use of a blockmesh, rather than a blockchain. While a blockchain is a chain of single blocks, a blockmesh makes use of a directed acyclic graph (DAG) composed of layers, with each layer containing many blocks.

See also
Proof of work
Proof of stake
Proof of authority
Proof of personhood

References
External links
Chives website
Chives Swap
Chives Explorer
Signum Network web site
Signum Documentation Website Documentation
Chia web site",52214944,https://en.wikipedia.org/wiki/Proof_of_space
Proof of Space and Time,"Proof of space (PoS) is a type of consensus algorithm achieved by demonstrating one's legitimate interest in a service (such as sending an email) by allocating a non-trivial amount of memory or disk space to solve a challenge presented by the service provider. The concept was formulated in 2013 by Dziembowski et al. and (with a different formulation) by Ateniese et al..
Proofs of space are very similar to proofs of work (PoW), except that instead of computation, storage is used to earn cryptocurrency. Proof-of-space is different from memory-hard functions in that the bottleneck is not in the number of memory access events, but in the amount of memory required.
After the release of Bitcoin, alternatives to its PoW mining mechanism were researched, and PoS was studied in the context of cryptocurrencies. Proofs of space are seen as a fairer and greener alternative by blockchain enthusiasts due to the general-purpose nature of storage and the lower energy cost required by storage.
In 2014, Signum (formerly Burstcoin) became the first practical implementation of a PoS (initially as proof of capacity) blockchain technology and is still actively developed. Other than Signum, several theoretical and practical implementations of PoS have been released and discussed, such as SpaceMint and Chia, but some were criticized for increasing demand and shortening the life of storage devices due to greater disc reading requirements than Signum.","Proof of space (PoS) is a type of consensus algorithm achieved by demonstrating one's legitimate interest in a service (such as sending an email) by allocating a non-trivial amount of memory or disk space to solve a challenge presented by the service provider. The concept was formulated in 2013 by Dziembowski et al. and (with a different formulation) by Ateniese et al..
Proofs of space are very similar to proofs of work (PoW), except that instead of computation, storage is used to earn cryptocurrency. Proof-of-space is different from memory-hard functions in that the bottleneck is not in the number of memory access events, but in the amount of memory required.
After the release of Bitcoin, alternatives to its PoW mining mechanism were researched, and PoS was studied in the context of cryptocurrencies. Proofs of space are seen as a fairer and greener alternative by blockchain enthusiasts due to the general-purpose nature of storage and the lower energy cost required by storage.
In 2014, Signum (formerly Burstcoin) became the first practical implementation of a PoS (initially as proof of capacity) blockchain technology and is still actively developed. Other than Signum, several theoretical and practical implementations of PoS have been released and discussed, such as SpaceMint and Chia, but some were criticized for increasing demand and shortening the life of storage devices due to greater disc reading requirements than Signum.

Concept description
A proof-of-space is a piece of data that a prover sends to a verifier to prove that the prover has reserved a certain amount of space. For practicality, the verification process needs to be efficient, namely, consume a small amount of space and time. For security, it should be hard for the prover to pass the verification if it does not actually reserve the claimed amount of space.
One way of implementing PoS is by using hard-to-pebble graphs. The verifier asks the prover to build a labeling of a hard-to-pebble graph. The prover commits to the labeling. The verifier then asks the prover to open several random locations in the commitment.

Proof of storage
A proof of storage (also proof of retrievability, proof of data possession) is related to a proof-of-space, but instead of showing that space is available for solving a puzzle, the prover shows that space is actually used to store a piece of data correctly at the time of proof.
Cryptocurrencies intended to assign value to store data use some form of this system; examples include Chives, Storj, Sia, Filecoin, and Arweave.

Proof of capacity
A proof of capacity is a system where miners are allowed to pre-calculate (""plot"") PoW functions and store them onto the HDD. The first implementation of proof of capacity was Signum (formerly burstcoin).

Conditional proof of capacity
The Proof of Capacity (PoC) consensus algorithm is used in some cryptocurrencies. Conditional Proof of Capacity (CPOC) is an improved version of PoC. It has a work, stake, and capacity system that works like the PoW, PoS, and PoC algorithms. By pledging their digital assets, users receive a higher income as a reward. Additionally, CPOC has designed a new reward measure for top users. In this algorithm, miners add a conditional component to the proof by ensuring that their plot file contains specific data related to the previous block. This additional condition enhances the security and decentralization of the consensus mechanism beyond traditional proof-of-capacity algorithms.

Proof of space-time
A proof of space-time (PoST) is a proof that shows the prover has spent an amount of time keeping the reserved space unchanged. Its creators reason that the cost of storage is inextricably linked not only to its capacity, but to the time in which that capacity is used. It is related to a proof-of-storage (but without necessarily storing any useful data), although the Moran-Orlov construction also allows a tradeoff between space and time. The first implementation of PoST is with the Chia blockchain.

Uses
Proofs of space could be used as an alternative to proofs of work in the traditional client puzzle applications, such as anti-spam measures and denial of service attack prevention. Proof-of-Space has also been used for malware detection, by determining whether the L1 cache of a processor is empty (e.g., has enough space to evaluate the PoS routine without cache misses) or contains a routine that resisted being evicted.Proofs of space have been developed further in several concept papers and in one live cryptocurrency implementation.

Signum (formerly Burstcoin)
The first blockchain to use hard disk based blockchain validation, established in 2014. Signum Proof of Capacity consumes disk space rather than computing resources to mine a block. Unlike PoW, where the miners keep changing the block header and hash to find the solution, proof of capacity (as implemented by Burstcoin, and developed further by Signum) generates random solutions, also called plots, using the Shabal cryptographic algorithm in advance and stores it on hard drives. This stage is called plotting, and it may take days or even weeks depending on the storage capacity of the drive. In the next stage - mining, miners match their solutions to the most recent puzzle and the node with the fastest solution gets to mine the next block.

SpaceMint
In 2015, a paper proposed a cryptocurrency called SpaceMint. It attempts to solve some of the practical design problems associated with the pebbling-based PoS schemes. In using PoS for decentralized cryptocurrency, the protocol has to be adapted to work in a non-interactive protocol since each individual in the network has to behave as a verifier.

Chia
In 2018, a proposed cryptocurrency Chia presented two papers presenting a new protocol based on proof of space and proof of time.In February 2021, Chia published a white paper outlining its business and has since launched its mainnet and Chia coin (XCH) using the Proof of Space Time concept. The spacetime model of Chia also depends on ""plotting"" (generation of proof-of-space files) to the storage medium to solve a puzzle.Unlike many proof-of-storage cryptocurrencies, Chia plots do not store any useful data. Also, Chia's proof-of-time method for plotting has raised concerns over shortened lifespans of solid-state drives due to the intensity of write activity involved in plot generation (typically, plotting occurs on an SSD and then the finished plots are transferred to a hard disk drive for long-term storage).

Spacemesh
In 2019, a paper was released by Tal Moran and Ilan Orlov proposing a new protocol based on proof of space-time.
Spacemesh is unique due to its use of a blockmesh, rather than a blockchain. While a blockchain is a chain of single blocks, a blockmesh makes use of a directed acyclic graph (DAG) composed of layers, with each layer containing many blocks.

See also
Proof of work
Proof of stake
Proof of authority
Proof of personhood

References
External links
Chives website
Chives Swap
Chives Explorer
Signum Network web site
Signum Documentation Website Documentation
Chia web site",52214944,https://en.wikipedia.org/wiki/Proof_of_space
Computer architecture,"In computer science and computer engineering, computer architecture is a description of the structure of a computer system made from component parts. It can sometimes be a high-level description that ignores details of the implementation. At a more detailed level, the description may include the instruction set architecture design, microarchitecture design, logic design, and implementation.","In computer science and computer engineering, computer architecture is a description of the structure of a computer system made from component parts. It can sometimes be a high-level description that ignores details of the implementation. At a more detailed level, the description may include the instruction set architecture design, microarchitecture design, logic design, and implementation.

History
The first documented computer architecture was in the correspondence between Charles Babbage and Ada Lovelace, describing the analytical engine. While building the computer Z1 in 1936, Konrad Zuse described in two patent applications for his future projects that machine instructions could be stored in the same storage used for data, i.e., the stored-program concept. Two other early and important examples are:

John von Neumann's 1945 paper, First Draft of a Report on the EDVAC, which described an organization of logical elements; and
Alan Turing's more detailed Proposed Electronic Calculator for the Automatic Computing Engine, also 1945 and which cited John von Neumann's paper.The term ""architecture"" in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM's main research center in 1959. Johnson had the opportunity to write a proprietary research communication about the Stretch, an IBM-developed supercomputer for Los Alamos National Laboratory (at the time known as Los Alamos Scientific Laboratory). To describe the level of detail for discussing the luxuriously embellished computer, he noted that his description of formats, instruction types, hardware parameters, and speed enhancements were at the level of ""system architecture"", a term that seemed more useful than ""machine organization"".Subsequently, Brooks, a Stretch designer, opened Chapter 2 of a book called Planning a Computer System: Project Stretch by stating, ""Computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints.""Brooks went on to help develop the IBM System/360 (now called the IBM zSeries) line of computers, in which ""architecture"" became a noun defining ""what the user needs to know"". Later, computer users came to use the term in many less explicit ways.The earliest computer architectures were designed on paper and then directly built into the final hardware form.
Later, computer architecture prototypes were physically built in the form of a transistor–transistor logic (TTL) computer—such as the prototypes of the 6800 and the PA-RISC—tested, and tweaked, before committing to the final hardware form.
As of the 1990s, new computer architectures are typically ""built"", tested, and tweaked—inside some other computer architecture in a computer architecture simulator; or inside a FPGA as a soft microprocessor; or both—before committing to the final hardware form.

Subcategories
The discipline of computer architecture has three main subcategories:
Instruction set architecture (ISA): defines the machine code that a processor reads and acts upon as well as the word size, memory address modes, processor registers, and data type.
Microarchitecture: also known as ""computer organization"", this describes how a particular processor will implement the ISA. The size of a computer's CPU cache for instance, is an issue that generally has nothing to do with the ISA.
Systems design: includes all of the other hardware components within a computing system, such as data processing other than the CPU (e.g., direct memory access), virtualization, and multiprocessing.There are other technologies in computer architecture. The following technologies are used in bigger companies like Intel, and were estimated in 2002 to count for 1% of all of computer architecture:

Macroarchitecture: architectural layers more abstract than microarchitecture
Assembly instruction set architecture: A smart assembler may convert an abstract assembly language common to a group of machines into slightly different machine language for different implementations.
Programmer-visible macroarchitecture: higher-level language tools such as compilers may define a consistent interface or contract to programmers using them, abstracting differences between underlying ISA, UISA, and microarchitectures. For example, the C, C++, or Java standards define different programmer-visible macroarchitectures.
Microcode: microcode is software that translates instructions to run on a chip. It acts like a wrapper around the hardware, presenting a preferred version of the hardware's instruction set interface. This instruction translation facility gives chip designers flexible options: E.g. 1. A new improved version of the chip can use microcode to present the exact same instruction set as the old chip version, so all software targeting that instruction set will run on the new chip without needing changes. E.g. 2. Microcode can present a variety of instruction sets for the same underlying chip, allowing it to run a wider variety of software.
UISA: User Instruction Set Architecture, refers to one of three subsets of the RISC CPU instructions provided by PowerPC RISC Processors. The UISA subset, are those RISC instructions of interest to application developers. The other two subsets are VEA (Virtual Environment Architecture) instructions used by virtualization system developers, and OEA (Operating Environment Architecture) used by Operation System developers.
Pin architecture: The hardware functions that a microprocessor should provide to a hardware platform, e.g., the x86 pins A20M, FERR/IGNNE or FLUSH. Also, messages that the processor should emit so that external caches can be invalidated (emptied). Pin architecture functions are more flexible than ISA functions because external hardware can adapt to new encodings, or change from a pin to a message. The term ""architecture"" fits, because the functions must be provided for compatible systems, even if the detailed method changes.

Roles
Definition
Computer architecture is concerned with balancing the performance, efficiency, cost, and reliability of a computer system. The case of instruction set architecture can be used to illustrate the balance of these competing factors. More complex instruction sets enable programmers to write more space efficient programs, since a single instruction can encode some higher-level abstraction (such as the x86 Loop instruction). However, longer and more complex instructions take longer for the processor to decode and can be more costly to implement effectively. The increased complexity from a large instruction set also creates more room for unreliability when instructions interact in unexpected ways.
The implementation involves integrated circuit design, packaging, power, and cooling. Optimization of the design requires familiarity with compilers, operating systems to logic design, and packaging.

Instruction set architecture
An instruction set architecture (ISA) is the interface between the computer's software and hardware and also can be viewed as the programmer's view of the machine. Computers do not understand high-level programming languages such as Java, C++, or most programming languages used. A processor only understands instructions encoded in some numerical fashion, usually as binary numbers. Software tools, such as compilers, translate those high level languages into instructions that the processor can understand.
Besides instructions, the ISA defines items in the computer that are available to a program—e.g., data types, registers, addressing modes, and memory.  Instructions locate these available items with register indexes (or names) and memory addressing modes.
The ISA of a computer is usually described in a small instruction manual, which describes how the instructions are encoded. Also, it may define short (vaguely) mnemonic names for the instructions. The names can be recognized by a software development tool called an assembler.  An assembler is a computer program that translates a human-readable form of the ISA into a computer-readable form.  Disassemblers are also widely available, usually in debuggers and software programs to isolate and correct malfunctions in binary computer programs.
ISAs vary in quality and completeness.  A good ISA compromises between programmer convenience (how easy the code is to understand), size of the code (how much code is required to do a specific action), cost of the computer to interpret the instructions (more complexity means more hardware needed to decode and execute the instructions), and speed of the computer (with more complex decoding hardware comes longer decode time).  Memory organization defines how instructions interact with the memory, and how memory interacts with itself.
During design emulation, emulators can run programs written in a proposed instruction set. Modern emulators can measure size, cost, and speed to determine whether a particular ISA is meeting its goals.

Computer organization
Computer organization helps optimize performance-based products. For example, software engineers need to know the processing power of processors. They may need to optimize software in order to gain the most performance for the lowest price. This can require quite a detailed analysis of the computer's organization.  For example, in an SD card, the designers might need to arrange the card so that the most data can be processed in the fastest possible way.
Computer organization also helps plan the selection of a processor for a particular project. Multimedia projects may need very rapid data access, while virtual machines may need fast interrupts. Sometimes certain tasks need additional components as well.  For example, a computer capable of running a virtual machine needs virtual memory hardware so that the memory of different virtual computers can be kept separated. Computer organization and features also affect power consumption and processor cost.

Implementation
Once an instruction set and micro-architecture have been designed, a practical machine must be developed. This design process is called the implementation. Implementation is usually not considered architectural design, but rather hardware design engineering. Implementation can be further broken down into several steps:

Logic implementation designs the circuits required at a logic-gate level.
Circuit implementation does transistor-level designs of basic elements (e.g., gates, multiplexers, latches) as well as of some larger blocks (ALUs, caches etc.) that may be implemented at the logic-gate level, or even at the physical level if the design calls for it.
Physical implementation draws physical circuits.  The different circuit components are placed in a chip floor plan or on a board and the wires connecting them are created.
Design validation tests the computer as a whole to see if it works in all situations and all timings. Once the design validation process starts, the design at the logic level are tested using logic emulators. However, this is usually too slow to run a realistic test.  So, after making corrections based on the first test, prototypes are constructed using Field-Programmable Gate-Arrays (FPGAs). Most hobby projects stop at this stage.  The final step is to test prototype integrated circuits, which may require several redesigns.For CPUs, the entire implementation process is organized differently and is often referred to as CPU design.

Design goals
The exact form of a computer system depends on the constraints and goals. Computer architectures usually trade off standards, power versus performance, cost, memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. Sometimes other considerations, such as features, size, weight, reliability, and expandability are also factors.
The most common scheme does an in-depth power analysis and figures out how to keep power consumption low while maintaining adequate performance.

Performance
Modern computer performance is often described in instructions per cycle (IPC), which measures the efficiency of the architecture at any clock frequency; a faster IPC rate means the computer is faster. Older computers had IPC counts as low as 0.1 while modern processors easily reach nearly 1. Superscalar processors may reach three to five IPC by executing several instructions per clock cycle.Counting machine-language instructions would be misleading because they can do varying amounts of work in different ISAs. The ""instruction"" in the standard measurements is not a count of the ISA's machine-language instructions, but a unit of measurement, usually based on the speed of the VAX computer architecture.
Many people used to measure a computer's speed by the clock rate (usually in MHz or GHz). This refers to the cycles per second of the main clock of the CPU. However, this metric is somewhat misleading, as a machine with a higher clock rate may not necessarily have greater performance. As a result, manufacturers have moved away from clock speed as a measure of performance.
Other factors influence speed, such as the mix of functional units, bus speeds, available memory, and the type and order of instructions in the programs.
There are two main types of speed: latency and throughput. Latency is the time between the start of a process and its completion. Throughput is the amount of work done per unit time.  Interrupt latency is the guaranteed maximum response time of the system to an electronic event (like when the disk drive finishes moving some data).
Performance is affected by a very wide range of design choices — for example, pipelining a processor usually makes latency worse, but makes throughput better. Computers that control machinery usually need low interrupt latencies. These computers operate in a real-time environment and fail if an operation is not completed in a specified amount of time. For example, computer-controlled anti-lock brakes must begin braking within a predictable and limited time period after the brake pedal is sensed or else failure of the brake will occur.
Benchmarking takes all these factors into account by measuring the time a computer takes to run through a series of test programs. Although benchmarking shows strengths, it should not be how you choose a computer. Often the measured machines split on different measures. For example, one system might handle scientific applications quickly, while another might render video games more smoothly. Furthermore, designers may target and add special features to their products, through hardware or software, that permit a specific benchmark to execute quickly but do not offer similar advantages to general tasks.

Power efficiency
Power efficiency is another important measurement in modern computers. Higher power efficiency can often be traded for lower speed or higher cost. The typical measurement when referring to power consumption in computer architecture is MIPS/W (millions of instructions per second per watt).
Modern circuits have less power required per transistor as the number of transistors per chip grows. This is because each transistor that is put in a new chip requires its own power supply and requires new pathways to be built to power it. However, the number of transistors per chip is starting to increase at a slower rate. Therefore, power efficiency is starting to become as important, if not more important than fitting more and more transistors into a single chip. Recent processor designs have shown this emphasis as they put more focus on power efficiency rather than cramming as many transistors into a single chip as possible. In the world of embedded computers, power efficiency has long been an important goal next to throughput and latency.

Shifts in market demand
Increases in clock frequency have grown more slowly over the past few years, compared to power reduction improvements. This has been driven by the end of Moore's Law and demand for longer battery life and reductions in size for mobile technology. This change in focus from higher clock rates to power consumption and miniaturization can be shown by the significant reductions in power consumption, as much as 50%, that were reported by Intel in their release of the Haswell microarchitecture; where they dropped their power consumption benchmark from 30 to 40 watts down to 10-20 watts. Comparing this to the processing speed increase of 3 GHz to 4 GHz (2002 to 2006) it can be seen that the focus in research and development is shifting away from clock frequency and moving towards consuming less power and taking up less space.

See also
References
Sources
John L. Hennessy and David Patterson (2006). Computer Architecture: A Quantitative Approach (Fourth ed.). Morgan Kaufmann. ISBN 978-0-12-370490-0.
Barton, Robert S., ""Functional Design of Computers"", Communications of the ACM 4(9): 405 (1961).
Barton, Robert S., ""A New Approach to the Functional Design of a Digital Computer"", Proceedings of the Western Joint Computer Conference, May 1961, pp. 393–396. About the design of the Burroughs B5000 computer.
Bell, C. Gordon; and Newell, Allen (1971). ""Computer Structures: Readings and Examples"", McGraw-Hill.
Blaauw, G.A., and Brooks, F.P., Jr., ""The Structure of System/360, Part I-Outline of the Logical Structure"", IBM Systems Journal, vol. 3, no. 2, pp. 119–135, 1964.
Tanenbaum, Andrew S. (1979). Structured Computer Organization. Englewood Cliffs, New Jersey: Prentice-Hall. ISBN 0-13-148521-0.

External links

ISCA: Proceedings of the International Symposium on Computer Architecture
Micro: IEEE/ACM International Symposium on Microarchitecture
HPCA: International Symposium on High Performance Computer Architecture
ASPLOS: International Conference on Architectural Support for Programming Languages and Operating Systems
ACM Transactions on Architecture and Code Optimization
IEEE Transactions on Computers
The von Neumann Architecture of Computer Systems",25652303,https://en.wikipedia.org/wiki/Computer_architecture
Abstraction layer,"In computing, an abstraction layer or abstraction level is a way of hiding the working details of a subsystem. Examples of software models that use layers of abstraction include the OSI model for network protocols, OpenGL, and other graphics libraries, which allow the separation of concerns to facilitate interoperability and platform independence. Another example is Media Transfer Protocol.
In computer science, an abstraction layer is a generalization of a conceptual model or algorithm, away from any specific implementation. These generalizations arise from broad similarities that are best encapsulated by models that express similarities present in various specific implementations. The simplification provided by a good abstraction layer allows for easy reuse by distilling a useful concept or design pattern so that situations, where it may be accurately applied, can be quickly recognized.
A layer is considered to be on top of another if it depends on it. Every layer can exist without the layers above it, and requires the layers below it to function. Frequently abstraction layers can be composed into a hierarchy of abstraction levels. The OSI model comprises seven abstraction layers. Each layer of the model encapsulates and addresses a different part of the needs of digital communications, thereby reducing the complexity of the associated engineering solutions.
A famous aphorism of David Wheeler is, ""All problems in computer science can be solved by another level of indirection."" This is often deliberately misquoted with ""abstraction"" substituted for ""indirection."" It is also sometimes misattributed to Butler Lampson. Kevlin Henney's corollary to this is, ""...except for the problem of too many layers of indirection.""","In computing, an abstraction layer or abstraction level is a way of hiding the working details of a subsystem. Examples of software models that use layers of abstraction include the OSI model for network protocols, OpenGL, and other graphics libraries, which allow the separation of concerns to facilitate interoperability and platform independence. Another example is Media Transfer Protocol.
In computer science, an abstraction layer is a generalization of a conceptual model or algorithm, away from any specific implementation. These generalizations arise from broad similarities that are best encapsulated by models that express similarities present in various specific implementations. The simplification provided by a good abstraction layer allows for easy reuse by distilling a useful concept or design pattern so that situations, where it may be accurately applied, can be quickly recognized.
A layer is considered to be on top of another if it depends on it. Every layer can exist without the layers above it, and requires the layers below it to function. Frequently abstraction layers can be composed into a hierarchy of abstraction levels. The OSI model comprises seven abstraction layers. Each layer of the model encapsulates and addresses a different part of the needs of digital communications, thereby reducing the complexity of the associated engineering solutions.
A famous aphorism of David Wheeler is, ""All problems in computer science can be solved by another level of indirection."" This is often deliberately misquoted with ""abstraction"" substituted for ""indirection."" It is also sometimes misattributed to Butler Lampson. Kevlin Henney's corollary to this is, ""...except for the problem of too many layers of indirection.""

Computer architecture
In a computer architecture, a computer system is usually represented as consisting of several abstraction levels such as:

software
programmable logic
hardwareProgrammable logic is often considered part of the hardware, while the logical definitions are also sometimes seen as part of a device's software or firmware. Firmware may include only low-level software, but can also include all software, including an operating system and applications. The software layers can be further divided into hardware abstraction layers, physical and logical device drivers, repositories such as filesystems, operating system kernels, middleware, applications, and others. A distinction can also be made from low-level programming languages like VHDL, machine language, assembly language to a compiled language, interpreter, and script language.

Input and output
In the Unix operating system, most types of input and output operations are considered to be streams of bytes read from a device or written to a device.  This stream of bytes model is used for file I/O, socket I/O, and terminal I/O in order to provide device independence. In order to read and write to a device at the application level, the program calls a function to open the device, which may be a real device such as a terminal or a virtual device such as a network port or a file in a file system. The device's physical characteristics are mediated by the operating system which in turn presents an abstract interface that allows the programmer to read and write bytes from/to the device. The operating system then performs the actual transformation needed to read and write the stream of bytes to the device.

Graphics
Most graphics libraries such as OpenGL provide an abstract graphical device model as an interface. The library is responsible for translating the commands provided by the programmer into the specific device commands needed to draw the graphical elements and objects. The specific device commands for a plotter are different from the device commands for a CRT monitor, but the graphics library hides the implementation and device-dependent details by providing an abstract interface which provides a set of primitives that are generally useful for drawing graphical objects.

See also
Application programming interface (API)
Application binary interface (ABI)
Compiler, a tool for abstraction between source code and machine code
Hardware abstraction
Information hiding
Layer (object-oriented design)
Namespace violation
Protection ring
Operating system, an abstraction layer between a program and computer hardware
Software engineering


== References ==",574775,https://en.wikipedia.org/wiki/Abstraction_layer
Address space,"In computing, an address space defines a range of discrete addresses, each of which may correspond to a network host, peripheral device, disk sector, a memory cell or other logical or physical entity.
For software programs to save and retrieve stored data, each datum must have an address where it can be located. The number of address spaces available depends on the underlying address structure, which is usually limited by the computer architecture being used. Often an address space in a system with virtual memory corresponds to a highest level translation table, e.g., a segment table in IBM System/370.
Address spaces are created by combining enough uniquely identified qualifiers to make an address unambiguous within the address space. For a person's physical address, the address space would be a combination of locations, such as a neighborhood, town, city, or country. Some elements of a data address space may be the same, but if any element in the address is different, addresses in said space will reference different entities. For example, there could be multiple buildings at the same address of ""32 Main Street"" but in different towns, demonstrating that different towns have different, although similarly arranged, street address spaces.
An address space usually provides (or allows) a partitioning to several regions according to the mathematical structure it has. In the case of total order, as for memory addresses, these are simply chunks. Like the hierarchical design of postal addresses, some nested domain hierarchies appear as a directed ordered tree, such as with the Domain Name System or a directory structure. In the Internet, the Internet Assigned Numbers Authority (IANA) allocates ranges of IP addresses to various registries so each can manage their parts of the global Internet address space.","In computing, an address space defines a range of discrete addresses, each of which may correspond to a network host, peripheral device, disk sector, a memory cell or other logical or physical entity.
For software programs to save and retrieve stored data, each datum must have an address where it can be located. The number of address spaces available depends on the underlying address structure, which is usually limited by the computer architecture being used. Often an address space in a system with virtual memory corresponds to a highest level translation table, e.g., a segment table in IBM System/370.
Address spaces are created by combining enough uniquely identified qualifiers to make an address unambiguous within the address space. For a person's physical address, the address space would be a combination of locations, such as a neighborhood, town, city, or country. Some elements of a data address space may be the same, but if any element in the address is different, addresses in said space will reference different entities. For example, there could be multiple buildings at the same address of ""32 Main Street"" but in different towns, demonstrating that different towns have different, although similarly arranged, street address spaces.
An address space usually provides (or allows) a partitioning to several regions according to the mathematical structure it has. In the case of total order, as for memory addresses, these are simply chunks. Like the hierarchical design of postal addresses, some nested domain hierarchies appear as a directed ordered tree, such as with the Domain Name System or a directory structure. In the Internet, the Internet Assigned Numbers Authority (IANA) allocates ranges of IP addresses to various registries so each can manage their parts of the global Internet address space.

Examples
Uses of addresses include, but are not limited to the following:

Memory addresses for main memory, memory-mapped I/O, as well as for virtual memory;
Device addresses on an expansion bus;
Sector addressing for disk drives;
File names on a particular volume;
Various kinds of network host addresses in computer networks;
Uniform resource locators in the Internet.

Address mapping and translation
Another common feature of address spaces are mappings and translations, often forming numerous layers. This usually means that some higher-level address must be translated to lower-level ones in some way. 
For example, a file system on a logical disk operates using linear sector numbers, which have to be translated to absolute LBA sector addresses, in simple cases, via addition of the partition's first sector address. Then, for a disk drive connected via Parallel ATA, each of them must be converted to logical cylinder-head-sector address due to the interface historical shortcomings. It is converted back to LBA by the disk controller, then, finally, to physical cylinder, head and sector numbers.
The Domain Name System maps its names to and from network-specific addresses (usually IP addresses), which in turn may be mapped to link layer network addresses via Address Resolution Protocol. Network address translation may also occur on the edge of different IP spaces, such as a local area network and the Internet.

An iconic example of virtual-to-physical address translation is virtual memory, where different pages of virtual address space map either to page file or to main memory physical address space. It is possible that several numerically different virtual addresses all refer to one physical address and hence to the same physical byte of RAM. It is also possible that a single virtual address maps to zero, one, or more than one physical address.

See also
Addressability
Flat memory model
Namespace
Virtualization


== References ==",507144,https://en.wikipedia.org/wiki/Address_space
Addressing mode,"Addressing modes are an aspect of the instruction set architecture in most central processing unit (CPU) designs. The various addressing modes that are defined in a given instruction set architecture define how the machine language instructions in that architecture identify the operand(s) of each instruction. An addressing mode specifies how to calculate the effective memory address of an operand by using information held in registers and/or constants contained within a machine instruction or elsewhere.
In computer programming, addressing modes are primarily of interest to those who write in assembly languages and to compiler writers.  For a related concept see orthogonal instruction set which deals with the ability of any instruction to use any addressing mode.","Addressing modes are an aspect of the instruction set architecture in most central processing unit (CPU) designs. The various addressing modes that are defined in a given instruction set architecture define how the machine language instructions in that architecture identify the operand(s) of each instruction. An addressing mode specifies how to calculate the effective memory address of an operand by using information held in registers and/or constants contained within a machine instruction or elsewhere.
In computer programming, addressing modes are primarily of interest to those who write in assembly languages and to compiler writers.  For a related concept see orthogonal instruction set which deals with the ability of any instruction to use any addressing mode.

Caveats
There are no generally accepted names for addressing modes: different authors and computer manufacturers may give different names to the same addressing mode, or the same names to different addressing modes. Furthermore, an addressing mode which, in one given architecture, is treated as a single addressing mode may represent functionality that, in another architecture, is covered by two or more addressing modes. For example, some complex instruction set computer (CISC) architectures, such as the Digital Equipment Corporation (DEC) VAX, treat registers and literal or immediate constants as just another addressing mode. Others, such as the IBM System/360 and its successors, and most reduced instruction set computer (RISC) designs, encode this information within the instruction. Thus, the latter machines have three distinct instruction codes for copying one register to another, copying a literal constant into a register, and copying the contents of a memory location into a register, while the VAX has only a single ""MOV"" instruction.
The term ""addressing mode"" is itself subject to different interpretations: either ""memory address calculation mode"" or ""operand accessing mode"". Under the first interpretation, instructions that do not read from memory or write to memory (such as ""add literal to register"") are considered not to have an ""addressing mode"". The second interpretation allows for machines such as VAX which use operand mode bits to allow for a register or for a literal operand. Only the first interpretation applies to instructions such as ""load effective address,"" which loads the address of the operand, not the operand itself.
The addressing modes listed below are divided into code addressing and data addressing. Most computer architectures maintain this distinction, but there are (or have been) some architectures which allow (almost) all addressing modes to be used in any context.
The instructions shown below are purely representative in order to illustrate the addressing modes, and do not necessarily reflect the mnemonics used by any particular computer.
Some computers, e.g., IBM 709, RCA 3301, do not have a single address mode field but rather have separate fields for indirect addressing and indexing.

Number of addressing modes
Computer architectures vary greatly as to the number of addressing modes they provide in hardware. There are some benefits to eliminating complex addressing modes and using only one or a few simpler addressing modes, even though it requires a few extra instructions, and perhaps an extra register.  It has proven much easier to design pipelined CPUs if the only addressing modes available are simple ones.
Most RISC architectures have only about five simple addressing modes, while CISC architectures such as the DEC VAX have over a dozen addressing modes, some of which are quite complicated. The IBM System/360 architecture had only three addressing modes; a few more have been added for the System/390.
When there are only a few addressing modes, the particular addressing mode required is usually encoded within the instruction code
(e.g. IBM System/360 and successors, most RISC). But when there are many addressing modes, a specific field is often set aside in the instruction to specify the addressing mode. The DEC VAX allowed multiple memory operands for almost all instructions, and so reserved the first few bits of each operand specifier to indicate the addressing mode for that particular operand.
Keeping the addressing mode specifier bits separate from the opcode operation bits produces an orthogonal instruction set.
Even on a computer with many addressing modes, measurements of actual programs indicate that the simple addressing modes listed below account for some 90% or more of all addressing modes used. Since most such measurements are based on code generated from high-level languages by compilers, this reflects to some extent the limitations of the compilers being used.

Important use case
Some instruction set architectures, such as Intel x86 and IBM/360 and its successors, have a load effective address instruction. This calculates the effective operand address and loads it into a register, without accessing the memory it refers to. This can be useful when passing the address of an array element to a subroutine. It may also be a clever way of doing more calculations than normal in one instruction; for example, using such an instruction with the addressing mode ""base+index+offset"" (detailed below) allows one to add two registers and a constant together in one instruction and store the result in a third register.

Simple addressing modes for code
Some simple addressing modes for code are shown below. The nomenclature may vary depending on platform.

Absolute or direct
+----+------------------------------+
   |jump|           address            |
   +----+------------------------------+

   (Effective PC address = address)

The effective address for an absolute instruction address is the address parameter itself with no modifications.

PC-relative
+----+------------------------------+
   |jump|           offset             |    jump relative
   +----+------------------------------+

   (Effective PC address = next instruction address + offset, offset may be negative)

The effective address for a PC-relative instruction address is the offset parameter added to the address of the next instruction. This offset is usually signed to allow reference to code both before and after the instruction.This is particularly useful in connection with jumps, because typical jumps are to nearby instructions (in a high-level language most if or while statements are reasonably short). Measurements of actual programs suggest that an 8 or 10 bit offset is large enough for some 90% of conditional jumps (roughly ±128 or ±512 bytes).Another advantage of PC-relative addressing is that the code may be position-independent, i.e. it can be loaded anywhere in memory without the need to adjust any addresses.
Some versions of this addressing mode may be conditional referring to two registers (""jump if reg1=reg2""), one register (""jump unless reg1=0"") or no registers, implicitly referring to some previously-set bit in the status register. See also conditional execution below.

Register indirect
+-------+-----+
   |jumpVia| reg |
   +-------+-----+

   (Effective PC address = contents of register 'reg')

The effective address for a Register indirect instruction is the address in the specified register. For example, (A7) to access the content of address register A7.
The effect is to transfer control to the instruction whose address is in the specified register.
Many RISC machines, as well as the CISC IBM System/360 and successors, have subroutine call instructions that place the return address in an address register—the register-indirect addressing mode is used to return from that subroutine call.

Sequential addressing modes
Sequential execution
+------+
   | nop  |              execute the following instruction
   +------+

   (Effective PC address = next instruction address)

The CPU, after executing a sequential instruction, immediately executes the following instruction.
Sequential execution is not considered to be an addressing mode on some computers.
Most instructions on most CPU architectures are sequential instructions. Because most instructions are sequential instructions, CPU designers often add features that deliberately sacrifice performance on the other instructions—branch instructions—in order to make these sequential instructions run faster.
Conditional branches load the PC with one of 2 possible results, depending on the condition—most CPU architectures use some other addressing mode for the ""taken"" branch, and sequential execution for the ""not taken"" branch.
Many features in modern CPUs—instruction prefetch and more complex pipelineing, out-of-order execution, etc.—maintain the illusion that each instruction finishes before the next one begins, giving the same final results, even though that's not exactly what happens internally.
Each ""basic block"" of such sequential instructions exhibits both temporal and spatial locality of reference.

CPUs that do not use sequential execution
CPUs that do not use sequential execution with a program counter are extremely rare. In some CPUs, each instruction always specifies the address of next instruction. Such CPUs have an instruction pointer that holds that specified address; it is not a program counter because there is no provision for incrementing it. Such CPUs include some drum memory computers such as the IBM 650, the SECD machine, Librascope LGP-30, and the RTX 32P.Other computing architectures go much further, attempting to bypass the von Neumann bottleneck using a variety of alternatives to the program counter.

Conditional execution
Some computer architectures have conditional instructions (such as ARM, but no longer for all instructions in 64-bit mode) or conditional load instructions (such as x86) which can in some cases make conditional branches unnecessary and avoid flushing the instruction pipeline.  An instruction such as a 'compare' is used to set a condition code, and subsequent instructions include a test on that condition code to see whether they are obeyed or ignored.

Skip
+------+-----+-----+
   |skipEQ| reg1| reg2|      skip the next instruction if reg1=reg2
   +------+-----+-----+

   (Effective PC address = next instruction address + 1)

Skip addressing may be considered a special kind of PC-relative addressing mode with a fixed ""+1"" offset. Like PC-relative addressing, some CPUs have versions of this addressing mode that only refer to one register (""skip if reg1=0"") or no registers, implicitly referring to some previously-set bit in the status register. Other CPUs have a version that selects a specific bit in a specific byte to test (""skip if bit 7 of reg12 is 0"").
Unlike all other conditional branches, a ""skip"" instruction never needs to flush the instruction pipeline, though it may need to cause the next instruction to be ignored.

Simple addressing modes for data
Some simple addressing modes for data are shown below. The nomenclature may vary depending on platform.

Register (or, register direct)
+------+-----+-----+-----+
   | mul  | reg1| reg2| reg3|      reg1 := reg2 * reg3;
   +------+-----+-----+-----+

This ""addressing mode"" does not have an effective address and is not considered to be an addressing mode on some computers.
In this example, all the operands are in registers, and the result is placed in a register.

Base plus offset, and variations
This is sometimes referred to as 'base plus displacement'

   +------+-----+-----+----------------+
   | load | reg | base|     offset     |  reg := RAM[base + offset]
   +------+-----+-----+----------------+

   (Effective address = offset + contents of specified base register)

The offset is usually a signed 16-bit value (though the 80386 expanded it to 32 bits).
If the offset is zero, this becomes an example of register indirect addressing; the effective address is just the value in the base register.
On many RISC machines, register 0 is fixed at the value zero. If register 0 is used as the base register, this becomes an example of absolute addressing. However, only a small portion of memory can be accessed (64 kilobytes, if the offset is 16 bits).
The 16-bit offset may seem very small in relation to the size of current computer memories (which is why the 80386 expanded it to 32-bit). It could be worse: IBM System/360 mainframes only have an unsigned 12-bit offset. However, the principle of locality of reference applies: over a short time span, most of the data items a program wants to access are fairly close to each other.
This addressing mode is closely related to the indexed absolute addressing mode.
Example 1:
Within a subroutine a programmer will mainly be interested in the parameters and the local variables, which will rarely exceed 64 KB, for which one base register (the frame pointer) suffices. If this routine is a class method in an object-oriented language, then a second base register is needed which points at the attributes for the current object (this or self in some high level languages).
Example 2:
If the base register contains the address of a composite type (a record or structure), the offset can be used to select a field from that record (most records/structures are less than 32 kB in size).

Immediate/literal
+------+-----+-----+----------------+
   | add  | reg1| reg2|    constant    |    reg1 := reg2 + constant;
   +------+-----+-----+----------------+

This ""addressing mode"" does not have an effective address, and is not considered to be an addressing mode on some computers.
The constant might be signed or unsigned. For example, move.l #$FEEDABBA, D0 to move the immediate hex value of ""FEEDABBA"" into register D0.
Instead of using an operand from memory, the value of the operand is held within the instruction itself. On the DEC VAX machine, the literal operand sizes could be 6, 8, 16, or 32 bits long.
Andrew Tanenbaum showed that 98% of all the constants in a program would fit in 13 bits (see RISC design philosophy).

Implicit
+-----------------+
   | clear carry bit |
   +-----------------+

   +-------------------+
   | clear Accumulator |
   +-------------------+

The implied addressing mode, also called the implicit addressing mode (x86 assembly language), does not explicitly specify an effective address for either the source or the destination (or sometimes both).
Either the source (if any) or destination effective address (or sometimes both) is implied by the opcode.
Implied addressing was quite common on older computers (up to mid-1970s). Such computers typically had only a single register in which arithmetic could be performed—the accumulator. Such accumulator machines implicitly reference that accumulator in almost every instruction. For example, the operation < a := b + c; > can be done using the sequence < load b; add c; store a; > -- the destination (the accumulator) is implied in every ""load"" and ""add"" instruction; the source (the accumulator) is implied in every ""store"" instruction.
Later computers generally had more than one general-purpose register or RAM location which could be the source or destination or both for arithmetic—and so later computers need some other addressing mode to specify the source and destination of arithmetic.
Among the x86 instructions, some use implicit registers for one of the operands or results (multiplication, division, counting conditional jump).
Many computers (such as x86 and AVR) have one special-purpose register called the stack pointer which is implicitly incremented or decremented when pushing or popping data from the stack, and the source or destination effective address is (implicitly) the address stored in that stack pointer.
Many 32-bit computers (such as 68000, ARM, or PowerPC) have more than one register which could be used as a stack pointer—and so use the ""register autoincrement indirect"" addressing mode to specify which of those registers should be used when pushing or popping data from a stack.
Some current computer architectures (e.g. IBM/390 and Intel Pentium) contain some instructions with implicit operands in order to maintain backwards compatibility with earlier designs.
On many computers, instructions that flip the user/system mode bit, the interrupt-enable bit, etc. implicitly specify the special register that holds those bits. This simplifies the hardware necessary to trap those instructions in order to meet the Popek and Goldberg virtualization requirements—on such a system, the trap logic does not need to look at any operand (or at the final effective address), but only at the opcode.
A few CPUs have been designed where every operand is always implicitly specified in every instruction -- zero-operand CPUs.

Other addressing modes for code or data
Absolute/direct
+------+-----+--------------------------------------+
   | load | reg |         address                      |
   +------+-----+--------------------------------------+

   (Effective address = address as given in instruction)

This requires space in an instruction for quite a large address. It is often available on CISC machines which have variable-length instructions, such as x86.
Some RISC machines have a special Load Upper Literal instruction which places a 16- or 20-bit constant in the top half of a register.  That can then be used as the base register in a base-plus-offset addressing mode which supplies the low-order 16 or 12 bits.  The combination allows a full 32-bit address.

Indexed absolute
+------+-----+-----+--------------------------------+
   | load | reg |index|         address                |
   +------+-----+-----+--------------------------------+

   (Effective address = address + contents of specified index register)

This also requires space in an instruction for quite a large address. The address could be the start of an array or vector, and the index could select the particular array element required. The processor may scale the index register to allow for the size of each array element.
Note that this is more or less the same as base-plus-offset addressing mode, except that the offset in this case is large enough to address any memory location.
Example 1:
Within a subroutine, a programmer may define a string as a local constant or a static variable. The address of the string is stored in the literal address in the instruction. The offset—which character of the string to use on this iteration of a loop—is stored in the index register.
Example 2:
A programmer may define several large arrays as globals or as class variables. The start of the array is stored in the literal address (perhaps modified at program-load time by a relocating loader) of the instruction that references it. The offset—which item from the array to use on this iteration of a loop—is stored in the index register. Often the instructions in a loop re-use the same register for the loop counter and the offsets of several arrays.

Base plus index
+------+-----+-----+-----+
   | load | reg | base|index|
   +------+-----+-----+-----+

   (Effective address = contents of specified base register + contents of specified index register)

The base register could contain the start address of an array or vector, and the index could select the particular array element required. The processor may scale the index register to allow for the size of each array element. This could be used for accessing elements of an array passed as a parameter.

Base plus index plus offset
+------+-----+-----+-----+----------------+
   | load | reg | base|index|         offset |
   +------+-----+-----+-----+----------------+

   (Effective address = offset + contents of specified base register + contents of specified index register)

The base register could contain the start address of an array or vector of records, the index could select the particular record required, and the offset could select a field within that record. The processor may scale the index register to allow for the size of each array element.

Scaled
+------+-----+-----+-----+
   | load | reg | base|index|
   +------+-----+-----+-----+

   (Effective address = contents of specified base register + scaled contents of specified index register)

The base register could contain the start address of an array or vector data structure, and the index could contain the offset of the one particular array element required.
This addressing mode dynamically scales the value in the index register to allow for the size of each array element, e.g. if the array elements are double precision floating-point numbers occupying 8 bytes each then the value in the index register is multiplied by 8 before being used in the effective address calculation. The scale factor is normally restricted to being a power of two, so that shifting rather than multiplication can be used.

Register indirect
+------+------+-----+
   | load | reg1 | base|
   +------+------+-----+
 
   (Effective address = contents of base register)

A few computers have this as a distinct addressing mode. Many computers just use base plus offset with an offset value of 0. For example, (A7)

Register autoincrement indirect
+------+-----+-------+
   | load | reg | base  |
   +------+-----+-------+

   (Effective address = contents of base register)

After determining the effective address, the value in the base register is incremented by the size of the data item that is to be accessed. For example, (A7)+ would access the content of the address register A7, then increase the address pointer of A7 by 1 (usually 1 word). Within a loop, this addressing mode can be used to step through all the elements of an array or vector.
In high-level languages it is often thought to be a good idea that functions which return a result should not have side effects (lack of side effects makes program understanding and validation much easier). This addressing mode has a side effect in that the base register is altered. If the subsequent memory access causes an error (e.g. page fault, bus error, address error) leading to an interrupt, then restarting the instruction becomes much more problematic since one or more registers may need to be set back to the state they were in before the instruction originally started.
There have been at least two computer architectures which have had implementation problems with regard to recovery from interrupts when this addressing mode is used:

Motorola 68000 (address is represented in 24 bits). Could have one or two autoincrement register operands. The 68010+ resolved the problem by saving the processor's internal state on bus or address errors.
DEC VAX. Could have up to 6 autoincrement register operands. Each operand access could cause two page faults (if operands happened to straddle a page boundary). Of course the instruction itself could be over 50 bytes long and might straddle a page boundary as well!

Register autodecrement indirect
+------+-----+-----+
   | load | reg | base|
   +------+-----+-----+

   (Effective address = new contents of base register)

Before determining the effective address, the value in the base register is decremented by the size of the data item which is to be accessed.
Within a loop, this addressing mode can be used to step backwards through all the elements of an array or vector. A stack can be implemented by using this mode in conjunction with the previous addressing mode (autoincrement).
See the discussion of side-effects under the autoincrement addressing mode.

Memory indirect or deferred
Any of the addressing modes mentioned in this article could have an extra bit to indicate indirect addressing, i.e. the address calculated using some mode is in fact the address of a location (typically a complete word) which contains the actual effective address.
Indirect addressing may be used for code or data. It can make implementation of pointers, references, or handles much easier, and can also make it easier to call subroutines which are not otherwise addressable. Indirect addressing does carry a performance penalty due to the extra memory access involved.
Some early minicomputers (e.g. DEC PDP-8, Data General Nova) had only a few registers and only a limited direct addressing range (8 bits). Hence the use of memory indirect addressing was almost the only way of referring to any significant amount of memory.
Half of the DEC PDP-11's eight addressing modes are deferred. Register deferred @Rn is the same as register indirect as defined above. Predecrement deferred @-(Rn), postincrement deferred @(Rn)+, and indexed deferred @nn(Rn) modes point to addresses in memory which are read to find the address of the parameter. The PDP-11's deferred modes, when combined with the program counter, provide its absolute and PC-relative addressing modes.

PC-relative
+------+------+---------+----------------+
   | load | reg1 | base=PC |     offset     |
   +------+------+---------+----------------+

   reg1 := RAM[PC + offset]
   (Effective address = PC + offset)

The PC-relative addressing mode can be used to load a register with a value stored in program memory a short distance away from the current instruction. It can be seen as a special case of the ""base plus offset"" addressing mode, one that selects the program counter (PC) as the ""base register"".
There are a few CPUs that support PC-relative data references. Such CPUs include:
The MOS 6502 and its derivatives used relative addressing for all branch instructions. Only these instructions used this mode, jumps used a variety of other addressing modes.
The x86-64 architecture and the 64-bit ARMv8-A architecture have PC-relative addressing modes, called ""RIP-relative"" in x86-64 and ""literal"" in ARMv8-A.  The Motorola 6809 also supports a PC-relative addressing mode.
The PDP-11 architecture, the VAX architecture, and the 32-bit ARM architectures support PC-relative addressing by having the PC in the register file.
The IBM z/Architecture includes specific instructions, e.g., Load Relative Long, with PC-relative addressing if the General-Instructions-Extension Facility is active.
When this addressing mode is used, the compiler typically places the constants in a literal pool immediately before or immediately after the subroutine that uses them, to prevent accidentally executing those constants as instructions.
This addressing mode, which always fetches data from memory or stores data to memory and then sequentially falls through to execute the next instruction (the effective address points to data), should not be confused with ""PC-relative branch"" which does not fetch data from or store data to memory, but instead branches to some other instruction at the given offset (the effective address points to an executable instruction).

Obsolete addressing modes
The addressing modes listed here were used in the 1950–1980 period, but are no longer available on most current computers.
This list is by no means complete; there have been many other interesting and peculiar addressing modes used from time to time, e.g.  absolute-minus-logical-OR of two or three index registers.

Multi-level memory indirect
If the word size is larger than the address, then the word referenced for memory-indirect addressing could itself have an indirect flag set to indicate another memory indirect cycle. This flag is referred to as an indirection bit, and the resulting pointer is a tagged pointer, the indirection bit tagging whether it is a direct pointer or an indirect pointer. Care is needed to ensure that a chain of indirect addresses does not refer to itself; if it does, one can get an infinite loop while trying to resolve an address.
The IBM 1620, the Data General Nova, the HP 2100 series, and the NAR 2 each have such a multi-level memory indirect, and could enter such an infinite address calculation loop.
The memory indirect addressing mode on the Nova influenced the invention of indirect threaded code.
The DEC PDP-10 computer with 18-bit addresses and 36-bit words allowed multi-level indirect addressing with the possibility of using an index register at each stage as well.  The priority interrupt system was queried before decoding of every address word.  So, an indirect address loop would not prevent execution of device service routines, including any preemptive multitasking scheduler's time-slice expiration handler.  A looping instruction would be treated like any other compute-bound job.

Memory-mapped registers
On some computers, there were addresses that referred to registers rather than to primary storage, or to primary memory used to implement those registers. Although on some early computers there were register addresses at the high end of the address range, e.g., IBM 650, IBM 7070, the trend has been to use only register address at the low end and to use only the first 8 or 16 words of memory (e.g. ICL 1900, DEC PDP-10). This meant that there was no need for a separate ""add register to register"" instruction – one could just use the ""add memory to register"" instruction.
In the case of early models of the PDP-10, which did not have any cache memory, a tight inner loop loaded into the first few words of memory (where the fast registers were addressable if installed) ran much faster than it would have in magnetic core memory.
Later models of the DEC PDP-11 series mapped the registers onto addresses in the input/output area, but this was primarily intended to allow remote diagnostics. Confusingly, the 16-bit registers were mapped onto consecutive 8-bit byte addresses.

Memory indirect and autoincrement
The DEC PDP-8 minicomputer had eight special locations (at addresses 8 through 15). When accessed via memory indirect addressing, these locations would automatically increment prior to use. This made it easy to step through memory in a loop without needing to use the accumulator to increment the address.
The Data General Nova minicomputer had 16 special memory locations at addresses 16 through 31. When accessed via memory indirect addressing, 16 through 23 would automatically increment before use, and 24 through 31 would automatically decrement before use.

Zero page
The Data General Nova, Motorola 6800 family, and MOS Technology 6502 family of processors had very few internal registers. Arithmetic and logical instructions were mostly performed against values in memory as opposed to internal registers. As a result, many instructions required a two-byte (16-bit) location to memory. Given that opcodes on these processors were only one byte (8 bits) in length, memory addresses could make up a significant part of code size.
Designers of these processors included a partial remedy known as ""zero page"" addressing. The initial 256 bytes of memory ($0000 – $00FF; a.k.a., page ""0"") could be accessed using a one-byte absolute or indexed memory address. This reduced instruction execution time by one clock cycle and instruction length by one byte. By storing often-used data in this region, programs could be made smaller and faster.
As a result, the zero page was used similarly to a register file. On many systems, however, this resulted in high utilization of the zero page memory area by the operating system and user programs, which limited its use since free space was limited.

Direct page
The zero page address mode was enhanced in several late model 8-bit processors, including the WDC 65816, the CSG 65CE02, and the Motorola 6809. The new mode, known as ""direct page"" addressing, added the ability to move the 256-byte zero page memory window from the start of memory (offset address $0000) to a new location within the first 64 KB of memory.
The CSG 65CE02 allowed the direct page to be moved to any 256-byte boundary within the first 64 KB of memory by storing an 8-bit offset value in the new base page (B) register. The Motorola 6809 could do the same with its direct page (DP) register. The WDC 65816 went a step further and allowed the direct page to be moved to any location within the first 64 KB of memory by storing a 16-bit offset value in the new direct (D) register.
As a result, a greater number of programs were able to utilize the enhanced direct page addressing mode versus legacy processors that only included the zero page addressing mode.

Scaled index with bounds checking
This is similar to scaled index addressing, except that the instruction has two extra operands (typically constants), and the hardware checks that the index value is between these bounds.
Another variation uses vector descriptors to hold the bounds; this makes it easy to implement dynamically allocated arrays and still have full bounds checking.

Indirect to bit field within word
Some computers had special indirect addressing modes for subfields within words.
The GE/Honeywell 600 series character addressing indirect word specified either 6-bit or 9-bit character fields within its 36-bit word.
The DEC PDP-10, also 36-bit, had special instructions which allowed memory to be treated as a sequence of fixed-size bit fields or bytes of any size from 1 bit to 36 bits. A one-word sequence descriptor in memory, called a ""byte pointer"", held the current word address within the sequence, a bit position within a word, and the size of each byte.
Instructions existed to load and store bytes via this descriptor, and to increment the descriptor to point at the next byte (bytes were not split across word boundaries). Much DEC software used five 7-bit bytes per word (plain ASCII characters), with one bit per word unused. Implementations of C had to use four 9-bit bytes per word, since the 'malloc' function in C assumes that the size of an int is some multiple of the size of a char; the actual multiple is determined by the system-dependent compile-time operator sizeof.

Index next instruction
The Elliott 503, the Elliott 803, and the Apollo Guidance Computer only used absolute addressing, and did not have any index registers.
Thus, indirect jumps, or jumps through registers, were not supported in the instruction set. Instead, it could be instructed to add the contents of the current memory word to the next instruction. Adding a small value to the next instruction to be executed could, for example, change a JUMP 0 into a JUMP 20, thus creating the effect of an indexed jump. Note that the instruction is modified on-the-fly and remains unchanged in memory, i.e. it is not self-modifying code. If the value being added to the next instruction was large enough, it could modify the opcode of that instruction as well as or instead of the address.

Glossary
IndirectData referred to through a pointer or address.
ImmediateData embedded directly in an instruction or command list.
IndexA dynamic offset, typically held in an index register, possibly scaled by an object size.
OffsetAn immediate value added to an address; e.g., corresponding to structure field access in the C programming language.
RelativeAn address formed relative to another address.
Post incrementThe stepping of an address past data used, similar to *p++ in the C programming language, used for stack pop operations.
Pre decrementThe decrementing of an address prior to use, similar to *--p in the C programming language, used for stack push operations.

See also
Instruction set architecture
Address bus

Notes
References
External links
Addressing modes in assembly language
Addressing modes",838142,https://en.wikipedia.org/wiki/Addressing_mode
Aperture (computer memory),"In computing, an aperture is a portion of physical address space (i.e. physical memory) that is associated with a particular peripheral device or a memory unit. Apertures may reach external devices such as ROM or RAM chips, or internal memory on the CPU itself.
Typically, a memory device attached to a computer accepts addresses starting at zero, and so a system with more than one such device would have ambiguous addressing. To resolve this, the memory logic will contain several aperture selectors, each containing a range selector and an interface to one of the memory devices. 
The set of selector address ranges of the apertures are disjoint. When the CPU presents a physical address within the range recognized by an aperture, the aperture unit routes the request (with the address remapped to a zero base) to the attached device. Thus, apertures form a layer of address translation below the level of the usual virtual-to-physical mapping.","In computing, an aperture is a portion of physical address space (i.e. physical memory) that is associated with a particular peripheral device or a memory unit. Apertures may reach external devices such as ROM or RAM chips, or internal memory on the CPU itself.
Typically, a memory device attached to a computer accepts addresses starting at zero, and so a system with more than one such device would have ambiguous addressing. To resolve this, the memory logic will contain several aperture selectors, each containing a range selector and an interface to one of the memory devices. 
The set of selector address ranges of the apertures are disjoint. When the CPU presents a physical address within the range recognized by an aperture, the aperture unit routes the request (with the address remapped to a zero base) to the attached device. Thus, apertures form a layer of address translation below the level of the usual virtual-to-physical mapping.

See also
Address bus
AGP aperture
Memory-mapped I/O

External links
Flash Memory Solutions",5965480,https://en.wikipedia.org/wiki/Aperture_(computer_memory)
Approximate computing,"Approximate computing is an emerging paradigm for energy-efficient and/or high-performance design. It includes a plethora of computation techniques that return a possibly inaccurate result rather than a guaranteed accurate result, and that can be used for applications where an approximate result is sufficient for its purpose. One example of such situation is for a search engine where no exact answer may exist for a certain search query and hence, many answers may be acceptable. Similarly, occasional dropping of some frames in a video application can go undetected due to perceptual limitations of humans. Approximate computing is based on the observation that in many scenarios, although performing exact computation requires large amount of resources, allowing bounded approximation can provide disproportionate gains in performance and energy, while still achieving acceptable result accuracy.  For example, in k-means clustering algorithm, allowing only 5% loss in classification accuracy can provide 50 times energy saving compared to the fully accurate classification.
The key requirement in approximate computing is that approximation can be introduced only in non-critical data, since approximating critical data (e.g., control operations) can lead to disastrous consequences, such as program crash or erroneous output.","Approximate computing is an emerging paradigm for energy-efficient and/or high-performance design. It includes a plethora of computation techniques that return a possibly inaccurate result rather than a guaranteed accurate result, and that can be used for applications where an approximate result is sufficient for its purpose. One example of such situation is for a search engine where no exact answer may exist for a certain search query and hence, many answers may be acceptable. Similarly, occasional dropping of some frames in a video application can go undetected due to perceptual limitations of humans. Approximate computing is based on the observation that in many scenarios, although performing exact computation requires large amount of resources, allowing bounded approximation can provide disproportionate gains in performance and energy, while still achieving acceptable result accuracy.  For example, in k-means clustering algorithm, allowing only 5% loss in classification accuracy can provide 50 times energy saving compared to the fully accurate classification.
The key requirement in approximate computing is that approximation can be introduced only in non-critical data, since approximating critical data (e.g., control operations) can lead to disastrous consequences, such as program crash or erroneous output.

Strategies
Several strategies can be used for performing approximate computing.

Approximate circuits
Approximate arithmetic circuits: adders, multipliers and other logical circuits can reduce hardware overhead. For example, an approximate multi-bit adder can ignore the carry chain and thus, allow all its sub-adders to perform addition operation in parallel.
Approximate storage and memory
Instead of storing data values exactly, they can be stored approximately, e.g., by truncating the lower-bits in floating point data. Another method is to accept less reliable memory. For this, in DRAM and eDRAM, refresh rate assignments can be lowered or controlled. In SRAM, supply voltage can be lowered or controlled. Approximate storage can be applied to reduce MRAM's high write energy consumption. In general, any error detection and correction mechanisms should be disabled.
Software-level approximation
There are several ways to approximate at software level. Memoization or fuzzy memoization (the use of a vector database for approximate retrieval from a cache, i.e. fuzzy caching) can be applied. Some iterations of loops can be skipped (termed as loop perforation) to achieve a result faster. Some tasks can also be skipped, for example when a run-time condition suggests that those tasks are not going to be useful (task skipping). Monte Carlo algorithms and Randomized algorithms trade correctness for execution time guarantees. The computation can be reformulated according to paradigms that allow easily the acceleration on specialized hardware, e.g. a neural processing unit.
Approximate system
In an approximate system, different subsystems of the system such as the processor, memory, sensor, and communication modules are synergistically approximated to obtain a much better system-level Q-E trade-off curve compared to individual approximations to each of the subsystems.

Application areas
Approximate computing has been used in a variety of domains where the applications are error-tolerant, such as multimedia processing, machine learning, signal processing, scientific computing. Therefore, approximate computing is mostly driven by applications that are related to human perception/cognition and have inherent error resilience. Many of these applications are based on statistical or probabilistic computation, such as different approximations can be made to better suit the desired objectives.
One notable application in machine learning is that Google is using this approach in their Tensor processing units (TPU, a custom ASIC).

Derived paradigms
The main issue in approximate computing is the identification of the section of the application that can be approximated. In the case of large scale applications, it is very common to find people holding the expertise on approximate computing techniques not having enough expertise on the application domain (and vice versa). In order to solve this problem, programming paradigms have been proposed. They all have in common the clear role separation between application programmer and application domain expert. These approaches allow the spread of the most common optimizations and approximate computing techniques.

See also
Artificial neural network
Metaheuristic
PCMOS


== References ==",49277634,https://en.wikipedia.org/wiki/Approximate_computing
Arithmetic logic unit,"In computing, an arithmetic logic unit (ALU) is a combinational digital circuit that performs arithmetic and bitwise operations on integer binary numbers. This is in contrast to a floating-point unit (FPU), which operates on floating point numbers. It is a fundamental building block of many types of computing circuits, including the central processing unit (CPU) of computers, FPUs, and graphics processing units (GPUs).The inputs to an ALU are the data to be operated on, called operands, and a code indicating the operation to be performed; the ALU's output is the result of the performed operation. In many designs, the ALU also has status inputs or outputs, or both, which convey information about a previous operation or the current operation, respectively, between the ALU and external status registers.","In computing, an arithmetic logic unit (ALU) is a combinational digital circuit that performs arithmetic and bitwise operations on integer binary numbers. This is in contrast to a floating-point unit (FPU), which operates on floating point numbers. It is a fundamental building block of many types of computing circuits, including the central processing unit (CPU) of computers, FPUs, and graphics processing units (GPUs).The inputs to an ALU are the data to be operated on, called operands, and a code indicating the operation to be performed; the ALU's output is the result of the performed operation. In many designs, the ALU also has status inputs or outputs, or both, which convey information about a previous operation or the current operation, respectively, between the ALU and external status registers.

Signals
An ALU has a variety of input and output nets, which are the electrical conductors used to convey digital signals between the ALU and external circuitry. When an ALU is operating, external circuits apply signals to the ALU inputs and, in response, the ALU produces and conveys signals to external circuitry via its outputs.

Data
A basic ALU has three parallel data buses consisting of two input operands (A and B) and a result output (Y). Each data bus is a group of signals that conveys one binary integer number. Typically, the A, B and Y bus widths (the number of signals comprising each bus) are identical and match the native word size of the external circuitry (e.g., the encapsulating CPU or other processor).

Opcode
The opcode input is a parallel bus that conveys to the ALU an operation selection code, which is an enumerated value that specifies the desired arithmetic or logic operation to be performed by the ALU. The opcode size (its bus width) determines the maximum number of distinct operations the ALU can perform; for example, a four-bit opcode can specify up to sixteen different ALU operations. Generally, an ALU opcode is not the same as a machine language opcode, though in some cases it may be directly encoded as a bit field within a machine language opcode.

Status
Outputs
The status outputs are various individual signals that convey supplemental information about the result of the current ALU operation. General-purpose ALUs commonly have status signals such as:

Carry-out, which conveys the carry resulting from an addition operation, the borrow resulting from a subtraction operation, or the overflow bit resulting from a binary shift operation.
Zero, which indicates all bits of Y are logic zero.
Negative, which indicates the result of an arithmetic operation is negative.
Overflow, which indicates the result of an arithmetic operation has exceeded the numeric range of Y.
Parity, which indicates whether an even or odd number of bits in Y are logic one.Upon completion of each ALU operation, the status output signals are usually stored in external registers to make them available for future ALU operations (e.g., to implement multiple-precision arithmetic) or for controlling conditional branching. The collection of bit registers that store the status outputs are often treated as a single, multi-bit register, which is referred to as the ""status register"" or ""condition code register"".

Inputs
The status inputs allow additional information to be made available to the ALU when performing an operation. Typically, this is a single ""carry-in"" bit that is the stored carry-out from a previous ALU operation.

Circuit operation
An ALU is a combinational logic circuit, meaning that its outputs will change asynchronously in response to input changes. In normal operation, stable signals are applied to all of the ALU inputs and, when enough time (known as the ""propagation delay"") has passed for the signals to propagate through the ALU circuitry, the result of the ALU operation appears at the ALU outputs. The external circuitry connected to the ALU is responsible for ensuring the stability of ALU input signals throughout the operation, and for allowing sufficient time for the signals to propagate through the ALU before sampling the ALU result.
In general, external circuitry controls an ALU by applying signals to its inputs. Typically, the external circuitry employs sequential logic to control the ALU operation, which is paced by a clock signal of a sufficiently low frequency to ensure enough time for the ALU outputs to settle under worst-case conditions.
For example, a CPU begins an ALU addition operation by routing operands from their sources (which are usually registers) to the ALU's operand inputs, while the control unit simultaneously applies a value to the ALU's opcode input, configuring it to perform addition. At the same time, the CPU also routes the ALU result output to a destination register that will receive the sum. The ALU's input signals, which are held stable until the next clock, are allowed to propagate through the ALU and to the destination register while the CPU waits for the next clock. When the next clock arrives, the destination register stores the ALU result and, since the ALU operation has completed, the ALU inputs may be set up for the next ALU operation.

Functions
A number of basic arithmetic and bitwise logic functions are commonly supported by ALUs. Basic, general purpose ALUs typically include these operations in their repertoires:

Arithmetic operations
Add: A and B are summed and the sum appears at Y and carry-out.
Add with carry: A, B and carry-in are summed and the sum appears at Y and carry-out.
Subtract: B is subtracted from A (or vice versa) and the difference appears at Y and carry-out. For this function, carry-out is effectively a ""borrow"" indicator. This operation may also be used to compare the magnitudes of A and B; in such cases the Y output may be ignored by the processor, which is only interested in the status bits (particularly zero and negative) that result from the operation.
Subtract with borrow: B is subtracted from A (or vice versa) with borrow (carry-in) and the difference appears at Y and carry-out (borrow out).
Two's complement (negate): A (or B) is subtracted from zero and the difference appears at Y.
Increment: A (or B) is increased by one and the resulting value appears at Y.
Decrement: A (or B) is decreased by one and the resulting value appears at Y.
Pass through: all bits of A (or B) appear unmodified at Y. This operation is typically used to determine the parity of the operand or whether it is zero or negative, or to load the operand into a processor register.

Bitwise logical operations
AND: the bitwise AND of A and B appears at Y.
OR: the bitwise OR of A and B appears at Y.
Exclusive-OR: the bitwise XOR of A and B appears at Y.
Ones' complement: all bits of A (or B) are inverted and appear at Y.

Bit shift operations
ALU shift operations cause operand A (or B) to shift left or right (depending on the opcode) and the shifted operand appears at Y. Simple ALUs typically can shift the operand by only one bit position, whereas more complex ALUs employ barrel shifters that allow them to shift the operand by an arbitrary number of bits in one operation. In all single-bit shift operations, the bit shifted out of the operand appears on carry-out; the value of the bit shifted into the operand depends on the type of shift.

Arithmetic shift: the operand is treated as a two's complement integer, meaning that the most significant bit is a ""sign"" bit and is preserved.
Logical shift: a logic zero is shifted into the operand. This is used to shift unsigned integers.
Rotate: the operand is treated as a circular buffer of bits so its least and most significant bits are effectively adjacent.
Rotate through carry: the carry bit and operand are collectively treated as a circular buffer of bits.

Applications
Multiple-precision arithmetic
In integer arithmetic computations, multiple-precision arithmetic is an algorithm that operates on integers which are larger than the ALU word size. To do this, the algorithm treats each operand as an ordered collection of ALU-size fragments, arranged from most-significant (MS) to least-significant (LS) or vice versa. For example, in the case of an 8-bit ALU, the 24-bit integer 0x123456 would be treated as a collection of three 8-bit fragments: 0x12 (MS), 0x34, and 0x56 (LS). Since the size of a fragment exactly matches the ALU word size, the ALU can directly operate on this ""piece"" of operand.
The algorithm uses the ALU to directly operate on particular operand fragments and thus generate a corresponding fragment (a ""partial"") of the multi-precision result. Each partial, when generated, is written to an associated region of storage that has been designated for the multiple-precision result. This process is repeated for all operand fragments so as to generate a complete collection of partials, which is the result of the multiple-precision operation.
In arithmetic operations (e.g., addition, subtraction), the algorithm starts by invoking an ALU operation on the operands' LS fragments, thereby producing both a LS partial and a carry out bit. The algorithm writes the partial to designated storage, whereas the processor's state machine typically stores the carry out bit to an ALU status register. The algorithm then advances to the next fragment of each operand's collection and invokes an ALU operation on these fragments along with the stored carry bit from the previous ALU operation, thus producing another (more significant) partial and a carry out bit. As before, the carry bit is stored to the status register and the partial is written to designated storage. This process repeats until all operand fragments have been processed, resulting in a complete collection of partials in storage, which comprise the multi-precision arithmetic result.
In multiple-precision shift operations, the order of operand fragment processing depends on the shift direction. In left-shift operations, fragments are processed LS first because the LS bit of each partial—which is conveyed via the stored carry bit—must be obtained from the MS bit of the previously left-shifted, less-significant operand. Conversely, operands are processed MS first in right-shift operations because the MS bit of each partial must be obtained from the LS bit of the previously right-shifted, more-significant operand.
In bitwise logical operations (e.g., logical AND, logical OR), the operand fragments may be processed in any arbitrary order because each partial depends only on the corresponding operand fragments (the stored carry bit from the previous ALU operation is ignored).

Complex operations
Although an ALU can be designed to perform complex functions, the resulting higher circuit complexity, cost, power consumption and larger size makes this impractical in many cases. Consequently, ALUs are often limited to simple functions that can be executed at very high speeds (i.e., very short propagation delays), and the external processor circuitry is responsible for performing complex functions by orchestrating a sequence of simpler ALU operations.
For example, computing the square root of a number might be implemented in various ways, depending on ALU complexity:

Calculation in a single clock: a very complex ALU that calculates a square root in one operation.
Calculation pipeline: a group of simple ALUs that calculates a square root in stages, with intermediate results passing through ALUs arranged like a factory production line. This circuit can accept new operands before finishing the previous ones and produces results as fast as the very complex ALU, though the results are delayed by the sum of the propagation delays of the ALU stages. For more information, see the article on instruction pipelining.
Iterative calculation: a simple ALU that calculates the square root through several steps under the direction of a control unit.The implementations above transition from fastest and most expensive to slowest and least costly. The square root is calculated in all cases, but processors with simple ALUs will take longer to perform the calculation because multiple ALU operations must be performed.

Implementation
An ALU is usually implemented either as a stand-alone integrated circuit (IC), such as the 74181, or as part of a more complex IC. In the latter case, an ALU is typically instantiated by synthesizing it from a description written in VHDL, Verilog or some other hardware description language. For example, the following VHDL code describes a very simple 8-bit ALU:

History
Mathematician John von Neumann proposed the ALU concept in 1945 in a report on the foundations for a new computer called the EDVAC.The cost, size, and power consumption of electronic circuitry was relatively high throughout the infancy of the information age. Consequently, all serial computers and many early computers, such as the PDP-8, had a simple ALU that operated on one data bit at a time, although they often presented a wider word size to programmers. One of the earliest computers to have multiple discrete single-bit ALU circuits was the 1948 Whirlwind I, which employed sixteen such ""math units"" to enable it to operate on 16-bit words.
In 1967, Fairchild introduced the first ALU implemented as an integrated circuit, the Fairchild 3800, consisting of an eight-bit ALU with accumulator. Other integrated-circuit ALUs soon emerged, including four-bit ALUs such as the Am2901 and 74181. These devices were typically ""bit slice"" capable, meaning they had ""carry look ahead"" signals that facilitated the use of multiple interconnected ALU chips to create an ALU with a wider word size. These devices quickly became popular and were widely used in bit-slice minicomputers.
Microprocessors began to appear in the early 1970s. Even though transistors had become smaller, there was often insufficient die space for a full-word-width ALU and, as a result, some early microprocessors employed a narrow ALU that required multiple cycles per machine language instruction. Examples of this includes the popular Zilog Z80, which performed eight-bit additions with a four-bit ALU. Over time, transistor geometries shrank further, following Moore's law, and it became feasible to build wider ALUs on microprocessors.
Modern integrated circuit (IC) transistors are orders of magnitude smaller than those of the early microprocessors, making it possible to fit highly complex ALUs on ICs. Today, many modern ALUs have wide word widths, and architectural enhancements such as barrel shifters and binary multipliers that allow them to perform, in a single clock cycle, operations that would have required multiple operations on earlier ALUs.
ALUs can be realized as mechanical, electro-mechanical or electronic circuits and, in recent years, research into biological ALUs has been carried out (e.g., actin-based).

See also
Adder (electronics)
Address generation unit (AGU)
Load–store unit
Binary multiplier
Execution unit

References
Further reading
Hwang, Enoch (2006). Digital Logic and Microprocessor Design with VHDL. Thomson. ISBN 0-534-46593-5.
Stallings, William (2006). Computer Organization & Architecture: Designing for Performance (7th ed.). Pearson Prentice Hall. ISBN 0-13-185644-8.


== External links ==",27046146,https://en.wikipedia.org/wiki/Arithmetic_logic_unit
Autonomous decentralized system,"An autonomous decentralized system (or ADS) is a decentralized system composed of modules or components that are designed to operate independently but are capable of interacting with each other to meet the overall goal of the system. This design paradigm enables the system to continue to function in the event of component failures. It also enables maintenance and repair to be carried out while the system remains operational. Autonomous decentralized systems have a number of applications including industrial production lines, railway signalling and robotics.
The ADS has been recently expanded from control applications to service application and embedded systems, thus autonomous decentralized service systems and autonomous decentralized device systems.","An autonomous decentralized system (or ADS) is a decentralized system composed of modules or components that are designed to operate independently but are capable of interacting with each other to meet the overall goal of the system. This design paradigm enables the system to continue to function in the event of component failures. It also enables maintenance and repair to be carried out while the system remains operational. Autonomous decentralized systems have a number of applications including industrial production lines, railway signalling and robotics.
The ADS has been recently expanded from control applications to service application and embedded systems, thus autonomous decentralized service systems and autonomous decentralized device systems.

History
Autonomous decentralized systems were first proposed in 1977.ADS received significant attention as such systems have been deployed in Japanese railway systems for many years safely with over 7 billion trips, proving the value of this concept. Japan railway with ADS is considered as a smart train as it also learns.To recognizing this outstanding contribution, Kinji Mori has received numerous awards including 2013 IEEE Life Fellow, 2012 Distinguished Service Award, Tokyo Metropolitan Government, 2012 Distinguished Specialist among 1000 in the world, Chinese Government, 2008 IEICE Fellow, 1995 IEEE Fellow 1994 Research and Development Award of Excellence Achievers, Science and Technology Agency, 1994 Ichimura Industrial Prize, 1992 Technology Achievement Award, Society of Instrument and Control Engineers, 1988 National Patent Award, Science and Technology Agency, and 1988 Mainichi Technology Prize of Excellence. Dr. Mori donated the cash from Ichimura Industrial Price to IEEE to fund the IEEE Kanai Award.Since 1977, ADS has been a subject of research by many researchers in the world including US, Japan, EU particularly Germany, and China.

ADS architecture
An ADS is a decoupled architecture where each component or subsystem communicates by message passing using shared data fields. A unique feature of the ADS is that there is no central operating system or coordinator. Instead each subsystem manages its own functionality and its coordination with other subsystems. When a subsystem needs to interact with other subsystems it broadcasts the shared data fields containing the request to all other subsystems. This broadcast does not include the identification or address of any other subsystem. Rather the other subsystems will, depending on their purpose and function, receive the broadcast message and make their own determination on what action (if any) to take.
As ADS moves into the service-oriented architecture (SOA) or ADSS (Autonomous Decentralized Service System), the data transmission can be carried out by ESB (Enterprise Service Bus), and each agent can a service that receives data from the ESB and acts according to the service specification. The results are again transmitted by the ESB to other autonomous agents.
An ADS is also similar to a blackboard system used in AI where a collection of agents will act upon seeing any data change in the common blackboard.
An ADS may include human in the loop, with both human and autonomous agents both co-learn at the same time to perform the system functionality.Cloud computing also uses autonomous computing, but its architecture and framework are different from ADS.

Applications
One application of ADS is software testing, particularly combinatorial testing. A framework has been proposed based on ADS for concurrent combinatorial testing using AR and TA.

Conferences
IEEE International Symposium on Autonomous Decentralized Systems (ISADS) is the major conference on this topic. The Symposium is a biennial event and the first Symposium was held in 1993.

ISADS 1993: 30 March – 1 April 1993, in Kawasaki, Japan
ISADS 1995：25–27 April 1995, Phoenix, Arizona, U.S.
ISADS 1997：9–11 April 1997, Berlin, Germany
ISADS 1999：20–23 March 1999, Tokyo, Japan
ISADS 2001：26–28 March 2001, Dallas, Texas, U.S.
ISADS 2003：9–11 April 2003, Pisa, Italy
ISADS 2005：4–8 April, 2005, Chengdu, China
ISADS 2007：21–23 March 2007, Sedona, Arizona, U.S.
ISADS 2009：23–25 March 2009, Athens, Greece
ISADS 2011：29 June – 1 July 2011, Kobe, Japan
ISADS 2013：6–8 March 2013, Mexico City, Mexico
ISADS 2015：25–27 March 2015, Taichung, Taiwan
ISADS 2017：22–24 March 2017, Bangkok, Thailand
ISADS 2019：8–10 April 2019, Utrecht, Netherlands
ISADS 2023：15–17 March 2023, Mexico City, Mexico

See also
ATOS
Blackboard system
Peer-to-peer
Robot as a Service
Service-oriented architecture

References
Further reading
Wei-Tek Tsai, Charles J. Colbourn, Jie Luo, Guanqiu Qi, Qingyang Li, Xiaoying Bai, ""Test Algebra for Combinatorial Testing"" 8th IEEE International Workshop on Automation of Software Test (AST2013), 18–19 May 2013, San Francisco, California, USA",43867008,https://en.wikipedia.org/wiki/Autonomous_decentralized_system
Bare machine computing,"Bare Machine Computing (BMC) is a computer architecture based on bare machines. In the BMC paradigm, applications run without the support of any operating system (OS) or centralized kernel i.e., no intermediary software is loaded on the bare machine prior to running applications. The applications, which are called bare machine applications or simply BMC applications, do not use any persistent storage or a hard disk, and instead are stored on detachable mass storage such as a USB flash drive. A BMC program consists of a single application or a small set of applications (application suite) that runs as a single executable within one address space. BMC applications have direct access to the necessary hardware resources. They are self-contained, self-managed and self-controlled entities that boot, load and run without using any other software components or external software. BMC applications have inherent security due to their design. There are no OS-related vulnerabilities, and each application only contains the necessary (minimal) functionality. There is no privileged mode in a BMC system since applications only run in user mode. Also, application code is statically compiled-there is no means to dynamically alter BMC program flow during execution.","Bare Machine Computing (BMC) is a computer architecture based on bare machines. In the BMC paradigm, applications run without the support of any operating system (OS) or centralized kernel i.e., no intermediary software is loaded on the bare machine prior to running applications. The applications, which are called bare machine applications or simply BMC applications, do not use any persistent storage or a hard disk, and instead are stored on detachable mass storage such as a USB flash drive. A BMC program consists of a single application or a small set of applications (application suite) that runs as a single executable within one address space. BMC applications have direct access to the necessary hardware resources. They are self-contained, self-managed and self-controlled entities that boot, load and run without using any other software components or external software. BMC applications have inherent security due to their design. There are no OS-related vulnerabilities, and each application only contains the necessary (minimal) functionality. There is no privileged mode in a BMC system since applications only run in user mode. Also, application code is statically compiled-there is no means to dynamically alter BMC program flow during execution.

History
In the early days of computing, computer applications directly communicated to the hardware and there was no operating system. As applications grew larger encompassing various domains, OSes were invented. They served as middleware providing hardware abstractions to applications. OSes have grown immensely in their size and complexity resulting in attempts to reduce OS overhead and improve performance including Microkernel, Exokernel, Tiny-OS, OS-Kit, Palacios and Kitten, IO_Lite, bare-metal Linux, IBM-Libra and other lean kernels. In addition to the above approaches, in embedded systems such as smart phones, a small and dedicated portion of an OS and a given set of applications are closely integrated with the hardware. There are also a myriad of industrial control and gaming applications that run directly on the hardware. In most of these systems, the hardware is not open to run general purpose applications.
Bare machine computing originated with the application object (AO) concept invented by Karne at Towson University. It evolved over the years into dispersed operating systems (DOSC), and  eventually into the BMC paradigm.

Compared to conventional computing
In many ways, the BMC paradigm differs from conventional computing. There is no centralized kernel or OS running during the execution of BMC applications. Also, a bare machine in the BMC paradigm does not have any ownership or store valuable resources; and it can be used to run general purpose computing applications. Such characteristics are not found in conventional computing systems including embedded systems and    system on a chip (SOC). In addition, the BMC concept is a minimalistic approach to achieve simplicity, smaller code sizes and security.In bare machine computing a computing device is bare and its programs directly communicate to hardware. Application and systems programs are one and the same. No user mode or kernel mode in this system. When a given application suite is running, no other things are running in the box. The entire programs are written in a single programming language C/C++ with very little assembly code. Application programmer controls the entire hardware resources. It is based on events thus avoiding centralized kernel. A given BMC application suite simply runs on a given instruction set architecture (ISA) for ever, as along the ISA remains upward compatible. This approach is friendly to green computing as there is no need to dump hardware and software caused by today's planned obsolescence, in every aspect of our information systems.

Applications and research
The BMC paradigm has been used to implement webservers, split servers, VoIP, SIP server, email, webmail, Text Based Browser, security protocols, file systems, RAID, transformed bare SQLite., middleware for network cards interfaces (NICS), and Ethernet bonding on BMC webserver with dual NICs, Success in transforming conventional Windows or Linux applications to run as BMC applications will pave the way for new uses of the BMC paradigm. Design issues in running a webserver on bare PC with 32-bit multi-core architecture using TCP was described in. A novel client/server protocol for web-based communication over UDP using 32-bit architecture on bare machine was demonstrated in. Developing computer applications without any OS or kernel in 64-bit multi-core architecture and its implementation was shown in.


== References ==",55677685,https://en.wikipedia.org/wiki/Bare_machine_computing
Berkeley IRAM project,"The Berkeley IRAM project was a 1996–2004 research project in the Computer Science Division of the University of California, Berkeley which explored computer architecture enabled by the wide bandwidth between memory and processor made possible when both are designed on the same integrated circuit (chip). Since it was envisioned that such a chip would consist primarily of random-access memory (RAM), with a smaller part needed for the central processing unit (CPU), the research team used the term ""Intelligent RAM"" (or IRAM) to describe a chip with this architecture.  Like the J–Machine project at MIT, the primary objective of the research was to avoid the Von Neumann bottleneck which occurs when the connection between memory and CPU is a relatively narrow memory bus between separate integrated circuits.","The Berkeley IRAM project was a 1996–2004 research project in the Computer Science Division of the University of California, Berkeley which explored computer architecture enabled by the wide bandwidth between memory and processor made possible when both are designed on the same integrated circuit (chip). Since it was envisioned that such a chip would consist primarily of random-access memory (RAM), with a smaller part needed for the central processing unit (CPU), the research team used the term ""Intelligent RAM"" (or IRAM) to describe a chip with this architecture.  Like the J–Machine project at MIT, the primary objective of the research was to avoid the Von Neumann bottleneck which occurs when the connection between memory and CPU is a relatively narrow memory bus between separate integrated circuits.

Theory
With strong competitive pressures, the technology employed for each component of a computer system—principally CPU, memory, and offline storage—is typically selected to minimize the cost needed to attain a given level of performance. Though both microprocessor and memory are implemented as integrated circuits, the prevailing technology used for each differs; microprocessor technology optimizes speed and memory technology optimizes density. For this reason, the integration of memory and processor in the same chip has (for the most part) been limited to static random-access memory (SRAM), which may be implemented using circuit technology optimized for logic performance, rather than the denser and lower-cost dynamic random-access memory (DRAM), which is not. Microprocessor access to off-chip memory costs time and power, however, significantly limiting processor performance. For this reason computer architecture employing a hierarchy of memory systems has developed, in which static memory is integrated with the microprocessor for temporary, easily accessible storage (or cache) of data which is also retained off-chip in DRAM. Since the on-chip cache memory is redundant, its presence adds to cost and power. The purpose of the IRAM research project was to find if (in some computing applications) a better trade-off between cost and performance could be achieved with an architecture in which DRAM was integrated on-chip with the processor, thus eliminating the need for a redundant static memory cache—even though the technology used was not optimum for DRAM implementation.

Contribution
While it is fair to say that Berkeley IRAM did not achieve the recognition that Berkeley RISC received, the IRAM project was nevertheless influential. 
Although initial IRAM proposals focused on trade-offs between CPU and DRAM, IRAM research came to concentrate on vector instruction sets.
Its publications were early advocates of the incorporation of vector processing and vector instruction sets into microprocessors, and several commercial microprocessors, such as the Intel Advanced Vector Extensions (AVX), subsequently adopted vector processing instruction set extensions.

Notes
References
Bowman, N., Cardwell, N., Kozyrakis, C., Romer, C., Wang, H. (1997). ""Evaluation of existing architectures in IRAM systems"" First Workshop on Mixing Logic and DRAM, 24th International Symposium on Computer Architecture
Hennessy, J. L. and Patterson, D. A. (2007) Computer Architecture: A Quantitative Approach, Fourth Edition, Elsevier.
Kozyrakis, C.E., Perissakis, S., Patterson, D., Anderson, T., Asanovic, K., Cardwell, N., Fromm, R., Golbus, J., Gribstad, B., Keeton, K., Thomas, R., Treuhaft, N., Yelick, K. (1997) ""Scalable processors in the billion-transistor era: IRAM"" Computer 30 (9) pp. 75–78. [1] doi:10.1109/2.612252.
Kozyrakis, C.; Patterson, D. (1998). ""A New Direction for Computer Architecture Research"" Computer, 31 (11), pp. 24–32. [2] doi:10.1109/2.730733.
Kozyrakis, C.E., Patterson, D.A. (2003). ""Scalable, vector processors for embedded systems"" IEEE Micro '23 (6) p. 36. doi:10.1109/MM.2003.1261385.
Patterson, D. (1995). ""Microprocessors in 2020,"" The Solid-State Century: Scientific American Presents, pp. 62–67.
Patterson, D., Anderson, T., Cardwell, N., Fromm, R., Keeton, K., Kozyrakis, C., Thomas, R., and Yelick, K. (1997). ""A Case for Intelligent RAM,"" IEEE Micro, 17 (2), pp. 34–44. doi:10.1109/40.592312
Patterson, D., Asanovic, K., Brown, A., Fromm, R., Golbus, J., Gribstad, B., Keeton, K., Kozyrakis, C., Martin, D., Perissakis, S., Thomas, R., Treuhaft, N., Yelick, K. (1997). ""Intelligent RAM (IRAM): the industrial setting, applications, and architectures"" Proceedings 1997 IEEE International Conference on Computer Design: VLSI in Computers and Processors (ICCD '97), pp 2–7. [3] doi:10.1109/ICCD.1997.628842.

External links
The Berkeley IRAM Project
Berkeley IRAM Project publication list",23469224,https://en.wikipedia.org/wiki/Berkeley_IRAM_project
Branch Queue,"In Computer Architecture, While Branch predictions Branch queue takes place. When Branch Predictor predicts if the branch is taken or not, Branch queue stores the predictions that to be used later.
Branch queue consists 2 values only. Taken or Not Taken.
Branch queue helps other algorithms to increase parallelism and optimization. It is not software implemented or Hardware one, It falls under hardware software co-design.


== References ==","In Computer Architecture, While Branch predictions Branch queue takes place. When Branch Predictor predicts if the branch is taken or not, Branch queue stores the predictions that to be used later.
Branch queue consists 2 values only. Taken or Not Taken.
Branch queue helps other algorithms to increase parallelism and optimization. It is not software implemented or Hardware one, It falls under hardware software co-design.


== References ==",53549637,https://en.wikipedia.org/wiki/Branch_Queue
Bridging model,"In computer science, a bridging model is an abstract model of a computer which provides a conceptual bridge between the physical implementation of the machine and the abstraction available to a programmer of that machine; in other words, it is intended to provide a common level of understanding between hardware and software engineers.
A successful bridging model is one which can be efficiently implemented in reality and efficiently targeted by programmers; in particular, it should be possible for a compiler to produce good code from a typical high-level language. The term was introduced by Leslie Valiant's 1990 paper A Bridging Model for Parallel Computation, which argued that the strength of the von Neumann model was largely responsible for the success of computing as a whole. The paper goes on to develop the bulk synchronous parallel model as an analogous model for parallel computing.


== References ==","In computer science, a bridging model is an abstract model of a computer which provides a conceptual bridge between the physical implementation of the machine and the abstraction available to a programmer of that machine; in other words, it is intended to provide a common level of understanding between hardware and software engineers.
A successful bridging model is one which can be efficiently implemented in reality and efficiently targeted by programmers; in particular, it should be possible for a compiler to produce good code from a typical high-level language. The term was introduced by Leslie Valiant's 1990 paper A Bridging Model for Parallel Computation, which argued that the strength of the von Neumann model was largely responsible for the success of computing as a whole. The paper goes on to develop the bulk synchronous parallel model as an analogous model for parallel computing.


== References ==",20067629,https://en.wikipedia.org/wiki/Bridging_model
Byte addressing,"Byte addressing in hardware architectures supports accessing individual bytes. Computers with byte addressing are sometimes called byte machines, in contrast to word-addressable architectures, word machines,  that access data by word.","Byte addressing in hardware architectures supports accessing individual bytes. Computers with byte addressing are sometimes called byte machines, in contrast to word-addressable architectures, word machines,  that access data by word.

Background
The basic unit of digital storage is a bit, storing a single 0 or 1. Many common instruction set architectures can address more than 8 bits of data at a time. For example, 32-bit x86 processors have 32-bit general-purpose registers and can handle 32-bit (4-byte) data in single instructions. However, data in memory may be of various lengths. Instruction sets that support byte addressing supports accessing data in units that are narrower than the word length. An eight-bit processor like the Intel 8008 addresses eight bits, but as this is the full width of the accumulator and other registers, this could be considered either byte-addressable or word-addressable. 32-bit x86 processors, which address memory in 8-bit units but have 32-bit general-purpose registers and can operate on 32-bit items with a single instruction, are byte-addressable.
The advantage of word addressing is that more memory can be addressed in the same number of bits. The IBM 7094 has 15-bit addresses, so could address 32,768 words of 36 bits. The machines were often built with a full complement of addressable memory. Addressing 32,768 bytes of 6 bits would have been much less useful for scientific and engineering users. Or consider  32-bit x86 processors. Their 32-bit linear addresses can address 4 billion different items. Using word addressing, a 32-bit processor could address 4 Gigawords; or 16 Gigabytes using the modern 8-bit byte. If the 386 and its successors had used word addressing, scientists, engineers, and gamers could all have run programs that were 4x larger on 32-bit machines. However, word processing, rendering HTML, and all other text applications would have run more slowly.
When computers were so costly that they were only or mainly used for science and engineering, word addressing was the obvious mode. As it became cost-effective to use computers for handling text, hardware designers moved to byte addressing.
To illustrate why byte addressing is useful, consider the IBM 7094, which is word-addressable and has no concept of a byte. It has 36-bit words and stores its six-bit character codes six to a word. To change the 16th character in a string, the program has to determine that this is the fourth character of the third word in the string, fetch the third word, mask out the old value of the fourth character from the value held in the register, bitwise or in the new one, and then store back the amended word. At least six machine instructions. Usually, these are relegated to a subroutine, so every store or fetch of a single character involves the overhead of calling a subroutine and returning. With byte addressing, that can be achieved in one instruction: store this character code at that byte address. Text programs are easier to write, they are smaller, and run faster.

Hybrid systems
Some systems with word addressing, such as the PDP-6/10 and the GE-600/Honeywell 6000 series, have special mechanisms for accessing bytes efficiently.
On the PDP-6/10, special instructions operated on a byte pointer which included a word address, a bit offset, and a bit width. The LDB/DPB instructions loaded or stored one byte, the IBP instruction incremented the byte pointer, and the ILDB/IDPB instructions incremented the byte pointer and then loaded or stored the next byte. These instructions could operate on arbitrary-width bit fields.: 2-85–2-89  Programs took advantage of this flexibility: those not needing lowercase letters used the limited character set of 6-bit bytes for efficiency; most used 7-bit ASCII, packed 5 to a word with one unused bit; and the C implementation used 9-bit bytes because C requires all memory to be byte-addressable.
On the GE/Honeywell machines, special indirect addressing modes could be used on most instruction types, and operated on a byte pointer which could operate on either 6-bit or 9-bit bytes.Neither of these machines originally had direct machine support for random access to bytes; adjusting a byte pointer to point N bytes before or after the byte to which it currently pointed required a sequence of multiple instructions.  The KL10 PDP-10 model extended the IBP instruction to become the ""adjust byte pointer"" instruction, ADJBP, that could adjust a byte pointer by an arbitrary number of bytes.: 2-89–2-91

See also
Data structure alignment
Endianness


== References ==",1161199,https://en.wikipedia.org/wiki/Byte_addressing
Cache (computing),"In computing, a cache (  KASH) is a hardware or software component that stores data so that future requests for that data can be served faster; the data stored in a cache might be the result of an earlier computation or a copy of data stored elsewhere. A cache hit occurs when the requested data can be found in a cache, while a cache miss occurs when it cannot. Cache hits are served by reading data from the cache, which is faster than recomputing a result or reading from a slower data store; thus, the more requests that can be served from the cache, the faster the system performs.To be cost-effective, caches must be relatively small. Nevertheless, caches are effective in many areas of computing because typical computer applications access data with a high degree of locality of reference. Such access patterns exhibit temporal locality, where data is requested that has been recently requested, and spatial locality, where data is requested that is stored near data that has already been requested.","In computing, a cache (  KASH) is a hardware or software component that stores data so that future requests for that data can be served faster; the data stored in a cache might be the result of an earlier computation or a copy of data stored elsewhere. A cache hit occurs when the requested data can be found in a cache, while a cache miss occurs when it cannot. Cache hits are served by reading data from the cache, which is faster than recomputing a result or reading from a slower data store; thus, the more requests that can be served from the cache, the faster the system performs.To be cost-effective, caches must be relatively small. Nevertheless, caches are effective in many areas of computing because typical computer applications access data with a high degree of locality of reference. Such access patterns exhibit temporal locality, where data is requested that has been recently requested, and spatial locality, where data is requested that is stored near data that has already been requested.

Motivation
In memory design, there is an inherent trade-off between capacity and speed because larger capacity implies larger size and thus greater physical distances for signals to travel causing propagation delays. There is also a tradeoff between high-performance technologies such as SRAM and cheaper, easily mass-produced commodities such as DRAM, flash, or hard disks.
The buffering provided by a cache benefits one or both of latency and throughput (bandwidth).
A larger resource incurs a significant latency for access – e.g. it can take hundreds of clock cycles for a modern 4 GHz processor to reach DRAM. This is mitigated by reading large chunks into the cache, in the hope that subsequent reads will be from nearby locations and can be read from the cache. Prediction or explicit prefetching can be used to guess where future reads will come from and make requests ahead of time; if done optimally, the latency is bypassed altogether.
The use of a cache also allows for higher throughput from the underlying resource, by assembling multiple fine-grain transfers into larger, more efficient requests. In the case of DRAM circuits, the additional throughput may be gained by using a wider data bus.

Operation
Hardware implements cache as a block of memory for temporary storage of data likely to be used again. Central processing units (CPUs), solid-state drives (SSDs) and hard disk drives (HDDs) frequently include hardware-based cache, while web browsers and web servers commonly rely on software caching.
A cache is made up of a pool of entries. Each entry has associated data, which is a copy of the same data in some backing store. Each entry also has a tag, which specifies the identity of the data in the backing store of which the entry is a copy. 
When the cache client (a CPU, web browser, operating system) needs to access data presumed to exist in the backing store, it first checks the cache. If an entry can be found with a tag matching that of the desired data, the data in the entry is used instead. This situation is known as a cache hit. For example, a web browser program might check its local cache on disk to see if it has a local copy of the contents of a web page at a particular URL. In this example, the URL is the tag, and the content of the web page is the data. The percentage of accesses that result in cache hits is known as the hit rate or hit ratio of the cache.
The alternative situation, when the cache is checked and found not to contain any entry with the desired tag, is known as a cache miss. This requires a more expensive access of data from the backing store. Once the requested data is retrieved, it is typically copied into the cache, ready for the next access.
During a cache miss, some other previously existing cache entry is typically removed in order to make room for the newly retrieved data. The heuristic used to select the entry to replace is known as the replacement policy. One popular replacement policy, least recently used (LRU), replaces the oldest entry, the entry that was accessed less recently than any other entry. More sophisticated caching algorithms also take into account the frequency of use of entries.

Writing policies
When a system writes data to cache, it must at some point write that data to the backing store as well. The timing of this write is controlled by what is known as the write policy. There are two basic writing approaches:
Write-through: write is done synchronously both to the cache and to the backing store.
Write-back: initially, writing is done only to the cache. The write to the backing store is postponed until the modified content is about to be replaced by another cache block.A write-back cache is more complex to implement, since it needs to track which of its locations have been written over, and mark them as dirty for later writing to the backing store. The data in these locations are written back to the backing store only when they are evicted from the cache, an effect referred to as a lazy write. For this reason, a read miss in a write-back cache (which requires a block to be replaced by another) will often require two memory accesses to service: one to write the replaced data from the cache back to the store, and then one to retrieve the needed data.
Other policies may also trigger data write-back. The client may make many changes to data in the cache, and then explicitly notify the cache to write back the data.
Since no data is returned to the requester on write operations, a decision needs to be made on write misses, whether or not data would be loaded into the cache. This is defined by these two approaches:

Write allocate (also called fetch on write): data at the missed-write location is loaded to cache, followed by a write-hit operation. In this approach, write misses are similar to read misses.
No-write allocate (also called write-no-allocate or write around): data at the missed-write location is not loaded to cache, and is written directly to the backing store. In this approach, data is loaded into the cache on read misses only.Both write-through and write-back policies can use either of these write-miss policies, but usually they are paired in this way:
A write-back cache uses write allocate, hoping for subsequent writes (or even reads) to the same location, which is now cached.
A write-through cache uses no-write allocate. Here, subsequent writes have no advantage, since they still need to be written directly to the backing store.Entities other than the cache may change the data in the backing store, in which case the copy in the cache may become out-of-date or stale. Alternatively, when the client updates the data in the cache, copies of those data in other caches will become stale. Communication protocols between the cache managers which keep the data consistent are known as coherency protocols.

Prefetch
On a cache read miss, caches with a demand paging policy read the minimum amount from the backing store. For example, demand-paging virtual memory reads one page of virtual memory (often 4 kBytes) from disk into the disk cache in RAM. For example, a typical CPU reads a single L2 cache line of 128 bytes from DRAM into the L2 cache, and a single L1 cache line of 64 bytes from the L2 cache into the L1 cache.
Caches with a prefetch input queue or more general anticipatory paging policy go further—they not only read the data requested, but guess that the next chunk or two of data will soon be required, and so prefetch that data into the cache ahead of time. Anticipatory paging is especially helpful when the backing store has a long latency to read the first chunk and much shorter times to sequentially read the next few chunks, such as disk storage and DRAM.
A few operating systems go further with a loader that always pre-loads the entire executable into RAM.
A few caches go even further, not only pre-loading an entire file, but also starting to load other related files that may soon be requested, such as the page cache associated with a prefetcher or the web cache associated with link prefetching.

Examples of hardware caches
CPU cache
Small memories on or close to the CPU can operate faster than the much larger main memory. Most CPUs since the 1980s have used one or more caches, sometimes in cascaded levels; modern high-end embedded, desktop and server microprocessors may have as many as six types of cache (between levels and functions). Some examples of caches with a specific function are the D-cache, I-cache and the translation lookaside buffer for the memory management unit (MMU).

GPU cache
Earlier graphics processing units (GPUs) often had limited read-only texture caches, and introduced Morton order swizzled textures to improve 2D cache coherency. Cache misses would drastically affect performance, e.g. if mipmapping was not used. Caching was important to leverage 32-bit (and wider) transfers for texture data that was often as little as 4 bits per pixel, indexed in complex patterns by arbitrary UV coordinates and perspective transformations in inverse texture mapping.
As GPUs advanced (especially with General Purpose GPU compute shaders) they have developed progressively larger and increasingly general caches, including instruction caches for shaders, exhibiting increasingly common functionality with CPU caches. For example, GT200 architecture GPUs did not feature an L2 cache, while the GTX 490 GPU has 768 KB of last-level cache, the GTX TITAN GPU has 1536 KB of last-level cache, and the GTX 980 GPU has 2048 KB of last-level cache. These caches have grown to handle synchronisation primitives between threads and atomic operations, and interface with a CPU-style MMU.

DSPs
Digital signal processors have similarly generalised over the years. Earlier designs used scratchpad memory fed by direct memory access, but modern DSPs such as Qualcomm Hexagon often include a very similar set of caches to a CPU (e.g. Modified Harvard architecture with shared L2, split L1 I-cache and D-cache).

Translation lookaside buffer
A memory management unit (MMU) that fetches page table entries from main memory has a specialized cache, used for recording the results of virtual address to physical address translations. This specialized cache is called a translation lookaside buffer (TLB).

In-network cache
Information-centric networking
Information-centric networking (ICN) is an approach to evolve the Internet infrastructure away from a host-centric paradigm, based on perpetual connectivity and the end-to-end principle, to a network architecture in which the focal point is identified information (or content or data). Due to the inherent caching capability of the nodes in an ICN, it can be viewed as a loosely connected network of caches, which has unique requirements of caching policies. However, ubiquitous content caching introduces the challenge to content protection against unauthorized access, which requires extra care and solutions.Unlike proxy servers, in ICN the cache is a network-level solution. Therefore, it has rapidly changing cache states and higher request arrival rates; moreover, smaller cache sizes further impose a different kind of requirements on the content eviction policies. In particular, eviction policies for ICN should be fast and lightweight. Various cache replication and eviction schemes for different ICN architectures and applications have been proposed.

Policies
Time aware least recently used (TLRU)
The Time aware Least Recently Used (TLRU) is a variant of LRU designed for the situation where the stored contents in cache have a valid life time. The algorithm is suitable in network cache applications, such as ICN, content delivery networks (CDNs) and distributed networks in general. TLRU introduces a new term: TTU (Time to Use). TTU is a time stamp of a content/page which stipulates the usability time for the content based on the locality of the content and the content publisher announcement. Owing to this locality based time stamp, TTU provides more control to the local administrator to regulate in network storage.
In the TLRU algorithm, when a piece of content arrives, a cache node calculates the local TTU value based on the TTU value assigned by the content publisher. The local TTU value is calculated by using a locally defined function. Once the local TTU value is calculated the replacement of content is performed on a subset of the total content stored in cache node. The TLRU ensures that less popular and small life content should be replaced with the incoming content.

Least frequent recently used (LFRU)
The Least Frequent Recently Used (LFRU) cache replacement scheme combines the benefits of LFU and LRU schemes. LFRU is suitable for 'in network' cache applications, such as ICN, CDNs and distributed networks in general. In LFRU, the cache is divided into two partitions called privileged and unprivileged partitions. The privileged partition can be defined as a protected partition. If content is highly popular, it is pushed into the privileged partition. Replacement of the privileged partition is done as follows: LFRU evicts content from the unprivileged partition, pushes content from privileged partition to unprivileged partition, and finally inserts new content into the privileged partition. In the above procedure the LRU is used for the privileged partition and an approximated LFU (ALFU) scheme is used for the unprivileged partition, hence the abbreviation LFRU. The basic idea is to filter out the locally popular contents with ALFU scheme and push the popular contents to one of the privileged partition.

Weather forecast
In 2011, the use of smartphones with weather forecasting options was overly taxing AccuWeather servers; two requests within the same park would generate separate requests. An optimization by edge-servers to truncate the GPS coordinates to fewer decimal places meant that the cached results from the earlier query would be used. The number of to-the-server lookups per day dropped by half.

Software caches
Disk cache
While CPU caches are generally managed entirely by hardware, a variety of software manages other caches. The page cache in main memory, which is an example of disk cache, is managed by the operating system kernel.
While the disk buffer, which is an integrated part of the hard disk drive or solid state drive, is sometimes misleadingly referred to as ""disk cache"", its main functions are write sequencing and read prefetching. Repeated cache hits are relatively rare, due to the small size of the buffer in comparison to the drive's capacity. However, high-end disk controllers often have their own on-board cache of the hard disk drive's data blocks.
Finally, a fast local hard disk drive can also cache information held on even slower data storage devices, such as remote servers (web cache) or local tape drives or optical jukeboxes; such a scheme is the main concept of hierarchical storage management. Also, fast flash-based solid-state drives (SSDs) can be used as caches for slower rotational-media hard disk drives, working together as hybrid drives or solid-state hybrid drives (SSHDs).

Web cache
Web browsers and web proxy servers employ web caches to store previous responses from web servers, such as web pages and images. Web caches reduce the amount of information that needs to be transmitted across the network, as information previously stored in the cache can often be re-used. This reduces bandwidth and processing requirements of the web server, and helps to improve responsiveness for users of the web.Web browsers employ a built-in web cache, but some Internet service providers (ISPs) or organizations also use a caching proxy server, which is a web cache that is shared among all users of that network.
Another form of cache is P2P caching, where the files most sought for by peer-to-peer applications are stored in an ISP cache to accelerate P2P transfers. Similarly, decentralised equivalents exist, which allow communities to perform the same task for P2P traffic, for example, Corelli.

Memoization
A cache can store data that is computed on demand rather than retrieved from a backing store. Memoization is an optimization technique that stores the results of resource-consuming function calls within a lookup table, allowing subsequent calls to reuse the stored results and avoid repeated computation. It is related to the dynamic programming algorithm design methodology, which can also be thought of as a means of caching.

Content delivery network
A content delivery network (CDN) is a network of distributed servers that deliver pages and other Web content to a user, based on the geographic locations of the user, the origin of the web page and the content delivery server. 
CDNs began in the late 1990s as a way to speed up the delivery of static content, such as HTML pages, images and videos. By replicating content on multiple servers around the world and delivering it to users based on their location, CDNs can significantly improve the speed and availability of a website or application. When a user requests a piece of content, the CDN will check to see if it has a copy of the content in its cache. If it does, the CDN will deliver the content to the user from the cache.

Cloud storage gateway
A cloud storage gateway, also known as an edge filer, is a hybrid cloud storage device that connects a local network to one or more cloud storage services, typically object storage services such as Amazon S3. It provides a cache for frequently accessed data, providing high speed local access to frequently accessed data in the cloud storage service. Cloud storage gateways also provide additional benefits such as accessing cloud object storage through traditional file serving protocols as well as continued access to cached data during connectivity outages.

Other caches
The BIND DNS daemon caches a mapping of domain names to IP addresses, as does a resolver library.
Write-through operation is common when operating over unreliable networks (like an Ethernet LAN), because of the enormous complexity of the coherency protocol required between multiple write-back caches when communication is unreliable. For instance, web page caches and client-side network file system caches (like those in NFS or SMB) are typically read-only or write-through specifically to keep the network protocol simple and reliable.
Search engines also frequently make web pages they have indexed available from their cache. For example, Google provides a ""Cached"" link next to each search result. This can prove useful when web pages from a web server are temporarily or permanently inaccessible.
Database caching can substantially improve the throughput of database applications, for example in the processing of indexes, data dictionaries, and frequently used subsets of data.
A distributed cache uses networked hosts to provide scalability, reliability and performance to the application. The hosts can be co-located or spread over different geographical regions.

Buffer vs. cache
The semantics of a ""buffer"" and a ""cache"" are not totally different; even so, there are fundamental differences in intent between the process of caching and the process of buffering.
Fundamentally, caching realizes a performance increase for transfers of data that is being repeatedly transferred. While a caching system may realize a performance increase upon the initial (typically write) transfer of a data item, this performance increase is due to buffering occurring within the caching system.
With read caches, a data item must have been fetched from its residing location at least once in order for subsequent reads of the data item to realize a performance increase by virtue of being able to be fetched from the cache's (faster) intermediate storage rather than the data's residing location. With write caches, a performance increase of writing a data item may be realized upon the first write of the data item by virtue of the data item immediately being stored in the cache's intermediate storage, deferring the transfer of the data item to its residing storage at a later stage or else occurring as a background process. Contrary to strict buffering, a caching process must adhere to a (potentially distributed) cache coherency protocol in order to maintain consistency between the cache's intermediate storage and the location where the data resides. Buffering, on the other hand,

reduces the number of transfers for otherwise novel data amongst communicating processes, which amortizes overhead involved for several small transfers over fewer, larger transfers,
provides an intermediary for communicating processes which are incapable of direct transfers amongst each other, or
ensures a minimum data size or representation required by at least one of the communicating processes involved in a transfer.With typical caching implementations, a data item that is read or written for the first time is effectively being buffered; and in the case of a write, mostly realizing a performance increase for the application from where the write originated. Additionally, the portion of a caching protocol where individual writes are deferred to a batch of writes is a form of buffering. The portion of a caching protocol where individual reads are deferred to a batch of reads is also a form of buffering, although this form may negatively impact the performance of at least the initial reads (even though it may positively impact the performance of the sum of the individual reads). In practice, caching almost always involves some form of buffering, while strict buffering does not involve caching.
A buffer is a temporary memory location that is traditionally used because CPU instructions cannot directly address data stored in peripheral devices. Thus, addressable memory is used as an intermediate stage. Additionally, such a buffer may be feasible when a large block of data is assembled or disassembled (as required by a storage device), or when data may be delivered in a different order than that in which it is produced. Also, a whole buffer of data is usually transferred sequentially (for example to hard disk), so buffering itself sometimes increases transfer performance or reduces the variation or jitter of the transfer's latency as opposed to caching where the intent is to reduce the latency. These benefits are present even if the buffered data are written to the buffer once and read from the buffer once.
A cache also increases transfer performance. A part of the increase similarly comes from the possibility that multiple small transfers will combine into one large block. But the main performance-gain occurs because there is a good chance that the same data will be read from cache multiple times, or that written data will soon be read. A cache's sole purpose is to reduce accesses to the underlying slower storage. Cache is also usually an abstraction layer that is designed to be invisible from the perspective of neighboring layers.

See also
References
Further reading
""What Every Programmer Should Know About Memory""
""Caching in the Distributed Environment""",6829,https://en.wikipedia.org/wiki/Cache_(computing)
Cache control instruction,"In computing, a cache control instruction is a hint embedded in the instruction stream of a processor intended to improve the performance of hardware caches, using foreknowledge of the memory access pattern supplied by the programmer or compiler. They may reduce cache pollution, reduce bandwidth requirement, bypass latencies, by providing better control over the working set. Most cache control instructions do not affect the semantics of a program, although some can.","In computing, a cache control instruction is a hint embedded in the instruction stream of a processor intended to improve the performance of hardware caches, using foreknowledge of the memory access pattern supplied by the programmer or compiler. They may reduce cache pollution, reduce bandwidth requirement, bypass latencies, by providing better control over the working set. Most cache control instructions do not affect the semantics of a program, although some can.

Examples
Several such instructions, with variants, are supported by several processor instruction set architectures, such as ARM, MIPS, PowerPC, and x86.

Prefetch
Also termed data cache block touch, the effect is to request loading the cache line associated with a given address. This is performed by the PREFETCH instruction in the x86 instruction set. Some variants bypass higher levels of the cache hierarchy, which is useful in a 'streaming' context for data that is traversed once, rather than held in the working set. The prefetch should occur sufficiently far ahead in time to mitigate the latency of memory access, for example in a loop traversing memory linearly. The GNU Compiler Collection intrinsic function __builtin_prefetch can be used to invoke this in the programming languages C or C++.

Instruction prefetch
A variant of prefetch for the instruction cache.

Data cache block allocate zero
This hint is used to prepare cache lines before overwriting the contents completely. In this example, the CPU needn't load anything from main memory. The semantic effect is equivalent to an aligned memset of a cache-line sized block to zero, but the operation is effectively free.

Data cache block invalidate
This hint is used to discard cache lines, without committing their contents to main memory. Care is needed since incorrect results are possible. Unlike other cache hints, the semantics of the program are significantly modified. This is used in conjunction with allocate zero for managing temporary data. This saves unneeded main memory bandwidth and cache pollution.

Data cache block flush
This hint requests the immediate eviction of a cache line, making way for future allocations. It is used when it is known that data is no longer part of the working set.

Other hints
Some processors support a variant of load–store instructions that also imply cache hints. An example is load last in the PowerPC instruction set, which suggests that data will only be used once, i.e., the cache line in question may be pushed to the head of the eviction queue, whilst keeping it in use if still directly needed.

Alternatives
Automatic prefetch
In recent times, cache control instructions have become less popular as increasingly advanced application processor designs from Intel and ARM devote more transistors to accelerating code written in traditional languages, e.g., performing automatic prefetch, with hardware to detect linear access patterns on the fly. However the techniques may remain valid for throughput-oriented processors, which have a different throughput vs latency tradeoff, and may prefer to devote more area to execution units.

Scratchpad memory
Some processors support scratchpad memory  into which temporaries may be put, and direct memory access (DMA) to transfer data to and from main memory when needed. This approach is used by the Cell processor, and some embedded systems. These allow greater control over memory traffic and locality (as the working set is managed by explicit transfers), and eliminates the need for expensive cache coherency in a manycore machine.
The disadvantage is it requires significantly different programming techniques to use. It is very hard to adapt programs written in traditional languages such as C and C++ which present the programmer with a uniform view of a large address space (which is an illusion simulated by caches). A traditional microprocessor can more easily run legacy code, which may then be accelerated by cache control instructions, whilst a scratchpad based machine requires dedicated coding from the ground up to even function. Cache control instructions are specific to a certain cache line size, which in practice may vary between generations of processors in the same architectural family. Caches may also help coalescing reads and writes from less predictable access patterns (e.g., during texture mapping), whilst scratchpad DMA requires reworking algorithms for more predictable 'linear' traversals.
As such scratchpads are generally harder to use with traditional programming models, although dataflow models (such as TensorFlow) might be more suitable.

Vector fetch
Vector processors (for example modern graphics processing unit (GPUs) and Xeon Phi) use massive parallelism to achieve high throughput whilst working around memory latency (reducing the need for prefetching). Many read operations are issued in parallel, for subsequent invocations of a compute kernel; calculations may be put on hold awaiting future data, whilst the execution units are devoted to working on data from past requests data that has already turned up. This is easier for programmers to leverage in conjunction with the appropriate programming models (compute kernels), but harder to apply to general purpose programming.
The disadvantage is that many copies of temporary states may be held in the local memory of a processing element, awaiting data in flight.


== References ==",50781701,https://en.wikipedia.org/wiki/Cache_control_instruction
Cache hierarchy,"Cache hierarchy, or multi-level cache, is a memory architecture that uses a hierarchy of memory stores based on varying access speeds to cache data. Highly requested data is cached in high-speed access memory stores, allowing swifter access by central processing unit (CPU) cores.
Cache hierarchy is a form and part of memory hierarchy and can be considered a form of tiered storage. This design was intended to allow CPU cores to process faster despite the memory latency of main memory access. Accessing main memory can act as a bottleneck for CPU core performance as the CPU waits for data, while making all of main memory high-speed may be prohibitively expensive. High-speed caches are a compromise allowing high-speed access to the data most-used by the CPU, permitting a faster CPU clock.","Cache hierarchy, or multi-level cache, is a memory architecture that uses a hierarchy of memory stores based on varying access speeds to cache data. Highly requested data is cached in high-speed access memory stores, allowing swifter access by central processing unit (CPU) cores.
Cache hierarchy is a form and part of memory hierarchy and can be considered a form of tiered storage. This design was intended to allow CPU cores to process faster despite the memory latency of main memory access. Accessing main memory can act as a bottleneck for CPU core performance as the CPU waits for data, while making all of main memory high-speed may be prohibitively expensive. High-speed caches are a compromise allowing high-speed access to the data most-used by the CPU, permitting a faster CPU clock.

Background
In the history of computer and electronic chip development, there was a period when increases in CPU speed outpaced the improvements in memory access speed. The gap between the speed of CPUs and memory meant that the CPU would often be idle. CPUs were increasingly capable of running and executing larger amounts of instructions in a given time, but the time needed to access data from main memory prevented programs from fully benefiting from this capability. This issue motivated the creation of memory models with higher access rates in order to realize the potential of faster processors.This resulted in the concept of cache memory, first proposed by Maurice Wilkes, a British computer scientist at the University of Cambridge in 1965. He called such memory models ""slave memory"". Between roughly 1970 and 1990, papers and articles by Anant Agarwal, Alan Jay Smith, Mark D. Hill, Thomas R. Puzak, and others discussed better cache memory designs. The first cache memory models were implemented at the time, but even as researchers were investigating and proposing better designs, the need for faster memory models continued. This need resulted from the fact that although early cache models improved data access latency, with respect to cost and technical limitations it was not feasible for a computer system's cache to approach the size of main memory. From 1990 onward, ideas such as adding another cache level (second-level), as a backup for the first-level cache were proposed. Jean-Loup Baer, Wen-Hann Wang, Andrew W. Wilson, and others have conducted research on this model. When several simulations and implementations demonstrated the advantages of two-level cache models, the concept of multi-level caches caught on as a new and generally better model of cache memories. Since 2000, multi-level cache models have received widespread attention and are currently implemented in many systems, such as the three-level caches that are present in Intel's Core i7 products.

Multi-level cache
Accessing main memory for each instruction execution may result in slow processing, with the clock speed depending on the time required to find and fetch the data. In order to hide this memory latency from the processor, data caching is used. Whenever the data is required by the processor, it is fetched from the main memory and stored in the smaller memory structure called a cache. If there is any further need of that data, the cache is searched first before going to the main memory. This structure resides closer to the processor in terms of the time taken to search and fetch data with respect to the main memory. The advantages of using cache can be proven by calculating the average access time (AAT) for the memory hierarchy with and without the cache.

Average access time (AAT)
Caches, being small in size, may result in frequent misses – when a search of the cache does not provide the sought-after information – resulting in a call to main memory to fetch data. Hence, the AAT is affected by the miss rate of each structure from which it searches for the data.
AAT=hit time+((miss rate)×(miss penalty)){\displaystyle {\text{AAT}}={\text{hit time}}+(({\text{miss rate}})\times ({\text{miss penalty}}))}AAT for main memory is given by Hit time main memory. AAT for caches can be given by

Hit timecache + (Miss ratecache × Miss Penaltytime taken to go to main memory after missing cache).The hit time for caches is less than the hit time for the main memory, so the AAT for data retrieval is significantly lower when accessing data through the cache rather than main memory.

Trade-offs
While using the cache may improve memory latency, it may not always result in the required improvement for the time taken to fetch data due to the way caches are organized and traversed. For example, direct-mapped caches that are the same size usually have a higher miss rate than fully associative caches. This may also depend on the benchmark of the computer testing the processor and on the pattern of instructions. But using a fully associative cache may result in more power consumption, as it has to search the whole cache every time. Due to this, the trade-off between power consumption (and associated heat) and the size of the cache becomes critical in the cache design.

Evolution
In the case of a cache miss, the purpose of using such a structure will be rendered useless and the computer will have to go to the main memory to fetch the required data. However, with a multiple-level cache, if the computer misses the cache closest to the processor (level-one cache or L1) it will then search through the next-closest level(s) of cache and go to main memory only if these methods fail. The general trend is to keep the L1 cache small and at a distance of 1–2 CPU clock cycles from the processor, with the lower levels of caches increasing in size to store more data than L1, hence being more distant but with a lower miss rate. This results in a better AAT. The number of cache levels can be designed by architects according to their requirements after checking for trade-offs between cost, AATs, and size.

Performance gains
With the technology-scaling that allowed memory systems able to be accommodated on a single chip, most modern day processors have up to three or four cache levels. The reduction in the AAT can be understood by this example, where the computer checks AAT for different configurations up to L3 caches.
Example: main memory = 50 ns, L1 = 1 ns with 10% miss rate, L2 = 5 ns with 1% miss rate, L3 = 10 ns with 0.2% miss rate.

No cache, AAT = 50 ns
L1 cache, AAT = 1 ns + (0.1 × 50 ns) = 6 ns
L1–2 caches, AAT = 1 ns + (0.1 × [5 ns + (0.01 × 50 ns)]) = 1.55 ns
L1–3 caches, AAT = 1 ns + (0.1 × [5 ns + (0.01 × [10 ns + (0.002 × 50 ns)])]) = 1.5101 ns

Disadvantages
Cache memory comes at an increased marginal cost than main memory and thus can increase the cost of the overall system.
Cached data is stored only so long as power is provided to the cache.
Increased on-chip area required for memory system.
Benefits may be minimized or eliminated in the case of a large programs with poor temporal locality, which frequently access the main memory.

Properties
Banked versus unified
In a banked cache, the cache is divided into a cache dedicated to instruction storage and a cache dedicated to data. In contrast, a unified cache contains both the instructions and data in the same cache. During a process, the L1 cache (or most upper-level cache in relation to its connection to the processor) is accessed by the processor to retrieve both instructions and data. Requiring both actions to be implemented at the same time requires multiple ports and more access time in a unified cache. Having multiple ports requires additional hardware and wiring, leading to a significant structure between the caches and processing units. To avoid this, the L1 cache is often organized as a banked cache which results in fewer ports, less hardware, and generally lower access times.Modern processors have split caches, and in systems with multilevel caches higher level caches may be unified while lower levels split.

Inclusion policies
Whether a block present in the upper cache layer can also be present in the lower cache level is governed by the memory system's inclusion policy, which may be inclusive, exclusive or non-inclusive non-exclusive (NINE).With an inclusive policy, all the blocks present in the upper-level cache have to be present in the lower-level cache as well. Each upper-level cache component is a subset of the lower-level cache component. In this case, since there is a duplication of blocks, there is some wastage of memory. However, checking is faster.Under an exclusive policy, all the cache hierarchy components are completely exclusive, so that any element in the upper-level cache will not be present in any of the lower cache components. This enables complete usage of the cache memory. However, there is a high memory-access latency.The above policies require a set of rules to be followed in order to implement them. If none of these are forced, the resulting inclusion policy is called non-inclusive non-exclusive (NINE). This means that the upper-level cache may or may not be present in the lower-level cache.

Write policies
There are two policies which define the way in which a modified cache block will be updated in the main memory: write through and write back.In the case of write through policy, whenever the value of the cache block changes, it is further modified in the lower-level memory hierarchy as well. This policy ensures that the data is stored safely as it is written throughout the hierarchy.
However, in the case of the write back policy, the changed cache block will be updated in the lower-level hierarchy only when the cache block is evicted. A ""dirty bit"" is attached to each cache block and set whenever the cache block is modified. During eviction, blocks with a set dirty bit will be written to the lower-level hierarchy. Under this policy, there is a risk for data-loss as the most recently changed copy of a datum is only stored in the cache and therefore some corrective techniques must be observed.
In case of a write where the byte is not present in the cache block, the byte may be brought to the cache as determined by a write allocate or write no-allocate policy. Write allocate policy states that in case of a write miss, the block is fetched from the main memory and placed in the cache before writing. In the write no-allocate policy, if the block is missed in the cache it will write in the lower-level memory hierarchy without fetching the block into the cache.The common combinations of the policies are ""write block"", ""write allocate"", and ""write through write no-allocate"".

Shared versus private
A private cache is assigned to one particular core in a processor, and cannot be accessed by any other cores. In some architectures, each core has its own private cache; this creates the risk of duplicate blocks in a system's cache architecture, which results in reduced capacity utilization. However, this type of design choice in a multi-layer cache architecture can also be good for a lower data-access latency.A shared cache is a cache which can be accessed by multiple cores. Since it is shared, each block in the cache is unique and therefore has a larger hit rate as there will be no duplicate blocks. However, data-access latency can increase as multiple cores try to access the same cache.In multi-core processors, the design choice to make a cache shared or private impacts the performance of the processor. In practice, the upper-level cache L1 (or sometimes L2) is implemented as private and lower-level caches are implemented as shared. This design provides high access rates for the high-level caches and low miss rates for the lower-level caches.

Recent implementation models
Intel Broadwell microarchitecture (2014)
L1 cache (instruction and data) – 64 kB per core
L2 cache – 256 kB per core
L3 cache – 2 MB to 6 MB shared
L4 cache – 128 MB of eDRAM (Iris Pro models only)

Intel Kaby Lake microarchitecture (2016)
L1 cache (instruction and data) – 64 kB per core
L2 cache – 256 kB per core
L3 cache – 2 MB to 8 MB shared

AMD Zen microarchitecture (2017)
L1 cache – 32 kB data & 64 kB instruction per core, 4-way
L2 cache – 512 kB per core, 4-way inclusive
L3 cache – 4 MB local & remote per 4-core CCX, 2 CCXs per chiplet, 16-way non-inclusive. Up to 16 MB on desktop CPUs and 64 MB on server CPUs

AMD Zen 2 microarchitecture (2019)
L1 cache – 32 kB data & 32 kB instruction per core, 8-way
L2 cache – 512 kB per core, 8-way inclusive
L3 cache – 16 MB local per 4-core CCX, 2 CCXs per chiplet, 16-way non-inclusive. Up to 64 MB on desktop CPUs and 256 MB on server CPUs

IBM POWER7 (2010)
L1 cache (instruction and data) – each 64-banked, each bank has 2rd+1wr ports 32 kB, 8-way associative, 128B block, write through
L2 cache – 256 kB, 8-way, 128B block, write back, inclusive of L1, 2 ns access latency
L3 cache – 8 regions of 4 MB (total 32 MB), local region 6 ns, remote 30 ns, each region 8-way associative, DRAM data array, SRAM tag array

See also
POWER7
Intel Broadwell Microarchitecture
Intel Kaby Lake Microarchitecture
CPU cache
Memory hierarchy
CAS latency
Cache (computing)


== References ==",52036756,https://en.wikipedia.org/wiki/Cache_hierarchy
Cache pollution,"Cache pollution describes situations where an executing computer program loads data into CPU cache unnecessarily, thus causing other useful data to be evicted from the cache into lower levels of the memory hierarchy, degrading performance. For example, in a multi-core processor, one core may replace the blocks fetched by other cores into shared cache, or prefetched blocks may replace demand-fetched blocks from the cache.","Cache pollution describes situations where an executing computer program loads data into CPU cache unnecessarily, thus causing other useful data to be evicted from the cache into lower levels of the memory hierarchy, degrading performance. For example, in a multi-core processor, one core may replace the blocks fetched by other cores into shared cache, or prefetched blocks may replace demand-fetched blocks from the cache.

Example
Consider the following illustration:

 T[0] = T[0] + 1;
 for i in 0..sizeof(CACHE)
   C[i] = C[i] + 1;
 T[0] = T[0] + C[sizeof(CACHE)-1];

(The assumptions here are that the cache is composed of only one level, it is unlocked, the replacement policy is pseudo-LRU, all data is cacheable, the set associativity of the cache is N (where N > 1), and at most one processor register is available to contain program values).
Right before the loop starts, T[0] will be fetched from memory into cache, its value updated. However, as the loop executes, because the number of data elements the loop references requires the whole cache to be filled to its capacity, the cache block containing T[0] has to be evicted. Thus, the next time the program requests T[0] to be updated, the cache misses, and the cache controller  has to request the data bus to bring the corresponding cache block from main memory again.
In this case the cache is said to be ""polluted"".  Changing the pattern of data accesses by positioning the first update of T[0] between the loop and the second update can eliminate the inefficiency:

 for i in 0..sizeof(CACHE)
   C[i] = C[i] + 1;
 T[0] = T[0] + 1;
 T[0] = T[0] + C[sizeof(CACHE)-1];

Solutions
Other than code-restructuring mentioned above, the solution to cache pollution is ensure that only high-reuse data are stored in cache. This can be achieved by using special cache control instructions, operating system support or hardware support.
Examples of specialized hardware instructions include  ""lvxl"" provided by PowerPC AltiVec. This instruction loads a 128 bit wide value into a register and marks the corresponding cache block as ""least recently used"" i.e. as the prime candidate for eviction upon a need to evict a block from its cache set. To appropriately use that instruction in the context of the above example, the data elements referenced by the loop would have to be loaded using this instruction. When implemented in this manner, cache pollution would not take place, since the execution of such loop would not cause premature eviction of T[0] from cache. This would be avoided because, as the loop would progress, the addresses of the elements in C would map to the same cache way, leaving the actually older (but not marked as ""least recently used"") data intact on the other way(s). Only the oldest data (not pertinent for the example given) would be evicted from cache, which T[0] is not a member of, since its update occurs right before the loop's start.
Similarly, using operating system (OS) support, the pages in main memory that correspond to the C data array can be marked as ""caching inhibited"" or, in other words, non-cacheable. Similarly, at hardware level, cache bypassing schemes can be used which identify low-reuse data based on program access pattern and bypass them from cache. Also, shared cache can be partitioned to avoid destructive interference between running applications. The tradeoff in these solutions is that OS-based schemes may have large latency which may nullify the gain achievable by  cache pollution avoidance (unless the memory region has been non-cacheable to begin with), whereas hardware-based techniques may not have a global view of the program control flow and memory access pattern.

Increasing importance
Cache pollution control has been increasing in importance because the penalties caused by the so-called ""memory wall"" keep on growing. Chip manufacturers continue devising new tricks to overcome the ever increasing relative memory-to-CPU latency. They do that by increasing cache sizes and by providing useful ways for software engineers to control the way data arrives and stays at the CPU. Cache pollution control is one of the numerous devices available to the (mainly embedded) programmer. However, other methods, most of which are proprietary and highly hardware and application specific, are used as well.


== References ==",4505223,https://en.wikipedia.org/wiki/Cache_pollution
Cellular architecture,"Cellular architecture is a type of computer architecture prominent in parallel computing. Cellular architectures are relatively new, with IBM's Cell microprocessor being the first one to reach the market. Cellular architecture takes multi-core architecture design to its logical conclusion, by giving the programmer the ability to run large numbers of concurrent threads within a single processor. Each 'cell' is a compute node containing thread units, memory, and communication. Speed-up is achieved by exploiting thread-level parallelism inherent in many applications.
Cell, a cellular architecture containing 9 cores, is the processor used in the PlayStation 3. Another prominent cellular architecture is Cyclops64, a massively parallel architecture currently under development by IBM.
Cellular architectures follow the low-level programming paradigm, which exposes the programmer to much of the underlying hardware. This allows the programmer to greatly optimize their code for the platform, but at the same time makes it more difficult to develop software.","Cellular architecture is a type of computer architecture prominent in parallel computing. Cellular architectures are relatively new, with IBM's Cell microprocessor being the first one to reach the market. Cellular architecture takes multi-core architecture design to its logical conclusion, by giving the programmer the ability to run large numbers of concurrent threads within a single processor. Each 'cell' is a compute node containing thread units, memory, and communication. Speed-up is achieved by exploiting thread-level parallelism inherent in many applications.
Cell, a cellular architecture containing 9 cores, is the processor used in the PlayStation 3. Another prominent cellular architecture is Cyclops64, a massively parallel architecture currently under development by IBM.
Cellular architectures follow the low-level programming paradigm, which exposes the programmer to much of the underlying hardware. This allows the programmer to greatly optimize their code for the platform, but at the same time makes it more difficult to develop software.

See also
Cellular automaton

External links
Cellular architecture builds next generation supercomputers
ORNL, IBM, and the Blue Gene Project
Energy, IBM are partners in biological supercomputing project
Cell-based Architecture",4243241,https://en.wikipedia.org/wiki/Cellular_architecture
Comparison of CPU microarchitectures,The following is a comparison of CPU microarchitectures.,"The following is a comparison of CPU microarchitectures.

See also
Processor design
Comparison of instruction set architectures

Notes


== References ==",41682723,https://en.wikipedia.org/wiki/Comparison_of_CPU_microarchitectures
Comparison of instruction set architectures,"An instruction set architecture (ISA) is an abstract model of a computer, also referred to as computer architecture. A realization of an ISA is called an implementation. An ISA permits multiple implementations that may vary in performance, physical size, and monetary cost (among other things); because the ISA serves as the interface between software and hardware. Software that has been written for an ISA can run on different implementations of the same ISA. This has enabled binary compatibility between different generations of computers to be easily achieved, and the development of computer families. Both of these developments have helped to lower the cost of computers and to increase their applicability. For these reasons, the ISA is one of the most important abstractions in computing today.
An ISA defines everything a machine language programmer needs to know in order to program a computer. What an ISA defines differs between ISAs; in general, ISAs define the supported data types, what state there is (such as the main memory and registers) and their semantics (such as the memory consistency and addressing modes), the instruction set (the set of machine instructions that comprises a computer's machine language), and the input/output model.","An instruction set architecture (ISA) is an abstract model of a computer, also referred to as computer architecture. A realization of an ISA is called an implementation. An ISA permits multiple implementations that may vary in performance, physical size, and monetary cost (among other things); because the ISA serves as the interface between software and hardware. Software that has been written for an ISA can run on different implementations of the same ISA. This has enabled binary compatibility between different generations of computers to be easily achieved, and the development of computer families. Both of these developments have helped to lower the cost of computers and to increase their applicability. For these reasons, the ISA is one of the most important abstractions in computing today.
An ISA defines everything a machine language programmer needs to know in order to program a computer. What an ISA defines differs between ISAs; in general, ISAs define the supported data types, what state there is (such as the main memory and registers) and their semantics (such as the memory consistency and addressing modes), the instruction set (the set of machine instructions that comprises a computer's machine language), and the input/output model.

Base
In the early decades of computing, there were computers that used binary, decimal and even ternary. Contemporary computers are almost exclusively binary.

Bits
Computer architectures are often described as n-bit architectures. In the 20th century, n is often 8, 16, or 32, and in the 21st century, n is often 16, 32 or 64, but other sizes have been used (including 6, 12, 18, 24, 30, 36, 39, 48, 60, 128). This is actually a simplification as computer architecture often has a few more or less ""natural"" data sizes in the instruction set, but the hardware implementation of these may be very different. Many instruction set architectures have instructions that, on some implementations of that instruction set architecture, operate on half and/or twice the size of the processor's major internal datapaths. Examples of this are the Z80, MC68000, and the IBM System/360. On these types of implementations, a twice as wide operation typically also takes around twice as many clock cycles (which is not the case on high performance implementations). On the 68000, for instance, this means 8 instead of 4 clock ticks, and this particular chip may be described as a 32-bit architecture with a 16-bit implementation. The IBM System/360 instruction set architecture is 32-bit, but several models of the System/360 series, such as the IBM System/360 Model 30, have smaller internal data paths, while others, such as the 360/195, have larger internal data paths.  The external databus width is not used to determine the width of the architecture; the NS32008, NS32016 and NS32032 were basically the same 32-bit chip with different external data buses; the NS32764 had a 64-bit bus, and used 32-bit register. Early 32-bit microprocessors often had a 24-bit address, as did the System/360 processors.

Operands
The number of operands is one of the factors that may give an indication about the performance of the instruction set.
A three-operand architecture (2-in, 1-out) will allow

A := B + C

to be computed in one instruction
A two-operand architecture (1-in, 1-in-and-out) will allow

A := A + B

to be computed in one instruction, so two instructions will need to be executed to simulate a single three-operand instruction.

A := B
A := A + C

Encoding length
As can be seen in the table below some instructions sets keep to a very simple fixed encoding length, and other have variable-length.  Usually it is RISC architectures that have fixed encoding length and CISC architectures that have variable length, but not always.

Endianness
An architecture may use ""big"" or ""little"" endianness, or both, or be configurable to use either. Little-endian processors order bytes in memory with the least significant byte of a multi-byte value in the lowest-numbered memory location. Big-endian architectures instead arrange bytes with the most significant byte at the lowest-numbered address. The x86 architecture as well as several 8-bit architectures are little-endian. Most RISC architectures (SPARC, Power, PowerPC, MIPS) were originally big-endian (ARM was little-endian), but many (including ARM) are now configurable as either.
Endianness only applies to processors that allow individual addressing of units of data (such as bytes) that are smaller than the basic addressable machine word.

Instruction sets
The table below compares basic information about instruction set architectures.
Notes: 

Usually the number of registers is a power of two, e.g. 8, 16, 32. In some cases a hardwired-to-zero pseudo-register is included, as ""part"" of register files of architectures, mostly to simplify indexing modes. The column ""Registers"" only counts the integer ""registers"" usable by general instructions at any moment. Architectures always include special-purpose registers such as the program counter (PC). Those are not counted unless mentioned. Note that some architectures, such as SPARC, have register windows; for those architectures, the count indicates how many registers are available within a register window. Also, non-architected registers for register renaming are not counted.
In the ""Type"" column, ""Register–Register"" is a synonym for a common type of architecture, ""load–store"", meaning that no instruction can directly access memory except some special ones, i.e. load to or store from register(s), with the possible exceptions of memory locking instructions for atomic operations.
In the ""Endianness"" column, ""Bi"" means that the endianness is configurable.

See also
Central processing unit (CPU)
Processor design
Comparison of CPU microarchitectures
Instruction set architecture
Microprocessor
Benchmark (computing)

Notes


== References ==",22549668,https://en.wikipedia.org/wiki/Comparison_of_instruction_set_architectures
Computational RAM,Computational RAM (C-RAM) is random-access memory with processing elements integrated on the same chip.  This enables C-RAM to be used as a SIMD computer. It also can be used to more efficiently use memory bandwidth within a memory chip. The general technique of doing computations in memory is called Processing-In-Memory (PIM).,"Computational RAM (C-RAM) is random-access memory with processing elements integrated on the same chip.  This enables C-RAM to be used as a SIMD computer. It also can be used to more efficiently use memory bandwidth within a memory chip. The general technique of doing computations in memory is called Processing-In-Memory (PIM).

Overview
The most influential implementations of computational RAM came from The Berkeley IRAM Project. Vector IRAM (V-IRAM) combines DRAM with a vector processor integrated on the same chip.Reconfigurable Architecture DRAM (RADram) is DRAM with reconfigurable computing FPGA logic elements integrated on the same chip.
SimpleScalar simulations show that RADram (in a system with a conventional processor) can give orders of magnitude better performance on some problems than traditional DRAM (in a system with the same processor).
Some embarrassingly parallel computational problems are already limited by the von Neumann bottleneck between the CPU and the DRAM.
Some researchers expect that, for the same total cost, a machine built from computational RAM will run orders of magnitude faster than a traditional general-purpose computer on these kinds of problems.As of 2011, the ""DRAM process"" (few layers; optimized for high capacitance) and the ""CPU process"" (optimized for high frequency; typically twice as many BEOL layers as DRAM; since each additional layer reduces yield and increases manufacturing cost, such chips are relatively expensive per square millimeter compared to DRAM) is distinct enough that there are three approaches to computational RAM:

starting with a CPU-optimized process and a device that uses much embedded SRAM, add an additional process step (making it even more expensive per square millimeter) to allow replacing the embedded SRAM with embedded DRAM (eDRAM), giving ≈3x area savings on the SRAM areas (and so lowering net cost per chip).
starting with a system with a separate CPU chip and DRAM chip(s), add small amounts of ""coprocessor"" computational ability to the DRAM, working within the limits of the DRAM process and adding only small amounts of area to the DRAM, to do things that would otherwise be slowed down by the narrow bottleneck between CPU and DRAM: zero-fill selected areas of memory, copy large blocks of data from one location to another, find where (if anywhere) a given byte occurs in some block of data, etc. The resulting system—the unchanged CPU chip, and ""smart DRAM"" chip(s)—is at least as fast as the original system, and potentially slightly lower in cost. The cost of the small amount of extra area is expected to be more than paid back in savings in expensive test time, since there is now enough computational capability on a ""smart DRAM"" for a wafer full of DRAM to do most testing internally in parallel, rather than the traditional approach of fully testing one DRAM chip at a time with an expensive external automatic test equipment.
starting with a DRAM-optimized process, tweak the process to make it slightly more like the ""CPU process"", and build a (relatively low-frequency, but low-power and very high bandwidth) general-purpose CPU within the limits of that process.Some CPUs designed to be built on a DRAM process technology (rather than a ""CPU"" or ""logic"" process technology specifically optimized for CPUs) include
The Berkeley IRAM Project, TOMI Technology
and the AT&T DSP1.
Because a memory bus to off-chip memory has many times the capacitance of an on-chip memory bus, a system with separate DRAM and CPU chips can have several times the energy consumption of an IRAM system with the same computer performance.
Because computational DRAM is expected to run hotter than traditional DRAM,
and increased chip temperatures result in faster charge leakage from the DRAM storage cells,
computational DRAM is expected to require more frequent DRAM refresh.

Processor-in-/near-memory
A processor-in-/near-memory (PINM) refers to a computer processor (CPU) tightly coupled to memory, generally on the same silicon chip.
The chief goal of merging the processing and memory components in this way is to reduce memory latency and increase bandwidth. Alternatively reducing the distance that data needs to be moved reduces the power requirements of a system. Much of the complexity (and hence power consumption) in current processors stems from strategies to deal with avoiding memory stalls.

Examples
In the 1980s, a tiny CPU that executed FORTH was fabricated into a DRAM chip to improve PUSH and POP.  FORTH is a stack-oriented programming language and this improved its efficiency.
The transputer also had large on chip memory given that it was made in the early 1980s making it essentially a processor-in-memory.
Notable PIM projects include the Berkeley IRAM project (IRAM) at the University of California, Berkeley project and the University of Notre Dame PIM effort.

DRAM-based PIM Taxonomy
DRAM-based near-memory and in-memory designs can be categorized into four groups:

DIMM-level approaches place the processing units near memory chips. These approaches require minimal/no change in the data layout(e.g., Chameleon, and RecNMP  ).
Logic-layer-level approaches embed processing units in the logic layer of 3D stack memories and can benefit from the high bandwidth of 3D stack memories (e.g., TOP_PIM )
Bank-level approaches place processing units inside the memory layers, near each bank. UPMEM and Samsung's PIM  are examples of these approaches
Subarray-level approaches process data inside each subarray. The Subarray-level approaches provide the highest access parallelism but often perform only simple operations, such as bitwise operations on an entire memory row (e.g., DRISA ) or sequential processing of the memory row using a single-world ALU (e.g., Fulcrum  )

See also
Computing with Memory
SyNAPSE also combines processing and memory in one chip.
In-memory processing

References
Bibliography
Duncan Elliott, Michael Stumm, W. Martin Snelgrove, Christian Cojocaru, Robert McKenzie, ""Computational RAM: Implementing Processors in Memory"", IEEE Design and Test of Computers, vol. 16, no. 1,  pp. 32–41, Jan–Mar 1999. doi:10.1109/54.748803.",7630898,https://en.wikipedia.org/wiki/Computational_RAM
Computer architecture simulator,"A computer architecture simulator is a program that simulates the execution of computer architecture.
Computer architecture simulators are used for the following purposes:

Lowering cost by evaluating hardware designs without building physical hardware systems.
Enabling access to unobtainable hardware.
Increasing the precision and volume of computer performance data.
Introducing abilities that are not normally possible on real hardware such as running code backwards when an error is detected or running in faster-than-real time.","A computer architecture simulator is a program that simulates the execution of computer architecture.
Computer architecture simulators are used for the following purposes:

Lowering cost by evaluating hardware designs without building physical hardware systems.
Enabling access to unobtainable hardware.
Increasing the precision and volume of computer performance data.
Introducing abilities that are not normally possible on real hardware such as running code backwards when an error is detected or running in faster-than-real time.

Categories
Computer architecture simulators can be classified into many different categories depending on the context.

Scope: Microarchitecture simulators model the microprocessor and its components. Full-system simulators also model the processor, memory systems, and I/O devices.
Detail: Functional simulators, such as instruction set simulators, achieve the same function as modeled components. They can be simulated faster if timing is not considered. Timing simulators are functional simulators that also reproduce timing. Timing simulators can be further categorized into digital cycle-accurate and analog sub-cycle simulators.
Workload: Trace-driven simulators (also called event-driven simulators) react to pre-recorded streams of instructions with some fixed input. Execution-driven simulators allow dynamic change of instructions to be executed depending on different input data.

Full-system simulators
A full-system simulator is execution-driven architecture simulation at such a level of detail that complete software stacks from real systems can run on the simulator without any modification. A full system simulator provides virtual hardware that is independent of the nature of the host computer. The full-system model typically includes processor cores, peripheral devices, memories, interconnection buses, and network connections. Emulators are full system simulators that imitate obsolete hardware instead of under development hardware.
The defining property of full-system simulation compared to an instruction set simulator is that the model allows real device drivers and operating systems to be run, not just single programs.  Thus, full-system simulation makes it possible to simulate individual computers and networked computer nodes with all their software, from network device drivers to operating systems, network stacks, middleware, servers, and application programs.
Full system simulation can speed the system development process by making it easier to detect, recreate and repair flaws. The use of multi-core processors is driving the need for full system simulation, because it can be extremely difficult and time-consuming to recreate and debug errors without the controlled environment provided by virtual hardware. This also allows the software development to take place before the hardware is ready, thus helping to validate design decisions.

Cycle-accurate simulator
A cycle-accurate simulator is a computer program that simulates a microarchitecture on a cycle-by-cycle basis. In contrast an instruction set simulator simulates an instruction set architecture usually faster but not cycle-accurate to a specific implementation of this architecture; they are often used when emulating older hardware, where time precision is important for legacy reasons. Often, a cycle-accurate simulator is used when designing new microprocessors – they can be tested, and benchmarked accurately (including running full operating system, or compilers) without actually building a physical chip, and easily change design many times to meet expected plan.
Cycle-accurate simulators must ensure that all operations are executed in the proper virtual (or real if it is possible) time – branch prediction, cache misses, fetches, pipeline stalls, thread context switching, and many other subtle aspects of microprocessors.

See also
Instruction set simulator

References
External links
The Archer virtual infrastructure for computer architecture simulation
""Mikrocodesimulator MikroSim 2010"". 0/1-SimWare. Retrieved 2010-12-06.",8723369,https://en.wikipedia.org/wiki/Computer_architecture_simulator
Computer data storage,"Computer data storage is a technology consisting of computer components and recording media that are used to retain digital data. It is a core function and fundamental component of computers.: 15–16 The central processing unit (CPU) of a computer is what manipulates data by performing computations. In practice, almost all computers use a storage hierarchy,: 468–473  which puts fast but expensive and small storage options close to the CPU and slower but less expensive and larger options further away. Generally, the fast technologies are referred to as ""memory"", while slower persistent technologies are referred to as ""storage"".
Even the first computer designs, Charles Babbage's Analytical Engine and Percy Ludgate's Analytical Machine, clearly distinguished between processing and memory (Babbage stored numbers as rotations of gears, while Ludgate stored numbers as displacements of rods in shuttles). This distinction was extended in the Von Neumann architecture, where the CPU consists of two main parts: The control unit and the arithmetic logic unit (ALU). The former controls the flow of data between the CPU and memory, while the latter performs arithmetic and logical operations on data.","Computer data storage is a technology consisting of computer components and recording media that are used to retain digital data. It is a core function and fundamental component of computers.: 15–16 The central processing unit (CPU) of a computer is what manipulates data by performing computations. In practice, almost all computers use a storage hierarchy,: 468–473  which puts fast but expensive and small storage options close to the CPU and slower but less expensive and larger options further away. Generally, the fast technologies are referred to as ""memory"", while slower persistent technologies are referred to as ""storage"".
Even the first computer designs, Charles Babbage's Analytical Engine and Percy Ludgate's Analytical Machine, clearly distinguished between processing and memory (Babbage stored numbers as rotations of gears, while Ludgate stored numbers as displacements of rods in shuttles). This distinction was extended in the Von Neumann architecture, where the CPU consists of two main parts: The control unit and the arithmetic logic unit (ALU). The former controls the flow of data between the CPU and memory, while the latter performs arithmetic and logical operations on data.

Functionality
Without a significant amount of memory, a computer would merely be able to perform fixed operations and immediately output the result. It would have to be reconfigured to change its behavior. This is acceptable for devices such as desk calculators, digital signal processors, and other specialized devices. Von Neumann machines differ in having a memory in which they store their operating instructions and data.: 20  Such computers are more versatile in that they do not need to have their hardware reconfigured for each new program, but can simply be reprogrammed with new in-memory instructions; they also tend to be simpler to design, in that a relatively simple processor may keep state between successive computations to build up complex procedural results. Most modern computers are von Neumann machines.

Data organization and representation
A modern digital computer represents data using the binary numeral system. Text, numbers, pictures, audio, and nearly any other form of information can be converted into a string of bits, or binary digits, each of which has a value of 0 or 1. The most common unit of storage is the byte, equal to 8 bits. A piece of information can be handled by any computer or device whose storage space is large enough to accommodate the binary representation of the piece of information, or simply data. For example, the complete works of Shakespeare, about 1250 pages in print, can be stored in about five megabytes (40 million bits) with one byte per character.
Data are encoded by assigning a bit pattern to each character, digit, or multimedia object. Many standards exist for encoding (e.g. character encodings like ASCII, image encodings like JPEG, and video encodings like MPEG-4).
By adding bits to each encoded unit, redundancy allows the computer to detect errors in coded data and correct them based on mathematical algorithms. Errors generally occur in low probabilities due to random bit value flipping, or ""physical bit fatigue"", loss of the physical bit in the storage of its ability to maintain a distinguishable value (0 or 1), or due to errors in inter or intra-computer communication. A random bit flip (e.g. due to random radiation) is typically corrected upon detection. A bit or a group of malfunctioning physical bits (the specific defective bit is not always known; group definition depends on the specific storage device) is typically automatically fenced out, taken out of use by the device, and replaced with another functioning equivalent group in the device, where the corrected bit values are restored (if possible). The cyclic redundancy check (CRC) method is typically used in communications and storage for error detection. A detected error is then retried.
Data compression methods allow in many cases (such as a database) to represent a string of bits by a shorter bit string (""compress"") and reconstruct the original string (""decompress"") when needed. This utilizes substantially less storage (tens of percent) for many types of data at the cost of more computation (compress and decompress when needed). Analysis of the trade-off between storage cost saving and costs of related computations and possible delays in data availability is done before deciding whether to keep certain data compressed or not.
For security reasons, certain types of data (e.g. credit card information) may be kept encrypted in storage to prevent the possibility of unauthorized information reconstruction from chunks of storage snapshots.

Hierarchy of storage
Generally, the lower a storage is in the hierarchy, the lesser its bandwidth and the greater its access latency is from the CPU. This traditional division of storage to primary, secondary, tertiary, and off-line storage is also guided by cost per bit.
In contemporary usage, memory is usually fast but temporary semiconductor read-write memory, typically DRAM (dynamic RAM) or other such devices. Storage consists of storage devices and their media not directly accessible by the CPU (secondary or tertiary storage), typically hard disk drives, optical disc drives, and other devices slower than RAM but non-volatile (retaining contents when powered down).Historically, memory has, depending on technology, been called central memory, core memory, core storage, drum, main memory, real storage, or internal memory. Meanwhile, slower persistent storage devices have been referred to as secondary storage, external memory, or auxiliary/peripheral storage.

Primary storage
Primary storage (also known as main memory, internal memory, or prime memory), often referred to simply as memory, is the only one directly accessible to the CPU. The CPU continuously reads instructions stored there and executes them as required. Any data actively operated on is also stored there in a uniform manner.
Historically, early computers used delay lines, Williams tubes, or rotating magnetic drums as primary storage. By 1954, those unreliable methods were mostly replaced by magnetic-core memory. Core memory remained dominant until the 1970s, when advances in integrated circuit technology allowed semiconductor memory to become economically competitive.
This led to modern random-access memory (RAM). It is small-sized, light, but quite expensive at the same time. The particular types of RAM used for primary storage are volatile, meaning that they lose the information when not powered. Besides storing opened programs, it serves as disk cache and write buffer to improve both reading and writing performance. Operating systems borrow RAM capacity for caching so long as it's not needed by running software. Spare memory can be utilized as RAM drive for temporary high-speed data storage.
As shown in the diagram, traditionally there are two more sub-layers of the primary storage, besides main large-capacity RAM:

Processor registers are located inside the processor. Each register typically holds a word of data (often 32 or 64 bits). CPU instructions instruct the arithmetic logic unit to perform various calculations or other operations on this data (or with the help of it). Registers are the fastest of all forms of computer data storage.
Processor cache is an intermediate stage between ultra-fast registers and much slower main memory. It was introduced solely to improve the performance of computers. Most actively used information in the main memory is just duplicated in the cache memory, which is faster, but of much lesser capacity. On the other hand, main memory is much slower, but has a much greater storage capacity than processor registers. Multi-level hierarchical cache setup is also commonly used—primary cache being smallest, fastest and located inside the processor; secondary cache being somewhat larger and slower.Main memory is directly or indirectly connected to the central processing unit via a memory bus. It is actually two buses (not on the diagram): an address bus and a data bus. The CPU firstly sends a number through an address bus, a number called memory address, that indicates the desired location of data. Then it reads or writes the data in the memory cells using the data bus. Additionally, a memory management unit (MMU) is a small device between CPU and RAM recalculating the actual memory address, for example to provide an abstraction of virtual memory or other tasks.
As the RAM types used for primary storage are volatile (uninitialized at start up), a computer containing only such storage would not have a source to read instructions from, in order to start the computer. Hence, non-volatile primary storage containing a small startup program (BIOS) is used to bootstrap the computer, that is, to read a larger program from non-volatile secondary storage to RAM and start to execute it. A non-volatile technology used for this purpose is called ROM, for read-only memory (the terminology may be somewhat confusing as most ROM types are also capable of random access).
Many types of ""ROM"" are not literally read only, as updates to them are possible; however it is slow and memory must be erased in large portions before it can be re-written. Some embedded systems run programs directly from ROM (or similar), because such programs are rarely changed. Standard computers do not store non-rudimentary programs in ROM, and rather, use large capacities of secondary storage, which is non-volatile as well, and not as costly.
Recently, primary storage and secondary storage in some uses refer to what was historically called, respectively, secondary storage and tertiary storage.

Secondary storage
Secondary storage (also known as external memory or auxiliary storage) differs from primary storage in that it is not directly accessible by the CPU. The computer usually uses its input/output channels to access secondary storage and transfer the desired data to primary storage. Secondary storage is non-volatile (retaining data when its power is shut off). Modern computer systems typically have two orders of magnitude more secondary storage than primary storage because secondary storage is less expensive.
In modern computers, hard disk drives (HDDs) or solid-state drives (SSDs) are usually used as secondary storage. The access time per byte for HDDs or SSDs is typically measured in milliseconds (thousandths of a second), while the access time per byte for primary storage is measured in nanoseconds (billionths of a second). Thus, secondary storage is significantly slower than primary storage. Rotating optical storage devices, such as CD and DVD drives, have even longer access times. Other examples of secondary storage technologies include USB flash drives, floppy disks, magnetic tape, paper tape, punched cards, and RAM disks.
Once the disk read/write head on HDDs reaches the proper placement and the data, subsequent data on the track are very fast to access. To reduce the seek time and rotational latency, data are transferred to and from disks in large contiguous blocks. Sequential or block access on disks is orders of magnitude faster than random access, and many sophisticated paradigms have been developed to design efficient algorithms based on sequential and block access. Another way to reduce the I/O bottleneck is to use multiple disks in parallel to increase the bandwidth between primary and secondary memory.Secondary storage is often formatted according to a file system format, which provides the abstraction necessary to organize data into files and directories, while also providing metadata describing the owner of a certain file, the access time, the access permissions, and other information.
Most computer operating systems use the concept of virtual memory, allowing the utilization of more primary storage capacity than is physically available in the system. As the primary memory fills up, the system moves the least-used chunks (pages) to a swap file or page file on secondary storage, retrieving them later when needed. If a lot of pages are moved to slower secondary storage, the system performance is degraded.

Tertiary storage
Tertiary storage or tertiary memory is a level below secondary storage. Typically, it involves a robotic mechanism which will mount (insert) and dismount removable mass storage media into a storage device according to the system's demands; such data are often copied to secondary storage before use. It is primarily used for archiving rarely accessed information since it is much slower than secondary storage (e.g. 5–60 seconds vs. 1–10 milliseconds). This is primarily useful for extraordinarily large data stores, accessed without human operators. Typical examples include tape libraries and optical jukeboxes.
When a computer needs to read information from the tertiary storage, it will first consult a catalog database to determine which tape or disc contains the information. Next, the computer will instruct a robotic arm to fetch the medium and place it in a drive. When the computer has finished reading the information, the robotic arm will return the medium to its place in the library.
Tertiary storage is also known as nearline storage because it is ""near to online"". The formal distinction between online, nearline, and offline storage is:
Online storage is immediately available for I/O.
Nearline storage is not immediately available, but can be made online quickly without human intervention.
Offline storage is not immediately available, and requires some human intervention to become online.For example, always-on spinning hard disk drives are online storage, while spinning drives that spin down automatically, such as in massive arrays of idle disks (MAID), are nearline storage. Removable media such as tape cartridges that can be automatically loaded, as in tape libraries, are nearline storage, while tape cartridges that must be manually loaded are offline storage.

Off-line storage
Off-line storage is computer data storage on a medium or a device that is not under the control of a processing unit. The medium is recorded, usually in a secondary or tertiary storage device, and then physically removed or disconnected. It must be inserted or connected by a human operator before a computer can access it again. Unlike tertiary storage, it cannot be accessed without human interaction.
Off-line storage is used to transfer information since the detached medium can easily be physically transported. Additionally, it is useful for cases of disaster, where, for example, a fire destroys the original data, a medium in a remote location will be unaffected, enabling disaster recovery. Off-line storage increases general information security since it is physically inaccessible from a computer, and data confidentiality or integrity cannot be affected by computer-based attack techniques. Also, if the information stored for archival purposes is rarely accessed, off-line storage is less expensive than tertiary storage.
In modern personal computers, most secondary and tertiary storage media are also used for off-line storage. Optical discs and flash memory devices are the most popular, and to a much lesser extent removable hard disk drives; older examples include floppy disks and Zip disks. In enterprise uses, magnetic tape cartridges are predominant; older examples include open-reel magnetic tape and punched cards.

Characteristics of storage
Storage technologies at all levels of the storage hierarchy can be differentiated by evaluating certain core characteristics as well as measuring characteristics specific to a particular implementation. These core characteristics are volatility, mutability, accessibility, and addressability. For any particular implementation of any storage technology, the characteristics worth measuring are capacity and performance.

Volatility
Non-volatile memory retains the stored information even if not constantly supplied with electric power. It is suitable for long-term storage of information. Volatile memory requires constant power to maintain the stored information. The fastest memory technologies are volatile ones, although that is not a universal rule. Since the primary storage is required to be very fast, it predominantly uses volatile memory.
Dynamic random-access memory is a form of volatile memory that also requires the stored information to be periodically reread and rewritten, or refreshed, otherwise it would vanish. Static random-access memory is a form of volatile memory similar to DRAM with the exception that it never needs to be refreshed as long as power is applied; it loses its content when the power supply is lost.
An uninterruptible power supply (UPS) can be used to give a computer a brief window of time to move information from primary volatile storage into non-volatile storage before the batteries are exhausted. Some systems, for example EMC Symmetrix, have integrated batteries that maintain volatile storage for several minutes.

Mutability
Read/write storage or mutable storage
Allows information to be overwritten at any time. A computer without some amount of read/write storage for primary storage purposes would be useless for many tasks. Modern computers typically use read/write storage also for secondary storage.
Slow write, fast read storage
Read/write storage which allows information to be overwritten multiple times, but with the write operation being much slower than the read operation. Examples include CD-RW and SSD.
Write once storage
Write once read many (WORM) allows the information to be written only once at some point after manufacture. Examples include semiconductor programmable read-only memory and CD-R.
Read only storage
Retains the information stored at the time of manufacture. Examples include mask ROM ICs and CD-ROM.

Accessibility
Random access
Any location in storage can be accessed at any moment in approximately the same amount of time. Such characteristic is well suited for primary and secondary storage. Most semiconductor memories, flash memories and hard disk drives provide random access, though both semiconductor and flash memories have minimal latency when compared to hard disk drives, as no mechanical parts need to be moved.
Sequential access
The accessing of pieces of information will be in a serial order, one after the other; therefore the time to access a particular piece of information depends upon which piece of information was last accessed. Such characteristic is typical of off-line storage.

Addressability
Location-addressable
Each individually accessible unit of information in storage is selected with its numerical memory address. In modern computers, location-addressable storage usually limits to primary storage, accessed internally by computer programs, since location-addressability is very efficient, but burdensome for humans.
File addressable
Information is divided into files of variable length, and a particular file is selected with human-readable directory and file names. The underlying device is still location-addressable, but the operating system of a computer provides the file system abstraction to make the operation more understandable. In modern computers, secondary, tertiary and off-line storage use file systems.
Content-addressable
Each individually accessible unit of information is selected based on the basis of (part of) the contents stored there. Content-addressable storage can be implemented using software (computer program) or hardware (computer device), with hardware being faster but more expensive option. Hardware content addressable memory is often used in a computer's CPU cache.

Capacity
Raw capacity
The total amount of stored information that a storage device or medium can hold. It is expressed as a quantity of bits or bytes (e.g. 10.4 megabytes).
Memory storage density
The compactness of stored information. It is the storage capacity of a medium divided with a unit of length, area or volume (e.g. 1.2 megabytes per square inch).

Performance
Latency
The time it takes to access a particular location in storage. The relevant unit of measurement is typically nanosecond for primary storage, millisecond for secondary storage, and second for tertiary storage. It may make sense to separate read latency and write latency (especially for non-volatile memory) and in case of sequential access storage, minimum, maximum and average latency.
Throughput
The rate at which information can be read from or written to the storage. In computer data storage, throughput is usually expressed in terms of megabytes per second (MB/s), though bit rate may also be used. As with latency, read rate and write rate may need to be differentiated. Also accessing media sequentially, as opposed to randomly, typically yields maximum throughput.
Granularity
The size of the largest ""chunk"" of data that can be efficiently accessed as a single unit, e.g. without introducing additional latency.
Reliability
The probability of spontaneous bit value change under various conditions, or overall failure rate.Utilities such as hdparm and sar can be used to measure IO performance in Linux.

Energy use
Storage devices that reduce fan usage automatically shut-down during inactivity, and low power hard drives can reduce energy consumption by 90 percent.
2.5-inch hard disk drives often consume less power than larger ones. Low capacity solid-state drives have no moving parts and consume less power than hard disks. Also, memory may use more power than hard disks. Large caches, which are used to avoid hitting the memory wall, may also consume a large amount of power.

Security
Full disk encryption, volume and virtual disk encryption, andor file/folder encryption is readily available for most storage devices.Hardware memory encryption is available in Intel Architecture, supporting Total Memory Encryption (TME) and page granular memory encryption with multiple keys (MKTME). and in SPARC M7 generation since October 2015.

Vulnerability and reliability
Distinct types of data storage have different points of failure and various methods of predictive failure analysis.
Vulnerabilities that can instantly lead to total loss are head crashing on mechanical hard drives and failure of electronic components on flash storage.

Error detection
Impending failure on hard disk drives is estimable using S.M.A.R.T. diagnostic data that includes the hours of operation and the count of spin-ups, though its reliability is disputed.Flash storage may experience downspiking transfer rates as a result of accumulating errors, which the flash memory controller attempts to correct.
The health of optical media can be determined by measuring correctable minor errors, of which high counts signify deteriorating and/or low-quality media. Too many consecutive minor errors can lead to data corruption. Not all vendors and models of optical drives support error scanning.

Storage media
As of 2011, the most commonly used data storage media are semiconductor, magnetic, and optical, while paper still sees some limited usage. Some other fundamental storage technologies, such as all-flash arrays (AFAs) are proposed for development.

Semiconductor
Semiconductor memory uses semiconductor-based integrated circuit (IC) chips to store information. Data are typically stored in metal–oxide–semiconductor (MOS) memory cells. A semiconductor memory chip may contain millions of memory cells, consisting of tiny MOS field-effect transistors (MOSFETs) and/or MOS capacitors. Both volatile and non-volatile forms of semiconductor memory exist, the former using standard MOSFETs and the latter using floating-gate MOSFETs.
In modern computers, primary storage almost exclusively consists of dynamic volatile semiconductor random-access memory (RAM), particularly dynamic random-access memory (DRAM). Since the turn of the century, a type of non-volatile floating-gate semiconductor memory known as flash memory has steadily gained share as off-line storage for home computers. Non-volatile semiconductor memory is also used for secondary storage in various advanced electronic devices and specialized computers that are designed for them.
As early as 2006, notebook and desktop computer manufacturers started using flash-based solid-state drives (SSDs) as default configuration options for the secondary storage either in addition to or instead of the more traditional HDD.

Magnetic
Magnetic storage uses different patterns of magnetization on a magnetically coated surface to store information. Magnetic storage is non-volatile. The information is accessed using one or more read/write heads which may contain one or more recording transducers. A read/write head only covers a part of the surface so that the head or medium or both must be moved relative to another in order to access data. In modern computers, magnetic storage will take these forms:

Magnetic disk;
Floppy disk, used for off-line storage;
Hard disk drive, used for secondary storage.
Magnetic tape, used for tertiary and off-line storage;
Carousel memory (magnetic rolls).In early computers, magnetic storage was also used as:

Primary storage in a form of magnetic memory, or core memory, core rope memory, thin-film memory and/or twistor memory;
Tertiary (e.g. NCR CRAM) or off line storage in the form of magnetic cards;
Magnetic tape was then often used for secondary storage.Magnetic storage does not have a definite limit of rewriting cycles like flash storage and re-writeable optical media, as altering magnetic fields causes no physical wear. Rather, their life span is limited by mechanical parts.

Optical
Optical storage, the typical optical disc, stores information in deformities on the surface of a circular disc and reads this information by illuminating the surface with a laser diode and observing the reflection. Optical disc storage is non-volatile. The deformities may be permanent (read only media), formed once (write once media) or reversible (recordable or read/write media). The following forms are in common use as of 2009:
CD, CD-ROM, DVD, BD-ROM: Read only storage, used for mass distribution of digital information (music, video, computer programs);
CD-R, DVD-R, DVD+R, BD-R: Write once storage, used for tertiary and off-line storage;
CD-RW, DVD-RW, DVD+RW, DVD-RAM, BD-RE: Slow write, fast read storage, used for tertiary and off-line storage;
Ultra Density Optical or UDO is similar in capacity to BD-R or BD-RE and is slow write, fast read storage used for tertiary and off-line storage.Magneto-optical disc storage is optical disc storage where the magnetic state on a ferromagnetic surface stores information. The information is read optically and written by combining magnetic and optical methods. Magneto-optical disc storage is non-volatile, sequential access, slow write, fast read storage used for tertiary and off-line storage.
3D optical data storage has also been proposed.
Light induced magnetization melting in magnetic photoconductors has also been proposed for high-speed low-energy consumption magneto-optical storage.

Paper
Paper data storage, typically in the form of paper tape or punched cards, has long been used to store information for automatic processing, particularly before general-purpose computers existed. Information was recorded by punching holes into the paper or cardboard medium and was read mechanically (or later optically) to determine whether a particular location on the medium was solid or contained a hole. Barcodes make it possible for objects that are sold or transported to have some computer-readable information securely attached.
Relatively small amounts of digital data (compared to other digital data storage) may be backed up on paper as a matrix barcode for very long-term storage, as the longevity of paper typically exceeds even magnetic data storage.

Other storage media or substrates
Vacuum-tube memory
A Williams tube used a cathode-ray tube, and a Selectron tube used a large vacuum tube to store information. These primary storage devices were short-lived in the market, since the Williams tube was unreliable, and the Selectron tube was expensive.Electro-acoustic memory
Delay-line memory used sound waves in a substance such as mercury to store information. Delay-line memory was dynamic volatile, cycle sequential read/write storage, and was used for primary storage.Optical tape
is a medium for optical storage, generally consisting of a long and narrow strip of plastic, onto which patterns can be written and from which the patterns can be read back. It shares some technologies with cinema film stock and optical discs, but is compatible with neither. The motivation behind developing this technology was the possibility of far greater storage capacities than either magnetic tape or optical discs.Phase-change memory
uses different mechanical phases of phase-change material to store information in an X–Y addressable matrix and reads the information by observing the varying electrical resistance of the material. Phase-change memory would be non-volatile, random-access read/write storage, and might be used for primary, secondary and off-line storage. Most rewritable and many write-once optical disks already use phase-change material to store information.Holographic data storage
stores information optically inside crystals or photopolymers. Holographic storage can utilize the whole volume of the storage medium, unlike optical disc storage, which is limited to a small number of surface layers. Holographic storage would be non-volatile, sequential-access, and either write-once or read/write storage. It might be used for secondary and off-line storage. See Holographic Versatile Disc (HVD).Molecular memory
stores information in polymer that can store electric charge. Molecular memory might be especially suited for primary storage. The theoretical storage capacity of molecular memory is 10 terabits per square inch (16 Gbit/mm2).Magnetic photoconductors
store magnetic information, which can be modified by low-light illumination.DNA
stores information in DNA nucleotides. It was first done in 2012, when researchers achieved a ratio of 1.28 petabytes per gram of DNA. In March 2017 scientists reported that a new algorithm called a DNA fountain achieved 85% of the theoretical limit, at 215 petabytes per gram of DNA.

Related technologies
Redundancy
While a group of bits malfunction may be resolved by error detection and correction mechanisms (see above), storage device malfunction requires different solutions. The following solutions are commonly used and valid for most storage devices:

Device mirroring (replication) – A common solution to the problem is constantly maintaining an identical copy of device content on another device (typically of the same type). The downside is that this doubles the storage, and both devices (copies) need to be updated simultaneously with some overhead and possibly some delays. The upside is the possible concurrent reading of the same data group by two independent processes, which increases performance. When one of the replicated devices is detected to be defective, the other copy is still operational and is being utilized to generate a new copy on another device (usually available operational in a pool of stand-by devices for this purpose).
Redundant array of independent disks (RAID) – This method generalizes the device mirroring above by allowing one device in a group of devices to fail and be replaced with the content restored (Device mirroring is RAID with n=2). RAID groups of n=5 or n=6 are common. n>2 saves storage, when compared with n=2, at the cost of more processing during both regular operation (with often reduced performance) and defective device replacement.Device mirroring and typical RAID are designed to handle a single device failure in the RAID group of devices. However, if a second failure occurs before the RAID group is completely repaired from the first failure, then data can be lost. The probability of a single failure is typically small. Thus the probability of two failures in the same RAID group in time proximity is much smaller (approximately the probability squared, i.e., multiplied by itself). If a database cannot tolerate even such a smaller probability of data loss, then the RAID group itself is replicated (mirrored). In many cases such mirroring is done geographically remotely, in a different storage array, to handle recovery from disasters (see disaster recovery above).

Network connectivity
A secondary or tertiary storage may connect to a computer utilizing computer networks. This concept does not pertain to the primary storage, which is shared between multiple processors to a lesser degree.

Direct-attached storage (DAS) is a traditional mass storage, that does not use any network. This is still a most popular approach. This retronym was coined recently, together with NAS and SAN.
Network-attached storage (NAS) is mass storage attached to a computer which another computer can access at file level over a local area network, a private wide area network, or in the case of online file storage, over the Internet. NAS is commonly associated with the NFS and CIFS/SMB protocols.
Storage area network (SAN) is a specialized network, that provides other computers with storage capacity. The crucial difference between NAS and SAN, is that NAS presents and manages file systems to client computers, while SAN provides access at block-addressing (raw) level, leaving it to attaching systems to manage data or file systems within the provided capacity. SAN is commonly associated with Fibre Channel networks.

Robotic storage
Large quantities of individual magnetic tapes, and optical or magneto-optical discs may be stored in robotic tertiary storage devices. In tape storage field they are known as tape libraries, and in optical storage field optical jukeboxes, or optical disk libraries per analogy. The smallest forms of either technology containing just one drive device are referred to as autoloaders or autochangers.
Robotic-access storage devices may have a number of slots, each holding individual media, and usually one or more picking robots that traverse the slots and load media to built-in drives. The arrangement of the slots and picking devices affects performance. Important characteristics of such storage are possible expansion options: adding slots, modules, drives, robots. Tape libraries may have from 10 to more than 100,000 slots, and provide terabytes or petabytes of near-line information. Optical jukeboxes are somewhat smaller solutions, up to 1,000 slots.
Robotic storage is used for backups, and for high-capacity archives in imaging, medical, and video industries. Hierarchical storage management is a most known archiving strategy of automatically migrating long-unused files from fast hard disk storage to libraries or jukeboxes. If the files are needed, they are retrieved back to disk.

See also
Primary storage topics
Aperture (computer memory)
Dynamic random-access memory (DRAM)
Memory latency
Mass storage
Memory cell (disambiguation)
Memory management
Memory leak
Virtual memory
Memory protection
Page address register
Stable storage
Static random-access memory (SRAM)

Secondary, tertiary and off-line storage topics
Cloud storage
Hybrid cloud storage
Data deduplication
Data proliferation
Data storage tag used for capturing research data
Disk utility
File system
List of file formats
Global filesystem
Flash memory
Geoplexing
Information repository
Noise-predictive maximum-likelihood detection
Object(-based) storage
Removable media
Solid-state drive
Spindle
Virtual tape library
Wait state
Write buffer
Write protection
Cold data

Data storage conferences
Storage Networking World
Storage World Conference

Notes
References
This article incorporates public domain material from Federal Standard 1037C. General Services Administration. Archived from the original on 22 January 2022.

Further reading
Goda, K.; Kitsuregawa, M. (2012). ""The history of storage systems"". Proceedings of the IEEE. 100: 1433–1440. doi:10.1109/JPROC.2012.2189787.
Memory & storage, Computer history museum",5300,https://en.wikipedia.org/wiki/Computer_data_storage
Data memory-dependent prefetcher,"A data memory-dependent prefetcher (DMP) is a cache prefetcher that looks at cache memory content for possible pointer values, and prefetches the data at those locations into cache if it sees memory access patterns that suggest following those pointers would be useful.As of 2022, data prefetching was already a common feature in CPUs, but most prefetchers do not inspect the data within the cache for pointers, instead working by monitoring memory access patterns. Data memory-dependent prefetchers take this one step further.
The DMP in Apple's M1 computer architecture was demonstrated to be capable of being used as a memory side-channel in an attack published in early 2024. At that time its authors did not know of any practical way to exploit it. The DMP was subsequently discovered to be even more opportunistic than previously thought, and has now been demonstrated to be able to be used to effectively attack a variety of cryptographic algorithms in work called GoFetch by its authors.Intel Core processors also have DMP functionality (Intel use the term ""Data Dependent Prefetcher"") but Intel states that they have features to prevent their DMPs being used for side-channel attacks. The authors of GoFetch state that they were unable to make their exploit work on Intel processors.


== References ==","A data memory-dependent prefetcher (DMP) is a cache prefetcher that looks at cache memory content for possible pointer values, and prefetches the data at those locations into cache if it sees memory access patterns that suggest following those pointers would be useful.As of 2022, data prefetching was already a common feature in CPUs, but most prefetchers do not inspect the data within the cache for pointers, instead working by monitoring memory access patterns. Data memory-dependent prefetchers take this one step further.
The DMP in Apple's M1 computer architecture was demonstrated to be capable of being used as a memory side-channel in an attack published in early 2024. At that time its authors did not know of any practical way to exploit it. The DMP was subsequently discovered to be even more opportunistic than previously thought, and has now been demonstrated to be able to be used to effectively attack a variety of cryptographic algorithms in work called GoFetch by its authors.Intel Core processors also have DMP functionality (Intel use the term ""Data Dependent Prefetcher"") but Intel states that they have features to prevent their DMPs being used for side-channel attacks. The authors of GoFetch state that they were unable to make their exploit work on Intel processors.


== References ==",76411338,https://en.wikipedia.org/wiki/Data_memory-dependent_prefetcher
Dataflow,"In computing, dataflow is a broad concept, which has various meanings depending on the application and context. In the context of software architecture, data flow relates to stream processing or reactive programming.","In computing, dataflow is a broad concept, which has various meanings depending on the application and context. In the context of software architecture, data flow relates to stream processing or reactive programming.

Software architecture
Dataflow computing is a software paradigm based on the idea of representing computations as a directed graph, where nodes are computations and data flow along the edges. Dataflow can also be called stream processing or reactive programming.There have been multiple data-flow/stream processing languages of various forms (see Stream processing). Data-flow hardware (see Dataflow architecture) is an alternative to the classic von Neumann architecture. The most obvious example of data-flow programming is the subset known as reactive programming with spreadsheets. As a user enters new values, they are instantly transmitted to the next logical ""actor"" or formula for calculation.
Distributed data flows have also been proposed as a programming abstraction that captures the dynamics of distributed multi-protocols. The data-centric perspective characteristic of data flow programming promotes high-level functional specifications and simplifies formal reasoning about system components.

Hardware architecture
Hardware architectures for dataflow was a major topic in computer architecture research in the 1970s and early 1980s. Jack Dennis of the Massachusetts Institute of Technology (MIT) pioneered the field of static dataflow architectures. Designs that use conventional memory addresses as data dependency tags are called static dataflow machines. These machines did not allow multiple instances of the same routines to be executed simultaneously because the simple tags could not differentiate between them. Designs that use content-addressable memory are called dynamic dataflow machines by Arvind. They use tags in memory to facilitate parallelism.
Data flows around the computer through the components of the computer. It gets entered from the input devices and can leave through output devices (printer etc.).

Concurrency
A dataflow network is a network of concurrently executing processes or automata that can communicate by sending data over channels (see message passing.)
In Kahn process networks, named after Gilles Kahn, the processes are determinate. This implies that each determinate process computes a continuous function from input streams to output streams, and that a network of determinate processes is itself determinate, thus computing a continuous function. This implies that the behavior of such networks can be described by a set of recursive equations, which can be solved using fixed point theory. The movement and transformation of the data is represented by a series of shapes and lines.

Other meanings
Dataflow can also refer to:

Power BI Dataflow, a Power Query implementation in the cloud used for transforming source data into cleansed Power BI Datasets to be used by Power BI report developers through the Microsoft Dataverse (formerly called Microsoft Common Data Service).
Google Cloud Dataflow, a fully managed service for executing Apache Beam pipelines within the Google Cloud Platform ecosystem.

See also
 The dictionary definition of dataflow at Wiktionary

Binary Modular Dataflow Machine (BMDFM)
Communicating sequential processes
Complex event processing
Data-flow diagram
Data-flow analysis, a type of program analysis
Data stream
Dataflow programming (a programming language paradigm)
Erlang (programming language)
Flow-based programming (FBP)
Flow control (data)
Functional reactive programming
Lazy evaluation
Lucid (programming language)
Oz (programming language)
Packet flow
Pipeline (computing)
Pure Data
State transition
TensorFlow
Theano
Ward-Mellor methodology


== References ==",864364,https://en.wikipedia.org/wiki/Dataflow
Dataflow architecture,"Dataflow architecture is a dataflow-based computer architecture that directly contrasts the traditional von Neumann architecture or control flow architecture. Dataflow architectures have no program counter, in concept: the executability and execution of instructions is solely determined based on the availability of input arguments to the instructions, so that the order of instruction execution may be hard to predict.  
Although no commercially successful general-purpose computer hardware has used a dataflow architecture, it has been successfully implemented in specialized hardware such as in digital signal processing, network routing, graphics processing, telemetry, and more recently in data warehousing, and artificial intelligence (as: polymorphic dataflow Convolution Engine, structure-driven, dataflow scheduling). It is also very relevant in many software architectures today including database engine designs and parallel computing frameworks.Synchronous dataflow architectures tune to match the workload presented by real-time data path applications such as wire speed packet forwarding. Dataflow architectures that are deterministic in nature enable programmers to manage complex tasks such as processor load balancing, synchronization and accesses to common resources.Meanwhile, there is a clash of terminology, since the term dataflow is used for a subarea of parallel programming: for dataflow programming.","Dataflow architecture is a dataflow-based computer architecture that directly contrasts the traditional von Neumann architecture or control flow architecture. Dataflow architectures have no program counter, in concept: the executability and execution of instructions is solely determined based on the availability of input arguments to the instructions, so that the order of instruction execution may be hard to predict.  
Although no commercially successful general-purpose computer hardware has used a dataflow architecture, it has been successfully implemented in specialized hardware such as in digital signal processing, network routing, graphics processing, telemetry, and more recently in data warehousing, and artificial intelligence (as: polymorphic dataflow Convolution Engine, structure-driven, dataflow scheduling). It is also very relevant in many software architectures today including database engine designs and parallel computing frameworks.Synchronous dataflow architectures tune to match the workload presented by real-time data path applications such as wire speed packet forwarding. Dataflow architectures that are deterministic in nature enable programmers to manage complex tasks such as processor load balancing, synchronization and accesses to common resources.Meanwhile, there is a clash of terminology, since the term dataflow is used for a subarea of parallel programming: for dataflow programming.

History
Hardware architectures for dataflow was a major topic in computer architecture research in the 1970s and early 1980s. Jack Dennis of MIT pioneered the field of static dataflow architectures while the Manchester Dataflow Machine and MIT Tagged Token architecture were major projects in dynamic dataflow.
The research, however, never overcame the problems related to:

Efficiently broadcasting data tokens in a massively parallel system.
Efficiently dispatching instruction tokens in a massively parallel system.
Building content-addressable memory (CAM) large enough to hold all of the dependencies of a real program.Instructions and their data dependencies proved to be too fine-grained to be effectively distributed in a large network. That is, the time for the instructions and tagged results to travel through a large connection network was longer than the time to do many computations.  
Nonetheless, out-of-order execution (OOE) has become the dominant computing paradigm since the 1990s. It is a form of restricted dataflow. This paradigm introduced the idea of an execution window. The execution window follows the sequential order of the von Neumann architecture, however within the window, instructions are allowed to be completed in data dependency order. This is accomplished in CPUs that dynamically tag the data dependencies of the code in the execution window. The logical complexity of dynamically keeping track of the data dependencies, restricts OOE CPUs to a small number of execution units (2-6) and limits the execution window sizes to the range of 32 to 200 instructions, much smaller than envisioned for full dataflow machines.

Dataflow architecture topics
Static and dynamic dataflow machines
Designs that use conventional memory addresses as data dependency tags are called static dataflow machines. These machines did not allow multiple instances of the same routines to be executed simultaneously because the simple tags could not differentiate between them. 
Designs that use content-addressable memory (CAM) are called dynamic dataflow machines. They use tags in memory to facilitate parallelism.

Compiler
Normally, in the control flow architecture, compilers analyze program source code for data dependencies between instructions in order to better organize the instruction sequences in the binary output files.  The instructions are organized sequentially but the dependency information itself is not recorded in the binaries. Binaries compiled for a dataflow machine contain this dependency information. 
A dataflow compiler records these dependencies by creating unique tags for each dependency instead of using variable names. By giving each dependency a unique tag, it allows the non-dependent code segments in the binary to be executed out of order and in parallel. Compiler detects the loops, break statements and various programming control syntax for data flow.

Programs
Programs are loaded into the CAM of a dynamic dataflow computer. When all of the tagged operands of an instruction become available (that is, output from previous instructions and/or user input), the instruction is marked as ready for execution by an execution unit. 
This is known as activating or firing the instruction. Once an instruction is completed by an execution unit, its output data is sent (with its tag) to the CAM. Any instructions that are dependent upon this particular datum (identified by its tag value) are then marked as ready for execution. In this way, subsequent instructions are executed in proper order, avoiding race conditions. This order may differ from the sequential order envisioned by the human programmer, the programmed order.

Instructions
An instruction, along with its required data operands, is transmitted to an execution unit as a packet, also called an instruction token. Similarly, output data is transmitted back to the CAM as a data token. The packetization of instructions and results allows for parallel execution of ready instructions on a large scale. 
Dataflow networks deliver the instruction tokens to the execution units and return the data tokens to the CAM. In contrast to the conventional von Neumann architecture, data tokens are not permanently stored in memory, rather they are transient messages that only exist when in transit to the instruction storage.

See also
Parallel computing
SISAL
Binary Modular Dataflow Machine (BMDFM)
Systolic array
Transport triggered architecture
Network on a chip (NoC)
System on a chip (SoC)
In-memory computing


== References ==",1325032,https://en.wikipedia.org/wiki/Dataflow_architecture
Directory-based cache coherence,"In computer engineering, directory-based cache coherence is a type of cache coherence mechanism, where directories are used to manage caches in place of bus snooping. Bus snooping methods scale poorly due to the use of broadcasting. These methods can be used to target both performance and scalability of directory systems.","In computer engineering, directory-based cache coherence is a type of cache coherence mechanism, where directories are used to manage caches in place of bus snooping. Bus snooping methods scale poorly due to the use of broadcasting. These methods can be used to target both performance and scalability of directory systems.

Full bit vector format
In the full bit vector format, for each possible cache line in memory, a bit is used to track whether every individual processor has that line stored in its cache. The full bit vector format is the simplest structure to implement, but the least scalable. The SGI Origin 2000 uses a combination of full bit vector and coarse bit vector depending on the number of processors.Each directory entry must have 1 bit stored per processor per cache line, along with bits for tracking the state of the directory. This leads to the total size required being (number of processors)×number of cache lines, having a storage overhead ratio of (number of processors)/(cache block size×8).
It can be observed that directory overhead scales linearly with the number of processors. While this may be fine for a small number of processors, when implemented in large systems the size requirements for the directory becomes excessive. For example, with a block size of 32 bytes and 1024 processors, the storage overhead ratio becomes 1024/(32×8) = 400%.

Coarse bit vector format
The coarse bit vector format has a similar structure to the full bit vector format, though rather than tracking one bit per processor for every cache line, the directory groups several processors into nodes, storing whether a cache line is stored in a node rather than a line. This improves size requirements at the expense of bus traffic saving (processors per node)×(total lines) bits of space. Thus the ratio overhead is the same, just replacing number of processors with number of processor groups. When a bus request is made for a cache line that one processor in the group has, the directory broadcasts the signal into every processor in the node rather than just the caches that contain it, leading to unnecessary traffic to nodes that do not have the data cached.In this case the directory entry uses 1 bit for a group of processors for each cache line. For the same example as Full Bit Vector format if we consider 1 bit for 8 processors as a group, then the storage overhead will be 128/(32×8)=50%. This is a significant improvement over the Full Bit Vector format.

Sparse directory format
A cache only stores a small subset of blocks in main memory at a particular time. Hence most of the entries in the directory will belong to uncached blocks. In the sparse directory format the wastage is reduced by storing only the cached blocks in the directory. Consider a processor with a cache size of 64KB with a block size of 32 bytes and the main memory size to be 4MB. The maximum number of entries that the directory can have in the sparse directory format is 2048. If the directory has an entry for all the blocks in the memory the number of entries in the directory will be 131072. Thus it is evident that the storage improvement provided by sparse directory format is very significant.

Number-balanced binary tree format
In this format the directory is decentralised and distributed among the caches that share a memory block. Different caches that share a memory block are arranged in the form of a binary tree. The cache that accesses a memory block first is the root node. Each memory block has the root node information (HEAD) and Sharing counter field (SC). The SC field has the number of caches that share the block. Each cache entry has pointers to the next sharing caches known as L-CHD and R-CHD.  A condition for this directory is that the binary tree should be number balanced, i.e the number of nodes in the left sub tree must be equal to or one greater than the number of nodes in the right subtree. All the subtrees should also be number balanced.

Chained directory format
In this format the memory holds the directory pointer to the latest cache that accessed the block and each cache has the pointer to the previous cache that accessed the block. So when a processor sends a write request to a block in memory, the processor sends invalidations down the chain of pointers.  In this directory when a cache block is replaced we need to traverse the list in order to change the directory which increases latency. In order to prevent this doubly linked lists are widely used now in which each cached copy has pointers to previous and the next cache that accesses the block.

Limited pointer format
The limited pointer format uses a set number of pointers to track the processors that are caching the data. When a new processor caches a block, a free pointer is chosen from a pool to point to that processor. There are a few options for handling cases when the number of sharers exceeds the number of free pointers. One method is to invalidate one of the sharers, using its pointer for the new requestor, though this can be costly in cases where a block has a large number of readers, such as a lock. Another method is to have a separate pool of free pointers available to all the blocks. This method is usually effective as the number of blocks shared by a large number of processors is not normally very large.


== References ==",51518781,https://en.wikipedia.org/wiki/Directory-based_cache_coherence
Directory-based coherence,"Directory-based coherence is a mechanism to handle cache coherence problem in distributed shared memory (DSM) a.k.a. non-uniform memory access (NUMA). Another popular way is to use a special type of computer bus between all the nodes as a ""shared bus"" (a.k.a. system bus). Directory-based coherence uses a special directory to serve instead of the shared bus in the bus-based coherence protocols. Both of these designs use the corresponding medium (i.e. directory or bus) as a tool to facilitate the communication between different nodes, and to guarantee that the coherence protocol is working properly along all the communicating nodes. In directory based cache coherence, this is done by using this directory to keep track of the status of all cache blocks, the status of each block includes in which cache coherence ""state"" that block is, and which nodes are sharing that block at that time, which can be used to eliminate the need to broadcast all the signals to all nodes, and only send it to the nodes that are interested in this single block.
Following are a few advantages and disadvantages of the directory based cache coherence protocol:

Scalability: This is one of the strongest motivations for going to directory based designs. Scalability is, in short, how good a specific system is in handling the growing amount of work that it is responsible to do. For this criterion, bus based systems cannot do well due to the limitation caused when having a shared bus that all nodes are using in the same time. For a relatively small number of nodes, bus systems can do well. However, while the number of nodes is growing, some problems may occur in this regard. Especially since only one node is allowed to use the bus at a time, which will significantly harm the performance of the overall system. On the other hand, using directory-based systems, there will be no such bottleneck to constrain the scalability of the system.
Simplicity: This is one of the points where the bus-system is superior. Since the bus structure itself can serve as an organizer for all the traffic that goes through the system, and ensure the atomicity of all the signals passed through, there will be no need to put more effort in ensuring atomicity and ordering between signals as the case in directory based systems, which leads to several overhead faced in the later system design when dealing with issues like consistency.From the above discussion it follows that using bus based systems seems more attractive for relatively small systems. However, directory based systems become crucial when the system scales up and the number of nodes grows. So there is a kind of trade-off between the simplicity and the scalability when comparing between bus-based and directory-based cache coherence designs.","Directory-based coherence is a mechanism to handle cache coherence problem in distributed shared memory (DSM) a.k.a. non-uniform memory access (NUMA). Another popular way is to use a special type of computer bus between all the nodes as a ""shared bus"" (a.k.a. system bus). Directory-based coherence uses a special directory to serve instead of the shared bus in the bus-based coherence protocols. Both of these designs use the corresponding medium (i.e. directory or bus) as a tool to facilitate the communication between different nodes, and to guarantee that the coherence protocol is working properly along all the communicating nodes. In directory based cache coherence, this is done by using this directory to keep track of the status of all cache blocks, the status of each block includes in which cache coherence ""state"" that block is, and which nodes are sharing that block at that time, which can be used to eliminate the need to broadcast all the signals to all nodes, and only send it to the nodes that are interested in this single block.
Following are a few advantages and disadvantages of the directory based cache coherence protocol:

Scalability: This is one of the strongest motivations for going to directory based designs. Scalability is, in short, how good a specific system is in handling the growing amount of work that it is responsible to do. For this criterion, bus based systems cannot do well due to the limitation caused when having a shared bus that all nodes are using in the same time. For a relatively small number of nodes, bus systems can do well. However, while the number of nodes is growing, some problems may occur in this regard. Especially since only one node is allowed to use the bus at a time, which will significantly harm the performance of the overall system. On the other hand, using directory-based systems, there will be no such bottleneck to constrain the scalability of the system.
Simplicity: This is one of the points where the bus-system is superior. Since the bus structure itself can serve as an organizer for all the traffic that goes through the system, and ensure the atomicity of all the signals passed through, there will be no need to put more effort in ensuring atomicity and ordering between signals as the case in directory based systems, which leads to several overhead faced in the later system design when dealing with issues like consistency.From the above discussion it follows that using bus based systems seems more attractive for relatively small systems. However, directory based systems become crucial when the system scales up and the number of nodes grows. So there is a kind of trade-off between the simplicity and the scalability when comparing between bus-based and directory-based cache coherence designs.

History
The idea of directory-based cache coherence systems began long ago. The idea of DASH (Directory Architecture for SHared-memory) was first proposed by C.K. Tang in the mid 1970s. However, applying it to cache coherence was proposed a few years later in 1978, when researchers at Stanford University proposed the first version of this coherence systems called Stanford DASH, in a paper that described the system with the difficulties and improvements associated with such designs. Beside this approach, several attempts were done to provide a scalable systems. For instance, BBN Butterfly which was introduced in 1985, and IBM PR3 which was introduced in 1987, are some examples of scalable multiprocessor systems. However, both of these systems have a drawback; For example, BBN Butterfly does not have caches. Similarly, IBM PR3 does not provide hardware cache coherence, which limits the performance of both of these designs, especially when employing high performance processors.The limitations of other competitors made it easier for DASH based systems to get chosen when designing cache coherence systems and other systems needing scalability in cache-based nodes. In 1985, James Archibald and Jean-Loup Baer from the University of Washington published a paper that proposes a more economical, expandable, and modular variation of the ""global directory"" approach in the term of hardware use in the design.
In 1992, Daniel Lenoski from Stanford university published a paper proposing advances in cache coherence protocols for directory-based systems. In a 1996 paper, he introduced the design of the SGI Origin 2000, a family of server computers employing directory based cache coherence. The subsequent Origin 3000 was introduced in July 2000.

Protocols
Unlike snoopy coherence protocols, in a directory based coherence approach, the information about which caches have a copy of a block is maintained in a structure called directory. In a directory based scheme, participating caches do not broadcast requests to all other sharing caches of the block in order to locate cached copies, instead it queries the directory to retrieve the information about which block have cached copies and sends only to those particular processors and hence traffic saving compared to a snoopy protocol is large. In well optimized applications, most data sharing is only for data that is read only, and there is little sharing for data that is frequently read and written. A directory approach can result in a substantial traffic saving compared to broadcast/snoopy approach in such applications.

As shown in the data flow diagram, the actors involved in a distributed shared memory system implementing directory based coherence protocol are:

Requestor Node: This node is the processor who is requesting for a read/write of a memory block.
Directory Node: This node maintains the information of the state of each cache block in the system and requestor directs its requests to the directory node.
Owner Node: An owner node owns the most recent state of the cache block, note that directory might not be always up to date with latest data.
Sharer Node: One or many node which are sharing a copy of the cache block.Requestor and Owner nodes maintain their state transition similar to a snoopy coherence protocols like MESI protocol. However, unlike a bus based implementation where nodes communicate using a common bus, directory based implementation uses message passing model to exchange information required for maintaining cache coherence.
Directory node acts as a serializing point and all communications are directed through this node to maintain correctness.

Directory node
A directory node keeps track of the overall state of a cache block in the entire cache system for all processors. It can be in three states :

Uncached (U): No processor has data cached, memory up-to-date .
Shared (S): one or more processors have data cached, memory up-to-date. In this state directory and sharers have clean copy of the cached block.
Exclusive/Modified (EM): one processor (owner) has data cached; memory out-of-date. Note that directory cannot distinguish a block cached in an exclusive or modified state at the processor, as processors can transition from an exclusive state to modified state without any bus transaction.Explanation of the directory state transition finite-state machine (refer image 1) is captured below in the table:

In addition to cache state, a directory must track which processors have data when in the shared state. This is required for sending invalidation and intervention requests to the individual processor caches which have the cache block in shared state. Few of the popular implementation approaches are: 

Full bit-vector: A bit field for each processor at the directory node are maintained. The storage overhead scales with the number of processors.
Limited pointer: In this approach directory information of limited number of blocks is kept at the directory to reduce storage overhead.The protocol described above is the basic implementation and race conditions can occur due to the fact that directory can be out of sync with the caches and also messages between processors can be overlapping. More complex implementations are available like Scalable Coherent Interface which have multiple states.
DASH cache coherence protocol is another protocol that uses directory-based coherence scheme. DASH protocol uses a clustered approach, where processors inside a cluster are kept coherent using bus based snooping scheme, while the clusters are connected in a directory approach. Even though various protocols use different implementations for tracking cache blocks, however the concept of directory remains same.

See also
Coherence protocol
MSI protocol
Bit array
Distributed shared memory
Snoopy cache


== References ==",52275869,https://en.wikipedia.org/wiki/Directory-based_coherence
Domain-specific architecture,"A domain-specific architecture (DSA) is a programmable computer architecture specifically tailored to operate very efficiently within the confines of a given application domain. The term is often used in contrast to general-purpose architectures, such as CPUs, that are designed to operate on any computer program.","A domain-specific architecture (DSA) is a programmable computer architecture specifically tailored to operate very efficiently within the confines of a given application domain. The term is often used in contrast to general-purpose architectures, such as CPUs, that are designed to operate on any computer program.

History
In conjunction with the semiconductor boom that started in the 1960s, computer architects were tasked with finding new ways to exploit the increasingly large number of transistors available. Moore's Law and Dennard Scaling enabled architects to focus on improving the performance of general-purpose microprocessors on general-purpose programs.These efforts yielded several technological innovations, such as multi-level caches, out-of-order execution, deep instruction pipelines, multithreading, and multiprocessing. The impact of these innovations was measured on generalist benchmarks such as SPEC, and architects were not concerned with the internal structure or specific characteristics of these programs.The end of Dennard Scaling pushed computer architects to switch from a single, very fast processor to several processor cores. Performance improvement could no longer be achieved by simply increasing the operating frequency of a single core.The end of Moore's Law shifted the focus away from general-purpose architectures towards more specialized hardware. Although general-purpose CPU will likely have a place in any computer system, heterogeneous systems composed of general-purpose and domain-specific components are the most recent trend for achieving high performance.While hardware accelerators and ASIC have been used in very specialized application domains since the inception of the semiconductor industry, they generally implement a specific function with very limited flexibility. In contrast, the shift towards domain-specific architectures wants to achieve a better balance of flexibility and specialization.A notable early example of a domain-specific programmable architecture are GPUs. These specialized hardware were developed specifically to operate within the domain of image processing and computer graphics. These programmable processing units found widespread adoption both in gaming consoles and personal computers. With the improvement of the hardware/software stack for both NVIDIA and AMD GPUs, these architectures are being used more and more for the acceleration of massively and embarrassingly parallel tasks, even outside of the domain of image processing.Since the renaissance of machine-learning-based artificial intelligence in the 2010s, several  domain-specific architectures have been developed to accelerate inference for different forms of artificial neural networks. Some examples are Google's TPU, NVIDIA's NVDLA and ARM's MLP.

Guidelines for DSA design
John Hennessy and David Patterson outlined five principles for DSA design that lead to better area efficiency and energy savings. The objective in these types of architecture is often also to reduce the Non-Recurring Engineering (NRE) costs so that the investment in a specialized solution can be more easily amortized.
Minimize the distance over which data is moved: moving data in general-purpose memory hierarchies requires a remarkable amount of energy in order to attempt to minimize the latency to access data. In the case of Domain-Specific Architectures, it is expected that understanding the application domains by hardware and compiler designers allows for simpler and specialized memory hierarchies, where the data movement is largely handled in software, with tailor-made memories for specific functions within the domain.
Invest saved resources into arithmetic units or bigger memories: since a remarkable amount of hardware resources can be saved by dropping general-purpose architectural optimizations such as out-of-order execution, prefetching, address coalescing, and hardware speculation, the resources saved should be re-invested to maximally exploit the available parallelism, for example, by adding more arithmetic units or solve any memory bandwidth issues by adding bigger memories.
Use the easiest form of parallelism that matches the domain: since the target application domains almost always present an inherent form of parallelism, it is important to decide how to take advantage of this parallelism and expose it to the software. If, for example, a SIMD architecture can work in the domain, it would be easier for the programmer to use than a MIMD architecture.
Reduce data size and type to the simplest needed for the domain: whenever possible, using narrower and simpler data types yields several advantages. For example, it reduces the cost of moving data for memory-bound applications, and it can also reduce the amount of resources required to implement the respective arithmetic units.
Use a domain-specific programming language to port code to the DSA: one of the challenges for DSAs is ease of use, and more specifically, being able to effectively program the architecture and run applications on it. Whenever possible, it is advised to use existing Domain-Specific Languages (DSL) such as Halide and TensorFlow to more easily program a DSA. Re-use of existing compiler toolchains and software frameworks makes using a new DSA significantly more accessible.

DSA for deep neural networks
One of the application domains where DSA have found the most amount of success is that of artificial intelligence. In particular, several architectures have been developed for the acceleration of Deep Neural Networks (DNN). In the following sections, we report some examples.

TPU
Google's TPU was developed in 2015 to accelerate DNN inference since the company projected that the use of voice search would require to double the computational resources allocated at the time for neural network inference.The TPU was designed to be a co-processor communicating via a PCIe bus, to be easily incorporated in existing servers. It is primarily a matrix-multiplication engine following a CISC (Complex Instruction Set Computer) ISA. The multiplication engine uses systolic execution to save energy, reducing the number of writes to SRAM.The TPU was fabricated with a 28-nm process and clocked at 700MHz. The portion of the application that runs on the TPU is implemented in TensorFlow.The TPU computes primarily reduced precision integers, which further contributes to energy savings and increased performance.

Microsoft Catapult
Microsoft's Project Catapult put an FPGA connected through a PCIe bus into data center servers, with the idea of using the FPGA to accelerate various applications running on the server, leveraging the reconfiguration capabilities of FPGA to accelerate many different applications.
Differently from Google's TPU, the Catapult FPGA needed to be programmed via hardware-description languages such as Verilog and VHDL. For this reason, a major concern for the authors of the framework was the limited programmability.Microsoft designed a CNN accelerator for the Catapult framework that was primarily designed to accelerate the ranking function in the Bing search engine. The proposed architecture provided a runtime reconfigurable design based on a two-dimensional systolic array.

NVDLA
NVDLA is NVIDIA's deep-learning inference accelerator. It is an open-source hardware design available in a number of highly parametrizable configurations. The small-NVDLA model is designed to be deployed in resource-constrained scenarios such as IoT where cost, area and power are the main concerns. Conversely. the large-NVDLA model is more suitable for HPC scenarios. NVDLA provides its own dedicated training infrastructure, compilation tools and runtime software stack.

DSA for other domains
Aside from an application in artificial intelligence, DSAs are being adopted in many domains within scientific computing, image processing, and networking.

Pixel Visual Core
The Pixel Visual Core (PVC) is an of ARM-based image processors designed by Google. The PVC is a fully programmable image, vision and AI multi-core domain-specific architecture (DSA) for mobile devices and in future for IoT. It first appeared in the Google Pixel 2 and 2 XL which were introduced on October 19, 2017. It has also appeared in the Google Pixel 3 and 3 XL. Starting with the Pixel 4, this chip was replaced with the Pixel Neural Core.

Anton3
Anton3 is a DSA designed to efficiently compute molecular-dynamics simulations. It uses a specialized 3D torus topology interconnection network to connect several computing nodes. Each computing node contains a set of 64 cores interconnected through a mesh. The cores implement a specialized deep pipeline to efficiently compute the force-field between molecules. This heterogeneous system combines general-purpose hardware and domain-specific components to achieve record-breaking simulation speed.

References
Further reading
Computer Architecture. A Quantitative Approach. Sixth Edition. John L. Hennessy. Stanford University. David A. Patterson. University of California, Berkeley.

See also
Hardware Accelerator
AI Accelerator
ASIC
FPGA",74209694,https://en.wikipedia.org/wiki/Domain-specific_architecture
DOPIPE,"DOPIPE parallelism is a method to perform loop-level parallelism by pipelining the statements in a loop. Pipelined parallelism may exist at different levels of abstraction like loops, functions and algorithmic stages. The extent of parallelism depends upon the programmers' ability to make best use of this concept. It also depends upon factors like identifying and separating the independent tasks and executing them parallelly.","DOPIPE parallelism is a method to perform loop-level parallelism by pipelining the statements in a loop. Pipelined parallelism may exist at different levels of abstraction like loops, functions and algorithmic stages. The extent of parallelism depends upon the programmers' ability to make best use of this concept. It also depends upon factors like identifying and separating the independent tasks and executing them parallelly.

Background
The main purpose of employing loop-level parallelism is to search and split sequential tasks of a program and convert them into parallel tasks without any prior information about the algorithm. Parts of data that are recurring and consume significant amount of execution time are good candidates for loop-level parallelism. Some common applications of loop-level parallelism are found in mathematical analysis that uses multiple-dimension matrices which are iterated in nested loops.There are different kind of parallelization techniques which are used on the basis of data storage overhead, degree of parallelization and data dependencies. Some of the known techniques are: DOALL, DOACROSS and DOPIPE.
DOALL: This technique is used where we can parallelize each iteration of the loop without any interaction between the iterations. Hence, the overall run-time gets reduced from N * T (for a serial processor, where T is the execution time for each iteration) to only T (since all the N iterations are executed in parallel).
DOACROSS: This technique is used wherever there is a possibility for data dependencies. Hence, we parallelize tasks in such a manner that all the data independent tasks are executed in parallel, but the dependent ones are executed sequentially. There is a degree of synchronization used to sync the dependent tasks across parallel processors.

Description
DOPIPE is a pipelined parallelization technique that is used in programs where each element produced during each iteration is consumed in the later iteration. The following example shows how to implement the DOPIPE technique to reduce the total execution time by breaking the tasks inside the loop and executing them in a pipelined manner. The breaking into tasks takes place in such a way that all the dependencies within the loop are unidirectional, i.e. the following iteration does not depend on the previous iteration.

Example
The program below shows a pseudocode for DOPIPE parallelization.
In this code, we see that there are three tasks (F0, F1 and F2) inside a loop iterating over j for 1 to N. Following is a list of dependencies in the code:
F1[j] → T F1[j+1], implies that statement F1 in iteration j+1 must be executed after statement F1 in iteration j. This is also known as true dependency.

F1[j] → T F2[j], implies that statement F2 in iteration j must be executed after statement F1 in iteration j.for (j=1; j<=N; j++) {
    F0: o[j] = x[j] - a[j];
    F1: z[j] = z[j-1] * 5;
    F2: y[j] = z[j] * w[j];
}
If this code would have been executed sequentially, then the total time consumed would be equal to N * (TF0 + TF1 + TF2), where TF0, TF1 and TF2 denote execution time for functions F0, F1 and F2 respectively per iteration.
Now, if we parallelize the loop by pipelining the statements inside the loop in the following manner:for (j=1; j<=N; j++) {
    F0: o[j] = x[j] - a[j];             // DOALL parallelism
}

for (j=1; j<=N; j++) {
    F1: z[j] = z[j-1] * 5;              // DOPIPE parallelism
    post(j);                            // The result of F1 is posted and available for use
}

for (j=1; j<=N; j++) {
    wait(j);                            // It waits till the F1 completes and produces the value z[j] to be used by F2
    F2: y[j] = z[j] * w[j];
}
Since, F0 is an independent function, i.e. it does not have any loop-carried dependency (no dependence on j+1 or j-1 iterations). Neither it has any dependency across other statements in the loop. Hence, we can completely separate out this function and run it parallelly using DOALL parallelism. On the other hand, Statements F1 and F2 are dependent (explained above), therefore we split them into two different loops and execute them in a pipelined fashion. We use post(j) and wait(j) to synchronize between F1 and F2 loops.
Starting from the first iteration of j, statement F1 gets executed in TF1 time. Meanwhile, F2 is not getting executed since it is waiting for the value z[j] to be produced by F1. When F1 completes its execution for iteration j, it posts the value using post(j). After waiting for F1's execution, using wait(j), F2 starts its execution since it has the value z[j] available for use. Also, since F1's execution is not restricted by F2, hence F1 executes j+1 simultaneously. The figure below shows the execution timeline of all the statements.

From the figure, we see that the total time to execute F0 is TF0, since all the iterations of F0 are executed in parallel. While for F1 and F2, the total execution time is equal to N * TF1 + TF2 (considering negligible synchronization time).
This is considerably less than the time obtained during sequential execution.

Comparison with other models
DOALL parallelism mainly works on principle of divide and conquer. Here all the tasks run in different iterations that use unique set of data. So the problem with this implementation is that when large amount of data works is computed together, a large cache space is needed to work for different threads. Since there is no dependencies in the threads, there is no overhead for the inter - thread communication.
While in DOPIPE, there is a synchronization overhead between the threads. But, due to its pipelined structure, it requires less cache space because the data produced is immediately consumed by the consumer.

See also
Parallel computing
Loop level parallelism
Task parallelism
Data dependency
OpenMP
Automatic parallelization
Thread (computing)
Cache (computing)


== References ==",51521334,https://en.wikipedia.org/wiki/DOPIPE
Duncan's taxonomy,"Duncan's taxonomy is a classification of computer architectures, proposed by Ralph Duncan in 1990. Duncan suggested modifications to Flynn's taxonomy to include pipelined vector processes.","Duncan's taxonomy is a classification of computer architectures, proposed by Ralph Duncan in 1990. Duncan suggested modifications to Flynn's taxonomy to include pipelined vector processes.

Taxonomy
The taxonomy was developed during 1988-1990 and was first published in 1990. Its original categories are indicated below.

Synchronous architectures
This category includes all the parallel architectures that coordinate concurrent execution in lockstep fashion and do so via mechanisms such as global clocks, central control units or vector unit controllers. Further subdivision of this category is made primarily on the basis of the synchronization mechanism.

Pipelined vector processors
Pipelined vector processors are characterized by pipelined functional units that accept a sequential stream of array or vector elements, such that different stages in a filled pipeline are processing different elements of the vector at a given time. Parallelism is provided both by the pipelining in individual functional units described above, as well as by operating multiple units of this kind in parallel and by chaining the output of one unit into another unit as input.Vector architectures that stream vector elements into functional units from special vector registers are termed register-to-register architectures, while those that feed functional units from special memory buffers are designated as  memory-to-memory architectures. Early examples of register-to-register architectures from the 1960s and early 1970s include the Cray-1 and Fujitsu VP-200, while the Control Data Corporation STAR-100, CDC 205 and the Texas Instruments Advanced Scientific Computer are early examples of memory-to-memory vector architectures.The late 1980s and early 1990s saw the introduction of vector architectures, such as the Cray Y-MP/4 and Nippon Electric Corporation SX-3 that supported 4-10 vector processors with a shared memory (see NEC SX architecture). RISC-V RVV may mark the beginning of the modern revival of Vector processing.

SIMD
This scheme uses the SIMD (single instruction stream, multiple data stream) category from Flynn's taxonomy as a root class for processor array and associative memory subclasses. SIMD architectures are characterized by having a control unit broadcast a common instruction to all processing elements, which execute that instruction in lockstep on diverse operands from local data. Common features include the ability for individual processors to disable an instruction and the ability to propagate instruction results to immediate neighbors over an interconnection network.

Processor array
Associative memory
Systolic array
Systolic arrays, proposed during the 1980s, are multiprocessors in which data and partial results are rhythmically pumped from processor to processor through a regular, local interconnection network. Systolic architectures use a global clock and explicit timing delays to synchronize data flow from processor to processor. Each processor in a systolic system executes an invariant sequence of instructions before data and results are pulsed to neighboring processors.

MIMD architectures
Based on Flynn's multiple-instruction-multiple-data streams terminology, this category spans a wide spectrum of architectures in which processors execute multiple instruction sequences on (potentially) dissimilar data streams without strict synchronization. Although both instruction and data streams can be different for each processor, they need not be. Thus, MIMD architectures can run identical programs that are in various stages at any given time, run unique instruction and data streams on each processor or execute a combination of each these scenarios. This category is subdivided further primarily on the basis of memory organization.

Distributed memory
Shared memory
MIMD-paradigm architectures
The MIMD-based paradigms category subsumes systems in which a specific programming or execution paradigm is at least as fundamental 
to the architectural design as structural considerations are. Thus, the design of dataflow architectures and reduction machines is as much the product of supporting their distinctive execution paradigm as it is a product of connecting processors and memories in MIMD fashion. The category's subdivisions are defined by these paradigms.

MIMD/SIMD hybrid
Dataflow machine
Reduction machine
Wavefront array


== References ==",27902531,https://en.wikipedia.org/wiki/Duncan%27s_taxonomy
Empathy map,"An empathy map is a widely-used visualization tool within the field of user experience design and human–computer interaction practice. In relation to empathetic design, the primary purpose of an empathy map is to bridge the understanding of the end user. Within context of its application, this tool is used to build a shared understanding of the user's needs and provide context to a user-centered solution.","An empathy map is a widely-used visualization tool within the field of user experience design and human–computer interaction practice. In relation to empathetic design, the primary purpose of an empathy map is to bridge the understanding of the end user. Within context of its application, this tool is used to build a shared understanding of the user's needs and provide context to a user-centered solution.

Structure
The traditional empathy map begins with four categories: says, thinks, does, and feels. At the center of the map, a user or persona is displayed to remind practitioners and stakeholders what type of individual this research is centered around. Each category of the empathy map represents a snapshot of the user's thoughts and feelings without any chronological order.

Says category contains what the user says out loud during research or testing. Ideally, each point is written down as close to the user's original words as possible.
Thinks category contains what the user is thinking. While content may overlap with the Says category, Thinks category exists to capture thoughts users may not want to share willing due to social factors, such as self-consciousness or politeness.
Does category contains the user's action and behaviors. This contains what the user is physically doing and captures what actions users are taking.
Feels category contains the user's emotional state in context with their experience. This typically contains information or phrases as to how they feel about the experience.However, as time evolved, the empathy map has been updated to provide more context and information architecture within the industry.Empathy maps could vary in forms, but they have common core elements. Other than the four traditional categories mentioned above, empathy map could also include other categories. Here are two other categories commonly used:

See category contains information users observed through eyes. It could be what users see in the marketplace or in the immediate environment, other people's saying and doing, or the content they watch or read.
Hear category is what user hears and how that impacts the user. It could be personal connections as well as other recourses such as media. Instead of documenting superficial information streams, team should focus on details that influence the user.

Empathy map vs. persona
It is easy to confuse the use of empathy map and persona. They are both important and common tools used in the research process. Here's the main difference:

Empathy map occurs in the early research process. It is used to get into user's head and heart. Empathy map helps to picture user's situation as well as to consider what future researches might be needed.
Persona is more definite and formal. In order to generate a well-build persona for addressing needs and problems, the team needs to conduct in-depth research. Personas are better leveraged later on in the process.


== References ==",52338266,https://en.wikipedia.org/wiki/Empathy_map
Feng's classification,Tse-yun Feng suggested the use of degree of parallelism to classify various computer architecture. It is based on sequential and parallel operations at a bit and word level.,"Tse-yun Feng suggested the use of degree of parallelism to classify various computer architecture. It is based on sequential and parallel operations at a bit and word level.

About degree of parallelism
Maximum degree of parallelism
The maximum number of binary digits that can be processed within a unit time by a computer system is called the maximum parallelism degree P. If a processor is processing P bits in unit time, then P is called the maximum
degree of parallelism.

Average degree of parallelism
Let i = 1, 2, 3, ..., T be the different timing instants and P1, P2, ..., PT be the corresponding bits processed.
Then,

Processor utilization
Processor utilization μ{\displaystyle \mu } is defined as

The maximum degree of parallelism depends on the structure of the arithmetic and logic unit. Higher degree of parallelism indicates a highly parallel ALU or processing element. Average parallelism depends on both the hardware and the software. Higher average parallelism can be achieved through concurrent programs.

Types of classification
According to Feng's classification, computer architecture can be classified into four. The classification is based on the way contents stored in memory are processed. The contents can be either data or instructions.
Word serial bit serial (WSBS)
Word serial bit parallel (WSBP)
Word parallel bit serial (WPBS)
Word parallel bit parallel (WPBP)

Word serial bit serial (WSBS)
One bit of one selected word is processed at a time. This represents serial processing and needs maximum processing time.

Word serial bit parallel (WSBP)
It is found in most existing computers and has been called ""word slice"" processing because one word of one bit is processed at a time. All bits of a selected word are processed at a time. Bit parallel means all bits of a word.

Word parallel bit serial (WPBS)
It has been called bit slice processing because m-bit slice is processed at a time. Word parallel signifies selection of all words. It can be considered as one bit from all words are processed at a time.

Word parallel bit parallel
Limitations of Feng's classification
It fails to project the concurrency in pipeline processors, as degree of parallelism doesn't account for concurrency handle by pipe-lined design.

See also
Händler's Erlangen Classification System (ECS)
Flynn's taxonomy


== References ==",51875565,https://en.wikipedia.org/wiki/Feng%27s_classification
Frequency scaling,"In computer architecture, frequency scaling (also known as frequency ramping) is the technique of increasing a processor's frequency so as to enhance the performance of the system containing the processor in question. Frequency ramping was the dominant force in commodity processor performance increases from the mid-1980s until roughly the end of 2004. 
The effect of processor frequency on computer speed can be seen by looking at the equation for computer program runtime: 

Runtime=InstructionsProgram×CyclesInstruction×TimeCycle,{\displaystyle \mathrm {Runtime} ={\frac {\mathrm {Instructions} }{\mathrm {Program} }}\times {\frac {\mathrm {Cycles} }{\mathrm {Instruction} }}\times {\frac {\mathrm {Time} }{\mathrm {Cycle} }},}where instructions per program is the total instructions being executed in a given program, cycles per instruction is a program-dependent, architecture-dependent average value, and time per cycle is by definition the inverse of processor frequency. An increase in frequency thus decreases runtime. 
However, power consumption in a chip is given by the equation 

P=C×V2×F,{\displaystyle P=C\times V^{2}\times F,}where P is power consumption, C is the capacitance being switched per clock cycle, V is voltage, and F is the processor frequency (cycles per second). Increases in frequency thus increase the amount of power used in a processor. Increasing processor power consumption led ultimately to Intel's May 2004 cancellation of its Tejas and Jayhawk processors, which is generally cited as the end of frequency scaling as the dominant computer architecture paradigm.Moore's Law was still in effect when frequency scaling ended. Despite power issues, transistor densities were still doubling every 18 to 24 months. With the end of frequency scaling, new transistors (which are no longer needed to facilitate frequency scaling) are used to add extra hardware, such as additional cores, to facilitate parallel computing - a technique that is being referred to as parallel scaling.
The end of frequency scaling as the dominant cause of processor performance gains has caused an industry-wide shift to parallel computing in the form of multicore processors.","In computer architecture, frequency scaling (also known as frequency ramping) is the technique of increasing a processor's frequency so as to enhance the performance of the system containing the processor in question. Frequency ramping was the dominant force in commodity processor performance increases from the mid-1980s until roughly the end of 2004. 
The effect of processor frequency on computer speed can be seen by looking at the equation for computer program runtime: 

Runtime=InstructionsProgram×CyclesInstruction×TimeCycle,{\displaystyle \mathrm {Runtime} ={\frac {\mathrm {Instructions} }{\mathrm {Program} }}\times {\frac {\mathrm {Cycles} }{\mathrm {Instruction} }}\times {\frac {\mathrm {Time} }{\mathrm {Cycle} }},}where instructions per program is the total instructions being executed in a given program, cycles per instruction is a program-dependent, architecture-dependent average value, and time per cycle is by definition the inverse of processor frequency. An increase in frequency thus decreases runtime. 
However, power consumption in a chip is given by the equation 

P=C×V2×F,{\displaystyle P=C\times V^{2}\times F,}where P is power consumption, C is the capacitance being switched per clock cycle, V is voltage, and F is the processor frequency (cycles per second). Increases in frequency thus increase the amount of power used in a processor. Increasing processor power consumption led ultimately to Intel's May 2004 cancellation of its Tejas and Jayhawk processors, which is generally cited as the end of frequency scaling as the dominant computer architecture paradigm.Moore's Law was still in effect when frequency scaling ended. Despite power issues, transistor densities were still doubling every 18 to 24 months. With the end of frequency scaling, new transistors (which are no longer needed to facilitate frequency scaling) are used to add extra hardware, such as additional cores, to facilitate parallel computing - a technique that is being referred to as parallel scaling.
The end of frequency scaling as the dominant cause of processor performance gains has caused an industry-wide shift to parallel computing in the form of multicore processors.

See also
Dynamic frequency scaling
Overclocking
Underclocking
Voltage scaling


== References ==",8898329,https://en.wikipedia.org/wiki/Frequency_scaling
Hardware architect,"(In the automation and engineering environments, the hardware engineer or architect encompasses the electronics engineering and electrical engineering fields, with subspecialities in analog, digital, or electromechanical systems.)
The hardware systems architect or hardware architect is responsible for:

Interfacing with a systems architect or client stakeholders.  It is extraordinarily rare nowadays for sufficiently large and/or complex hardware systems that require a hardware architect not to require substantial software and a systems architect. The hardware architect will therefore normally interface with a systems architect, rather than directly with user(s), sponsor(s), or other client stakeholders. However, in the absence of a systems architect, the hardware systems architect must be prepared to interface directly with the client stakeholders in order to determine their (evolving) needs to be realized in hardware.  The hardware architect may also need to interface directly with a software architect or engineer(s), or with other mechanical or electrical engineers.
Generating the highest level of hardware requirements, based on the user's needs and other constraints such as cost and schedule.
Ensuring that this set of high level requirements is consistent, complete, correct, and operationally defined.
Performing cost–benefit analyses to determine the best methods or approaches for meeting the hardware requirements; making maximum use of commercial off-the-shelf or already developed components.
Developing partitioning algorithms (and other processes) to allocate all present and foreseeable (hardware) requirements into discrete hardware partitions such that a minimum of communications is needed among partitions, and between the user and the system.
Partitioning large hardware systems into (successive layers of) subsystems and components each of which can be handled by a single hardware engineer or team of engineers.
Ensuring that maximally robust hardware architecture is developed.
Generating a set of acceptance test requirements, together with the designers, test engineers, and the user, which determine that all of the high level hardware requirements have been met, especially for the computer-human-interface.
Generating products such as sketches, models, an early user's manual, and prototypes to keep the user and the engineers constantly up to date and in agreement on the system to be provided as it is evolving.","(In the automation and engineering environments, the hardware engineer or architect encompasses the electronics engineering and electrical engineering fields, with subspecialities in analog, digital, or electromechanical systems.)
The hardware systems architect or hardware architect is responsible for:

Interfacing with a systems architect or client stakeholders.  It is extraordinarily rare nowadays for sufficiently large and/or complex hardware systems that require a hardware architect not to require substantial software and a systems architect. The hardware architect will therefore normally interface with a systems architect, rather than directly with user(s), sponsor(s), or other client stakeholders. However, in the absence of a systems architect, the hardware systems architect must be prepared to interface directly with the client stakeholders in order to determine their (evolving) needs to be realized in hardware.  The hardware architect may also need to interface directly with a software architect or engineer(s), or with other mechanical or electrical engineers.
Generating the highest level of hardware requirements, based on the user's needs and other constraints such as cost and schedule.
Ensuring that this set of high level requirements is consistent, complete, correct, and operationally defined.
Performing cost–benefit analyses to determine the best methods or approaches for meeting the hardware requirements; making maximum use of commercial off-the-shelf or already developed components.
Developing partitioning algorithms (and other processes) to allocate all present and foreseeable (hardware) requirements into discrete hardware partitions such that a minimum of communications is needed among partitions, and between the user and the system.
Partitioning large hardware systems into (successive layers of) subsystems and components each of which can be handled by a single hardware engineer or team of engineers.
Ensuring that maximally robust hardware architecture is developed.
Generating a set of acceptance test requirements, together with the designers, test engineers, and the user, which determine that all of the high level hardware requirements have been met, especially for the computer-human-interface.
Generating products such as sketches, models, an early user's manual, and prototypes to keep the user and the engineers constantly up to date and in agreement on the system to be provided as it is evolving.

Background
Large systems architecture was developed as a way to handle systems too large for one person to conceive of, let alone design.  Systems of this size are rapidly becoming the norm, so architectural approaches and architects are increasingly needed to solve the problems of large systems.

Users and sponsors
Engineers as a group do not have a reputation for understanding and responding to human needs comfortably or for developing humanly functional and aesthetically pleasing products.  Architects are expected to understand human needs and develop humanly functional and aesthetically pleasing products. A good architect is a translator between the user/sponsor and the engineers—and even among just engineers of different specialties.  A good architect is also the principal keeper of the user's vision of the end product—and of the process of deriving requirements from and implementing that vision.
Determining what the users/sponsors actually want, rather than what they say they want, is not engineering—it is an art.  An architect does not follow an exact procedure.  S/he communicates with users/sponsors in a highly interactive way—together they extract the true requirements necessary for the engineered system.  The hardware architect must remain constantly in communication with the end users (or a systems architect).  Therefore, the architect must be familiar with the user's environment and problem.  The engineer need only be very knowledgeable of the potential engineering solution space.

High-level requirements
The user/sponsor should view the architect as the user's representative and provide all input through the architect.  Direct interaction with project engineers is generally discouraged as the chance of mutual misunderstanding is very high.  The user requirements' specification should be a joint product of the user and hardware architect (or, the systems and hardware architects): the user brings his  needs and wish list, the architect brings knowledge of what is likely to prove doable within cost and time constraints.  When the user needs are translated into a set of high level requirements is also the best time to write the first version of the acceptance test, which should, thereafter, be religiously kept up to date with the requirements.  That way, the user will be absolutely clear about what s/he is getting.  It is also a safeguard against untestable requirements, misunderstandings, and requirements creep.
The development of the first level of hardware engineering requirements is not a purely analytical exercise and should also involve both the hardware architect and engineer.  If any compromises are to be made—to meet constraints like cost, schedule, power, or space, the architect must ensure that the final product and overall look and feel do not stray very far from the user's intent.  The engineer should focus on developing a design that optimizes the constraints but ensures a workable and reliable product.  The architect is primarily concerned with the comfort and usability of the product; the engineer is primarily concerned with the producibility and utility of the product. 
The provision of needed services to the user is the true function of an engineered system.  However, as systems become ever larger and more complex, and as their  emphases move away from simple hardware components, the narrow application of traditional hardware development principles is found to be insufficient—the application of the more general principles of hardware architecture to the design of (sub) systems is seen to be needed.  A Hardware architecture is also a simplified model of the finished end product—its primary function is to define the hardware components and their relationships to each other so that the whole can be seen to be a consistent, complete, and correct representation of what the user had in mind—especially for the computer–human interface.  It is also used to ensure that the components fit together and relate in the desired way.
It is necessary to distinguish between the architecture of the user's world and the engineered hardware architecture.  The former represents and addresses problems and solutions in the user's world.  It is principally captured in the computer–human interfaces (CHI) of the engineered system.  The engineered system represents the engineering solutions—how the engineer proposes to develop and/or select and combine the components of the technical infrastructure to support the CHI.  In the absence of an architect, there is an unfortunate tendency to confuse the two architectures, since the engineer thinks in terms of hardware, but the user may be thinking in terms of solving a problem of getting people from point A to point B in a reasonable amount of time and with a reasonable expenditure of energy, or of getting needed information to customers and staff. A hardware architect is expected to combine knowledge of both the architecture of the user's world and of (all potentially useful) hardware engineering architectures.  The former is a joint activity with the user; the latter is a joint activity with the engineers.  The product is a set of high level requirements reflecting the user's requirements which can be used by the engineers to develop hardware systems design requirements.
Because requirements evolve over the course of a project, especially a long one, an architect is needed until the hardware system is accepted by the user: the architect is the best insurance that no changes and interpretations made during the course of development compromise the user's viewpoint.

Cost–benefit analyses
Most hardware engineers are specialists.  They know the applications of hardware design and development intimately, apply their knowledge to practical situations—that is, solve real world problems, evaluate the cost–benefits of various solutions within their hardware specialty, and ensure the correct operation of whatever they design.  Hardware architects are generalists.  They are not expected to be experts in any one hardware technology or approach, but are expected to be knowledgeable of many, and able to judge their applicability to specific situations.  They also apply their knowledge to practical situations, but evaluate the cost/benefits of various solutions using different hardware technologies, for example, specially developed versus commercially available hardware components, and assure that the system as a whole performs according to the user's expectations.
Many commercial-off-the-shelf or already developed hardware components may be selected independently according to constraints such as cost, response, throughput, etc.  In some cases, the architect can already assemble the end system unaided.  Or, s/he may still need the help of a hardware engineer to select components and to design and build any special purpose function.  The architects (or engineers) may also enlist the aid of specialists—in safety, security, communications, special purpose hardware, graphics, human factors, test and evaluation, quality control, RMA, interface management, etc.  An effective hardware architectural team must have immediate access to specialists in critical specialties.

Partitioning and layering
An architect planning a building works on the overall design, making sure it will be pleasing and useful to its inhabitants. While a  single architect by himself may be enough to build a single-family house,  many engineers may be needed, in addition, to solve the detailed problems that arise when a novel high-rise building is designed.  If the job is large and complex enough, parts of the architecture may be designed as components.  That is, if we are building a housing complex, we may have one architect for the complex, and one for each type of building, as part of an architectural team. 
Large hardware systems also require an architect and much engineering talent.  If the engineered system is large and complex enough, the chief hardware systems architect may defer to subordinate architects for parts of the job, although they all may be members of a joint architectural team.  But the architect must never be viewed as an engineering supervisor.
The architect should sub-allocate the hardware requirements to major components or subsystems that are within the scope of a single hardware engineer, or engineering manager or subordinate architect.  Ideally, each such hardware component/subsystem is a sufficiently stand-alone object that it can be tested as a complete component, separate from the whole, using only a simple testbed to supply simulated inputs and record outputs.  That is, it is not necessary to know how an air traffic control system works in order to design and build a data management subsystem for it.  It is only necessary to know the constraints under which the subsystem will be expected to operate.
A good architect ensures that the system, however complex, is built upon relatively simple and ""clean"" concepts for each (sub) system or layer—easily understandable by everyone, especially the user, without special training. The architect will use a minimum of rules to ensure that each partition is well-defined and clean of kludges, work-arounds, short-cuts, or confusing detail and exceptions. As user needs evolve, (once the system is fielded and in use), it is a lot easier subsequently to evolve a simple concept than one laden with exceptions, special cases, and much ""fine print.""
Layering the hardware architecture is important for keeping it sufficiently simple at each layer so that it remains comprehensible to a single mind. As layers are ascended, whole systems at lower layers become simple components at the higher layers, and may disappear altogether at the highest layers.

Acceptance test
The acceptance test always remains the principal responsibility of the architect(s).  It is the chief means by which the architect will prove to the user that the hardware is as originally planned and that all subordinate architects and engineers have met their objectives.  Large projects tend to be dynamic, with changes along the way needed by the user (e.g., as his problems change), or expected of the user (e.g., for cost or schedule reasons). But acceptance tests must be kept current at all times. They are the principal means by which the user is kept informed as to how the final product will perform.  And they act as the principal goal towards which all subordinate personnel must design, build and test for.

Good communications with users and engineers
A building architect uses sketches, models, drawings.  A hardware systems architect should use sketches, models, and prototypes to discuss different solutions and results with the user or system architect, engineers, and subordinate architects.  An early, draft version of the user's manual is invaluable, especially in conjunction with a prototype.  A set of (engineering) requirements as a means of communicating with the users is explicitly to be avoided.  A well written set of requirements, or specification, is intelligible only to the engineering fraternity, much as a legal contract is for lawyers.

People
Herb Sutter

See also
Systems architecture / Systems architect
Software architecture / Software architect
Hardware architecture
Systems engineering / Systems engineer
Software engineering / Software engineer
Requirements analysis
Systems design
Electrical engineering
Electronics engineering


== References ==",3561465,https://en.wikipedia.org/wiki/Hardware_architect
Harvard architecture,"The Harvard architecture is a computer architecture with separate storage and signal pathways for instructions and data. It is often contrasted with the von Neumann architecture, where program instructions and data share the same memory and pathways.
The term is often stated as having originated from the Harvard Mark I relay-based computer, which stored instructions on punched tape (24 bits wide) and data in electro-mechanical counters. These early machines had data storage entirely contained within the central processing unit, and provided no access to the instruction storage as data. Programs needed to be loaded by an operator; the processor could not initialize itself. However, in the only peer-reviewed published paper on the topic – The Myth of the Harvard Architecture published in the IEEE Annals of the History of Computing – the author demonstrates that: 

'The term ""Harvard architecture"" was coined decades later, in the context of microcontroller design' and only 'retrospectively applied to the Harvard machines and subsequently applied to RISC microprocessors with separated caches';'The so-called ""Harvard"" and ""von Neumann"" architectures are often portrayed as a dichotomy, but the various devices labeled as the former have far more in common with the latter than they do with each other';'In short [the Harvard architecture] isn't an architecture and didn't derive from work at Harvard'.Modern processors appear to the user to be systems with von Neumann architectures, with the program code stored in the same main memory as the data. For performance reasons, internally and largely invisible to the user, most designs have separate processor caches for the instructions and data, with separate pathways into the processor for each. This is one form of what is known as the modified Harvard architecture.
Harvard architecture is historically, and traditionally, split into two address spaces, but having three, i.e. two extra (and all accessed in each cycle) is also done, while rare.","The Harvard architecture is a computer architecture with separate storage and signal pathways for instructions and data. It is often contrasted with the von Neumann architecture, where program instructions and data share the same memory and pathways.
The term is often stated as having originated from the Harvard Mark I relay-based computer, which stored instructions on punched tape (24 bits wide) and data in electro-mechanical counters. These early machines had data storage entirely contained within the central processing unit, and provided no access to the instruction storage as data. Programs needed to be loaded by an operator; the processor could not initialize itself. However, in the only peer-reviewed published paper on the topic – The Myth of the Harvard Architecture published in the IEEE Annals of the History of Computing – the author demonstrates that: 

'The term ""Harvard architecture"" was coined decades later, in the context of microcontroller design' and only 'retrospectively applied to the Harvard machines and subsequently applied to RISC microprocessors with separated caches';'The so-called ""Harvard"" and ""von Neumann"" architectures are often portrayed as a dichotomy, but the various devices labeled as the former have far more in common with the latter than they do with each other';'In short [the Harvard architecture] isn't an architecture and didn't derive from work at Harvard'.Modern processors appear to the user to be systems with von Neumann architectures, with the program code stored in the same main memory as the data. For performance reasons, internally and largely invisible to the user, most designs have separate processor caches for the instructions and data, with separate pathways into the processor for each. This is one form of what is known as the modified Harvard architecture.
Harvard architecture is historically, and traditionally, split into two address spaces, but having three, i.e. two extra (and all accessed in each cycle) is also done, while rare.

Memory details
In a Harvard architecture, there is no need to make the two memories share characteristics. In particular, the word width, timing, implementation technology, and memory address structure can differ. In some systems, instructions for pre-programmed tasks can be stored in read-only memory while data memory generally requires read-write memory. In some systems, there is much more instruction memory than data memory so instruction addresses are wider than data addresses.

Contrast with von Neumann architectures
In a system with a pure von Neumann architecture, instructions and data are stored in the same memory, so instructions are fetched over the same data path used to fetch data. This means that a CPU cannot simultaneously read an instruction and read or write data from or to the memory. In a computer using the Harvard architecture, the CPU can both read an instruction and perform a data memory access at the same time, even without a cache. A Harvard architecture computer can thus be faster for a given circuit complexity because instruction fetches and data access do not contend for a single memory pathway.
Also, a Harvard architecture machine has distinct code and data address spaces: instruction address zero is not the same as data address zero. Instruction address zero might identify a twenty-four-bit value, while data address zero might indicate an eight-bit byte that is not part of that twenty-four-bit value.

Contrast with modified Harvard architecture
A modified Harvard architecture machine is very much like a Harvard architecture machine, but it relaxes the strict separation between instruction and data while still letting the CPU concurrently access two (or more) memory buses. The most common modification includes separate instruction and data caches backed by a common address space.  While the CPU executes from cache, it acts as a pure Harvard machine.  When accessing backing memory, it acts like a von Neumann machine (where code can be moved around like data, which is a powerful technique). This modification is widespread in modern processors, such as the ARM architecture, Power ISA and x86 processors.  It is sometimes loosely called a Harvard architecture, overlooking the  fact that it is actually ""modified"".
Another modification provides a pathway between the instruction memory (such as ROM or flash memory) and the CPU to allow words from the instruction memory to be treated as read-only data. This technique is used in some microcontrollers, including the Atmel AVR. This allows constant data, such as text strings or function tables, to be accessed without first having to be copied into data memory, preserving scarce (and power-hungry) data memory for read/write variables. Special machine language instructions are provided to read data from the instruction memory, or the instruction memory can be accessed using a peripheral interface. (This is distinct from instructions which themselves embed constant data, although for individual constants the two mechanisms can substitute for each other.)

Speed
In recent years, the speed of the CPU has grown many times in comparison to the access speed of the main memory. Care needs to be taken to reduce the number of times main memory is accessed in order to maintain performance. If, for instance, every instruction run in the CPU requires an access to memory, the computer gains nothing for increased CPU speed—a problem referred to as being memory bound.
It is possible to make extremely fast memory, but this is only practical for small amounts of memory for cost, power and signal routing reasons. The solution is to provide a small amount of very fast memory known as a CPU cache which holds recently accessed data. As long as the data that the CPU needs is in the cache, the performance is much higher than it is when the CPU has to get the data from the main memory. On the other side, however, it may still be limited to storing repetitive programs or data and still has a storage size limitation, and other potential problems associated with it.

Internal vs. external design
Modern high performance CPU chip designs incorporate aspects of both Harvard and von Neumann architecture. In particular, the ""split cache"" version of the modified Harvard architecture is very common. CPU cache memory is divided into an instruction cache and a data cache. Harvard architecture is used as the CPU accesses the cache. In the case of a cache miss, however, the data is retrieved from the main memory, which is not formally divided into separate instruction and data sections, although it may well have separate memory controllers used for concurrent access to RAM, ROM and (NOR) flash memory.
Thus, while a von Neumann architecture is visible in some contexts, such as when data and code come through the same memory controller, the hardware implementation gains the efficiencies of the Harvard architecture for cache accesses and at least some main memory accesses.
In addition, CPUs often have write buffers which let CPUs proceed after writes to non-cached regions. The von Neumann nature of memory is then visible when instructions are written as data by the CPU and software must ensure that the caches (data and instruction) and write buffer are synchronized before trying to execute those just-written instructions.

Modern uses of the Harvard architecture
The principal advantage of the pure Harvard architecture—simultaneous access to more than one memory system—has been reduced by modified Harvard processors using modern CPU cache systems. Relatively pure Harvard architecture machines are used mostly in applications where trade-offs, like the cost and power savings from omitting caches, outweigh the programming penalties from featuring distinct code and data address spaces.

Digital signal processors (DSPs) generally execute small, highly optimized audio or video processing algorithms. They avoid caches because their behavior must be extremely reproducible. The difficulties of coping with multiple address spaces are of secondary concern to speed of execution. Consequently, some DSPs feature multiple data memories in distinct address spaces to facilitate SIMD and VLIW processing. Texas Instruments TMS320 C55x processors, for one example, feature multiple parallel data buses (two write, three read) and one instruction bus.
Microcontrollers are characterized by having small amounts of program (flash memory) and data (SRAM) memory, and take advantage of the Harvard architecture to speed processing by concurrent instruction and data access. The separate storage means the program and data memories may feature different bit widths, for example using 16-bit-wide instructions and 8-bit-wide data. They also mean that instruction prefetch can be performed in parallel with other activities. Examples include the PIC by Microchip Technology, Inc. and the AVR by Atmel Corp (now part of Microchip Technology).Even in these cases, it is common to employ special instructions in order to access program memory as though it were data for read-only tables, or for reprogramming; those processors are modified Harvard architecture processors.

Notes
References
External links
Harvard Architecture
Harvard vs von Neumann Architectures
Difference Between Harvard Architecture And Von Neumann Architecture",58019,https://en.wikipedia.org/wiki/Harvard_architecture
Hybrid-core computing,"Hybrid-core computing is the technique of extending a commodity instruction set architecture (e.g. x86) with application-specific instructions to accelerate application performance. It is a form of heterogeneous computing wherein asymmetric computational units coexist with a ""commodity"" processor.
Hybrid-core processing differs from general heterogeneous computing in that the computational units share a common logical address space, and an executable is composed of a single instruction stream—in essence a contemporary coprocessor. The instruction set of a hybrid-core computing system contains instructions that can be dispatched either to the host instruction set or to the application-specific hardware.
Typically, hybrid-core computing is best deployed where the predominance of computational cycles are spent in a few identifiable kernels, as is often seen in high-performance computing applications. Acceleration is especially pronounced when the kernel's logic maps poorly to a sequence of commodity processor instructions, and/or maps well to the application-specific hardware.
Hybrid-core computing is used to accelerate applications beyond what is currently physically possible with off-the-shelf processors, or to lower power & cooling costs in a data center by reducing computational footprint. (i.e., to circumvent obstacles such as the power/density challenges faced with today's commodity processors).


== References ==","Hybrid-core computing is the technique of extending a commodity instruction set architecture (e.g. x86) with application-specific instructions to accelerate application performance. It is a form of heterogeneous computing wherein asymmetric computational units coexist with a ""commodity"" processor.
Hybrid-core processing differs from general heterogeneous computing in that the computational units share a common logical address space, and an executable is composed of a single instruction stream—in essence a contemporary coprocessor. The instruction set of a hybrid-core computing system contains instructions that can be dispatched either to the host instruction set or to the application-specific hardware.
Typically, hybrid-core computing is best deployed where the predominance of computational cycles are spent in a few identifiable kernels, as is often seen in high-performance computing applications. Acceleration is especially pronounced when the kernel's logic maps poorly to a sequence of commodity processor instructions, and/or maps well to the application-specific hardware.
Hybrid-core computing is used to accelerate applications beyond what is currently physically possible with off-the-shelf processors, or to lower power & cooling costs in a data center by reducing computational footprint. (i.e., to circumvent obstacles such as the power/density challenges faced with today's commodity processors).


== References ==",50015640,https://en.wikipedia.org/wiki/Hybrid-core_computing
IBM System/360 architecture,"The IBM System/360 architecture is the model independent architecture for the entire S/360 line of mainframe computers, including but not limited to the instruction set architecture. The elements of the architecture are documented in the IBM System/360 Principles of Operation and the IBM System/360 I/O Interface Channel to Control Unit Original Equipment Manufacturers' Information manuals.","The IBM System/360 architecture is the model independent architecture for the entire S/360 line of mainframe computers, including but not limited to the instruction set architecture. The elements of the architecture are documented in the IBM System/360 Principles of Operation and the IBM System/360 I/O Interface Channel to Control Unit Original Equipment Manufacturers' Information manuals.

Features
The System/360 architecture provides the following features:

16 32-bit general-purpose registers
4 64-bit floating-point registers
64-bit processor status register (PSW), which includes a 24-bit instruction address
24-bit (16 MB) byte-addressable memory space
Big-endian byte/word order
A standard instruction set, including fixed-point binary arithmetic and logical instructions, present on all System/360 models (except the Model 20, see below).
A commercial instruction set, adding decimal arithmetic instructions, is optional on some models, as is a scientific instruction set, which adds floating-point instructions. The universal instruction set includes all of the above plus the storage protection instructions and is standard for some models.
The Model 44 provides a few unique instructions for data acquisition and real-time processing and is missing the storage-to-storage instructions. However, IBM offered a 'Commercial Instruction Set"" feature that ran in bump storage and simulated the missing instructions.
The Model 20 offers a stripped-down version of the standard instruction set, limited to eight general registers with halfword (16-bit) instructions only, plus the commercial instruction set, and unique instructions for input/output.
The Model 67 includes some instructions to handle 32-bit addresses and ""dynamic address translation"", with additional privileged instructions to provide virtual memory.

Memory
Memory (storage) in System/360 is addressed in terms of 8-bit bytes. Various instructions operate on larger units called halfword (2 bytes), fullword (4 bytes), doubleword (8 bytes), quad word (16 bytes) and 2048 byte storage block, specifying the leftmost (lowest address) of the unit. Within a halfword, fullword, doubleword or quadword, low numbered bytes are more significant than high numbered bytes; this is sometimes referred to as big-endian. Many uses for these units require aligning them on the corresponding boundaries. Within this article the unqualified term word refers to a fullword.
The original architecture of System/360 provided for up to 224 = 16,777,216 bytes of memory. The later Model 67 extended the architecture to allow up to 232 = 4,294,967,296 bytes of virtual memory.

Addressing
System/360 uses truncated addressing similar to that of the UNIVAC III. That means that instructions do not contain complete addresses, but rather specify a base register and a positive offset from the addresses in the base registers. In the case of System/360 the base address is contained in one of 15 general registers. In some instructions, for example shifts, the same computations are performed for 32-bit quantities that are not addresses.

Data formats
The S/360 architecture defines formats for characters, integers, decimal integers and hexadecimal floating point numbers. Character and integer instructions are mandatory, but decimal and floating point instructions are part of the Decimal arithmetic and Floating-point arithmetic features.

Characters are stored as 8-bit bytes.
Integers are stored as two's complement binary halfword or fullword values.
Packed decimal numbers are stored as 1 to 16 8-bit bytes containing an odd number of decimal digits followed by a 4-bit sign. Sign values of hexadecimal A, C, E, and F are positive and sign values of hexadecimal B and D are negative. Digit values of hexadecimal A-F and sign values of 0-9 are invalid, but the PACK and UNPK instructions do not test for validity.
Zoned decimal numbers are stored as 1 to 16 8-bit bytes, each containing a zone in bits 0-3 and a digit in bits 4-7. The zone of the rightmost byte is interpreted as a sign.
Floating point numbers are only stored as fullword or doubleword values on older models. On the 360/85 and 360/195 there are also extended precision floating point numbers stored as quadwords. For all three formats, bit 0 is a sign and bits 0-7 are a characteristic (exponent, biased by 64). Bits 8-31 (8-63) are a hexadecimal fraction. For extended precision, the low order doubleword has its own sign and characteristic, which are ignored on input and generated on output.

Instruction formats
Instructions in the S/360 are two, four or six bytes in length, with the opcode in byte 0. Instructions have one of the following formats:

RR (two bytes). Generally byte 1 specifies two 4-bit register numbers, but in some cases, e.g., SVC, byte 1 is a single 8-bit immediate field.
RS (four bytes). Byte 1 specifies two register numbers; bytes 2-3 specify a base and displacement.
RX (four bytes). Bits 0-3 of byte 1 specify either a register number or a modifier; bits 4-7 of byte 1 specify the number of the general register to be used as an index; bytes 2-3 specify a base and displacement.
SI (four bytes). Byte 1 specifies an immediate field; bytes 2-3 specify a base and displacement.
SS (six bytes). Byte 1 specifies two 4-bit length fields or one 8-bit length field; bytes 2-3 and 4-5 each specify a base and displacement. The encoding of the length fields is length-1.Instructions must be on a two-byte boundary in memory; hence the low-order bit of the instruction address is always 0.

Program Status Word (PSW)
The Program Status Word (PSW): 71–72  contains a variety of controls for the currently operating program. The 64-bit PSW describes (among other things) the address of the current instruction being executed, condition code and interrupt masks.

Load Program Status Word (LPSW) is a privileged instruction that loads the Program Status Word (PSW), including the program mode, protection key, and the address of the next instruction to be executed. LPSW is most often used to ""return"" from an interruption by loading the ""old"" PSW which is associated with the interruption class. Other privileged instructions (e.g., SSM, STNSM, STOSM, SPKA, etcetera) are available for manipulating subsets of the PSW without causing an interruption or loading a PSW; and one non-privileged instruction (SPM) is available for manipulating the program mask.

Interruption system
The architecture: 77–83  defines 5 classes of interruption. An interruption is a mechanism for automatically changing the program state; it is used for both synchronous and asynchronous events.

There are two storage fields assigned to each class of interruption on the S/360; an old PSW double-word and a new PSW double-word. The processor stores the PSW, with an interruption code inserted, into the old PSW location and then loads the PSW from the new PSW location. This generally replaces the instruction address, thereby effecting a branch, and (optionally) sets and/or resets other fields within the PSW, thereby effecting a mode change.
The S/360 architecture defines a priority to each interruption class, but it is only relevant when two interruptions occur simultaneously; an interruption routine can be interrupted by any other enabled interruption, including another occurrence of the initial interruption. For this reason, it is normal practice to specify all of the mask bits, with the exception of machine-check mask bit, as 0 for the ""first-level"" interruption handlers. ""Second-level"" interruption handlers are generally designed for stacked interruptions (multiple occurrences of interruptions of the same interruption class).

Input/Output interruption
An I/O interruption: 78–79  occurs at the completion of a channel program, after fetching a CCW with the PCI bit set and also for asynchronous events detected by the device, control unit or channel, e.g., completion of a mechanical movement. The system stores the device address into the interruption code and stores channel status into the CSW at location 64 ('40'X).

Program interruption
A Program interruption: 16, 79–80.1  occurs when an instruction encounters one of 15 exceptions; however, if the Program Mask bit corresponding to an exception is 0 then there is no interruption for that exception. 
On 360/65,: 12  360/67: 46  and 360/85: 12  the Protection Exception and Addressing Exception interruptions can be imprecise, in which case they store an Instruction Length Code of 0.
The Interruption code may be any of

An operation exception: 79  is recognized when a program attempts to execute an instruction with an opcode that the computer does not implement. In particular, an operation exception is recognized when a program is written for an optional feature, e.g., floating point, that is not installed.
A privileged operation exception: 79  is recognized when a program attempts to execute a privileged instruction when the problem state bit in the PSW is 1.
An execute exception: 79  is recognized when the operand of an EXECUTE instruction (EX) is another EXECUTE instruction.
A protection exception: 79  is recognized when a program attempts to store into a location whose storage protect key does not match the PSW key, or to fetch from a fetch protected location whose storage protect key does not match the PSW key.
An addressing exception: 79–80  is recognized when a program attempts to access a storage location that is not currently available. This normally occurs with an address beyond the capacity of the machine, but it may also occur on machines that allow blocks of storage to be taken offline.
A specification exception: 80  is recognized when an instruction has a length or register field with values not permitted by the operation, or when it has an operand address that does not satisfy the alignment requirements of the opcode, e.g., a LH instruction with an odd operand address on a machine without the byte alignment feature.
A data exception: 80  is recognized when a decimal instruction specifies invalid operands, e.g., invalid data, invalid overlap.
A fixed-point overflow exception: 80  is recognized when significant bits are lost in a fixed point arithmetic or shift instruction, other than divide.
A fixed-point divide exception: 80  is recognized when significant bits are lost in a fixed point divide or Convert to Binary instruction.
A decimal overflow  exception: 80  is recognized when significant digits are lost in a decimal arithmetic instruction, other than divide.
A decimal divide exception: 80  is recognized when significant bits are lost in a decimal divide instruction. The destination is not altered.
An exponent overflow exception: 80  is recognized when the characteristic in a floating-point arithmetic operation exceeds 127 and the fraction is not zero.
An exponent underflow exception: 80  is recognized when the characteristic in a floating-point arithmetic operation is negative and the fraction is not zero.
A significance exception: 80  is recognized when the fraction in a floating-point add or subtract operation is zero.
A floating-point divide exception: 80.1  is recognized when the fraction in the divisor of a floating-point divide operation is zero.

Supervisor Call interruption
A Supervisor Call interruption: 80.1–81  occurs as the result of a Supervisor Call instruction; the system stores bits 8-15 of the SVC instruction as the Interruption Code.

External interruption
An External: 81  interruption occurs as the result of certain asynchronous events. Bits 16-24 of the External Old PSW are set to 0 and one or more of bits 24-31 is set to 1

Machine Check interruption
A Machine Check interruption: 82–83  occurs to report unusual conditions associated with the channel or CPU that cannot be reported by another class of interruption. The most important class of conditions causing a Machine Check is a hardware error such as a parity error found in registers or storage, but some models may use it to report less serious conditions. Both the interruption code and the data stored in the scanout area at '80'x (128 decimal) are model dependent.

Input/Output
This article describes I/O from the CPU perspective. It does not discuss the channel cable or connectors, which have a  separate article; there is a summary elsewhere and details can be found in the IBM literature and in FIPS PUB 60-2.I/O is carried out by a conceptually separate processor called a channel. Channels have their own instruction set, and access memory independently of the program running on the CPU. On the smaller models (through 360/50) a single microcode engine runs both the CPU program and the channel program. On the larger models the channels are in separate cabinets and have their own interfaces to memory. A channel may contain multiple subchannels, each containing the status of an individual channel program. A subchannel associated with multiple devices that cannot concurrently have channel programs is referred to as shared; a subchannel representing a single device is referred to as unshared.
There are three types of channels on the S/360:

A byte multiplexer channel is capable of executing multiple CCWs concurrently; it is normally used to attach slow devices such as card readers and telecommunications lines. A byte multiplexer channel could have a number of selector subchannels, each with only a single subchannel, which behave like low-speed selector channels.
A selector channel has only a single subchannel, and hence is only capable of executing one channel command at a time. It is normally used to attach fast devices that are not capable of exploiting a block multiplexer channel to suspend the connection, such as magnetic tape drives.
A block multiplexer channel is capable of concurrently running multiple channel programs, but only one at a time can be active. The control unit can request suspension at the end of a channel command and can later request resumption. This is intended for devices in which there is a mechanical delay after completion of data transfer, e.g., for seeks on moving-head DASD. The block multiplexer channel was a late addition to the System/360 architecture; early machines had only byte multiplexer channels and selector channels. The block multiplexer channel was an optional feature only on the models 85 and 195. The block multiplexor channel was also available on the later System/370 computers.Conceptually peripheral equipment is attached to a S/360 through control units, which in turn are attached through channels. However, the architecture does not require that control units be physically distinct, and in practice they are sometimes integrated with the devices that they control. Similarly, the architecture does not require the channels to be physically distinct from the processor, and the smaller S/360 models (through 360/50) have integrated channels that steal cycles from the processor.
Peripheral devices are addressed with 16-bit addresses.,: 89  referred to as cua or cuu; this article will use the term cuu. The high 8 bits identify a channel, numbered from 0 to 6, while the low 8 bits identify a device on that channel. A device may have multiple cuu addresses.
Control units are assigned an address ""capture"" range. For example, a CU might be assigned range 20-2F or 40-7F. The purpose of this is to assist with the connection and prioritization of multiple control units to a channel. For example, a channel might have three disk control units at 20-2F, 50-5F, and 80-8F. Not all of the captured addresses need to have an assigned physical device. Each control unit is also marked as High or Low priority on the channel.
Device selection progresses from the channel to each control unit in the order they are physically attached to their channel. At the end of the chain the selection process continues in reverse back towards the channel. If the selection returns to the channel then no control unit accepted the command and SIO returns Condition Code 3. Control units marked as High Priority check the outbound CUU to be within their range. If so, then the I/O was processed. If not, then the selection was passed to the next outbound CU. Control units marked as Low Priority check for inbound (returning) CUU to be within their range. If so, then the I/O is processed. If not, then the selection is passed to the next inbound CU (or the channel). The connection of three controls unit to a channel might be physically -A-B-C and, if all are marked as High then the priority would be ABC. If all are marked low then the priority would be CBA. If B was marked High and AC low then the order would be BCA. Extending this line of reasoning then the first of N controllers would be priority 1 (High) or 2N-1 (Low), the second priority 2 or 2N-2, the third priority 3 or 2N-3, etc. The last physically attached would always be priority N.
There are three storage fields reserved for I/O; a double word I/O old PSW, a doubleword I/O new PSW and a fullword Channel Address Word (CAW). Performing an I/O normally requires the following:

initializing the CAW with the storage key and the address of the first CCW
issuing a Start I/O (SIO) instruction that specifies the cuu for the operation
waiting for an I/O interruption
handling any unusual conditions indicated in the Channel Status Word (CSW)A channel program consists of a sequence of Channel Control Words (CCWs) chained together (see below.) Normally the channel fetches CCWs from consecutive doublewords, but a control unit can direct the channel to skip a CCW and a Transfer In Channel (TIC) CCW can direct the channel to start fetching CCWs from a new location.
There are several defined ways for a channel command to complete. Some of these allow the channel to continue fetching CCWs, while others terminate the channel program. In general, if the CCW does not have the chain-command bit set and is not a TIC, then the channel will terminate the I/O operation and cause an I/O interruption when the command completes. Certain status bits from the control unit suppress chaining.
The most common ways for a command to complete are for the count to be exhausted when chain-data is not set and for the control unit to signal that no more data transfers should be made. If Suppress-Length-Indication (SLI) is not set and one of those occurs without the other, chaining is not allowed. The most common situations that suppress chaining are unit-exception and unit-check. However, the combination of unit-check and status-modifier does not suppress chaining; rather, it causes the channel to do a command retry, reprocessing the same CCW.
In addition to the interruption signal sent to the CPU when an I/O operation is complete, a channel can also send a Program-Controlled interruption (PCI) to the CPU while the channel program is running, without terminating the operation, and a delayed device-end interruption after the I/O completion interruption.

Channel status
These conditions are detected by the channel and indicated in the CSW.: 116–118 
Program-controlled interruption: 116–117  indicates that the channel has fetched a CCW with the PCI bit set. The channel continues processing; this interruption simply informs the CPU of the channel's progress. An example of the use of Program-controlled interruption is in the ""Program Fetch"" function of Contents Supervision, whereby the control program is notified that a Control/Relocation Record has been read. To ensure that this record has been completely read into main storage, a ""disabled bit spin"", one of the few which remains in the control program, is initiated. Satisfaction of the spin indicates that the Control/Relocation Record is completely in main storage and the immediately preceding Text Record may be relocated. After relocation, a NOP CCW is changed to a TIC and the channel program continues. In this way, an entire load module may be read and relocated while utilizing only one EXCP, and possibly only one revolution of the disk drive. PCI also has applications in teleprocessing access method buffer management.
Incorrect length: 117  indicates that the data transfer for a command completed before the Count was exhausted. This indication is suppressed if the Suppress-Length-Indication bit in the CCW is set.
Program check: 117  indicates one of the following errors
Nonzero bits where zeros are required
An invalid data or CCW address
The CAW or a TIC refers to a TIC
Protection check: 117–118  indicates that the protection key in the CAW is non-zero and does not match the storage protection key.
Channel data check: 118  indicates a parity error during a data transfer.
Channel control check: 118  indicates a channel malfunction other than Channel data check or Interface control check.
Interface control check: 118  indicates an invalid signal in the channel to control unit interface.
Chaining check: 118  indicates lost data during data chaining.

Unit status
These conditions are presented to the channel by the control unit or device.: 113–116  In some cases they are handled by the channel and in other cases they are indicated in the CSW. There is no distinction between conditions detected by the control unit and conditions detected by the device.

Attention: 113  indicates an unusual condition not associated with an ongoing channel program.  It often indicates some sort of operator action like requesting input, in which case the CPU would respond by issuing a read-type command, most often a sense command (04h) from which additional information could be deduced. Attention is a special condition, and requires specific operating system support, and for which the operating system has a special attention table with a necessarily limited number of entries.
Status modifier: 113–114  (SM) indicates one of three unusual conditions
A Test I/O instruction was issued to a device that does not support it.
A Busy status refers to the control unit rather than to the device.
A device has detected a condition that requires skipping a CCW. A CCW with a command for which Status Modifier is possible will normally specify command chaining, in which case the SM is processed by the channel and does not cause an interruption.A typical channel program where SM occurs is    ...
    Search Id Equal
    TIC           *-8
    Read Data

where the TIC causes the channel to refetch the search until the device indicates a successful search by raising SM.Control unit end: 114  indicates that a previous control unit busy status has been cleared.
Busy: 114–115  indicates that a device (SM=0) or a control unit (SM=1) is busy.
Channel end: 115  indicates that the device has completed the data transfer for a channel command. There may also be an Incorrect length indication if the Count field of the CCW is exhausted, depending on the value of the Suppress-Length-Indication bit.
Device end: 115  indicates that the device has completed an operation and is ready to accept another. DE may be signalled concurrently with CE or may be delayed.
Unit check: 115–116  indicates that the device or control unit has detected an unusual conditions and that details may be obtained by issuing a Sense command.
Unit exception: 116  indicates that the device has detected an unusual condition, e.g., end of file.

Channel Address Word
The fullword Channel Address Word: 99  (CAW) contains a 4-bit storage protection key and a 24-bit address of the channel program to be started.

Channel Command Word
A Channel Command Word is a doubleword containing the following:

an 8-bit channel Command Code: 100 
a 24-bit address: 100–101 
a 5-bit flag field: 99–100, 101–105 
an unsigned halfword Count field: 100–101

CCW Command codes
The low order 2 or 4 bits determine the six types of operations that the channel performs;.: 100, 105  The encoding is

The meaning of the high order six or four bits, the modifier bits, M in the table above, depends upon the type of I/O device attached, see e.g., DASD CKD CCWs. All eight bits are sent to and interpreted in the associated control unit (or its functional equivalent).
Control is used to cause a state change in a device or control unit, often associated with mechanical motion, e.g., rewind, seek.
Sense is used to read data describing the status of the device. The most important case is that when a command terminates with unit check, the specific cause can only be determined by doing a Sense and examining the data returned. A Sense command with the modifier bits all zero is always valid.
A noteworthy deviation from the architecture is that DASD use Sense command codes for Reserve and Release, instead of using Control.

CCW flags
The flags in a CCW affect how it executes and terminates.

Channel Status Word
The Channel Status Word (CSW): 113–121  provides data associated with an I/O interruption.

The Protection Key field contains the protect key from the CAW at the time that the I/O operation was initiated for I/O complete or PCI interruptions.: 119 
The Command Address field contains the address+8 of the last CCW fetched for an I/O complete or PCI interruption. However, there are 9 exceptions.: 119 
The Status field contains one byte of Channel status bits, indicating conditions detected by the channel,: 116–118  and one byte of Unit status bits, indicating conditions detected by the I/O unit.: 113–116  There is no distinction between conditions detected by the control unit and conditions detected by the device.
The Residual Count is a half word that gives the number of bytes in the area described by the CCW that have not been transferred to or from the channel.: 120  The difference between the count in the CCW and the residual count gives the number of bytes transferred.

I/O instructions
The S/360 has four I/O instructions: Start I/O (SIO), Test I/O (TIO), Halt I/O (HIO) and Test Channel (TCH). All four are privileged and thus will cause a privileged operation program interruption if used in problem state. The B1 (base) and D1 (displacement) fields are used to calculate the cuu (channel and device number); bits 8-15 of the instructions are unused and should be zero for compatibility with the S/370.

Start I/O (SIO)
SIO attempts to start the channel program pointed to by the CAW, using the storage protection key in the CAW.

Test I/O (TIO)
TIO  tests the status of a channel and device. It may also store a CSW, in which case it completes with condition code 1.

Halt I/O (HIO)
HIO attempt to terminate an active channel program. It may also store a CSW, in which case it completes with condition code 1.

Test Channel (TCH)
TCH tests the status of a channel. It does not affect the status of an active channel program and does not store a CSW,

Operator controls
The architecture of System/360 specified the existence of several common functions, but did not specify their means of implementation. This allowed IBM to use different physical means, e.g., dial, keyboard, pushbutton, roller, image or text on a CRT, for selecting the functions and values on different processors. Any reference to key or switch should be read as applying to, e.g., a light-pen selection, an equivalent keyboard sequence.

System Reset sends a reset signal on every I/O channel and clears the processor state; all pending interruptions are cancelled. System Reset is not guaranteed to correct parity errors in general registers, floating point registers or storage. System Reset does not reset the state of shared I/O devices.
Initial Program Load (IPL): 123  is a process for loading a program when there isn't a loader available in storage, usually because the machine was just powered on or to load an alternative operating system.: 123  This process is sometimes known as Booting.As part of the IPL facility the operator has a means of specifying a 12-bit device address, typically with three dials as shown in the operator controls drawing. When the operator selects the Load function, the system performs a System Reset, sends a Read IPL channel command to the selected device in order to read 24 bytes into locations 0-23 and causes the channel to begin fetching CCWs at location 8; the effect is as if the channel had fetched a CCW with a length of 24, and address of 0 and the flags containing Command Chaining + Suppress Length Indication. At the completion of the operation, the system stores the I/O address in the halfword at location 2 and loads the PSW from location 0.Initial program loading is typically done from a tape, a card reader, or a disk drive. Generally, the operating system was loaded from a disk drive; IPL from tape or cards was used only for diagnostics or for installing an operating system on a new computer.Emergency pull switch: 124  (Emergency power off, EPO) sends an EPO signal to every I/O channel, then turns off power to the processor complex. Because EPO bypasses the normal sequencing of power down, damage can result, and the EPO control has a mechanical latch to ensure that a customer engineer inspects the equipment before attempting to power it back on.
Power on: 124  powers up all components of the processor complex and performs a system reset.
Power off: 124  initiates an orderly power-off sequence. Although the contents of storage are preserved, the associated storage keys may be lost.
The Interrupt key: 124  causes an external interruption with bit 25 set in the External Old PSW.
The Wait light: 124  indicates that the PSW has bit 14 (wait) set; the processor is temporarily halted but resumes operation when an interruption condition occurs.
The Manual light: 124  indicates that the CPU is in a stopped state.
The System light: 124  indicates that a meter is running, either due to CPU activity or due to I/O channel activity.
The Test light: 124  indicates that certain operator controls are active, when certain facilities, e.g., INSTRUCTION STEP, have been used by a Diagnose instruction or when abnormal thermal conditions exist. The details are model dependent.
The Load light: 124  is turned on by IPL and external start. It is turned off by loading the PSW from location 0 at the completion of the load process.
The Load unit: 124–125  controls provide the rightmost 11 bits of the device from which to perform an IPL.
The Load Key: 125  starts the IPL sequence.
The Prefix Select Key Switch: 125  selects whether IPL will use the primary prefix or the alternative prefix.
The System-Reset Key: 125  initiates a System Reset.
The Stop Key: 125  puts the CPU in a stopped state; channel programs continue running and interruption conditions remain pending.
The Rate Switch: 125  determines the mode in which the processor fetches instructions. Two modes are defined by the architecture:
PROCESS
INSTRUCTION STEP
The Start Key: 125  initiates instruction fetching in accordance with the setting of the Rate Switch.
The Storage-Select Switch: 126  determines the type of resource accessed by the Store Key and Display Key. Three selections are defined by the architecture:
Main storage
General registers
Floating-point registers
The Address Switches: 126  specify the address or register number for the Store Key, Display Key and, on some models, the Set IC Key..
The Data Switches: 126  specify the data for the Store Key and, on some models, the Set IC Key.
The Store Key: 126  stores the value in the Data Switches as specified by the Storage-Select Switch and the Address Switches.
The Display Key: 126  displays the value specified by the Storage-Select Switch and the Address Switches.
The Set IC=: 126  sets the instruction address portion of the PSW from the Data Switches or the Address Switches, depending on the model.
The Address-Compare Switches: 126  select the mode of comparison and what is compared. Stop on instruction address compare is present on all models, but stop on data address compare is only present on some models.
The Alternate-Prefix Light: 126  is on when the prefix trigger is in the alternate state.

Optional features
Byte-aligned operands
On some models, e.g., the S/360-85, the alignment requirements for some problem-state instructions were relaxed. There is no mechanism to turn off this feature, and programs depending on receiving a program check type 6 (alignment) on those instructions must be modified.

Decimal arithmetic
The decimal arithmetic feature provides instructions that operate on packed decimal data. A packed decimal number has 1-31 decimal digits followed by a 4-bit sign. All of the decimal arithmetic instructions except PACK and UNPACK generate a Data exception if a digit is not in the range 0-9 or a sign is not in the range A-F.

Direct Control
The Direct Control: 17.1  feature provides six external signal lines and an 8-bit data path to/from storage.

Floating-point arithmetic
The floating-point arithmetic feature provides 4 64-bit floating point registers and instructions to operate on 32 and 64 bit hexadecimal floating point numbers. The 360/85 and 360/195 also support 128 bit extended precision floating point numbers.

Interval timer
If the interval timer feature: 17.1  is installed, the processor decrements the word at location 80 ('50'X) at regular intervals; the architecture does not specify the interval but does require that value subtracted make it appear as though 1 were subtracted from bit 23 300 times per second. The smaller models decremented at the same frequency (50 Hz or 60 Hz) as the AC power supply, but larger models had a high resolution timer feature. The processor causes an External interruption when the timer goes to zero.

Multi-system operation
Multi-system operation: 17.1–18  is a set of features to support multi-processor systems, e.g., Direct Control, direct address relocation (prefixing).

Storage protection
If the storage protection feature: 17-17.1  is installed, then there is a 4-bit storage key associated with every 2,048-byte block of storage and that key is checked when storing into any address in that block by either a CPU or an I/O channel. A CPU or channel key of 0 disables the check; a nonzero CPU or channel key allows data to be stored only in a block with the matching key.
Storage Protection was used to prevent a defective application from writing over storage belonging to the operating system or another application. This permitted testing to be performed along with production. Because the key was only four bits in length, the maximum number of different applications that could be run simultaneously was 15.
An additional option available on some models was fetch protection. It allowed the operating system to specify that blocks were protected from fetching as well as from storing.

Deviations and extensions
The System/360 Model 20 is radically different and should not be considered to be a S/360.
The System/360 Model 44 is missing certain instructions, but a feature allowed the missing instructions to be simulated in hidden memory thus allowing the use of standard S/360 operating systems and applications.
Some models have features that extended the architecture, e.g., emulation instructions, paging, and some models make minor deviations from the architecture. Examples include:

The multisystem feature on the S/360-65 which modifies the behavior of the direct control feature and of the Set System Mask (SSM) instruction.
The System/360 Model 67-2 had similar, but incompatible, changes.Some deviations served as prototypes for features of the S/370 architecture.

See also
Memory protection key

Notes
References
S360
IBM System/360 Principles of Operation (Eighth ed.). IBM. September 1968. A22-6821-7. {{cite book}}: |work= ignored (help)

Further reading
Prasad, N.S. (1989). IBM Mainframes. McGraw-Hill. ISBN 0070506868. — Chapter 3 (pp. 41–110) describes the System/360 architecture.
Greiner, Dan (August 10, 2011). ""IBM z/Architecture CPU Features - A Historical Perspective"" (PDF). Evolution of The IBM Mainframe Architecture. SHARE 117 in Orlando. SHARE. Session 9220. Retrieved February 7, 2023.

External links
Introduction to IBM System/360 Architecture (Student Text)",28739443,https://en.wikipedia.org/wiki/IBM_System/360_architecture
Instruction prefetch,"Cache prefetching is a technique used by computer processors to boost execution performance by fetching instructions or data from their original storage in slower memory to a faster local memory before it is actually needed (hence the term 'prefetch'). Most modern computer processors have fast and local cache memory in which prefetched data is held until it is required. The source for the prefetch operation is usually main memory. Because of their design, accessing cache memories is typically much faster than accessing main memory, so prefetching data and then accessing it from caches is usually many orders of magnitude faster than accessing it directly from main memory. Prefetching can be done with non-blocking cache control instructions.","Cache prefetching is a technique used by computer processors to boost execution performance by fetching instructions or data from their original storage in slower memory to a faster local memory before it is actually needed (hence the term 'prefetch'). Most modern computer processors have fast and local cache memory in which prefetched data is held until it is required. The source for the prefetch operation is usually main memory. Because of their design, accessing cache memories is typically much faster than accessing main memory, so prefetching data and then accessing it from caches is usually many orders of magnitude faster than accessing it directly from main memory. Prefetching can be done with non-blocking cache control instructions.

Data vs. instruction cache prefetching
Cache prefetching can either fetch data or instructions into cache.

Data prefetching fetches data before it is needed. Because data access patterns show less regularity than instruction patterns, accurate data prefetching is generally more challenging than instruction prefetching.
Instruction prefetching fetches instructions before they need to be executed. The first mainstream microprocessors to use some form of instruction prefetch were the Intel 8086 (six bytes) and the Motorola 68000 (four bytes). In recent years, all high-performance processors use prefetching techniques.

Hardware vs. software cache prefetching
Cache prefetching can be accomplished either by hardware or by software.
Hardware based prefetching is typically accomplished by having a dedicated hardware mechanism in the processor that watches the stream of instructions or data being requested by the executing program, recognizes the next few elements that the program might need based on this stream and prefetches into the processor's cache.
Software based prefetching is typically accomplished by having the compiler analyze the code and insert additional ""prefetch"" instructions in the program during compilation itself.

Methods of hardware prefetching
Stream buffers
Stream buffers were developed based on the concept of ""one block lookahead (OBL) scheme"" proposed by Alan Jay Smith.
Stream buffers are one of the most common hardware based prefetching techniques in use. This technique was originally proposed by Norman Jouppi in 1990 and many variations of this method have been developed since. The basic idea is that the cache miss address (and k{\displaystyle k} subsequent addresses) are fetched into a separate buffer of depth k{\displaystyle k}. This buffer is called a stream buffer and is separate from the cache. The processor then consumes data/instructions from the stream buffer if the address associated with the prefetched blocks match the requested address generated by the program executing on the processor. The figure below illustrates this setup:Whenever the prefetch mechanism detects a miss on a memory block, say A, it allocates a stream to begin prefetching successive blocks from the missed block onward. If the stream buffer can hold 4 blocks, then the processor would prefetch A+1, A+2, A+3, A+4 and hold those in the allocated stream buffer. If the processor consumes A+1 next, then it shall be moved ""up"" from the stream buffer to the processor's cache. The first entry of the stream buffer would now be A+2 and so on. This pattern of prefetching successive blocks is called Sequential Prefetching. It is mainly used when contiguous locations are to be prefetched. For example, it is used when prefetching instructions.
This mechanism can be scaled up by adding multiple such 'stream buffers' - each of which would maintain a separate prefetch stream. For each new miss, there would be a new stream buffer allocated and it would operate in a similar way as described above.
The ideal depth of the stream buffer is something that is subject to experimentation against various benchmarks and depends on the rest of the microarchitecture involved.

Strided prefetching
This type of prefetching monitors the delta between the addresses of the memory accesses and looks for patterns within it.

Regular strides
In this pattern, consecutive memory accesses are made to blocks that are s{\displaystyle s} addresses apart. In this case, the prefetcher calculates the s{\displaystyle s} and uses it to compute the memory address for prefetching. E.g.: If the s{\displaystyle s} is 4, the address to be prefetched would A+4.

Irregular spatial strides
In this case, the delta between the addresses of consecutive memory accesses is variable but still follows a pattern. Some prefetchers designs exploit this property to predict and prefetch for future accesses.

Irregular temporal prefetching
This class of prefetchers look for memory access streams that repeat over time. E.g. In this stream of memory accesses: N, A, B, C, E, G, H, A, B, C, I, J, K, A, B, C, L, M, N, O, A, B, C, ...; the stream A,B,C is repeating over time. Other design variation have tried to provide more efficient, performant implementations.

Collaborative prefetching
Computer applications generate a variety of access patterns. The processor and memory subsystem architectures used to execute these applications further disambiguate the memory access patterns they generate. Hence, the effectiveness and efficiency of prefetching schemes often depend on the application and the architectures used to execute them. Recent research has focused on building collaborative mechanisms to synergistically use multiple prefetching schemes for better prefetching coverage and accuracy.

Methods of software prefetching
Compiler directed prefetching
Compiler directed prefetching is widely used within loops with a large number of iterations. In this technique, the compiler predicts future cache misses and inserts a prefetch instruction based on the miss penalty and execution time of the instructions.
These prefetches are non-blocking memory operations, i.e. these memory accesses do not interfere with actual memory accesses. They do not change the state of the processor or cause page faults.
One main advantage of software prefetching is that it reduces the number of compulsory cache misses.The following example shows how a prefetch instruction would be added into code to improve cache performance.

Consider a for loop as shown below:At each iteration, the ith element of the array ""array1"" is accessed. Therefore, the system can prefetch the elements that are going to be accessed in future iterations by inserting a ""prefetch"" instruction as shown below:Here, the prefetch stride, k{\displaystyle k} depends on two factors, the cache miss penalty and the time it takes to execute a single iteration of the for loop. For instance, if one iteration of the loop takes 7 cycles to execute, and the cache miss penalty is 49 cycles then there should be k=49/7=7{\displaystyle k=49/7=7} - which means that the system should prefetch 7 elements ahead. With the first iteration, i will be 0, so the system prefetches the 7th element. Now, with this arrangement, the first 7 accesses (i=0->6) will still be misses (under the simplifying assumption that each element of array1 is in a separate cache line of its own).

Comparison of hardware and software prefetching
While software prefetching requires programmer or compiler intervention, hardware prefetching requires special hardware mechanisms.
Software prefetching works well only with loops where there is regular array access as the programmer has to hand code the prefetch instructions, whereas hardware prefetchers work dynamically based on the program's behavior at runtime.
Hardware prefetching also has less CPU overhead when compared to software prefetching. However, software prefetching can mitigate certain constraints of hardware prefetching, leading to improvements in performance.

Metrics of cache prefetching
There are three main metrics to judge cache prefetching

Coverage
Coverage is the fraction of total misses that are eliminated because of prefetching, i.e.
Coverage=Cache Misses eliminated by PrefetchingTotal Cache Misses{\displaystyle Coverage={\frac {\text{Cache Misses eliminated by Prefetching}}{\text{Total Cache Misses}}}},
where, Total Cache Misses=(Cache misses eliminated by prefetching)+(Cache misses not eliminated by prefetching){\displaystyle {\text{Total Cache Misses}}=({\text{Cache misses eliminated by prefetching}})+({\text{Cache misses not eliminated by prefetching}})}

Accuracy
Accuracy is the fraction of total prefetches that were useful - i.e. the ratio of the number of memory addresses prefetched were actually referenced by the program to the total prefetches done.
Prefetch Accuracy=Cache Misses eliminated by prefetching(Useless Cache Prefetches)+(Cache Misses eliminated by prefetching){\displaystyle {\text{Prefetch Accuracy}}={\frac {\text{Cache Misses eliminated by prefetching}}{({\text{Useless Cache Prefetches}})+({\text{Cache Misses eliminated by prefetching}})}}}
While it appears that having perfect accuracy might imply that there are no misses, this is not the case. The prefetches themselves might result in new misses if the prefetched blocks are placed directly into the cache. Although these may be a small fraction of the total number of misses observed without any prefetching, this is a non-zero number of misses.

Timeliness
The qualitative definition of timeliness is how early a block is prefetched versus when it is actually referenced. An example to further explain timeliness is as follows:
Consider a for loop where each iteration takes 3 cycles to execute and the 'prefetch' operation takes 12 cycles. This implies that for the prefetched data to be useful, the system must start the prefetch 12/3=4{\displaystyle 12/3=4}  iterations prior to its usage to maintain timeliness.

See also
Prefetch input queue
Link prefetching
Prefetcher
Cache control instruction


== References ==",51540963,https://en.wikipedia.org/wiki/Cache_prefetching
Instruction window,"An instruction window in computer architecture refers to the set of instructions which can execute out-of-order in a speculative processor.
In particular, in a conventional design, the instruction window consists of all instructions which are in the re-order buffer (ROB). In such a processor, any instruction within the instruction window can be executed when its operands are ready. Out-of-order processors derive their name because this may occur out-of-order (if operands to a younger instruction are ready before those of an older instruction).
The instruction window has a finite size, and new instructions can enter the window (usually called dispatch or allocate) only when other instructions leave the window (usually called retire or commit). Instructions enter and leave the instruction window in program order, and an instruction can only leave the window when it is the oldest instruction in the window, and it has been completed. Hence, the instruction window can be seen as a sliding window in which the instructions can become out-of-order. All execution within the window is speculative (i.e., side-effects are not applied outside the CPU) until it is committed in order to support asynchronous exception handling like interrupts.
This paradigm is also known as restricted dataflow because instructions within the window execute in dataflow order (not necessarily in program order) but the window in which this occurs is restricted (of finite size).
The instruction window is distinct from pipelining: instructions in an in-order pipeline are not in an instruction window in the conventionally understood sense, because they cannot execute out of order with respect to one another. Out-of-order processors are usually built around pipelines, but many of the pipeline stages (e.g., front-end instruction fetch and decode stages) are not considered to be part of the instruction window.","An instruction window in computer architecture refers to the set of instructions which can execute out-of-order in a speculative processor.
In particular, in a conventional design, the instruction window consists of all instructions which are in the re-order buffer (ROB). In such a processor, any instruction within the instruction window can be executed when its operands are ready. Out-of-order processors derive their name because this may occur out-of-order (if operands to a younger instruction are ready before those of an older instruction).
The instruction window has a finite size, and new instructions can enter the window (usually called dispatch or allocate) only when other instructions leave the window (usually called retire or commit). Instructions enter and leave the instruction window in program order, and an instruction can only leave the window when it is the oldest instruction in the window, and it has been completed. Hence, the instruction window can be seen as a sliding window in which the instructions can become out-of-order. All execution within the window is speculative (i.e., side-effects are not applied outside the CPU) until it is committed in order to support asynchronous exception handling like interrupts.
This paradigm is also known as restricted dataflow because instructions within the window execute in dataflow order (not necessarily in program order) but the window in which this occurs is restricted (of finite size).
The instruction window is distinct from pipelining: instructions in an in-order pipeline are not in an instruction window in the conventionally understood sense, because they cannot execute out of order with respect to one another. Out-of-order processors are usually built around pipelines, but many of the pipeline stages (e.g., front-end instruction fetch and decode stages) are not considered to be part of the instruction window.

See also
Superscalar processor


== References ==",28915147,https://en.wikipedia.org/wiki/Instruction_window
Load–store architecture,"In computer engineering, a load–store architecture (or a register–register architecture) is an instruction set architecture that divides instructions into two categories: memory access (load and store between memory and registers) and ALU operations (which only occur between registers).: 9–12 Some RISC architectures such as PowerPC, SPARC, RISC-V, ARM, and MIPS are load–store architectures.: 9–12 For instance, in a load–store approach both operands and destination for an ADD operation must be in registers. This differs from a register–memory architecture (for example, a CISC instruction set architecture such as x86) in which one of the operands for the ADD operation may be in memory, while the other is in a register.: 9–12 The earliest example of a load–store architecture was the CDC 6600.: 54–56  Almost all vector processors (including many GPUs) use the load–store approach.","In computer engineering, a load–store architecture (or a register–register architecture) is an instruction set architecture that divides instructions into two categories: memory access (load and store between memory and registers) and ALU operations (which only occur between registers).: 9–12 Some RISC architectures such as PowerPC, SPARC, RISC-V, ARM, and MIPS are load–store architectures.: 9–12 For instance, in a load–store approach both operands and destination for an ADD operation must be in registers. This differs from a register–memory architecture (for example, a CISC instruction set architecture such as x86) in which one of the operands for the ADD operation may be in memory, while the other is in a register.: 9–12 The earliest example of a load–store architecture was the CDC 6600.: 54–56  Almost all vector processors (including many GPUs) use the load–store approach.

See also
Load–store unit
Register–memory architecture


== References ==",35161236,https://en.wikipedia.org/wiki/Load%E2%80%93store_architecture
Load–store unit,"In computer engineering, a load–store unit (LSU) is a specialized execution unit responsible for executing all load and store instructions, generating virtual addresses of load and store operations and loading data from memory or storing it back to memory from registers.The load–store unit usually includes a queue which acts as a waiting area for memory instructions, and the unit itself operates independently of other processor units.Load–store units may also be used in vector processing, and in such cases the term ""load–store vector"" may be used.Some load–store units are also capable of executing simple fixed-point and/or integer operations.","In computer engineering, a load–store unit (LSU) is a specialized execution unit responsible for executing all load and store instructions, generating virtual addresses of load and store operations and loading data from memory or storing it back to memory from registers.The load–store unit usually includes a queue which acts as a waiting area for memory instructions, and the unit itself operates independently of other processor units.Load–store units may also be used in vector processing, and in such cases the term ""load–store vector"" may be used.Some load–store units are also capable of executing simple fixed-point and/or integer operations.

See also
Address-generation unit
Arithmetic–logic unit
Floating-point unit
Load–store architecture


== References ==",35456317,https://en.wikipedia.org/wiki/Load%E2%80%93store_unit
Machine Check Architecture,"In computing, Machine Check Architecture (MCA) is an Intel and AMD mechanism in which the CPU reports hardware errors to the operating system.
Intel's P6 and Pentium 4 family processors, AMD's K7 and K8 family processors, as well as the Itanium architecture implement a machine check architecture that provides a mechanism for detecting and reporting hardware (machine) errors, such as: system bus errors, ECC errors, parity errors, cache errors, and translation lookaside buffer errors. It consists of a set of model-specific registers (MSRs) that are used to set up machine checking and additional banks of MSRs used for recording errors that are detected.","In computing, Machine Check Architecture (MCA) is an Intel and AMD mechanism in which the CPU reports hardware errors to the operating system.
Intel's P6 and Pentium 4 family processors, AMD's K7 and K8 family processors, as well as the Itanium architecture implement a machine check architecture that provides a mechanism for detecting and reporting hardware (machine) errors, such as: system bus errors, ECC errors, parity errors, cache errors, and translation lookaside buffer errors. It consists of a set of model-specific registers (MSRs) that are used to set up machine checking and additional banks of MSRs used for recording errors that are detected.

See also
Machine-check exception (MCE)
High availability (HA)
Reliability, availability and serviceability (RAS)
Windows Hardware Error Architecture (WHEA)

References
External links
Microsoft's article on Itanium's MCA
Linux x86 daemon for processing of machine checks",14655528,https://en.wikipedia.org/wiki/Machine_Check_Architecture
Manycore processor,"Manycore processors are special kinds of multi-core processors designed for a high degree of parallel processing, containing numerous simpler, independent processor cores (from a few tens of cores to thousands or more). Manycore processors are used extensively in embedded computers and high-performance computing.","Manycore processors are special kinds of multi-core processors designed for a high degree of parallel processing, containing numerous simpler, independent processor cores (from a few tens of cores to thousands or more). Manycore processors are used extensively in embedded computers and high-performance computing.

Contrast with multicore architecture
Manycore processors are distinct from multi-core processors in being optimized from the outset for a higher degree of explicit parallelism, and for higher throughput (or lower power consumption) at the expense of latency and lower single-thread performance.
The broader category of multi-core processors, by contrast, are usually designed to efficiently run both parallel and serial code, and therefore place more emphasis on high single-thread performance (e.g. devoting more silicon to out-of-order execution, deeper pipelines, more superscalar execution units, and larger, more general caches), and shared memory. These techniques devote runtime resources toward figuring out implicit parallelism in a single thread. They are used in systems where they have evolved continuously (with backward compatibility) from single core processors. They usually have a 'few' cores (e.g. 2, 4, 8) and may be complemented by a manycore accelerator (such as a GPU) in a heterogeneous system.

Motivation
Cache coherency is an issue limiting the scaling of multicore processors. Manycore processors may bypass this with methods such as message passing, scratchpad memory, DMA, partitioned global address space, or read-only/non-coherent caches. A manycore processor using a network on a chip  and local memories gives software the opportunity to explicitly optimise the spatial layout of tasks (e.g. as seen in tooling developed for TrueNorth).Manycore processors may have more in common (conceptually) with technologies originating in high-performance computing such as clusters and vector processors.GPUs may be considered a form of manycore processor having multiple shader processing units, and only being suitable for highly parallel code (high throughput, but extremely poor single thread performance).

Suitable programming models
Message passing interface
OpenCL or other APIs supporting compute kernels
Partitioned global address space
Actor model
OpenMP
Dataflow

Classes of manycore systems
GPUs, which can be described as manycore vector processors
Massively parallel processor array
Asynchronous array of simple processors

Specific manycore architectures
ZettaScaler [1], Japanese PEZY Computing 2,048-core modules
Xeon Phi coprocessor, which has MIC (Many Integrated Cores) architecture
Tilera
Adapteva Epiphany Architecture, a manycore chip using PGAS scratchpad memory
Coherent Logix hx3100 Processor, a 100-core DSP/GPP processor based on HyperX Architecture
Movidius Myriad 2, a manycore vision processing unit (VPU)
Kalray, a manycore PCI-e accelerator for data-intensive tasks
Teraflops Research Chip, a manycore processor using message passing
TrueNorth, an AI accelerator with a manycore network on a chip architecture
Green arrays, a manycore processor using message passing aimed at low power applications
Sunway SW26010, a 260-core manycore processor used in the then top 1 supercomputer Sunway TaihuLight
SW52020, an improved 520-core variant of SW26010, with 512-bit SIMD (also adding support for half-precision), used in a prototype, meant for an exascale system (and in the future 10 exascale system), and according to datacenterdynamics China is rumored to already have two separate exascale systems secretly
Eyeriss, a manycore processor designed for running convolutional neural nets for embedded vision applications
Graphcore, a manycore AI accelerator

Specific manycore computers with 1M+ CPU cores
A number of computers built from multicore processors have one million or more individual CPU cores. Examples include:

Gyoukou (Japanese: 暁光 Hepburn: gyōkō, dawn light), a supercomputer developed by ExaScaler and PEZY Computing, with 20,480,000 processing elements total plus the 1,250 Intel Xeon D host processors.
SpiNNaker, a massively parallel (1 million CPU cores) manycore processor (ARM-based) built as part of the Human Brain Project.

Specific computers with 5 million or more CPU cores
Quite a few supercomputers have over 5 million CPU cores. When there are also coprocessors, e.g. GPUs used with, then those cores are not listed in the core-count, then quite a few more computers would hit those targets.

Frontier
Fugaku, a Japanese supercomputer using Fujitsu A64FX ARM-based cores, 7,630,848 in total.
Sunway TaihuLight, a massively parallel (10 million CPU cores) Chinese supercomputer, once one of the fastest supercomputers in the world, using a custom manycore architecture. As of November 2018, it was the world's third fastest supercomputer (as ranked by the TOP500 list), obtaining its performance from 40,960 SW26010 manycore processors, each containing 256 cores.

See also
Multi-core processor
Vector processor
SIMD
High-performance computing
Computer cluster
Multiprocessor system on a chip
Vision processing unit
Memory access pattern
Cache coherency
Embarrassingly parallel
Massively parallel
CUDA

References
External links
Architecting solutions for the Manycore future, published on Feb 19, 2010 (more than one dead link in the slide)
Eyeriss architecture",23548810,https://en.wikipedia.org/wiki/Manycore_processor
MCDRAM,"Multi-Channel DRAM or MCDRAM (pronounced em cee dee ram) is a 3D-stacked DRAM that is used in the Intel Xeon Phi processor codenamed Knights Landing.  It is a version of Hybrid Memory Cube developed in partnership with Micron Technology, and a competitor to High Bandwidth Memory.  
The many cores in the Xeon Phi processors, along with their associated vector processing units, enable them to consume many more gigabytes per second than traditional DRAM DIMMs can supply.  The ""Multi-channel"" part of the MCDRAM full name reflects the cores having many more channels available to access the MCDRAM than processors have to access their attached DIMMs.
This high channel count leads to MCDRAM's high bandwidth, up to 400+ GB/s, although the latencies are similar to a DIMM access.
Its physical placement on the processor imposes some limits on capacity – up to 16 GB at launch, although speculated to go higher in the future.","Multi-Channel DRAM or MCDRAM (pronounced em cee dee ram) is a 3D-stacked DRAM that is used in the Intel Xeon Phi processor codenamed Knights Landing.  It is a version of Hybrid Memory Cube developed in partnership with Micron Technology, and a competitor to High Bandwidth Memory.  
The many cores in the Xeon Phi processors, along with their associated vector processing units, enable them to consume many more gigabytes per second than traditional DRAM DIMMs can supply.  The ""Multi-channel"" part of the MCDRAM full name reflects the cores having many more channels available to access the MCDRAM than processors have to access their attached DIMMs.
This high channel count leads to MCDRAM's high bandwidth, up to 400+ GB/s, although the latencies are similar to a DIMM access.
Its physical placement on the processor imposes some limits on capacity – up to 16 GB at launch, although speculated to go higher in the future.

Programming
The memory can be partitioned at boot time, with some used as cache for more distant DDR, and the remainder mapped into the physical address space.
The application can request pages of virtual memory to be assigned to either the distant DDR directly, to the portion of DDR that is cached by the MCDRAM, or to the portion of the MCDRAM that is not being used as cache.  One way to do this is via thememkind API.When used as cache, the latency of a miss accessing both the MCDRAM and DDR is slightly higher than going directly to DDR, and so applications may need to be tuned
to avoid excessive cache misses.

References
External links

MCDRAM (High Bandwidth Memory) on Knights Landing – Analysis Methods & Tools
An Intro to MCDRAM (High Bandwidth Memory) on Knights Landing
High Bandwidth Memory (HBM): how will it benefit your application?
Micron HMC Webinar July 2017 slides",50223751,https://en.wikipedia.org/wiki/MCDRAM
Memory dependence prediction,"Memory dependence prediction is a technique, employed by high-performance out-of-order execution microprocessors that execute memory access operations (loads and stores) out of program order, to predict true dependencies between loads and stores at instruction execution time. With the predicted dependence information, the processor can then decide to speculatively execute certain loads and stores out of order, while preventing other loads and stores from executing out-of-order (keeping them in-order). Later in the pipeline, memory disambiguation techniques are used to determine if the loads and stores were correctly executed and, if not, to recover.
By using the memory dependence predictor to keep most dependent loads and stores in order, the processor gains the benefits of aggressive out-of-order load/store execution but avoids many of the memory dependence violations that occur when loads and stores were incorrectly executed. This increases performance because it reduces the number of pipeline flushes that are required to recover from these memory dependence violations. See the memory disambiguation article for more information on memory dependencies, memory dependence violations, and recovery.
In general, memory dependence prediction predicts whether two memory operations are dependent, that is, if they interact by accessing the same memory location. Besides using store to load (RAW or true) memory dependence prediction for the out-of-order scheduling of loads and stores, other applications of memory dependence prediction have been proposed. See for example.Memory dependence prediction is an optimization on top of memory dependency speculation. Sequential execution semantics imply that stores and loads appear to execute in the order specified by the program. However, as with out-of-order execution of other instructions, it may be possible to execute two memory operations in a different order from that implied by the program. This is possible when the two operations are independent. In memory dependence speculation a load may be allowed to execute before a store that precedes it. Speculation succeeds when the load is independent of the store, that is, when the two instructions access different memory locations. Speculation fails when the load is dependent upon the store, that is, when the two accesses overlap in memory. In the first, modern out-of-order designs, memory speculation was not used as its benefits were limited. Αs the scope of the out-of-order execution increased over few tens of instructions, naive memory dependence speculation was used. In naive memory dependence speculation, a load is allowed to bypass any preceding store. As with any form of speculation, it is important to weight the benefits of correct speculation against the penalty paid on incorrect speculation. As the scope of out-of-order execution increases further into several tens of instructions, the performance benefits of naive speculation decrease. To retain the benefits of aggressive memory dependence speculation while avoiding the costs of mispeculation several predictors have been proposed.
Selective memory dependence prediction stalls specific loads until it is certain that no violation may occur. It does not explicitly predict dependencies. This predictor may delay loads longer than necessary and hence result in suboptimal performance. In fact, in some cases it performs worse than naively speculating all loads as early as possible. This is because often its faster to mispeculate and recover than to wait for all preceding stores to execute. Exact memory dependence prediction was developed at the University of Wisconsin–Madison. Specifically, Dynamic Speculation and Synchronization delays loads only as long as it is necessary by predicting the exact store a load should wait for. This predictor predicts exact dependences (store and load pair). The synonym predictor groups together all dependences that share a common load or store instruction. The store sets predictor represents multiple potential dependences efficiently by grouping together all possible stores a load may depend upon. The store barrier predictor treats certain store instructions as barriers. That is, all subsequent load or store operations are not allowed to bypass the specific store. The store barrier predictor does not explicitly predict dependencies. This predictor may unnecessarily delay subsequent, yet independent loads. Memory dependence prediction has other applications beyond the scheduling of loads and stores. For example, speculative memory cloaking and speculative memory bypassing use memory dependence prediction to streamline the communication of values through memory.","Memory dependence prediction is a technique, employed by high-performance out-of-order execution microprocessors that execute memory access operations (loads and stores) out of program order, to predict true dependencies between loads and stores at instruction execution time. With the predicted dependence information, the processor can then decide to speculatively execute certain loads and stores out of order, while preventing other loads and stores from executing out-of-order (keeping them in-order). Later in the pipeline, memory disambiguation techniques are used to determine if the loads and stores were correctly executed and, if not, to recover.
By using the memory dependence predictor to keep most dependent loads and stores in order, the processor gains the benefits of aggressive out-of-order load/store execution but avoids many of the memory dependence violations that occur when loads and stores were incorrectly executed. This increases performance because it reduces the number of pipeline flushes that are required to recover from these memory dependence violations. See the memory disambiguation article for more information on memory dependencies, memory dependence violations, and recovery.
In general, memory dependence prediction predicts whether two memory operations are dependent, that is, if they interact by accessing the same memory location. Besides using store to load (RAW or true) memory dependence prediction for the out-of-order scheduling of loads and stores, other applications of memory dependence prediction have been proposed. See for example.Memory dependence prediction is an optimization on top of memory dependency speculation. Sequential execution semantics imply that stores and loads appear to execute in the order specified by the program. However, as with out-of-order execution of other instructions, it may be possible to execute two memory operations in a different order from that implied by the program. This is possible when the two operations are independent. In memory dependence speculation a load may be allowed to execute before a store that precedes it. Speculation succeeds when the load is independent of the store, that is, when the two instructions access different memory locations. Speculation fails when the load is dependent upon the store, that is, when the two accesses overlap in memory. In the first, modern out-of-order designs, memory speculation was not used as its benefits were limited. Αs the scope of the out-of-order execution increased over few tens of instructions, naive memory dependence speculation was used. In naive memory dependence speculation, a load is allowed to bypass any preceding store. As with any form of speculation, it is important to weight the benefits of correct speculation against the penalty paid on incorrect speculation. As the scope of out-of-order execution increases further into several tens of instructions, the performance benefits of naive speculation decrease. To retain the benefits of aggressive memory dependence speculation while avoiding the costs of mispeculation several predictors have been proposed.
Selective memory dependence prediction stalls specific loads until it is certain that no violation may occur. It does not explicitly predict dependencies. This predictor may delay loads longer than necessary and hence result in suboptimal performance. In fact, in some cases it performs worse than naively speculating all loads as early as possible. This is because often its faster to mispeculate and recover than to wait for all preceding stores to execute. Exact memory dependence prediction was developed at the University of Wisconsin–Madison. Specifically, Dynamic Speculation and Synchronization delays loads only as long as it is necessary by predicting the exact store a load should wait for. This predictor predicts exact dependences (store and load pair). The synonym predictor groups together all dependences that share a common load or store instruction. The store sets predictor represents multiple potential dependences efficiently by grouping together all possible stores a load may depend upon. The store barrier predictor treats certain store instructions as barriers. That is, all subsequent load or store operations are not allowed to bypass the specific store. The store barrier predictor does not explicitly predict dependencies. This predictor may unnecessarily delay subsequent, yet independent loads. Memory dependence prediction has other applications beyond the scheduling of loads and stores. For example, speculative memory cloaking and speculative memory bypassing use memory dependence prediction to streamline the communication of values through memory.

Analogy to branch prediction
Memory dependence prediction for loads and stores is analogous to branch prediction for conditional branch instructions. In branch prediction, the branch predictor predicts which way the branch will resolve before it is known. The processor can then speculatively fetch and execute instructions down one of the paths of the branch. Later, when the branch instruction executes, it can be determined if the branch instruction was correctly predicted. If not, this is a branch misprediction, and a pipeline flush is necessary to throw away instructions that were speculatively fetched and executed.
Branch prediction can be thought of as a two step process. First, the predictor determines the direction of the branch (taken or not). This is a binary decision. Then, the predictor determines the actual target address. Similarly, memory dependence prediction can be thought of as a two step process. First, the predictor determines whether there is a dependence. Then it determines which this dependence is.

See also
Memory-level parallelism
Memory disambiguation


== References ==",6753240,https://en.wikipedia.org/wiki/Memory_dependence_prediction
Memory disambiguation,"Memory disambiguation is a set of techniques employed by high-performance out-of-order execution microprocessors that execute memory access instructions (loads and stores) out of program order.  The mechanisms for performing memory disambiguation, implemented using digital logic inside the microprocessor core, detect true dependencies between memory operations at execution time and allow the processor to recover when a dependence has been violated.  They also eliminate spurious memory dependencies and allow for greater instruction-level parallelism by allowing safe out-of-order execution of loads and stores.","Memory disambiguation is a set of techniques employed by high-performance out-of-order execution microprocessors that execute memory access instructions (loads and stores) out of program order.  The mechanisms for performing memory disambiguation, implemented using digital logic inside the microprocessor core, detect true dependencies between memory operations at execution time and allow the processor to recover when a dependence has been violated.  They also eliminate spurious memory dependencies and allow for greater instruction-level parallelism by allowing safe out-of-order execution of loads and stores.

Background
Dependencies
When attempting to execute instructions out of order, a microprocessor must respect true dependencies between instructions.  For example, consider a simple true dependence:

1: add $1, $2, $3      # R1 <= R2 + R3
2: add $5, $1, $4      # R5 <= R1 + R4 (dependent on 1)

In this example, the add instruction on line 2 is dependent on the add instruction on line 1 because the register R1 is a source operand of the addition operation on line 2.  The add on line 2 cannot execute until the add on line 1 completes.  In this case, the dependence is static and easily determined by a microprocessor, because the sources and destinations are registers.  The destination register of the add instruction on line 1 (R1) is part of the instruction encoding, and so can be determined by the microprocessor early on, during the decode stage of the pipeline.  Similarly, the source registers of the add instruction on line 2 (R1 and R4) are also encoded into the instruction itself and are determined in decode.  To respect this true dependence, the microprocessor's scheduler logic will issue these instructions in the correct order (instruction 1 first, followed by instruction 2) so that the results of 1 are available when instruction 2 needs them.
Complications arise when the dependence is not statically determinable.  Such non-static dependencies arise with memory instructions (loads and stores) because the location of the operand may be indirectly specified as a register operand rather than directly specified in the instruction encoding itself.

1: store $1, 2($2)      # Mem[R2+2] <= R1
2: load  $3, 4($4)      # R3 <= Mem[R4+4] (possibly dependent on 1, possible same address as above)

Here, the store instruction writes a value to the memory location specified by the value in the address (R2+2), and the load instruction reads the value at the memory location specified by the value in address (R4+4).  The microprocessor cannot statically determine, prior to execution, if the memory locations specified in these two instructions are different, or are the same location, because the locations depend on the values in R2 and R4.  If the locations are different, the instructions are independent and can be successfully executed out of order.  However, if the locations are the same, then the load instruction is dependent on the store to produce its value.  This is known as an ambiguous dependence.

Out-of-order execution and memory access operations
Executing loads and stores out of order can produce incorrect results if a dependent load/store pair was executed out of order.  Consider the following code snippet, given in MIPS assembly:

1: div $27, $20
2: sw  $27, 0($30)
3: lw  $08, 0($31)
4: sw  $26, 0($30)
5: lw  $09, 0($31)

Assume that the scheduling logic will issue an instruction to the execution unit when all of its register operands are ready.  Further, assume that registers $30 and $31 are ready: the values in $30 and $31 were computed a long time ago and have not changed.  However, assume $27 is not ready: its value is still in the process of being computed by the div (integer divide) instruction.  Finally, assume that registers $30 and $31 hold the same value, and thus all the loads and stores in the snippet access the same memory word.
In this situation, the sw $27, 0($30) instruction on line 2 is not ready to execute, but the lw  $08, 0($31) instruction on line 3 is ready.  If the processor allows the lw instruction to execute before the sw, the load will read an old value from the memory system; however, it should have read the value that was just written there by the sw.  The load and store were executed out of program order, but there was a memory dependence between them that was violated.
Similarly, assume that register $26 is ready.  The sw $26, 0($30) instruction on line 4 is also ready to execute, and it may execute before the preceding lw  $08, 0($31) on line 3.  If this occurs, the lw  $08, 0($31) instruction will read the wrong value from the memory system, since a later store instruction wrote its value there before the load executed.

Characterization of memory dependencies
Memory dependencies come in three flavors:

Read-After-Write (RAW) dependencies: Also known as true dependencies, RAW dependencies arise when a load operation reads a value from memory that was produced by the most recent preceding store operation to that same address.
Write-After-Read (WAR) dependencies: Also known as anti dependencies, WAR dependencies arise when a store operation writes a value to memory that a preceding load reads.
Write-After-Write (WAW) dependencies: Also known as output dependencies, WAW dependencies arise when two store operations write values to the same memory address.The three dependencies are shown in the preceding code segment (reproduced for clarity):

1: div $27, $20
2: sw  $27, 0($30)
3: lw  $08, 0($31)
4: sw  $26, 0($30)
5: lw  $09, 0($31)

The lw  $08, 0($31) instruction on line 3 has a RAW dependence on the sw $27, 0($30) instruction on line 2, and the lw  $09, 0($31) instruction on line 5 has a RAW dependence on the sw $26, 0($30) instruction on line 4.  Both load instructions read the memory address that the preceding stores wrote.  The stores were the most recent producers to that memory address, and the loads are reading that memory address's value.
The sw  $26, 0($30) instruction on line 4 has a WAR dependence on the lw  $08, 0($31) instruction on line 3 since it writes the memory address that the preceding load reads from.
The sw  $26, 0($30) instruction on line 4 has a WAW dependence on the sw  $27, 0($30) instruction on line 2 since both stores write to the same memory address.

Memory disambiguation mechanisms
Modern microprocessors use the following mechanisms, implemented in hardware, to resolve ambiguous dependences and recover when a dependence was violated.

Avoiding WAR and WAW dependencies
Values from store instructions are not committed to the memory system (in modern microprocessors, CPU cache) when they execute.  Instead, the store instructions, including the memory address and store data, are buffered in a store queue until they reach the retirement point.  When a store retires, it then writes its value to the memory system.  This avoids the WAR and WAW dependence problems shown in the code snippet above where an earlier load receives an incorrect value from the memory system because a later store was allowed to execute before the earlier load.
Additionally, buffering stores until retirement allows processors to speculatively execute store instructions that follow an instruction that may produce an exception (such as a load of a bad address, divide by zero, etc.) or a conditional branch instruction whose direction (taken or not taken) is not yet known.  If the exception-producing instruction has not executed or the branch direction was predicted incorrectly, the processor will have fetched and executed instructions on a ""wrong path.""  These instructions should not have been executed at all; the exception condition should have occurred before any of the speculative instructions executed, or the branch should have gone the other direction and caused different instructions to be fetched and executed.  The processor must ""throw away"" any results from the bad-path, speculatively-executed instructions when it discovers the exception or branch misprediction.  The complication for stores is that any stores on the bad or mispredicted path should not have committed their values to the memory system; if the stores had committed their values, it would be impossible to ""throw away"" the commit, and the memory state of the machine would be corrupted by data from a store instruction that should not have executed.
Thus, without store buffering, stores cannot execute until all previous possibly-exception-causing instructions have executed (and not caused an exception) and all previous branch directions are known.  Forcing stores to wait until branch directions and exceptions are known significantly reduces the out-of-order aggressiveness and limits ILP (Instruction level parallelism) and performance.  With store buffering, stores can execute ahead of exception-causing or unresolved branch instructions, buffering their data in the store queue but not committing their values until retirement.  This prevents stores on mispredicted or bad paths from committing their values to the memory system while still offering the increased ILP and performance from full out-of-order execution of stores.

Store to load forwarding
Buffering stores until retirement avoids WAW and WAR dependencies but introduces a new issue.  Consider the following scenario: a store executes and buffers its address and data in the store queue.  A few instructions later, a load executes that reads from the same memory address to which the store just wrote.  If the load reads its data from the memory system, it will read an old value that would have been overwritten by the preceding store.  The data obtained by the load will be incorrect.
To solve this problem, processors employ a technique called store-to-load forwarding using the store queue.  In addition to buffering stores until retirement, the store queue serves a second purpose: forwarding data from completed but not-yet-retired (""in-flight"") stores to later loads.  Rather than a simple FIFO queue, the store queue is really a Content-Addressable Memory (CAM) searched using the memory address.  When a load executes, it searches the store queue for in-flight stores to the same address that are logically earlier in program order.  If a matching store exists, the load obtains its data value from that store instead of the memory system.  If there is no matching store, the load accesses the memory system as usual; any preceding, matching stores must have already retired and committed their values.  This technique allows loads to obtain correct data if their producer store has completed but not yet retired.
Multiple stores to the load's memory address may be present in the store queue.  To handle this case, the store queue is priority encoded to select the latest store that is logically earlier than the load in program order.  The determination of which store is ""latest"" can be achieved by attaching some sort of timestamp to the instructions as they are fetched and decoded, or alternatively by knowing the relative position (slot) of the load with respect to the oldest and newest stores within the store queue.

RAW dependence violations
Detecting RAW dependence violations
Modern out-of-order CPUs can use a number of techniques to detect a RAW dependence violation, but all techniques require tracking in-flight loads from execution until retirement.  When a load executes, it accesses the memory system and/or store queue to obtain its data value, and then its address and data are buffered in a load queue until retirement.  The load queue is similar in structure and function to the store queue, and in fact in some processors may be combined with the store queue in a single structure called a load-store queue, or LSQ.  The following techniques are used or have been proposed to detect RAW dependence violations:

Load queue CAM search
With this technique, the load queue, like the store queue, is a CAM searched using the memory access address, and keeps track of all in-flight loads.  When a store executes, it searches the load queue for completed loads from the same address that are logically later in program order.  If such a matching load exists, it must have executed before the store and thus read an incorrect, old value from the memory system/store queue.  Any instructions that used the load's value have also used bad data.  To recover if such a violation is detected, the load is marked as ""violated"" in the retirement buffer.  The store remains in the store queue and retirement buffer and retires normally, committing its value to the memory system when it retires.  However, when the violated load reaches the retirement point, the processor flushes the pipeline and restarts execution from the load instruction.  At this point, all previous stores have committed their values to the memory system.  The load instruction will now read the correct value from the memory system, and any dependent instructions will re-execute using the correct value.
This technique requires an associative search of the load queue on every store execution, which consumes circuit power and can prove to be a difficult timing path for large load queues.  However, it does not require any additional memory (cache) ports or create resource conflicts with other loads or stores that are executing.

Disambiguation at retirement
With this technique, load instructions that have executed out-of-order are re-executed (they access the memory system and read the value from their address a second time) when they reach the retirement point.  Since the load is now the retiring instruction, it has no dependencies on any instruction still in-flight; all stores ahead of it have committed their values to the memory system, and so any value read from the memory system is guaranteed to be correct.  The value read from memory at re-execution time is compared to the value obtained when the load first executed.  If the values are the same, the original value was correct and no violation has occurred.  If the re-execution value differs from the original value, a RAW violation has occurred and the pipeline must be flushed because instructions dependent on the load have used an incorrect value.
This technique is conceptually simpler than the load queue search, and it eliminates a second CAM and its power-hungry search (the load queue can now be a simple FIFO queue).  Since the load must re-access the memory system just before retirement, the access must be very fast, so this scheme relies on a fast cache.  No matter how fast the cache is, however, the second memory system access for every out-of-order load instruction does increase instruction retirement latency and increases the total number of cache accesses that must be performed by the processor.  The additional retire-time cache access can be satisfied by re-using an existing cache port; however, this creates port resource contention with other loads and stores in the processor trying to execute, and thus may cause a decrease in performance.  Alternatively, an additional cache port can be added just for load disambiguation, but this increases the complexity, power, and area of the cache.  Some recent work (Roth 2005) has shown ways to filter many loads from re-executing if it is known that no RAW dependence violation could have occurred; such a technique would help or eliminate such latency and resource contention.
A minor benefit of this scheme (compared to a load-queue search) is that it will not flag a RAW dependence violation and trigger a pipeline flush if a store that would have caused a RAW dependence violation (the store's address matches an in-flight load's address) has a data value that matches the data value already in the cache.  In the load-queue search scheme, an additional data comparison would need to be added to the load-queue search hardware to prevent such a pipeline flush.

Avoiding RAW dependence violations
CPUs that fully support out-of-order execution of loads and stores must be able to detect RAW dependence violations when they occur.  However, many CPUs avoid this problem by forcing all loads and stores to execute in-order, or by supporting only a limited form of out-of-order load/store execution.  This approach offers lower performance compared to supporting full out-of-order load/store execution, but it can significantly reduce the complexity of the execution core and caches.
The first option, making loads and stores go in-order, avoids RAW dependences because there is no possibility of a load executing before its producer store and obtaining incorrect data.  Another possibility is to effectively break loads and stores into two operations: address generation and cache access.  With these two separate but linked operations, the CPU can allow loads and stores to access the memory system only once all previous loads and stores have had their address generated and buffered in the LSQ.  After address generation, there are no longer any ambiguous dependencies since all addresses are known, and so dependent loads will not be executed until their corresponding stores complete.  This scheme still allows for some ""out-of-orderness"" — the address generation operations for any in-flight loads and stores can execute out-of-order, and once addresses have been generated, the cache accesses for each load or store can happen in any order that respects the (now known) true dependences.

Additional Issues
Memory dependence prediction
Processors that fully support out-of-order load/store execution can use an additional, related technique, called memory dependence prediction, to attempt to predict true dependences between loads and stores before their addresses are known.  Using this technique, the processor can prevent loads that are predicted to be dependent on an in-flight store from executing before that store completes, avoiding a RAW dependence violation and thus avoiding the pipeline flush and the performance penalty that is incurred.  See the memory dependence prediction article for more details.

See also
Instruction pipeline
Out-of-order execution
CPU cache
Memory dependence prediction",5375682,https://en.wikipedia.org/wiki/Memory_disambiguation
Memory hierarchy,"In computer organisation, the memory hierarchy separates computer storage into a hierarchy based on response time. Since response time, complexity, and capacity are related, the levels may also be distinguished by their performance and controlling technologies. Memory hierarchy affects performance in computer architectural design, algorithm predictions, and lower level programming constructs involving locality of reference. 
Designing for high performance requires considering the restrictions of the memory hierarchy, i.e. the size and capabilities of each component. Each of the various components can be viewed as part of a hierarchy of memories (m1, m2, ..., mn) in which each member mi is typically smaller and faster than the next highest member mi+1 of the hierarchy. To limit waiting by higher levels, a lower level will respond by filling a buffer and then signaling for activating the transfer.
There are four major storage levels.
Internal – Processor registers and cache.
Main – the system RAM and controller cards.
On-line mass storage – Secondary storage.
Off-line bulk storage – Tertiary and Off-line storage.This is a general memory hierarchy structuring. Many other structures are useful.  For example, a paging algorithm may be considered as a level for virtual memory when designing a computer architecture, and one can include a level of nearline storage between online and offline storage.","In computer organisation, the memory hierarchy separates computer storage into a hierarchy based on response time. Since response time, complexity, and capacity are related, the levels may also be distinguished by their performance and controlling technologies. Memory hierarchy affects performance in computer architectural design, algorithm predictions, and lower level programming constructs involving locality of reference. 
Designing for high performance requires considering the restrictions of the memory hierarchy, i.e. the size and capabilities of each component. Each of the various components can be viewed as part of a hierarchy of memories (m1, m2, ..., mn) in which each member mi is typically smaller and faster than the next highest member mi+1 of the hierarchy. To limit waiting by higher levels, a lower level will respond by filling a buffer and then signaling for activating the transfer.
There are four major storage levels.
Internal – Processor registers and cache.
Main – the system RAM and controller cards.
On-line mass storage – Secondary storage.
Off-line bulk storage – Tertiary and Off-line storage.This is a general memory hierarchy structuring. Many other structures are useful.  For example, a paging algorithm may be considered as a level for virtual memory when designing a computer architecture, and one can include a level of nearline storage between online and offline storage.

Properties of the technologies in the memory hierarchy
Adding complexity slows down the memory hierarchy.
CMOx memory technology stretches the Flash space in the memory hierarchy
One of the main ways to increase system performance is minimising how far down the memory hierarchy one has to go to manipulate data.
Latency and bandwidth are two metrics associated with caches. Neither of them is uniform, but is specific to a particular component of the memory hierarchy.
Predicting where in the memory hierarchy the data resides is difficult.
...the location in the memory hierarchy dictates the time required for the prefetch to occur.

Examples
The number of levels in the memory hierarchy and the performance at each level has increased over time. The type of memory or storage components also change historically.  For example, the memory hierarchy of an Intel Haswell Mobile processor circa 2013 is:

Processor registers – the fastest possible access (usually 1 CPU cycle). A few thousand bytes in size
Cache
Level 0 (L0) Micro operations cache – 6,144 bytes (6 KiB) in size
Level 1 (L1) Instruction cache – 128 KiB in size
Level 1 (L1) Data cache – 128 KiB in size. Best access speed is around 700 GB/s
Level 2 (L2) Instruction and data (shared) – 1 MiB in size. Best access speed is around 200 GB/s
Level 3 (L3) Shared cache – 6 MiB in size. Best access speed is around 100 GB/s
Level 4 (L4) Shared cache – 128 MiB in size. Best access speed is around 40 GB/s
Main memory (Primary storage) – GiB in size. Best access speed is around 10 GB/s. In the case of a NUMA machine, access times may not be uniform
Disk storage (Secondary storage) – Terabytes in size. As of 2017, best access speed is from a consumer solid state drive is about 2000 MB/s
Nearline storage (Tertiary storage) – Up to exabytes in size.  As of 2013, best access speed is about 160 MB/s
Offline storageThe lower levels of the hierarchy – from disks downwards – are also known as tiered storage. The formal distinction between online, nearline, and offline storage is:
Online storage is immediately available for I/O.
Nearline storage is not immediately available, but can be made online quickly without human intervention.
Offline storage is not immediately available, and requires some human intervention to bring online.For example, always-on spinning disks are online, while spinning disks that spin-down, such as massive array of idle disk (MAID), are nearline. Removable media such as tape cartridges that can be automatically loaded, as in a tape library, are nearline, while cartridges that must be manually loaded are offline.
Most modern CPUs are so fast that for most program workloads, the bottleneck is the locality of reference of memory accesses and the efficiency of the caching and memory transfer between different levels of the hierarchy. As a result, the CPU spends much of its time idling, waiting for memory I/O to complete.  This is sometimes called the space cost, as a larger memory object is more likely to overflow a small/fast level and require use of a larger/slower level. The resulting load on memory use is known as pressure (respectively register pressure, cache pressure, and (main) memory pressure). Terms for data being missing from a higher level and needing to be fetched from a lower level are, respectively: register spilling (due to register pressure: register to cache), cache miss (cache to main memory), and (hard) page fault (main memory to disk).
Modern programming languages mainly assume two levels of memory, main memory and disk storage, though in assembly language and inline assemblers in languages such as C, registers can be directly accessed. Taking optimal advantage of the memory hierarchy requires the cooperation of programmers, hardware, and compilers (as well as underlying support from the operating system):

Programmers are responsible for moving data between disk and memory through file I/O.
Hardware is responsible for moving data between memory and caches.
Optimizing compilers are responsible for generating code that, when executed, will cause the hardware to use caches and registers efficiently.Many programmers assume one level of memory.  This works fine until the application hits a performance wall.  Then the memory hierarchy will be assessed during code refactoring.

See also
Cache hierarchy
Use of spatial and temporal locality: hierarchical memory
Buffer vs. cache
Cache hierarchy in a modern processor
Memory wall
Computer memory
Hierarchical storage management
Cloud storage
Memory access pattern
Communication-avoiding algorithm


== References ==",137146,https://en.wikipedia.org/wiki/Memory_hierarchy
Programming language,"A programming language is a system of notation for writing computer programs.Programming languages are described in terms of their syntax (form) and semantics (meaning), usually defined by a formal language. Languages usually provide features such as a type system, variables and mechanisms for error handling. An implementation of a programming language in the form of a compiler or interpreter allows programs to be executed, either directly or by producing an executable.
Computer architecture has strongly influenced the design of programming languages, with the most common type (imperative languages—which implement operations in a specified order) developed to perform well on the popular von Neumann architecture. While early programming languages were closely tied to the hardware, over time, they have developed more abstraction to hide implementation details for greater simplicity. 
Thousands of programming languages—often classified as imperative, functional, logic, or object-oriented—have been developed for a wide variety of uses. Many aspects of programming language design involve tradeoffs—for example, exception handling simplifies error handling, but at a performance cost. Programming language theory is the subfield of computer science that studies the design, implementation, analysis, characterization, and classification of programming languages.","A programming language is a system of notation for writing computer programs.Programming languages are described in terms of their syntax (form) and semantics (meaning), usually defined by a formal language. Languages usually provide features such as a type system, variables and mechanisms for error handling. An implementation of a programming language in the form of a compiler or interpreter allows programs to be executed, either directly or by producing an executable.
Computer architecture has strongly influenced the design of programming languages, with the most common type (imperative languages—which implement operations in a specified order) developed to perform well on the popular von Neumann architecture. While early programming languages were closely tied to the hardware, over time, they have developed more abstraction to hide implementation details for greater simplicity. 
Thousands of programming languages—often classified as imperative, functional, logic, or object-oriented—have been developed for a wide variety of uses. Many aspects of programming language design involve tradeoffs—for example, exception handling simplifies error handling, but at a performance cost. Programming language theory is the subfield of computer science that studies the design, implementation, analysis, characterization, and classification of programming languages.

Definitions
There are a variety of criteria that may be considered when defining what constitutes a programming language.

Computer languages vs programming languages
The term computer language is sometimes used interchangeably with programming language. However, the usage of both terms varies among authors, including the exact scope of each. One usage describes programming languages as a subset of computer languages. Similarly, languages used in computing that have a different goal than expressing computer programs are generically designated computer languages. For instance, markup languages are sometimes referred to as computer languages to emphasize that they are not meant to be used for programming.
One way of classifying computer languages is by the computations they are capable of expressing, as described by the theory of computation. The majority of practical programming languages are Turing complete, and all Turing complete languages can implement the same set of algorithms. ANSI/ISO SQL-92 and Charity are examples of languages that are not Turing complete, yet are often called programming languages. However, some authors restrict the term ""programming language"" to Turing complete languages.Another usage regards programming languages as theoretical constructs for programming abstract machines and computer languages as the subset thereof that runs on physical computers, which have finite hardware resources. John C. Reynolds emphasizes that formal specification languages are just as much programming languages as are the languages intended for execution. He also argues that textual and even graphical input formats that affect the behavior of a computer are programming languages, despite the fact they are commonly not Turing-complete, and remarks that ignorance of programming language concepts is the reason for many flaws in input formats.

Domain and target
In most practical contexts, a programming language involves a computer; consequently, programming languages are usually defined and studied this way. Programming languages differ from natural languages in that natural languages are only used for interaction between people, while programming languages also allow humans to communicate instructions to machines.
The domain of the language is also worth consideration. Markup languages like XML, HTML, or troff, which define structured data, are not usually considered programming languages. Programming languages may, however, share the syntax with markup languages if a computational semantics is defined. XSLT, for example, is a Turing complete language entirely using XML syntax. Moreover, LaTeX, which is mostly used for structuring documents, also contains a Turing complete subset.

Abstractions
Programming languages usually contain abstractions for defining and manipulating data structures or controlling the flow of execution. The practical necessity that a programming language supports adequate abstractions is expressed by the abstraction principle. This principle is sometimes formulated as a recommendation to the programmer to make proper use of such abstractions.

History
Early developments
The first programmable computers were invented at the end of the 1940s, and with them, the first programming languages. The earliest computers were programmed in first-generation programming languages (1GLs), machine language (simple instructions that could be directly executed by the processor). This code was very difficult to debug and was not portable between different computer systems. In order to improve the ease of programming, assembly languages (or second-generation programming languages—2GLs) were invented, diverging from the machine language to make programs easier to understand for humans, although they did not increase portability.Initially, hardware resources were scarce and expensive, while human resources were cheaper. Therefore, cumbersome languages that were time-consuming to use, but were closer to the hardware for higher efficiency were favored. The introduction of high-level programming languages (third-generation programming languages—3GLs)—revolutionized programming. These languages abstracted away the details of the hardware, instead being designed to express algorithms that could be understood more easily by humans. For example, arithmetic expressions could now be written in symbolic notation and later translated into machine code that the hardware could execute. In 1957, Fortran (FORmula TRANslation) was invented. Often considered the first compiled high-level programming language, Fortran has remained in use into the twenty-first century.

1960s and 1970s
Around 1960, the first mainframes—general purpose computers—were developed, although they could only be operated by professionals and the cost was extreme. The data and instructions were input by punch cards, meaning that no input could be added while the program was running. The languages developed at this time therefore are designed for minimal interaction. After the invention of the microprocessor, computers in the 1970s became dramatically cheaper. New computers also allowed more user interaction, which was supported by newer programming languages.Lisp, implemented in 1958, was the first functional programming language. Unlike Fortran, it supports recursion and conditional expressions, and it also introduced dynamic memory management on a heap and automatic garbage collection. For the next decades, Lisp dominated artificial intelligence applications. In 1978, another functional language, ML, introduced inferred types and polymorphic parameters.After ALGOL (ALGOrithmic Language) was released in 1958 and 1960, it became the standard in computing literature for describing algorithms. Although its commercial success was limited, most popular imperative languages—including C, Pascal, Ada, C++, Java, and C#—are directly or indirectly descended from ALGOL 60. Among its innovations adopted by later programming languages included greater portability and the first use of context-free, BNF grammar. Simula, the first language to support object-oriented programming (including subtypes, dynamic dispatch, and inheritance), also descends from ALGOL and achieved commercial success. C, another ALGOL descendant, has sustained popularity into the twenty-first century. C allows access to lower-level machine operations more than other contemporary languages. Its power and efficiency, generated in part with flexible pointer operations, comes at the cost of making it more difficult to write correct code.Prolog, designed in 1972, was the first logic programming language, communicating with a computer using formal logic notation. With logic programming, the programmer specifies a desired result and allows the interpreter to decide how to achieve it.

1980s to 2000s
During the 1980s, the invention of the personal computer transformed the roles for which programming languages were used. New languages introduced in the 1980s included C++, a superset of C that can compile C programs but also supports classes and inheritance. Ada and other new languages introduced support for concurrency. The Japanese government invested heavily into the so-called fifth-generation languages that added support for concurrency to logic programming constructs, but these languages were outperformed by other concurrency-supporting languages.Due to the rapid growth of the Internet and the World Wide Web in the 1990s, new programming languages were introduced to support Web pages and networking. Java, based on C++ and designed for increased portability across systems and security, enjoyed large-scale success because these features are essential for many Internet applications. Another development was that of dynamically typed scripting languages—Python, JavaScript, PHP, and Ruby—designed to quickly produce small programs that coordinate existing applications. Due to their integration with HTML, they have also been used for building web pages hosted on servers.

2000s to present
During the 2000s, there was a slowdown in the development of new programming languages that achieved widespread popularity. One innovation was service-oriented programming, designed to exploit distributed systems whose components are connected by a network. Services are similar to objects in object-oriented programming, but run on a separate process. C# and F# cross-pollinated ideas between imperative and functional programming. After 2010, several new languages—Rust, Go, Swift, Zig and Carbon —competed for the performance-critical software for which C had historically been used.Most of the new programming languages uses static typing while a few numbers of new languages use dynamic typing like Ring and Julia.Some of the new programming languages are classified as visual programming languages like Scratch, LabVIEW and PWCT. Also, some of these languages mix between textual and visual programming usage like Ballerina. Also, this trend lead to developing projects that help in developing new VPLs like Blockly by Google.Many game engines like Unreal and Unity added support for visual scripting too.

Elements
All programming languages have some primitive building blocks for the description of data and the processes or transformations applied to them (like the addition of two numbers or the selection of an item from a collection). These primitives are defined by syntactic and semantic rules which describe their structure and meaning respectively.

Syntax
A programming language's surface form is known as its syntax. Most programming languages are purely textual; they use sequences of text including words, numbers, and punctuation, much like written natural languages. On the other hand, some programming languages are more graphical in nature, using visual relationships between symbols to specify a program.
The syntax of a language describes the possible combinations of symbols that form a syntactically correct program. The meaning given to a combination of symbols is handled by semantics (either formal or hard-coded in a reference implementation). Since most languages are textual, this article discusses textual syntax.
The programming language syntax is usually defined using a combination of regular expressions (for lexical structure) and Backus–Naur form (for grammatical structure). Below is a simple grammar, based on Lisp:

This grammar specifies the following:

an expression is either an atom or a list;
an atom is either a number or a symbol;
a number is an unbroken sequence of one or more decimal digits, optionally preceded by a plus or minus sign;
a symbol is a letter followed by zero or more of any characters (excluding whitespace); and
a list is a matched pair of parentheses, with zero or more expressions inside it.The following are examples of well-formed token sequences in this grammar: 12345, () and (a b c232 (1)).
Not all syntactically correct programs are semantically correct. Many syntactically correct programs are nonetheless ill-formed, per the language's rules; and may (depending on the language specification and the soundness of the implementation) result in an error on translation or execution. In some cases, such programs may exhibit undefined behavior. Even when a program is well-defined within a language, it may still have a meaning that is not intended by the person who wrote it.
Using natural language as an example, it may not be possible to assign a meaning to a grammatically correct sentence or the sentence may be false:

""Colorless green ideas sleep furiously."" is grammatically well-formed but has no generally accepted meaning.
""John is a married bachelor."" is grammatically well-formed but expresses a meaning that cannot be true.The following C language fragment is syntactically correct, but performs operations that are not semantically defined (the operation *p >> 4 has no meaning for a value having a complex type and p->im is not defined because the value of p is the null pointer):

If the type declaration on the first line were omitted, the program would trigger an error on the undefined variable p during compilation. However, the program would still be syntactically correct since type declarations provide only semantic information.
The grammar needed to specify a programming language can be classified by its position in the Chomsky hierarchy. The syntax of most programming languages can be specified using a Type-2 grammar, i.e., they are context-free grammars. Some languages, including Perl and Lisp, contain constructs that allow execution during the parsing phase. Languages that have constructs that allow the programmer to alter the behavior of the parser make syntax analysis an undecidable problem, and generally blur the distinction between parsing and execution. In contrast to Lisp's macro system and Perl's BEGIN blocks, which may contain general computations, C macros are merely string replacements and do not require code execution.

Semantics
The term semantics refers to the meaning of languages, as opposed to their form (syntax).

Static semantics
Static semantics defines restrictions on the structure of valid texts that are hard or impossible to express in standard syntactic formalisms. For compiled languages, static semantics essentially include those semantic rules that can be checked at compile time. Examples include checking that every identifier is declared before it is used (in languages that require such declarations) or that the labels on the arms of a case statement are distinct. Many important restrictions of this type, like checking that identifiers are used in the appropriate context (e.g. not adding an integer to a function name), or that subroutine calls have the appropriate number and type of arguments, can be enforced by defining them as rules in a logic called a type system. Other forms of static analyses like data flow analysis may also be part of static semantics. Programming languages such as Java and C# have definite assignment analysis, a form of data flow analysis, as part of their respective static semantics.

Dynamic semantics
Once data has been specified, the machine must be instructed to perform operations on the data. For example, the semantics may define the strategy by which expressions are evaluated to values, or the manner in which control structures conditionally execute statements. The dynamic semantics (also known as execution semantics) of a language defines how and when the various constructs of a language should produce a program behavior. There are many ways of defining execution semantics. Natural language is often used to specify the execution semantics of languages commonly used in practice. A significant amount of academic research goes into formal semantics of programming languages, which allows execution semantics to be specified in a formal manner. Results from this field of research have seen limited application to programming language design and implementation outside academia.

Type system
A type system defines how a programming language classifies values and expressions into types, how it can manipulate those types and how they interact. The goal of a type system is to verify and usually enforce a certain level of correctness in programs written in that language by detecting certain incorrect operations. Any decidable type system involves a trade-off: while it rejects many incorrect programs, it can also prohibit some correct, albeit unusual programs. In order to bypass this downside, a number of languages have type loopholes, usually unchecked casts that may be used by the programmer to explicitly allow a normally disallowed operation between different types. In most typed languages, the type system is used only to type check programs, but a number of languages, usually functional ones, infer types, relieving the programmer from the need to write type annotations. The formal design and study of type systems is known as type theory.

Typed versus untyped languages
A language is typed if the specification of every operation defines types of data to which the operation is applicable. For example, the data represented by ""this text between the quotes"" is a string, and in many programming languages, dividing a number by a string has no meaning and will not be executed. The invalid operation may be detected when the program is compiled (""static"" type checking) and will be rejected by the compiler with a compilation error message, or it may be detected while the program is running (""dynamic"" type checking), resulting in a run-time exception. Many languages allow a function called an exception handler to handle this exception and, for example, always return ""-1"" as the result.
A special case of typed languages is the single-typed languages. These are often scripting or markup languages, such as REXX or SGML, and have only one data type–—most commonly character strings which are used for both symbolic and numeric data.
In contrast, an untyped language, such as most assembly languages, allows any operation to be performed on any data, generally sequences of bits of various lengths. High-level untyped languages include BCPL, Tcl, and some varieties of Forth.
In practice, while few languages are considered typed from the type theory (verifying or rejecting all operations), most modern languages offer a degree of typing. Many production languages provide means to bypass or subvert the type system, trading type safety for finer control over the program's execution (see casting).

Static vis-à-vis dynamic typing
In static typing, all expressions have their types determined before a program executes, typically at compile-time. For example, 1 and (2+2) are integer expressions; they cannot be passed to a function that expects a string or stored in a variable that is defined to hold dates.Statically-typed languages can be either manifestly typed or type-inferred. In the first case, the programmer must explicitly write types at certain textual positions (for example, at variable declarations). In the second case, the compiler infers the types of expressions and declarations based on context. Most mainstream statically-typed languages, such as C++, C#, and Java, are manifestly typed. Complete type inference has traditionally been associated with functional languages such as Haskell and ML. However, many manifestly-typed languages support partial type inference; for example, C++, Java, and C# all infer types in certain limited cases. Additionally, some programming languages allow for some types to be automatically converted to other types; for example, an int can be used where the program expects a float.
Dynamic typing, also called latent typing, determines the type-safety of operations at run time; in other words, types are associated with run-time values rather than textual expressions. As with type-inferred languages, dynamically-typed languages do not require the programmer to write explicit type annotations on expressions. Among other things, this may permit a single variable to refer to values of different types at different points in the program execution. However, type errors cannot be automatically detected until a piece of code is actually executed, potentially making debugging more difficult. Lisp, Smalltalk, Perl, Python, JavaScript, Ruby, Ring and Julia are all examples of dynamically-typed languages.

Weak and strong typing
Weak typing allows a value of one type to be treated as another, for example treating a string as a number. This can occasionally be useful, but it can also allow some kinds of program faults to go undetected at compile time and even at run time.
Strong typing prevents these program faults. An attempt to perform an operation on the wrong type of value raises an error. Strongly-typed languages are often termed type-safe or safe.
An alternative definition for ""weakly typed"" refers to languages, such as Perl, Ring and JavaScript, which permit a large number of implicit type conversions. In JavaScript, for example, the expression 2 * x implicitly converts x to a number, and this conversion succeeds even if x is null, undefined, an Array, or a string of letters. Such implicit conversions are often useful, but they can mask programming errors. Strong and static are now generally considered orthogonal concepts, but usage in the literature differs. Some use the term strongly typed to mean strongly, statically typed, or, even more confusingly, to mean simply statically typed. Thus C has been called both strongly typed and weakly, statically typed.It may seem odd to some professional programmers that C could be ""weakly, statically typed"". However, the use of the generic pointer, the void* pointer, does allow casting pointers to other pointers without needing to do an explicit cast. This is extremely similar to somehow casting an array of bytes to any kind of datatype in C without using an explicit cast, such as (int) or (char).

Standard library and run-time system
Most programming languages have an associated core library (sometimes known as the ""standard library"", especially if it is included as part of the published language standard), which is conventionally made available by all implementations of the language. Core libraries typically include definitions for commonly used algorithms, data structures, and mechanisms for input and output.
The line between a language and its core library differs from language to language. In some cases, the language designers may treat the library as a separate entity from the language. However, a language's core library is often treated as part of the language by its users, and some language specifications even require that this library be made available in all implementations. Indeed, some languages are designed so that the meanings of certain syntactic constructs cannot even be described without referring to the core library. For example, in Java, a string literal is defined as an instance of the java.lang.String class; similarly, in Smalltalk, an anonymous function expression (a ""block"") constructs an instance of the library's BlockContext class. Conversely, Scheme contains multiple coherent subsets that suffice to construct the rest of the language as library macros, and so the language designers do not even bother to say which portions of the language must be implemented as language constructs, and which must be implemented as parts of a library.

Concurrency
In computing, multiple instructions can be executed simultaneously. Many programming languages support instruction-level and subprogram-level concurrency. By the twenty-first century, additional processing power on computers was increasingly coming from the use of additional processors, which requires programmers to design software that makes use of multiple processors simultaneously to achieve improved performance. Interpreted languages such as Python and Ruby do not support the concurrent use of multiple processors. Other programming languages do support managing data shared between different threads by controlling the order of execution of key instructions via the use of semaphores, controlling access to shared data via monitor, or enabling message passing between threads.

Exception handling
Many programming languages include exception handlers, a section of code triggered by runtime errors that can deal with them in two main ways:
Termination: shutting down and handing over control to the operating system. This option is considered the simplest.
Resumption: resuming the program near where the exception occurred. This can trigger a repeat of the exception, unless the exception handler is able to modify values to prevent the exception from reoccurring.Some programming languages support dedicating a block of code to run regardless of whether an exception occurs before the code is reached; this is called finalization.There is a tradeoff between increased ability to handle exceptions and reduced performance. For example, even though array index errors are common C does not check them for performance reasons.  Although programmers can write code to catch user-defined exceptions, this can clutter a program. Standard libraries in some languages, such as C, use their return values to indicate an exception. Some languages and their compilers have the option of turning on and off error handling capability, either temporarily or permanently.

Design and implementation
Programming languages share properties with natural languages related to their purpose as vehicles for communication, having a syntactic form separate from its semantics, and showing language families of related languages branching one from another. But as artificial constructs, they also differ in fundamental ways from languages that have evolved through usage. A significant difference is that a programming language can be fully described and studied in its entirety since it has a precise and finite definition. By contrast, natural languages have changing meanings given by their users in different communities. While constructed languages are also artificial languages designed from the ground up with a specific purpose, they lack the precise and complete semantic definition that a programming language has.
Many programming languages have been designed from scratch, altered to meet new needs, and combined with other languages. Many have eventually fallen into disuse. Although there have been attempts to design one ""universal"" programming language that serves all purposes, all of them have failed to be generally accepted as filling this role. The need for diverse programming languages arises from the diversity of contexts in which languages are used:

Programs range from tiny scripts written by individual hobbyists to huge systems written by hundreds of programmers.
Programmers range in expertise from novices who need simplicity above all else to experts who may be comfortable with considerable complexity.
Programs must balance speed, size, and simplicity on systems ranging from microcontrollers to supercomputers.
Programs may be written once and not change for generations, or they may undergo continual modification.
Programmers may simply differ in their tastes: they may be accustomed to discussing problems and expressing them in a particular language.One common trend in the development of programming languages has been to add more ability to solve problems using a higher level of abstraction. The earliest programming languages were tied very closely to the underlying hardware of the computer. As new programming languages have developed, features have been added that let programmers express ideas that are more remote from simple translation into underlying hardware instructions. Because programmers are less tied to the complexity of the computer, their programs can do more computing with less effort from the programmer. This lets them write more functionality per time unit.
Natural-language programming has been proposed as a way to eliminate the need for a specialized language for programming. However, this goal remains distant and its benefits are open to debate. Edsger W. Dijkstra took the position that the use of a formal language is essential to prevent the introduction of meaningless constructs, and dismissed natural-language programming as ""foolish"". Alan Perlis was similarly dismissive of the idea. Hybrid approaches have been taken in Structured English and SQL.
A language's designers and users must construct a number of artifacts that govern and enable the practice of programming. The most important of these artifacts are the language specification and implementation.

Specification
The specification of a programming language is an artifact that the language users and the implementors can use to agree upon whether a piece of source code is a valid program in that language, and if so what its behavior shall be.
A programming language specification can take several forms, including the following:

An explicit definition of the syntax, static semantics, and execution semantics of the language. While syntax is commonly specified using a formal grammar, semantic definitions may be written in natural language (e.g., as in the C language), or a formal semantics (e.g., as in Standard ML and Scheme specifications).
A description of the behavior of a translator for the language (e.g., the C++ and Fortran specifications). The syntax and semantics of the language have to be inferred from this description, which may be written in natural or formal language.
A reference or model implementation, sometimes written in the language being specified (e.g., Prolog or ANSI REXX). The syntax and semantics of the language are explicit in the behavior of the reference implementation.

Implementation
An implementation of a programming language provides a way to write programs in that language and execute them on one or more configurations of hardware and software. There are, broadly, two approaches to programming language implementation: compilation and interpretation. It is generally possible to implement a language using either technique.
The output of a compiler may be executed by hardware or a program called an interpreter. In some implementations that make use of the interpreter approach, there is no distinct boundary between compiling and interpreting. For instance, some implementations of BASIC compile and then execute the source one line at a time.
Programs that are executed directly on the hardware usually run much faster than those that are interpreted in software.One technique for improving the performance of interpreted programs is just-in-time compilation. Here the virtual machine, just before execution, translates the blocks of bytecode which are going to be used to machine code, for direct execution on the hardware.

Proprietary languages
Although most of the most commonly used programming languages have fully open specifications and implementations, many programming languages exist only as proprietary programming languages with the implementation available only from a single vendor, which may claim that such a proprietary language is their intellectual property. Proprietary programming languages are commonly domain-specific languages or internal scripting languages for a single product; some proprietary languages are used only internally within a vendor, while others are available to external users.Some programming languages exist on the border between proprietary and open; for example, Oracle Corporation asserts proprietary rights to some aspects of the Java programming language, and Microsoft's C# programming language, which has open implementations of most parts of the system, also has Common Language Runtime (CLR) as a closed environment.Many proprietary languages are widely used, in spite of their proprietary nature; examples include MATLAB, VBScript, and Wolfram Language. Some languages may make the transition from closed to open; for example, Erlang was originally Ericsson's internal programming language.Open source programming languages are particularly helpful for open science applications, enhancing the capacity for replication and code sharing.

Use
Thousands of different programming languages have been created, mainly in the computing field.
Individual software projects commonly use five programming languages or more.Programming languages differ from most other forms of human expression in that they require a greater degree of precision and completeness. When using a natural language to communicate with other people, human authors and speakers can be ambiguous and make small errors, and still expect their intent to be understood. However, figuratively speaking, computers ""do exactly what they are told to do"", and cannot ""understand"" what code the programmer intended to write. The combination of the language definition, a program, and the program's inputs must fully specify the external behavior that occurs when the program is executed, within the domain of control of that program. On the other hand, ideas about an algorithm can be communicated to humans without the precision required for execution by using pseudocode, which interleaves natural language with code written in a programming language.
A programming language provides a structured mechanism for defining pieces of data, and the operations or transformations that may be carried out automatically on that data. A programmer uses the abstractions present in the language to represent the concepts involved in a computation. These concepts are represented as a collection of the simplest elements available (called primitives). Programming is the process by which programmers combine these primitives to compose new programs, or adapt existing ones to new uses or a changing environment.
Programs for a computer might be executed in a batch process without human interaction, or a user might type commands in an interactive session of an interpreter. In this case the ""commands"" are simply programs, whose execution is chained together. When a language can run its commands through an interpreter (such as a Unix shell or other command-line interface), without compiling, it is called a scripting language.

Measuring language usage
Determining which is the most widely used programming language is difficult since the definition of usage varies by context. One language may occupy the greater number of programmer hours, a different one has more lines of code, and a third may consume the most CPU time. Some languages are very popular for particular kinds of applications. For example, COBOL is still strong in the corporate data center, often on large mainframes; Fortran in scientific and engineering applications; Ada in aerospace, transportation, military, real-time, and embedded applications; and C in embedded applications and operating systems. Other languages are regularly used to write many different kinds of applications.
Various methods of measuring language popularity, each subject to a different bias over what is measured, have been proposed:

counting the number of job advertisements that mention the language
the number of books sold that teach or describe the language
estimates of the number of existing lines of code written in the language –  which may underestimate languages not often found in public searches
counts of language references (i.e., to the name of the language) found using a web search engine.Combining and averaging information from various internet sites, stackify.com reported the ten most popular programming languages (in descending order by overall popularity): Java, C, C++, Python, C#, JavaScript, VB .NET, R, PHP, and MATLAB.As of February 2024, the top five programming languages as measured by TIOBE index are Python, C, C++, Java and C#. TIOBE provide a list of top 100 programming languages according to popularity and update this list every month.

Dialects, flavors and implementations
A dialect of a programming language or a data exchange language is a (relatively small) variation or extension of the language that does not change its intrinsic nature. With languages such as Scheme and Forth, standards may be considered insufficient, inadequate, or illegitimate by implementors, so often they will deviate from the standard, making a new dialect. In other cases, a dialect is created for use in a domain-specific language, often a subset. In the Lisp world, most languages that use basic S-expression syntax and Lisp-like semantics are considered Lisp dialects, although they vary wildly as do, say, Racket and Clojure. As it is common for one language to have several dialects, it can become quite difficult for an inexperienced programmer to find the right documentation. The BASIC language has many dialects.

Classifications
Programming languages are often placed into four main categories: imperative, functional, logic, and object oriented.
Imperative languages are designed to implement an algorithm in a specified order; they include visual programming languages such as .NET for generating graphical user interfaces. Scripting languages, which are partly or fully interpreted rather than compiled, are sometimes considered a separate category but meet the definition of imperative languages.
Functional programming languages work by successively applying functions to the given parameters. Although appreciated by many researchers for their simplicity and elegance, problems with efficiency have prevented them from being widely adopted.
Logic languages are designed so that the software, rather than the programmer, decides what order in which the instructions are executed.
Object-oriented programming—whose characteristic features are data abstraction, inheritance, and dynamic dispatch—is supported by most popular imperative languages and some functional languages.Although markup languages are not programming languages, some have extensions that support limited programming. Additionally, there are special-purpose languages that are not easily compared to other programming languages.

See also
References


== Further reading ==",23015,https://en.wikipedia.org/wiki/Programming_language
ABAP,"ABAP (Advanced Business Application Programming, originally Allgemeiner Berichts-Aufbereitungs-Prozessor, German for ""general report preparation processor"") is a high-level programming language created by the German software company SAP SE. It is currently positioned, alongside Java, as the language for programming the SAP NetWeaver Application Server, which is part of the SAP NetWeaver platform for building business applications.","ABAP (Advanced Business Application Programming, originally Allgemeiner Berichts-Aufbereitungs-Prozessor, German for ""general report preparation processor"") is a high-level programming language created by the German software company SAP SE. It is currently positioned, alongside Java, as the language for programming the SAP NetWeaver Application Server, which is part of the SAP NetWeaver platform for building business applications.

Introduction
ABAP is one of the many application-specific fourth-generation languages (4GLs) first developed in the 1980s. It was originally the report language for SAP R/2, a platform that enabled large corporations to build mainframe business applications for materials management and financial and management accounting.
ABAP used to be an abbreviation of Allgemeiner Berichts-Aufbereitungs-Prozessor, German for ""generic report preparation processor"", but was later renamed to the English Advanced Business Application Programming. ABAP was one of the first languages to include the concept of Logical Databases (LDBs), which provides a high level of abstraction from the basic database level(s), which supports every platform, language and units.
The ABAP language was originally used by developers to develop the SAP R/3 platform. It was also intended to be used by SAP customers to enhance SAP applications – customers can develop custom reports and interfaces with ABAP programming. The language was geared towards more technical customers with programming experience.
ABAP remains as the language for creating programs for the client–server R/3 system, which SAP first released in 1992. As computer hardware evolved through the 1990s, more and more of SAP's applications and systems were written in ABAP. By 2001, all but the most basic functions were written in ABAP. In 1999, SAP released an object-oriented extension to ABAP called ABAP Objects, along with R/3 release 4.6.
SAP's current development platform NetWeaver supports both ABAP and Java.
ABAP has an abstraction between the business applications, the operating system and database. This ensures that applications do not depend directly upon a specific server or database platform and can easily be ported from one platform to another.
SAP Netweaver currently runs on UNIX (AIX, HP-UX, Solaris, Linux), Microsoft Windows, i5/OS on IBM System i (formerly iSeries, AS/400), and z/OS on IBM System z (formerly zSeries, S/390). Supported databases are HANA, SAP ASE (formerly Sybase), IBM Db2, Informix, MaxDB, Oracle, and Microsoft SQL Server (support for Informix was discontinued in SAP Basis release 7.00).

ABAP Runtime Environment
All ABAP programs reside inside the SAP database. They are not stored in separate external files like Java or C++ programs. In the database all ABAP code exists in two forms: source code, which can be viewed and edited with the ABAP Workbench tools; and generated code, a binary representation somewhat comparable with Java bytecode. ABAP programs execute under the control of the runtime system, which is part of the SAP kernel. The runtime system is responsible for processing ABAP statements, controlling the flow logic of screens and responding to events (such as a user clicking on a screen button); in this respect it can be seen as a Virtual Machine comparable with the Java VM. A key component of the ABAP runtime system is the Database Interface, which turns database-independent ABAP statements (""Open SQL"") into statements understood by the underlying DBMS (""Native SQL""). The database interface handles all the communication with the relational database on behalf of ABAP programs; It also contains extra features such as buffering of tables and frequently accessed data in the local memory of the application server.

SAP Systems and Landscapes
All SAP data exists and all SAP software runs in the context of a SAP system. A system consists of a central relational database and one or more application servers (""instances"") accessing the data and programs in this database. A SAP system contains at least one instance but may contain more, mostly for reasons of sizing and performance. In a system with multiple instances, load balancing mechanisms ensure that the load is spread evenly over the available application servers.
Installations of the Web Application Server (landscapes) typically consist of three systems: one for development; one for testing and quality assurance; and one for production. The landscape may contain more systems (e.g., separate systems for unit testing and pre-production testing) or it may contain fewer (e.g., only development and production, without separate QA); nevertheless three is the most common configuration. ABAP programs are created and undergo first testing in the development system. Afterwards they are distributed to the other systems in the landscape. These actions take place under control of the Change and Transport System (CTS), which is responsible for concurrency control (e.g., preventing two developers from changing the same code at the same time), version management, and deployment of programs on the QA and production systems.
The Web Application Server consists of three layers: the database layer; the application layer; and the presentation layer. These layers may run on the same or on different physical machines. The database layer contains the relational database and the database software. The 'application layer' knowledge contains the instance or instances of the system. All application processes, including the business transactions and the ABAP development, run on the application layer. The presentation layer handles the interaction with users of the system. Online access to ABAP application servers can go via a proprietary graphical interface, which is called ""SAP GUI"", or via a Web browser.

Software Layers
ABAP software is deployed in software components.
Examples for these are:

SP_BASIS is the technical base layer which is required in every ABAP system.
SAP_ABA contains functionalities which is required for all kinds of business applications, like business partner and address management.
SAP_UI provides the functionality to create SAP UI5 applications.
BBPCRM is an example for a business application, in this case the CRM application
SAP ABAP is an ERP programming language.

Transactions
A transaction in SAP terminology is the execution of a program. The normal way of executing ABAP code in the SAP system is by entering a transaction code (for instance, VA01 is the transaction code for ""Create Sales Order""). The common T-codes used by ABAP developer are SE38, SE09, SE10, SE24, SE11, SE16N, SE80, SE37, ST22  e.t.c . Transactions can be called via system-defined or user-specific, role-based menus. They can also be started by entering the transaction code directly into a command field, which is present in every SAP screen. Transactions can also be invoked programmatically by means of the ABAP statements CALL TRANSACTION and LEAVE TO TRANSACTION.
The general notion of a transaction is called a Logical Unit of Work (LUW) in SAP terminology; the short form of transaction code is T-code.

Types of ABAP programs
As in other programming languages, an ABAP program is either an executable unit or a library, which provides reusable code to other programs and is not independently executable.
ABAP distinguishes two types of executable programs:

Reports
Module poolsReports follow a relatively simple programming model whereby a user optionally enters a set of parameters (e.g., a selection over a subSET of data) and the program then uses the input parameters to produce a report in the form of an interactive list. The term ""report"" can be somewhat misleading in that reports can also be designed to modify data; the reason why these programs are called reports is the ""list-oriented"" nature of the output they produce.
Module pools define more complex patterns of user interaction using a collection of screens. The term “screen” refers to the actual, physical image that the user sees. Each screen also has a ""flow logic"", which refers to the ABAP code implicitly invoked by the screens, which is divided into a ""PBO"" (Process Before Output) and ""PAI"" (Process After Input) section. In SAP documentation the term “dynpro” (dynamic program) refers to the combination of the screen and its flow logic.
The non-executable program types are:

INCLUDE modules - These get included at generation time into the calling unit; it is often used to subdivide large programs.
Subroutine pools - These contain ABAP subroutines (blocks of code enclosed by FORM/ENDFORM statements and invoked with PERFORM).
Function groups - These are libraries of self-contained function modules (enclosed by FUNCTION/ENDFUNCTION and invoked with CALL FUNCTION).
Object classes - These are similar to Java classes and interfaces; the first define a set of methods and attributes, the second contain ""empty"" method definitions, for which any class implementing the interface must provide explicit code.
Interfaces - Same as object classes
Type pools - These define collections of data types and constants.ABAP programs are composed of individual sentences (statements). The first word in a statement is called an ABAP keyword. Each statement ends with a period. Words must always be separated by at least one space. Statements can be indented as you wish. With keywords, additions and operands, the ABAP runtime system does not differentiate between upper and lowercase.
Statements can extend beyond one line. You can have several statements in a single line (though this is not recommended). Lines that begin with asterisk * in the first column are recognized as comment lines by the ABAP runtime system and are ignored. Double quotations marks ("") indicate that the remainder of a line is a comment.

Development environment
There are two possible ways to develop in ABAP. The availability depends on the release of the ABAP system.

ABAP Workbench
The ABAP Workbench is part of the ABAP system and is accessed via SAP GUI. It contains different tools for editing programs. The most important of these are (transaction codes are shown in parentheses):

ABAP Editor for writing and editing reports, module pools, includes and subroutine pools (SE38)
ABAP Dictionary for processing database table definitions and retrieving global types (SE11)
Menu Painter for designing the user interface (menu bar, standard toolbar, application toolbar, function key assignment) (SE41)
Screen Painter for designing screens and flow logic (SE51)
Function Builder for function modules (SE37)
Class Builder for ABAP Objects classes and interfaces (SE24)The Object Navigator (transaction SE80) provides a single integrated interface into these various tools.

ABAP Development Tools
The ABAP Development Tools (ADT), formally known as ""ABAP in Eclipse"", is a set of plugins for the Eclipse IDE to develop ABAP objects.In this scenario, the ABAP developer installs the required tools on his computer and works locally, whereas a continuous synchronization with the backend is performed.

ABAP Dictionary
The ABAP Dictionary contains all metadata about the data in the SAP system. It is closely linked with the ABAP Workbench in that any reference to data (e.g., a table, a view, or a data type) will be obtained from the dictionary. Developers use the ABAP Dictionary transactions (directly or through the SE80 Object Navigator inside the ABAP Workbench) to display and maintain this metadata.
When a dictionary object is changed, a program that references the changed object will automatically reference the new version the next time the program runs. Because ABAP is interpreted, it is not necessary to recompile programs that reference changed dictionary objects.
A brief description of the most important types of dictionary objects follows:

Tables are data containers that exist in the underlying relational database. In the majority of cases there is a 1-to-1 relationship between the definition of a table in the ABAP Dictionary and the definition of that same table in the database (same name, same columns). These tables are known as ""transparent"". There are two types of non-transparent tables: ""pooled"" tables exist as independent entities in the ABAP Dictionary but they are grouped together in large physical tables (""pools"") at the database level. Pooled tables are often small tables holding for example configuration data. ""Clustered"" tables are physically grouped in ""clusters"" based on their primary keys; for instance, assume that a clustered table H contains ""header"" data about sales invoices, whereas another clustered table D holds the invoice line items. Each row of H would then be physically grouped with the related rows from D inside a ""cluster table"" in the database. This type of clustering, which is designed to improve performance, also exists as native functionality in some, though not all, relational database systems.
Indexes provide accelerated access to table data for often used selection conditions. Every SAP table has a ""primary index"", which is created implicitly along with the table and is used to enforce primary key uniqueness. Additional indexes (unique or non-unique) may be defined; these are called ""secondary indexes"".
Views have the same purpose as in the underlying database: they define subsets of columns (and/or rows) from one or - using a join condition - several tables. Since views are virtual tables (they refer to data in other tables) they do not take a substantial amount of space.
Structures are complex data types consisting of multiple fields (comparable to struct in C/C++).
Data elements provide the semantic content for a table or structure field. For example, dozens of tables and structures might contain a field giving the price (of a finished product, raw material, resource, ...). All these fields could have the same data element ""PRICE"".
Domains define the structural characteristics of a data element. For example, the data element PRICE could have an assigned domain that defines the price as a numeric field with two decimals. Domains can also carry semantic content in providing a list of possible values. For example, a domain ""BOOLEAN"" could define a field of type ""character"" with length 1 and case-insensitive, but would also restrict the possible values to ""T"" (true) or ""F"" (false).
Search helps (successors to the now obsolete ""matchcodes"") provide advanced search strategies when a user wants to see the possible values for a data field. The ABAP runtime provides implicit assistance (by listing all values for the field, e.g. all existing customer numbers) but search helps can be used to refine this functionality, e.g. by providing customer searches by geographical location, credit rating, etc.
Lock objects implement application-level locking when changing data.

ABAP syntax
This brief description of the ABAP syntax begins with the ubiquitous ""Hello.

Hello world
This example contains two statements: REPORT and WRITE. The program displays a list on the screen. In this case, the list consists of the single line ""Hello, World!"". The REPORT statement indicates that this program is a report. This program could be a module pool after replacing the REPORT statement with PROGRAM.

Chained statements
Consecutive statements with an identical first (leftmost) part can be combined into a ""chained"" statement using the chain operator :. The common part of the statements is written to the left of the colon, the differing parts are written to the right of the colon and separated by commas. The colon operator is attached directly to the preceding token, without a space (the same applies to the commas in the token list on, as can be seen in the examples below).
Chaining is often used in WRITE statements. WRITE accepts just one argument, so if for instance you wanted to display three fields from a structure called FLIGHTINFO, you would have to code:

Chaining the statements results in a more readable and more intuitive form:

In a chain statement, the first part (before the colon) is not limited to the statement name alone. The entire common part of the consecutive statements can be placed before the colon. Example:

could be rewritten in chained form as:

Comments
ABAP has 2 ways of defining text as a comment:

An asterisk (*) in the leftmost column of a line makes the entire line a comment
A double quotation mark ("") anywhere on a line makes the rest of that line a commentExample:

Spaces
Code in ABAP is whitespace-sensitive.

assigns to variable x the substring of the variable a, starting from b with the length defined by the variable c.

assigns to variable x the sum of the variable a and the result of the call to method b with the parameter c.

ABAP statements
In contrast with languages like C/C++ or Java, which define a limited set of language-specific statements and provide most functionality via libraries, ABAP contains an extensive amount of built-in statements. These statements traditionally used sentence-like structures and avoided symbols, making ABAP programs relatively verbose. However, in more recent versions of the ABAP language, a terser style is possible.An example of statement based syntax (whose syntax originates in COBOL) versus expression-based syntax (as in C/Java):

Data types and variables
ABAP provides a set of built-in data types. In addition, every structure, table, view or data element defined in the ABAP Dictionary can be used to type a variable. Also, object classes and interfaces can be used as types.
The built-in data types are:

Date variables or constants (type D) contain the number of days since January 1, 1 AD. Time variables or constants (type T) contain the number of seconds since midnight. A special characteristic of both types is that they can be accessed both as integers and as character strings (with internal format ""YYYYMMDD"" for dates and ""hhmmss"" for times), which can be used for date and time handling. For example, the code snippet below calculates the last day of the previous month (note: SY-DATUM is a system-defined variable containing the current date):

All ABAP variables have to be explicitly declared in order to be used. They can be declared either with individual statements and explicit typing or, since ABAP 7.40, inline with inferred typing.

Explicitly typed declaration
Normally all declarations are placed at the top of the code module (program, subroutine, function) before the first executable statement; this placement is a convention and not an enforced syntax rule.  The declaration consists of the name, type, length (where applicable), additional modifiers (e.g. the number of implied decimals for a packed decimal field) and optionally an initial value:

Notice the use of the colon to chain together consecutive DATA statements.

Inline declaration
Since ABAP 7.40, variables can be declared inline with the following syntax:

For this type of declaration it must be possible to infer the type statically, e.g. by method signature or database table structure.
This syntax is also possible in OpenSQL statements:

ABAP Objects
The ABAP language supports object-oriented programming, through a feature known as ""ABAP Objects"". This helps to simplify applications and make them more controllable.
ABAP Objects is fully compatible with the existing language, so one can use existing statements and modularization units in programs that use ABAP Objects, and can also use ABAP Objects in existing ABAP programs.  Syntax checking is stronger in ABAP Objects programs, and some syntactical forms (usually older ones) of certain statements are not permitted.
Objects form a capsule which combines the character to the respective behavior. Objects should enable programmers to map a real problem and its proposed software solution on a one-to-one basis. Typical objects in a business environment are, for example, ‘Customer’, ‘Order’, or ‘Invoice’. From Release 3.1 onwards, the Business Object Repository (BOR) of SAP Web Application Server ABAP has contained examples of such objects. The BOR object model will be integrated into ABAP Objects in the next Release by migrating the BOR object types to the ABAP class library.
A comprehensive introduction to object orientation as a whole would go far beyond the limits of this introduction to ABAP Objects. This documentation introduces a selection of terms that are used universally in object orientation and also occur in ABAP Objects. In subsequent sections, it goes on to discuss in more detail how these terms are used in ABAP Objects. The end of this section contains a list of further reading, with a selection of titles about object orientation.

Objects are instances of classes. They contain data and provide services. The data forms the attributes of the object. The services are known as methods (also known as operations or functions). Typically, methods operate on private data (the attributes, or state of the object), which is only visible to the methods of the object. Thus the attributes of an object cannot be changed directly by the user, but only by the methods of the object. This guarantees the internal consistency of the object.
Classes describe objects. From a technical point of view, objects are runtime instances of a class. In theory, any number of objects based on a single class may be created. Each instance (object) of a class has a unique identity and its own set of values for its attributes.
Object References are unique addresses that may be used to identify and point to objects in a program. Object references allow access to the attributes and methods of an object.In object-oriented programming, objects usually have the following properties:

Encapsulation - Objects restrict the visibility of their resources (attributes and methods) to other users. Every object has an interface, which determines how other objects can interact with it. The implementation of the object is encapsulated, that is, invisible outside the object itself.
Inheritance - An existing class may be used to derive a new class. Derived classes inherit the data and methods of the superclass. However, they can overwrite existing methods, and also add new ones.
Polymorphism - Identical (identically-named) methods behave differently in different classes. In ABAP Objects, polymorphism is implemented by redefining methods during inheritance and by using constructs called interfaces.

CDS Views
The ABAP Core Data Services (ABAP CDS) are the implementation of the general CDS concept for AS ABAP. ABAP CDS makes it possible to define semantic data models on the central database of the application server. On AS ABAP, these models can be defined independently of the database system. The entities of these models provide enhanced access functions when compared with existing database tables and views defined in ABAP Dictionary, making it possible to optimize Open SQL-based applications. This is particularly clear when an AS ABAP uses a SAP HANA database, since its in-memory characteristics can be implemented in an optimum manner.
The data models are defined using the data definition language (DDL) and data control language (DCL) provided in the ABAP CDS in the ABAP CDS syntax. The objects defined using these languages are integrated into ABAP Dictionary and managed here too.
CDS source code can only be programmed in the Eclipse-based ABAP Development Tools (ADT). The Data Definition Language (DDL) and the Data Control Language (DCL) use different editors.

Features
Internal tables in ABAP
Internal tables are an important feature of the ABAP language. An internal table is defined similarly to a vector of structs in C++ or a vector of objects in Java. The main difference with these languages is that ABAP provides a collection of statements to easily access and manipulate the contents of internal tables. Note that ABAP does not support arrays; the only way to define a multi-element data object is to use an internal table.Internal tables are a way to store variable data sets of a fixed structure in the working memory of ABAP, and provides the functionality of dynamic arrays. The data is stored on a row-by-row basis, where each row has the same structure.
Internal tables are preferably used to store and format the content of database tables from within a program. Furthermore, internal tables in connection with structures are an important means of defining complex data structures in an ABAP program.
The following example defines an internal table with two fields with the format of database table VBRK.

History
The following list only gives a rough overview about some important milestones in the history of the language ABAP. For more details, see ABAP - Release-Specific Changes.

See also
ERP software
Secure Network Communications
SAP Logon Ticket
Single sign-on

References
External links
ABAP — Keyword Documentation
SAP Help Portal
ABAP Development discussions, blogs, documents and videos on the SAP Community Network (SCN)",271832,https://en.wikipedia.org/wiki/ABAP
Ada (programming language),"Ada is a structured, statically typed, imperative, and object-oriented high-level programming language, inspired by Pascal and other languages. It has built-in language support for design by contract (DbC), extremely strong typing, explicit concurrency, tasks, synchronous message passing, protected objects, and non-determinism. Ada improves code safety and maintainability by using the compiler to find errors in favor of runtime errors. Ada is an international technical standard, jointly defined by the International Organization for Standardization (ISO), and the International Electrotechnical Commission (IEC). As of May 2023, the standard, called Ada 2022 informally, is ISO/IEC 8652:2023.Ada was originally designed by a team led by French computer scientist Jean Ichbiah of Honeywell under contract to the United States Department of Defense (DoD) from 1977 to 1983 to supersede over 450 programming languages used by the DoD at that time. Ada was named after Ada Lovelace (1815–1852), who has been credited as the first computer programmer.","Ada is a structured, statically typed, imperative, and object-oriented high-level programming language, inspired by Pascal and other languages. It has built-in language support for design by contract (DbC), extremely strong typing, explicit concurrency, tasks, synchronous message passing, protected objects, and non-determinism. Ada improves code safety and maintainability by using the compiler to find errors in favor of runtime errors. Ada is an international technical standard, jointly defined by the International Organization for Standardization (ISO), and the International Electrotechnical Commission (IEC). As of May 2023, the standard, called Ada 2022 informally, is ISO/IEC 8652:2023.Ada was originally designed by a team led by French computer scientist Jean Ichbiah of Honeywell under contract to the United States Department of Defense (DoD) from 1977 to 1983 to supersede over 450 programming languages used by the DoD at that time. Ada was named after Ada Lovelace (1815–1852), who has been credited as the first computer programmer.

Features
Ada was originally designed for embedded and real-time systems. The Ada 95 revision, designed by S. Tucker Taft of Intermetrics between 1992 and 1995, improved support for systems, numerical, financial, and object-oriented programming (OOP).
Features of Ada include: strong typing, modular programming mechanisms (packages), run-time checking, parallel processing (tasks, synchronous message passing, protected objects, and nondeterministic select statements), exception handling, and generics. Ada 95 added support for object-oriented programming, including dynamic dispatch.
The syntax of Ada minimizes choices of ways to perform basic operations, and prefers English keywords (such as ""or else"" and ""and then"") to symbols (such as ""||"" and ""&&""). Ada uses the basic arithmetical operators ""+"", ""-"", ""*"", and ""/"", but avoids using other symbols. Code blocks are delimited by words such as ""declare"", ""begin"", and ""end"", where the ""end"" (in most cases) is followed by the identifier of the block it closes (e.g., if ... end if, loop ... end loop). In the case of conditional blocks this avoids a dangling else that could pair with the wrong nested if-expression in other languages like C or Java.
Ada is designed for developing very large software systems. Ada packages can be compiled separately. Ada package specifications (the package interface) can also be compiled separately without the implementation to check for consistency. This makes it possible to detect problems early during the design phase, before implementation starts.
A large number of compile-time checks are supported to help avoid bugs that would not be detectable until run-time in some other languages or would require explicit checks to be added to the source code.  For example, the syntax requires explicitly named closing of blocks to prevent errors due to mismatched end tokens. The adherence to strong typing allows detecting many common software errors (wrong parameters, range violations, invalid references, mismatched types, etc.) either during compile-time, or otherwise during run-time. As concurrency is part of the language specification, the compiler can in some cases detect potential deadlocks. Compilers also commonly check for misspelled identifiers, visibility of packages, redundant declarations, etc. and can provide warnings and useful suggestions on how to fix the error.
Ada also supports run-time checks to protect against access to unallocated memory, buffer overflow errors, range violations, off-by-one errors, array access errors, and other detectable bugs. These checks can be disabled in the interest of runtime efficiency, but can often be compiled efficiently. It also includes facilities to help program verification. For these reasons, Ada is sometimes used in critical systems, where any anomaly might lead to very serious consequences, e.g., accidental death, injury or severe financial loss. Examples of systems where Ada is used include avionics, air traffic control, railways, banking, military and space technology.Ada's dynamic memory management is high-level and type-safe. Ada has no generic or untyped pointers; nor does it implicitly declare any pointer type. Instead, all dynamic memory allocation and deallocation must occur via explicitly declared access types. Each access type has an associated storage pool that handles the low-level details of memory management; the programmer can either use the default storage pool or define new ones (this is particularly relevant for Non-Uniform Memory Access). It is even possible to declare several different access types that all designate the same type but use different storage pools. Also, the language provides for accessibility checks, both at compile time and at run time, that ensures that an access value cannot outlive the type of the object it points to.Though the semantics of the language allow automatic garbage collection of inaccessible objects, most implementations do not support it by default, as it would cause unpredictable behaviour in real-time systems.  Ada does support a limited form of region-based memory management; also, creative use of storage pools can provide for a limited form of automatic garbage collection, since destroying a storage pool also destroys all the objects in the pool.
A double-dash (""--""), resembling an em dash, denotes comment text.  Comments stop at end of line; there is intentionally no way to make a comment span multiple lines, to prevent unclosed comments from accidentally voiding whole sections of source code.  Disabling a whole block of code therefore requires the prefixing of each line (or column) individually with ""--"". While this clearly denotes disabled code by creating a column of repeated ""--"" down the page, it also renders the experimental dis/re-enablement of large blocks a more drawn-out process in editors without block commenting support.
The semicolon ("";"") is a statement terminator, and the null or no-operation statement is null;. A single ; without a statement to terminate is not allowed.
Unlike most ISO standards, the Ada language definition (known as the Ada Reference Manual or ARM, or sometimes the Language Reference Manual or LRM) is free content. Thus, it is a common reference for Ada programmers, not only programmers implementing Ada compilers. Apart from the reference manual, there is also an extensive rationale document which explains the language design and the use of various language constructs. This document is also widely used by programmers. When the language was revised, a new rationale document was written.
One notable free software tool that is used by many Ada programmers to aid them in writing Ada source code is the GNAT Programming Studio, and GNAT which is part of the GNU Compiler Collection.

History
In the 1970s the US Department of Defense (DoD) became concerned by the number of different programming languages being used for its embedded computer system projects, many of which were obsolete or hardware-dependent, and none of which supported safe modular programming. In 1975, a working group, the High Order Language Working Group (HOLWG), was formed with the intent to reduce this number by finding or creating a programming language generally suitable for the department's and the UK Ministry of Defence's requirements. After many iterations beginning with an original straw-man proposal the eventual programming language was named Ada. The total number of high-level programming languages in use for such projects fell from over 450 in 1983 to 37 by 1996.
HOLWG crafted the Steelman language requirements, a series of documents stating the requirements they felt a programming language should satisfy. Many existing languages were formally reviewed, but the team concluded in 1977 that no existing language met the specifications.

Requests for proposals for a new programming language were issued and four contractors were hired to develop their proposals under the names of Red (Intermetrics led by Benjamin Brosgol), Green (Honeywell, led by Jean Ichbiah), Blue (SofTech, led by John Goodenough) and Yellow (SRI International, led by Jay Spitzen). In April 1978, after public scrutiny, the Red and Green proposals passed to the next phase. In May 1979, the Green proposal, designed by Jean Ichbiah at Honeywell, was chosen and given the name Ada—after Augusta Ada King, Countess of Lovelace, usually known as Ada Lovelace. This proposal was influenced by the language LIS that Ichbiah and his group had developed in the 1970s. The preliminary Ada reference manual was published in ACM SIGPLAN Notices in June 1979. The Military Standard reference manual was approved on December 10, 1980 (Ada Lovelace's birthday), and given the number MIL-STD-1815 in honor of Ada Lovelace's birth year. In 1981, Tony Hoare took advantage of his Turing Award speech to criticize Ada for being overly complex and hence unreliable, but subsequently seemed to recant in the foreword he wrote for an Ada textbook.Ada attracted much attention from the programming community as a whole during its early days. Its backers and others predicted that it might become a dominant language for general purpose programming and not only defense-related work. Ichbiah publicly stated that within ten years, only two programming languages would remain: Ada and Lisp.  Early Ada compilers struggled to implement the large, complex language, and both compile-time and run-time performance tended to be slow and tools primitive.   Compiler vendors expended most of their efforts in passing the massive, language-conformance-testing, government-required Ada Compiler Validation Capability (ACVC) validation suite that was required in another novel feature of the Ada language effort. The Jargon File, a dictionary of computer hacker slang originating in 1975–1983, notes in an entry on Ada that ""it is precisely what one might expect given that kind of endorsement by fiat; designed by committee...difficult to use, and overall a disastrous, multi-billion-dollar boondoggle...Ada Lovelace...would almost certainly blanch at the use her name has been latterly put to; the kindest thing that has been said about it is that there is probably a good small language screaming to get out from inside its vast, elephantine bulk.""The first validated Ada implementation was the NYU Ada/Ed translator, certified on April 11, 1983. NYU Ada/Ed is implemented in the high-level set language SETL. Several commercial companies began offering Ada compilers and associated development tools, including Alsys, TeleSoft, DDC-I, Advanced Computer Techniques, Tartan Laboratories, Irvine Compiler, TLD Systems, and Verdix. Computer manufacturers who had a significant business in the defense, aerospace, or related industries, also offered Ada compilers and tools on their platforms; these included Concurrent Computer Corporation, Cray Research, Inc., Digital Equipment Corporation, Harris Computer Systems, and Siemens Nixdorf Informationssysteme AG.In 1991, the US Department of Defense began to require the use of Ada (the Ada mandate) for all software, though exceptions to this rule were often granted.  The Department of Defense Ada mandate was effectively removed in 1997, as the DoD began to embrace commercial off-the-shelf (COTS) technology. Similar requirements existed in other NATO countries: Ada was required for NATO systems involving command and control and other functions, and Ada was the mandated or preferred language for defense-related applications in countries such as Sweden, Germany, and Canada.By the late 1980s and early 1990s, Ada compilers had improved in performance, but there were still barriers to fully exploiting Ada's abilities, including a tasking model that was different from what most real-time programmers were used to.Because of Ada's safety-critical support features, it is now used not only for military applications, but also in commercial projects where a software bug can have severe consequences, e.g., avionics and air traffic control, commercial rockets such as the Ariane 4 and 5, satellites and other space systems, railway transport and banking.
For example, the Primary Flight Control System, the fly-by-wire system software in the Boeing 777, was written in Ada, as were the fly-by-wire systems for the aerodynamically unstable Eurofighter Typhoon, Saab Gripen, Lockheed Martin F-22 Raptor and the DFCS replacement flight control system for the Grumman F-14 Tomcat. The Canadian Automated Air Traffic System was written in 1 million lines of Ada (SLOC count). It featured advanced distributed processing, a distributed Ada database, and object-oriented design. Ada is also used in other air traffic systems, e.g., the UK's next-generation Interim Future Area Control Tools Support (iFACTS) air traffic control system is designed and implemented using SPARK Ada.
It is also used in the French TVM in-cab signalling system on the TGV high-speed rail system, and the metro suburban trains in Paris, London, Hong Kong and New York City.

Standardization
Preliminary Ada can be found in ACM Sigplan Notices Vol 14, No 6, June 1979Ada was first published in 1980 as an ANSI standard ANSI/MIL-STD 1815. As this very first version held many errors and inconsistencies , the revised edition was published in 1983 as ANSI/MIL-STD 1815A. Without any further changes, it became an ISO standard in 1987. This version of the language is commonly known as Ada 83, from the date of its adoption by ANSI, but is sometimes referred to also as Ada 87, from the date of its adoption by ISO. There is also a French translation; DIN translated it into German as DIN 66268 in 1988.
Ada 95, the joint ISO/IEC/ANSI standard ISO/IEC 8652:1995 was published in February 1995, making it the first ISO standard object-oriented programming language. To help with the standard revision and future acceptance, the US Air Force funded the development of the GNAT Compiler. Presently, the GNAT Compiler is part of the GNU Compiler Collection.
Work has continued on improving and updating the technical content of the Ada language. A Technical Corrigendum to Ada 95 was published in October 2001, and a major Amendment, ISO/IEC 8652:1995/Amd 1:2007  was published on March 9, 2007, commonly known as Ada 2005 because work on the new standard was finished that year. 
At the Ada-Europe 2012 conference in Stockholm, the Ada Resource Association (ARA) and Ada-Europe announced the completion of the design of the latest version of the Ada language and the submission of the reference manual to the ISO/IEC JTC 1/SC 22/WG 9 of the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC) for approval. ISO/IEC 8652:2012(see Ada 2012 RM) was published in December 2012, known as Ada 2012. A technical corrigendum, ISO/IEC 8652:2012/COR 1:2016, was published (see RM 2012 with TC 1).
On May 2, 2023, the Ada community saw the formal approval of publication of the Ada 2022 edition of the programming language standard.Despite the names Ada 83, 95 etc., legally there is only one Ada standard, the one of the last ISO/IEC standard: with the acceptance of a new standard version, the previous one becomes withdrawn. The other names are just informal ones referencing a certain edition.
Other related standards include ISO/IEC 8651-3:1988 Information processing systems—Computer graphics—Graphical Kernel System (GKS) language bindings—Part 3: Ada.

Language constructs
Ada is an ALGOL-like programming language featuring control structures with reserved words such as if, then, else, while, for, and so on. However, Ada also has many data structuring facilities and other abstractions which were not included in the original ALGOL 60, such as type definitions, records, pointers, enumerations. Such constructs were in part inherited from or inspired by Pascal.

""Hello, world!"" in Ada
A common example of a language's syntax is the Hello world program:
(hello.adb)

This program can be compiled by using the freely available open source compiler GNAT, by executing

Data types
Ada's type system is not based on a set of predefined primitive types but allows users to declare their own types. This declaration in turn is not based on the internal representation of the type but on describing the goal which should be achieved. This allows the compiler to determine a suitable memory size for the type, and to check for violations of the type definition at compile time and run time (i.e., range violations, buffer overruns, type consistency, etc.). Ada supports numerical types defined by a range, modulo types, aggregate types (records and arrays), and enumeration types. Access types define a reference to an instance of a specified type; untyped pointers are not permitted.
Special types provided by the language are task types and protected types.
For example, a date might be represented as:

Important to note: Day_type, Month_type, Year_type, Hours are incompatible types, meaning that for instance the following expression is illegal:

The predefined plus-operator can only add values of the same type, so the expression is illegal. 
Types can be refined by declaring subtypes:

Types can have modifiers such as limited, abstract, private etc. Private types do not show their inner structure; objects of limited types cannot be copied. Ada 95 adds further features for object-oriented extension of types.

Control structures
Ada is a structured programming language, meaning that the flow of control is structured into standard statements. All standard constructs and deep-level early exit are supported, so the use of the also supported ""go to"" commands is seldom needed.

Packages, procedures and functions
Among the parts of an Ada program are packages, procedures and functions.
Example:
Package specification (example.ads)

Package body (example.adb)

This program can be compiled, e.g., by using the freely available open-source compiler GNAT, by executing

Packages, procedures and functions can nest to any depth, and each can also be the logical outermost block.
Each package, procedure or function can have its own declarations of constants, types, variables, and other procedures, functions and packages, which can be declared in any order.

Pragmas
A pragma is a compiler directive that conveys information to the compiler to allow specific manipulating of compiled output.  Certain pragmas are built into the language, while others are implementation-specific.
Examples of common usage of compiler pragmas would be to disable certain features, such as run-time type checking or array subscript boundary checking, or to instruct the compiler to insert object code instead of a function call (as C/C++ does with inline functions).

Generics
See also
Ada compilers
APSE – a specification for a programming environment to support software development in Ada
Ravenscar profile – a subset of the Ada tasking features designed for safety-critical hard real-time computing
SPARK – a programming language consisting of a highly restricted subset of Ada, annotated with meta-information describing desired component behavior and individual runtime requirements

Notes
References
International standards
ISO/IEC 8652: Information technology—Programming languages—Ada
ISO/IEC 15291: Information technology—Programming languages—Ada Semantic Interface Specification (ASIS)
ISO/IEC 18009: Information technology—Programming languages—Ada: Conformity assessment of a language processor (ACATS)
IEEE Standard 1003.5b-1996, the POSIX Ada binding
Ada Language Mapping Specification, the CORBA interface description language (IDL) to Ada mapping

Rationale
These documents have been published in various forms, including print.

Ichbiah, Jean D.; Barnes, John G. P.; Firth, Robert J.; Woodger, Mike (1986), Rationale for the Design of the Ada Programming Language, archived from the original on 2007-02-02 Also available apps.dtic.mil, pdf
Barnes, John G. P. (1995), Ada 95 rationale: the language: the standard libraries
Barnes, John (2006) [2005], Rationale for Ada 2005

Books
Further reading
Barnes, John (2006). Programming in Ada 2005. Addison-Wesley. ISBN 0-321-34078-7.
Barnes, John (1991). Programming in Ada plus Language Reference Manual. Addison-Wesley. ISBN 0-201-56539-0.
Barnes, John (1998). Programming in Ada 95. Addison-Wesley. ISBN 0-201-34293-6.
Barnes, John (1997). High Integrity Ada: The SPARK Approach. Addison-Wesley. ISBN 0-201-17517-7.
Barnes, John (2003). High Integrity Software: The SPARK Approach to Safety and Security. Addison-Wesley. ISBN 0-321-13616-0.

External links

Ada Resource Association
DOD Ada programming language (ANSI/MIL STD 1815A-1983) specification
JTC1/SC22/WG9 ISO home of Ada Standards
Ada (programming language) at Curlie
Ada Programming Language Materials, 1981–1990. Charles Babbage Institute, University of Minnesota.",1242,https://en.wikipedia.org/wiki/Ada_(programming_language)
Address (programming language),"The Address programming language (Ukrainian: Адресна мова програмування, Russian: Адресный язык программирования) is one of the world's first high-level programming languages. It was created in 1955 by Kateryna Yushchenko. In particular, the Address programming language made possible indirect addressing and addresses of the highest rank –  analogous to pointers.Unlike Fortran and ALGOL 60, APL (Address Programming Language) supported indirect addressing and addressing of higher ranks. Indirect addressing is a mechanism that appeared in other programming languages much later (1964 –  in PL/1). 
The Address language was implemented on all the computers of the first and second generation produced in the Soviet Union. The Address language influenced the architecture of the Kyiv, M-20, Dnipro, Ural, Promin and Minsk computers. The Address programming language was used exclusively for the solution of economical problems, including aviation, space exploration, machine building, and military complex –  in particular, to calculate the trajectories of ballistic missiles in flight –  in the 1950–60s. Implementations of the Address programming language were used for nearly 20 years. A book about APL was published in Ukraine in 1963 and it was translated and published in France in 1974. 
The Address language affected not only the Soviet Union's and other socialist countries economical development, but information technology and programming of over the world. APL's proposed and implemented ideas and tools can be found in many programming-related fields, such as abstract data types, object-oriented programming, functional programming, logical programming, databases and artificial intelligence.","The Address programming language (Ukrainian: Адресна мова програмування, Russian: Адресный язык программирования) is one of the world's first high-level programming languages. It was created in 1955 by Kateryna Yushchenko. In particular, the Address programming language made possible indirect addressing and addresses of the highest rank –  analogous to pointers.Unlike Fortran and ALGOL 60, APL (Address Programming Language) supported indirect addressing and addressing of higher ranks. Indirect addressing is a mechanism that appeared in other programming languages much later (1964 –  in PL/1). 
The Address language was implemented on all the computers of the first and second generation produced in the Soviet Union. The Address language influenced the architecture of the Kyiv, M-20, Dnipro, Ural, Promin and Minsk computers. The Address programming language was used exclusively for the solution of economical problems, including aviation, space exploration, machine building, and military complex –  in particular, to calculate the trajectories of ballistic missiles in flight –  in the 1950–60s. Implementations of the Address programming language were used for nearly 20 years. A book about APL was published in Ukraine in 1963 and it was translated and published in France in 1974. 
The Address language affected not only the Soviet Union's and other socialist countries economical development, but information technology and programming of over the world. APL's proposed and implemented ideas and tools can be found in many programming-related fields, such as abstract data types, object-oriented programming, functional programming, logical programming, databases and artificial intelligence.

Books
Glushkov V.M., & Yushchenko E.L., D 1966, The Kiev Computer; a Mathematical Description, USA, Ohio, Translation Division, Foreign Technology Div., Wright-Pattenon AFB, 234p., ASIN: B0007G3QGC.
Gnedenko B.V., Koroliouk V. S. & Iouchtchenko E.L., D 1969, Eléments de programmation sur ordinateurs, Paris, Dunod, 362p., ASIN: B0014UQTU0, viewed 24 October 2021,<https://files.infoua.net/yushchenko/Elements-de-programmation-sur-ordinateurs_BGnedenko-VKoroliouk-EIouchtchenko_1969_France_OCR.pdf>.

Gnedenko B.V., Koroljuk V.S. & Justschenko E.L., D 1964, Elemente der Programmierung, DDR, Leipzig, Verlag: B. G. Teubner, 327 oldal.
Gnedenko B.V., Korolyuk V.S. & Juscsenko E.L. D 1964, Bevezetѐs a progamozásba, – I, II. – Magyarország, Budapest, Uj technica.
Вычислительная машина «Киев»: математическое описание / В. М. Глушков, Е. Л. Ющенко. — К. : Техн. лит., 1962. — 183 с.
Кулинкович А.Е., Ющенко Е.Л., О базовом алгоритмическом языке. / Кулинкович А.Е., Ющенко Е.Л., в журн.: «Кибернетика», К. : № 2, 1965. C.3-9, – URL: https://files.infoua.net/yushchenko/O-bazovom-algoritmicheskov-yazyke_AKulinkovich_EYushchenko_1965.pdf
Ющенко Е. Л. Адресное программирование / Е. Л. Ющенко. — К. : Техн. лит., 1963. — 286 с. https://files.infoua.net/yushchenko/Adresnoe-programmirovanie_EYushchenko_1963.pdf
Ющенко Е. Л. Программирующая программа с входным адресным языком для машины Урал −1 / Е. Л. Ющенко, Т. А. Гринченко. — К. : Наук. думка, 1964. — 107 с.
Ющенко Е.Л., Адресный язык (Тема 5) // Кибернетика на транспорте: Заочный семинар. / Киевский дом Научно-технической пропаганды / – К. : – 1962. – 32 с., – URL: Kibernetika-na-transporte_Adresnyy-yazyk_KYushchenko_1962.pdf (infoua.net)
Управляющая машина широкого назначения «Дніпро» и программирующая программа в ней / Е. Л. Ющенко, Б. Н. Малиновский, Г. А. Полищук, Э. К. Ядренко, А. И. Никитин. — К. : Наук. думка, 1964. — 280 с.


== References ==",34146907,https://en.wikipedia.org/wiki/Address_(programming_language)
Agda (programming language),"Agda is a dependently typed functional programming language originally developed by Ulf Norell at Chalmers University of Technology with implementation described in his PhD thesis. The original Agda system was developed at Chalmers by Catarina Coquand in 1999. The current version, originally known as Agda 2, is a full rewrite, which should be considered a new language that shares a name and tradition.
Agda is also a proof assistant based on the propositions-as-types paradigm, but unlike Coq, has no separate tactics language, and proofs are written in a functional programming style. The language has ordinary programming constructs such as data types, pattern matching, records, let expressions and modules, and a Haskell-like syntax. The system has Emacs, Atom, and VS Code interfaces but can also be run in batch mode from the command line.
Agda is based on Zhaohui Luo's unified theory of dependent types (UTT), a type theory similar to Martin-Löf type theory.
Agda is named after the Swedish song ""Hönan Agda"", written by Cornelis Vreeswijk, which is about a hen named Agda. This alludes to the name of the theorem prover Coq, which was named after Thierry Coquand.","Agda is a dependently typed functional programming language originally developed by Ulf Norell at Chalmers University of Technology with implementation described in his PhD thesis. The original Agda system was developed at Chalmers by Catarina Coquand in 1999. The current version, originally known as Agda 2, is a full rewrite, which should be considered a new language that shares a name and tradition.
Agda is also a proof assistant based on the propositions-as-types paradigm, but unlike Coq, has no separate tactics language, and proofs are written in a functional programming style. The language has ordinary programming constructs such as data types, pattern matching, records, let expressions and modules, and a Haskell-like syntax. The system has Emacs, Atom, and VS Code interfaces but can also be run in batch mode from the command line.
Agda is based on Zhaohui Luo's unified theory of dependent types (UTT), a type theory similar to Martin-Löf type theory.
Agda is named after the Swedish song ""Hönan Agda"", written by Cornelis Vreeswijk, which is about a hen named Agda. This alludes to the name of the theorem prover Coq, which was named after Thierry Coquand.

Features
Inductive types
The main way of defining data types in Agda is via inductive data types which are similar to algebraic data types in non-dependently typed programming languages.
Here is a definition of Peano numbers in Agda:

Basically, it means that there are two ways to construct a value of type N{\displaystyle \mathbb {N} }, representing a natural number. To begin, zero is a natural number, and if n is a natural number, then suc n, standing for the successor of n, is a natural number too.
Here is a definition of the ""less than or equal"" relation between two natural numbers:

The first constructor, z≤n, corresponds to the axiom that zero is less than or equal to any natural number. The second constructor, s≤s, corresponds to an inference rule, allowing to turn a proof of n ≤ m into a proof of suc n ≤ suc m. So the value s≤s {zero} {suc zero} (z≤n {suc zero}) is a proof that one (the successor of zero), is less than or equal to two (the successor of one). The parameters provided in curly brackets may be omitted if they can be inferred.

Dependently typed pattern matching
In core type theory, induction and recursion principles are used to prove theorems about inductive types. In Agda, dependently typed pattern matching is used instead. For example, natural number addition can be defined like this:

This way of writing recursive functions/inductive proofs is more natural than applying raw induction principles. In Agda, dependently typed pattern matching is a primitive of the language; the core language lacks the induction/recursion principles that pattern matching translates to.

Metavariables
One of the distinctive features of Agda, when compared with other similar systems such as Coq, is heavy reliance on metavariables for program construction. For example, one can write functions like this in Agda:

? here is a metavariable. When interacting with the system in emacs mode, it will show the user expected type and allow them to refine the metavariable, i.e., to replace it with more detailed code. This feature allows incremental program construction in a way similar to tactics-based proof assistants such as Coq.

Proof automation
Programming in pure type theory involves a lot of tedious and repetitive proofs. Although Agda has no separate tactics language, it is possible to program useful tactics within Agda itself. Typically, this works by writing an Agda function that optionally returns a proof of some property of interest. A tactic is then constructed by running this function at type-checking time, for example using the following auxiliary definitions:

Given a function check-even : (n : N{\displaystyle \mathbb {N} }) → Maybe (Even n) that inputs a number and optionally returns a proof of its evenness, a tactic can then be constructed as follows:

The actual proof of each lemma will be automatically constructed at type-checking time. If the tactic fails, type-checking will fail.
Additionally, to write more complex tactics, Agda has support for automation via reflection. The reflection mechanism allows one to quote program fragments into – or unquote them from – the abstract syntax tree. The way reflection is used is similar to the way Template Haskell works.Another mechanism for proof automation is proof search action in emacs mode. It enumerates possible proof terms (limited to 5 seconds), and if one of the terms fits the specification, it will be put in the meta variable where the action is invoked. This action accepts hints, e.g., which theorems and from which modules can be used, whether the action can use pattern matching, etc.

Termination checking
Agda is a total language, i.e., each program in it must terminate and all possible patterns must be matched. Without this feature, the logic behind the language becomes inconsistent, and it becomes possible to prove arbitrary statements. For termination checking, Agda uses the approach of the Foetus termination checker.

Standard library
Agda has an extensive de facto standard library, which includes many useful definitions and theorems about basic data structures, such as natural numbers, lists, and vectors. The library is in beta, and is under active development.

Unicode
One of the more notable features of Agda is a heavy reliance on Unicode in program source code. The standard emacs mode uses shortcuts for input, such as \Sigma for Σ.

Backends
There are two compiler backends, MAlonzo for Haskell and one for JavaScript.

See also
List of proof assistants

References
Further reading
Bove, Ana; Dybjer, Peter; Norell, Ulf (n.d.). ""Brief Overview of Agda – A Functional Language with Dependent Types"" (PDF).
Norell, Ulf; Chapman, James (n.d.). ""Dependently Typed Programming in Agda"" (PDF).

External links
Official website
Introduction to Agda, a five-part YouTube playlist by Daniel Peebles
Brutal [Meta]Introduction to Dependent Types in Agda
Agda Tutorial: ""explore programming in Agda without theoretical background""
HoTTEST Summer School 2022, 66 lectures on Homotopy Type Theory, including a number of introductory lectures and exercises on Agda",4426773,https://en.wikipedia.org/wiki/Agda_(programming_language)
ALGOL 68,"ALGOL 68 (short for Algorithmic Language 1968) is an imperative programming language that was conceived as a successor to the ALGOL 60 programming language, designed with the goal of a much wider scope of application and more rigorously defined syntax and semantics.
The complexity of the language's definition, which runs to several hundred pages filled with non-standard terminology, made compiler implementation difficult and it was said it had ""no implementations and no users"". This was only partly true; ALGOL 68 did find use in several niche markets, notably in the United Kingdom where it was popular on International Computers Limited (ICL) machines, and in teaching roles. Outside these fields, use was relatively limited.
Nevertheless, the contributions of ALGOL 68 to the field of computer science have been deep, wide-ranging and enduring, although many of these contributions were only publicly identified when they had reappeared in subsequently developed programming languages. Many languages were developed specifically as a response to the perceived complexity of the language, the most notable being Pascal, or were reimplementations for specific roles, like Ada.
Many languages of the 1970s trace their design specifically to ALGOL 68, selecting some features while abandoning others that were considered too complex or out-of-scope for given roles. Among these is the language C, which was directly influenced by ALGOL 68, especially by its strong typing and structures. Most modern languages trace at least some of their syntax to either C or Pascal, and thus directly or indirectly to ALGOL 68.","ALGOL 68 (short for Algorithmic Language 1968) is an imperative programming language that was conceived as a successor to the ALGOL 60 programming language, designed with the goal of a much wider scope of application and more rigorously defined syntax and semantics.
The complexity of the language's definition, which runs to several hundred pages filled with non-standard terminology, made compiler implementation difficult and it was said it had ""no implementations and no users"". This was only partly true; ALGOL 68 did find use in several niche markets, notably in the United Kingdom where it was popular on International Computers Limited (ICL) machines, and in teaching roles. Outside these fields, use was relatively limited.
Nevertheless, the contributions of ALGOL 68 to the field of computer science have been deep, wide-ranging and enduring, although many of these contributions were only publicly identified when they had reappeared in subsequently developed programming languages. Many languages were developed specifically as a response to the perceived complexity of the language, the most notable being Pascal, or were reimplementations for specific roles, like Ada.
Many languages of the 1970s trace their design specifically to ALGOL 68, selecting some features while abandoning others that were considered too complex or out-of-scope for given roles. Among these is the language C, which was directly influenced by ALGOL 68, especially by its strong typing and structures. Most modern languages trace at least some of their syntax to either C or Pascal, and thus directly or indirectly to ALGOL 68.

Overview
ALGOL 68 features include expression-based syntax, user-declared types and structures/tagged-unions, a reference model of variables and reference parameters, string, array and matrix slicing, and concurrency.
ALGOL 68 was designed by the International Federation for Information Processing (IFIP) IFIP Working Group 2.1 on Algorithmic Languages and Calculi. On December 20, 1968, the language was formally adopted by the group, and then approved for publication by the General Assembly of IFIP.
ALGOL 68 was defined using a formalism, a two-level formal grammar, invented by Adriaan van Wijngaarden. Van Wijngaarden grammars use a context-free grammar to generate an infinite set of productions that will recognize a particular ALGOL 68 program; notably, they are able to express the kind of requirements that in many other programming language technical standards are labelled semantics, and must be expressed in ambiguity-prone natural language prose, and then implemented in compilers as ad hoc code attached to the formal language parser.

The main aims and principles of design of ALGOL 68:

Completeness and clarity of description
Orthogonality of design
Security
Efficiency:Static mode checking
Mode-independent parsing
Independent compiling
Loop optimizing
Representations – in minimal & larger character setsALGOL 68 has been criticized, most prominently by some members of its design committee such as C. A. R. Hoare and Edsger Dijkstra, for abandoning the simplicity of ALGOL 60, becoming a vehicle for complex or overly general ideas, and doing little to make the compiler writer's task easier, in contrast to deliberately simple contemporaries (and competitors) such as C, S-algol and Pascal.
In 1970, ALGOL 68-R became the first working compiler for ALGOL 68.
In the 1973 revision, certain features — such as proceduring, gommas and formal bounds — were omitted. C.f. The language of the unrevised report.r0
Though European defence agencies (in Britain Royal Signals and Radar Establishment (RSRE)) promoted the use of ALGOL 68 for its expected security advantages, the American side of the NATO alliance decided to develop a different project, the language Ada, making its use obligatory for US defense contracts.
ALGOL 68 also had a notable influence in the Soviet Union, details of which can be found in Andrey Terekhov's 2014 paper: ""ALGOL 68 and Its Impact on the USSR and Russian Programming"", and ""Алгол 68 и его влияние на программирование в СССР и России"".Steve Bourne, who was on the ALGOL 68 revision committee, took some of its ideas to his Bourne shell (and thereby, to descendant Unix shells such as Bash) and to C (and thereby to descendants such as C++).
The complete history of the project can be found in C. H. Lindsey's A History of ALGOL 68.For a full-length treatment of the language, see ""Programming ALGOL 68 Made Easy"" by Dr. Sian Mountbatten, or ""Learning ALGOL 68 Genie"" by Marcel van der Veer which includes the Revised Report.

History
Origins
ALGOL 68, as the name implies, is a follow-on to the ALGOL language that was first formalized in 1960. That same year the International Federation for Information Processing (IFIP) formed and started the Working Group on ALGOL, or WG2.1. This group released an updated ALGOL 60 specification in Rome in April 1962. At a follow-up meeting in March 1964, it was agreed that the group should begin work on two follow-on standards, ALGOL X which would be a redefinition of the language with some additions, and an ALGOL Y, which would have the ability to modify its own programs in the style of the language LISP.

Definition process
The first meeting of the ALGOL X group was held in Princeton University in May 1965. A report of the meeting noted two broadly supported themes, the introduction of strong typing and interest in Euler's concepts of 'trees' or 'lists' for handling collections.At the second meeting in October in France, three formal proposals were presented, Niklaus Wirth's ALGOL W along with comments about record structures by C.A.R. (Tony) Hoare, a similar language by Gerhard Seegmüller, and a paper by Adriaan van Wijngaarden on ""Orthogonal design and description of a formal language"". The latter, written in almost indecipherable ""W-Grammar"", proved to be a decisive shift in the evolution of the language. The meeting closed with an agreement that van Wijngaarden would re-write the Wirth/Hoare submission using his W-Grammar.This seemingly simple task ultimately proved more difficult than expected, and the follow-up meeting had to be delayed six months. When it met in April 1966 in Kootwijk, van Wijngaarden's draft remained incomplete and Wirth and Hoare presented a version using more traditional descriptions. It was generally agreed that their paper was ""the right language in the wrong formalism"". As these approaches were explored, it became clear there was a difference in the way parameters were described that would have real-world effects, and while Wirth and Hoare protested that further delays might become endless, the committee decided to wait for van Wijngaarden's version. Wirth then implemented their current definition as ALGOL W.At the next meeting in Warsaw in October 1966, there was an initial report from the I/O Subcommittee who had met at the Oak Ridge National Laboratory and the University of Illinois but had not yet made much progress. The two proposals from the previous meeting were again explored, and this time a new debate emerged about the use of pointers; ALGOL W used them only to refer to records, while van Wijngaarden's version could point to any object. To add confusion, John McCarthy presented a new proposal for operator overloading and the ability to string together and or constructs, and Klaus Samelson wanted to allow anonymous functions. In the resulting confusion, there was some discussion of abandoning the entire effort. The confusion continued through what was supposed to be the ALGOL Y meeting in Zandvoort in May 1967.

Publication
A draft report was finally published in February 1968. This was met by ""shock, horror and dissent"", mostly due to the hundreds of pages of unreadable grammar and odd terminology. Charles H. Lindsey attempted to figure out what ""language was hidden inside of it"", a process that took six man-weeks of effort. The resulting paper, ""ALGOL 68 with fewer tears"", was widely circulated. At a wider information processing meeting in Zürich in May 1968, attendees complained that the language was being forced upon them and that IFIP was ""the true villain of this unreasonable situation"" as the meetings were mostly closed and there was no formal feedback mechanism. Wirth and Peter Naur formally resigned their authorship positions in WG2.1 at that time.The next WG2.1 meeting took place in Tirrenia in June 1968. It was supposed to discuss the release of compilers and other issues, but instead devolved into a discussion on the language. van Wijngaarden responded by saying (or threatening) that he would release only one more version of the report. By this point Naur, Hoare, and Wirth had left the effort, and several more were threatening to do so. Several more meetings followed, North Berwick in August 1968, Munich in December which produced the release of the official Report in January 1969 but also resulted in a contentious Minority Report being written. Finally, at Banff, Alberta in September 1969, the project was generally considered complete and the discussion was primarily on errata and a greatly expanded Introduction to the Report.The effort took five years, burned out many of the greatest names in computer science, and on several occasions became deadlocked over issues both in the definition and the group as a whole. Hoare released a ""Critique of ALGOL 68"" almost immediately, which has been widely referenced in many works. Wirth went on to further develop the ALGOL W concept and released this as Pascal in 1970.

Implementations
ALGOL 68-R
The first implementation of the standard, based on the late-1968 draft Report, was introduced by the Royal Radar Establishment in the UK as ALGOL 68-R in July 1970. This was, however, a subset of the full language, and Barry Mailloux, the final editor of the Report, joked that ""It is a question of morality.  We have a Bible and you are sinning!"" This version nevertheless became very popular on the ICL machines, and became a widely-used language in military coding, especially in the UK.Among the changes in 68-R was the requirement for all variables to be declared before their first use. This had a significant advantage that it allowed the compiler to be one-pass, as space for the variables in the activation record was set aside before it was used. However, this change also had the side-effect of demanding the PROCs be declared twice, once as a declaration of the types, and then again as the body of code. Another change was to eliminate the assumed VOID mode, an expression that returns no value (named a statement in other languages) and demanding the word VOID be added where it would have been assumed. Further, 68-R eliminated the explicit parallel processing commands based on PAR.

Others
The first full implementation of the language was introduced in 1974 by CDC Netherlands for the Control Data mainframe series. This saw limited use, mostly teaching in Germany and the Netherlands.A version similar to 68-R was introduced from Carnegie Mellon University in 1976 as 68S, and was again a one-pass compiler based on various simplifications of the original and intended for use on smaller machines like the DEC PDP-11. It too was used mostly for teaching purposes.A version for IBM mainframes did not become available until 1978, when one was released from Cambridge University. This was ""nearly complete"". Lindsey released a version for small machines including the IBM PC in 1984.Three open source Algol 68 implementations are known:
a68g, GPLv3, written by Marcel van der Veer.
algol68toc, an open-source software port of ALGOL 68RS.
experimental Algol68 frontend for GCC,  written by Jose E. Marchesi.

Timeline
""A Shorter History of Algol 68""
ALGOL 68 – 3rd generation ALGOL

The Algorithmic Language ALGOL 68 Reports and Working Group members
March 1968: Draft Report on the Algorithmic Language ALGOL 68 – Edited by: Adriaan van Wijngaarden, Barry J. Mailloux, John Peck and Cornelis H. A. Koster.""Van Wijngaarden once characterized the four authors, somewhat tongue-in-cheek, as: Koster: transputter, Peck: syntaxer, Mailloux: implementer, Van Wijngaarden: party ideologist."" – Koster.
October 1968: Penultimate Draft Report on the Algorithmic Language ALGOL 68 — Chapters 1-9 Chapters 10-12 — Edited by: A. van Wijngaarden, B.J. Mailloux, J. E. L. Peck and C. H. A. Koster.
December 1968: Report on the Algorithmic Language ALGOL 68 — Offprint from Numerische Mathematik, 14, 79-218 (1969); Springer-Verlag. — Edited by: A. van Wijngaarden, B. J. Mailloux, J. E. L. Peck and C. H. A. Koster.
March 1970: Minority report, ALGOL Bulletin AB31.1.1 — signed by Edsger Dijkstra, Fraser Duncan, Jan Garwick, Tony Hoare,  Brian Randell, Gerhard Seegmüller, Wlad Turski, and  Mike Woodger.
September 1973: Revised Report on the Algorithmic Language Algol 68 — Springer-Verlag 1976 — Edited by: A. van Wijngaarden, B. Mailloux, J. Peck, K. Koster, Michel Sintzoff, Charles H. Lindsey, Lambert Meertens and Richard G. Fisker.
other WG 2.1 members active in ALGOL 68 design: Friedrich L. Bauer • Hans Bekic • Gerhard Goos • Peter Zilahy Ingerman • Peter Landin • John McCarthy • Jack Merner • Peter Naur • Manfred Paul • Willem van der Poel • Doug Ross • Klaus Samelson • Niklaus Wirth • Nobuo Yoneda.

Timeline of standardization
1968: On 20 December 1968, the ""Final Report"" (MR 101) was adopted by the Working Group, then subsequently approved by the General Assembly of UNESCO's IFIP for publication. Translations of the standard were made for Russian, German, French and Bulgarian, and then later Japanese and Chinese. The standard was also made available in Braille.
1984: TC 97 considered ALGOL 68 for standardisation as ""New Work Item"" TC97/N1642 [2][3]. West Germany, Belgium, Netherlands, USSR and Czechoslovakia willing to participate in preparing the standard but the USSR and Czechoslovakia ""were not the right kinds of member of the right ISO committees""[4] and Algol 68's ISO standardisation stalled.[5]
1988: Subsequently ALGOL 68 became one of the GOST standards in Russia.

GOST 27974-88 Programming language ALGOL 68 — Язык программирования АЛГОЛ 68
GOST 27975-88 Programming language ALGOL 68 extended — Язык программирования АЛГОЛ 68 расширенный

Notable language elements
Bold symbols and reserved words
The standard language contains about sixty reserved words, typically bolded in print, and some with ""brief symbol"" equivalents:

MODE, OP, PRIO, PROC,
FLEX, HEAP, LOC, LONG, REF, SHORT,
BITS, BOOL, BYTES, CHAR, COMPL, INT, REAL, SEMA, STRING, VOID,
CHANNEL, FILE, FORMAT, STRUCT, UNION,
AT ""@"", EITHERr0, IS "":=:"", ISNT  IS NOTr0 "":/=:"" "":≠:"", OF ""→""r0, TRUE, FALSE, EMPTY, NIL ""○"", SKIP ""~"",
CO ""¢"", COMMENT ""¢"", PR, PRAGMAT,
CASE ~ IN ~ OUSE ~ IN ~ OUT ~ ESAC ""( ~ | ~ |: ~ | ~ | ~ )"",
FOR ~ FROM ~ TO ~ BY ~ WHILE ~ DO ~ OD,
IF ~ THEN ~ ELIF ~ THEN ~ ELSE ~ FI ""( ~ | ~ |: ~ | ~ | ~ )"",
PAR BEGIN ~ END ""( ~ )"", GO TO, GOTO, EXIT ""□""r0.

Units: Expressions
The basic language construct is the unit. A unit may be a formula, an enclosed clause, a routine text or one of several technically needed constructs (assignation, jump, skip, nihil). The technical term enclosed clause unifies some of the inherently bracketing constructs known as block, do statement, switch statement in other contemporary languages. When keywords are used, generally the reversed character sequence of the introducing keyword is used for terminating the enclosure, e.g. ( IF ~ THEN ~ ELSE ~ FI, CASE ~ IN ~ OUT ~ ESAC, FOR ~ WHILE ~ DO ~ OD ). This Guarded Command syntax was reused by Stephen Bourne in the common Unix Bourne shell. An expression may also yield a multiple value, which is constructed from other values by a collateral clause. This construct just looks like the parameter pack of a procedure call.

mode: Declarations
The basic data types (called modes in Algol 68 parlance) are real, int, compl (complex number), bool, char, bits and bytes. For example:

INT n = 2;
CO n is fixed as a constant of 2. CO
INT m := 3;
CO m is a newly created local variable whose value is initially set to 3. CO
CO    This is short for ref int m = loc int := 3; CO
REAL avogadro = 6.0221415⏨23; CO Avogadro number CO
long long real long long pi = 3.14159 26535 89793 23846 26433 83279 50288 41971 69399 37510;
COMPL square root of minus one = 0 ⊥ 1;

However, the declaration REAL x; is just syntactic sugar for REF REAL x = LOC REAL;. That is, x is really the constant identifier for a reference to a newly generated local REAL variable.
Furthermore, instead of defining both float and double, or int and long and short, etc., ALGOL 68 provides modifiers, so that the presently common double would be written as LONG REAL or LONG LONG REAL instead, for example. The prelude constants max real and min long int are provided to adapt programs to different implementations.
All variables need to be declared, but declaration does not have to precede the first use.
primitive-declarer: INT, REAL, COMPL, COMPLEXG, BOOL, CHAR, STRING, BITS, BYTES, FORMAT, FILE, PIPEG, CHANNEL, SEMA

BITS – a ""packed vector"" of BOOL.
BYTES – a ""packed vector"" of CHAR.
STRING – a FLEXible array of CHAR.
SEMA – a SEMAphore which can be initialised with the OPerator LEVEL.Complex types can be created from simpler ones using various type constructors:

REF mode – a reference to a value of type mode, similar to & in C/C++ and REF in Pascal
STRUCT – used to build structures, like STRUCT in C/C++ and RECORD in Pascal
UNION – used to build unions, like in C/C++ and Pascal
PROC – used to specify procedures, like functions in C/C++ and procedures/functions in PascalFor some examples, see Comparison of ALGOL 68 and C++.
Other declaration symbols include:  FLEX, HEAP, LOC, REF, LONG, SHORT, EVENTS
FLEX – declare the array to be flexible, i.e. it can grow in length on demand.
HEAP – allocate variable some free space from the global heap.
LOC – allocate variable some free space of the local stack.
LONG – declare an INT, REAL or COMPL to be of a LONGer size.
SHORT – declare an INT, REAL or COMPL to be of a SHORTer size.A name for a mode (type) can be declared using a MODE declaration,
which is similar to TYPEDEF in C/C++ and TYPE in Pascal:

 INT max=99;
 MODE newmode = [0:9][0:max]STRUCT (
     LONG REAL a, b, c, SHORT INT i, j, k, REF REAL r
 );

This is similar to the following C code:

For ALGOL 68, only the NEWMODE mode-indication appears to the left of the equals symbol, and most notably the construction is made, and can be read, from left to right without regard to priorities. Also, the lower bound of Algol 68 arrays is one by default, but can be any integer from -max int to max int.
Mode declarations allow types to be recursive: defined directly or indirectly in terms of themselves.
This is subject to some restrictions – for instance, these declarations are illegal:

 MODE A = REF A
 MODE A = STRUCT (A a, B b)
 MODE A = PROC (A a) A

while these are valid:

 MODE A = STRUCT (REF A a, B b)
 MODE A = PROC (REF A a) REF A

Coercions: casting
The coercions produce a coercee from a coercend according to three criteria: the a priori mode of the coercend before the application of any coercion, the a posteriori mode of the coercee required after those coercions, and the syntactic position or ""sort"" of the coercee. Coercions may be cascaded.
The six possible coercions are termed deproceduring, dereferencing, uniting, widening, rowing, and voiding. Each coercion, except for uniting, prescribes a corresponding dynamic effect on the associated values. Hence, many primitive actions can be programmed implicitly by coercions.
Context strength – allowed coercions:

soft – deproceduring
weak – dereferencing or deproceduring, yielding a name
meek – dereferencing or deproceduring
firm – meek, followed by uniting
strong – firm, followed by widening, rowing or voiding

Coercion hierarchy with examples
ALGOL 68 has a hierarchy of contexts which determine the kind of coercions available at a particular point in the program. These contexts are:

For more details about Primaries, Secondaries, Tertiary & Quaternaries refer to Operator precedence.

pr & co: Pragmats and Comments
Pragmats are directives in the program, typically hints to the compiler; in newer languages these are called ""pragmas"" (no 't'). e.g.

PRAGMAT heap=32 PRAGMAT
PR heap=32 PR

Comments can be inserted in a variety of ways:

¢ The original way of adding your 2 cents worth to a program ¢
COMMENT ""bold"" comment COMMENT
CO Style i comment CO
# Style ii comment #
£ This is a hash/pound comment for a UK keyboard £

Normally, comments cannot be nested in ALGOL 68. This restriction can be circumvented by using different comment delimiters (e.g. use hash only for temporary code deletions).

Expressions and compound statements
ALGOL 68 being an expression-oriented programming language, the value returned by an assignment statement is a reference to the destination. Thus, the following is valid ALGOL 68 code:

 REAL half pi, one pi; one pi := 2 * ( half pi := 2 * arc tan(1) )

This notion is present in C and Perl, among others. Note that as in earlier languages such as Algol 60 and FORTRAN, spaces are allowed in identifiers, so that half pi is a single identifier (thus avoiding the underscores versus camel case versus all lower-case issues).
As another example, to express the mathematical idea of a sum of f(i) from i=1 to n, the following ALGOL 68 integer expression suffices:

 (INT sum := 0; FOR i TO n DO sum +:= f(i) OD; sum)

Note that, being an integer expression, the former block of code can be used in any context where an integer value can be used. A block of code returns the value of the last expression it evaluated; this idea is present in Lisp, among other languages.
Compound statements are all terminated by distinctive closing brackets:

IF choice clauses: IF condition THEN statements [ ELSE statements ] FI
 ""brief"" form:  ( condition | statements | statements )

 IF condition1 THEN statements ELIF condition2 THEN statements [ ELSE statements ] FI
 ""brief"" form:  ( condition1 | statements |: condition2 | statements | statements )

This scheme not only avoids the dangling else problem but also avoids having to use BEGIN and END in embedded statement sequences.

CASE choice clauses: CASE switch IN statements, statements,... [ OUT statements ] ESAC
 ""brief"" form:  ( switch | statements,statements,... | statements )

 CASE switch1 IN statements, statements,... OUSE switch2 IN statements, statements,... [ OUT statements ] ESAC
 ""brief"" form of CASE statement:  ( switch1 | statements,statements,... |: switch2 | statements,statements,... | statements )

Choice clause example with Brief symbols:

PROC days in month = (INT year, month)INT:
  (month|
    31,
    (year÷×4=0 ∧ year÷×100≠0  ∨  year÷×400=0 | 29 | 28 ),
    31, 30, 31, 30, 31, 31, 30, 31, 30, 31
  );

Choice clause example with Bold symbols:

PROC days in month = (INT year, month)INT:
  CASE month IN
    31,
    IF year MOD 4 EQ 0 AND year MOD 100 NE 0  OR  year MOD 400 EQ 0 THEN 29 ELSE 28 FI,
    31, 30, 31, 30, 31, 31, 30, 31, 30, 31
  ESAC;

Choice clause example mixing Bold and Brief symbols:

PROC days in month = (INT year, month)INT:
  CASE month IN
¢Jan¢ 31,
¢Feb¢ ( year MOD 4 = 0 AND year MOD 100 ≠ 0  OR  year MOD 400 = 0 | 29 | 28 ),
¢Mar¢ 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 ¢ to Dec. ¢
  ESAC;

Algol68 allowed the switch to be of either type INT or (uniquely) UNION. The latter allows the enforcing strong typing onto UNION variables. c.f. union below for example.

do loop clause: [ FOR index ] [ FROM first ] [ BY increment ] [ TO last ] [ WHILE condition ] DO statements OD
 The minimum form of a ""loop clause"" is thus: DO statements OD

This was considered the ""universal"" loop, the full syntax is:

FOR i FROM 1 BY -22 TO -333 WHILE i×i≠4444 DO ~ OD

The construct have several unusual aspects:

only the DO ~ OD portion was compulsory, in which case the loop will iterate indefinitely.
thus the clause TO 100 DO ~ OD, will iterate only 100 times.
the WHILE ""syntactic element"" allowed a programmer to break from a FOR loop early. e.g.INT sum sq:=0;
FOR i
WHILE
  print((""So far:"",i,newline));
  sum sq≠70↑2
DO
  sum sq+:=i↑2
OD

Subsequent ""extensions"" to the standard Algol68 allowed the TO syntactic element to be replaced with UPTO and DOWNTO to achieve a small optimisation.  The same compilers also incorporated:

UNTIL(C) – for late loop termination.
FOREACH(S) – for working on arrays in parallel.Further examples can be found in the code examples below.

struct, union & [:]: Structures, unions and arrays
ALGOL 68 supports arrays with any number of dimensions, and it allows for the slicing of whole or partial rows or columns.

 MODE VECTOR = [1:3]    REAL;   # vector MODE declaration (typedef)  #
 MODE MATRIX = [1:3,1:3]REAL;   # matrix MODE declaration (typedef)  #
 VECTOR v1  := (1,2,3);         # array variable initially (1,2,3)   #
 []REAL v2   = (4,5,6);         # constant array, type equivalent to VECTOR, bounds are implied  #
 OP + = (VECTOR a,b) VECTOR:    # binary OPerator definition         #
   (VECTOR out; FOR i FROM ⌊a TO ⌈a DO out[i] := a[i]+b[i] OD; out);
 MATRIX m := (v1, v2, v1+v2);
 print ((m[,2:]));              # a slice of the 2nd and 3rd columns #

Matrices can be sliced either way, e.g.:

 REF VECTOR row = m[2,];  # define a REF (pointer) to the 2nd row #
 REF VECTOR col = m[,2];  # define a REF (pointer) to the 2nd column #

ALGOL 68 supports multiple field structures (STRUCT) and united modes. Reference variables may point to any MODE including array slices and structure fields.
For an example of all this, here is the traditional linked list declaration:

 MODE NODE = UNION (VOID, REAL, INT, COMPL, STRING),
      LIST = STRUCT (NODE val, REF LIST next);

Usage example for UNION CASE of NODE:

proc: Procedures
Procedure (PROC) declarations require type specifications for both the parameters and the result (VOID if none):

 PROC max of real = (REAL a, b) REAL:
    IF a > b THEN a ELSE b FI;

or, using the ""brief"" form of the conditional statement:

 PROC max of real = (REAL a, b) REAL: (a>b | a | b);

The return value of a proc is the value of the last expression evaluated in the procedure. References to procedures (ref proc) are also permitted. Call-by-reference parameters are provided by specifying references (such as ref real) in the formal argument list. The following example defines a procedure that applies a function (specified as a parameter) to each element of an array:

 PROC apply = (REF [] REAL a, PROC (REAL) REAL f):
  
    FOR i FROM LWB a TO UPB a DO a[i] := f(a[i]) OD

This simplicity of code was unachievable in ALGOL 68's predecessor ALGOL 60.

op: Operators
The programmer may define new operators and both those and the pre-defined ones may be overloaded and their priorities may be changed by the coder. The following example defines operator MAX with both dyadic and monadic versions (scanning across the elements of an array).

 PRIO MAX = 9;
  
 OP MAX = (INT a,b) INT: ( a>b | a | b );
 OP MAX = (REAL a,b) REAL: ( a>b | a | b );
 OP MAX = (COMPL a,b) COMPL: ( ABS a > ABS b | a | b );
  
 OP MAX = ([]REAL a) REAL:
    (REAL out := a[LWB a];
     FOR i FROM LWB a + 1 TO UPB a DO ( a[i]>out | out:=a[i] ) OD;
     out)

Array, Procedure, Dereference and coercion operations
These are technically not operators, rather they are considered ""units associated with names""

Monadic operators
Dyadic operators with associated priorities
Specific details:

Tertiaries include names NIL and ○.
LWS: In Algol68r0 the operators LWS and ⎩ ... both return TRUE if the lower state of the dimension of an array is fixed.
The UPS and ⎧ operators are similar on the upper state.
The LWB and UPB operators are automatically available on UNIONs of different orders (and MODEs) of arrays. eg. UPB of union([]int, [,]real, flex[,,,]char)

Assignation and identity relations, etc.
These are technically not operators, rather they are considered ""units associated with names""

Note: Quaternaries include names SKIP and ~.
"":=:"" (alternatively ""IS"") tests if two pointers are equal; "":/=:"" (alternatively ""ISNT"") tests if they are unequal.
Why :=: and :/=: are needed: Consider trying to compare two pointer values, such as the following variables, declared as pointers-to-integer:

REF INT ip, jp Now consider how to decide whether these two are pointing to the same location, or whether one of them is pointing to NIL. The following expression

ip = jp will dereference both pointers down to values of type INT, and compare those, since the ""="" operator is defined for INT, but not REF INT. It is not legal to define ""="" for operands of type REF INT and INT at the same time, because then calls become ambiguous, due to the implicit coercions that can be applied: should the operands be left as REF INT and that version of the operator called? Or should they be dereferenced further to INT and that version used instead? Therefore the following expression can never be made legal:

ip = NIL Hence the need for separate constructs not subject to the normal coercion rules for operands to operators. But there is a gotcha. The following expressions:

ip :=: jp 
ip :=: NIL while legal, will probably not do what might be expected. They will always return FALSE, because they are comparing the actual addresses of the variables ip and jp, rather than what they point to. To achieve the right effect, one would have to write

ip :=: REF INT(jp) 
ip :=: REF INT(NIL)

Special characters
Most of Algol's ""special"" characters (⊂, ≡, ␣, ×, ÷, ≤, ≥, ≠, ¬, ⊃, ≡, ∨, ∧, →, ↓, ↑, ⌊, ⌈, ⎩, ⎧, ⊥, ⏨, ¢, ○ and □) can be found on the IBM 2741 keyboard with the APL ""golf-ball"" print head inserted; these became available in the mid-1960s while ALGOL 68 was being drafted. These characters are also part of the Unicode standard and most of them are available in several popular fonts.

transput: Input and output
Transput is the term used to refer to ALGOL 68's input and output facilities. It includes pre-defined procedures for unformatted, formatted and binary transput. Files and other transput devices are handled in a consistent and machine-independent manner. The following example prints out some unformatted output to the standard output device:

  print ((newpage, ""Title"", newline, ""Value of i is "",
    i, ""and x[i] is "", x[i], newline))

Note the predefined procedures newpage and newline passed as arguments.

Books, channels and files
The TRANSPUT is considered to be of BOOKS, CHANNELS and FILES:

Books are made up of pages, lines and characters, and may be backed up by files.
A specific book can be located by name with a call to match.
CHANNELs correspond to physical devices.  e.g. card punches and printers.
Three standard channels are distinguished: stand in channel, stand out channel, stand back channel.
A FILE is a means of communicating between a program and a book that has been opened via some channel.
The MOOD of a file may be read, write, char, bin, and opened.
transput procedures include: establish, create, open, associate, lock, close, scratch.
position enquires: char number, line number, page number.
layout routines include:
space, backspace, newline, newpage.
get good line, get good page, get good book, and PROC set=(REF FILE f, INT page,line,char)VOID:
A file has event routines. e.g. on logical file end, on physical file end, on page end, on line end, on format end, on value error, on char error.

formatted transput
""Formatted transput"" in ALGOL 68's transput has its own syntax and patterns (functions), with FORMATs embedded between two $ characters.Examples:

 printf (($2l""The sum is:""x, g(0)$, m + n)); ¢ prints the same as: ¢
 print ((new line, new line, ""The sum is:"", space, whole (m + n, 0))

par: Parallel processing
ALGOL 68 supports programming of parallel processing. Using the keyword PAR, a collateral clause is converted to a parallel clause, where the synchronisation of actions is controlled using semaphores. In A68G the parallel actions are mapped to threads when available on the hosting operating system. In A68S a different paradigm of parallel processing was implemented (see below).

PROC
    eat = VOID: ( muffins-:=1; print((""Yum!"",new line))),
    speak = VOID: ( words-:=1; print((""Yak..."",new line)));
 
INT muffins := 4, words := 8;
SEMA mouth = LEVEL 1;
 
PAR BEGIN
    WHILE muffins > 0 DO
        DOWN mouth;
        eat;
        UP mouth
    OD,
    WHILE words > 0 DO
        DOWN mouth;
        speak;
        UP mouth
    OD
END

Miscellaneous
For its technical intricacies, ALGOL 68 needs a cornucopia of methods to deny the existence of something:

SKIP, ""~"" or ""?""C – an undefined value always syntactically valid,
EMPTY – the only value admissible to VOID, needed for selecting VOID in a UNION,
VOID – syntactically like a MODE, but not one,
NIL or ""○"" – a name not denoting anything, of an unspecified reference mode,
() or specifically [1:0]INT – a vacuum is an empty array (here specifically of MODE []INT).
undefined – a standards reports procedure raising an exception in the runtime system.
ℵ – Used in the standards report to inhibit introspection of certain types. e.g. SEMA

The term NIL IS var always evaluates to TRUE for any variable (but see above for correct use of IS :/=:), whereas it is not known to which value a comparison x < SKIP evaluates for any integer x.
ALGOL 68 leaves intentionally undefined what happens in case of integer overflow, the integer bit representation, and the degree of numerical accuracy for floating point.
Both official reports included some advanced features that were not part of the standard language.  These were indicated with an ℵ and considered effectively private.  Examples include ""≮"" and ""≯"" for templates, the  OUTTYPE/INTYPE for crude duck typing, and the STRAIGHTOUT and STRAIGHTIN operators for ""straightening"" nested arrays and structures

Examples of use
Code sample
This sample program implements the Sieve of Eratosthenes to find all the prime numbers that are less than 100. NIL is the ALGOL 68 analogue of the null pointer in other languages. The notation x OF y accesses a member x of a STRUCT y.

BEGIN # Algol-68 prime number sieve, functional style #
  
  PROC error = (STRING s) VOID:
     (print(( newline, "" error: "", s, newline)); GOTO stop);
  PROC one to = (INT n) LIST:
     (PROC f = (INT m,n) LIST: (m>n | NIL | cons(m, f(m+1,n))); f(1,n));
  
  MODE LIST = REF NODE;
  MODE NODE = STRUCT (INT h, LIST t);
  PROC cons = (INT n, LIST l) LIST: HEAP NODE := (n,l);
  PROC hd   = (LIST l) INT: ( l IS NIL | error(""hd NIL""); SKIP | h OF l );
  PROC tl   = (LIST l) LIST: ( l IS NIL | error(""tl NIL""); SKIP | t OF l );
  PROC show = (LIST l) VOID: ( l ISNT NIL | print(("" "",whole(hd(l),0))); show(tl(l)));
  
  PROC filter = (PROC (INT) BOOL p, LIST l) LIST:
     IF l IS NIL THEN NIL
     ELIF p(hd(l)) THEN cons(hd(l), filter(p,tl(l)))
     ELSE filter(p, tl(l))
     FI;
  
  PROC sieve = (LIST l) LIST:
     IF l IS NIL THEN NIL
     ELSE
        PROC not multiple = (INT n) BOOL: n MOD hd(l) ~= 0;
        cons(hd(l), sieve( filter( not multiple, tl(l) )))
     FI;
  
  PROC primes = (INT n) LIST: sieve( tl( one to(n) ));
  
  show( primes(100) )
END

Operating systems written in ALGOL 68
Cambridge CAP computer – All procedures constituting the operating system were written in ALGOL 68C, although several other closely associated protected procedures, such as a paginator, are written in BCPL.
Eldon 3 – Developed at Leeds University for the ICL 1900 was written in ALGOL 68-R.
Flex machine – The hardware was custom and microprogrammable, with an operating system, (modular) compiler, editor, garbage collector and filing system all written in ALGOL 68RS. The command shell Curt was designed to access typed data similar to Algol-68 modes.
VME – S3 was the implementation language of the operating system VME. S3 was based on ALGOL 68 but with data types and operators aligned to those offered by the ICL 2900 Series.Note: The Soviet Era computers Эльбрус-1 (Elbrus-1) and Эльбрус-2 were created using high-level language Эль-76 (AL-76), rather than the traditional assembly. Эль-76 resembles Algol-68, The main difference is the dynamic binding types in Эль-76 supported at the hardware level. Эль-76 is used for application, job control, system programming.

Applications
Both ALGOL 68C and ALGOL 68-R are written in ALGOL 68, effectively making ALGOL 68 an application of itself. Other applications include:

ELLA – a hardware description language and support toolset. Developed by the Royal Signals and Radar Establishment during the 1980s and 1990s.
RAF Strike Command System – ""... 400K of error-free ALGOL 68-RT code was produced with three man-years of work. ...""

Libraries and APIs
NAG Numerical Libraries – a software library of numerical analysis routines. Supplied in ALGOL 68 during the 1980s.
TORRIX – a programming system for operations on vectors and matrices over arbitrary fields and of variable size by S. G. van der Meulen and M. Veldhorst.

Program representation
A feature of ALGOL 68, inherited from the ALGOL tradition, is its different representations. There is a representation language used to describe algorithms in printed work, a strict language (rigorously defined in the Report), and an official reference language intended to be used in compiler input. The examples contain BOLD typeface words, this is the STRICT language. ALGOL 68's reserved words are effectively in a different namespace from identifiers, and spaces are allowed in identifiers, so this next fragment is legal:

 INT a real int = 3 ;

The programmer who writes executable code does not always have an option of BOLD typeface or underlining in the code as this may depend on hardware and cultural issues. Different methods to denote these identifiers have been devised. This is called a stropping regime. For example, all or some of the following may be available programming representations:

 INT a real int = 3; # the STRICT language #
'INT'A REAL INT = 3; # QUOTE stropping style #
.INT A REAL INT = 3; # POINT stropping style #
 INT a real int = 3; # UPPER stropping style #
 int a_real_int = 3; # RES stropping style, there are 61 accepted reserved words #

All implementations must recognize at least POINT, UPPER and RES inside PRAGMAT sections. Of these, POINT and UPPER stropping are quite common, while RES stropping is a contradiction to the specification (as there are no reserved words). QUOTE (single apostrophe quoting) was the original recommendation, while matched apostrophe quoting, common in ALGOL 60, is not used much in ALGOL 68.The following characters were recommended for portability, and termed ""worthy characters"" in the Report on the Standard Hardware Representation of Algol 68 Archived 2014-01-02 at the Wayback Machine:

^ Worthy Characters: ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 ""#$%'()*+,-./:;<=>@[ ]_|This reflected a problem in the 1960s where some hardware didn't support lower-case, nor some other non-ASCII characters, indeed in the 1973 report it was written: ""Four worthy characters — ""|"", ""_"", ""["", and ""]"" — are often coded differently, even at installations which nominally use the same character set.""

Base characters: ""Worthy characters"" are a subset of ""base characters"".

Example of different program representations
ALGOL 68 allows for every natural language to define its own set of keywords Algol-68. As a result, programmers are able to write programs using keywords from their native language. Below is an example of a simple procedure that calculates ""the day following"", the code is in two languages: English and German.
 # Next day date - English variant #
 MODE DATE = STRUCT(INT day, STRING month, INT year);
 PROC the day following = (DATE x) DATE:
      IF day OF  x < length of month (month OF x, year OF x)
      THEN (day OF x + 1, month OF x, year OF x)
      ELIF month OF x = ""December""
      THEN (1, ""January"", year OF x + 1)
      ELSE (1, successor of month (month OF x), year OF x)
      FI;

 # Nachfolgetag - Deutsche Variante #
 MENGE DATUM = TUPEL(GANZ tag, WORT monat, GANZ jahr);
 FUNKTION naechster tag nach = (DATUM x) DATUM:
          WENN tag VON x < monatslaenge(monat VON x, jahr VON x)
          DANN (tag VON x + 1, monat VON x, jahr VON x)
          WENNABER monat VON x = ""Dezember""
          DANN (1, ""Januar"", jahr VON x + 1)
          ANSONSTEN (1, nachfolgemonat(monat VON x), jahr VON x)
          ENDEWENN;

Russian/Soviet example:
In English Algol68's case statement reads CASE ~ IN ~ OUT ~ ESAC, in Cyrillic this reads выб ~ в ~ либо ~ быв.

Revisions
Except where noted (with a superscript), the language described above is that of the ""Revised Report(r1)"".

The language of the unrevised report
The original language (As per the ""Final Report""r0) differs in syntax of the mode cast, and it had the feature of proceduring, i.e. coercing the value of a term into a procedure which evaluates the term. Proceduring would be intended to make evaluations lazy. The most useful application could have been the short-circuited evaluation of boolean operators. In:

OP ANDF = (BOOL a,PROC BOOL b)BOOL:(a | b | FALSE);
OP ORF = (BOOL a,PROC BOOL b)BOOL:(a | TRUE | b);

b is only evaluated if a is true.
As defined in ALGOL 68, it did not work as expected, for example in the code:

IF FALSE ANDF CO proc bool: CO ( print (""Should not be executed""); TRUE)
THEN ...

against the programmers naïve expectations the print would be executed as it is only the value of the elaborated enclosed-clause after ANDF that was procedured. Textual insertion of the commented-out PROC BOOL: makes it work.
Some implementations emulate the expected behaviour for this special case by extension of the language.
Before revision, the programmer could decide to have the arguments of a procedure evaluated serially instead of collaterally by using semicolons instead of commas (gommas).
For example in:

PROC test = (REAL a; REAL b) :...
...
test (x PLUS 1, x);

The first argument to test is guaranteed to be evaluated before the second, but in the usual:

PROC test = (REAL a, b) :...
...
test (x PLUS 1, x);

then the compiler could evaluate the arguments in whatever order it felt like.

Extension proposals from IFIP WG 2.1
After the revision of the report, some extensions to the language have been proposed to widen the applicability:

partial parametrisation (aka Currying): creation of functions (with fewer parameters) by specification of some, but not all parameters for a call, e.g. a function logarithm of two parameters, base and argument, could be specialised to natural, binary or decadic log,
module extension: for support of external linkage,  two mechanisms were proposed, bottom-up definition modules, a more powerful version of the facilities from ALGOL 68-R and top-down holes, similar to the ENVIRON and USING clauses from ALGOL 68C
mode parameters: for implementation of limited parametrical polymorphism (most operations on data structures like lists, trees or other data containers can be specified without touching the pay load).So far, only partial parametrisation has been implemented, in Algol 68 Genie.

True ALGOL 68s specification and implementation timeline
The S3 language that was used to write the ICL VME operating system and much other system software on the ICL 2900 Series was a direct derivative of Algol 68. However, it omitted many of the more complex features, and replaced the basic modes with a set of data types that mapped directly to the 2900 Series hardware architecture.

Implementation specific extensions
ALGOL 68R(R) from RRE was the first ALGOL 68 subset implementation, running on the ICL 1900. Based on the original language, the main subset restrictions were definition before use and no parallel processing. This compiler was popular in UK universities in the 1970s, where many computer science students learnt ALGOL 68 as their first programming language; the compiler was renowned for good error messages.
ALGOL 68RS(RS) from RSRE was a portable compiler system written in ALGOL 68RS (bootstrapped from ALGOL 68R), and implemented on a variety of systems including the ICL 2900/Series 39, Multics and DEC VAX/VMS. The language was based on the Revised Report, but with similar subset restrictions to ALGOL 68R. This compiler survives in the form of an Algol68-to-C compiler.
In ALGOL 68S(S) from Carnegie Mellon University the power of parallel processing was improved by adding an orthogonal extension, eventing. Any variable declaration containing keyword EVENT made assignments to this variable eligible for parallel evaluation, i.e. the right hand side was made into a procedure which was moved to one of the processors of the C.mmp multiprocessor system. Accesses to such variables were delayed after termination of the assignment.
Cambridge ALGOL 68C(C) was a portable compiler that implemented a subset of ALGOL 68, restricting operator definitions and omitting garbage collection, flexible rows and formatted transput.
Algol 68 Genie(G) by M. van der Veer is an ALGOL 68 implementation for today's computers and operating systems.
""Despite good intentions, a programmer may violate portability by inadvertently employing a local extension.  To guard against this, each implementation should provide a PORTCHECK pragmat option.  While this option is in force, the compiler prints a message for each construct that it recognizes as violating some portability constraint.""

Quotes
... The scheme of type composition adopted by C owes considerable debt to Algol 68, although it did not, perhaps, emerge in a form that Algol's adherents would approve of. The central notion I captured from Algol was a type structure based on atomic types (including structures), composed into arrays, pointers (references), and functions (procedures). Algol 68's concept of unions and casts also had an influence that appeared later. Dennis Ritchie Apr 1993.
... C does not descend from Algol 68 is true, yet there was influence, much of it so subtle that it is hard to recover even when I think hard. In particular, the union type (a late addition to C) does owe to A68, not in any details, but in the idea of having such a type at all. More deeply, the type structure in general and even, in some strange way, the declaration syntax (the type-constructor part) was inspired by A68. And yes, of course, ""long"". Dennis Ritchie, 18 June 1988
""Congratulations, your Master has done it"" – Niklaus Wirth
The more I see of it, the more unhappy I become – E. W. Dijkstra, 1968
[...] it was said that A68's popularity was inversely proportional to [...] the distance from Amsterdam – Guido van Rossum
[...] The best we could do was to send with it a minority report, stating our considered view that, ""... as a tool for the reliable creation of sophisticated programs, the language was a failure."" [...]  – C. A. R. Hoare in his Oct 1980 Turing Award Lecture
""[...] More than ever it will be required from an adequate programming tool that it assists, by structure, the programmer in the most difficult aspects of his job, viz. in the reliable creation of sophisticated programs. In this respect we fail to see how the language proposed here  is a significant step forward: on the contrary, we feel that its implicit view of the programmer's task is very much the same as, say, ten years ago. This forces upon us the conclusion that, regarded as a programming tool, the language must be regarded as obsolete. [...]"" 1968 Working Group minority report on 23 December 1968.

See also
References
Citations
Works cited
External links
Revised Report on the Algorithmic Language ALGOL 68 The official reference for users and implementors of the language (large pdf file, scanned from Algol Bulletin)
Revised Report on the Algorithmic Language ALGOL 68 Hyperlinked HTML version of the Revised Report
A Tutorial on Algol 68, by Andrew S. Tanenbaum, in Computing Surveys, Vol. 8, No. 2, June 1976, with Corrigenda (Vol. 9, No. 3, September 1977)
Algol 68 Genie – a GNU GPL Algol 68 compiler-interpreter
Open source ALGOL 68 implementations, on SourceForge
Algol68 Standard Hardware representation (.pdf) Archived 2014-01-02 at the Wayback Machine
Из истории создания компилятора с Алгол 68
Algol 68 – 25 Years in the USSR
Система программ динамической поддержки для транслятора с Алгол 68
C history with Algol68 heritage
McJones, Paul, ""Algol 68 implementations and dialects"", Software Preservation Group, Computer History Museum, 2011-07-05
Web enabled ALGOL 68 compiler for small experiments",692880,https://en.wikipedia.org/wiki/ALGOL_68
Apache Groovy,"Apache Groovy is a Java-syntax-compatible object-oriented programming language for the Java platform. It is both a static and dynamic language with features similar to those of Python, Ruby, and Smalltalk. It can be used as both a programming language and a scripting language for the Java Platform, is compiled to Java virtual machine (JVM) bytecode, and interoperates seamlessly with other Java code and libraries. Groovy uses a curly-bracket syntax similar to Java's. Groovy supports closures, multiline strings, and expressions embedded in strings. Much of Groovy's power lies in its AST transformations, triggered through annotations.
Groovy 1.0 was released on January 2, 2007, and Groovy 2.0 in July, 2012. Since version 2, Groovy can be compiled statically, offering type inference and performance near that of Java. Groovy 2.4 was the last major release under Pivotal Software's sponsorship which ended in March 2015. Groovy has since changed its governance structure to a Project Management Committee in the Apache Software Foundation.","Apache Groovy is a Java-syntax-compatible object-oriented programming language for the Java platform. It is both a static and dynamic language with features similar to those of Python, Ruby, and Smalltalk. It can be used as both a programming language and a scripting language for the Java Platform, is compiled to Java virtual machine (JVM) bytecode, and interoperates seamlessly with other Java code and libraries. Groovy uses a curly-bracket syntax similar to Java's. Groovy supports closures, multiline strings, and expressions embedded in strings. Much of Groovy's power lies in its AST transformations, triggered through annotations.
Groovy 1.0 was released on January 2, 2007, and Groovy 2.0 in July, 2012. Since version 2, Groovy can be compiled statically, offering type inference and performance near that of Java. Groovy 2.4 was the last major release under Pivotal Software's sponsorship which ended in March 2015. Groovy has since changed its governance structure to a Project Management Committee in the Apache Software Foundation.

History
James Strachan first talked about the development of Groovy on his blog in August 2003. In March 2004, Groovy was submitted to the JCP as JSR 241 and accepted by ballot. Several versions were released between 2004 and 2006. After the Java Community Process (JCP) standardization effort began, the version numbering changed, and a version called ""1.0"" was released on January 2, 2007. After various betas and release candidates numbered 1.1, on December 7, 2007, Groovy 1.1 Final was released and immediately renumbered as Groovy 1.5 to reflect the many changes made.
In 2007, Groovy won the first prize at JAX 2007 innovation award. In 2008, Grails, a Groovy web framework, won the second prize at JAX 2008 innovation award.In November 2008, SpringSource acquired the Groovy and Grails company (G2One). In August 2009 VMware acquired SpringSource.In April 2012, after eight years of inactivity, the Spec Lead changed the status of JSR 241 to dormant.Strachan had left the project silently a year before the Groovy 1.0 release in 2007. In Oct 2016, Strachan stated ""I still love groovy (jenkins pipelines are so groovy!), java, go, typescript and kotlin"".On July 2, 2012, Groovy 2.0 was released, which, among other new features, added static compiling and static type checking.
When the Pivotal Software joint venture was spun-off by EMC Corporation (EMC) and VMware in April 2013, Groovy and Grails formed part of its product portfolio. Pivotal ceased sponsoring Groovy and Grails from April 2015.
That same month, Groovy changed its governance structure from a Codehaus repository to a Project Management Committee (PMC) in the Apache Software Foundation via its incubator.
Groovy graduated from Apache's incubator and became a top-level project in November 2015.On February 7, 2020, Groovy 3.0 was released. Version 4.0 was released on January 25, 2022.

Features
Most valid Java files are also valid Groovy files. Although the two languages are similar, Groovy code can be more compact, because it does not need all the elements that Java needs. This makes it possible for Java programmers to learn Groovy gradually by starting with familiar Java syntax before acquiring more Groovy programming idioms.Groovy features not available in Java include both static and dynamic typing (with the keyword def), operator overloading, native syntax for lists and associative arrays (maps), native support for regular expressions, polymorphic iteration, string interpolation, added helper methods, and the safe navigation operator ?. to check automatically for null pointers (for example, variable?.method(), or variable?.field).Since version 2 Groovy also supports modularity (being able to ship only the needed jars according to the project needs, thus reducing the size of Groovy's library), type checking, static compiling, Project Coin syntax enhancements, multicatch blocks and ongoing performance enhancements using the invokedynamic instruction introduced in Java 7.Groovy provides native support for various markup languages such as XML and HTML, accomplished via an inline Document Object Model (DOM) syntax. This feature enables the definition and manipulation of many types of heterogeneous data assets with a uniform and concise syntax and programming methodology.Unlike Java, a Groovy source code file can be executed as an (uncompiled) script, if it contains code outside any class definition, if it is a class with a main method, or if it is a Runnable or GroovyTestCase. A Groovy script is fully parsed, compiled, and generated before executing (similar to Python and Ruby). This occurs under the hood, and the compiled version is not saved as an artifact of the process.

GroovyBeans, properties
GroovyBeans are Groovy's version of JavaBeans. Groovy implicitly generates getters and setters. In the following code, setColor(String color) and getColor() are implicitly generated. The last two lines, which appear to access color directly, are actually calling the implicitly generated methods.

Groovy offers simple, consistent syntax for handling lists and maps, reminiscent of Java's array syntax.

Prototype extension
Groovy offers support for prototype extension through ExpandoMetaClass, Extension Modules (only in Groovy 2), Objective-C-like Categories and DelegatingMetaClass.ExpandoMetaClass offers a domain-specific language (DSL) to express the changes in the class easily, similar to Ruby's open class concept:

Groovy's changes in code through prototyping are not visible in Java, since each attribute/method invocation in Groovy goes through the metaclass registry. The changed code can only be accessed from Java by going to the metaclass registry.
Groovy also allows overriding methods as getProperty(), propertyMissing() among others, enabling the developer to intercept calls to an object and specify an action for them, in a simplified aspect-oriented way. The following code enables the class java.lang.String to respond to the hex property:

The Grails framework uses metaprogramming extensively to enable GORM dynamic finders, like User.findByName('Josh') and others.

Dot and parentheses
Groovy's syntax permits omitting parentheses and dots in some situations. The following groovy code

can be written as

enabling the development of domain-specific languages (DSLs) that look like plain English.

Functional programming
Although Groovy is mostly an object-oriented language, it also offers functional programming features.

Closures
According to Groovy's documentation: ""Closures in Groovy work similar to a 'method pointer', enabling code to be written and run in a later point in time"". Groovy's closures support free variables, i.e. variables that have not been explicitly passed as a parameter to it, but exist in its declaration context, partial application (that it terms 'currying'), delegation, implicit, typed and untyped parameters.
When working on Collections of a determined type, the closure passed to an operation on the collection can be inferred:

A group of expressions can be written in a closure block without reference to an implementation and the responding object can be assigned at a later point using delegation:

Curry
Usually called partial application, this Groovy feature allows closures' parameters to be set to a default parameter in any of their arguments, creating a new closure with the bound value. Supplying one argument to the curry() method will fix argument one. Supplying N arguments will fix arguments 1 .. N.

Curry can also be used in the reverse direction (fixing the last N arguments) using rcurry().

Groovy also supports lazy evaluation, reduce/fold, infinite structures and immutability, among others.

JSON and XML processing
On JavaScript Object Notation (JSON) and XML processing, Groovy employs the Builder pattern, making the production of the data structure less verbose. For example, the following XML:

can be generated via the following Groovy code:

and also can be processed in a streaming way through StreamingMarkupBuilder. To change the implementation to JSON, the MarkupBuilder can be swapped to JsonBuilder.To parse it and search for a functional language, Groovy's findAll method can serve:

String interpolation
In Groovy, strings can be interpolated with variables and expressions by using GStrings:

GStrings containing variables and expressions must be declared using double quotes.
A complex expression must be enclosed in curly brackets. This prevents parts of it from being interpreted as belonging to the surrounding string instead of to the expression:

Expression evaluation can be deferred by employing arrow syntax:

Abstract syntax tree transformation
According to Groovy's own documentation, ""When the Groovy compiler compiles Groovy scripts and classes, at some point in the process, the source code will end up being represented in memory in the form of a Concrete Syntax Tree, then transformed into an Abstract Syntax Tree. The purpose of AST Transformations is to let developers hook into the compilation process to be able to modify the AST before it is turned into bytecode that will be run by the JVM. AST Transformations provides Groovy with improved compile-time metaprogramming capabilities allowing powerful flexibility at the language level, without a runtime performance penalty.""Examples of ASTs in Groovy are:

Category and Mixin transformation
Immutable AST Macro
Newify transformation
Singleton transformationamong others.
The testing framework Spock uses AST transformations to allow the programmer to write tests in a syntax not supported by Groovy, but the relevant code is then manipulated in the AST to valid code. An example of such a test is:

Traits
According to Groovy's documentation, ""Traits are a structural construct of the language that allows: composition of behaviors, runtime implementation of interfaces, behavior overriding, and compatibility with static type checking/compilation.""
Traits can be seen as interfaces carrying both default implementations and state. A trait is defined using the trait keyword:

Then, it can be used like a normal interface using the keyword implements:

Traits allow a wide range of abilities, from simple composition to testing.

Adoption
Notable examples of Groovy adoption include:

Adaptavist ScriptRunner, embeds a Groovy implementation to automate and extend Atlassian tools, in use by more than 20000 organisations around the world.
Apache OFBiz, the open-source enterprise resource planning (ERP) system, uses Groovy.
Eucalyptus, a cloud management system, uses a significant amount of Groovy.
Gradle is a popular build automation tool using Groovy.
LinkedIn uses Groovy and Grails for some of their subsystems.
LogicMonitor, a cloud-based monitoring platform, uses Groovy in script-based data sources.
Jenkins, a platform for continuous integration. With version 2, Jenkins includes a Pipeline plugin that allows for build instructions to be written in Groovy.
Liferay, uses groovy in their kaleo workflow
Sky.com uses Groovy and Grails to serve massive online media content.
SmartThings, an open platform for smart homes and the consumer Internet of Things, uses a security-oriented subset of Groovy
SoapUI provides Groovy as a language for webservice tests development.
Survata, a market research startup, uses Groovy and Grails.
The European Patent Office (EPO) developed a dataflow programming language in Groovy ""to leverage similarities in the processes for communicating with each individual country’s patent office, and transform them into a single, universal process.""
Though Groovy can be integrated into any JVM environment, the JBoss Seam framework provides Groovy, besides Java, as a development language, out of the box.
vCalc.com uses Groovy for all of the user defined mathematics in its math crowd-sourcing engine.
Wired.com uses Groovy and Grails for the Product Reviews standalone section of the website.
XWiki SAS uses Groovy as scripting language in their collaborative open-source product.

IDE support
Many integrated development environments (IDEs) and text editors support Groovy:

Android Studio, IDE used for making Android apps
Atom editor
Eclipse, through Groovy-Eclipse
Emacs, using the groovy-emacs-mode project's groovy-mode.
IntelliJ IDEA, Community Edition, Grails/Griffon in the Ultimate Edition only
JDeveloper, for use with Oracle ADF
jEdit, an advanced text editor for the Java platform
Kate, an advanced text editor for KDE supports Groovy and over 200 other file formats
NetBeans, since version 6.5
Notepad++, an advanced text editor for Microsoft Windows
Sublime Text, a cross platform text editor
TextMate
Visual Studio Code
UltraEdit, general purpose program editor

Dialects
There is one alternative implementation of Groovy:

Grooscript converts Groovy code to JavaScript code. Although Grooscript has some limitations compared to Apache Groovy, it can use domain classes in both the server and the client. Plugin support for Grails version 3.0 is provided, as well as online code conversions.

See also
Comparison of programming languages
Griffon (framework) – a desktop framework
Project Zero
Spock (testing framework)

References
Citations
Sources
External links
Official website 
Groovy at Curlie",508401,https://en.wikipedia.org/wiki/Apache_Groovy
APL (programming language),"APL (named after the book A Programming Language) is a programming language developed in the 1960s by Kenneth E. Iverson. Its central datatype is the multidimensional array. It uses a large range of special graphic symbols to represent most functions and operators, leading to very concise code. It has been an important influence on the development of concept modeling, spreadsheets, functional programming, and computer math packages. It has also inspired several other programming languages.","APL (named after the book A Programming Language) is a programming language developed in the 1960s by Kenneth E. Iverson. Its central datatype is the multidimensional array. It uses a large range of special graphic symbols to represent most functions and operators, leading to very concise code. It has been an important influence on the development of concept modeling, spreadsheets, functional programming, and computer math packages. It has also inspired several other programming languages.

History
Mathematical notation
A mathematical notation for manipulating arrays was developed by Kenneth E. Iverson, starting in 1957 at Harvard University. In 1960, he began work for IBM where he developed this notation with Adin Falkoff and published it in his book A Programming Language in 1962. The preface states its premise:

Applied mathematics is largely concerned with the design and analysis of explicit procedures for calculating the exact or approximate values of various functions. Such explicit procedures are called algorithms or programs. Because an effective notation for the description of programs exhibits considerable syntactic structure, it is called a programming language.

This notation was used inside IBM for short research reports on computer systems, such as the Burroughs B5000 and its stack mechanism when stack machines versus register machines were being evaluated by IBM for upcoming computers.
Iverson also used his notation in a draft of the chapter A Programming Language, written for a book he was writing with Fred Brooks, Automatic Data Processing, which would be published in 1963.In 1979, Iverson received the Turing Award for his work on APL.

Development into a computer programming language
As early as 1962, the first attempt to use the notation to describe a complete computer system happened after Falkoff discussed with William C. Carter his work to standardize the instruction set for the machines that later became the IBM System/360 family.
In 1963, Herbert Hellerman, working at the IBM Systems Research Institute, implemented a part of the notation on an IBM 1620 computer, and it was used by students in a special high school course on calculating transcendental functions by series summation. Students tested their code in Hellerman's lab. This implementation of a part of the notation was called Personalized Array Translator (PAT).In 1963, Falkoff, Iverson, and Edward H. Sussenguth Jr., all working at IBM, used the notation for a formal description of the IBM System/360 series machine architecture and functionality, which resulted in a paper published in IBM Systems Journal in 1964. After this was published, the team turned their attention to an implementation of the notation on a computer system. One of the motivations for this focus of implementation was the interest of John L. Lawrence who had new duties with Science Research Associates, an educational company bought by IBM in 1964. Lawrence asked Iverson and his group to help use the language as a tool to develop and use computers in education.After Lawrence M. Breed and Philip S. Abrams of Stanford University joined the team at IBM Research, they continued their prior work on an implementation programmed in FORTRAN IV for a part of the notation which had been done for the IBM 7090 computer running on the IBSYS operating system. This work was finished in late 1965 and later named IVSYS (for Iverson system). The basis of this implementation was described in detail by Abrams in a Stanford University Technical Report, ""An Interpreter for Iverson Notation"" in 1966. The academic aspect of this was formally supervised by Niklaus Wirth. Like Hellerman's PAT system earlier, this implementation did not include the APL character set but used special English reserved words for functions and operators. The system was later adapted for a time-sharing system and, by November 1966, it had been reprogrammed for the IBM System/360 Model 50 computer running in a time-sharing mode and was used internally at IBM.

Hardware
A key development in the ability to use APL effectively, before the wide use of cathode ray tube (CRT) terminals, was the development of a special IBM Selectric typewriter interchangeable typing element with all the special APL characters on it. This was used on paper printing terminal workstations using the Selectric typewriter and typing element mechanism, such as the IBM 1050 and IBM 2741 terminal. Keycaps could be placed over the normal keys to show which APL characters would be entered and typed when that key was struck. For the first time, a programmer could type in and see proper APL characters as used in Iverson's notation and not be forced to use awkward English keyword representations of them. Falkoff and Iverson had the special APL Selectric typing elements, 987 and 988, designed in late 1964, although no APL computer system was available to use them. Iverson cited Falkoff as the inspiration for the idea of using an IBM Selectric typing element for the APL character set.Many APL symbols, even with the APL characters on the Selectric typing element, still had to be typed in by over-striking two extant element characters. An example is the grade up character, which had to be made from a delta (shift-H) and a Sheffer stroke (shift-M). This was necessary because the APL character set was much larger than the 88 characters allowed on the typing element, even when letters were restricted to upper-case (capitals).

Commercial availability
The first APL interactive login and creation of an APL workspace was in 1966 by Larry Breed using an IBM 1050 terminal at the IBM Mohansic Labs near Thomas J. Watson Research Center, the home of APL, in Yorktown Heights, New York.IBM was chiefly responsible for introducing APL to the marketplace. The first publicly available version of APL was released in 1968 for the IBM 1130. IBM provided APL\1130 for free but without liability or support. It would run in as little as 8k 16-bit words of memory, and used a dedicated 1 megabyte hard disk.
APL gained its foothold on mainframe timesharing systems from the late 1960s through the early 1980s, in part because it would support multiple users on lower-specification systems that had no dynamic address translation hardware. Additional improvements in performance for selected IBM System/370 mainframe systems included the APL Assist Microcode in which some support for APL execution was included in the processor's firmware, as distinct from being implemented entirely by higher-level software. Somewhat later, as suitably performing hardware was finally growing available in the mid- to late-1980s, many users migrated their applications to the personal computer environment.
Early IBM APL interpreters for IBM 360 and IBM 370 hardware implemented their own multi-user management instead of relying on the host services, thus they were their own timesharing systems. First introduced for use at IBM in 1966, the APL\360 system was a multi-user interpreter. The ability to programmatically communicate with the operating system for information and setting interpreter system variables was done through special privileged ""I-beam"" functions, using both monadic and dyadic operations.In 1973, IBM released APL.SV, which was a continuation of the same product, but which offered shared variables as a means to access facilities outside of the APL system, such as operating system files. In the mid-1970s, the IBM mainframe interpreter was even adapted for use on the IBM 5100 desktop computer, which had a small CRT and an APL keyboard, when most other small computers of the time only offered BASIC. In the 1980s, the VSAPL program product enjoyed wide use with Conversational Monitor System (CMS), Time Sharing Option (TSO), VSPC, MUSIC/SP, and CICS users.
In 1973–1974, Patrick E. Hagerty directed the implementation of the University of Maryland APL interpreter for the 1100 line of the Sperry UNIVAC 1100/2200 series mainframe computers.  In 1974, student Alan Stebbens was assigned the task of implementing an internal function. Xerox APL was available from June 1975 for Xerox 560 and Sigma 6, 7, and 9 mainframes running CP-V and for Honeywell CP-6.In the 1960s and 1970s, several timesharing firms arose that sold APL services using modified versions of the IBM APL\360 interpreter. In North America, the better-known ones were IP Sharp Associates, Scientific Time Sharing Corporation (STSC), Time Sharing Resources (TSR), and The Computer Company (TCC). CompuServe also entered the market in 1978 with an APL Interpreter based on a modified version of Digital Equipment Corp and Carnegie Mellon's, which ran on DEC's KI and KL 36-bit machines. CompuServe's APL was available both to its commercial market and the consumer information service. With the advent first of less expensive mainframes such as the IBM 4300, and later the personal computer, by the mid-1980s, the timesharing industry was all but gone.
Sharp APL was available from IP Sharp Associates, first as a timesharing service in the 1960s, and later as a program product starting around 1979. Sharp APL was an advanced APL implementation with many language extensions, such as packages (the ability to put one or more objects into a single variable), a file system, nested arrays, and shared variables.
APL interpreters were available from other mainframe and mini-computer manufacturers also, notably Burroughs, Control Data Corporation (CDC), Data General, Digital Equipment Corporation (DEC), Harris, Hewlett-Packard (HP), Siemens, Xerox and others.
Garth Foster of Syracuse University sponsored regular meetings of the APL implementers' community at Syracuse's Minnowbrook Conference Center in Blue Mountain Lake, New York. In later years, Eugene McDonnell organized similar meetings at the Asilomar Conference Grounds near Monterey, California, and at Pajaro Dunes near Watsonville, California. The SIGAPL special interest group of the Association for Computing Machinery continues to support the APL community.

Microcomputers
On microcomputers, which became available from the mid-1970s onwards, BASIC became the dominant programming language. Nevertheless, some microcomputers provided APL instead – the first being the Intel 8008-based MCM/70 which was released in 1974 and which was primarily used in education. Another machine of this time was the VideoBrain Family Computer, released in 1977, which was supplied with its dialect of APL called APL/S.The Commodore SuperPET, introduced in 1981, included an APL interpreter developed by the University of Waterloo.In 1976, Bill Gates claimed in his Open Letter to Hobbyists that Microsoft Corporation was implementing APL for the Intel 8080 and Motorola 6800 but had ""very little incentive to make [it] available to hobbyists"" because of software piracy. It was never released.

APL2
Starting in the early 1980s, IBM APL development, under the leadership of Jim Brown, implemented a new version of the APL language that contained as its primary enhancement the concept of nested arrays, where an array can contain other arrays, and new language features which facilitated integrating nested arrays into program workflow. Ken Iverson, no longer in control of the development of the APL language, left IBM and joined I. P. Sharp Associates, where one of his major contributions was directing the evolution of Sharp APL to be more in accord with his vision. APL2 was first released for CMS and TSO in 1984. The APL2 Workstation edition (Windows, OS/2, AIX, Linux, and Solaris) followed later.As other vendors were busy developing APL interpreters for new hardware, notably Unix-based microcomputers, APL2 was almost always the standard chosen for new APL interpreter developments. Even today, most APL vendors or their users cite APL2 compatibility as a selling point for those products. IBM cites its use for problem solving, system design, prototyping, engineering and scientific computations, expert systems, for teaching mathematics and other subjects, visualization and database access.

Modern implementations
Various implementations of APL by APLX, Dyalog, et al., include extensions for object-oriented programming, support for .NET, XML-array conversion primitives, graphing, operating system interfaces, and lambda calculus expressions. Freeware versions include GNU APL for Linux and NARS2000 for Windows (which runs on Linux under Wine). Both of these are fairly complete versions of APL2 with various language extensions.

Derivative languages
APL has formed the basis of, or influenced, the following languages:
A and A+, an alternative APL, the latter with graphical extensions.
FP, a functional programming language.
Ivy, an interpreter for an APL-like language developed by Rob Pike, and which uses ASCII as input.
J, which was also designed by Iverson, and which uses ASCII with digraphs instead of special symbols.
K, a proprietary variant of APL developed by Arthur Whitney.
MATLAB, a numerical computation tool.
Nial, a high-level array programming language with a functional programming notation.
Polymorphic Programming Language, an interactive, extensible language with a similar base language.
S, a statistical programming language (usually now seen in the open-source version known as R).
Snap!, a low-code block-based programming language, born as an extended reimplementation of Scratch
Speakeasy, a numerical computing interactive environment.
Wolfram Language, the programming language of Mathematica.

Language characteristics
Character set
APL has been criticized and praised for its choice of a unique, non-standard character set. In the 1960s and 1970s, few terminal devices or even displays could reproduce the APL character set. The most popular ones employed the IBM Selectric print mechanism used with a special APL type element. One of the early APL line terminals (line-mode operation only, not full screen) was the Texas Instruments TI Model 745 (c. 1977) with the full APL character set which featured half and full duplex telecommunications modes, for interacting with an APL time-sharing service or remote mainframe to run a remote computer job, called an RJE.
Over time, with the universal use of high-quality graphic displays, printing devices and Unicode support, the APL character font problem has largely been eliminated. However, entering APL characters requires the use of input method editors, keyboard mappings, virtual/on-screen APL symbol sets, or easy-reference printed keyboard cards which can frustrate beginners accustomed to other programming languages. With beginners who have no prior experience with other programming languages, a study involving high school students found that typing and using APL characters did not hinder the students in any measurable way.In defense of APL, it requires fewer characters to type, and keyboard mappings become memorized over time. Special APL keyboards are also made and in use today, as are freely downloadable fonts for operating systems such as Microsoft Windows. The reported productivity gains assume that one spends enough time working in the language to make it worthwhile to memorize the symbols, their semantics, and keyboard mappings, not to mention a substantial number of idioms for common tasks.

Design
Unlike traditionally structured programming languages, APL code is typically structured as chains of monadic or dyadic functions, and operators acting on arrays. APL has many nonstandard primitives (functions and operators) that are indicated by a single symbol or a combination of a few symbols. All primitives are defined to have the same precedence, and always associate to the right. Thus, APL is read or best understood from right-to-left.
Early APL implementations (c. 1970 or so) had no programming loop-flow control structures, such as do or while loops, and if-then-else constructs. Instead, they used array operations, and use of structured programming constructs was often not necessary, since an operation could be performed on a full array in one statement. For example, the iota function (ι) can replace for-loop iteration: ιN when applied to a scalar positive integer yields a one-dimensional array (vector), 1 2 3 ... N. More recent implementations of APL generally include comprehensive control structures, so that data structure and program control flow can be clearly and cleanly separated.
The APL environment is called a workspace. In a workspace the user can define programs and data, i.e., the data values exist also outside the programs, and the user can also manipulate the data without having to define a program. In the examples below, the APL interpreter first types six spaces before awaiting the user's input. Its own output starts in column one.

The user can save the workspace with all values, programs, and execution status.
APL uses a set of non-ASCII symbols, which are an extension of traditional arithmetic and algebraic notation. Having single character names for single instruction, multiple data (SIMD) vector functions is one way that APL enables compact formulation of algorithms for data transformation such as computing Conway's Game of Life in one line of code. In nearly all versions of APL, it is theoretically possible to express any computable function in one expression, that is, in one line of code.Due to the unusual character set, many programmers use special keyboards with APL keytops to write APL code. Although there are various ways to write APL code using only ASCII characters, in practice it is almost never done. (This may be thought to support Iverson's thesis about notation as a tool of thought.) Most if not all modern implementations use standard keyboard layouts, with special mappings or input method editors to access non-ASCII characters. Historically, the APL font has been distinctive, with uppercase italic alphabetic characters and upright numerals and symbols. Most vendors continue to display the APL character set in a custom font.
Advocates of APL claim that the examples of so-called write-only code (badly written and almost incomprehensible code) are almost invariably examples of poor programming practice or novice mistakes, which can occur in any language. Advocates also claim that they are far more productive with APL than with more conventional computer languages, and that working software can be implemented in far less time and with far fewer programmers than using other technology.They also may claim that because it is compact and terse, APL lends itself well to larger-scale software development and complexity, because the number of lines of code can be reduced greatly. Many APL advocates and practitioners also view standard programming languages such as COBOL and Java as being comparatively tedious. APL is often found where time-to-market is important, such as with trading systems.

Terminology
APL makes a clear distinction between functions and operators. Functions take arrays (variables or constants or expressions) as arguments, and return arrays as results. Operators (similar to higher-order functions) take functions or arrays as arguments, and derive related functions. For example, the sum function is derived by applying the reduction operator to the addition function. Applying the same reduction operator to the maximum function (which returns the larger of two numbers) derives a function which returns the largest of a group (vector) of numbers. In the J language, Iverson substituted the terms verb for function and adverb or conjunction for operator.
APL also identifies those features built into the language, and represented by a symbol, or a fixed combination of symbols, as primitives. Most primitives are either functions or operators. Coding APL is largely a process of writing non-primitive functions and (in some versions of APL) operators. However a few primitives are considered to be neither functions nor operators, most noticeably assignment.
Some words used in APL literature have meanings that differ from those in both mathematics and the generality of computer science.

Syntax
APL has explicit representations of functions, operators, and syntax, thus providing a basis for the clear and explicit statement of extended facilities in the language, and tools to experiment on them.

Examples
Hello, world
This displays ""Hello, world"":

A design theme in APL is to define default actions in some cases that would produce syntax errors in most other programming languages.
The 'Hello, world' string constant above displays, because display is the default action on any expression for which no action is specified explicitly (e.g. assignment, function parameter).

Exponentiation
Another example of this theme is that exponentiation in APL is written as 2*3, which indicates raising 2 to the power 3 (this would be written as 2^3 or 2**3 in some languages, or relegated to a function call such as pow(2, 3); in others). Many languages use * to signify multiplication, as in 2*3, but APL chooses to use 2×3. However, if no base is specified (as with the statement *3 in APL, or ^3 in other languages), most programming languages one would see this as a syntax error. APL, however, assumes the missing base to be the natural logarithm constant e, and interprets *3 as 2.71828*3.

Simple statistics
Suppose that X is an array of numbers. Then (+/X)÷⍴X gives its average. Reading right-to-left, ⍴X gives the number of elements in X, and since ÷ is a dyadic operator, the term to its left is required as well. It is surrounded by parentheses since otherwise X would be taken (so that the summation would be of X÷⍴X—each element of X divided by the number of elements in X), and +/X gives the sum of the elements of X. Building on this, the following expression computes standard deviation: 
Naturally, one would define this expression as a function for repeated use rather than rewriting it each time. Further, since assignment is an operator, it can appear within an expression, so the following would place suitable values into T, AV and SD:

Pick 6 lottery numbers
This following immediate-mode expression generates a typical set of Pick 6 lottery numbers: six pseudo-random integers ranging from 1 to 40, guaranteed non-repeating, and displays them sorted in ascending order:

The above does a lot, concisely, although it may seem complex to a new APLer. It combines the following APL functions (also called primitives and glyphs):

The first to be executed (APL executes from rightmost to leftmost) is dyadic function ? (named deal when dyadic) that returns a vector consisting of a select number (left argument: 6 in this case) of random integers ranging from 1 to a specified maximum (right argument: 40 in this case), which, if said maximum ≥ vector length, is guaranteed to be non-repeating; thus, generate/create 6 random integers ranging from 1 to 40.
This vector is then assigned (←) to the variable x, because it is needed later.
This vector is then sorted in ascending order by a monadic ⍋ function, which has as its right argument everything to the right of it up to the next unbalanced close-bracket or close-parenthesis. The result of ⍋ is the indices that will put its argument into ascending order.
Then the output of ⍋ is used to index the variable x, which we saved earlier for this purpose, thereby selecting its items in ascending sequence.Since there is no function to the left of the left-most x to tell APL what to do with the result, it simply outputs it to the display (on a single line, separated by spaces) without needing any explicit instruction to do that.
? also has a monadic equivalent called roll, which simply returns one random integer between 1 and its sole operand [to the right of it], inclusive. Thus, a role-playing game program might use the expression ?20 to roll a twenty-sided die.

Prime numbers
The following expression finds all prime numbers from 1 to R. In both time and space, the calculation complexity is O(R2){\displaystyle O(R^{2})\,\!} (in Big O notation).

Executed from right to left, this means:

Iota ⍳ creates a vector containing integers from 1 to R (if R= 6 at the start of the program, ⍳R is 1 2 3 4 5 6)
Drop first element of this vector (↓ function), i.e., 1. So 1↓⍳R is 2 3 4 5 6
Set R to the new vector (←, assignment primitive), i.e., 2 3 4 5 6
The / replicate operator is dyadic (binary) and the interpreter first evaluates its left argument (fully in parentheses):
Generate outer product of R multiplied by R, i.e., a matrix that is the multiplication table of R by R (°.× operator), i.e.,Build a vector the same length as R with 1 in each place where the corresponding number in R is in the outer product matrix (∈, set inclusion or element of or Epsilon operator), i.e., 0 0 1 0 1
Logically negate (not) values in the vector (change zeros to ones and ones to zeros) (∼, logical not or Tilde operator), i.e., 1 1 0 1 0
Select the items in R for which the corresponding element is 1 (/ replicate operator), i.e., 2 3 5(Note, this assumes the APL origin is 1, i.e., indices start with 1. APL can be set to use 0 as the origin, so that ι6 is 0 1 2 3 4 5, which is convenient for some calculations.)

Sorting
The following expression sorts a word list stored in matrix X according to word length:

Game of Life
The following function ""life"", written in Dyalog APL, takes a Boolean matrix and calculates the new generation according to Conway's Game of Life. It demonstrates the power of APL to implement a complex algorithm in very little code, but understanding it requires some advanced knowledge of APL (as the same program would in many languages).

HTML tags removal
In the following example, also Dyalog, the first line assigns some HTML code to a variable txt and then uses an APL expression to remove all the HTML tags (explanation):

Naming
APL derives its name from the initials of Iverson's book A Programming Language, even though the book describes Iverson's mathematical notation, rather than the implemented programming language described in this article. The name is used only for actual implementations, starting with APL\360.
Adin Falkoff coined the name in 1966 during the implementation of APL\360 at IBM:

As I walked by the office the three students shared, I could hear sounds of an argument going on. I poked my head in the door, and Eric asked me, ""Isn't it true that everyone knows the notation we're using is called APL?"" I was sorry to have to disappoint him by confessing that I had never heard it called that. Where had he got the idea it was well known? And who had decided to call it that? In fact, why did it have to be called anything? Quite a while later I heard how it was named. When the implementation effort started in June of 1966, the documentation effort started, too. I suppose when they had to write about ""it"", Falkoff and Iverson realized that they would have to give ""it"" a name. There were probably many suggestions made at the time, but I have heard of only two. A group in SRA in Chicago which was developing instructional materials using the notation was in favor of the name ""Mathlab"". This did not catch on. Another suggestion was to call it ""Iverson's Better Math"" and then let people coin the appropriate acronym. This was deemed facetious.
Then one day Adin Falkoff walked into Ken's office and wrote ""A Programming Language"" on the board, and underneath it the acronym ""APL"". Thus it was born. It was just a week or so after this that Eric Iverson asked me his question, at a time when the name hadn't yet found its way the thirteen miles up the Taconic Parkway from IBM Research to IBM Mohansic.
APL is occasionally re-interpreted as Array Programming Language or Array Processing Language, thereby making APL into a backronym.

Logo
There has always been cooperation between APL vendors, and joint conferences were held on a regular basis from 1969 until 2010. At such conferences, APL merchandise was often handed out, featuring APL motifs or collection of vendor logos. Common were apples (as a pun on the similarity in pronunciation of apple and APL) and the code snippet ⍺*⎕ which are the symbols produced by the classic APL keyboard layout when holding the APL modifier key and typing ""APL"".
Despite all these community efforts, no universal vendor-agnostic logo for the programming language emerged. As popular programming languages increasingly have established recognisable logos, Fortran getting one in 2020, British APL Association launched a campaign in the second half of 2021, to establish such a logo for APL, and after a community election and multiple rounds of feedback, a logo was chosen in May 2022.

Use
APL is used for many purposes including financial and insurance applications, artificial intelligence,neural networks
and robotics. It has been argued that APL is a calculation tool and not a programming language; its symbolic nature and array capabilities have made it popular with domain experts and data scientists who do not have or require the skills of a computer programmer.APL is well suited to image manipulation and computer animation, where graphic transformations can be encoded as matrix multiplications. One of the first commercial computer graphics houses, Digital Effects, produced an APL graphics product named Visions, which was used to create television commercials and animation for the 1982 film Tron. Latterly, the Stormwind boating simulator uses APL to implement its core logic, its interfacing to the rendering pipeline middleware and a major part of its physics engine.Today, APL remains in use in a wide range of commercial and scientific applications, for example
investment management,asset management,health care,
and DNA profiling.

Notable implementations
APL\360
The first implementation of APL using recognizable APL symbols was APL\360 which ran on the IBM System/360, and was completed in November 1966 though at that time remained in use only within IBM. In 1973 its implementors, Larry Breed, Dick Lathwell and Roger Moore, were awarded the Grace Murray Hopper Award from the Association for Computing Machinery (ACM). It was given ""for their work in the design and implementation of APL\360, setting new standards in simplicity, efficiency, reliability and response time for interactive systems.""In 1975, the IBM 5100 microcomputer offered APL\360 as one of two built-in ROM-based interpreted languages for the computer, complete with a keyboard and display that supported all the special symbols used in the language.Significant developments to APL\360 included CMS/APL, which made use of the virtual storage capabilities of CMS and APLSV, which introduced shared variables, system variables and system functions. It was subsequently ported to the IBM System/370 and VSPC platforms until its final release in 1983, after which it was replaced by APL2.

APL\1130
In 1968, APL\1130 became the first publicly available APL system, created by IBM for the IBM 1130. It became the most popular IBM Type-III Library software that IBM released.

APL*Plus and Sharp APL
APL*Plus and Sharp APL are versions of APL\360 with added business-oriented extensions such as data formatting and facilities to store APL arrays in external files. They were jointly developed by two companies, employing various members of the original IBM APL\360 development team.The two companies were I. P. Sharp Associates (IPSA), an APL\360 services company formed in 1964 by Ian Sharp, Roger Moore and others, and STSC, a time-sharing and consulting service company formed in 1969 by Lawrence Breed and others. Together the two developed APL*Plus and thereafter continued to work together but develop APL separately as APL*Plus and Sharp APL. STSC ported APL*Plus to many platforms with versions being made for the VAX 11, PC and UNIX, whereas IPSA took a different approach to the arrival of the personal computer and made Sharp APL available on this platform using additional PC-XT/360 hardware. In 1993, Soliton Incorporated was formed to support Sharp APL and it developed Sharp APL into SAX (Sharp APL for Unix). As of 2018, APL*Plus continues as APL2000 APL+Win.
In 1985, Ian Sharp, and Dan Dyer of STSC, jointly received the Kenneth E. Iverson Award for Outstanding Contribution to APL.

APL2
APL2 was a significant re-implementation of APL by IBM which was developed from 1971 and first released in 1984. It provides many additions to the language, of which the most notable is nested (non-rectangular) array support. The entire APL2 Products and Services Team was awarded the Iverson Award in 2007.In 2021, IBM sold APL2 to Log-On Software, who develop and sell the product as Log-On APL2.

APLGOL
In 1972, APLGOL was released as an experimental version of APL that added structured programming language constructs to the language framework. New statements were added for interstatement control, conditional statement execution, and statement structuring, as well as statements to clarify the intent of the algorithm. It was implemented for Hewlett-Packard in 1977.

Dyalog APL
Dyalog APL was first released by British company Dyalog Ltd. in 1983 and, as of 2018, is available for AIX, Linux (including on the Raspberry Pi), macOS and Microsoft Windows platforms. It is based on APL2, with extensions to support object-oriented programming, functional programming, and tacit programming. Licences are free for personal/non-commercial use.In 1995, two of the development team – John Scholes and Peter Donnelly – were awarded the Iverson Award for their work on the interpreter. Gitte Christensen and Morten Kromberg were joint recipients of the Iverson Award in 2016.

NARS2000
NARS2000 is an open-source APL interpreter written by Bob Smith, a prominent APL developer and implementor from STSC in the 1970s and 1980s. NARS2000 contains advanced features and new datatypes and runs natively on Microsoft Windows, and other platforms under Wine. It is named after a development tool from the 1980s, NARS (Nested Arrays Research System).

APLX
APLX is a cross-platform dialect of APL, based on APL2 and with several extensions, which was first released by British company MicroAPL in 2002. Although no longer in development or on commercial sale it is now available free of charge from Dyalog.

York APL
York APL was developed at the York University, Ontario around 1968, running on IBM 360 mainframes. One notable difference between it and APL\360 was that it defined the ""shape"" (ρ) of a scalar as 1 whereas APL\360 defined it as the more mathematically correct 0 — this made it easier to write functions that acted the same with scalars and vectors.

GNU APL
GNU APL is a free implementation of Extended APL as specified in ISO/IEC 13751:2001 and is thus an implementation of APL2. It runs on Linux, macOS, several BSD dialects, and on Windows (either using Cygwin for full support of all its system functions or as a native 64-bit Windows binary with some of its system functions missing). GNU APL uses Unicode internally and can be scripted. It was written by Jürgen Sauermann.Richard Stallman, founder of the GNU Project, was an early adopter of APL, using it to write a text editor as a high school student in the summer of 1969.

Interpretation and compilation of APL
APL is traditionally an interpreted language, having language characteristics such as weak variable typing not well suited to compilation. However, with arrays as its core data structure it provides opportunities for performance gains through parallelism, parallel computing, massively parallel applications, and very-large-scale integration (VLSI), and from the outset APL has been regarded as a high-performance language – for example, it was noted for the speed with which it could perform complicated matrix operations ""because it operates on arrays and performs operations like matrix inversion internally"".Nevertheless, APL is rarely purely interpreted and compilation or partial compilation techniques that are, or have been, used include the following:

Idiom recognition
Most APL interpreters support idiom recognition and evaluate common idioms as single operations. For example, by evaluating the idiom BV/⍳⍴A as a single operation (where BV is a Boolean vector and A is an array), the creation of two intermediate arrays is avoided.

Optimised bytecode
Weak typing in APL means that a name may reference an array (of any datatype), a function or an operator. In general, the interpreter cannot know in advance which form it will be and must therefore perform analysis, syntax checking etc. at run-time. However, in certain circumstances, it is possible to deduce in advance what type a name is expected to reference and then generate bytecode which can be executed with reduced run-time overhead. This bytecode can also be optimised using compilation techniques such as constant folding or common subexpression elimination. The interpreter will execute the bytecode when present and when any assumptions which have been made are met. Dyalog APL includes support for optimised bytecode.

Compilation
Compilation of APL has been the subject of research and experiment since the language first became available; the first compiler is considered to be the Burroughs APL-700 which was released around 1971. In order to be able to compile APL, language limitations have to be imposed. APEX is a research APL compiler which was written by Robert Bernecky and is available under the GNU Public License.The STSC APL Compiler is a hybrid of a bytecode optimiser and a compiler – it enables compilation of functions to machine code provided that its sub-functions and globals are declared, but the interpreter is still used as a runtime library and to execute functions which do not meet the compilation requirements.

Standards
APL has been standardized by the American National Standards Institute (ANSI) working group X3J10 and International Organization for Standardization (ISO) and International Electrotechnical Commission (IEC), ISO/IEC Joint Technical Committee 1 Subcommittee 22 Working Group 3. The Core APL language is specified in ISO 8485:1989, and the Extended APL language is specified in ISO/IEC 13751:2001.

References
Further reading
An APL Machine (1970 Stanford doctoral dissertation by Philip Abrams)
A Personal History Of APL Archived 2023-11-07 at the Wayback Machine (1982 article by Michael S. Montalbano)
McIntyre, Donald B. (1991). ""Language as an intellectual tool: From hieroglyphics to APL"" (PDF). IBM Systems Journal. 30 (4): 554–581. doi:10.1147/sj.304.0554. Archived from the original (PDF) on May 4, 2006.
Iverson, Kenneth E. (1991). ""A Personal view of APL"" (PDF). IBM Systems Journal. 30 (4): 582–593. doi:10.1147/sj.304.0582. Archived from the original (PDF) on February 27, 2008.
A Programming Language by Kenneth E. Iverson
APL in Exposition by Kenneth E. Iverson
Brooks, Frederick P.; Kenneth Iverson (1965). Automatic Data Processing, System/360 Edition. ISBN 0-471-10605-4.
Askoolum, Ajay (August 2006). System Building with APL + Win. Wiley. ISBN 978-0-470-03020-2.
Falkoff, Adin D.; Iverson, Kenneth E.; Sussenguth, Edward H. (1964). ""A Formal Description of System/360"" (PDF). IBM Systems Journal. 3 (2): 198–261. doi:10.1147/sj.32.0198. Archived from the original (PDF) on February 27, 2008.
Wexelblat, Richard L, ed. (1981). ""XIV"". History of Programming Languages: Proceedings of the History of Programming Languages Conference, Los Angeles, Calif., June 1-3, 1978. ISBN 978-0127450407.
Banon, Gerald Jean Francis (1989). Bases da Computacao Grafica. Rio de Janeiro: Campus. p. 141.
LePage, Wilbur R. (1978). Applied A.P.L. Programming. Prentice Hall.
Mougin, Philippe; Ducasse, Stephane (November 2003). ""OOPAL: Integrating array programming in object-oriented programming"" (PDF). ACM SIGPLAN Notices. 38 (11): 65–77. doi:10.1145/949343.949312. Archived from the original (PDF) on November 14, 2006.
An Introduction to Object Oriented Programming For APL Programmers (PDF). Dyalog Limited. September 2006. Archived from the original (PDF) on October 4, 2007.
Shustek, Len (October 10, 2012). ""The APL Programming Language Source Code"". Computer History Museum (CHM). Archived from the original on September 6, 2017. Retrieved September 6, 2017.
Svoboda, Antonín; White, Donnamaie E. (2016) [2012, 1985, 1979-08-01]. Advanced Logical Circuit Design Techniques (PDF) (retyped electronic reissue ed.). Garland STPM Press (original issue) / WhitePubs Enterprises, Inc. (reissue). ISBN 978-0-8240-7014-4. LCCN 78-31384. Archived (PDF) from the original on 2017-04-14. Retrieved 2017-04-15. [1] [2]

Video
The Origins of APL on YouTube – a 1974 talk show style interview with the original developers of APL.
APL demonstration on YouTube – a 1975 live demonstration of APL by Professor Bob Spence, Imperial College London.
Conway's Game Of Life in APL on YouTube – a 2009 tutorial by John Scholes of Dyalog Ltd. which implements Conway's Game of Life in a single line of APL.
50 Years of APL on YouTube – a 2009 introduction to APL by Graeme Robertson.

External links
Online resources
TryAPL.org, an online APL primer
APL at Curlie
APL2C, a source of links to APL compilers",1451,https://en.wikipedia.org/wiki/APL_(programming_language)
AppleScript,"AppleScript is a scripting language created by Apple Inc. that facilitates automated control over scriptable Mac applications. First introduced in System 7, it is currently included in all versions of macOS as part of a package of system automation tools. The term ""AppleScript"" may refer to the language itself, to an individual script written in the language, or, informally, to the macOS Open Scripting Architecture that underlies the language.","AppleScript is a scripting language created by Apple Inc. that facilitates automated control over scriptable Mac applications. First introduced in System 7, it is currently included in all versions of macOS as part of a package of system automation tools. The term ""AppleScript"" may refer to the language itself, to an individual script written in the language, or, informally, to the macOS Open Scripting Architecture that underlies the language.

Overview
AppleScript is primarily a scripting language developed by Apple to do inter-application communication (IAC) using Apple events. AppleScript is related to, but different from, Apple events. Apple events are designed to exchange data between and control other applications in order to automate repetitive tasks.
AppleScript has some processing abilities of its own, in addition to sending and receiving Apple events to applications. AppleScript can do basic calculations and text processing, and is extensible, allowing the use of scripting additions that add new functions to the language. Mainly, however, AppleScript relies on the functionality of applications and processes to handle complex tasks. As a structured command language, AppleScript can be compared to Unix shells, the Microsoft Windows Script Host, or IBM REXX but it is distinct from all three. Essential to its functionality is the fact that Macintosh applications publish ""dictionaries"" of addressable objects and operations.
AppleScript has some elements of procedural programming, object-oriented programming (particularly in the construction of script objects), and natural language programming tendencies in its syntax, but does not strictly conform to any of these programming paradigms.: xxvi

History
In the late 1980s Apple considered using HyperCard's HyperTalk scripting language as the standard language for end-user development across the company and within its classic Mac OS operating system, and for interprocess communication between Apple and non-Apple products. HyperTalk could be used by novices to program a HyperCard stack. Apple engineers recognized that a similar, but more object-oriented scripting language could be designed to be used with any application, and the AppleScript project was born as a spin-off of a research effort to modernize the Macintosh as a whole and finally became part of System 7.AppleScript was released in October 1993 as part of System 7.1.1 (System 7 Pro, the first major upgrade to System 7). QuarkXPress (ver. 3.2) was one of the first major software applications that supported AppleScript. This in turn led to AppleScript being widely adopted within the publishing and prepress world, often tying together complex workflows. This was a key factor in retaining the Macintosh's dominant position in publishing and prepress, even after QuarkXpress and other publishing applications were ported to Microsoft Windows.
After some uncertainty about the future of AppleScript on Apple's next generation OS, the move to Mac OS X (around 2002) and its Cocoa frameworks greatly increased the usefulness and flexibility of AppleScript. Cocoa applications allow application developers to implement basic scriptability for their apps with minimal effort, broadening the number of applications that are directly scriptable. At the same time, the shift to the Unix underpinnings and AppleScript's ability to run Unix commands directly, with the do shell script command, allowed AppleScripts much greater control over the operating system itself.: 863  AppleScript Studio, released with Mac OS X 10.2 as part of Xcode, and later AppleScriptObjC framework, released in Mac OS X 10.6, allowed users to build Cocoa applications using AppleScript.: 969 In a 2006 article, Macworld included AppleScript among its rankings of Apple's 30 most significant products to date, placing it at #17.In a 2013 article for Macworld, veteran Mac software developer and commentator John Gruber concluded his reflection on ""the unlikely persistence of AppleScript"" by noting: ""In theory, AppleScript could be much better; in practice, though, it's the best thing we have that works. It exemplifies the Mac's advantages over iOS for tinkerers and advanced users.""In October 2016, longtime AppleScript product manager and automation evangelist Sal Soghoian left Apple when his position was eliminated ""for business reasons"". Veterans in the Mac community such as John Gruber and Andy Ihnatko generally responded with concern, questioning Apple's commitment to the developer community and pro users. Apple senior vice president of software engineering Craig Federighi responded in an email saying that ""We have every intent to continue our support for the great automation technologies in macOS!"", though Jeff Gamet at The Mac Observer opined that it did little to assuage his doubt about the future of Apple automation in general and AppleScript in particular. For the time being, AppleScript remains one component of macOS automation technologies, along with Automator, Shortcuts, Services, and shell scripting.

Basic concepts
AppleScript was designed to be used as an accessible end-user scripting language, offering users an intelligent mechanism to control applications, and to access and modify data and documents. AppleScript uses Apple events, a set of standardized data formats that the Macintosh operating system uses to send information to applications, roughly analogous to sending XPath queries over XML-RPC in the world of web services.: xxvi  Apple events allow a script to work with multiple applications simultaneously, passing data between them so that complex tasks can be accomplished without human interaction. For example, an AppleScript to create a simple web gallery might do the following:

Open a photo in a photo-editing application (by sending that application an Open File Apple event).
Tell the photo-editing application to manipulate the image (e.g. reduce its resolution, add a border, add a photo credit)
Tell the photo-editing application to save the changed image in a file in some different folder (by sending that application a Save and/or Close Apple event).
Send the new file path (via another Apple event) to a text editor or web editor application.
Tell that editor application to write a link for the photo into an HTML file.
Repeat the above steps for an entire folder of images (hundreds or even thousands of photos).
Upload the HTML file and folder of revised photos to a website, by sending Apple events to a graphical FTP client, by using built-in AppleScript commands, or by sending Apple events to Unix FTP utilities.For the user, hundreds or thousands of steps in multiple applications have been reduced to the single act of running the script, and the task is accomplished in much less time and with no possibility of random human error. A large complex script could be developed to run only once, while other scripts are used again and again.
An application's scriptable elements are visible in the application's Scripting Dictionary (distributed as part of the application), which can be viewed in any script editor. Elements are generally grouped into suites, according to loose functional relationships between them. There are two basic kinds of elements present in any suite: classes and commands.

Classes are scriptable objects—for example, a text editing application will almost certainly have classes for windows, documents, and texts—and these classes will have properties that can be changed (window size, document background color, text font size, etc.), and may contain other classes (a window will contain one or more documents, a document will contain text, a text object will contain paragraphs and words and characters).
Commands, by contrast, are instructions that can be given to scriptable objects. The general format for a block of AppleScript is to tell a scriptable object to run a command.All scriptable applications share a few basic commands and objects, usually called the Standard Suite—commands to open, close or save a file, to print something, to quit, to set data to variables—as well as a basic application object that gives the scriptable properties of the application itself. Many applications have numerous suites capable of performing any task the application itself can perform. In exceptional cases, applications may support plugins which include their own scripting dictionaries.
AppleScript was designed with the ability to build scripts intuitively by recording user actions. Such AppleScript recordability has to be engineered into the app—the app must support Apple events and AppleScript recording; as Finder supports AppleScript recording, it can be useful for reference. When AppleScript Editor (Script Editor) is open and the Record button clicked, user actions for recordable apps are converted to their equivalent AppleScript commands and output to the Script Editor window. The resulting script can be saved and re-run to duplicate the original actions, or modified to be more generally useful.

Comments
Comments can be made multiple ways. A one-line comment can begin with 2 hyphens (--). In AppleScript 2.0, first released in Mac OS X Leopard, it may also begin with a number sign (#). This permits a self-contained AppleScript script to be stored as an executable text file beginning with the shebang line #!/usr/bin/osascript
Example:

For comments that take up multiple lines, AppleScript uses parentheses with asterisks inside.
Example:

Hello, world!
In AppleScript, the traditional ""Hello, World!"" program could be written in many different forms, including:

AppleScript has several user interface options, including dialogs, alerts, and list of choices. (The character ¬, produced by typing ⌥ Option+return in the Script Editor, denotes continuation of a single statement across multiple lines.)

Each user interaction method can return the values of buttons clicked, items chosen or text entered for further processing. For example:

Natural language metaphor
Whereas Apple events are a way to send messages into applications, AppleScript is a particular language designed to send Apple events. In keeping with the objective of ease-of-use for beginners, the AppleScript language is designed on the natural language metaphor, just as the graphical user interface is designed on the desktop metaphor. A well-written AppleScript should be clear enough to be read and understood by anyone, and easily edited. The language is based largely on HyperCard's HyperTalk language, extended to refer not only to the HyperCard world of cards and stacks, but also theoretically to any document. To this end, the AppleScript team introduced the AppleEvent Object Model (AEOM), which specifies the objects any particular application ""knows"".
The heart of the AppleScript language is the use of terms that act as nouns and verbs that can be combined. For example, rather than a different verb to print a page, document or range of pages (such as printPage, printDocument, printRange), AppleScript uses a single ""print"" verb which can be combined with an object, such as a page, a document or a range of pages.

Generally, AEOM defines a number of objects—like ""document"" or ""paragraph""—and corresponding actions—like ""cut"" and ""close"". The system also defines ways to refer to properties of objects, so one can refer to the ""third paragraph of the document 'Good Day'"", or the ""color of the last word of the front window"". AEOM uses an application dictionary to associate the Apple events with human-readable terms, allowing the translation back and forth between human-readable AppleScript and bytecode Apple events. To discover what elements of a program are scriptable, dictionaries for supported applications may be viewed. (In the Xcode and Script Editor applications, this is under File → Open Dictionary.)
To designate which application is meant to be the target of such a message, AppleScript uses a ""tell"" construct:

Alternatively, the tell may be expressed in one line by using an infinitive:

For events in the ""Core Suite"" (activate, open, reopen, close, print, and quit), the application may be supplied as the direct object to transitive commands:

The concept of an object hierarchy can be expressed using nested blocks:

The concept of an object hierarchy can also be expressed using either nested prepositional phrases or a series of possessives:

which in another programming language might be expressed as sequential method calls, like in this pseudocode:

AppleScript includes syntax for ordinal counting, ""the first paragraph"", as well as cardinal, ""paragraph one"". Likewise, the numbers themselves can be referred to as text or numerically, ""five"", ""fifth"" and ""5"" are all supported; they are synonyms in AppleScript. Also, the word ""the"" can legally be used anywhere in the script in order to enhance readability: it has no effect on the functionality of the script.

Examples of scripts
A failsafe calculator:

A simple username and password dialog box sequence. Here, the username is John and password is app123:

Development tools
Script editors
Script editors provide a unified programing environment for AppleScripts, including tools for composing, validating, compiling, running, and debugging scripts. They also provide mechanisms for opening and viewing AppleScript dictionaries from scriptable applications, saving scripts in a number of formats (compiled script files, application packages, script bundles, and plain text files), and usually provide features such as syntax highlighting and prewritten code snippets.

From Apple
AppleScript Editor (Script Editor)
The editor for AppleScript packaged with macOS, called AppleScript Editor in Mac OS X Snow Leopard (10.6) through OS X Mavericks (10.9) and Script Editor in all earlier and later versions of macOS. Scripts are written in document editing windows where they can be compiled and run, and these windows contain various panes in which logged information, execution results, and other information is available for debugging purposes. Access to scripting dictionaries and prewritten code snippets is available through the application menus. Since OS X Yosemite (10.10), Script Editor includes the ability to write in both AppleScript and JavaScript.Xcode
A suite of tools for developing applications with features for editing AppleScripts or creating full-fledged applications written with AppleScript.

From third parties
Script Debugger, from Late Night Software
A third-party commercial IDE for AppleScript. Script Debugger is a more advanced AppleScript environment that allows the script writer to debug AppleScripts via single stepping, breakpoints, stepping in and out of functions/subroutines, variable tracking, etc. Script Debugger also contains an advanced dictionary browser that allows the user to see the dictionary in action in real world situations. That is, rather than just a listing of what the dictionary covers, one can open a document in Pages, for example, and see how the dictionary's terms apply to that document, making it easier to determine which parts of the dictionary to use. Script Debugger is not designed to create scripts with a GUI, other than basic alerts and dialogs, but is focused more on the coding and debugging of scripts.Smile and SmileLab
A third-party freeware/commercial IDE for AppleScript, itself written entirely in AppleScript. Smile is free, and primarily designed for AppleScript development. SmileLab is commercial software with extensive additions for numerical analysis, graphing, machine automation and web production. Smile and SmileLab use an assortment of different windows—AppleScript windows for running and saving full scripts, AppleScript terminals for testing code line-by-line, unicode windows for working with text and XML. Users can create complex interfaces—called dialogs—for situations where the built-in dialogs in AppleScript are insufficient.ASObjC Explorer 4, from Shane Stanley
A discontinued third-party commercial IDE for AppleScript, especially for AppleScriptObjC. The main feature is Cocoa-object/event logging, debugging and code-completion. Users can read Cocoa events and objects like other scriptable applications. This tool was originally built for AppleScript Libraries (available in OS X Mavericks). AppleScript Libraries aims for re-usable AppleScript components and supports built-in AppleScript dictionary (sdef). ASObjC Explorer 4 can be an external Xcode script editor, too.FaceSpan, from Late Night Software
A discontinued third-party commercial IDE for creating AppleScript applications with graphic user interfaces.

Script launchers
AppleScripts can be run from a script editor, but it is usually more convenient to run scripts directly, without opening a script editor application. There are a number of options for doing so:

Applets
AppleScripts can be saved from a script editor as applications (called applets, or droplets when they accept input via drag and drop).: 69  Applets can be run from the Dock, from the toolbar of Finder windows, from Spotlight, from third-party application launchers, or from any other place where applications can be run.Folder actions
Using AppleScript folder actions, scripts can be launched when specific changes occur in folders (such as adding or removing files). Folder actions can be assigned by clicking on a folder and choosing Folder Actions Setup... from the contextual menu; the location of this command differs slightly in Mac OS X 10.6.x from earlier versions. This same action can be achieved with third-party utilities such as Hazel.Hotkey launchers
Keyboard shortcuts can be assigned to AppleScripts in the script menu using the Keyboard & Mouse Settings Preference Pane in System Preferences. In addition, various third-party utilities are available—Alfred, FastScripts, Keyboard Maestro, QuicKeys, Quicksilver, TextExpander—which can run AppleScripts on demand using key combinations.Script menu
This system-wide menu provides access to AppleScripts from the macOS menu bar, visible no matter what application is running. (In addition, many Apple applications, some third-party applications, and some add-ons provide their own script menus. These may be activated in different ways, but all function in essentially the same manner.) Selecting a script in the script menu launches it. Since Mac OS X 10.6.x, the system-wide script menu can be enabled from the preferences of Script Editor; in prior versions of Mac OS X, it could be enabled from the AppleScript Utility application. When first enabled, the script menu displays a default library of fairly generic, functional AppleScripts, which can also be opened in Script Editor and used as examples for learning AppleScript. Scripts can be organized so that they only appear in the menu when particular applications are in the foreground.Unix command line and launchd
AppleScripts can be run from the Unix command line, or from launchd for scheduled tasks,: 716  by using the osascript command line tool. The osascript tool can run compiled scripts (.scpt files) and plain text files (.applescript files—these are compiled by the tool at runtime). Script applications can be run using the Unix open command.

AppleScript resources
AppleScript Libraries
Re-usable AppleScript modules (available since OS X Mavericks), written in AppleScript or AppleScriptObjC and saved as script files or bundles in certain locations, that can be called from other scripts. When saved as a bundle, a library can include an AppleScript dictionary (sdef) file, thus functioning like a scripting addition but written in AppleScript or AppleScriptObjC.

AppleScript Studio
A framework for attaching Cocoa interfaces to AppleScript applications, part of the Xcode package in Mac OS X 10.4 and 10.5, now deprecated in favor of AppleScriptObjC.: 438

AppleScriptObjC
A Cocoa development software framework, also called AppleScript/Objective-C or ASOC, part of the Xcode package since Mac OS X Snow Leopard. AppleScriptObjC allows AppleScripts to use Cocoa classes and methods directly. The following table shows the availability of AppleScriptObjC in various versions of macOS:
AppleScriptObjC can be used in all subsequent Mac OS X versions.

Automator
A graphical, modular editing environment in which workflows are built up from actions. It is intended to duplicate many of the functions of AppleScript without the necessity for programming knowledge. Automator has an action specifically designed to contain and run AppleScripts, for tasks that are too complex for Automator's simplified framework.

Scriptable core system applications
These background-only applications, packaged with macOS, are used to allow AppleScript to access features that would not normally be scriptable. As of Mac OS X 10.6.3 they include the scriptable applications for:

VoiceOver (scriptable auditory and braille screen reader package)
System Events (control of non-scriptable applications and access to certain system functions and basic file operations)
Printer Setup Utility (scriptable utility for handling print jobs)
Image Events (core image manipulation)
HelpViewer (scriptable utility for showing help displays)
Database Events (minimal SQLite3 database interface)
AppleScript Utility (for scripting a few AppleScript related preferences)

Scripting Additions (OSAX)
Plug-ins for AppleScript developed by Apple or third parties. They are designed to extend the built-in command set, expanding AppleScript's features and making it somewhat less dependent on functionality provided by applications. macOS includes a collection of scripting additions referred to as Standard Additions (StandardAdditions.osax) that adds a set of commands and classes that are not part of AppleScript's core features, including user interaction dialogs, reading and writing files, file system commands, date functions, and text and mathematical operations; without this OSAX, AppleScript would have no capacity to perform many basic actions not directly provided by an application.

Language essentials
Classes (data types)
While applications can define specialized classes (or data types), AppleScript also has a number of built-in classes. These basic data classes are directly supported by the language and tend to be universally recognized by scriptable applications. The most common ones are as follows:

Basic objects
application: an application object, used mostly as a specifier for tell statements (tell application ""Finder"" …).
script: a script object. Script objects are containers for scripts. Every AppleScript creates a script object when run, and script objects may be created within AppleScripts.
class: a meta-object that specifies the type of other objects.
reference: an object that encapsulates an unevaluated object specifier that may or may not point to a valid object. Can be evaluated on-demand by accessing its contents property.
Standard data objects
constant: a constant value. There are a number of language-defined constants, such as pi, tab, and linefeed.
boolean: a Boolean true/false value. Actually a subclass of constant.
number: a rarely used abstract superclass of integer and real.
integer: an integer. Can be manipulated with built-in mathematical operators.
real: a floating-point (real) number. Can be manipulated with built-in mathematical operators.
date: a date and time.
text: text. In versions of AppleScript before 2.0 (Mac OS X 10.4 and below) the text class was distinct from string and Unicode text, and the three behaved somewhat differently; in 2.0 (10.5) and later, they are all synonyms and all text is handled as being UTF-16 (“Unicode”)-encoded.
Containers
list: an ordered list of objects. Can contain any class, including other lists and classes defined by applications.
record: a keyed list of objects. Like a list, except structured as key–value pairs. Runtime keyed access is unsupported; all keys must be compile-time constant identifiers.
File system
alias: a reference to a file system object (file or folder). The alias will maintain its link to the object if the object is moved or renamed.
file: a reference to a file system object (file or folder). This is a static reference, and can point to an object that does not currently exist.
POSIX file: a reference to a file system object (file or folder), in plain text, using Unix (POSIX)-style slash (/) notation. Not a true data type, as AppleScript automatically converts POSIX files to ordinary files whenever they are used.
Miscellaneous
RGB color: specifies an RGB triplet (in 16-bit high color format), for use in commands and objects that work with colors.
unit types: class that converts between standard units. For instance, a value can be defined as square yards, then converted to square feet by casting between unit types (using the as operator).

Language structures
Many AppleScript processes are managed by blocks of code, where a block begins with a command command and ends with an end command statement. The most important structures are described below.

Conditionals
AppleScript offers two kinds of conditionals.

Loops
The repeat loop of AppleScript comes in several slightly different flavors. They all execute the block between repeat and end repeat lines a number of times. The looping can be prematurely stopped with command exit repeat.
Repeat forever. 

Repeat a given number of times.

Conditional loops. The block inside repeat while loop executes as long as the condition evaluates to true. The condition is re-evaluated after each execution of the block. The repeat until loop is otherwise identical, but the block is executed as long as the condition evaluates to false.

Loop with a variable. When starting the loop, the variable is assigned to the start value. After each execution of the block, the optional step value is added to the variable. Step value defaults to 1. 

Enumerate a list. On each iteration set the loopVariable to a new item in the given list

One important variation on this block structure is in the form of on —end ... blocks that are used to define handlers (function-like subroutines). Handlers begin with on functionName() and ending with end functionName, and are not executed as part of the normal script flow unless called from somewhere in the script.

Handlers can also be defined using ""to"" in place of ""on"" and can be written to accept labeled parameters, not enclosed in parens.

There are four types of predefined handlers in AppleScript—run, open, idle, and quit—each of which is created in the same way as the run handler shown above.

Run handler
Defines the main code of the script, which is called when the script is run. Run handler blocks are optional, unless arguments are being passed to the script. If an explicit run handler block is omitted, then all code that is not contained inside handler blocks is executed as though it were in an implicit run handler.
Open handler
Defined using ""on open theItems"".
When a script containing an ""open handler' is saved as an applet, the applet becomes a droplet. A droplet can be identified in the Finder by its icon, which includes an arrow, indicating items can be dropped onto the icon. The droplet's open handler is executed when files or folders are dropped onto droplet's icon. References to the items dropped on the droplet's icon are passed to the droplet's script as the parameter of the open handler. A droplet can also be launched the same way as an ordinary applet, executing its run handler.

Idle handler
A subroutine that is run periodically by the system when the application is idle.
An idle handler can be used in applets or droplets saved as stay-open applets, and is useful for scripts that watch for particular data or events. The length of the idle time is 30 seconds by default, but can be changed by including a 'return x' statement at the end of the subroutine, where x is the number of seconds the system should wait before running the handler again.

Quit handler
A handler that is run when the applet receives a Quit request. This can be used to save data or do other ending tasks before quitting.
Script objects
Script objects may be defined explicitly using the syntax:

Script objects can use the same 'tell' structures that are used for application objects, and can be loaded from and saved to files. Runtime execution time can be reduced in some cases by using script objects.

Miscellaneous information
Variables are not strictly typed, and do not need to be declared. Variables can take any data type (including scripts and functions). The following commands are examples of the creation of variables:
Script objects are full objects—they can encapsulate methods and data and inherit data and behavior from a parent script.
Subroutines cannot be called directly from application tell blocks. Use the 'my' or 'of me' keywords to do so.
Using the same technique for scripting addition commands can reduce errors and improve performance.

Open Scripting Architecture
An important aspect of the AppleScript implementation is the Open Scripting Architecture (OSA). Apple provides OSA for other scripting languages and third-party scripting/automation products such as QuicKeys and UserLand Frontier, to function on an equal status with AppleScript. AppleScript was implemented as a scripting component, and the basic specs for interfacing such components to the OSA were public, allowing other developers to add their own scripting components to the system. Public client APIs for loading, saving and compiling scripts would work the same for all such components, which also meant that applets and droplets could hold scripts in any of those scripting languages.
One feature of the OSA is scripting additions, or OSAX for Open Scripting Architecture eXtension, which were inspired by HyperCard's External Commands. Scripting additions are libraries that allow programmers to extend the function of AppleScript. Commands included as scripting additions are available system-wide, and are not dependent on an application (see also § AppleScript Libraries). The AppleScript Editor is also able to directly edit and run some of the OSA languages.

JavaScript for Automation
Under OS X Yosemite and later versions of macOS, the JavaScript for Automation (JXA) component remains the only serious OSA language alternative to AppleScript, though the Macintosh versions of Perl, Python, Ruby, and Tcl all support native means of working with Apple events without being OSA components.: 516 JXA also provides an Objective-C (and C language) foreign language interface. Being an environment based on WebKit's JavaScriptCore engine, the JavaScript feature set is in sync with the system Safari browser engine. JXA provides a JavaScript module system and it is also possible to use CommonJS modules via browserify.

See also
ARexx – competitive technology of 1987

References
Further reading
""AppleScript Language Guide"". developer.apple.com. 2016. Retrieved May 9, 2017.
Munro, Mark Conway (2010). AppleScript. Developer Reference. Indianapolis: Wiley. ISBN 978-0-470-56229-1. OCLC 468969567.
Rosenthal, Hanaan; Sanderson, Hamish (2010). Learn AppleScript: The Comprehensive Guide to Scripting and Automation on Mac OS X (3rd ed.). Berkeley: Apress. doi:10.1007/978-1-4302-2362-7. ISBN 978-1-4302-2361-0. OCLC 308193726.
Soghoian, Sal; Cheeseman, Bill (2009). Apple Training Series: AppleScript 1-2-3. Apple Pro training series. Berkeley: Peachpit Press. ISBN 978-0-321-14931-2. OCLC 298560807.
Cook, William (2007). ""AppleScript"" (PDF). Proceedings of the third ACM SIGPLAN conference on History of programming languages. ACM. pp. 1–21. CiteSeerX 10.1.1.86.2218. doi:10.1145/1238844.1238845. ISBN 9781595937667. S2CID 220938191.
Ford Jr., Jerry Lee (2007). AppleScript Programming for the Absolute Beginner. Boston: Thomson Course Technology. ISBN 978-1-59863-384-9. OCLC 76910522.
Neuburg, Matt (2006). AppleScript: The Definitive Guide (2nd ed.). Beijing; Farnham: O'Reilly Media. ISBN 0-596-10211-9. OCLC 68694976.
Goldstein, Adam (2005). AppleScript: The Missing Manual. Missing Manual series. Sebastopol, CA; Farnham: O'Reilly Media. ISBN 0-596-00850-3. OCLC 56912218.
Trinko, Tom (2004). AppleScript for Dummies. For Dummies series (2nd ed.). Hoboken, NJ: Wiley. ISBN 978-0-7645-7494-8. OCLC 56500506.

External links

""AppleScript Overview"". developer.apple.com. 2007. Retrieved November 7, 2020.
""AppleScript for Python Programmers (Comparison Chart)"". aurelio.net. 2005. Retrieved May 9, 2017.
""Doug's AppleScripts for iTunes"". dougscripts.com. Retrieved May 9, 2017.
""MacScripter AppleScript community"". macscripter.net. Retrieved May 9, 2017.",88392,https://en.wikipedia.org/wiki/AppleScript
AspectJ,"AspectJ is an aspect-oriented programming (AOP) extension for the Java programming language, created at PARC. It is available in Eclipse Foundation open-source projects, both stand-alone and integrated into Eclipse. AspectJ has become a widely used de facto standard for AOP by emphasizing simplicity and usability for end users. It uses Java-like syntax, and included IDE integrations for displaying crosscutting structure since its initial public release in 2001.","AspectJ is an aspect-oriented programming (AOP) extension for the Java programming language, created at PARC. It is available in Eclipse Foundation open-source projects, both stand-alone and integrated into Eclipse. AspectJ has become a widely used de facto standard for AOP by emphasizing simplicity and usability for end users. It uses Java-like syntax, and included IDE integrations for displaying crosscutting structure since its initial public release in 2001.

Simple language description
All valid Java programs are also valid AspectJ programs, but AspectJ lets programmers define special constructs called aspects. Aspects can contain several entities unavailable to standard classes. These are:

Extension methods
Allow a programmer to add methods, fields, or interfaces to existing classes from within the aspect. This example adds an acceptVisitor (see visitor pattern) method to the Point class:Pointcuts
Allow a programmer to specify join points (well-defined moments in the execution of a program, like method call, object instantiation, or variable access). All pointcuts are expressions (quantifications) that determine whether a given join point matches. For example, this point-cut matches the execution of any instance method in an object of type Point whose name begins with set:Advices
Allow a programmer to specify code to run at a join point matched by a pointcut. The actions can be performed before, after, or around the specified join point. Here, the advice refreshes the display every time something on Point is set, using the pointcut declared above:AspectJ also supports limited forms of pointcut-based static checking and aspect reuse (by inheritance). See the AspectJ Programming Guide for a more detailed description of the language.

AspectJ compatibility and implementations
AspectJ can be implemented in many ways, including source-weaving or bytecode-weaving, and directly in the virtual machine (VM). In all cases, the AspectJ program becomes a valid Java program that runs in a Java VM. Classes affected by aspects are binary-compatible with unaffected classes (to remain compatible with classes compiled with the unaffected originals). Supporting multiple implementations allows the language to grow as technology changes, and being Java-compatible ensures platform availability.
Key to its success has been engineering and language decisions that make the language usable and programs deployable. The original Xerox AspectJ implementation used source weaving, which required access to source code. When Xerox contributed the code to Eclipse, AspectJ was reimplemented using the Eclipse Java compiler and a bytecode weaver based on BCEL, so developers could write aspects for code in binary (.class) form. At this time the AspectJ language was restricted to support a per-class model essential for incremental compilation and load-time weaving. This made IDE integrations as responsive as their Java counterparts, and it let developers deploy aspects without altering the build process. This led to increased adoption, as AspectJ became usable for impatient Java programmers and enterprise-level deployments. Since then, the Eclipse team has increased performance and correctness, upgraded the AspectJ language to support Java 5 language features like generics and annotations, and integrated annotation-style pure-java aspects from AspectWerkz.
The Eclipse project supports both command-line and Ant interfaces. A related Eclipse project has steadily improved the Eclipse IDE support for AspectJ (called AspectJ Development Tools (AJDT)) and other providers of crosscutting structure. IDE support for emacs, NetBeans, and JBuilder foundered when Xerox put them into open source, but support for Oracle's JDeveloper did appear. IDE support has been key to Java programmers using AspectJ and understanding crosscutting concerns.
BEA has offered limited VM support for aspect-oriented extensions, but for extensions supported in all Java VM's would require agreement through Sun's Java Community Process (see also the java.lang.instrument package available since Java SE 5 — which is a common ground for JVM load-time instrumentation).
Academic interest in the semantics and implementation of aspect-oriented languages has surrounded AspectJ since its release. The leading research implementation of AspectJ is the AspectBench Compiler, or abc; it supports extensions for changing the syntax and semantics of the language and forms the basis for many AOP experiments that the AspectJ team can no longer support, given its broad user base.
Many programmers discover AspectJ as an enabling technology for other projects, most notably Spring AOP. A sister Spring project, Spring Roo, automatically maintains AspectJ inter-type declarations as its principal code generation output.

History and contributors
Gregor Kiczales started and led the Xerox PARC team that eventually developed AspectJ. He coined the term crosscutting. Fourth on the team, Chris Maeda coined the term aspect-oriented programming. Jim Hugunin and Erik Hilsdale (Xerox PARC team members 12 and 13) were the original compiler and weaver engineers, Mik Kersten implemented the IDE integration and started the Eclipse AJDT project with Adrian Colyer and Andrew Clement. After Adrian Colyer, Andrew Clement took over as project lead and main contributor for AspectJ. AJDT has since been retired as a separate project and taken over into the Eclipse AspectJ umbrella project to streamline maintenance. However, both AspectJ and AJDT are still maintained in separate source repositories.
In 2021, Alexander Kriegisch joined the project, first as a contributor, then as a committer and maintainer. Since March 2021, he is basically the sole maintainer. Since 2024, he also is formally the AspectJ and AJDT project lead.
The AspectBench Compiler was developed and is maintained as a joint effort of the Programming Tools Group at the Oxford University Computing Laboratory, the Sable Research Group at McGill University, and the Institute for Basic Research in Computer Science (BRICS).

AspectWerkz
AspectWerkz was a dynamic, lightweight and high-performance AOP/AOSD framework for Java. It has been merged with the AspectJ project, which supports AspectWerkz functionality since AspectJ 5.
Jonas Boner and Alex Vasseur engineered the AspectWerkz project, and later contributed to the AspectJ project when it merged in the AspectWerkz annotation style and load-time weaving support.
Unlike AspectJ prior to version 5, AspectWerkz did not add any new language constructs to Java, but instead supported declaration of aspects within Java annotations. It utilizes bytecode modification to weave classes at project build-time, class load time, as well as runtime. It uses standardized JVM level APIs. Aspects can be defined using either Java annotations (introduced with Java 5), Java 1.3/1.4 custom doclet or a simple XML definition file.
AspectWerkz provides an API to use the very same aspects for proxies, hence providing a transparent experience, allowing a smooth transition for users familiar with proxies.
AspectWerkz is free software. The LGPL-style license allows the use of AspectWerkz 2.0 in both commercial and open source projects.

See also
Aspect-oriented programming
Spring AOP (part of the Spring Framework)
Aspect-oriented software development

References
External links
AJDT
Aspect bench : https://web.archive.org/web/20170816093700/http://www.sable.mcgill.ca/abc/
AspectJ Home Page
AspectWerkz Project homepage
Improve modularity with aspect-oriented programming
Spring AOP and AspectJ Introduction
The AspectJ Programming Guide
Xerox has U.S. patent 6,467,086 for AOP/AspectJ, but published AspectJ source code under the Common Public License, which grants some patent rights.",237214,https://en.wikipedia.org/wiki/AspectJ
B (programming language),"B is a programming language developed at Bell Labs circa 1969 by Ken Thompson and Dennis Ritchie.
B was derived from BCPL, and its name may possibly be a contraction of BCPL.  Thompson's coworker Dennis Ritchie speculated that the name might be based on Bon, an earlier, but unrelated, programming language that Thompson designed for use on Multics.B was designed for recursive, non-numeric, machine-independent applications, such as system and language software. It was a typeless language, with the only data type being the underlying machine's natural memory word format, whatever that might be. Depending on the context, the word was treated either as an integer or a memory address.
As machines with ASCII processing became common, notably the DEC PDP-11 that arrived at Bell Labs, support for character data stuffed in memory words became important. The typeless nature of the language was seen as a disadvantage, which led Thompson and Ritchie to develop an expanded version of the language supporting new internal and user-defined types, which became the C programming language.","B is a programming language developed at Bell Labs circa 1969 by Ken Thompson and Dennis Ritchie.
B was derived from BCPL, and its name may possibly be a contraction of BCPL.  Thompson's coworker Dennis Ritchie speculated that the name might be based on Bon, an earlier, but unrelated, programming language that Thompson designed for use on Multics.B was designed for recursive, non-numeric, machine-independent applications, such as system and language software. It was a typeless language, with the only data type being the underlying machine's natural memory word format, whatever that might be. Depending on the context, the word was treated either as an integer or a memory address.
As machines with ASCII processing became common, notably the DEC PDP-11 that arrived at Bell Labs, support for character data stuffed in memory words became important. The typeless nature of the language was seen as a disadvantage, which led Thompson and Ritchie to develop an expanded version of the language supporting new internal and user-defined types, which became the C programming language.

History
BCPL semantics with a lot of SMALGOL syntax
Circa 1969, Ken Thompson and later Dennis Ritchie developed B basing it mainly on the BCPL language Thompson used in the Multics project. B was essentially the BCPL system stripped of any component Thompson felt he could do without in order to make it fit within the memory capacity of the minicomputers of the time. The BCPL to B transition also included changes made to suit Thompson's preferences (mostly along the lines of reducing the number of non-whitespace characters in a typical program). Much of the typical ALGOL-like syntax of BCPL was rather heavily changed in this process. The assignment operator := reverted to the = of Rutishauser's Superplan, and the equality operator = was replaced by ==.
Thompson added ""two-address assignment operators"" using x =+ y syntax to add y to x (in C the operator is written +=). This syntax came from Douglas McIlroy's implementation of TMG, in which B's compiler was first implemented (and it came to TMG from ALGOL 68's x +:= y syntax). Thompson went further by inventing the increment and decrement operators (++ and --). Their prefix or postfix position determines whether the value is taken before or after alteration of the operand. This innovation was not in the earliest versions of B. According to Dennis Ritchie, people often assumed that they were created for the auto-increment and auto-decrement address modes of the DEC PDP-11, but this is historically impossible as the machine didn't exist when B was first developed.The semicolon version of the for loop was borrowed by Ken Thompson from the work of Stephen Johnson.B is typeless, or more precisely has one data type: the computer word. Most operators (e.g. +, -, *, /) treated this as an integer, but others treated it as a memory address to be dereferenced. In many other ways it looked a lot like an early version of C. There are a few library functions, including some that vaguely resemble functions from the standard I/O library in C. 
In Thompson's words: ""B and the old old C were very very similar languages except for all the types [in C]"".Early implementations were for the DEC PDP-7 and PDP-11 minicomputers using early Unix, and Honeywell GE 645 36-bit mainframes running the operating system GCOS. The earliest PDP-7 implementations compiled to threaded code, and Ritchie wrote a compiler using TMG which produced machine code. In 1970 a PDP-11 was acquired and threaded code was used for the port; an assembler, dc, and the B language itself were written in B to bootstrap the computer. An early version of yacc was produced with this PDP-11 configuration. Ritchie took over maintenance during this period.The typeless nature of B made sense on the Honeywell, PDP-7 and many older computers, but was a problem on the PDP-11 because it was difficult to elegantly access the character data type that the PDP-11 and most modern computers fully support. Starting in 1971 Ritchie made changes to the language while converting its compiler to produce machine code, most notably adding data typing for variables. During 1971 and 1972 B evolved into ""New B"" (NB) and then C.B is almost extinct, having been superseded by the C language. However, it continues to see use on GCOS mainframes (as of 2014) 
and on certain embedded systems (as of 2000) for a variety of reasons: limited hardware in small systems, extensive libraries, tooling, licensing cost issues, and simply being good enough for the job. The highly influential AberMUD was originally written in B.

Examples
The following examples are from the Users' Reference to B by Ken Thompson:

Notes
References
External links
Manual page for b(1) from Unix First Edition
The Development of the C Language, Dennis M. Ritchie. Puts B in the context of BCPL and C.
Users' Reference to B, Ken Thompson. Describes the PDP-11 version.
The Programming Language B, S. C. Johnson & B. W. Kernighan, Technical Report CS TR 8, Bell Labs (January 1973). The GCOS version on Honeywell equipment.
B Language Reference Manual, Thinkage Ltd. The production version of the language as used on GCOS, including language and runtime library.",4475,https://en.wikipedia.org/wiki/B_(programming_language)
BASIC,"BASIC (Beginners' All-purpose Symbolic Instruction Code) is a family of general-purpose, high-level programming languages designed for ease of use. The original version was created by John G. Kemeny and Thomas E. Kurtz at Dartmouth College in 1963. They wanted to enable students in non-scientific fields to use computers. At the time, nearly all computers required writing custom software, which only scientists and mathematicians tended to learn.
In addition to the programming language, Kemeny and Kurtz developed the Dartmouth Time Sharing System (DTSS), which allowed multiple users to edit and run BASIC programs simultaneously on remote terminals. This general model became popular on minicomputer systems like the PDP-11 and Data General Nova in the late 1960s and early 1970s. Hewlett-Packard produced an entire computer line for this method of operation, introducing the HP2000 series in the late 1960s and continuing sales into the 1980s. Many early video games trace their history to one of these versions of BASIC.
The emergence of microcomputers in the mid-1970s led to the development of multiple BASIC dialects, including Microsoft BASIC in 1975. Due to the tiny main memory available on these machines, often 4 KB, a variety of Tiny BASIC dialects were also created. BASIC was available for almost any system of the era, and became the de facto programming language for home computer systems that emerged in the late 1970s. These PCs almost always had a BASIC interpreter installed by default, often in the machine's firmware or sometimes on a ROM cartridge.
BASIC declined in popularity in the 1990s, as more powerful microcomputers came to market and programming languages with advanced features (such as Pascal and C) became tenable on such computers. By then, most nontechnical personal computer users relied on pre-written applications rather than writing their own programs. In 1991, Microsoft released Visual Basic, combining an updated version of BASIC with a visual forms builder. This reignited use of the language and ""VB"" remains a major programming language in the form of VB.NET, while a hobbyist scene for BASIC more broadly continues to exist.","BASIC (Beginners' All-purpose Symbolic Instruction Code) is a family of general-purpose, high-level programming languages designed for ease of use. The original version was created by John G. Kemeny and Thomas E. Kurtz at Dartmouth College in 1963. They wanted to enable students in non-scientific fields to use computers. At the time, nearly all computers required writing custom software, which only scientists and mathematicians tended to learn.
In addition to the programming language, Kemeny and Kurtz developed the Dartmouth Time Sharing System (DTSS), which allowed multiple users to edit and run BASIC programs simultaneously on remote terminals. This general model became popular on minicomputer systems like the PDP-11 and Data General Nova in the late 1960s and early 1970s. Hewlett-Packard produced an entire computer line for this method of operation, introducing the HP2000 series in the late 1960s and continuing sales into the 1980s. Many early video games trace their history to one of these versions of BASIC.
The emergence of microcomputers in the mid-1970s led to the development of multiple BASIC dialects, including Microsoft BASIC in 1975. Due to the tiny main memory available on these machines, often 4 KB, a variety of Tiny BASIC dialects were also created. BASIC was available for almost any system of the era, and became the de facto programming language for home computer systems that emerged in the late 1970s. These PCs almost always had a BASIC interpreter installed by default, often in the machine's firmware or sometimes on a ROM cartridge.
BASIC declined in popularity in the 1990s, as more powerful microcomputers came to market and programming languages with advanced features (such as Pascal and C) became tenable on such computers. By then, most nontechnical personal computer users relied on pre-written applications rather than writing their own programs. In 1991, Microsoft released Visual Basic, combining an updated version of BASIC with a visual forms builder. This reignited use of the language and ""VB"" remains a major programming language in the form of VB.NET, while a hobbyist scene for BASIC more broadly continues to exist.

Origin
John G. Kemeny was the chairman of the Dartmouth College Mathematics Department. Based largely on his reputation as an innovator in math teaching, in 1959 the College won an Alfred P. Sloan Foundation award for $500,000 to build a new department building. Thomas E. Kurtz had joined the department in 1956, and from the 1960s Kemeny and Kurtz agreed on the need for programming literacy among students outside the traditional STEM fields. Kemeny later noted that ""Our vision was that every student on campus should have access to a computer, and any faculty member should be able to use a computer in the classroom whenever appropriate. It was as simple as that.""Kemeny and Kurtz had made two previous experiments with simplified languages, DARSIMCO (Dartmouth Simplified Code) and DOPE (Dartmouth Oversimplified Programming Experiment). These did not progress past a single freshman class. New experiments using Fortran and ALGOL followed, but Kurtz concluded these languages were too tricky for what they desired. As Kurtz noted, Fortran had numerous oddly-formed commands, notably an ""almost impossible-to-memorize convention for specifying a loop: DO 100, I = 1, 10, 2. Is it '1, 10, 2' or '1, 2, 10', and is the comma after the line number required or not?""Moreover, the lack of any sort of immediate feedback was a key problem; the machines of the era used batch processing and took a long time to complete a run of a program. While Kurtz was visiting MIT, John McCarthy suggested that time-sharing offered a solution; a single machine could divide up its processing time among many users, giving them the illusion of having a (slow) computer to themselves. Small programs would return results in a few seconds. This led to increasing interest in a system using time-sharing and a new language specifically for use by non-STEM students.Kemeny wrote the first version of BASIC. The acronym BASIC comes from the name of an unpublished paper by Thomas Kurtz. The new language was heavily patterned on FORTRAN II; statements were one-to-a-line, numbers were used to indicate the target of loops and branches, and many of the commands were similar or identical to Fortran. However, the syntax was changed wherever it could be improved. For instance, the difficult to remember DO loop was replaced by the much easier to remember FOR I = 1 TO 10 STEP 2, and the line number used in the DO was instead indicated by the NEXT I. Likewise, the cryptic IF statement of Fortran, whose syntax matched a particular instruction of the machine on which it was originally written, became the simpler IF I=5 THEN GOTO 100. These changes made the language much less idiosyncratic while still having an overall structure and feel similar to the original FORTRAN.The project received a $300,000 grant from the National Science Foundation, which was used to purchase a GE-225 computer for processing, and a Datanet-30 realtime processor to handle the Teletype Model 33 teleprinters used for input and output. A team of a dozen undergraduates worked on the project for about a year, writing both the DTSS system and the BASIC compiler. The first version BASIC language was released on 1 May 1964.Initially, BASIC concentrated on supporting straightforward mathematical work, with matrix arithmetic support from its initial implementation as a batch language, and character string functionality being added by 1965. Usage in the university rapidly expanded, requiring the main CPU to be replaced by a GE-235, and still later by a GE-635. By the early 1970s there were hundreds of terminals connected to the machines at Dartmouth, some of them remotely.
Wanting use of the language to become widespread, its designers made the compiler available free of charge. In the 1960s, software became a chargeable commodity; until then, it was provided without charge as a service with expensive computers, usually available only to lease. They also made it available to high schools in the Hanover, New Hampshire, area and regionally throughout New England on Teletype Model 33 and Model 35 teleprinter terminals connected to Dartmouth via dial-up phone lines, and they put considerable effort into promoting the language. In the following years, as other dialects of BASIC appeared, Kemeny and Kurtz's original BASIC dialect became known as Dartmouth BASIC.
New Hampshire recognized the accomplishment in 2019 when it erected a highway historical marker in Hanover describing the creation of ""the first user-friendly programming language"".

Spread on time-sharing services
The emergence of BASIC took place as part of a wider movement toward time-sharing systems. First conceptualized during the late 1950s, the idea became so dominant in the computer industry by the early 1960s that its proponents were speaking of a future in which users would ""buy time on the computer much the same way that the average household buys power and water from utility companies"".General Electric, having worked on the Dartmouth project, wrote their own underlying operating system and launched an online time-sharing system known as Mark I. It featured BASIC as one of its primary selling points. Other companies in the emerging field quickly followed suit; Tymshare introduced SUPER BASIC in 1968, CompuServe had a version on the DEC-10 at their launch in 1969, and by the early 1970s BASIC was largely universal on general-purpose mainframe computers. Even IBM eventually joined the club with the introduction of VS-BASIC in 1973.Although time-sharing services with BASIC were successful for a time, the widespread success predicted earlier was not to be. The emergence of minicomputers during the same period, and especially low-cost microcomputers in the mid-1970s, allowed anyone to purchase and run their own systems rather than buy online time which was typically billed at dollars per minute.

Spread on minicomputers
BASIC, by its very nature of being small, was naturally suited to porting to the minicomputer market, which was emerging at the same time as the time-sharing services. These machines had small main memory, perhaps as little as 4 KB in modern terminology, and lacked high-performance storage like hard drives that make compilers practical. On these systems, BASIC was normally implemented as an interpreter rather than a compiler due to its lower requirement for working memory.A particularly important example was HP Time-Shared BASIC, which, like the original Dartmouth system, used two computers working together to implement a time-sharing system. The first, a low-end machine in the HP 2100 series, was used to control user input and save and load their programs to tape or disk. The other, a high-end version of the same underlying machine, ran the programs and generated output. For a cost of about $100,000, one could own a machine capable of running between 16 and 32 users at the same time. The system, bundled as the HP 2000, was the first mini platform to offer time-sharing and was an immediate runaway success, catapulting HP to become the third-largest vendor in the minicomputer space, behind DEC and Data General (DG).DEC, the leader in the minicomputer space since the mid-1960s, had initially ignored BASIC. This was due to their work with RAND Corporation, who had purchased a PDP-6 to run their JOSS language, which was conceptually very similar to BASIC. This led DEC to introduce a smaller, cleaned up version of JOSS known as FOCAL, which they heavily promoted in the late 1960s. However, with timesharing systems widely offering BASIC, and all of their competition in the minicomputer space doing the same, DEC's customers were clamoring for BASIC. After management repeatedly ignored their pleas, David H. Ahl took it upon himself to buy a BASIC for the PDP-8, which was a major success in the education market. By the early 1970s, FOCAL and JOSS had been forgotten and BASIC had become almost universal in the minicomputer market. DEC would go on to introduce their updated version, BASIC-PLUS, for use on the RSTS/E time-sharing operating system.
During this period a number of simple text-based games were written in BASIC, most notably Mike Mayfield's Star Trek. David Ahl collected these, some ported from FOCAL, and published them in an educational newsletter he compiled. He later collected a number of these into book form, 101 BASIC Computer Games, published in 1973. During the same period, Ahl was involved in the creation of a small computer for education use, an early personal computer. When management refused to support the concept, Ahl left DEC in 1974 to found the seminal computer magazine, Creative Computing. The book remained popular, and was re-published on several occasions.

Explosive growth: the home computer era
The introduction of the first microcomputers in the mid-1970s was the start of explosive growth for BASIC. It had the advantage that it was fairly well known to the young designers and computer hobbyists who took an interest in microcomputers, many of whom had seen BASIC on minis or mainframes. Despite Dijkstra's famous judgement in 1975, ""It is practically impossible to teach good programming to students that have had a prior exposure to BASIC: as potential programmers they are mentally mutilated beyond hope of regeneration"", BASIC was one of the few languages that was both high-level enough to be usable by those without training and small enough to fit into the microcomputers of the day, making it the de facto standard programming language on early microcomputers.
The first microcomputer version of BASIC was co-written by Bill Gates, Paul Allen and Monte Davidoff for their newly formed company, Micro-Soft. This was released by MITS in punch tape format for the Altair 8800 shortly after the machine itself, immediately cementing BASIC as the primary language of early microcomputers. Members of the Homebrew Computer Club began circulating copies of the program, causing Gates to write his Open Letter to Hobbyists, complaining about this early example of software piracy.
Partially in response to Gates's letter, and partially to make an even smaller BASIC that would run usefully on 4 KB machines, Bob Albrecht urged Dennis Allison to write their own variation of the language. How to design and implement a stripped-down version of an interpreter for the BASIC language was covered in articles by Allison in the first three quarterly issues of the People's Computer Company newsletter published in 1975 and implementations with source code published in Dr. Dobb's Journal of Tiny BASIC Calisthenics & Orthodontia: Running Light Without Overbyte. This led to a wide variety of Tiny BASICs with added features or other improvements, with versions from Tom Pittman and Li-Chen Wang becoming particularly well known.Micro-Soft, by this time Microsoft, ported their interpreter for the MOS 6502, which quickly become one of the most popular microprocessors of the 8-bit era. When new microcomputers began to appear, notably the ""1977 trinity"" of the TRS-80, Commodore PET and Apple II, they either included a version of the MS code, or quickly introduced new models with it. Ohio Scientific's personal computers also joined this trend at that time. By 1978, MS BASIC was a de facto standard and practically every home computer of the 1980s included it in ROM. Upon boot, a BASIC interpreter in direct mode was presented.
Commodore Business Machines included Commodore BASIC, based on Microsoft BASIC. The Apple II and TRS-80 each had two versions of BASIC, a smaller introductory version introduced with the initial releases of the machines and an MS-based version introduced as interest in the platforms increased. As new companies entered the field, additional versions were added that subtly changed the BASIC family. The Atari 8-bit family had its own Atari BASIC that was modified in order to fit on an 8 KB ROM cartridge. Sinclair BASIC was introduced in 1980 with the Sinclair ZX80, and was later extended for the Sinclair ZX81 and the Sinclair ZX Spectrum. The BBC published BBC BASIC, developed by Acorn Computers Ltd, incorporating many extra structured programming keywords and advanced floating-point operation features.
As the popularity of BASIC grew in this period, computer magazines published complete source code in BASIC for video games, utilities, and other programs. Given BASIC's straightforward nature, it was a simple matter to type in the code from the magazine and execute the program. Different magazines were published featuring programs for specific computers, though some BASIC programs were considered universal and could be used in machines running any variant of BASIC (sometimes with minor adaptations). Many books of type-in programs were also available, and in particular, Ahl published versions of the original 101 BASIC games converted into the Microsoft dialect and published it from Creative Computing as BASIC Computer Games. This book, and its sequels, provided hundreds of ready-to-go programs that could be easily converted to practically any BASIC-running platform. The book reached the stores in 1978, just as the home computer market was starting off, and it became the first million-selling computer book. Later packages, such as Learn to Program BASIC would also have gaming as an introductory focus. On the business-focused CP/M computers which soon became widespread in small business environments, Microsoft BASIC (MBASIC) was one of the leading applications.In 1978, David Lien published the first edition of The BASIC Handbook: An Encyclopedia of the BASIC Computer Language, documenting keywords across over 78 different computers. By 1981, the second edition documented keywords from over 250 different computers, showcasing the explosive growth of the microcomputer era.

IBM PC and compatibles
When IBM was designing the IBM PC, they followed the paradigm of existing home computers in having a built-in BASIC interpreter. They sourced this from Microsoft – IBM Cassette BASIC – but Microsoft also produced several other versions of BASIC for MS-DOS/PC DOS including IBM Disk BASIC (BASIC D), IBM BASICA (BASIC A), GW-BASIC (a BASICA-compatible version that did not need IBM's ROM) and QBasic, all typically bundled with the machine. In addition they produced the Microsoft BASIC Compiler aimed at professional programmers. Turbo Pascal-publisher Borland published Turbo Basic 1.0 in 1985 (successor versions are still being marketed under the name PowerBASIC). On Unix-like systems, specialized implementations  were created such as XBasic and X11-Basic. XBasic was ported to Microsoft Windows as XBLite, and cross-platform variants such as SmallBasic, yabasic, Bywater BASIC, nuBasic, MyBasic, Logic Basic, Liberty BASIC, and wxBasic emerged. FutureBASIC and Chipmunk Basic meanwhile targeted the Apple Macintosh, while yab is a version of yaBasic optimized for BeOS, ZETA and Haiku.These later variations introduced many extensions, such as improved string manipulation and graphics support, access to the file system and additional data types. More important were the facilities for structured programming, including additional control structures and proper subroutines supporting local variables. However, by the latter half of the 1980s, users were increasingly using pre-made applications written by others rather than learning programming themselves; while professional programmers now had a wide range of more advanced languages available on small computers. C and later C++ became the languages of choice for professional ""shrink wrap"" application development.A niche that BASIC continued to fill was for hobbyist video game development, as game creation systems and readily available game engines were still in their infancy. The Atari ST had STOS BASIC while the Amiga had AMOS BASIC for this purpose. Microsoft first exhibited BASIC for game development with DONKEY.BAS for GW-BASIC, and later GORILLA.BAS and NIBBLES.BAS for QuickBASIC. QBasic maintained an active game development community, which helped later spawn the QB64 and FreeBASIC implementations. In 2013 a game written in QBasic and compiled with QB64 for modern computers entitled Black Annex was released on Steam. Blitz Basic, Dark Basic, SdlBasic, Super Game System Basic, RCBasic, PlayBASIC, CoolBasic, AllegroBASIC, ethosBASIC, NaaLaa, GLBasic and Basic4GL further filled this demand, right up to the modern AppGameKit, Monkey 2 and Cerberus-X.

Visual Basic
In 1991, Microsoft introduced Visual Basic, an evolutionary development of QuickBASIC. It included constructs from that language such as block-structured control statements, parameterized subroutines and optional static typing as well as object-oriented constructs from other languages such as ""With"" and ""For Each"". The language retained some compatibility with its predecessors, such as the Dim keyword for declarations, ""Gosub""/Return statements and optional line numbers which could be used to locate errors. An important driver for the development of Visual Basic was as the new macro language for Microsoft Excel, a spreadsheet program. To the surprise of many at Microsoft who still initially marketed it as a language for hobbyists, the language came into widespread use for small custom business applications shortly after the release of VB version 3.0, which is widely considered the first relatively stable version. Microsoft also spun it off as Visual Basic for Applications and Embedded Visual Basic. 
While many advanced programmers still scoffed at its use, VB met the needs of small businesses efficiently as by that time, computers running Windows 3.1 had become fast enough that many business-related processes could be completed ""in the blink of an eye"" even using a ""slow"" language, as long as large amounts of data were not involved. Many small business owners found they could create their own small, yet useful applications in a few evenings to meet their own specialized needs. Eventually, during the lengthy lifetime of VB3, knowledge of Visual Basic had become a marketable job skill. Microsoft also produced VBScript in 1996 and Visual Basic .NET in 2001. The latter has essentially the same power as C# and Java but with syntax that reflects the original Basic language, and also features some cross-platform capability through implementations such as Mono-Basic. The IDE, with its event-driven GUI builder, was also influential on other rapid application development tools, most notably Borland Software's Delphi for Object Pascal and its own descendants such as Lazarus.Mainstream support for the final version 6.0 of the original Visual Basic ended on March 31, 2005, followed by extended support in March 2008. Owing to its persistent remaining popularity, third-party attempts to further support it, such as Rubberduck and ModernVB, exist. On February 2, 2017 Microsoft announced that development on VB.NET would no longer be in parallel with that of C#, and on March 11, 2020 it was announced that evolution of the VB.NET language had also concluded. Even so, the language was still supported and the third-party Mercury extension has since been produced. Meanwhile, competitors exist such as B4X, RAD Basic, twinBASIC, VisualFBEditor, InForm, Xojo, and Gambas.

Post-1990 versions and dialects
Many other BASIC dialects have also sprung up since 1990, including the open source QB64 and FreeBASIC, inspired by QBasic, and the Visual Basic-styled RapidQ, HBasic, Basic For Qt and Gambas. Modern commercial incarnations include PureBasic, PowerBASIC, Xojo, Monkey X and True BASIC (the direct successor to Dartmouth BASIC from a company controlled by Kurtz).
Several web-based simple BASIC interpreters also now exist, including Quite Basic by Nikko Strom, as well as Microsoft's Small Basic and Google's wwwBASIC. A number of compilers also exist that convert BASIC into JavaScript, such as JSBasic which re-implements Applesoft BASIC, Spider BASIC, and NS Basic.
Building from earlier efforts such as Mobile Basic and CellularBASIC, many dialects are now available for smartphones and tablets. Through the Apple App Store for iOS options include Hand BASIC, Learn BASIC, Smart Basic based on Minimal BASIC, Basic! by
miSoft, and BASIC by Anastasia Kovba. The Google Play store for Android meanwhile has the touchscreen focused Touch Basic, B4A, the RFO BASIC! interpreter based on Dartmouth Basic, and adaptations of SmallBasic, BBC Basic, Tiny Basic, X11-Basic, and NS Basic.
On game consoles, an application for the Nintendo 3DS and Nintendo DSi called Petit Computer allows for programming in a slightly modified version of BASIC with DS button support. A version has also been released for Nintendo Switch, which has also been supplied a version of the Fuze Code System, a BASIC variant first implemented as a custom Raspberry Pi machine. Previously BASIC was made available on consoles as Family BASIC (for the Nintendo Famicom) and PSX Chipmunk Basic (for the original PlayStation), while yabasic was ported to the PlayStation 2 and FreeBASIC to the original Xbox, with Dragon BASIC created for homebrew on the Game Boy Advance and Nintendo DS.

Calculators
Variants of BASIC are available on graphing and otherwise programmable calculators made by Texas Instruments (TI-BASIC), HP (HP BASIC), Casio (Casio BASIC), and others.

Windows command-line
QBasic, a version of Microsoft QuickBASIC without the linker to make EXE files, is present in the Windows NT and DOS-Windows 95 streams of operating systems and can be obtained for more recent releases like Windows 7 which do not have them. Prior to DOS 5, the Basic interpreter was GW-Basic. QuickBasic is part of a series of three languages issued by Microsoft for the home and office power user and small-scale professional development; QuickC and QuickPascal are the other two. For Windows 95 and 98, which do not have QBasic installed by default, they can be copied from the installation disc, which will have a set of directories for old and optional software; other missing commands like Exe2Bin and others are in these same directories.

Other
The various Microsoft, Lotus, and Corel office suites and related products are programmable with Visual Basic in one form or another, including LotusScript, which is very similar to VBA 6. The Host Explorer terminal emulator uses WWB as a macro language; or more recently the programme and the suite in which it is contained is programmable in an in-house Basic variant known as Hummingbird Basic. The VBScript variant is used for programming web content, Outlook 97, Internet Explorer, and the Windows Script Host. WSH also has a Visual Basic for Applications (VBA) engine installed as the third of the default engines along with VBScript, JScript, and the numerous proprietary or open source engines which can be installed like PerlScript, a couple of Rexx-based engines, Python, Ruby, Tcl, Delphi, XLNT, PHP, and others; meaning that the two versions of Basic can be used along with the other mentioned languages, as well as LotusScript, in a WSF file, through the component object model, and other WSH and VBA constructions. VBScript is one of the languages that can be accessed by the 4Dos, 4NT, and Take Command enhanced shells. SaxBasic and WWB are also very similar to the Visual Basic line of Basic implementations. The pre-Office 97 macro language for Microsoft Word is known as WordBASIC. Excel 4 and 5 use Visual Basic itself as a macro language. Chipmunk Basic, an old-school interpreter similar to BASICs of the 1970s, is available for Linux, Microsoft Windows and macOS.

Legacy
The ubiquity of BASIC interpreters on personal computers was such that textbooks once included simple ""Try It In BASIC"" exercises that encouraged students to experiment with mathematical and computational concepts on classroom or home computers. Popular computer magazines of the day typically included type-in programs.
Futurist and sci-fi writer David Brin mourned the loss of ubiquitous BASIC in a 2006 Salon article as have others who first used computers during this era. In turn, the article prompted Microsoft to develop and release Small Basic; it also inspired similar projects like Basic-256 and the web based Quite Basic. Dartmouth held a 50th anniversary celebration for BASIC on 1 May 2014, as did other organisations; at least one organisation of VBA programmers organised a 35th anniversary observance in 1999. The pedagogical use of BASIC has been followed by other languages, such as Pascal, Java and particularly Python.Dartmouth College celebrated the 50th anniversary of the BASIC language with a day of events on April 30, 2014. A short documentary film was produced for the event.

Syntax
Typical BASIC keywords
Data manipulation
LET
assigns a value (which may be the result of an expression) to a variable. In most dialects of BASIC, LET is optional, and a line with no other identifiable keyword will assume the keyword to be LET.
DATA
holds a list of values which are assigned sequentially using the READ command.
READ
reads a value from a DATA statement and assigns it to a variable. An internal pointer keeps track of the last DATA element that was read and moves it one position forward with each READ. Most dialects allow multiple variables as parameters, reading several values in a single operation.
RESTORE
resets the internal pointer to the first DATA statement, allowing the program to begin READing from the first value. Many dialects allow an optional line number or ordinal value to allow the pointer to be reset to a selected location.
DIM
Sets up an array.

Program flow control
IF ... THEN ... {ELSE}
used to perform comparisons or make decisions. Early dialects only allowed a line number after the THEN, but later versions allowed any valid statement to follow. ELSE was not widely supported, especially in earlier versions.
FOR ... TO ... {STEP} ... NEXT
repeat a section of code a given number of times. A variable that acts as a counter, the ""index"", is available within the loop.
WHILE ... WEND and REPEAT ... UNTIL
repeat a section of code while the specified condition is true. The condition may be evaluated before each iteration of the loop, or after. Both of these commands are found mostly in later dialects.
DO ... LOOP {WHILE} or {UNTIL}
repeat a section of code indefinitely or while/until the specified condition is true. The condition may be evaluated before each iteration of the loop, or after. Similar to WHILE, these keywords are mostly found in later dialects.
GOTO
jumps to a numbered or labelled line in the program. Most dialects also allowed the form GO TO.
GOSUB ... RETURN
jumps to a numbered or labelled line, executes the code it finds there until it reaches a RETURN command, on which it jumps back to the statement following the GOSUB, either after a colon, or on the next line. This is used to implement subroutines.
ON ... GOTO/GOSUB
chooses where to jump based on the specified conditions. See Switch statement for other forms.
DEF FN
a pair of keywords introduced in the early 1960s to define functions. The original BASIC functions were modelled on FORTRAN single-line functions. BASIC functions were one expression with variable arguments, rather than subroutines, with a syntax on the model of DEF FND(x) = x*x at the beginning of a program. Function names were originally restricted to FN, plus one letter, i.e., FNA, FNB ...

Input and output
LIST
displays the full source code of the current program.
PRINT
displays a message on the screen or other output device.
INPUT
asks the user to enter the value of a variable. The statement may include a prompt message.
TAB
used with PRINT to set the position where the next character will be shown on the screen or printed on paper. AT is an alternative form.
SPC
prints out a number of space characters. Similar in concept to TAB but moves by a number of additional spaces from the current column rather than moving to a specified column.

Mathematical functions
ABS
Absolute value
ATN
Arctangent (result in radians)
COS
Cosine (argument in radians)
EXP
Exponential function
INT
Integer part (typically floor function)
LOG
Natural logarithm
RND
Random number generation
SIN
Sine (argument in radians)
SQR
Square root
TAN
Tangent (argument in radians)

Miscellaneous
REM
holds a programmer's comment or REMark; often used to give a title to the program and to help identify the purpose of a given section of code.
 USR (""User Serviceable Routine"")
transfers program control to a machine language subroutine, usually entered as an alphanumeric string or in a list of DATA statements.
CALL
alternative form of USR found in some dialects. Does not require an artificial parameter to complete the function-like syntax of USR, and has a clearly defined method of calling different routines in memory.
TRON /  TROFF
turns on display of each line number as it is run (""TRace ON""). This was useful for debugging or correcting of problems in a program. TROFF turns it back off again.
ASM
some compilers such as Freebasic, Purebasic, and Powerbasic also support inline assembly language, allowing the programmer to intermix high-level and low-level code, typically prefixed with ""ASM"" or ""!"" statements.

Data types and variables
Minimal versions of BASIC had only integer variables and one- or two-letter variable names, which minimized requirements of limited and expensive memory (RAM). More powerful versions had floating-point arithmetic, and variables could be labelled with names six or more characters long. There were some problems and restrictions in early implementations; for example, Applesoft BASIC allowed variable names to be several characters long, but only the first two were significant, thus it was possible to inadvertently write a program with variables ""LOSS"" and ""LOAN"", which would be treated as being the same; assigning a value to ""LOAN"" would silently overwrite the value intended as ""LOSS"". Keywords could not be used in variables in many early BASICs; ""SCORE"" would be interpreted as ""SC"" OR ""E"", where OR was a keyword. String variables are usually distinguished in many microcomputer dialects by having $ suffixed to their name as a sigil, and values are often identified as strings by being delimited by ""double quotation marks"". Arrays in BASIC could contain integers, floating point or string variables.
Some dialects of BASIC supported matrices and matrix operations, which can be used to solve sets of simultaneous linear algebraic equations. These dialects would directly support matrix operations such as assignment, addition, multiplication (of compatible matrix types), and evaluation of a determinant. Many microcomputer BASICs did not support this data type; matrix operations were still possible, but had to be programmed explicitly on array elements.

Examples
Unstructured BASIC
New BASIC programmers on a home computer might start with a simple program, perhaps using the language's PRINT statement to display a message on the screen; a well-known and often-replicated example is Kernighan and Ritchie's ""Hello, World!"" program:

An infinite loop could be used to fill the display with the message:

Note that the END statement is optional and has no action in most dialects of BASIC. It was not always included, as is the case in this example. This same program can be modified to print a fixed number of messages using the common FOR...NEXT statement:

Most home computers BASIC versions, such as MSX BASIC and GW-BASIC, supported simple data types, loop cycles, and arrays. The following example is written for GW-BASIC, but will work in most versions of BASIC with minimal changes:

The resulting dialog might resemble:

What is your name: Mike
Hello Mike
How many stars do you want: 7
*******
Do you want more stars? yes
How many stars do you want: 3
***
Do you want more stars? no
Goodbye Mike

The original Dartmouth Basic was unusual in having a matrix keyword, MAT. Although not implemented by most later microprocessor derivatives, it is used in this example from the 1968 manual which averages the numbers that are input:

Structured BASIC
Second-generation BASICs (for example, VAX Basic, SuperBASIC, True BASIC, QuickBASIC, BBC BASIC, Pick BASIC, PowerBASIC, Liberty BASIC, QB64 and (arguably) COMAL) introduced a number of features into the language, primarily related to structured and procedure-oriented programming. Usually, line numbering is omitted from the language and replaced with labels (for GOTO) and procedures to encourage easier and more flexible design. In addition keywords and structures to support repetition, selection and procedures with local variables were introduced.
The following example is in Microsoft QuickBASIC:

Object-oriented BASIC
Third-generation BASIC dialects such as Visual Basic, Xojo, Gambas, StarOffice Basic, BlitzMax and PureBasic introduced features to support object-oriented and event-driven programming paradigm. Most built-in procedures and functions are now represented as methods of standard objects rather than operators. Also, the operating system became increasingly accessible to the BASIC language.
The following example is in Visual Basic .NET:

Standards
ANSI/ISO/IEC Standard for Minimal BASIC:
ANSI X3.60-1978 ""For minimal BASIC""
ISO/IEC 6373:1984 ""Data Processing—Programming Languages—Minimal BASIC""
ECMA-55 Minimal BASIC (withdrawn, similar to ANSI X3.60-1978)
ANSI/ISO/IEC Standard for Full BASIC:
ANSI X3.113-1987 ""Programming Languages Full BASIC""
INCITS/ISO/IEC 10279-1991 (R2005) ""Information Technology – Programming Languages – Full BASIC""
ANSI/ISO/IEC Addendum Defining Modules:
ANSI X3.113 Interpretations-1992 ""BASIC Technical Information Bulletin # 1 Interpretations of ANSI 03.113-1987""
ISO/IEC 10279:1991/ Amd 1:1994 ""Modules and Single Character Input Enhancement""
ECMA-116 BASIC (withdrawn, similar to ANSI X3.113-1987)

Compilers and interpreters
See also
List of BASIC dialects

Notes
References
General references
External links

BASIC at Curlie
""BASIC—Beginners All-purpose Symbolic Instruction Code"". The Encyclopedia of Computer Languages. Murdoch University.
The Birth of Basic on YouTube
gotBASIC.com - For all people interested in the continued usage and evolution of the BASIC programming language.
Awesome Basic - A curated list of awesome BASIC dialects, IDEs, and tutorials.
The Basics' page (Since 2001) - Comprehensive listing of dialects.",4015,https://en.wikipedia.org/wiki/BASIC
Behavioral Description Language,"Behavioral Description Language (BDL) is a programming language based on ANSI C with extensions for hardware description, developed to describe hardware at levels ranging from the algorithm level to the functional level.Although the term Behavioral Description Language is a generic term and can refer to multiple high-level description languages, NEC Corporation has developed a C-subset called BDL for High-Level Synthesis. This C-subset includes its own data types (called var-class), special constants for hardware design e.g. high impedance, timing descriptors and control statements.
As BDL is meant for Hardware synthesis, the complete ANSI-C syntax is not supported. The principal unsupported operations are: (i) Floating point data types (ii) Sizeof operator (iii) unions and (iv) Recursive functions.
BDL is sometimes also known as Cyber C because it is synthesized using NEC's High-Level Synthesis tool called CyberWorkBench [1].","Behavioral Description Language (BDL) is a programming language based on ANSI C with extensions for hardware description, developed to describe hardware at levels ranging from the algorithm level to the functional level.Although the term Behavioral Description Language is a generic term and can refer to multiple high-level description languages, NEC Corporation has developed a C-subset called BDL for High-Level Synthesis. This C-subset includes its own data types (called var-class), special constants for hardware design e.g. high impedance, timing descriptors and control statements.
As BDL is meant for Hardware synthesis, the complete ANSI-C syntax is not supported. The principal unsupported operations are: (i) Floating point data types (ii) Sizeof operator (iii) unions and (iv) Recursive functions.
BDL is sometimes also known as Cyber C because it is synthesized using NEC's High-Level Synthesis tool called CyberWorkBench [1].

References

Wakabayashi, K.; Okamoto, T. (2006). ""C-based SoC design flow and EDA tools: an ASIC and system vendor perspective"". IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. 19 (12): 1507–1522. doi:10.1109/43.898829.",28806128,https://en.wikipedia.org/wiki/Behavioral_Description_Language
BLISS,"BLISS is a system programming language developed at Carnegie Mellon University (CMU) by W. A. Wulf, D. B. Russell, and A. N. Habermann around 1970. It was perhaps the best known system language until C debuted a few years later. Since then, C became popular and common, and BLISS faded into obscurity. When C was in its infancy, a few projects within Bell Labs debated the merits of BLISS vs. C.BLISS is a typeless block-structured programming language based on expressions rather than statements, and includes constructs for exception handling, coroutines, and macros. It does not include a goto statement.
The name is variously said to be short for Basic Language for Implementation of System Software or System Software Implementation Language, Backwards. However, in his 2015 oral history for the Babbage Institute's Computer Security History Project, Wulf claimed that the acronym was originally based on the name ""Bill's Language for Implementing System Software.""The original Carnegie Mellon compiler was notable for its extensive use of optimizations, and formed the basis of the classic book The Design of an Optimizing Compiler.
Digital Equipment Corporation (DEC) developed and maintained BLISS compilers for the PDP-10, PDP-11, VAX, DEC PRISM, MIPS, DEC Alpha, and Intel IA-32, The language did not become popular among customers and few had the compiler, but DEC used it heavily in-house into the 1980s; most of the utility programs for the OpenVMS operating system were written in BLISS-32. The DEC BLISS compiler has been ported to the IA-64 and x86-64 architectures as part of the ports of OpenVMS to these platforms. The x86-64 BLISS compiler uses LLVM as its backend code generator, replacing the proprietary GEM backend used for Alpha and IA-64.","BLISS is a system programming language developed at Carnegie Mellon University (CMU) by W. A. Wulf, D. B. Russell, and A. N. Habermann around 1970. It was perhaps the best known system language until C debuted a few years later. Since then, C became popular and common, and BLISS faded into obscurity. When C was in its infancy, a few projects within Bell Labs debated the merits of BLISS vs. C.BLISS is a typeless block-structured programming language based on expressions rather than statements, and includes constructs for exception handling, coroutines, and macros. It does not include a goto statement.
The name is variously said to be short for Basic Language for Implementation of System Software or System Software Implementation Language, Backwards. However, in his 2015 oral history for the Babbage Institute's Computer Security History Project, Wulf claimed that the acronym was originally based on the name ""Bill's Language for Implementing System Software.""The original Carnegie Mellon compiler was notable for its extensive use of optimizations, and formed the basis of the classic book The Design of an Optimizing Compiler.
Digital Equipment Corporation (DEC) developed and maintained BLISS compilers for the PDP-10, PDP-11, VAX, DEC PRISM, MIPS, DEC Alpha, and Intel IA-32, The language did not become popular among customers and few had the compiler, but DEC used it heavily in-house into the 1980s; most of the utility programs for the OpenVMS operating system were written in BLISS-32. The DEC BLISS compiler has been ported to the IA-64 and x86-64 architectures as part of the ports of OpenVMS to these platforms. The x86-64 BLISS compiler uses LLVM as its backend code generator, replacing the proprietary GEM backend used for Alpha and IA-64.

Language description
BLISS has many of the features of other modern high-level languages. It has block structure, an automatic stack, and mechanisms for defining and calling recursive routines ... provides a variety of predefined data structures and ... facilities for testing and iteration ...
On the other hand, BLISS omits certain features of other high-level languages. It does not have built-in facilities for input/output, because a system-software project usually develops its own input/output or builds on basic monitor I/O or screen management services ... it permits access to machine-specific features, because system software often requires this. BLISS has characteristics that are unusual among high-level languages. A name ... is uniformly interpreted as the address of that segment rather than the value of the segment ... Also, BLISS is an ""expression language"" rather than a ""statement language"".

This means that every construct of the language that is not a declaration is an expression. Expressions produce a value as well as possibly causing an action such as modification of storage, transfer of control, or execution of a program loop. For example, the counterpart of an assignment ""statement"" in BLISS is, strictly speaking, an expression that itself has a value. The value of an expression can be either used or discarded in BLISS ... Finally, BLISS includes a macro facility that provides a level of capability usually found only in macro-assemblers.
The BLISS language has the following characteristics:

All constants are full word for the machine being used, e.g. on a 16-bit machine such as the PDP-11, a constant is 16 bits; on a VAX computer, constants are 32 bits, and on a PDP-10, a constant is 36 bits.
A reference to a variable is always to the address of that variable. For example, the instruction Z+8 refers to adding 8 to the address of Z, not to its value. If one needs to add 8 to the value of Z, one must prefix the variable with a period; so one would type .Z+8 to perform this function, which adds 8 to the contents of Z.
Assignment is done with the standard = symbol, e.g. Z=8 – which says to create a full-word constant containing 8, and store it in the location whose address corresponds to that of Z. So Z+12=14 (or, alternatively 12+Z=14) places the constant 14 into the location which is 12 words after the address of Z. (This is considered bad practice.)
Block statements are similar to those of ALGOL: a block is started with a BEGIN statement and terminated with END. As with ALGOL, statements are terminated with the semicolon ("";""). When a value is computed, it is saved until the next statement terminator – which means that a value can be computed, assigned to a variable, and carried forward to the next statement, if desired. Alternatively, an open parenthesis may be used to begin a block, with the close parenthesis used to close the block. When parentheses are included in an expression, the standard precedence rules are used, in which parenthesized expressions are computed first,
Conditional execution uses the IF expression, which tests a true-false condition, performs alternative actions, and returns a result.
Comparison uses keywords such as EQL for equality (as opposed to overloading the = symbol for the same purpose), GTR for Greater Than, and NEQ for not equal. For example, the following code will assign the absolute value of Z to the address indicated by Q:Q = (IF .Z GTR 0 THEN .Z ELSE -.Z);Identifiers (variables and constants) must be declared before use, typically using the OWN keyword. Declaring a variable normally causes the compiler to allocate space for it; when necessary, a variable may be assigned a fixed machine address via the BIND declaration. This feature is primarily used for accessing either machine registers or certain special addresses.
Subroutines in the language are called routines, and are declared with the keyword ROUTINE.
Macros, which allow for text substitution, are declared with the keyword MACRO.
The language supports arrays, which are referred to as structures, and declared with the keyword VECTOR.
The language supports some high-level programming language constructs such as:
Alternative execution paths via the CASE expression
Looping through use of the INCR expression, which is similar to ALGOL's FOR statement
Built-in string functions
Certain automatic data conversions (number to string, etc.)

Source example
The following example is taken verbatim from the Bliss Language Manual:

Versions
BLISS-10
BLISS-11 - a cross compiler for the PDP-11
BLISS-16
BLISS-16C - DEC version of BLISS-11
BLISS-32
BLISS-36
BLISS-64
Common BLISS - portable subset

Notes
References
Wulf, W. A.; Russell, D. B.; Habermann, A. N. (December 1971). ""BLISS: A Language for Systems Programming"" (PDF). Communications of the ACM. 14 (12): 780–790. doi:10.1145/362919.362936. S2CID 9564255. Also: ""BLISS: A Language for Systems Programming"". (PostScript)
Wulf, W. A.; Johnson, R. K.; Weinstock, C. B.; Hobbs, S. O.; Geschke, C. M. (1975). The Design of an Optimizing Compiler. New York: Elsevier, ISBN 0-444-00158-1.
Brender, Ronald F. (2002). ""The BLISS programming language: a history"" (PDF). Software: Practice and Experience. 32 (10): 955–981. doi:10.1002/spe.470. S2CID 45466625.

External links
BLISS Manual at DECUS
Lehotsky, Alan; a post about BLISS at DEC
Madison, Matthew D.; Session notes for ""Introduction to BLISS"" (PostScript)

Downloads
BLISS-10
BLISS-11
BLISS-36
BLISS-11, BLISS-32 and BLISS-64
FreeVMS Portable BLISS for GCC",390261,https://en.wikipedia.org/wiki/BLISS
Boo (programming language),"Boo is an object-oriented, statically typed, general-purpose programming language that seeks to make use of the Common Language Infrastructure's support for Unicode, internationalization, and web applications, while using a Python-inspired syntax and a special focus on language and compiler extensibility. Some features of note include type inference, generators, multimethods, optional duck typing, macros, true closures, currying, and first-class functions.
Boo was one of the three scripting languages for the Unity game engine (Unity Technologies employed De Oliveira, its designer), until official support was dropped in 2014 due to the small userbase. The Boo Compiler was removed from the engine in 2017. Boo has since been abandoned by De Oliveira, with development being taken over by Mason Wheeler.Boo is free software released under the BSD 3-Clause license. It is compatible with the Microsoft .NET and Mono frameworks.","Boo is an object-oriented, statically typed, general-purpose programming language that seeks to make use of the Common Language Infrastructure's support for Unicode, internationalization, and web applications, while using a Python-inspired syntax and a special focus on language and compiler extensibility. Some features of note include type inference, generators, multimethods, optional duck typing, macros, true closures, currying, and first-class functions.
Boo was one of the three scripting languages for the Unity game engine (Unity Technologies employed De Oliveira, its designer), until official support was dropped in 2014 due to the small userbase. The Boo Compiler was removed from the engine in 2017. Boo has since been abandoned by De Oliveira, with development being taken over by Mason Wheeler.Boo is free software released under the BSD 3-Clause license. It is compatible with the Microsoft .NET and Mono frameworks.

Syntax
See also
Fantom
Apache Groovy
IronPython
IronRuby
Nemerle
REBOL
StaDyn

References
External links
Official website
How To Think Like a Computer Scientist: Learning to Program with Boo
Boo Succinctly Revealed
Bootorial",1147624,https://en.wikipedia.org/wiki/Boo_(programming_language)
Boomerang (programming language),"Boomerang is a programming language for writing lenses—well-behaved bidirectional transformations —that operate on ad-hoc, textual data formats.
Boomerang grew out of the Harmony generic data synchronizer, which grew out of the Unison file synchronization project.","Boomerang is a programming language for writing lenses—well-behaved bidirectional transformations —that operate on ad-hoc, textual data formats.
Boomerang grew out of the Harmony generic data synchronizer, which grew out of the Unison file synchronization project.

References
External links
Official website
Mailing list",21008097,https://en.wikipedia.org/wiki/Boomerang_(programming_language)
Bs (programming language),"bs is a programming language and a compiler/interpreter for modest-sized programs on UNIX systems. The bs command can be invoked either for interactive programming or with a file containing a program, optionally taking arguments, via a Unix shell, e.g., using a Shebang (Unix) #!/usr/bin/bs.
An early man page states, ""[bs] is a remote descendant of Basic [sic] and SNOBOL4, with a little C thrown in.""","bs is a programming language and a compiler/interpreter for modest-sized programs on UNIX systems. The bs command can be invoked either for interactive programming or with a file containing a program, optionally taking arguments, via a Unix shell, e.g., using a Shebang (Unix) #!/usr/bin/bs.
An early man page states, ""[bs] is a remote descendant of Basic [sic] and SNOBOL4, with a little C thrown in.""

History
The bs command appears in UNIX System III Release 3.0 (1980), first released outside of Bell Labs in 1982. It was written by Dick Haight (Richard C. Haight) circa 1978, who recounts it as follows:
I wrote bs at the time Unix (V 3?) and all of the commands were being converted from assembler to C. So [ Ken Thompson’s ] bas became my bs — sort of.
The Release 3.0 manual mentions bs prominently on page 9 (emphasis added):
Writing a program. To enter the text of a source program into a UNIX file, use ed(1). The four principal languages available under UNIX are C (see cc(1)), Fortran (see f77(1)), bs (a compiler/interpreter in the spirit of Basic, see bs(1)), and assembly language (see as(1)).
While not released outside prior to System III, the bs command was present internally in UNIX/TS 1.0 (November 1978), PWB/UNIX 2.0 (June 1979), and CB UNIX editions 2.1 (November 1979) and 2.3 (1981).
The bs command does not appear in some earlier internal releases, e.g., the UNIX Support Group’s March 1977 release, nor the PWB/UNIX manual dated May, 1977, suggesting its creation circa 1978. It does not appear in any version of Research Unix nor the Berkeley Software Distribution.
Subsequently and into the 1990s, bs was included in a variety of System III-derived or System V-derived commercial operating systems including, but not limited to: PC/IX; UNIX System V Releases 2 & 3: SVR2, SVR3, SVR3.2 (1986); HP-UX; AIX; and A/UX.
(The User's Manual for the AT&T UNIX PC (3B1) specifically mentions that the bs command is not available, but that it is available on SVR3.2.)
Occasionally, bs was touted as one of the primary programming languages for development under UNIX. However, bs is not included in the POSIX.1 commands and utilities (the standard List of Unix commands) nor in the Single UNIX Specification and is not provided with most contemporary operating systems. For example in Linux, similar syntax and functionality is provided by bc, Perl, and POSIX shell.
In the 21st century, bs is present in, at least, HP-UX Release 11i (2000), as well as AIX versions 6.1 (2007) and 7.2 (2018), likely due to their UNIX System V heritage.

Design and features
The bs man page, ostensibly the programming language's only specification, characterizes it as follows:

Bs is designed for programming tasks where program development time is as important as the resulting speed of execution. Formalities of data declaration and file/process manipulation are minimized. Line-at-a-time debugging, the trace and dump statements, and useful run-time  error messages all simplify program testing. Furthermore, incomplete programs can be debugged; inner functions can be tested before outer functions have been written and vice versa.
A bs program is compiled and executed differently from programs written in the other principal Unix programming languages of the time: C, FORTRAN, and assembly language, whose respective commands compile program source code to executable assembler output (a.out). Instead, a bs program is, first, converted by the bs command to an internal reverse Polish (RPN) intermediate representation and then executed by the command's internal virtual stack machine. The bs language, thus, is a hybrid interpreter and compiler and a divergence in Unix programming from Ancient Unix.
The bs language shares some features and syntax with BASIC, SNOBOL, and C, the two former presumably inspiring its name. Like BASIC, it can be used interactively, either executing statements immediately or collecting them into a program to be executed subsequently. Like in SNOBOL4, the assignment operator (=) is used for I/O and bs can execute code in strings, using its eval function. It also includes SNOBOL's interrogation operator (?) used to test whether an expression evaluation succeeds or not. The built-in format function, limited to one argument, supports a subset of C's printf format conversion specifiers, e.g., ""%f"".
The language has some conspicuous elements. For instance, its program functions are defined using the fun ... nuf syntax and its functions can have local variables. Also, bs can operate in two modes, either interpreting (and executing) statements and programs or compiling them, and switching between the two using compile and stop. Otherwise, its functionality is unique only collectively (in one language), since individual features are redundant with those of coexisting tools, such as the Unix Shell, e.g., file I/O and loops, and AWK, e.g., associative arrays and Regular expression matching.
The bs language was meant for convenient development and debugging of small, modular programs. It has a collection of syntax and features from prior, popular languages but it is internally compiled, unlike a Shell script. As such, in purpose, design, and function, bs is a largely unknown, modest predecessor of hybrid interpreted/compiled languages such as Perl and Python.

Syntax Examples
The following examples are derived from an A/UX bs(1) man page.This example uses bs as a calculator:

This example is the outline of a typical bs program:

This example demonstrates I/O:

Sample Program
The following is a sample bs program that emits the words to the song 99 Bottles of Beer using /usr/bin/bs.

See also
dc
bc


== References ==",43779466,https://en.wikipedia.org/wiki/Bs_(programming_language)
Cameleon (programming language),"Cameleon is a free and open source graphical language for functional programming, released under an MIT License.
Cameleon language is a graphical data flow language following a two-scale paradigm. It allows an easy up-scale, that is, the integration of any library writing in C++ into the data flow language. Cameleon language aims to democratize macro-programming by an intuitive interaction between the human and the computer where building an application based on a data-process and a GUI is a simple task to learn and to do. Cameleon language allows conditional execution and repetition to solve complex macro-problems.
Cameleon is built on an extension of the petri net model for the description of how the Cameleon language executes a composition.","Cameleon is a free and open source graphical language for functional programming, released under an MIT License.
Cameleon language is a graphical data flow language following a two-scale paradigm. It allows an easy up-scale, that is, the integration of any library writing in C++ into the data flow language. Cameleon language aims to democratize macro-programming by an intuitive interaction between the human and the computer where building an application based on a data-process and a GUI is a simple task to learn and to do. Cameleon language allows conditional execution and repetition to solve complex macro-problems.
Cameleon is built on an extension of the petri net model for the description of how the Cameleon language executes a composition.

Features
Graphical Algorithm Editor,
Real time calibration,
Dynamic building,
Multi-Scale approach,
XML-based model for data definition and manipulation based on XML Schema, XPath and XQuery,
Easy integration of new algorithm with the dev kit.

See also
Bioinformatics workflow management system
Business Process Management
CEITON
Dataflow
Petri net
Programming language
Visual programming language
Workflow
Workflow patterns
YAWL

References
George Pashev, George Totkov, EMS – A Workflow Programming Language and Environment, TEM Journal, 2018
JM Pereira, Modern Trends in Geomechanics, 2016
Kenichi Soga, Krishna Kumar, Giovanna Biscontin, Geomechanics from Micro to Macro, Technology & Engineering, 2014
Nasser Khalili, Adrian Russell, Arman Khoshghalb, Unsaturated Soils: Research & Applications, Technology & Engineering, 2014
J.-F. Bruchon, Effondrement capillaire, 2014
J.-F. Bruchon, J.-M. Pereira, M. Vandamme, N. Lenoir, P. Delage, M. Bornert, Full 3D investigation and characterisation of capillary collapse of a loose unsaturated sand using X-ray CT. Granular Matter, 2013 SegSand
J.-F Bruchon., Pereira J.-M., M., Vandamme, N. Lenoir, P. Delage and M. Bornert X-ray microtomography characterisation of the changes in statistical homogeneity of an unsaturated sand during imbibition Géotechnique letter, 2013
IPOL communication, 2012
Programmation par propriétés : application au traitement d’images, 2010
Cameleon language Part 1: Processor O. Cugnon de Sevricourt, V. Tariel, 2011

External links
Official Web Site",42573172,https://en.wikipedia.org/wiki/Cameleon_(programming_language)
C Sharp (programming language),"C# ( see SHARP) is a general-purpose high-level programming language supporting multiple paradigms. C# encompasses static typing,: 4  strong typing, lexically scoped, imperative, declarative, functional, generic,: 22  object-oriented (class-based), and component-oriented programming disciplines.The C# programming language was designed by Anders Hejlsberg from Microsoft in 2000 and was later approved as an international standard by Ecma (ECMA-334) in 2002 and ISO/IEC (ISO/IEC 23270 and 20619) in 2003. Microsoft introduced C# along with .NET Framework and Visual Studio, both of which were closed-source. At the time, Microsoft had no open-source products. Four years later, in 2004, a free and open-source project called Mono began, providing a cross-platform compiler and runtime environment for the C# programming language. A decade later, Microsoft released Visual Studio Code (code editor), Roslyn (compiler), and the unified .NET platform (software framework), all of which support C# and are free, open-source, and cross-platform. Mono also joined Microsoft but was not merged into .NET.
As of November 2023, the most recent stable version of the language is C# 12.0, which was released in 2023 in .NET 8.0.","C# ( see SHARP) is a general-purpose high-level programming language supporting multiple paradigms. C# encompasses static typing,: 4  strong typing, lexically scoped, imperative, declarative, functional, generic,: 22  object-oriented (class-based), and component-oriented programming disciplines.The C# programming language was designed by Anders Hejlsberg from Microsoft in 2000 and was later approved as an international standard by Ecma (ECMA-334) in 2002 and ISO/IEC (ISO/IEC 23270 and 20619) in 2003. Microsoft introduced C# along with .NET Framework and Visual Studio, both of which were closed-source. At the time, Microsoft had no open-source products. Four years later, in 2004, a free and open-source project called Mono began, providing a cross-platform compiler and runtime environment for the C# programming language. A decade later, Microsoft released Visual Studio Code (code editor), Roslyn (compiler), and the unified .NET platform (software framework), all of which support C# and are free, open-source, and cross-platform. Mono also joined Microsoft but was not merged into .NET.
As of November 2023, the most recent stable version of the language is C# 12.0, which was released in 2023 in .NET 8.0.

Design goals
The Ecma standard lists these design goals for C#:
The language is intended to be a simple, modern, general-purpose, object-oriented programming language.
The language, and implementations thereof, should provide support for software engineering principles such as strong type checking, array bounds checking,: 58–59  detection of attempts to use uninitialized variables, and automatic garbage collection.: 563  Software robustness, durability, and programmer productivity are important.
The language is intended for use in developing software components suitable for deployment in distributed environments.
Portability is very important for source code and programmers, especially those already familiar with C and C++.
Support for internationalization: 314  is very important.
C# is intended to be suitable for writing applications for both hosted and embedded systems, ranging from the very large that use sophisticated operating systems, down to the very small having dedicated functions.
Although C# applications are intended to be economical with regard to memory and processing power requirements, the language was not intended to compete directly on performance and size with C or assembly language.

History
During the development of the .NET Framework, the class libraries were originally written using a managed code compiler system called ""Simple Managed C"" (SMC). In January 1999, Anders Hejlsberg formed a team to build a new language at the time called Cool, which stood for ""C-like Object Oriented Language"". Microsoft had considered keeping the name ""Cool"" as the final name of the language, but chose not to do so for trademark reasons. By the time the .NET project was publicly announced at the July 2000 Professional Developers Conference, the language had been renamed C#, and the class libraries and ASP.NET runtime had been ported to C#.
Hejlsberg is C#'s principal designer and lead architect at Microsoft, and was previously involved with the design of Turbo Pascal, Embarcadero Delphi (formerly CodeGear Delphi, Inprise Delphi and Borland Delphi), and Visual J++. In interviews and technical papers he has stated that flaws in most major programming languages (e.g. C++, Java, Delphi, and Smalltalk) drove the fundamentals of the Common Language Runtime (CLR), which, in turn, drove the design of the C# language itself.
James Gosling, who created the Java programming language in 1994, and Bill Joy, a co-founder of Sun Microsystems, the originator of Java, called C# an ""imitation"" of Java; Gosling further said that ""[C# is] sort of Java with reliability, productivity and security deleted."" 
In July 2000, Hejlsberg said that C# is ""not a Java clone"" and is ""much closer to C++"" in its design.Since the release of C# 2.0 in November 2005, the C# and Java languages have evolved on increasingly divergent trajectories, becoming two quite different languages. One of the first major departures came with the addition of generics to both languages, with vastly different implementations. C# makes use of reification to provide ""first-class"" generic objects that can be used like any other class, with code generation performed at class-load time.
Furthermore, C# has added several major features to accommodate functional-style programming, culminating in the LINQ extensions released with C# 3.0 and its supporting framework of lambda expressions, extension methods, and anonymous types.  These features enable C# programmers to use functional programming techniques, such as closures, when it is advantageous to their application. The LINQ extensions and the functional imports help developers reduce the amount of boilerplate code that is included in common tasks like querying a database, parsing an xml file, or searching through a data structure, shifting the emphasis onto the actual program logic to help improve readability and maintainability.C# used to have a mascot called Andy (named after Anders Hejlsberg). It was retired on January 29, 2004.C# was originally submitted to the ISO/IEC JTC 1 subcommittee SC 22 for review, under ISO/IEC 23270:2003, was withdrawn and was then approved under ISO/IEC 23270:2006. The 23270:2006 is withdrawn under 23270:2018 and approved with this version.

Name
Microsoft first used the name C# in 1988 for a variant of the C language designed for incremental compilation. That project was not completed, and the name was later reused.

The name ""C sharp"" was inspired by the musical notation whereby a sharp symbol indicates that the written note should be made a semitone higher in pitch.
This is similar to the language name of C++, where ""++"" indicates that a variable should be incremented by 1 after being evaluated. The sharp symbol also resembles a ligature of four ""+"" symbols (in a two-by-two grid), further implying that the language is an increment of C++.Due to technical limitations of display (standard fonts, browsers, etc.) and the fact that the sharp symbol (U+266F ♯ MUSIC SHARP SIGN (&sharp;)) is not present on most keyboard layouts, the number sign (U+0023 # NUMBER SIGN (&num;)) was chosen to approximate the sharp symbol in the written name of the programming language.
This convention is reflected in the ECMA-334 C# Language Specification.The ""sharp"" suffix has been used by a number of other .NET languages that are variants of existing languages, including J# (a .NET language also designed by Microsoft that is derived from Java 1.1), A# (from Ada), and the functional programming language F#. The original implementation of Eiffel for .NET was called Eiffel#, a name retired since the full Eiffel language is now supported. The suffix has also been used for libraries, such as Gtk# (a .NET wrapper for GTK and other GNOME libraries) and Cocoa# (a wrapper for Cocoa).

Versions
Syntax
The core syntax of the C# language is similar to that of other C-style languages such as C, C++ and Java, particularly:

Semicolons are used to denote the end of a statement.
Curly brackets are used to group statements. Statements are commonly grouped into methods (functions), methods into classes, and classes into namespaces.
Variables are assigned using an equals sign, but compared using two consecutive equals signs.
Square brackets are used with arrays, both to declare them and to get a value at a given index in one of them.

Distinguishing features
Some notable features of C# that distinguish it from C, C++, and Java where noted, are:

Portability
By design, C# is the programming language that most directly reflects the underlying Common Language Infrastructure (CLI).  Most of its intrinsic types correspond to value-types implemented by the CLI framework. However, the language specification does not state the code generation requirements of the compiler: that is, it does not state that a C# compiler must target a Common Language Runtime, or generate Common Intermediate Language (CIL), or generate any other specific format. Some C# compilers can also generate machine code like traditional compilers of C++ or Fortran.

Typing
C# supports strongly, implicitly typed variable declarations with the keyword var,: 470  and implicitly typed arrays with the keyword new[] followed by a collection initializer.: 80 : 58 C# supports a strict Boolean data type, bool. Statements that take conditions, such as while and if, require an expression of a type that implements the true operator, such as the Boolean type. While C++ also has a Boolean type, it can be freely converted to and from integers, and expressions such as if (a) require only that a is convertible to bool, allowing a to be an int, or a pointer. C# disallows this ""integer meaning true or false"" approach, on the grounds that forcing programmers to use expressions that return exactly bool can prevent certain types of programming mistakes such as if (a = b) (use of assignment = instead of equality ==).
C# is more type safe than C++. The only implicit conversions by default are those that are considered safe, such as widening of integers. This is enforced at compile-time, during JIT, and, in some cases, at runtime. No implicit conversions occur between Booleans and integers, nor between enumeration members and integers (except for literal 0, which can be implicitly converted to any enumerated type). Any user-defined conversion must be explicitly marked as explicit or implicit, unlike C++ copy constructors and conversion operators, which are both implicit by default.
C# has explicit support for covariance and contravariance in generic types,: 144 : 23  unlike C++ which has some degree of support for contravariance simply through the semantics of return types on virtual methods.
Enumeration members are placed in their own scope.
The C# language does not allow for global variables or functions. All methods and members must be declared within classes. Static members of public classes can substitute for global variables and functions.
Local variables cannot shadow variables of the enclosing block, unlike C and C++.

Metaprogramming
Metaprogramming can be achieved in several ways:

Reflection is supported through .NET APIs, which enable scenarios such as type metadata inspection and dynamic method invocation.
Expression trees represent code as an abstract syntax tree, where each node is an expression that can be inspected or executed. This enables dynamic modification of executable code at runtime. Expression trees introduce some homoiconicity to the language.
Attributes are metadata that can be attached to types, members, or entire assemblies, equivalent to annotations in Java. Attributes are accessible both to the compiler and to code through reflection. Many of native attributes duplicate the functionality of GCC's and VisualC++'s platform-dependent preprocessor directives.
System.Reflection.Emit namespace, which contains classes that emit metadata and CIL (types, assemblies, etc) at runtime.
The .NET Compiler Platform (Roslyn) provides API access to language compilation services, allowing for the compilation of C# code from within .NET applications. It exposes APIs for syntactic (lexical) analysis of code, semantic analysis, dynamic compilation to CIL, and code emission.
Source generators, a feature of the Roslyn C# compiler, enable compile time metaprogramming. During the compilation process, developers can inspect the code being compiled with the compiler's API and pass additional generated C# source code to be compiled.

Methods and functions
A method in C# is a member of a class that can be invoked as a function (a sequence of instructions), rather than the mere value-holding capability of a field (i.e. class or instance variable). As in other syntactically similar languages, such as C++ and ANSI C, the signature of a method is a declaration comprising in order: any optional accessibility keywords (such as private), the explicit specification of its return type (such as int, or the keyword void if no value is returned), the name of the method, and finally, a parenthesized sequence of comma-separated parameter specifications, each consisting of a parameter's type, its formal name and optionally, a default value to be used whenever none is provided. Certain specific kinds of methods, such as those that simply get or set a class property by return value or assignment, do not require a full signature, but in the general case, the definition of a class includes the full signature declaration of its methods.
Like C++, and unlike Java, C# programmers must use the scope modifier keyword virtual to allow methods to be overridden by subclasses.Extension methods in C# allow programmers to use static methods as if they were methods from a class's method table, allowing programmers to add methods to an object that they feel should exist on that object and its derivatives.: 103–105 : 202–203 The type dynamic allows for run-time method binding, allowing for JavaScript-like method calls and run-time object composition.: 114–118 C# has support for strongly-typed function pointers via the keyword delegate. Like the Qt framework's pseudo-C++ signal and slot, C# has semantics specifically surrounding publish-subscribe style events, though C# uses delegates to do so.
C# offers Java-like synchronized method calls, via the attribute [MethodImpl(MethodImplOptions.Synchronized)], and has support for mutually-exclusive locks via the keyword lock.

Property
C# supports classes with properties. The properties can be simple accessor functions with a backing field, or implement getter and setter functions.
Since C# 3.0 the syntactic sugar of auto-implemented properties is available, where the accessor (getter) and mutator (setter) encapsulate operations on a single attribute of a class.

Namespace
A C# namespace provides the same level of code isolation as a Java package or a C++ namespace, with very similar rules and features to a package. Namespaces can be imported with the ""using"" syntax.

Memory access
In C#, memory address pointers can only be used within blocks specifically marked as unsafe, and programs with unsafe code need appropriate permissions to run. Most object access is done through safe object references, which always either point to a ""live"" object or have the well-defined null value; it is impossible to obtain a reference to a ""dead"" object (one that has been garbage collected), or to a random block of memory. An unsafe pointer can point to an instance of an unmanaged value type that does not contain any references to objects subject to garbage collections such as class instances, arrays or strings. Code that is not marked as unsafe can still store and manipulate pointers through the System.IntPtr type, but it cannot dereference them.
Managed memory cannot be explicitly freed; instead, it is automatically garbage collected. Garbage collection addresses the problem of memory leaks by freeing the programmer of responsibility for releasing memory that is no longer needed in most cases. Code that retains references to objects longer than is required can still experience higher memory usage than necessary, however once the final reference to an object is released the memory is available for garbage collection.

Exception
A range of standard exceptions are available to programmers. Methods in standard libraries regularly throw system exceptions in some circumstances and the range of exceptions thrown is normally documented. Custom exception classes can be defined for classes allowing handling to be put in place for particular circumstances as needed.Checked exceptions are not present in C# (in contrast to Java). This has been a conscious decision based on the issues of scalability and versionability.

Polymorphism
Unlike C++, C# does not support multiple inheritance, although a class can implement any number of ""interfaces"" (fully abstract classes). This was a design decision by the language's lead architect to avoid complications and to simplify architectural requirements throughout CLI.
When implementing multiple interfaces that contain a method with the same name and taking parameters of the same type in the same order (i.e. the same signature), similar to Java, C# allows both a single method to cover all interfaces and if necessary specific methods for each interface.
However, unlike Java, C# supports operator overloading.

Language Integrated Query (LINQ)
C# has the ability to utilize LINQ through the .NET Framework. A developer can query a variety of data sources, provided IEnumerable<T> interface is implemented on the object. This includes XML documents, an ADO.NET dataset, and SQL databases.Using LINQ in C# brings advantages like IntelliSense support, strong filtering capabilities, type safety with compile error checking ability, and consistency for querying data over a variety of sources.  There are several different language structures that can be utilized with C# and LINQ and they are query expressions, lambda expressions, anonymous types, implicitly typed variables, extension methods, and object initializers.LINQ has two syntaxes: query syntax and method syntax. However, the compiler always converts the query syntax to method syntax at compile time.

Functional programming
Though primarily an imperative language, C# always adds functional features over time, for example:

Functions as first-class citizen – C# 1.0 delegates
Higher-order functions – C# 1.0 together with delegates
Anonymous functions – C# 2 anonymous delegates and C# 3 lambdas expressions
Closures – C# 2 together with anonymous delegates and C# 3 together with lambdas expressions
Type inference – C# 3 with implicitly typed local variables var and C# 9 target-typed new expressions new()
List comprehension – C# 3 LINQ
Tuples – .NET Framework 4.0 but it becomes popular when C# 7.0 introduced a new tuple type with language support
Nested functions – C# 7.0
Pattern matching – C# 7.0
Immutability – C# 7.2 readonly struct C# 9 record types and Init only setters
Type classes – C# 12 roles/extensions (in development)

Common type system
C# has a unified type system. This unified type system is called Common Type System (CTS).: Part 2, Chapter 4: The Type System A unified type system implies that all types, including primitives such as integers, are subclasses of the System.Object class. For example, every type inherits a ToString() method.

Categories of data types
CTS separates data types into two categories:
Reference types
Value typesInstances of value types neither have referential identity nor referential comparison semantics. Equality and inequality comparisons for value types compare the actual data values within the instances, unless the corresponding operators are overloaded. Value types are derived from System.ValueType, always have a default value, and can always be created and copied. Some other limitations on value types are that they cannot derive from each other (but can implement interfaces) and cannot have an explicit default (parameterless) constructor because they already have an implicit one which initializes all contained data to the type-dependent default value (0, null, or alike). Examples of value types are all primitive types, such as int (a signed 32-bit integer), float (a 32-bit IEEE floating-point number), char (a 16-bit Unicode code unit), and System.DateTime (identifies a specific point in time with nanosecond precision). Other examples are enum (enumerations) and struct (user defined structures).
In contrast, reference types have the notion of referential identity, meaning that each instance of a reference type is inherently distinct from every other instance, even if the data within both instances is the same. This is reflected in default equality and inequality comparisons for reference types, which test for referential rather than structural equality, unless the corresponding operators are overloaded (such as the case for System.String). Some operations are not always possible, such as creating an instance of a reference type, copying an existing instance, or performing a value comparison on two existing instances. Though specific reference types can provide such services by exposing a public constructor or implementing a corresponding interface (such as ICloneable or IComparable). Examples of reference types are object (the ultimate base class for all other C# classes), System.String (a string of Unicode characters), and System.Array (a base class for all C# arrays).
Both type categories are extensible with user-defined types.

Boxing and unboxing
Boxing is the operation of converting a value-type object into a value of a corresponding reference type. Boxing in C# is implicit.
Unboxing is the operation of converting a value of a reference type (previously boxed) into a value of a value type. Unboxing in C# requires an explicit type cast. A boxed object of type T can only be unboxed to a T (or a nullable T).Example:

Libraries
The C# specification details a minimum set of types and class libraries that the compiler expects to have available. In practice, C# is most often used with some implementation of the Common Language Infrastructure (CLI), which is standardized as ECMA-335 Common Language Infrastructure (CLI).
In addition to the standard CLI specifications, there are many commercial and community class libraries that build on top of the .NET framework libraries to provide additional functionality.C# can make calls to any library included in the List of .NET libraries and frameworks.

Examples
Hello World
The following is a very simple C# program, a version of the classic ""Hello world"" example using the top-level statements feature introduced in C# 9:

For code written as C# 8 or lower, the entry point logic of a program must be written in a Main method inside a type:

This code will display this text in the console window:

Hello, world!

Each line has a purpose:

The above line imports all types in the System namespace. For example, the Console class used later in the source code is defined in the System namespace, meaning it can be used without supplying the full name of the type (which includes the namespace).

This line is a comment; it describes and documents the code for the programmer(s).
Above is a class definition for the Program class. Everything that follows between the pair of braces describes that class.The curly brackets demarcate the boundaries of a code block. In this first instance, they are marking the start and end of the Program class.
This declares the class member method where the program begins execution. The .NET runtime calls the Main method. Unlike in Java, the Main method does not need the public keyword, which tells the compiler that the method can be called from anywhere by any class. Writing static void Main(string[] args) is equivalent to writing private static void Main(string[] args). The static keyword makes the method accessible without an instance of Program. Each console application's Main entry point must be declared static otherwise the program would require an instance of Program, but any instance would require a program. To avoid that irresolvable circular dependency, C# compilers processing console applications (like that above) report an error if there is no static Main method. The void keyword declares that Main has no return value. (Note, however, that short programs can be written using Top Level Statements introduced in C# 9, as mentioned earlier.) 

This line writes the output. Console is a static class in the System namespace. It provides an interface to the standard input, output, and error streams for console applications. The program calls the Console method WriteLine, which displays on the console a line with the argument, the string ""Hello, world!"".

GUI
A Windows GUI example:

This example is similar to the previous example, except that it generates a dialog box that contains the message ""Hello, World!"" instead of writing it to the console.

Images
Another useful library is the System.Drawing library, which is used to programmatically draw images. For example:This will create an image that is identical to that stored in ""Image.png"".

Standardization and licensing
In August 2001, Microsoft, Hewlett-Packard and Intel co-sponsored the submission of specifications for C# as well as the Common Language Infrastructure (CLI) to the standards organization Ecma International. In December 2001, ECMA released ECMA-334 C# Language Specification. C# became an ISO/IEC standard in 2003 (ISO/IEC 23270:2003 - Information technology — Programming languages — C#). ECMA had previously adopted equivalent specifications as the 2nd edition of C#, in December 2002. In June 2005, ECMA approved edition 3 of the C# specification, and updated ECMA-334. Additions included partial classes, anonymous methods, nullable types, and generics (somewhat similar to C++ templates). In July 2005, ECMA submitted to ISO/IEC JTC 1/SC 22, via the latter's Fast-Track process, the standards and related TRs. This process usually takes 6–9 months.
The C# language definition and the CLI are standardized under ISO/IEC and Ecma standards that provide reasonable and non-discriminatory licensing protection from patent claims.
Microsoft initially agreed not to sue open-source developers for violating patents in non-profit projects for the part of the framework that is covered by the Open Specification Promise. Microsoft has also agreed not to enforce patents relating to Novell products against Novell's paying customers with the exception of a list of products that do not explicitly mention C#, .NET or Novell's implementation of .NET (The Mono Project). However, Novell maintained that Mono does not infringe any Microsoft patents. Microsoft also made a specific agreement not to enforce patent rights related to the Moonlight browser plugin, which depends on Mono, provided it is obtained through Novell.A decade later, Microsoft began developing free, open-source, and cross-platform tooling for C#, namely Visual Studio Code, .NET Core, and Roslyn. Mono joined Microsoft as a project of Xamarin, a Microsoft subsidiary.

Implementations
Microsoft is leading the development of the open-source reference C# compilers and set of tools. The first compiler, Roslyn, compiles into intermediate language (IL), and the second one, RyuJIT, is a JIT (just-in-time) compiler, which is dynamic and does on-the-fly optimization and compiles the IL into native code for the front-end of the CPU. RyuJIT is open source and written in C++. Roslyn is entirely written in managed code (C#), has been opened up and functionality surfaced as APIs.  It is thus enabling developers to create refactoring and diagnostics tools. Two branches of official implementation are .NET Framework (closed-source, Windows-only) and .NET Core (open-source, cross-platform); they eventually converged into one open-source implementation: .NET 5.0. At .NET Framework 4.6, a new JIT compiler replaced the former.Other C# compilers (some of which include an implementation of the Common Language Infrastructure and .NET class libraries):

Mono, a Microsoft-sponsored project provides an open-source C# compiler, a complete open-source implementation of the CLI (including the required framework libraries as they appear in the ECMA specification,) and a nearly complete implementation of the NET class libraries up to .NET Framework 3.5.
The Elements tool chain from RemObjects includes RemObjects C#, which compiles C# code to .NET's Common Intermediate Language, Java bytecode, Cocoa, Android bytecode, WebAssembly, and native machine code for Windows, macOS, and Linux.
The DotGNU project (now discontinued) also provided an open-source C# compiler, a nearly complete implementation of the Common Language Infrastructure including the required framework libraries as they appear in the ECMA specification, and subset of some of the remaining Microsoft proprietary .NET class libraries up to .NET 2.0 (those not documented or included in the ECMA specification, but included in Microsoft's standard .NET Framework distribution).The Unity game engine uses C# as its primary scripting language. The Godot game engine has implemented an optional C# module thanks to a donation of $24,000 from Microsoft.

See also
Notes
References
Further reading
Albahari, Joseph (2022). C# 10 in a Nutshell (First ed.). O'Reilly. ISBN 978-1-098-12195-2.
Archer, Tom (2001). ""Part 2, Chapter 4: The Type System"". Inside C#. Redmond, Washington: Microsoft Press. ISBN 0-7356-1288-9.
Drayton, Peter; Albahari, Ben; Neward, Ted (2002). C# Language Pocket Reference. O'Reilly. ISBN 0-596-00429-X.
Novák, István; Velvart, Andras; Granicz, Adam; Balássy, György; Hajdrik, Attila; Sellers, Mitchel; Hillar, Gastón C.; Molnár, Ágnes; Kanjilal, Joydip (2010). Visual Studio 2010 and .NET 4 Six-in-One. Wrox Press. ISBN 978-0470499481.
Petzold, Charles (2002). Programming Microsoft Windows with C#. Microsoft Press. ISBN 0-7356-1370-2.
Skeet, Jon (2019). C# in Depth (Fourth ed.). Manning. ISBN 978-1617294532.

External links
C# Language Specification
C# Programming Guide
ISO C# Language Specification
C# Compiler Platform (""Roslyn"") source code",2356196,https://en.wikipedia.org/wiki/C_Sharp_(programming_language)
Caml,"Caml (originally an acronym for Categorical Abstract Machine Language) is a multi-paradigm, general-purpose programming language which is a dialect of the ML programming language family.  Caml was developed in France at INRIA and ENS.
Caml is statically typed, strictly evaluated, and uses automatic memory management. OCaml, the main descendant of Caml, adds many features to the language, including an object layer.","Caml (originally an acronym for Categorical Abstract Machine Language) is a multi-paradigm, general-purpose programming language which is a dialect of the ML programming language family.  Caml was developed in France at INRIA and ENS.
Caml is statically typed, strictly evaluated, and uses automatic memory management. OCaml, the main descendant of Caml, adds many features to the language, including an object layer.

Examples
In the following, # represents the Caml prompt.

Hello World
Factorial function (recursion and purely functional programming)
Many mathematical functions, such as factorial, are most naturally represented in a purely functional form. The following recursive, purely functional Caml function implements factorial:

The function can be written equivalently using pattern matching:

This latter form is the mathematical definition of factorial as a recurrence relation.
Note that the compiler inferred the type of this function to be int -> int, meaning that this function maps ints onto ints. For example, 12! is:

Numerical derivative (higher-order functions)
Since Caml is a functional programming language, it is easy to create and pass around functions in Caml programs. This capability has an enormous number of applications. Calculating the numerical derivative of a function is one such application. The following Caml function d computes the numerical derivative of a given function f at a given point x:

This function requires a small value delta. A good choice for delta is the cube root of the machine epsilon.
The type of the function d indicates that it maps a float onto another function with the type (float -> float) -> float -> float. This allows us to partially apply arguments. This functional style is known as currying. In this case, it is useful to partially apply the first argument delta to d, to obtain a more specialised function:

Note that the inferred type indicates that the replacement d is expecting a function with the type float -> float as its first argument. We can compute a numerical approximation to the derivative of x3−x−1{\displaystyle x^{3}-x-1} at x=3{\displaystyle x=3} with:

The correct answer is f′(x)=3x2−1→f′(3)=27−1=26{\displaystyle f'(x)=3x^{2}-1\rightarrow f'(3)=27-1=26}.
The function d is called a ""higher-order function"" because it accepts another function (f) as an argument.
We can go further and create the (approximate) derivative of f, by applying d while omitting the x argument:

The concepts of curried and higher-order functions are clearly useful in mathematical programs. In fact, these concepts are equally applicable to most other forms of programming and can be used to factor code much more aggressively, resulting in shorter programs and fewer bugs.

Discrete wavelet transform (pattern matching)
The 1D Haar wavelet transform of an integer-power-of-two-length list of numbers can be implemented very succinctly in Caml and is an excellent example of the use of pattern matching over lists, taking pairs of elements (h1 and h2) off the front and storing their sums and differences on the lists s and d, respectively:

For example:

Pattern matching allows complicated transformations to be represented clearly and succinctly. Moreover, the Caml compiler turns pattern matches into very efficient code, at times resulting in programs that are shorter and faster than equivalent code written with a case statement (Cardelli 1984, p. 210.).

History
The first Caml implementation was written in Lisp by Ascánder Suárez in 1987 at the French Institute for Research in Computer Science and Automation (INRIA).Its successor, Caml Light, was implemented in C by Xavier Leroy and Damien Doligez, and the original was nicknamed ""Heavy Caml"" because of its higher memory and CPU requirements.Caml Special Light was a further complete rewrite that added a powerful module system to the core language. It was augmented with an object layer to become Objective Caml, eventually renamed OCaml.

See also
Categorical abstract machine
OCaml

References
Bibliography
The Functional Approach to Programming with Caml Archived 2007-12-24 at the Wayback Machine by Guy Cousineau and Michel Mauny.
Cardelli, Luca (1984). Compiling a functional language ACM Symposium on LISP and functional programming, Association of Computer Machinery.

External links
Official website, Caml language family",2362118,https://en.wikipedia.org/wiki/Caml
Carbon (programming language),"Carbon is an experimental programming language designed for connectiveness with C++. The project is open-source and was started at Google. Google engineer Chandler Carruth first introduced Carbon at the CppNorth conference in Toronto in July 2022. He stated that Carbon was created to be a C++ successor. The language is expected to have an experimental MVP version 0.1 in 2025 and a production-ready version 1.0 after 2027.The language intends to fix several perceived shortcomings of C++ but otherwise provides a similar feature set.
The main goals of the language are readability and ""bi-directional interoperability"" (which allows the user to include C++ code in the Carbon file), as opposed to using a new language like Rust, that, while being influenced by C++, is not two-way compatible with C++ programs. Changes to the language will be decided by the Carbon leads.Carbon's documents, design, implementation, and related tools are hosted on GitHub under the Apache-2.0 license with LLVM Exceptions.","Carbon is an experimental programming language designed for connectiveness with C++. The project is open-source and was started at Google. Google engineer Chandler Carruth first introduced Carbon at the CppNorth conference in Toronto in July 2022. He stated that Carbon was created to be a C++ successor. The language is expected to have an experimental MVP version 0.1 in 2025 and a production-ready version 1.0 after 2027.The language intends to fix several perceived shortcomings of C++ but otherwise provides a similar feature set.
The main goals of the language are readability and ""bi-directional interoperability"" (which allows the user to include C++ code in the Carbon file), as opposed to using a new language like Rust, that, while being influenced by C++, is not two-way compatible with C++ programs. Changes to the language will be decided by the Carbon leads.Carbon's documents, design, implementation, and related tools are hosted on GitHub under the Apache-2.0 license with LLVM Exceptions.

Example
The following shows how a program might be written in Carbon and C++:

See also
Comparison of programming languages
Timeline of programming languages
C++
D
Go
Rust
Ring
Mojo
V

References
External links
Carbon-language on GitHub
Carbon at the Compiler Explorer (godbolt)",71357638,https://en.wikipedia.org/wiki/Carbon_(programming_language)
Cedar (programming language),"Mesa is a programming language developed in the mid 1970s at the Xerox Palo Alto Research Center in Palo Alto, California, United States. The language name was a pun based upon the programming language catchphrases of the time, because Mesa is a ""high level"" programming language.
Mesa is an ALGOL-like language with strong support for modular programming. Every library module has at least two source files: a definitions file specifying the library's interface plus one or more program files specifying the implementation of the procedures in the interface. To use a library, a program or higher-level library must ""import"" the definitions. The Mesa compiler type-checks all uses of imported entities; this combination of separate compilation with type-checking was unusual at the time.Mesa introduced several other innovations in language design and implementation, notably in the handling of software exceptions, thread synchronization, and incremental compilation.
Mesa was developed on the Xerox Alto, one of the first personal computers with a graphical user interface, however, most of the Alto's system software was written in BCPL. Mesa was the system programming language of the later Xerox Star workstations, and for the GlobalView desktop environment.  Xerox PARC later developed Cedar, which was a superset of Mesa.
Mesa and Cedar had a major influence on the design of other important languages, such as Modula-2 and Java, and was an important vehicle for the development and dissemination of the fundamentals of GUIs, networked environments, and the other advances Xerox contributed to the field of computer science.","Mesa is a programming language developed in the mid 1970s at the Xerox Palo Alto Research Center in Palo Alto, California, United States. The language name was a pun based upon the programming language catchphrases of the time, because Mesa is a ""high level"" programming language.
Mesa is an ALGOL-like language with strong support for modular programming. Every library module has at least two source files: a definitions file specifying the library's interface plus one or more program files specifying the implementation of the procedures in the interface. To use a library, a program or higher-level library must ""import"" the definitions. The Mesa compiler type-checks all uses of imported entities; this combination of separate compilation with type-checking was unusual at the time.Mesa introduced several other innovations in language design and implementation, notably in the handling of software exceptions, thread synchronization, and incremental compilation.
Mesa was developed on the Xerox Alto, one of the first personal computers with a graphical user interface, however, most of the Alto's system software was written in BCPL. Mesa was the system programming language of the later Xerox Star workstations, and for the GlobalView desktop environment.  Xerox PARC later developed Cedar, which was a superset of Mesa.
Mesa and Cedar had a major influence on the design of other important languages, such as Modula-2 and Java, and was an important vehicle for the development and dissemination of the fundamentals of GUIs, networked environments, and the other advances Xerox contributed to the field of computer science.

History
Mesa was originally designed in the Computer Systems Laboratory (CSL), a branch of the Xerox Palo Alto Research Center, for the Alto, an experimental micro-coded workstation.  Initially, its spread was confined to PARC and a few universities to which Xerox had donated some Altos.
Mesa was later adopted as the systems programming language for Xerox's commercial workstations such as the Xerox 8010 (Xerox Star, Dandelion) and Xerox 6085 (Daybreak), in particular for the Pilot operating system.
A secondary development environment, called the Xerox Development Environment (XDE) allowed developers to debug both the operating system Pilot as well as ViewPoint GUI applications using a world swap mechanism. This allowed the entire ""state"" of the world to be swapped out, and allowed low-level system crashes which paralyzed the whole system to be debugged. This technique did not scale very well to large application images (several megabytes), and so the Pilot/Mesa world in later releases moved away from the world swap view when the micro-coded machines were phased out in favor of SPARC workstations and Intel PCs running a Mesa PrincOps emulator for the basic hardware instruction set.
Mesa was compiled into a stack-machine language, purportedly with the highest code density ever achieved (roughly 4 bytes per high-level language statement).  This was touted in a 1981 paper where implementors from the Xerox Systems Development Department (then, the development arm of PARC), tuned up the instruction set and published a paper on the resultant code density.Mesa was taught via the Mesa Programming Course that took people through the wide range of technology Xerox had available at the time and ended with the programmer writing a ""hack"", a workable program designed to be useful. An actual example of such a hack is the BWSMagnifier, which was written in 1988 and allowed people to magnify sections of the workstation screen as defined by a resizable window and a changeable magnification factor.  Trained Mesa programmers from Xerox were well versed in the fundamental of GUIs, networking, exceptions, and multi-threaded programming, almost a decade before they became standard tools of the trade.
Within Xerox, Mesa was eventually superseded by the Cedar programming language. Many Mesa programmers and developers left Xerox in 1985; some of them went to DEC Systems Research Center where they used their experience with Mesa in the design of Modula-2+, and later of Modula-3.

Main features
Semantics
Mesa was a strongly typed programming language with type-checking across module boundaries, but with enough flexibility in its type system that heap allocators could be written in Mesa.Due to its strict separation between interface and implementation, Mesa allows true incremental compilation and encourages architecture- and platform-independent programming.  They also simplified source-level debugging, including remote debugging via the Ethernet.
Mesa had rich exception handling facilities, with four types of exceptions.  It had support for thread synchronization via monitors. Mesa was the first language to implement monitor BROADCAST, a concept introduced by the Pilot operating system.

Syntax
Mesa has an ""imperative"" and ""algebraic"" syntax, based on ALGOL and Pascal rather than on BCPL or C; for instance, compound commands are indicated by the BEGIN and END keywords rather than braces. In Mesa, all keywords are written in uppercase.Due to PARC's using the 1963 variant of ASCII rather than the more common 1967 variant, the Alto's character set included a left-pointing arrow (←) rather than an underscore. The result of this is that Alto programmers (including those using Mesa, Smalltalk etc.) conventionally used camelCase for compound identifiers, a practice which was incorporated in PARC's standard programming style. On the other hand, the availability of the left-pointing arrow allowed them to use it for the assignment operator, as it originally had been in ALGOL.
When the Mesa designers wanted to implement an exception facility, they hired a recent M.Sc. graduate from Colorado who had written his thesis on exception handling facilities in algorithmic languages.  This led to the richest exception facility for its time, with primitives SIGNAL, ERROR, ABORT, RETRY, CATCH, and CONTINUE.  As the language did not have type-safe checks to verify full coverage for signal handling, uncaught exceptions were a common cause of bugs in released software.

Cedar
Mesa was the precursor to the programming language Cedar. Cedar's main additions were garbage collection, dynamic types, better string support through ropes, a limited form of type parameterization, and special syntax for identifying the type-safe parts of multi-module software packages, to ensure deterministic execution and prevent memory leaks.

Descendants
The United States Department of Defense approached Xerox to use Mesa for its ""IronMan"" programming language (see Steelman language requirements), but Xerox declined due to conflicting goals.  Xerox PARC employees argued that Mesa was a proprietary advantage that made Xerox software engineers more productive than engineers at other companies.  The Department of Defense instead eventually chose and developed the Ada programming language from the candidates.
The original Star Desktop evolved into the ViewPoint Desktop and later became GlobalView which was ported to various Unix platforms, such as SunOS Unix and AIX. A Mesa to C compiler was written and the resulting code compiled for the target platform. This was a workable solution but made it nearly impossible to develop on the Unix machines since the power of the Mesa compiler and associated tool chain was lost using this approach. There was some commercial success on Sun SPARC workstations in the publishing world, but this approach resulted in isolating the product to narrow market opportunities.
In 1976, during a sabbatical at Xerox PARC, Niklaus Wirth became acquainted with Mesa, which had a major influence in the design of his Modula-2 language.
Java explicitly refers to Mesa as a predecessor.

See also
History of the graphical user interface

References
External links
Mesa Programming Language Manual, Version 5 (1979) at bitsavers.org
Other Mesa documents at bitsavers.org
World-Stop Debuggers Archived 26 August 2016 at the Wayback Machine, Don Gillies, Xerox SDD/ISD Employee, 1984–86.
Teitelman, Warren (April 1984). ""A Tour Through Cedar"". IEEE Software. 1 (2): 44–73. CiteSeerX 10.1.1.105.3163. doi:10.1109/ms.1984.234050.",19962,https://en.wikipedia.org/wiki/Mesa_(programming_language)
Céu (programming language),"Céu is ""Structured Synchronous Reactive Programming"" 
According to its web page, Céu supports synchronous concurrency with shared memory and deterministic execution and has a small memory footprint.","Céu is ""Structured Synchronous Reactive Programming"" 
According to its web page, Céu supports synchronous concurrency with shared memory and deterministic execution and has a small memory footprint.

References


== Sources ==",52350190,https://en.wikipedia.org/wiki/C%C3%A9u_(programming_language)
Charm (programming language),"Charm is a computer programming language devised in the early 1990s with similarities to the RTL/2, Pascal and C languages in addition to containing some unique features of its own. The Charm language is defined by a context-free grammar amenable to being processed by recursive descent parser as described in seminal books on compiler design.A set of Charm tools including a compiler, assembler and linker was made available for Acorn's RISC OS platform. Charm reworked for RISC OS platforms has subsequently been reviewed in Archive magazine.Charm is further described in the e-book Programming in Charm on the Raspberry Pi.","Charm is a computer programming language devised in the early 1990s with similarities to the RTL/2, Pascal and C languages in addition to containing some unique features of its own. The Charm language is defined by a context-free grammar amenable to being processed by recursive descent parser as described in seminal books on compiler design.A set of Charm tools including a compiler, assembler and linker was made available for Acorn's RISC OS platform. Charm reworked for RISC OS platforms has subsequently been reviewed in Archive magazine.Charm is further described in the e-book Programming in Charm on the Raspberry Pi.

Grammar
The definition of the Charm grammar in Backus–Naur form along with descriptive examples of Charm constructs is defined on the Charm language page.The language is block structured, with each block being introduced by a language keyword that is descriptive of the operation being performed in the block e.g. for, while, repeat (iteration), case, if (selection). Each block is enclosed by { and } delimiters.  Additionally language lines within a block are normally indented for clarity, though this not required as white space is ignored.
Each grammatically conforming text represents a collection of executable code and associated data which can be used by a Charm tool set as a component when assembling a program that can be run under an operating system utilising the services it provides to do useful work such as data processing or interacting with users through a graphical user interface (GUI).

Data types
Charm is a strongly typed language, but does allow some implicit conversions between numeric and floating point types. The following basic variable types are supported:

int – integers
char – characters
boolean – boolean values (true or false)
real – floating point numbersData aggregates of the same type may be declared and statically initialised using the array keyword, and these may be multidimensional. Aggregates of different types may be declared using the record keyword, and it is allowable for such a declaration to define a union of record fields that overlay each other in terms of storage allocation. Modules may also aggregate a mixture of static and dynamic data members. Instances of both records and modules (dynamic content only) can be instantiated on the stack, or on the heap via the new operator. Modules may also define a constructor ~new procedure to initialise dynamic data and corresponding ~delete deconstructor procedure to release resources in a similar manner to the C++ language.

Referencing
Data or procedures within the scope of a module may be made global to the final application by using the export keyword. If a module wishes to reference a procedure or data from another Charm module, it does so using the import keyword. Modules may contain instance based member variables which are accessible through procedures declared with the dynamic keyword through the implicit first parameter this pointer.
References to data constructs and procedures may be made using the ref keyword. These can be dereferenced using the val keyword. When using reference variables, comparison operators are available to check whether two reference variables refer to the same item of data ( :=: ) or whether the data they point to is the same ( = ).

Example
The original classic Hello world program written in Charm is:

and the equivalent latest version following evolutionary syntactic language changes is:

Tool set
Tool set implementations are expected to provide a compiler and an assembler to generate object files from Charm source code and assembler source code, which can then be linked together along with library and run time support files to generate an executable program.
At the time of writing only one Charm tool set installation is available (free of charge) for download. The tools are themselves written in the Charm language, and the source code is available under the terms of the GNU General Public License. They run on RISC OS PCs and platforms with ARM CPUs (such as the Raspberry Pi) and on emulators for RISC OS which are hosted on Windows or Linux platforms (such as RPCEmu). Code generation for hardware assisted double precision floating point operations is supported for platforms based on ARM chips that support the VFP version 2 coprocessor architecture.

Compiler
The Charm compiler is a recursive descent single pass compiler which parses Charm source code to generate quadruples of the form result := lhs op rhs in an intermediate language that supports arithmetic, logical and flow of control operations. Data is stored in temporaries which are assigned to registers and memory locations in the back end of the compiler. Two back ends are currently in existence, one generating Motorola 68000 assembly language, and the other generating ARM architecture.The quadruple output from the hello world example is:

       param   l1$
       call    write_string[proc (ref array char) void]

and the assembler output is:

In more recent releases of Charm, the I/O procedures have been split into their own modules In and Out. Other standard library procedures are organised into a set of records with procedure references as fields. As part of this reorganisation, the write_string method is now invoked through the run time library module Out via static member reference .vdu as procedure str i.e. in the hello world example above write_string (""Hello world"") becomes Out.vdu.str (""Hello world"").

Assembler
The assembler accepts instruction mnemonics, data declarations and directives and constructs an object file containing information readily understandable by the CPU of the target processor, in particular code instructions coded in binary.

Linker
One and only one of the Charm modules linked to form an executable program must contain a procedure matching one of the signatures:

   export proc ~start ()
   export proc ~start (int argc, ref array ref array char argv)

This is analogous to the main function in the C and Java languages. Here argc contains the number of parameters passed on the command line and argv contains a reference to an array of argc + 1 strings (one string per positional parameter in order and a terminating nil).
In addition, modules may optional contain static startup and shutdown procedures invoked during program startup and shutdown that match the signatures:

   export proc ~startup ()
   export proc ~shutdown ()

The linker adds any necessary header information required by the operating system in order to execute the program, and ensures the run time library assembler support code is run which sets up the run time environment (data and stack pointers) and passes control to the start procedure of the application.
A map file showing the names of all modules linked to form the program along with global data and code references is optionally produced which can be used by debuggers and profilers.

References
External links
Charm for RISC OS
Risc PC Emulator
ARM Information Center",31915190,https://en.wikipedia.org/wiki/Charm_(programming_language)
Chef (programming language),"An esoteric programming language (sometimes shortened to esolang) is a programming language designed to test the boundaries of computer programming language design, as a proof of concept, as software art, as a hacking interface to another language (particularly functional programming or procedural programming languages), or as a joke. The use of the word esoteric distinguishes them from languages that working developers use to write software. The creators of most esolangs do not intend them to be used for mainstream programming, although some esoteric features, such as visuospatial syntax, have inspired practical applications in the arts. Such languages are often popular among hackers and hobbyists.Usability is rarely a goal for designers of esoteric programming languages; often their design leads to quite the opposite. Their usual aim is to remove or replace conventional language features while still maintaining a language that is Turing-complete, or even one for which the computational class is unknown.","An esoteric programming language (sometimes shortened to esolang) is a programming language designed to test the boundaries of computer programming language design, as a proof of concept, as software art, as a hacking interface to another language (particularly functional programming or procedural programming languages), or as a joke. The use of the word esoteric distinguishes them from languages that working developers use to write software. The creators of most esolangs do not intend them to be used for mainstream programming, although some esoteric features, such as visuospatial syntax, have inspired practical applications in the arts. Such languages are often popular among hackers and hobbyists.Usability is rarely a goal for designers of esoteric programming languages; often their design leads to quite the opposite. Their usual aim is to remove or replace conventional language features while still maintaining a language that is Turing-complete, or even one for which the computational class is unknown.

History
The earliest, and still the canonical example of an esoteric programming language, is INTERCAL, designed in 1972 by Don Woods and James M. Lyon, who said that their intention was to create a programming language unlike any with which they were familiar. It parodied elements of established programming languages of the day such as Fortran, COBOL and assembly language.
For many years, INTERCAL was represented only by paper copies of the INTERCAL manual. Its revival in 1990 as an implementation in C under Unix stimulated a wave of interest in the intentional design of esoteric computer languages.

In 1993, Wouter van Oortmerssen created FALSE, a small stack-oriented programming language with syntax designed to make the code inherently obfuscated, confusing and unreadable. Its compiler is only 1024 bytes in size. This inspired Urban Müller to create an even smaller language, the now-infamous Brainfuck, which consists of only eight recognized characters. Along with Chris Pressey's Befunge (like FALSE, but with a two-dimensional instruction pointer), Brainfuck is now one of the best-supported esoteric programming languages, with canonical examples of minimal Turing tarpits and needlessly obfuscated language features. Brainfuck is related to the P′′ family of Turing machines.

Common features
While esoteric programming languages differ in many ways, there are some common traits that characterize many languages, such as parody, minimalism, and the goal of making programming difficult. Many esoteric programming languages, such as brainfuck, and similar, use single characters as commands, however, it is not uncommon for languages to read line by line like conventional programming languages.

Unique data representations
Conventional imperative programming languages typically allow data to be stored in variables, but esoteric languages may utilize different methods of storing and accessing data. Languages like Brainfuck and Malbolge only permit data to be read through a single pointer, which must be moved to a location of interest before data is read. Others, like Befunge and Shakespeare, utilize one or more stacks to hold data, leading to a manner of execution akin to Reverse Polish notation. Finally, there are languages which explore alternative forms of number representation: the Brainfuck variant Boolfuck only permits operations on single bits, while Malbolge and INTERCAL variant TriINTERCAL replace bits altogether with a base 3 ternary system.

Unique instruction representations
Esoteric languages also showcase unique ways of representing program instructions. Some languages, such as Befunge and Piet, represent programs in two or more dimensions, with program control moving around in multiple possible directions through the program. This differs from conventional languages in which a program is a set of instructions usually encountered in sequence. Other languages modify instructions to appear in an unusual form, often one that can be read by humans with an alternate meaning to the underlying instructions. Shakespeare achieves this by making all programs resemble Shakespearian plays. Chef achieves the same by having all programs be recipes. Chef is particularly notable in that some have created programs that successfully function both as a program and as a recipe, demonstrating the ability of the language to produce this double meaning.

Difficulty to read and write
Many esoteric programming languages are designed to produce code that is deeply obfuscated, making it difficult to read and to write. The purpose of this may be to provide an interesting puzzle or challenge for program writers: Malbolge for instance was explicitly designed to be challenging, and so it has features like self-modifying code and highly counterintuitive operations. On the other hand, some esoteric languages become difficult to write due to their other design choices. Brainfuck is committed to the idea of a minimalist instruction set, so even though its instructions are straightforward in principle, the code that arises is difficult for a human to read. INTERCAL's difficulty arises as a result of the choice to avoid operations used in any other programming language, which stems from its origin as a parody of other languages.

Parody and spoof
One of the aims of esoteric programming languages is to parody or spoof existing languages and trends in the field of programming. For instance, the first esoteric language INTERCAL began as a spoof of languages used in the 1960s, such as APL, Fortran, and COBOL. INTERCAL's rules appear to be the inverse of rules in these other languages. However, the subject of parody is not always another established programming language. Shakespeare can be viewed as spoofing the structure of Shakespearean plays, for instance. The language Ook! is a parody of Brainfuck, where Brainfuck's eight commands are replaced by various orangutang sounds like ""Ook. Ook?""

Examples
Befunge
Befunge allows the instruction pointer to roam in multiple dimensions through the code. For example, the following program displays ""Hello World"" by pushing the characters in reverse order onto the stack, then printing the characters in a loop which circulates clockwise through the instructions >, :, v, _, ,, and ^.

There are many versions of Befunge, the most common being Befunge-93, which is named as such because it was released in 1993.

Binary combinatory logic
Binary combinatory logic, otherwise known as binary lambda calculus, is designed from an algorithmic information theory perspective to allow for the densest possible code with the most minimal means, featuring a 29-byte self interpreter, a 21-byte prime number sieve, and a 112-byte Brainfuck interpreter.

Brainfuck
Brainfuck is designed for extreme minimalism and leads to obfuscated code, with programs containing only eight distinct characters. The following program outputs ""Hello, world!"":

All characters other than +-<>,.[] are ignored.

Chicken
Chicken has just three tokens, the word ""chicken"", "" "" (the space character), and the newline character. The compiler interprets the amount of ""chickens"" on a line as an opcode instruction which it uses to manipulate data on a stack. A simple chicken program can contain dozens of lines with nothing but the word ""chicken"" repeated countless times. Chicken was invented by Torbjörn Söderstedt who drew his inspiration for the language from a parody of a scientific dissertation.

Chef
Chef is a stack-oriented programming language created by David Morgan-Mar, designed to make programs look like cooking recipes. Programs consist of a title, a list of variables and their data values, and a list of stack manipulation instructions. A joking design principle states that ""program recipes should not only generate valid output, but be easy to prepare and delicious"", and Morgan-Mar notes that an example ""Hello, World!"" program with ""101 eggs"" and ""111 cups oil"" would produce ""a lot of food for one person.""

FRACTRAN
A FRACTRAN program is an ordered list of positive fractions together with an initial positive integer input n{\displaystyle n}. The program is run by multiplying the integer n{\displaystyle n} by the first fraction f{\displaystyle f} in the list for which nf{\displaystyle nf} is an integer. The integer n{\displaystyle n} is then replaced by nf{\displaystyle nf} and the rule is repeated. If no fraction in the list produces an integer when multiplied by n{\displaystyle n}, the program halts. FRACTRAN was invented by mathematician John Conway.

GolfScript
Programs in GolfScript, a language created for code golf, consist of lists of items, each of which is pushed onto the stack as it is encountered, with the exception of variables which have code blocks as their value, in which case the code is executed.

INTERCAL
INTERCAL, short for ""Compiler Language With No Pronounceable Acronym"", was created in 1972 as a parody to satirize aspects of the various programming languages at the time.

JSFuck
JSFuck is an esoteric programming style of JavaScript, where code is written using only six characters: [, ], (, ), !, and +. 
Unlike Brainfuck, which requires its own compiler or interpreter, JSFuck is valid JavaScript code, meaning JSFuck programs can be run in any web browser or engine that interprets JavaScript. It has been used in a number of cross-site scripting (XSS) attacks on websites such as eBay due to its ability to evade cross-site scripting detection filters.

LOLCODE
LOLCODE is designed to resemble the speech of lolcats. The following is the ""Hello World"" example:

HAI
CAN HAS STDIO?
VISIBLE ""HAI WORLD!""
KTHXBYE

While the semantics of LOLCODE is not unusual, its syntax has been described as a linguistic phenomenon, representing an unusual example of informal speech and internet slang in programming.

Malbolge
Malbolge (named after the 8th circle of Hell) was designed to be the most difficult and esoteric programming language. Among other features, code is self-modifying by design and the effect of an instruction depends on its address in memory.

Piet
Piet is a language designed by David Morgan-Mar, whose programs are bitmaps that look like abstract art. The execution is guided by a ""pointer"" that moves around the image, from one continuous coloured region to the next. Procedures are carried out when the pointer exits a region.
There are 20 colours for which behaviour is specified: 18 ""colourful"" colours, which are ordered by a 6-step hue cycle and a 3-step brightness cycle; and black and white, which are not ordered. When exiting a ""colourful"" colour and entering another one, the performed procedure is determined by the number of steps of change in hue and brightness. Black cannot be entered; when the pointer tries to enter a black region, the rules of choosing the next block are changed instead. If all possible rules are tried, the program terminates. Regions outside the borders of the image are also treated as black. White does not perform operations, but allows the pointer to ""pass through"". The behaviour of colours other than the 20 specified is left to the compiler or interpreter.Variables are stored in memory as signed integers in a single stack. Most specified procedures deal with operations on that stack, while others deal with input/output and with the rules by which the compilation pointer moves.Piet was named after the Dutch painter Piet Mondrian. The original intended name, Mondrian, was already taken by an open-source statistical data-visualization system.

REON-4213
The REON-4213 programming language is an example of a mixed esoteric language, programming language, and musical language blended together and used in the video game series of Ar tonelico. This unique format allows a video game to broach the subject of programming in an entertaining manner that is suitable for younger audiences.
Although this language cannot be used to express application code it uses concepts from real programming languages such as C++ and JavaScript to introduce the ideas and structures of software code.

Rockstar
Rockstar is a computer programming language designed for creating programs that are also hair metal power ballads. It was created by Dylan Beattie.

Shakespeare
Shakespeare is designed to make programs look like Shakespearean plays. For example, the following statement declares a point in the program which can be reached via a GOTO-type statement:
 Act I: Hamlet's insults and flattery.

Storyteller
Storyteller is a computer programming language designed to make programs look like rich, emotional narrative.

Unlambda
Unlambda is a minimalist functional programming language based on SKI calculus, but combined with first-class continuations and imperative I/O (with input usually requiring the use of continuations).

Whitespace
Whitespace uses only whitespace characters (space, tab, and return), ignoring all other characters, which can therefore be used for comments. This is the reverse of many traditional languages, which do not distinguish between different whitespace characters, treating tab and space the same. It also allows Whitespace programs to be hidden in the source code of programs in languages like C.

Cultural context
The cultural context of esolangs has been studied by Geoff Cox, who writes that esolangs ""shift attention from command and control toward cultural expression and refusal"", seeing esolangs as similar to code art and code poetry, such as Mez Breeze's mezangelle, a belief shared by others in field. Daniel Temkin describes Brainfuck as ""refusing to ease the boundary between human expression and assembly code and thereby taking us on a ludicrous journey of logic,"" exposing the inherent conflict between human thinking and computer logic by deconstructing their relationship. He connects programming within an esolang to performing an event score such as those of the Fluxus movement, where playing out the irregular rules of the logic in code makes the point of view of the language clear.

References
Bibliography
Paloque-Bergès, Camille (2009). ""Langages ésotériques"". Poétique des codes sur le réseau informatique. Archives contemporaines. ISBN 978-2-914610-70-4.
Cox, Geoff (2013). Speaking Code: Coding as Aesthetic and Political Expression. MIT Press. ISBN 978-0-262-01836-4.
Kneusel, Ronald (2022). Strange Code: Esoteric Languages That Make Programming Fun Again. No Starch Press. ISBN 978-1718502406.

External links

Esolang, the esoteric programming languages wiki
Obfuscated Programming Languages at Curlie",53398,https://en.wikipedia.org/wiki/Esoteric_programming_language
Clascal,"Clascal is an object-oriented programming language (and associated  discontinued compiler) developed in 1983 by the Personal Office Systems (POS) division (later renamed The Lisa Division, then later The 32-Bit Systems Division) of  Apple Computer. Clascal was used to program applications for the Lisa Office System, the operating environment of the Lisa.
Developed as an extension of Lisa Pascal, which in turn harked back to the UCSD Pascal model originally implemented on the Apple II, the language was strongly influenced by the Xerox Palo Alto Research Center (PARC) release of Smalltalk-80, v1 (which had been formerly ported to the Lisa), and by Modula.  According to Larry Tesler, Clascal was developed as a replacement for Apple's version of Smalltalk, which was ""too slow"" and because the experience offered by the Smalltalk syntax was too unfamiliar for most people.Clascal was the basis for Object Pascal on the Apple Macintosh in 1985. With the demise of the Lisa in 1986, Pascal and Object Pascal continued to be used in the Macintosh Programmer's Workshop for systems and application development for several more years, until it was finally supplanted by the languages C and C++. The MacApp application framework was based on Toolkit originally written in Clascal.Object Pascal, in turn, served as the basis for Borland's Delphi.","Clascal is an object-oriented programming language (and associated  discontinued compiler) developed in 1983 by the Personal Office Systems (POS) division (later renamed The Lisa Division, then later The 32-Bit Systems Division) of  Apple Computer. Clascal was used to program applications for the Lisa Office System, the operating environment of the Lisa.
Developed as an extension of Lisa Pascal, which in turn harked back to the UCSD Pascal model originally implemented on the Apple II, the language was strongly influenced by the Xerox Palo Alto Research Center (PARC) release of Smalltalk-80, v1 (which had been formerly ported to the Lisa), and by Modula.  According to Larry Tesler, Clascal was developed as a replacement for Apple's version of Smalltalk, which was ""too slow"" and because the experience offered by the Smalltalk syntax was too unfamiliar for most people.Clascal was the basis for Object Pascal on the Apple Macintosh in 1985. With the demise of the Lisa in 1986, Pascal and Object Pascal continued to be used in the Macintosh Programmer's Workshop for systems and application development for several more years, until it was finally supplanted by the languages C and C++. The MacApp application framework was based on Toolkit originally written in Clascal.Object Pascal, in turn, served as the basis for Borland's Delphi.

References

Keohan, Susan (July 1984). An Introduction to Clascal (PDF). Lisa Division, Apple Computer.",10580097,https://en.wikipedia.org/wiki/Clascal
Clipper (programming language),"Clipper is an xBase compiler that implements a variant of the xBase computer programming language. It is used to create 
or extend software programs that originally operated primarily under MS-DOS. Although it is a powerful general-purpose programming
language, it was primarily used to create database/business programs.
One major dBase feature  not implemented in Clipper is the dot-prompt (. prompt) interactive command set, which was an important part of the original dBase implementation.
Clipper, from Nantucket Corp and later Computer Associates, started out as a native code compiler for dBase III databases, and later evolved.","Clipper is an xBase compiler that implements a variant of the xBase computer programming language. It is used to create 
or extend software programs that originally operated primarily under MS-DOS. Although it is a powerful general-purpose programming
language, it was primarily used to create database/business programs.
One major dBase feature  not implemented in Clipper is the dot-prompt (. prompt) interactive command set, which was an important part of the original dBase implementation.
Clipper, from Nantucket Corp and later Computer Associates, started out as a native code compiler for dBase III databases, and later evolved.

History
Clipper was created by Nantucket Corporation, a company that was started in 1984 by Barry ReBell (management) and Brian Russell (technical); 
Larry Heimendinger was Nantucket's president. In 1992, the company was sold to Computer Associates for 190 million dollars and the product was renamed to CA-Clipper.Clipper was created as a replacement programming language for Ashton Tate's dBASE III, a very popular database language at the time. The advantage of Clipper over dBASE was that it could be compiled and executed under MS-DOS as a standalone application. In the years between 1985 and 1992, millions of Clipper applications were built, typically for small businesses dealing with databases concerning many aspects of client management and inventory management. For many smaller businesses, having a Clipper application designed to their specific needs was their first experience with software development. Also a lot of applications for banking and insurance companies were developed, here especially in those cases where the application was considered too small to be developed and run on traditional mainframes. In these environments Clipper also served as a front end for existing mainframe applications.As the product matured, it remained a DOS tool for many years, but added elements of the C programming language and Pascal programming language, as well as OOP, and the code-block data-type (hybridizing the concepts of dBase macros, or string-evaluation, and function pointers), to become far more powerful than the original. Nantucket's Aspen project later matured into the Windows native-code CA-Visual Objects compiler.

Market penetration
Nantucket sold well in Western markets.  Also, in November 1991, the New York Times reported the company's success in ""painstakingly convincing Soviet software developers that buying is preferable to pirating"".  According to the article, Clipper had sold 2,000 copies in the Soviet Union (compared to 250,000 worldwide).

Decline
In the early 1990s, under new ownership, Clipper failed to transition from MS-DOS to Microsoft Windows.  As a result, almost no new commercial applications were written in Clipper after 1995.
By then, the ""classically trained programmer"" commonly used strong typing, in contrast to the original dBASE language.
An evolution of Clipper, named VO, added strong typing but made it optional, in order to remain compatible with existing code.
Four of the more important languages that took over from Clipper were Visual Basic, Microsoft Access, Delphi, and Powerbuilder.
They all provided strong typing.

Revival by third-parties
The Clipper language is being actively implemented and extended by multiple organizations/vendors, like XBase++ from Alaska Software and FlagShip, as well as free (GPL-licensed) projects like Harbour and xHarbour.Many of the current implementations are portable (DOS, Windows, Linux (32- and 64-bit), Unix (32- and 64-bit), and macOS), supporting many language extensions, and have greatly extended runtime libraries, as well as various Replaceable Database Drivers (RDD) supporting many popular database formats, like DBF, DBTNTX, DBFCDX (FoxPro, Apollo, Comix, and Advantage Database Server), MachSix (SIx Driver and Apollo), SQL, and more. These newer implementations all strive for full compatibility with the standard dBase/xBase syntax, while also offering OOP approaches and target-based syntax such as SQLExecute().

Usenet
The Clipper Usenet newsgroups are comp.lang.clipper and comp.lang.clipper.visual-objects.

Programming in Clipper
A simple hello world - application:

? ""Hello World!""

A simple data base input mask:

USE Customer SHARED NEW
clear
@  1, 0 SAY ""CustNum"" GET Customer->CustNum PICT ""999999"" VALID Customer->CustNum > 0
@  3, 0 SAY ""Contact"" GET Customer->Contact VALID !empty(Customer->Contact)
@  4, 0 SAY ""Address"" GET Customer->Address
READ

Version history
The various versions of Clipper were
From Nantucket Corporation; the ""seasonal versions"", billed as ""dBase compilers""

Nantucket Clipper Winter'84 - released May 25, 1985
Nantucket Clipper Summer'85 - released 1985
Nantucket Clipper Winter'85 - released January 29, 1986
Nantucket Clipper Autumn'86 - released October 31, 1986
Nantucket Clipper Summer'87 - released December 21, 1987From Nantucket Corporation; Clipper 5

Nantucket Clipper 5.00         - released 1990
Nantucket Clipper 5.01         - released April 15, 1991
Nantucket Clipper 5.01 Rev.129 - released March 31, 1992and from Computer Associates; CA-Clipper 5

CA Clipper 5.01a -
CA Clipper 5.20  - released February 15, 1993
CA-Clipper 5.2a  - released March 15, 1993
CA Clipper 5.2b  - released June 25, 1993
CA-Clipper 5.2c  - released August 6, 1993
CA Clipper 5.2d  - released March 25, 1994
CA-Clipper 5.2e  - released February 7, 1995
CA Clipper 5.30  - released June 26, 1995
CA Clipper 5.3a  - released May 20, 1996
CA Clipper 5.3b  - released May 20, 1997

Clipper tools
In addition to the standard clipper library, a library named ""Clipper Tools"" was developed by CA after purchasing Nantucket.  Three versions of this library were released, alongside Clipper versions.  This library became a de facto standard amongst Clipper clones, such as xHarbour.  It was also cloned by several of Clipper's clones.

References
External links
Free Open Source Graphic, GUI & Form Designer for CA-Clipper
mini Clipper FAQ Archived 2002-12-11 at the Wayback Machine
Print from Clipper to newest Windows printers article
The Oasis is the largest file archive for CA-Clipper and xBase on the web
Harbour Project A 32/64 bit multiplatform Clipper compiler
CA-Clipper Website CA-Clipper Website",246367,https://en.wikipedia.org/wiki/Clipper_(programming_language)
Clojure,"Clojure (, like closure) is a dynamic and functional dialect of the Lisp programming language on the Java platform.Like most other Lisps, Clojure's syntax is built on S-expressions that are first parsed into data structures by a reader before being compiled. Clojure's reader supports literal syntax for maps, sets and vectors along with lists, and these are compiled to the mentioned structures directly. Clojure treats code as data and has a Lisp macro system. Clojure is a Lisp-1 and is not intended to be code-compatible with other dialects of Lisp, since it uses its own set of data structures incompatible with other Lisps.Clojure advocates immutability and immutable data structures and encourages programmers to be explicit about managing identity and its states. This focus on programming with immutable values and explicit progression-of-time constructs is intended to facilitate developing more robust, especially concurrent, programs that are simple and fast. While its type system is entirely dynamic, recent efforts have also sought the implementation of a dependent type system.The language was created by Rich Hickey in the mid-2000s, originally for the Java platform; the language has since been ported to other platforms, such as the Common Language Runtime (.NET). Hickey continues to lead development of the language as its benevolent dictator for life.","Clojure (, like closure) is a dynamic and functional dialect of the Lisp programming language on the Java platform.Like most other Lisps, Clojure's syntax is built on S-expressions that are first parsed into data structures by a reader before being compiled. Clojure's reader supports literal syntax for maps, sets and vectors along with lists, and these are compiled to the mentioned structures directly. Clojure treats code as data and has a Lisp macro system. Clojure is a Lisp-1 and is not intended to be code-compatible with other dialects of Lisp, since it uses its own set of data structures incompatible with other Lisps.Clojure advocates immutability and immutable data structures and encourages programmers to be explicit about managing identity and its states. This focus on programming with immutable values and explicit progression-of-time constructs is intended to facilitate developing more robust, especially concurrent, programs that are simple and fast. While its type system is entirely dynamic, recent efforts have also sought the implementation of a dependent type system.The language was created by Rich Hickey in the mid-2000s, originally for the Java platform; the language has since been ported to other platforms, such as the Common Language Runtime (.NET). Hickey continues to lead development of the language as its benevolent dictator for life.

History
Rich Hickey is the creator of the Clojure language. Before Clojure, he developed dotLisp, a similar project based on the .NET platform, and three earlier attempts to provide interoperability between Lisp and Java: a Java foreign language interface for Common Lisp (jfli), A Foreign Object Interface for Lisp (FOIL), and a Lisp-friendly interface to Java Servlets (Lisplets).Hickey spent about two and a half years working on Clojure before releasing it publicly in October 2007, much of that time working exclusively on Clojure with no outside funding. At the end of this time, Hickey sent an email announcing the language to some friends in the Common Lisp community.
Clojure's name, according to Hickey, is a word play on the programming concept ""closure"" incorporating the letters C, L, and J for C#, Lisp, and Java respectively—three languages which had a major influence on Clojure's design.

Design
Rich Hickey developed Clojure because he wanted a modern Lisp for functional programming, symbiotic with the established Java platform, and designed for concurrency.Clojure's approach to state is characterized by the concept of identities, which are represented as a series of immutable states over time. Since states are immutable values, any number of workers can operate on them in parallel, and concurrency becomes a question of managing changes from one state to another. For this purpose, Clojure provides several mutable reference types, each having well-defined semantics for the transition between states.Clojure runs on the Java platform and as a result, integrates with Java and fully supports calling Java code from Clojure, and Clojure code can be called from Java, too. The community uses tools such as Clojure command-line interface (CLI) or Leiningen for project automation, providing support for Maven integration. These tools handle project package management and dependencies and are configured using Clojure syntax.
As a Lisp dialect, Clojure supports functions as first-class objects, a read–eval–print loop (REPL), and a macro system. Clojure's Lisp macro system is very similar to that of Common Lisp with the exception that Clojure's version of the backquote (termed ""syntax quote"") qualifies symbols with their namespace. This helps prevent unintended name capture, as binding to namespace-qualified names is forbidden. It is possible to force a capturing macro expansion, but it must be done explicitly. Clojure does not allow user-defined reader macros, but the reader supports a more constrained form of syntactic extension. Clojure supports multimethods and for interface-like abstractions has a protocol based polymorphism and data type system using records, providing high-performance and dynamic polymorphism designed to avoid the expression problem.
Clojure has support for lazy sequences and encourages the principle of immutability and persistent data structures. As a functional language, emphasis is placed on recursion and higher-order functions instead of side-effect-based looping. Automatic tail call optimization is not supported as the JVM does not support it natively; it is possible to do so explicitly by using the recur keyword. For parallel and concurrent programming Clojure provides software transactional memory, a reactive agent system, and channel-based concurrent programming.Clojure 1.7 introduced reader conditionals by allowing the embedding of Clojure, ClojureScript and ClojureCLR code in the same namespace. Transducers were added as a method for composing transformations. Transducers enable higher-order functions such as map and fold to generalize over any source of input data. While traditionally these functions operate on sequences, transducers allow them to work on channels and let the user define their own models for transduction.

Extensible Data Notation
Extensible Data Notation, or edn, is a subset of the Clojure language intended as a data transfer format. It can be used to serialize and deserialize Clojure data structures, and Clojure itself uses a superset of edn to represent programs.
edn is used in a similar way to JSON or XML, but has a relatively large list of built-in elements, shown here with examples:

booleans: true, false
strings: ""foo bar""
characters: \c, \tab
symbols: name
keywords: :key
integers: 123
floating point numbers: 3.14
lists: (a b 42)
vectors: [a b 42]
maps: {:a 1, ""foo"" :bar, [1 2 3] four}
sets: #{a b [1 2 3]}
nil: nil (a null-like value)In addition to those elements, it supports extensibility through the use of tags, which consist of the character # followed by a symbol. When encountering a tag, the reader passes the value of the next element to the corresponding handler, which returns a data value. For example, this could be a tagged element: #myapp/Person {:first ""Fred"" :last ""Mertz""}, whose interpretation will depend on the appropriate handler of the reader.
This definition of extension elements in terms of the others avoids relying on either convention or context to convey elements not included in the base set.

Alternative platforms
The primary platform of Clojure is Java, but other target implementations exist. The most notable of these is ClojureScript, which compiles to ECMAScript 3, and ClojureCLR, a full port on the .NET platform, interoperable with its ecosystem.
Other implementations of Clojure on different platforms include:

Babashka, Native Clojure scripting language leveraging GraalVM native image and Small Clojure Interpreter
CljPerl, Clojure on Perl
ClojureDart, Extend Clojure's reach to mobile & desktop apps by porting Clojure to Dart and Flutter
Clojerl, Clojure on BEAM, the Erlang virtual machine
clojure-py, Clojure in pure Python
ClojureRS, Clojure on Rust
Ferret, compiles to self-contained C++11 that can run on microcontrollers
jank, Native Clojure hosted in C++ on an LLVM-based JIT
Joker, an interpreter and linter written in Go
Las3r, a subset of Clojure that runs on the ActionScript Virtual Machine (the Adobe Flash Player platform)
Pixie, Clojure-inspired Lisp dialect written in RPython
Rouge, Clojure on YARV in Ruby

Tools
Tooling for Clojure development has seen significant improvement over the years. The following is a list of some popular IDEs and text editors with plug-ins that add support for programming in Clojure:
Emacs, with CIDER
IntelliJ IDEA, with Cursive (a free license is available for non-commercial use)
Sublime Text, with Clojure Sublimed, or Tutkain,
Vim, with fireplace.vim, vim-iced, or Conjure (Neovim only)
Visual Studio Code, with Calva or CloverIn addition to the tools provided by the community, the official Clojure command-line interface (CLI) tools have also become available on Linux, macOS, and Windows since Clojure 1.9.

Development
The development process is restricted to the Clojure core team, though issues are publicly visible at the Clojure JIRA project page. Anyone can ask questions or submit issues and ideas at ask.clojure.org. If it's determined that a new issue warrants a JIRA ticket, a core team member will triage it and add it. JIRA issues are processed by a team of screeners and finally approved by Rich Hickey.

Impact
With continued interest in functional programming, Clojure's adoption by software developers using the Java platform has continued to increase. The language has also been recommended by software developers such as Brian Goetz, Eric Evans, James Gosling, Paul Graham, and Robert C. Martin. ThoughtWorks, while assessing functional programming languages for their Technology Radar, described Clojure as ""a simple, elegant implementation of Lisp on the JVM"" in 2010 and promoted its status to ""ADOPT"" in 2012.In the ""JVM Ecosystem Report 2018"" (which was claimed to be ""the largest survey ever of Java developers""), that was prepared in collaboration by Snyk and Java Magazine, ranked Clojure as the 2nd most used programming language on the JVM for ""main applications"". Clojure is used in industry by firms such as Apple, Atlassian, Funding Circle, Netflix, Nubank, Puppet, and Walmart as well as government agencies such as NASA. It has also been used for creative computing, including visual art, music, games, and poetry.

Release history
See also
List of JVM languages
List of CLI languages
Comparison of programming languages

References
Further reading
External links
Official website",16561990,https://en.wikipedia.org/wiki/Clojure
COMAL,"COMAL (Common Algorithmic Language) is a computer programming language developed in Denmark by Børge R. Christensen and Benedict Løfstedt and originally released in 1975. It was based on the BASIC programming language, adding multi-line statements and well-defined subroutines among other additions.
COMAL was originally written for minicomputers, but was small enough to run on early microcomputers as well. It is one of the few structured programming languages that were available for and comfortably usable on 8-bit home computers. 
""COMAL Kernel Syntax & Semantics"" contains the formal definition of the language. Further extensions are common to many implementations.","COMAL (Common Algorithmic Language) is a computer programming language developed in Denmark by Børge R. Christensen and Benedict Løfstedt and originally released in 1975. It was based on the BASIC programming language, adding multi-line statements and well-defined subroutines among other additions.
COMAL was originally written for minicomputers, but was small enough to run on early microcomputers as well. It is one of the few structured programming languages that were available for and comfortably usable on 8-bit home computers. 
""COMAL Kernel Syntax & Semantics"" contains the formal definition of the language. Further extensions are common to many implementations.

History
Minicomputer versions
COMAL was originally developed in Denmark by mathematics teacher Børge R. Christensen. The school in which he taught had received a Data General Nova 1200 minicomputer in 1972, with the expectation that the school would begin to teach computer science. Christensen, who had taken a short course on the subject at university, was expected to lead the program and to maintain the computer system.The NOVA was supplied with Data General Extended BASIC, and Christensen quickly became frustrated with the way in which the unstructured language led students to write low-quality code that was difficult to read and thus mark. While complaining about these problems to computer scientist Benedict Løfstedt, Løfstedt encouraged Christensen to read Systematic Programming, the then-new book on programming language design by Niklaus Wirth, the creator of Pascal. Christensen was impressed, but found that he could not use Pascal directly, as it lacked the interactive shell that made BASIC so easy for students to develop with.Over the next six months Christensen and Løfstedt corresponded by mail to design an alternative to BASIC which retained its interactive elements but added structured elements from Pascal. By 1974, the language's definition was complete but Christensen was unsuccessful in attracting interest from software firms in developing an implementation. Over the next six months he worked with two of his students, to whom he had taught NOVA 1200 machine language, to write an implementation themselves. One of the first things added was the ability to use eight-character variable names, up from the typical one or two. Later additions in the first version included multi-line IF...THEN...ELSE...ENDIF statements, and the PROC...ENDPROC definitions and the EXECUTE statement to call them.The first proof-of-concept implementation (running a five-line loop) was ready on 5 August 1974, and the first release (on paper tape) was ready in February 1975. Development costs had been around US$300. Only now did the system (which had previously used an internal Danish name) pick up the name COMAL, for Common Algorithmic Language, inspired by ALGOL, with which Christensen had been experimenting. The first release was therefore named COMAL 75. Christensen subsequently wrote a textbook on the language which evolved into Beginning COMAL.

Microcomputer versions
In 1978, Christensen began to adapt COMAL such that it would run on microcomputers, which were becoming available. He was worried that without such an implementation he would be required to teach and use BASIC again as Danish schools acquired the new machines. By 1980, a version of COMAL developed in conjunction with a college group was able to run on the Zilog Z80, and thus COMAL 80 was released.Around the same time, a Danish firm introduced the Comet, a very capable microcomputer for the time, which would be the first machine to run a version of what would look like the later COMAL releases. Christensen subsequently stepped back from COMAL development around 1980-81, which was handed over to groups including UniComal, started by Mogens Kjaer, who had written to Christensen with critiques of COMAL and subsequently ported it to the Commodore PET for release 0.14. At this time, Danish schools insisted that COMAL be available on any microcomputer they purchased.In the early 1980s, Apple Computer won a contract to supply Apple II computers running CP/M and COMAL to Irish secondary schools. It was popular for education and some textbooks were locally written.In 1984, Acornsoft released a COMAL implementation, by David Christensen, Jim Warwick and David Evers, for their 8-bit BBC Micro and Acorn Electron computers (with a manual by Paul Christensen and Roy Thornton)
Between 1984-1987, TeleNova, a subsidiary of the industrial arm of the Swedish Telecoms system, manufactured a desktop PC called ""Compis"" for the educational sector. An enhanced version of COMAL was supplied as the standard programming language for this PC. Versions were created for both CP/M-86 and MS-DOS. The latter version is available for Windows XP. The (Swedish) reference manual is ISBN 91-24-40022-X.
In 1990, Thomas Lundy and Rory O'Sullivan produced the definitive text on COMAL Programming. They matched and compared COMAL with BBC Structured Basic.
As of 2016, COMAL is still actively in use as an educational programming language. Some high schools in the United Kingdom continue to use it to teach the subject of computing.

Description
COMAL was created as a mixture of the prevalent educational programming languages of the time, BASIC, Pascal, and, at least in the Commodore and Compis versions, the turtle graphics of Logo. The language was meant to introduce structured programming elements in an environment where BASIC would normally be used.
In early versions, the primary additions to the language were block versions of IF...THEN, and the PROC construct. In most previous versions of BASIC, the only block construct was the FOR...NEXT loop. For instance:

10 FOR I=1 TO 10
20 PRINT I
30 J=J+1
40 NEXT I

This example performs a loop ten times, and performs two instructions every time through the loop. In contrast, almost every other instruction in BASIC, or statement, has to be accomplished on a single line. This can make multi-line statements difficult to perform on an all-or-nothing basis. For instance, if a program desires to run three instructions if a particular value is greater than 10, the typical solution is:

10 IF A<=10 THEN 50
20 PRINT ""A IS GREATER THAN 10""
30 A=A+10
40 PRINT ""A IS NOW "";A
50 PRINT ""RETURNING TO OUR REGULARLY SCHEDULED PROGRAMMING""

This sort of construct hides the true intension of the program, the decision is based on the opposite logic of what the programmer actually wants to accomplish. Additionally, to understand what will happen in this case, the reader has to find line 50, which in real programs might be much further into the source code. This is one of the major reasons that BASIC programs are referred to as ""spaghetti code"", as to follow the logic one moves around the program as if following a series of random spaghetti noodles.
COMAL addresses this issue through the use of blocks. To accomplish this same series of instructions, in COMAL one would write:

10 IF A>10 THEN
20   PRINT ""A IS GREATER THAN 10""
30   A=A+10
40   PRINT ""A IS NOW "";A
50 ENDIF
60 PRINT ""RETURNING TO OUR REGULARLY SCHEDULED PROGRAMMING""

In this case, the author writes the decision they are actually trying to accomplish, and the reader can follow the logic simply by looking for the ENDIF. This is aided by COMAL's use of leading spaces to visually indicate blocks.

Examples
""Hello, world!""
Conditions
Loops
Print statements with variables

Availability
COMAL was available for:

BBC Micro
Commodore PET (public domain software)
Commodore 64 (public domain software)
Commodore 128
Amiga
Compis/Scandis
CP/M
IBM PC
Tiki 100
ZX Spectrum
Grundy NewBrain
Windows XP

See also
Action! (programming language)

References
Further reading
Thomas Lundy & Rory O'Sullivan: Beginning Structured Programming in BASIC and COMAL, 1990
Roy Atherton: Structured programming with COMAL. Horwood, Chichester 1982, ISBN 0-85312-416-7.
Bramer, M. A. (1982). ""COMAL 80—Adding structure to BASIC"". Computers & Education. 6 (2): 179–192. doi:10.1016/0360-1315(82)90031-8. ISSN 0360-1315.
Børge R. Christensen: Beginning Comal. Horwood, Chichester 1982, ISBN 0-85312-435-3.
Børge R. Christensen: COMAL Reference Guide. Toronto PET Users Group, Toronto Ontario, ISBN 0-920607-00-4.
Leuschner, Burkhard (1987). ""Comal's the thing"". System. 15 (3): 373–376. doi:10.1016/0346-251X(87)90011-X. ISSN 0346-251X.
Len Lindsay: COMAL handbook. Reston Publishing, Reston, VA, 1983, ISBN 0-8359-0878-X.
Gordon Shigley: COMAL Workbook. Comal Users Group, USA, 1985, ISBN 0-928411-05-2.

External links
OpenCOMAL for Unix, MS-DOS and Win32
A fork of the above for standards-compliant Unix, mainly Linux and Mac OS X
UniComal 3.11 packaged to run under DOSBox
Description of COMAL, versions, and characteristics (1984)",197700,https://en.wikipedia.org/wiki/COMAL
Concordion,"Concordion is a specification by example framework originally developed by David Peterson, and now maintained by a team of contributors, led by Nigel Charman.
Inspired by the Fit Framework, David states the following aims were behind Concordion:
Improved readability of documents
More ""opinionated"" (scripting is actively discouraged)
Easier to use","Concordion is a specification by example framework originally developed by David Peterson, and now maintained by a team of contributors, led by Nigel Charman.
Inspired by the Fit Framework, David states the following aims were behind Concordion:
Improved readability of documents
More ""opinionated"" (scripting is actively discouraged)
Easier to use

How it works
Concordion specifications are written in Markdown, HTML or Excel and then instrumented with special links, attributes or comments respectively. When the corresponding test fixture class is run, Concordion interprets the instrumentation to execute the test. Rather than forcing product owners to specify requirements in a specially structured language, Concordion lets you write them in normal language using paragraphs, tables and proper punctuation. This makes the specifications much more natural to read and write, and helps everyone to understand and agree about what a feature is supposed to do.The Markdown, HTML or Excel files are typically stored with the source code, which has the benefit that they can be under the same version control system as the rest of the code ensuring the specification and tests are branched and merged along with the main source code.
Concordion includes a flexible extension mechanism for adding functionality, for example implementing new commands, listening to events, or modifying the output documentation. By providing functionality such as embedding screenshots, storyboards or logging output, extensions provide confidence in what the test is doing without locking the test into a specific implementation.Concordion enriches agile processes and has been successfully applied in industrial context.

Example
Markdown format specification
HTML format specification
The fixture code
HelloWorldTest.java
The fixture that works with the instrumentation

Integrated Development Environment Support
The Concordion Support plugin for the IntelliJ IDEA Integrated development environment (IDE) simplifies development of fixtures and specifications with features including autocompletion, navigation between spec and test fixture, renaming, running tests, inspections and quick fixes.The Eclipse (software) Concordion plugin is much more limited and hasn't been updated since 2011. The original author has stopped using Concordion and Eclipse and is unable to accommodate the necessary time to extend and maintain the plugin.

Ports
Concordion has been ported to other languages including:

C# (Concordion.NET)
Python (PyConcordion)
Ruby (Ruby-Concordion)

References
External links
Official website 
David Peterson: Concordion 1.3.1 at the Wayback Machine (archived 2017-08-31)
concordion on GitHub
concordion.net on GitHub",32040842,https://en.wikipedia.org/wiki/Concordion
Concurrent Haskell,"Concurrent Haskell extends Haskell 98 with explicit concurrency. Its two main underlying concepts are:

A primitive type MVar α implementing a bounded/single-place asynchronous channel, which is either empty or holds a value of type α.
The ability to spawn a concurrent thread via the forkIO primitive.Built atop this is a collection of useful concurrency and synchronisation abstractions such as unbounded channels, semaphores and sample variables.
Haskell threads have very low overhead: creation, context-switching and scheduling are all internal to the Haskell runtime. These Haskell-level threads are mapped onto a configurable number of OS-level threads, usually one per processor core.","Concurrent Haskell extends Haskell 98 with explicit concurrency. Its two main underlying concepts are:

A primitive type MVar α implementing a bounded/single-place asynchronous channel, which is either empty or holds a value of type α.
The ability to spawn a concurrent thread via the forkIO primitive.Built atop this is a collection of useful concurrency and synchronisation abstractions such as unbounded channels, semaphores and sample variables.
Haskell threads have very low overhead: creation, context-switching and scheduling are all internal to the Haskell runtime. These Haskell-level threads are mapped onto a configurable number of OS-level threads, usually one per processor core.

Software Transactional Memory
The software transactional memory (STM) extension to GHC reuses the process forking primitives of Concurrent Haskell. STM however:

avoids MVars in favour of TVars.
introduces the retry and orElse primitives, allowing alternative atomic actions to be composed together.

STM monad
The STM monad is an implementation of software transactional memory in Haskell. It is implemented in GHC, and allows for mutable variables to be modified in transactions.

Traditional approach
Consider a banking application as an example, and a transaction in it—the transfer function, which takes money from one account, and puts it into another account. In the IO monad, this might look like:

This causes problems in concurrent situations where multiple transfers might be taking place on the same account at the same time. If there were two transfers transferring money from account from, and both calls to transfer ran line (A) before either of them had written their new values, it is possible that money would be put into the other two accounts, with only one of the amounts being transferred being removed from account from, thus creating a race condition. This would leave the banking application in an inconsistent state.  
A traditional solution to such a problem is locking. For instance, locks can be placed around modifications to an account to ensure that credits and debits occur atomically. In Haskell, locking is accomplished with MVars:

Using such procedures will ensure that money will never be lost or gained due to improper interleaving of reads and writes to any individual account. However, if one tries to compose them together to create a procedure like transfer:

a race condition still exists: the first account may be debited, then execution of the thread may be suspended, leaving the accounts as a whole in an inconsistent state. Thus, additional locks must be added to ensure correctness of composite operations, and in the worst case, one might need to simply lock all accounts regardless of how many are used in a given operation.

Atomic transactions
To avoid this, one can use the STM monad, which allows one to write atomic transactions. This means that all operations inside the transaction fully complete, without any other threads modifying the variables that our transaction is using, or it fails, and the state is rolled back to where it was before the transaction was begun. In short, atomic transactions either complete fully, or it is as if they were never run at all.
The lock-based code above translates in a relatively straightforward way:

The return types of STM () may be taken to indicate that we are composing scripts for transactions. When the time comes to actually execute such a transaction, a function atomically :: STM a -> IO a is used. The above implementation will make sure that no other transactions interfere with the variables it is using (from and to) while it is executing, allowing the developer to be sure that race conditions like that above are not encountered. More improvements can be made to make sure that some other ""business logic"" is maintained in the system, i.e. that the transaction should not try to take money from an account until there is enough money in it:

Here the retry function has been used, which will roll back a transaction, and try it again. Retrying in STM is smart in that it won't try to run the transaction again until one of the variables it references during the transaction has been modified by some other transactional code. This makes the STM monad quite efficient.
An example program using the transfer function might look like this:

which should print out ""Bob's balance: 8000, Jill's balance: 6000"". Here the atomically function has been used to run STM actions in the IO monad.


== References ==",4249256,https://en.wikipedia.org/wiki/Concurrent_Haskell
COWSEL,"COWSEL (COntrolled Working SpacE Language) is a programming language designed between 1964 and 1966 by Robin Popplestone. It was based on an reverse Polish notation (RPN) form of the language Lisp, combined with some ideas from Combined Programming Language (CPL).
COWSEL was initially implemented on a Ferranti Pegasus computer at the University of Leeds and on a Stantec Zebra at the Bradford Institute of Technology. Later, Rod Burstall implemented it on an Elliot 4120 at the University of Edinburgh.
COWSEL was renamed POP-1 in 1966, during summer, and development continued under that name from then on.","COWSEL (COntrolled Working SpacE Language) is a programming language designed between 1964 and 1966 by Robin Popplestone. It was based on an reverse Polish notation (RPN) form of the language Lisp, combined with some ideas from Combined Programming Language (CPL).
COWSEL was initially implemented on a Ferranti Pegasus computer at the University of Leeds and on a Stantec Zebra at the Bradford Institute of Technology. Later, Rod Burstall implemented it on an Elliot 4120 at the University of Edinburgh.
COWSEL was renamed POP-1 in 1966, during summer, and development continued under that name from then on.

Example code
function member
lambda x y
comment Is x a member of list y;
define      y atom then *0 end
            y hd x equal then *1 end
            y tl -> y repeat up

Reserved words (keywords) were also underlined in the original printouts. Popplestone performed syntax highlighting by using underscoring on a Friden Flexowriter.

See also
POP-2 programming language
POP-11 programming language
Poplog programming environment

References
Technical report: EPU-R-12, U Edinburgh (Apr 1966)

External links
""The Early Development of POP"" on The Encyclopedia of Computer Languages",94451,https://en.wikipedia.org/wiki/COWSEL
Crystal (programming language),"Crystal is a high-level general-purpose, object-oriented programming language, designed and developed by Ary Borenszweig, Juan Wajnerman, Brian Cardiff and more than 400 contributors. With syntax inspired by the language Ruby, it is a compiled language with static type-checking, but specifying the types of variables or method arguments is generally unneeded. Types are resolved by an advanced global type inference algorithm. Crystal 
is currently in active development. It is released as free and open-source software under the Apache License version 2.0.","Crystal is a high-level general-purpose, object-oriented programming language, designed and developed by Ary Borenszweig, Juan Wajnerman, Brian Cardiff and more than 400 contributors. With syntax inspired by the language Ruby, it is a compiled language with static type-checking, but specifying the types of variables or method arguments is generally unneeded. Types are resolved by an advanced global type inference algorithm. Crystal 
is currently in active development. It is released as free and open-source software under the Apache License version 2.0.

History
Work on the language began in June 2011, with the aim of merging the elegance and productivity of Ruby with the speed, efficiency, and type safety of a compiled language. Initially named Joy, it was quickly renamed to Crystal.The Crystal compiler was first written in Ruby, but later rewritten in Crystal, thus becoming self-hosting, as of November 2013. The first official version was released in June 2014. In July 2016, Crystal joined the TIOBE index.

Description
Although resembling the Ruby language in syntax, Crystal compiles to much more efficient native code using an LLVM backend, at the cost of precluding the dynamic aspects of Ruby. The advanced global type inference used by the Crystal compiler, combined with union types, gives it more the feel of a higher-level scripting language than many other comparable programming languages. It has automated garbage collection and offers a Boehm collector. Crystal possesses a macro system and supports generics as well as method and operator overloading. Its concurrency model is inspired by communicating sequential processes (CSP) and implements lightweight fibers and channels (for interfiber communication) inspired by Go.

Examples
Hello World
This is the simplest way to write the Hello World program in Crystal:

The same as in Ruby.
Or using an object-oriented programming style:

HTTP server
TCP echo server
Type inference and union types
The following code defines an array containing different types with no usable common ancestor. Crystal automatically creates a union type out of the types of the individual items.

Concurrency
Channels can be used to communicate between fibers, which are initiated using the keyword spawn.

Further reading
References
External links
Official website
Documentation
Crystal-lang on GitHub
/r/crystal_programming subreddit
Crystal Announcements",48972626,https://en.wikipedia.org/wiki/Crystal_(programming_language)
Cuneiform (programming language),"Cuneiform is an open-source workflow language
for large-scale scientific data analysis.
It is a statically typed functional programming language promoting parallel computing. It features a versatile foreign function interface allowing users to integrate software from many external programming languages. At the organizational level Cuneiform provides facilities like conditional branching and general recursion making it Turing-complete. In this, Cuneiform is the attempt to close the gap between scientific workflow systems like Taverna, KNIME, or Galaxy and large-scale data analysis programming models like MapReduce or Pig Latin while offering the generality of a functional programming language.
Cuneiform is implemented in distributed Erlang. If run in distributed mode it drives a POSIX-compliant distributed file system like Gluster or Ceph (or a FUSE integration of some other file system, e.g., HDFS). Alternatively, Cuneiform scripts can be executed on top of HTCondor or Hadoop.Cuneiform is influenced by the work of Peter Kelly who proposes functional programming as a model for scientific workflow execution.
In this, Cuneiform is distinct from related workflow languages based on dataflow programming like Swift.","Cuneiform is an open-source workflow language
for large-scale scientific data analysis.
It is a statically typed functional programming language promoting parallel computing. It features a versatile foreign function interface allowing users to integrate software from many external programming languages. At the organizational level Cuneiform provides facilities like conditional branching and general recursion making it Turing-complete. In this, Cuneiform is the attempt to close the gap between scientific workflow systems like Taverna, KNIME, or Galaxy and large-scale data analysis programming models like MapReduce or Pig Latin while offering the generality of a functional programming language.
Cuneiform is implemented in distributed Erlang. If run in distributed mode it drives a POSIX-compliant distributed file system like Gluster or Ceph (or a FUSE integration of some other file system, e.g., HDFS). Alternatively, Cuneiform scripts can be executed on top of HTCondor or Hadoop.Cuneiform is influenced by the work of Peter Kelly who proposes functional programming as a model for scientific workflow execution.
In this, Cuneiform is distinct from related workflow languages based on dataflow programming like Swift.

External software integration
External tools and libraries (e.g., R or Python libraries) are integrated via a foreign function interface. In this it resembles, e.g., KNIME which allows the use of external software through snippet nodes, or Taverna which offers BeanShell services for integrating Java software. By defining a task in a foreign language it is possible to use the API of an external tool or library. This way, tools can be integrated directly without the need of writing a wrapper or reimplementing the tool.Currently supported foreign programming languages are:

Foreign language support for AWK and gnuplot are planned additions.

Type system
Cuneiform provides a simple, statically checked type system. While Cuneiform provides lists as compound data types it omits traditional list accessors (head and tail) to avoid the possibility of runtime errors which might arise when accessing the empty list. Instead lists are accessed in an all-or-nothing fashion by only mapping or folding over them. Additionally, Cuneiform omits (at the organizational level) arithmetics which excludes the possibility of division by zero. The omission of any partially defined operation allows to guarantee that runtime errors can arise exclusively in foreign code.

Base data types
As base data types Cuneiform provides Booleans, strings, and files. Herein, files are used to exchange data in arbitrary format between foreign functions.

Records and pattern matching
Cuneiform provides records (structs) as compound data types. The example below shows the definition of a variable r being a record with two fields a1 and a2, the first being a string and the second being a Boolean.

Records can be accessed either via projection or via pattern matching. The example below extracts the two fields a1 and a2 from the record r.

Lists and list processing
Furthermore, Cuneiform provides lists as compound data types. The example below shows the definition of a variable xs being a file list with three elements.

Lists can be processed with the for and fold operators. Herein, the for operator can be given multiple lists to consume list element-wise (similar to for/list in Racket, mapcar in Common Lisp or zipwith in Erlang).
The example below shows how to map over a single list, the result being a file list.

The example below shows how to zip two lists the result also being a file list.

Finally, lists can be aggregated by using the fold operator. The following example sums up the elements of a list.

Parallel execution
Cuneiform is a purely functional language, i.e., it does not support mutable references. In the consequence, it can use subterm-independence to divide a program into parallelizable portions. The Cuneiform scheduler distributes these portions to worker nodes. In addition, Cuneiform uses a Call-by-Name evaluation strategy to compute values only if they contribute to the computation result. Finally, foreign function applications are memoized to speed up computations that contain previously derived results.
For example, the following Cuneiform program allows the applications of f and g to run in parallel while h is dependent and can be started only when both f and g are finished.

let output-of-f : File = f();
let output-of-g : File = g();

h( f = output-of-f, g = output-of-g );
The following Cuneiform program creates three parallel applications of the function f by mapping f over a three-element list:

let xs : [File] =
  ['a.txt', 'b.txt', 'c.txt' : File];

for x <- xs do
  f( x = x )
  : File
end;
Similarly, the applications of f and g are independent in the construction of the record r and can, thus, be run in parallel:

Examples
A hello-world script:

This script defines a task greet in Bash which prepends ""Hello "" to its string argument person.
The function produces a record with a single string field out.
Applying greet, binding the argument person to the string ""world"" produces the record <out = ""Hello world"">. Projecting this record to its field out evaluates the string ""Hello world"".
Command line tools can be integrated by defining a task in Bash:

In this example a task samtoolsSort is defined.
It calls the tool SAMtools, consuming an input file, in BAM format, and producing a sorted output file, also in BAM format.

Release history
In April 2016, Cuneiform's implementation language switched from Java to Erlang and, in February 2018, its major distributed execution platform changed from a Hadoop to distributed Erlang. Additionally, from 2015 to 2018 HTCondor had been maintained as an alternative execution platform.
Cuneiform's surface syntax was revised twice, as reflected in the major version number.

Version 1
In its first draft published in May 2014, Cuneiform was closely related to Make in that it constructed a static data dependency graph which the interpreter traversed during execution. The major difference to later versions was the lack of conditionals, recursion, or static type checking. Files were distinguished from strings by juxtaposing single-quoted string values with a tilde ~. The script's query expression was introduced with the target keyword. Bash was the default foreign language. Function application had to be performed using an apply form that took task as its first keyword argument. One year later, this surface syntax was replaced by a streamlined but similar version.
The following example script downloads a reference genome from an FTP server.

declare download-ref-genome;

deftask download-fa( fa : ~path ~id ) *{
    wget $path/$id.fa.gz
    gunzip $id.fa.gz
    mv $id.fa $fa
}*

ref-genome-path = ~'ftp://hgdownload.cse.ucsc.edu/goldenPath/hg19/chromosomes';
ref-genome-id = ~'chr22';

ref-genome = apply(
    task : download-fa
    path : ref-genome-path
    id : ref-genome-id
);

target ref-genome;

Version 2
The second draft of the Cuneiform surface syntax, first published in March 2015, remained in use for three years outlasting the transition from Java to Erlang as Cuneiform's implementation language. Evaluation differs from earlier approaches in that the interpreter reduces a query expression instead of traversing a static graph. During the time the surface syntax remained in use the interpreter was formalized and simplified which resulted in a first specification of Cuneiform's semantics. The syntax featured conditionals. However, Booleans were encoded as lists, recycling the empty list as Boolean false and the non-empty list as Boolean true. Recursion was added later as a byproduct of formalization. However, static type checking was introduced only in Version 3.
The following script decompresses a zipped file and splits it into evenly sized partitions.

deftask unzip( <out( File )> : zip( File ) ) in bash *{
  unzip -d dir $zip
  out=`ls dir | awk '{print ""dir/"" $0}'`
}*

deftask split( <out( File )> : file( File ) ) in bash *{
  split -l 1024 $file txt
  out=txt*
}*

sotu = ""sotu/stateoftheunion1790-2014.txt.zip"";
fileLst = split( file: unzip( zip: sotu ) );

fileLst;

Version 3
The current version of Cuneiform's surface syntax, in comparison to earlier drafts, is an attempt to close the gap to mainstream functional programming languages. It features a simple, statically checked type system and introduces records in addition to lists as a second type of compound data structure. Booleans are a separate base data type.
The following script untars a file resulting in a file list.

def untar( tar : File ) -> <fileLst : [File]>
in Bash *{
  tar xf $tar
  fileLst=`tar tf $tar`
}*

let hg38Tar : File =
  'hg38/hg38.tar';

let <fileLst = faLst : [File]> =
  untar( tar = hg38Tar );

faLst;


== References ==",51797637,https://en.wikipedia.org/wiki/Cuneiform_(programming_language)
D (programming language),"D, also known as dlang, is a multi-paradigm system programming language created by Walter Bright at Digital Mars and released in 2001. Andrei Alexandrescu joined the design and development effort in 2007. Though it originated as a re-engineering of C++, D is now a very different language drawing inspiration from other high-level programming languages, notably Java, Python, Ruby, C#, and Eiffel.
The D language reference describes it as follows:

D is a general-purpose systems programming language with a C-like syntax that compiles to native code. It is statically typed and supports both automatic (garbage collected) and manual memory management. D programs are structured as modules that can be compiled separately and linked with external libraries to create native libraries or executables.","D, also known as dlang, is a multi-paradigm system programming language created by Walter Bright at Digital Mars and released in 2001. Andrei Alexandrescu joined the design and development effort in 2007. Though it originated as a re-engineering of C++, D is now a very different language drawing inspiration from other high-level programming languages, notably Java, Python, Ruby, C#, and Eiffel.
The D language reference describes it as follows:

D is a general-purpose systems programming language with a C-like syntax that compiles to native code. It is statically typed and supports both automatic (garbage collected) and manual memory management. D programs are structured as modules that can be compiled separately and linked with external libraries to create native libraries or executables.

Features
D is not source compatible with C and C++ source code in general. However, any code that is legal in both C and D should behave in the same way.
Like C++, D has closures, anonymous functions, compile-time function execution, ranges, built-in container iteration concepts, and type inference. Unlike C++, D also implements design by contract, modules, garbage collection, first class arrays, array slicing, nested functions and lazy evaluation. D uses Java-style single inheritance with interfaces and mixins rather than C++-style multiple inheritance. On the other hand, D's declaration, statement and expression syntax closely matches that of C++.
D is a systems programming language. Like C++, D supports low-level programming including inline assembler, which typifies the differences between D and application languages like Java and C#. Inline assembler lets programmers enter machine-specific assembly code within standard D code, a method used by system programmers to access the low-level features of the processor needed to run programs that interface directly with the underlying hardware, such as operating systems and device drivers, as well as writing high-performance code (i.e. using vector extensions, SIMD) that is hard to generate by the compiler automatically.
D supports function overloading and operator overloading. Symbols (functions, variables, classes) can be declared in any order - forward declarations are not required.
In D, text character strings are arrays of characters, and arrays in D are bounds-checked. D has first class types for complex and imaginary numbers.

Programming paradigms
D supports five main programming paradigms:

concurrent (actor model)
object-oriented
imperative
functional
metaprogramming

Imperative
Imperative programming in D is almost identical to that in C. Functions, data, statements, declarations and expressions work just as they do in C, and the C runtime library may be accessed directly. On the other hand, some notable differences between D and C in the area of imperative programming include D's foreach loop construct, which allows looping over a collection, and nested functions, which are functions that are declared inside another and may access the enclosing function's local variables.

Object-oriented
Object-oriented programming in D is based on a single inheritance hierarchy, with all classes derived from class Object. D does not support multiple inheritance; instead, it uses Java-style interfaces, which are comparable to C++'s pure abstract classes, and mixins, which separates common functionality from the inheritance hierarchy. D also allows the defining of static and final (non-virtual) methods in interfaces.
Interfaces and inheritance in D support covariant types for return types of overridden methods.
D supports type forwarding, as well as optional custom dynamic dispatch.
Classes (and interfaces) in D can contain invariants which are automatically checked before and after entry to public methods, in accordance with the design by contract methodology.
Many aspects of classes (and structs) can be introspected automatically at compile time (a form of reflection using type traits) and at run time (RTTI / TypeInfo), to facilitate generic code or automatic code generation (usually using compile-time techniques).

Functional
D supports functional programming features such as function literals, closures, recursively-immutable objects and the use of higher-order functions. There are two syntaxes for anonymous functions, including a multiple-statement form and a ""shorthand"" single-expression notation:

There are two built-in types for function literals, function, which is simply a pointer to a stack-allocated function, and delegate, which also includes a pointer to the relevant stack frame, the surrounding ‘environment’, which contains the current local variables. Type inference may be used with an anonymous function, in which case the compiler creates a delegate unless it can prove that an environment pointer is not necessary. Likewise, to implement a closure, the compiler places enclosed local variables on the heap only if necessary (for example, if a closure is returned by another function, and exits that function's scope). When using type inference, the compiler will also add attributes such as pure and nothrow to a function's type, if it can prove that they apply.
Other functional features such as currying and common higher-order functions such as map, filter, and reduce are available through the standard library modules std.functional and std.algorithm.

Alternatively, the above function compositions can be expressed using Uniform function call syntax (UFCS) for more natural left-to-right reading:

Parallelism
Parallel programming concepts are implemented in the library, and do not require extra support from the compiler. However the D type system and compiler ensure that data sharing can be detected and managed transparently.

iota(11).parallel is equivalent to std.parallelism.parallel(iota(11)) by using UFCS.
The same module also supports taskPool which can be used for dynamic creation of parallel tasks, as well as map-filter-reduce and fold style operations on ranges (and arrays), which is useful when combined with functional operations. std.algorithm.map returns a lazily evaluated range rather than an array. This way, the elements are computed by each worker task in parallel automatically.

Concurrency
Concurrency is fully implemented in the library, and it does not require support from the compiler. Alternative implementations and methodologies of writing concurrent code are possible. The use of D typing system does help ensure memory safety.

Metaprogramming
Metaprogramming is supported through templates, compile-time function execution, tuples, and string mixins. The following examples demonstrate some of D's compile-time features.
Templates in D can be written in a more imperative style compared to the C++ functional style for templates. This is a regular function that calculates the factorial of a number:

Here, the use of static if, D's compile-time conditional construct, is demonstrated to construct a template that performs the same calculation using code that is similar to that of the function above:

In the following two examples, the template and function defined above are used to compute factorials. The types of constants need not be specified explicitly as the compiler infers their types from the right-hand sides of assignments:

This is an example of compile-time function execution (CTFE). Ordinary functions may be used in constant, compile-time expressions provided they meet certain criteria:

The std.string.format function performs printf-like data formatting (also at compile-time, through CTFE), and the ""msg"" pragma displays the result at compile time:

String mixins, combined with compile-time function execution, allow for the generation of D code using string operations at compile time. This can be used to parse domain-specific languages, which will be compiled as part of the program:

Memory management
Memory is usually managed with garbage collection, but specific objects may be finalized immediately when they go out of scope. This is what the majority of programs and libraries written in D use.
In case more control over memory layout and better performance is needed, explicit memory management is possible using the overloaded operator new, by calling C's malloc and free directly, or implementing custom allocator schemes (i.e. on stack with fallback, RAII style allocation, reference counting, shared reference counting). Garbage collection can be controlled: programmers may add and exclude memory ranges from being observed by the collector, can disable and enable the collector and force either a generational or full collection cycle. The manual gives many examples of how to implement different highly optimized memory management schemes for when garbage collection is inadequate in a program.In functions, struct instances are by default allocated on the stack, while class instances by default allocated on the heap (with only reference to the class instance being on the stack). However this can be changed for classes, for example using standard library template std.typecons.scoped, or by using new for structs and assigning to a pointer instead of a value-based variable.In functions, static arrays (of known size) are allocated on the stack. For dynamic arrays, one can use the core.stdc.stdlib.alloca function (similar to alloca in C), to allocate memory on the stack. The returned pointer can be used (recast) into a (typed) dynamic array, by means of a slice (however resizing array, including appending must be avoided; and for obvious reasons they must not be returned from the function).A scope keyword can be used both to annotate parts of code, but also variables and classes/structs, to indicate they should be destroyed (destructor called) immediately on scope exit. Whatever the memory is deallocated also depends on implementation and class-vs-struct differences.std.experimental.allocator contains a modular and composable allocator templates, to create custom high performance allocators for special use cases.

SafeD
SafeD
is the name given to the subset of D that can be guaranteed to be memory safe (no writes to memory that has not been allocated or that has been recycled). Functions marked @safe are checked at compile time to ensure that they do not use any features that could result in corruption of memory, such as pointer arithmetic and unchecked casts, and any other functions called must also be marked as @safe or @trusted. Functions can be marked @trusted for the cases where the compiler cannot distinguish between safe use of a feature that is disabled in SafeD and a potential case of memory corruption.

Scope lifetime safety
Initially under the banners of DIP1000 and DIP25 (now part of the language specification), D provides protections against certain ill-formed constructions involving the lifetimes of data.
The current mechanisms in place primarily deal with function parameters and stack memory however it is a stated ambition of the leadership of the programming language to provide a more thorough treatment of lifetimes within the D programming language (influenced by ideas from Rust programming language).

Lifetime safety of assignments
Within @safe code, the lifetime of an assignment involving a reference type is checked to ensure that the lifetime of the assignee is longer than that of the assigned.
For example:

Function parameter lifetime annotations within @safe code
When applied to function parameter which are either of pointer type or references, the keywords return and scope constrain the lifetime and use of that parameter.
The language standard dictates the following behaviour:

An annotated example is given below.

Interaction with other systems
C's application binary interface (ABI) is supported, as well as all of C's fundamental and derived types, enabling direct access to existing C code and libraries. D bindings are available for many popular C libraries. Additionally, C's standard library is part of standard D.
On Microsoft Windows, D can access Component Object Model (COM) code.
As long as memory management is properly taken care of, many other languages can be mixed with D in a single binary. For example, the GDC compiler allows to link and intermix C, C++, and other supported language codes such as Objective-C. D code (functions) can also be marked as using C, C++, Pascal ABIs, and thus be passed to the libraries written in these languages as callbacks. Similarly data can be interchanged between the codes written in these languages in both ways. This usually restricts use to primitive types, pointers, some forms of arrays, unions, structs, and only some types of function pointers.
Because many other programming languages often provide the C API for writing extensions or running the interpreter of the languages, D can interface directly with these languages as well, using standard C bindings (with a thin D interface file). For example, there are bi-directional bindings for languages like Python, Lua and other languages, often using compile-time code generation and compile-time type reflection methods.

Interaction with C++ code
For D code marked as extern(C++), the following features are specified:

The name mangling conventions shall match those of C++ on the target.
For function calls, the ABI shall be equivalent.
The vtable shall be matched up to single inheritance (the only level supported by the D language specification).C++ namespaces are used via the syntax extern(C++, namespace) where namespace is the name of the C++ namespace.

An example of C++ interoperation
The C++ side

The D side

Better C
The D programming language has an official subset known as ""Better C"". This subset forbids access to D features requiring use of runtime libraries other than that of C.
Enabled via the compiler flags ""-betterC"" on DMD and LDC, and ""-fno-druntime"" on GDC, Better C may only call into D code compiled under the same flag (and linked code other than D) but code compiled without the Better C option may call into code compiled with it: this will, however, lead to slightly different behaviours due to differences in how C and D handle asserts.

Features included in Better C
Unrestricted use of compile-time features (for example, D's dynamic allocation features can be used at compile time to pre-allocate D data)
Full metaprogramming facilities
Nested functions, nested structs, delegates and lambdas
Member functions, constructors, destructors, operating overloading, etc.
The full module system
Array slicing, and array bounds checking
RAII
scope(exit)
Memory safety protections
Interfacing with C++
COM classes and C++ classes
assert failures are directed to the C runtime library
switch with strings
final switch
unittest blocks
printf format validation

Features excluded from Better C
Garbage collection
TypeInfo and ModuleInfo
Built-in threading (e.g. core.thread)
Dynamic arrays (though slices of static arrays work) and associative arrays
Exceptions
synchronized and core.sync
Static module constructors or destructors

History
Walter Bright started working on a new language in 1999. D was first released in December 2001 and reached version 1.0 in January 2007. The first version of the language (D1) concentrated on the imperative, object oriented and metaprogramming paradigms, similar to C++.
Some members of the D community dissatisfied with Phobos, D's official runtime and standard library, created an alternative runtime and standard library named Tango. The first public Tango announcement came within days of D 1.0's release. Tango adopted a different programming style, embracing OOP and high modularity. Being a community-led project, Tango was more open to contributions, which allowed it to progress faster than the official standard library. At that time, Tango and Phobos were incompatible due to different runtime support APIs (the garbage collector, threading support, etc.). This made it impossible to use both libraries in the same project. The existence of two libraries, both widely in use, has led to significant dispute due to some packages using Phobos and others using Tango.In June 2007, the first version of D2 was released. The beginning of D2's development signaled D1's stabilization. The first version of the language has been placed in maintenance, only receiving corrections and implementation bugfixes. D2 introduced breaking changes to the language, beginning with its first experimental const system. D2 later added numerous other language features, such as closures, purity, and support for the functional and concurrent programming paradigms. D2 also solved standard library problems by separating the runtime from the standard library. The completion of a D2 Tango port was announced in February 2012.The release of Andrei Alexandrescu's book The D Programming Language on 12 June 2010, marked the stabilization of D2, which today is commonly referred to as just ""D"".
In January 2011, D development moved from a bugtracker / patch-submission basis to GitHub. This has led to a significant increase in contributions to the compiler, runtime and standard library.In December 2011, Andrei Alexandrescu announced that D1, the first version of the language, would be discontinued on 31 December 2012. The final D1 release, D v1.076, was on 31 December 2012.Code for the official D compiler, the Digital Mars D compiler by Walter Bright, was originally released under a custom license, qualifying as source available but not conforming to the Open Source Definition. In 2014, the compiler front-end was re-licensed as open source under the Boost Software License. This re-licensed code excluded the back-end, which had been partially developed at Symantec. On 7 April 2017, the whole compiler was made available under the Boost license after Symantec gave permission to re-license the back-end, too. On 21 June 2017, the D Language was accepted for inclusion in GCC.

Implementations
Most current D implementations compile directly into machine code.
Production ready compilers:

DMD – The Digital Mars D compiler by Walter Bright is the official D compiler; open sourced under the Boost Software License. The DMD frontend is shared by GDC (now in GCC) and LDC, to improve compatibility between compilers. Initially the frontend was written in C++, but now most of it is written in D itself (self-hosting). The backend and machine code optimizers are based on the Symantec compiler. At first it supported only 32-bit x86, with support added for 64-bit amd64 and PowerPC by Walter Bright. Later the backend and almost the entire compiler was ported from C++ to D for full self-hosting.
GCC – The GNU Compiler Collection, merged GDC into GCC 9 on 29 October 2018. The first working versions of GDC with GCC, based on GCC 3.3 and GCC 3.4 on 32-bit x86 on Linux and macOS was released on 22 March 2004. Since then GDC has gained support for additional platforms, improved performance, and fixed bugs, while tracking upstream DMD code for the frontend and language specification.
LDC – A compiler based on the DMD front-end that uses LLVM as its compiler back-end. The first release-quality version was published on 9 January 2009. It supports version 2.0.Toy and proof-of-concept compilers:

D Compiler for .NET – A back-end for the D programming language 2.0 compiler. It compiles the code to Common Intermediate Language (CIL) bytecode rather than to machine code. The CIL can then be run via a Common Language Infrastructure (CLI) virtual machine. The project has not been updated in years and the author indicated the project is not active anymore.
SDC – The Snazzy D Compiler uses a custom front-end and LLVM as its compiler back-end. It is written in D and uses a scheduler to handle symbol resolution in order to elegantly handle the compile-time features of D. This compiler currently supports a limited subset of the language.Using above compilers and toolchains, it is possible to compile D programs to target many different architectures, including IA-32, amd64, AArch64, PowerPC, MIPS64, DEC Alpha, Motorola m68k, SPARC, s390, WebAssembly. The primary supported operating systems are Windows and Linux, but various compilers also support Mac OS X, FreeBSD, NetBSD, AIX, Solaris/OpenSolaris and Android, either as a host or target, or both. WebAssembly target (supported via LDC and LLVM) can operate in any WebAssembly environment, like modern web browser (Google Chrome, Mozilla Firefox, Microsoft Edge, Apple Safari), or dedicated Wasm virtual machines.

Development tools
Editors and integrated development environments (IDEs) supporting syntax highlighting and partial code completion for the language include SlickEdit, Emacs, vim, SciTE, Smultron, Zeus, and Geany among others.
Dexed (formerly Coedit), a D focused graphical IDE written in Object Pascal
Mono-D is a feature rich cross-platform D focused graphical IDE based on MonoDevelop / Xamarin Studio, mainly written in C Sharp.
Eclipse plug-ins for D include DDT and Descent (dead project).
Visual Studio integration is provided by VisualD.
Visual Studio Code integration with extensions as Dlang-Vscode or Code-D.
A bundle is available for TextMate, and the Code::Blocks IDE includes partial support for the language. However, standard IDE features such as code completion or refactoring are not yet available, though they do work partially in Code::Blocks (due to D's similarity to C).
The Xcode 3 plugin ""D for Xcode"" enables D-based projects and development.
KDevelop (as well as its text editor backend, Kate) autocompletion plugin is available.Open source D IDEs for Windows exist, some written in D, such as Poseidon, D-IDE, and Entice Designer.D applications can be debugged using any C/C++ debugger, like GDB or WinDbg, although support for various D-specific language features is extremely limited. On Windows, D programs can be debugged using Ddbg, or Microsoft debugging tools (WinDBG and Visual Studio), after having converted the debug information using cv2pdb. The ZeroBUGS Archived 23 December 2017 at the Wayback Machine debugger for Linux has experimental support for the D language. Ddbg can be used with various IDEs or from the command line; ZeroBUGS has its own graphical user interface (GUI).
DustMite is a tool for minimizing D source code, useful when finding compiler or tests issues.dub is a popular package and build manager for D applications and libraries, and is often integrated into IDE support.

Examples
Example 1
This example program prints its command line arguments. The main function is the entry point of a D program, and args is an array of strings representing the command line arguments. A string in D is an array of characters, represented by immutable(char)[].

The foreach statement can iterate over any collection. In this case, it is producing a sequence of indexes (i) and values (arg) from the array args. The index i and the value arg have their types inferred from the type of the array args.

Example 2
The following shows several D capabilities and D design trade-offs in a short program. It iterates over the lines of a text file named words.txt, which contains a different word on each line, and prints all the words that are anagrams of other words.

signature2words is a built-in associative array that maps dstring (32-bit / char) keys to arrays of dstrings. It is similar to defaultdict(list) in Python.
lines(File()) yields lines lazily, with the newline. It has to then be copied with idup to obtain a string to be used for the associative array values (the idup property of arrays returns an immutable duplicate of the array, which is required since the dstring type is actually immutable(dchar)[]). Built-in associative arrays require immutable keys.
The ~= operator appends a new dstring to the values of the associate dynamic array.
toLower, join and chomp are string functions that D allows the use of with a method syntax. The name of such functions are often similar to Python string methods. The toLower converts a string to lower case, join("" "") joins an array of strings into a single string using a single space as separator, and chomp removes a newline from the end of the string if one is present. The w.dup.sort().release().idup is more readable, but equivalent to release(sort(w.dup)).idup for example. This feature is called UFCS (Uniform Function Call Syntax), and allows extending any built-in or third party package types with method-like functionality. The style of writing code like this is often referenced as pipeline (especially when the objects used are lazily computed, for example iterators / ranges) or Fluent interface.
The sort is an std.algorithm function that sorts the array in place, creating a unique signature for words that are anagrams of each other. The release() method on the return value of sort() is handy to keep the code as a single expression.
The second foreach iterates on the values of the associative array, it is able to infer the type of words.
signature is assigned to an immutable variable, its type is inferred.
UTF-32 dchar[] is used instead of normal UTF-8 char[] otherwise sort() refuses to sort it. There are more efficient ways to write this program using just UTF-8.

Uses
Notable organisations that use the D programming language for projects include Facebook, eBay, and Netflix.D has been successfully used for AAA games, language interpreters, virtual machines, an operating system kernel, GPU programming, web development, numerical analysis, GUI applications, a passenger information system, machine learning, text processing, web and application servers and research.
The notorious North Korean hacking group known as Lazarus exploited CVE-2021-44228, aka ""Log4Shell,"" to deploy three malware families written in DLang.

See also
Ddoc
D Language Foundation

References
Further reading
Alexandrescu, Andrei (4 January 2010). The D Programming Language (1 ed.). Addison-Wesley Professional. ISBN 978-0-321-63536-5.
Alexandrescu, Andrei (15 June 2009). ""The Case for D"". Dr. Dobb's Journal.
Bright, Walter (8 April 2014). ""How I Came to Write D"". Dr. Dobb's Journal.
Çehreli, Ali (1 February 2012). ""Programming in D"". (distributed under CC-BY-NC-SA license). This book teaches programming to novices, but covers many advanced D topics as well.
Metz, Cade (7 July 2014). ""The Next Big Programming Language You've Never Heard Of"". Wired.
Ruppe, Adam (May 2014). D Cookbook (1 ed.). PACKT Publishing. ISBN 978-1-783-28721-5.

External links

Official website 
Digital Mars
Turkish Forum
Dlang on GitHub",243881,https://en.wikipedia.org/wiki/D_(programming_language)
DARSIMCO,"DARSIMCO, short for Dartmouth Simplified Code, was a simple programming language written by John Kemeny in 1956 that expanded simple mathematical operations into IBM 704 assembly language (Share Assembly Language, SAL). It was an attempt to simplify basic mathematical processing, a common theme in the 1950s, but found little use before the arrival of FORTRAN at MIT the next year.","DARSIMCO, short for Dartmouth Simplified Code, was a simple programming language written by John Kemeny in 1956 that expanded simple mathematical operations into IBM 704 assembly language (Share Assembly Language, SAL). It was an attempt to simplify basic mathematical processing, a common theme in the 1950s, but found little use before the arrival of FORTRAN at MIT the next year.

Description
This language was essentially a set of macros that expanded out user source code into a series of assembly language instructions, which were then compiled using the existing SAL assembler, Symbolic Assembly Program. For instance, the formula A + B = C would add the values in memory locations A and B and put the result in C. To do this, the DARSIMCO compiler would write out the following three instructions:

 LDA A
 FAD B
 STO C

The language included similar expansions for subtraction, multiplication, division, and simple looping.
The language was implemented on the IBM 704 at MIT's New England Regional Computer Center. Programmed using punch cards, the system had a two-week turnaround because Kemeny had to take the cards in via train from Dartmouth.

See also
Autocode, a similar concept for mathematical programming

References
Kurtz, Thomas (1981). ""BASIC"". History of programming languages. History of programming languages I. ACM. pp. 515–537. doi:10.1145/800025.1198404. ISBN 0-12-745040-8.",57980375,https://en.wikipedia.org/wiki/DARSIMCO
Dartmouth Oversimplified Programming Experiment,"DOPE, short for Dartmouth Oversimplified Programming Experiment, was a simple programming language designed by John Kemény in 1962 to offer students a transition from flow-charting to programming the LGP-30. Lessons learned from implementing DOPE were subsequently applied to the invention and development of BASIC.","DOPE, short for Dartmouth Oversimplified Programming Experiment, was a simple programming language designed by John Kemény in 1962 to offer students a transition from flow-charting to programming the LGP-30. Lessons learned from implementing DOPE were subsequently applied to the invention and development of BASIC.

Description
Each statement was designed to correspond to a flowchart operation and consisted of a numeric line number, an operation, and the required operands:

 7 + A B C
10 SIN X Z

The final variable specified the destination for the computation. The above program corresponds in functionality to the later BASIC program:

DOPE might be the first programming language to require every statement to have a line number, predating JOSS and BASIC.
The language was case insensitive.
Variable names were a single letter A to Z, or a letter followed by a digit (A0 to Z9). As with Fortran, different letters represented different variable types. Variables starting with letters A to D were floating point, as were variables from I to Z; variables E, F, G, and H each were defined as vectors with components from 1 to 16.

The language was used by only one freshman computing class. Kemeny collaborated with high school student Sidney Marshall (taking freshman calculus) to develop the language.

Legacy
According to Thomas Kurtz, a co-inventor of BASIC, ""Though not a success in itself, DOPE presaged BASIC. DOPE provided default vectors, default printing formats, and general input formats. Line numbers doubled as jump targets.""
The language had a number of other features and innovations that were carried over into BASIC:

Variable names were either a letter or a letter followed by a digit
Arrays (vectors) did not have to be declared and had a default size (16 instead of 10)
Every line required a numeric label*
Lines were sorted in numeric order*
Every line begins with a keyword*
Function names were three letters long*
The only loop construct was a for-loop*Unlike either Fortran or Algol 60.

See also
DARSIMCO, 'Dartmouth Simplified Code', a 1956 assembler macro language
Dartmouth ALGOL 30, a compiler developed by Dartmouth for the LGP-30


== References ==",65434331,https://en.wikipedia.org/wiki/Dartmouth_Oversimplified_Programming_Experiment
Darwin (programming language),"Darwin is a closed source programming language developed by Gaston Gonnet and colleagues at ETH Zurich.  It is used to develop the OMA orthology inference software, which was also initially developed by Gonnet. The language backend consists of the kernel, responsible for performing simple mathematical calculations, for transporting and storing data and for interpreting the user's commands, and the library, a set of programs which can perform more complicated calculations. The target audience for the language is the biosciences, so the library consisted of routines such as those to compute pairwise alignments, phylogenetic trees, multiple sequence alignments, and to make secondary structure predictions.","Darwin is a closed source programming language developed by Gaston Gonnet and colleagues at ETH Zurich.  It is used to develop the OMA orthology inference software, which was also initially developed by Gonnet. The language backend consists of the kernel, responsible for performing simple mathematical calculations, for transporting and storing data and for interpreting the user's commands, and the library, a set of programs which can perform more complicated calculations. The target audience for the language is the biosciences, so the library consisted of routines such as those to compute pairwise alignments, phylogenetic trees, multiple sequence alignments, and to make secondary structure predictions.

Example Code
One would write the Hello World program as:

The following procedure calculates the factorial of a number:

See also
List of programming languages


== References ==",12794721,https://en.wikipedia.org/wiki/Darwin_(programming_language)
DataFlex,"DataFlex is an object-oriented high-level programming language and a fourth generation visual tool for developing Windows, web and mobile software applications on one framework-based platform. It was introduced and developed by Data Access Corporation beginning in 1982.","DataFlex is an object-oriented high-level programming language and a fourth generation visual tool for developing Windows, web and mobile software applications on one framework-based platform. It was introduced and developed by Data Access Corporation beginning in 1982.

History and overview
DataFlex can be traced back to 1982 when the company called Data Access Corporation (founded in 1976) created and developed a language allowing application code to run on almost any system architecture, regardless of hardware. It started as a relatively early example of a fully fledged and commercially used fourth-generation programming language (4GL). In its early forms, DataFlex was available for CP/M, MS-DOS, TurboDOS, Novell NetWare, OS/2, Unix, VMS and IBM AIX operating systems. By 1985, DataFlex was applied in a variety of high-tech industries including automated inventory control systems and insurance fraud detection systems.DataFlex has lasted many years as a niche application development environment. The DataFlex product supports many relational database environments: Oracle database, Microsoft SQL Server, IBM Db2, MySQL, PostgreSQL and any ODBC database. DataFlex applications are used by around 3 million users. In 1991, the 3.0 version with a modernized interface was released. In 2014, Data Access released 2014/18.0 version. The release of DataFlex 2023/23.0 introduced FlexTron technology that allows the usage of web controls within Windows desktop applications.
DataFlex is developed and provided by Data Access Worldwide, a software company with main offices in Miami, Florida, Hengelo, Netherlands, and São Paulo, Brazil.

Features
The DataFlex language supports: 

Supports many database environments: Oracle database, Microsoft SQL Server, IBM Db2, MySQL, PostgreSQL as well as any ODBC database.
Easily switch between database backends, no code change needed.
Variables are loosely typed. The virtual machine takes care of conversions.
Flexibility; the language is object oriented, so developers can create subclasses and libraries.
Code compiles to an intermediate byte-code which makes the programs easily portable between operating systems.
No threads or multitasking
Methods can - for ease of coding - be defined or redefined inside the object definition. Technically the compiler simply sub-classes the superclass and adds the methods to the class.
Automatic delegation of messages in the object-oriented programming environment
Embedded Database access is ISAM-based. It can be used royalty-free.

Language Extension
Functions defined in Dynamic Link Libraries can be used.
Classes, methods and properties defined in a COM module can be used. COM automation, controls and embedding is supported.

Development environments
The DataFlex programming language is used in the following development environments:

DataFlex Studio
This is the flagship visual development environment from Data Access Worldwide. DataFlex is available for Microsoft Windows only. DataFlex is a GUI development language in a style comparable with Visual Basic, Delphi and C++. From version 4 (1996) up until version 17.1 (2015), the product was labeled Visual DataFlex.
DataFlex WebApp Server
Available for Microsoft IIS only, the DataFlex WebApp Server can be used to develop thin client applications such as browser-based applications (both full class browsers such as Google Chrome, Internet Explorer, Mozilla Firefox and Opera, as well as WAP browsers). Developers can also create Web Service client and server applications. The server has built-in load balancing capabilities which also assist with High Availability, this does, however, require an SPLF license.
Web Framework
DataFlex includes a web framework for writing web and mobile applications.
Character mode DataFlex
The latest iteration of the original character mode application (3.2) is available as a Console Mode application for MS-DOS, Microsoft Windows and Unix variants (notably Linux).

References
External links
Data Access Worldwide website
DataFlex Learning database  (online resource for learning about building applications with DataFlex)
VDF-GUIdance (independent resource for users of the DataFlex programming language)",742526,https://en.wikipedia.org/wiki/DataFlex
Deductive language,"A deductive language is a computer programming language in which the program is a collection of predicates ('facts') and rules that connect them. Such a language is used to create knowledge based systems or expert systems which can deduce answers to problem sets by applying the rules to the facts they have been given.
An example of a deductive language is Prolog, or its database-query cousin, Datalog.","A deductive language is a computer programming language in which the program is a collection of predicates ('facts') and rules that connect them. Such a language is used to create knowledge based systems or expert systems which can deduce answers to problem sets by applying the rules to the facts they have been given.
An example of a deductive language is Prolog, or its database-query cousin, Datalog.

History
As the name implies, deductive languages are rooted in the principles of deductive reasoning; making inferences based upon current knowledge.  The first recommendation to use a clausal form of logic for representing computer programs was made by Cordell Green (1969) at Stanford Research Institute (now SRI International). This idea can also be linked back to the battle between procedural and declarative information representation in early artificial intelligence systems.  Deductive languages and their use in logic programming can also be dated to the same year when Foster and Elcock introduced Absys, the first deductive/logical programming language.  Shortly after, the first Prolog system was introduced in 1972 by Colmerauer through collaboration with Robert Kowalski.

Components
The components of a deductive language are a system of formal logic and a knowledge base upon which the logic is applied.

Formal Logic
Formal logic is the study of inference in regards to formal content. The distinguishing feature between formal and informal logic is that in the former case, the logical rule applied to the content is not specific to a situation. The laws hold regardless of a change in context.  Although first-order logic is described in the example below to demonstrate the uses of a deductive language, no formal system is mandated and the use of a specific system is defined within the language rules or grammar.
As input, a predicate takes any object(s) in the domain of interest and outputs either one of two Boolean values: true or false.  For example, consider the sentences ""Barack Obama is the 44th president"" and ""If it rains today, I will bring an umbrella"".  The first is a statement with an associated truth value.  The second is a conditional statement relying on the value of some other statement.  Either of these sentences can be broken down into predicates which can be compared and form the knowledge base of a deductive language.
Moreover, variables such as 'Barack Obama' or 'president' can be quantified over.  For example, take 'Barack Obama' as variable 'x'.  In the sentence ""There exists an 'x' such that if 'x' is the president, then 'x' is the commander in chief.""  This is an example of the existential quantifier in first order logic.  Take 'president' to be the variable 'y'.  In the sentence ""For every 'y', 'y' is the leader of their nation.""  This is an example of the universal quantifier.

Knowledge Base
A collection of 'facts' or predicates and variables form the knowledge base of a deductive language.  Depending on the language, the order of declaration of these predicates within the knowledge base may or may not influence the result of applying logical rules.  Upon application of certain 'rules' or inferences, new predicates may be added to a knowledge base.  As new facts are established or added, they form the basis for new inferences.  As the core of early expert systems, artificial intelligence systems which can make decisions like an expert human, knowledge bases provided more information than databases. They contained structured data, with classes, subclasses, and instances.

Prolog
Prolog is an example of a deductive, declarative language that applies first- order logic to a knowledge base. To run a program in Prolog, a query is posed and based upon the inference engine and the specific facts in the knowledge base, a result is returned.  The result can be anything appropriate from a new relation or predicate, to a literal such as a Boolean (true/false), depending on the engine and type system.


== References ==",6477222,https://en.wikipedia.org/wiki/Deductive_language
DIBOL,"DIBOL or Digital's Business Oriented Language is a general-purpose, procedural, imperative programming language that was designed for use in Management Information Systems (MIS) software development. It was developed from 1970 to 1993.
DIBOL has a syntax similar to FORTRAN and BASIC, along with BCD arithmetic. It shares the COBOL program structure of separate data and procedure divisions. Unlike Fortran's numeric labels (for GOTO), DIBOL's were alphanumeric; the language supported a counterpart to computed goto.","DIBOL or Digital's Business Oriented Language is a general-purpose, procedural, imperative programming language that was designed for use in Management Information Systems (MIS) software development. It was developed from 1970 to 1993.
DIBOL has a syntax similar to FORTRAN and BASIC, along with BCD arithmetic. It shares the COBOL program structure of separate data and procedure divisions. Unlike Fortran's numeric labels (for GOTO), DIBOL's were alphanumeric; the language supported a counterpart to computed goto.

History
DIBOL was originally marketed by Digital Equipment Corporation (DEC) in 1970.
The original version, DIBOL-8, was produced for PDP-8 systems running COS-300. The PDP-8-like DECmate II, supports the COS-310 Commercial Operating System, featuring DIBOL.DIBOL-11 was developed for the PDP-11 running COS-350 operating system. It also ran on RSX-11, RT-11, and from 1978 on RSTS/E. DIBOL-32 runs on VMS systems, although it can also be used on other systems through emulators.
ANSI Standards were released in 1983, 1988 and 1992 (ANSI X3.165-1992). The 1992 standard was revised in 2002.
DIBOL compilers were developed by several other companies, including DBL from DISC (later Synergex), Softbol from Omtool, and Unibol from Software Ireland, Ltd. Development of DIBOL effectively ceased after 1993, when an agreement between DEC and DISC replaced DIBOL with DBL on OpenVMS, Digital UNIX, and SCO Unix.

See also
Timeline of programming languages

References
Reading
American National Standards Institute; Computer and Business Equipment Manufacturers Association (CBEMA) (1988). American National Standard for Information Systems- Programming Language, DIBOL. New York, NY: American National Standards Institute. OCLC 23056850. {{cite book}}: |author2= has generic name (help)
American National Standards Institute; Computer and Business Equipment Manufacturers Association (CBEMA) (1992). American National Standard for Information Systems- Programming Language, DIBOL. New York, NY: American National Standards Institute. OCLC 27058852. {{cite book}}: |author2= has generic name (help)",598142,https://en.wikipedia.org/wiki/DIBOL
E (programming language),"E is an object-oriented programming language for secure distributed computing, created by Mark S. Miller, Dan Bornstein, Douglas Crockford, Chip Morningstar and others at Electric Communities in 1997. E is mainly descended from the concurrent language Joule and from Original-E, a set of extensions to Java for secure distributed programming. E combines message-based computation with Java-like syntax. A concurrency model based on event loops and promises ensures that deadlock can never occur.","E is an object-oriented programming language for secure distributed computing, created by Mark S. Miller, Dan Bornstein, Douglas Crockford, Chip Morningstar and others at Electric Communities in 1997. E is mainly descended from the concurrent language Joule and from Original-E, a set of extensions to Java for secure distributed programming. E combines message-based computation with Java-like syntax. A concurrency model based on event loops and promises ensures that deadlock can never occur.

Philosophy
The E language is designed for computer security and secure computing. This is performed mainly by strict adherence to the object-oriented computing model, which in its pure form, has properties that support secure computing. The E language and its standard library employ a capability-based design philosophy throughout in order to help programmers build secure software and to enable software components to co-operate even if they don't fully trust each other. In E, object references serve as capabilities, hence capabilities add no computational or conceptual overhead costs. The language syntax is designed to be easy for people to audit for security flaws. For example, lexical scoping limits the amount of code that must be examined for its effects on a given variable. As another example, the language uses the == operator for comparison and the := operator for assignment; to avoid the possibility of confusion, there is no = operator.

Computational model
In E, all values are objects and computation is performed by sending messages to objects. Each object belongs to a vat (analogous to a process). Each vat has a single thread of execution, a stack frame, and an event queue. Distributed programming is just a matter of sending messages to remote objects (objects in other vats). All communication with remote parties is encrypted by the E runtime. Arriving messages are placed into the vat's event queue; the vat's event loop processes the incoming messages one by one in order of arrival.
E has two ways to send messages: an immediate call and an eventual send. An immediate call is just like a typical function or method call in a non-concurrent language: a sender waits until a receiver finishes and returns a value. An eventual send sends a message while producing a placeholder for a result called a promise. A sender proceeds immediately with the promise. Later, when a receiver finishes and yields a result, the promise resolves to a result. Since only eventual sends are allowed when communicating with remote objects, deadlocks cannot happen. In distributed systems, the promise mechanism also minimizes delays caused by network latency.

Syntax and examples
E's syntax is most similar to Java, though it also bears some resemblance to Python and Pascal. Variables are dynamically typed and lexically scoped. Unlike Java or Python, however, E is composed entirely of expressions. Here is an extremely simple E program:

Here is a recursive function for computing the factorial of a number, written in E. Functions are defined using the def keyword.

In the first line, :int is a guard that constrains the argument and result of the function. A guard is not quite the same thing as a type declaration; guards are optional and can specify constraints. The first :int ensures that the body of the function will only have to handle an integer argument. Without the second :int above, the function would not be able to return a value. Being able to see up front that information escapes out of the function is helpful for security auditing.
Since E is intended to support secure co-operation, the canonical example for E programs is the mint, a simple electronic money system in just a few lines of E. The following code defines a function that makes mints, where each mint has its own currency. Each mint can make purses that hold its currency, and any holder of two purses of the same currency can securely transfer money between the purses. By quick examination of the source code, an E programmer can easily verify that only mints may change the amount of money in circulation, that money can only be created and not destroyed, that mints can only create money of their own currency, and that only the holder of a purse can change its balance.

Objects in E are defined with the def keyword, and within the object definition, the to keyword begins each method. The guard expressions in this example illustrate how to specify a value constraint (as in :(int >= 0) or :(0..balance)).
The mint example makes use of a built-in mechanism called a sealer. The function makeBrandPair creates two associated objects, a sealer and an unsealer, such that the sealer can seal an object in a box and the unsealer is the only object that can retrieve the contents of the box. See the E website for a more detailed explanation of this money example.

See also
Object-capability model

References
External links
Official website",1377046,https://en.wikipedia.org/wiki/E_(programming_language)
ELAN (programming language),"ELAN is an interpreted educational programming language for learning and teaching systematic programming.It was developed in 1974 by C.H.A. Koster and a group at the Technical University of Berlin as an alternative to BASIC in teaching, and approved for use in secondary schools in Germany by the ""Arbeitskreis Schulsprache"". It was in use until the late 1980s in a number of schools in Germany, Belgium, the Netherlands, and Hungary for informatics teaching in secondary education, and used at the Radboud University Nijmegen in the Netherlands for teaching systematic programming to students from various disciplines and in teacher courses.
The language design focuses strongly on structured programming, and has a special construction for stepwise refinement, allowing students to focus on top-down design, and bottom-up coding.
The microkernel operating system Eumel began as a runtime system (environment) for ELAN.","ELAN is an interpreted educational programming language for learning and teaching systematic programming.It was developed in 1974 by C.H.A. Koster and a group at the Technical University of Berlin as an alternative to BASIC in teaching, and approved for use in secondary schools in Germany by the ""Arbeitskreis Schulsprache"". It was in use until the late 1980s in a number of schools in Germany, Belgium, the Netherlands, and Hungary for informatics teaching in secondary education, and used at the Radboud University Nijmegen in the Netherlands for teaching systematic programming to students from various disciplines and in teacher courses.
The language design focuses strongly on structured programming, and has a special construction for stepwise refinement, allowing students to focus on top-down design, and bottom-up coding.
The microkernel operating system Eumel began as a runtime system (environment) for ELAN.

See also
ALGOL 68

References
External links
ELAN implementation built by the Radboud University Nijmegen
ELAN implementation download site
Dresden uni on ELAN",1179492,https://en.wikipedia.org/wiki/ELAN_(programming_language)
Elixir (programming language),"Elixir is a functional, concurrent, high-level general-purpose programming language that runs on the BEAM virtual machine, which is also used to implement the Erlang programming language. Elixir builds on top of Erlang and shares the same abstractions for building distributed, fault-tolerant applications. Elixir also provides tooling and an extensible design. The latter is supported by compile-time metaprogramming with macros and polymorphism via protocols.The community organizes yearly events in the United States, Europe, and Japan, as well as minor local events and conferences.","Elixir is a functional, concurrent, high-level general-purpose programming language that runs on the BEAM virtual machine, which is also used to implement the Erlang programming language. Elixir builds on top of Erlang and shares the same abstractions for building distributed, fault-tolerant applications. Elixir also provides tooling and an extensible design. The latter is supported by compile-time metaprogramming with macros and polymorphism via protocols.The community organizes yearly events in the United States, Europe, and Japan, as well as minor local events and conferences.

History
José Valim created the Elixir programming language as a research and development project at Plataformatec. His goals were to enable higher extensibility and productivity in the Erlang VM while maintaining compatibility with Erlang's ecosystem.Elixir is aimed at large-scale sites and apps. It uses features of Ruby, Erlang, and Clojure to develop a high-concurrency and low-latency language. It was designed to handle large data volumes. Elixir is also used in telecommunications, e-commerce, and finance.On July 12, 2018, Honeypot released a mini-documentary on Elixir.

Versioning
Each of the minor versions supports a specific range of Erlang/OTP versions. The current stable release version is 1.16.2 .

Features
Compiles to bytecode for the BEAM virtual machine of Erlang. Full interoperability with Erlang code, without runtime impact.
Scalability and fault-tolerance, thanks to Erlang's lightweight concurrency mechanisms
Built-in tooling for managing dependencies, code compilation, running tests, formatting code, remote debugging and more.
An interactive REPL inside running programs, including Phoenix web servers, with code reloading and access to internal state
Everything is an expression
Pattern matching to promote assertive code
Type hints for static analysis tools
Immutable data, with an emphasis, like other functional languages, on recursion and higher-order functions instead of side-effect-based looping
Shared nothing concurrent programming via message passing (actor model)
Lazy and async collections with streams
Railway oriented programming via the with construct
Hygienic metaprogramming by direct access to the abstract syntax tree (AST). Libraries often implement small domain-specific languages, such as for databases or testing.
Code execution at compile time. The Elixir compiler also runs on the BEAM, so modules that are being compiled can immediately run code which has already been compiled.
Polymorphism via a mechanism called protocols. Dynamic dispatch, as in Clojure, however, without multiple dispatch because Elixir protocols dispatch on a single type.
Support for documentation via Python-like docstrings in the Markdown formatting language
Unicode support and UTF-8 strings

Examples
The following examples can be run in an iex shell or saved in a file and run from the command line by typing elixir <filename>.
Classic Hello world example:

Pipe operator:

Pattern matching (a.k.a. destructuring):

Pattern matching with multiple clauses:

List comprehension:

Asynchronously reading files with streams:

Multiple function bodies with guards:

Relational databases with the Ecto library:

Sequentially spawning a thousand processes:

Asynchronously performing a task:

See also
Concurrent computing
Distributed computing
Parallel computing

References
Further reading
Simon St. Laurent; J. Eisenberg (December 22, 2016). Introducing Elixir: Getting Started in Functional Programming 2nd Edition. O'Reilly Media. ASIN B01N9KCTIC. ISBN 978-1491956779.
Sasa Juric (January 12, 2019). Elixir in Action 2nd Edition. Manning Publications. ASIN B0978KZTJG. ISBN 978-1617295027.",38202780,https://en.wikipedia.org/wiki/Elixir_(programming_language)
Erlang (programming language),"Erlang ( UR-lang) is a general-purpose, concurrent, functional high-level programming language, and a garbage-collected runtime system. The term Erlang is used interchangeably with Erlang/OTP, or Open Telecom Platform (OTP), which consists of the Erlang runtime system, several ready-to-use components (OTP) mainly written in Erlang, and a set of design principles for Erlang programs.The Erlang runtime system is designed for systems with these traits:

Distributed
Fault-tolerant
Soft real-time
Highly available, non-stop applications
Hot swapping, where code can be changed without stopping a system.The Erlang programming language has immutable data, pattern matching, and functional programming. The sequential subset of the Erlang language supports eager evaluation, single assignment, and dynamic typing.
A normal Erlang application is built out of hundreds of small Erlang processes.
It was originally proprietary software within Ericsson, developed by Joe Armstrong, Robert Virding, and Mike Williams in 1986, but was released as free and open-source software in 1998. Erlang/OTP is supported and maintained by the Open Telecom Platform (OTP) product unit at Ericsson.","Erlang ( UR-lang) is a general-purpose, concurrent, functional high-level programming language, and a garbage-collected runtime system. The term Erlang is used interchangeably with Erlang/OTP, or Open Telecom Platform (OTP), which consists of the Erlang runtime system, several ready-to-use components (OTP) mainly written in Erlang, and a set of design principles for Erlang programs.The Erlang runtime system is designed for systems with these traits:

Distributed
Fault-tolerant
Soft real-time
Highly available, non-stop applications
Hot swapping, where code can be changed without stopping a system.The Erlang programming language has immutable data, pattern matching, and functional programming. The sequential subset of the Erlang language supports eager evaluation, single assignment, and dynamic typing.
A normal Erlang application is built out of hundreds of small Erlang processes.
It was originally proprietary software within Ericsson, developed by Joe Armstrong, Robert Virding, and Mike Williams in 1986, but was released as free and open-source software in 1998. Erlang/OTP is supported and maintained by the Open Telecom Platform (OTP) product unit at Ericsson.

History
The name Erlang, attributed to Bjarne Däcker, has been presumed by those working on the telephony switches (for whom the language was designed) to be a reference to Danish mathematician and engineer Agner Krarup Erlang and a syllabic abbreviation of ""Ericsson Language"". Erlang was designed with the aim of improving the development of telephony applications. The initial version of Erlang was implemented in Prolog and was influenced by the programming language PLEX used in earlier Ericsson exchanges. By 1988 Erlang had proven that it was suitable for prototyping telephone exchanges, but the Prolog interpreter was far too slow. One group within Ericsson estimated that it would need to be 40 times faster to be suitable for production use. In 1992, work began on the BEAM virtual machine (VM) which compiles Erlang to C using a mix of natively compiled code and threaded code to strike a balance between performance and disk space. According to co-inventor Joe Armstrong, the language went from lab product to real applications following the collapse of the next-generation AXE telephone exchange named AXE-N in 1995. As a result, Erlang was chosen for the next Asynchronous Transfer Mode (ATM) exchange AXD.
In February 1998, Ericsson Radio Systems banned the in-house use of Erlang for new products, citing a preference for non-proprietary languages. The ban caused Armstrong and others to make plans to leave Ericsson. In March 1998 Ericsson announced the AXD301 switch, containing over a million lines of Erlang and reported to achieve a high availability of nine ""9""s. In December 1998, the implementation of Erlang was open-sourced and most of the Erlang team resigned to form a new company Bluetail AB. Ericsson eventually relaxed the ban and re-hired Armstrong in 2004.In 2006, native symmetric multiprocessing support was added to the runtime system and VM.

Processes
Erlang applications are built of very lightweight Erlang processes in the Erlang runtime system. Erlang processes can be seen as ""living"" objects (object-oriented programming), with data encapsulation and message passing, but capable of changing behavior during runtime. The Erlang runtime system provides strict process isolation between Erlang processes (this includes data and garbage collection, separated individually by each Erlang process) and transparent communication between processes (see Location transparency) on different Erlang nodes (on different hosts).
Joe Armstrong, co-inventor of Erlang, summarized the principles of processes in his PhD thesis:
Everything is a process.
Processes are strongly isolated.
Process creation and destruction is a lightweight operation.
Message passing is the only way for processes to interact.
Processes have unique names.
If you know the name of a process you can send it a message.
Processes share no resources.
Error handling is non-local.
Processes do what they are supposed to do or fail.Joe Armstrong remarked in an interview with Rackspace in 2013: ""If Java is 'write once, run anywhere', then Erlang is 'write once, run forever'.""

Usage
In 2014, Ericsson reported Erlang was being used in its support nodes, and in GPRS, 3G and LTE mobile networks worldwide and also by Nortel and T-Mobile.Erlang is used in RabbitMQ. As Tim Bray, director of Web Technologies at Sun Microsystems, expressed in his keynote at O'Reilly Open Source Convention (OSCON) in July 2008:

If somebody came to me and wanted to pay me a lot of money to build a large scale message handling system that really had to be up all the time, could never afford to go down for years at a time, I would unhesitatingly choose Erlang to build it in.
Erlang is the programming language used to code WhatsApp.It is also the language of choice for Ejabberd – an XMPP messaging server.
Elixir is a programming language that compiles into BEAM byte code (via Erlang Abstract Format).Since being released as open source, Erlang has been spreading beyond telecoms, establishing itself in other vertical markets such as FinTech, gaming, healthcare, automotive, internet of things and blockchain. Apart from WhatsApp, there are other companies listed as Erlang's success stories: Vocalink (a MasterCard company), Goldman Sachs, Nintendo, AdRoll, Grindr, BT Mobile, Samsung, OpenX, and SITA.

Functional programming examples
Factorial
A factorial algorithm implemented in Erlang:

Fibonacci sequence
A tail recursive algorithm that produces the Fibonacci sequence:

Here is the same program without the explanatory comments:

Quicksort
Quicksort in Erlang, using list comprehension:

The above example recursively invokes the function qsort until nothing remains to be sorted. The expression [Front || Front <- Rest, Front < Pivot] is a list comprehension, meaning ""Construct a list of elements Front such that Front is a member of Rest, and Front is less than Pivot."" ++ is the list concatenation operator.
A comparison function can be used for more complicated structures for the sake of readability.
The following code would sort lists according to length:

A Pivot is taken from the first parameter given to qsort() and the rest of Lists is named Rest. Note that the expression

is no different in form from

(in the previous example) except for the use of a comparison function in the last part, saying ""Construct a list of elements X such that X is a member of Rest, and Smaller is true"", with Smaller being defined earlier as

The anonymous function is named Smaller in the parameter list of the second definition of qsort so that it can be referenced by that name within that function. It is not named in the first definition of qsort, which deals with the base case of an empty list and thus has no need of this function, let alone a name for it.

Data types
Erlang has eight primitive data types:

Integers
Integers are written as sequences of decimal digits, for example, 12, 12375 and -23427 are integers. Integer arithmetic is exact and only limited by available memory on the machine. (This is called arbitrary-precision arithmetic.)
Atoms
Atoms are used within a program to denote distinguished values. They are written as strings of consecutive alphanumeric characters, the first character being lowercase. Atoms can contain any character if they are enclosed within single quotes and an escape convention exists which allows any character to be used within an atom. Atoms are never garbage collected and should be used with caution, especially if using dynamic atom generation.
Floats
Floating point numbers use the IEEE 754 64-bit representation.
References
References are globally unique symbols whose only property is that they can be compared for equality. They are created by evaluating the Erlang primitive make_ref().
Binaries
A binary is a sequence of bytes. Binaries provide a space-efficient way of storing binary data. Erlang primitives exist for composing and decomposing binaries and for efficient input/output of binaries.
Pids
Pid is short for process identifier – a Pid is created by the Erlang primitive spawn(...) Pids are references to Erlang processes.
Ports
Ports are used to communicate with the external world. Ports are created with the built-in function open_port. Messages can be sent to and received from ports, but these messages must obey the so-called ""port protocol.""
Funs
Funs are function closures. Funs are created by expressions of the form: fun(...) -> ... end.And three compound data types:

Tuples
Tuples are containers for a fixed number of Erlang data types. The syntax {D1,D2,...,Dn} denotes a tuple whose arguments are D1, D2, ... Dn. The arguments can be primitive data types or compound data types. Any element of a tuple can be accessed in constant time.
Lists
Lists are containers for a variable number of Erlang data types. The syntax [Dh|Dt] denotes a list whose first element is Dh, and whose remaining elements are the list Dt. The syntax [] denotes an empty list. The syntax [D1,D2,..,Dn] is short for [D1|[D2|..|[Dn|[]]]]. The first element of a list can be accessed in constant time. The first element of a list is called the head of the list. The remainder of a list when its head has been removed is called the tail of the list.
Maps
Maps contain a variable number of key-value associations. The syntax is#{Key1=>Value1,...,KeyN=>ValueN}.Two forms of syntactic sugar are provided:

Strings
Strings are written as doubly quoted lists of characters. This is syntactic sugar for a list of the integer Unicode code points for the characters in the string. Thus, for example, the string ""cat"" is shorthand for [99,97,116].
Records
Records provide a convenient way for associating a tag with each of the elements in a tuple. This allows one to refer to an element of a tuple by name and not by position. A pre-compiler takes the record definition and replaces it with the appropriate tuple reference.Erlang has no method to define classes, although there are external libraries available.

""Let it crash"" coding style
Erlang is designed with a mechanism that makes it easy for external processes to monitor for crashes (or hardware failures), rather than an in-process mechanism like exception handling used in many other programming languages. Crashes are reported like other messages, which is the only way processes can communicate with each other, and subprocesses can be spawned cheaply (see below). The ""let it crash"" philosophy prefers that a process be completely restarted rather than trying to recover from a serious failure. Though it still requires handling of errors, this philosophy results in less code devoted to defensive programming where error-handling code is highly contextual and specific.

Supervisor trees
A typical Erlang application is written in the form of a supervisor tree.  This architecture is based on a hierarchy of processes in which the top level process is known as a ""supervisor"".  The supervisor then spawns multiple child processes that act either as workers or more, lower level supervisors.  Such hierarchies can exist to arbitrary depths and have proven to provide a highly scalable and fault-tolerant environment within which application functionality can be implemented.
Within a supervisor tree, all supervisor processes are responsible for managing the lifecycle of their child processes, and this includes handling situations in which those child processes crash.  Any process can become a supervisor by first spawning a child process, then calling erlang:monitor/2 on that process.  If the monitored process then crashes, the supervisor will receive a message containing a tuple whose first member is the atom 'DOWN'.  The supervisor is responsible firstly for listening for such messages and secondly, for taking the appropriate action to correct the error condition.

Concurrency and distribution orientation
Erlang's main strength is support for concurrency. It has a small but powerful set of primitives to create processes and communicate among them. Erlang is conceptually similar to the language occam, though it recasts the ideas of communicating sequential processes (CSP) in a functional framework and uses asynchronous message passing. Processes are the primary means to structure an Erlang application. They are neither operating system processes nor threads, but lightweight processes that are scheduled by BEAM. Like operating system processes (but unlike operating system threads), they share no state with each other. The estimated minimal overhead for each is 300 words. Thus, many processes can be created without degrading performance. In 2005, a benchmark with 20 million processes was successfully performed with 64-bit Erlang on a machine with 16 GB random-access memory (RAM; total 800 bytes/process). Erlang has supported symmetric multiprocessing since release R11B of May 2006.
While threads need external library support in most languages, Erlang provides language-level features to create and manage processes with the goal of simplifying concurrent programming. Though all concurrency is explicit in Erlang, processes communicate using message passing instead of shared variables, which removes the need for explicit locks (a locking scheme is still used internally by the VM).Inter-process communication works via a shared-nothing asynchronous message passing system: every process has a ""mailbox"", a queue of messages that have been sent by other processes and not yet consumed. A process uses the receive primitive to retrieve messages that match desired patterns. A message-handling routine tests messages in turn against each pattern, until one of them matches. When the message is consumed and removed from the mailbox the process resumes execution. A message may comprise any Erlang structure, including primitives (integers, floats, characters, atoms), tuples, lists, and functions.
The code example below shows the built-in support for distributed processes:

As the example shows, processes may be created on remote nodes, and communication with them is transparent in the sense that communication with remote processes works exactly as communication with local processes.
Concurrency supports the primary method of error-handling in Erlang. When a process crashes, it neatly exits and sends a message to the controlling process which can then take action, such as starting a new process that takes over the old process's task.

Implementation
The official reference implementation of Erlang uses BEAM. BEAM is included in the official distribution of Erlang, called Erlang/OTP. BEAM executes bytecode which is converted to threaded code at load time. It also includes a native code compiler on most platforms, developed by the High Performance Erlang Project (HiPE) at Uppsala University. Since October 2001 the HiPE system is fully integrated in Ericsson's Open Source Erlang/OTP system. It also supports interpreting, directly from source code via abstract syntax tree, via script as of R11B-5 release of Erlang.

Hot code loading and modules
Erlang supports language-level Dynamic Software Updating. To implement this, code is loaded and managed as ""module"" units; the module is a compilation unit. The system can keep two versions of a module in memory at the same time, and processes can concurrently run code from each. The versions are referred to as the ""new"" and the ""old"" version. A process will not move into the new version until it makes an external call to its module.
An example of the mechanism of hot code loading:

For the second version, we add the possibility to reset the count to zero.

Only when receiving a message consisting of the atom code_switch will the loop execute an external call to codeswitch/1 (?MODULE is a preprocessor macro for the current module). If there is a new version of the counter module in memory, then its codeswitch/1 function will be called. The practice of having a specific entry-point into a new version allows the programmer to transform state to what is needed in the newer version. In the example, the state is kept as an integer.
In practice, systems are built up using design principles from the Open Telecom Platform, which leads to more code upgradable designs. Successful hot code loading is exacting. Code must be written with care to make use of Erlang's facilities.

Distribution
In 1998, Ericsson released Erlang as free and open-source software to ensure its independence from a single vendor and to increase awareness of the language. Erlang, together with libraries and the real-time distributed database Mnesia, forms the OTP collection of libraries. Ericsson and a few other companies support Erlang commercially.
Since the open source release, Erlang has been used by several firms worldwide, including Nortel and T-Mobile. Although Erlang was designed to fill a niche and has remained an obscure language for most of its existence, its popularity is growing due to demand for concurrent services.
Erlang has found some use in fielding massively multiplayer online role-playing game (MMORPG) servers.

See also
Elixir – a functional, concurrent, general-purpose programming language that runs on BEAM
Luerl - Lua on the BEAM, designed and implemented by one of the creators of Erlang.
Lisp Flavored Erlang (LFE) – a Lisp-based programming language that runs on BEAM
Mix (build tool)
Phoenix (web framework)

References
Further reading
External links

Official website",9646,https://en.wikipedia.org/wiki/Erlang_(programming_language)
EXAPT,"EXAPT (a portmanteau of ""Extended Subset of APT"") is a production-oriented programming language that allows users to generate NC programs with control information for machining tools and facilitates decision-making for production-related issues that may arise during various machining processes.
EXAPT was first developed to address industrial requirements. Through the years, the company created additional software for the manufacturing industry. Today, EXAPT offers a suite of SAAS products and services for the manufacturing industry.
The trade name, EXAPT, is most commonly associated with the CAD/CAM-System, production data, and tool management software of the German company EXAPT Systemtechnik GmbH based in Aachen, DE.","EXAPT (a portmanteau of ""Extended Subset of APT"") is a production-oriented programming language that allows users to generate NC programs with control information for machining tools and facilitates decision-making for production-related issues that may arise during various machining processes.
EXAPT was first developed to address industrial requirements. Through the years, the company created additional software for the manufacturing industry. Today, EXAPT offers a suite of SAAS products and services for the manufacturing industry.
The trade name, EXAPT, is most commonly associated with the CAD/CAM-System, production data, and tool management software of the German company EXAPT Systemtechnik GmbH based in Aachen, DE.

General
EXAPT is a modularly built programming system for all NC machining operations  as

Drilling
Turning
Milling
Turn-Milling
Nibbling
Flame-, laser-, plasma- and water jet cutting
Wire eroding
Operations with industrial robotsDue to the modular structure, the main product groups, EXAPTcam and EXAPTpdo, are gradually expandable and permit individual software for the manufacturing industry used individually and also in compound with an existing IT environment.

Functionality
EXAPTcam meets the requirements for NC planning, especially for the cutting operations such as turning, drilling, and milling up to 5-axis simultaneous machining. Thereby new process technologies, tool, and machine concepts are constantly involved. In the NC programming data from different sources such as 3D CAD models, drawings or tables can flow in. The possibilities of NC programming reaches from the language-oriented to the feature-oriented NC programming. The integrated EXAPT knowledge database and intelligent and scalable automatisms support the user. The EXAPT NC planning also covers the generation of production information as clamping and tool plans, presetting data or time calculations. The realistic simulation possibilities of NC planning and NC control data provide with production reliability.
EXAPTpdo (EXAPT ProductionsDataOrganization) provides a neutrally applicable technology platform for the information compound of the NC planning - to the shop floor. This applies to all NC production data which are necessary for the set-up of NC machines, for the provision, presetting and stocking of manufacturing resources and provided by EXAPTpdo in a central database. Beside classical functions of the tool management system (TMS) as the management of cutting tools, measuring, testing and clamping devices the technology data management and tool lifecycle management (TLM) is also included. System-supported ""where-used lists"" helps to handle the manufacturing resource cycle by secured requirement determination and requirement fulfillment. Unnecessary transports and unplanned dispositive adjustments are dropped, stocks are reduced, set-up times reduced and the throughput is increased. EXAPTpdo synchronizes involved systems within the value chain. Stock systems, MES systems or ERP systems (e.g. from the purchasing or production areas) do not work in isolation from each other but they interact with each other. EXAPTpdo provides the base to Smart Factory, for more flexibility in production and a faster communication.

History
With the foundation of the EXAPT-Verein in 1967 as spin-off of the universities Aachen, Berlin and Stuttgart the further development ""EXAPT (EXtended Subset of APT)"" of the programming language ""APT (Automatically Programmed Tool)"" was focused and so the first milestone for the EXAPT history was set.
In the same year the system EXAPT 1 for drilling and simple milling tasks became available.
1969 The industrial application of EXAPT 2 for the programming of NC machines with 2-axis linear and path control begins. In the following year, the development of the EXAPT modular system starts.
1972 BASIC-EXAPT is provided for the universal, homogeneous programming of all NC tasks. The support is made by the EXAPT applications consultancy.
1973 EXAPT 1.1 is provided for the programming of straight-cut and continuous-path controlled drilling and milling machines and machining centres. At the Hanover Fair (IHA 73) the interactive access to a mainframe via a time-sharing terminal for the part program entry and correction is presented and starts the replacement of the punch card.
1974 The possibilities for the use of process computers for the NC data transfer are levelled out. EXAPT offers the possibility of the result simulation when using plotters with display of tool paths and tools in assignment to the workpiece.
In April 1975, the EXAPT NC Systemtechnik GmbH was founded with the aim, of enabling entry into the NC technique for small and medium-sized companies by a complete product and service program. In the following year, the system portfolio is extended with further system modules and service programs and the provision of postprocessors.
1978 The development activities on the EXAPT module system started in 1970 are completed. Using modern software techniques, the different system parts BASIC-EXAPT, EXAPT 1, EXAPT 1.1 and EXAPT 2 are composed of a total system. System support and applications consultancy become a new working focus.
From the beginning to the middle of the 1980s Beside new portable software modules for CAD/CAM applications (e. g. CAPEX, NESTEX, CADEX, CADCPL), the first version of the EXAPT DNC system and extensions of the EXAPT NC programming system for the machining of sculptured surfaces are presented.
1988 EXAPT expands the software product range by systems for the tool data management (BMO) and production data management (FDO). EXAPT trains more than 1,300 course participants including company-specific courses.
1992 The first version of the completely new product generation EXAPTplus is presented and the agency in Dresden is opened.
1993 The company name ""EXAPT NC Systemtechnik GmbH"" is changed to ""EXAPT Systemtechnik GmbH."" EXAPTplus is presented on PC under Windows NT at the EMO '93. The decentralization of the use of EXAPT systems expands the range of application. In the following year, EXAPT-DNC is executable under Windows on a customary PC. Special hardware is not needed and so it can be used in compound with the database-supported EXAPT production data management system (FDO).
1995 EXAPTplus is also ready for complex application cases as machining of tubes at extrusion tools. EXAPT-CADI provides the transfer of 2D CAD data to EXAPTplus. With the new office Gießen the marketing is strengthened. In the following year the EXAPT NC editor is developed for the direct processing of NC control data with tool path display and visualization of the tools.
In the course of the market entry of more comfortable 3D CAD systems for the solid modelling of components a detailed evaluation of current systems is made in 1997. It is decided to use SolidWorks as reference system for the solid oriented NC planning with EXAPT.
1998 The first solution for the transfer of geometry data between SolidWorks and EXAPTplus is generated. The EXAPT organization systems are (beside SQL) also executable under Oracle now. The use of client server solutions supports the data flow in the production.
1999 AFR functions are provided in connection with EXAPTsolid to support a workpiece modelling for NC. The millennium capability is ensured for all EXAPT systems. AFR is a ground-breaking for the integration of third-party products.
2002 EXAPT-BMG is developed for the generation and visualization of tools with additional functions for the assembly from components. The acquisition of tools with their geometric and technological presentation offers extensive support of the NC planning with EXAPT systems.
2003 EXAPTpdo is available to optimize the process chains in production planning and production execution optimally regarding the increasing requirements of changing production conditions.
2004 Diverse system extensions are made in EXAPTplus, EXAPTsolid, EXAPT NC editor, EXAPTpdo for the complete machining on turning/milling centres with result reliability because of more extensive simulation based on realNC (Tecnomatix), for the use of new complex tool systems and for the compound use between ERP systems as SAP and intelligent CNC systems. In the following year, EXAPTpdo is extended for the cross-order set-up optimization and provision of manufacturing re-sources especially for single and small series production with connection to purchase and physical portfolio management.
2006 The EXAPT systems are available in the extended use as information platform for the production, the time management, and similar requirements. EXAPTsolid is extended for the feature-oriented milling operation and machine simulation. The NC programming of complex machine tools, e.g. three-turret-turning/milling centres is supported by EXAPT systems, as well as the use of multi-functional tools.
2007 A module for 3-5-axis simultaneous milling machining is presented.


== References ==",51684378,https://en.wikipedia.org/wiki/EXAPT
F (programming language),"F is a modular, compiled, numeric programming language, designed for scientific programming and scientific computation. F was developed as a modern Fortran, thus making it a subset of Fortran 95. It combines both numerical and data abstraction features from these languages. F is also backwards compatible with Fortran 77, allowing calls to Fortran 77 programs. F was implemented on top of compilers from NAG, Fujitsu, Salford Software and Absoft. It was later included in the g95 compiler.","F is a modular, compiled, numeric programming language, designed for scientific programming and scientific computation. F was developed as a modern Fortran, thus making it a subset of Fortran 95. It combines both numerical and data abstraction features from these languages. F is also backwards compatible with Fortran 77, allowing calls to Fortran 77 programs. F was implemented on top of compilers from NAG, Fujitsu, Salford Software and Absoft. It was later included in the g95 compiler.

Overview
F is designed to be a minimal subset of Fortran, with only about one hundred intrinsic procedures. Language keywords and intrinsic function names are reserved keywords in F and no other names may take this exact form. F contains the same character set used in Fortran 90/95 with a limit of 132 characters. Reserved words are always written in lowercase. Any uppercase letter may appear in a character constant. Variable names do not have restriction and can include upper and lowercase characters.

Operators
F supports many of the standard operators used in Fortran. The operators supported by F are: 

Arithmetic operators: +, -, *, /, **
Relational operators: <, <=, ==, /=, >, >=
Logical operators: .not., .and., .or., .eqv., .neqv.
character concatenation: //The assignment operator is denoted by the equal sign =. In addition, pointer assignment is denoted by =>. Comments are denoted by the ! symbol:

Data types
Similar to Fortran, the type specification is made up of a type, a list of attributes for the declared variables, and the variable list. F provides the same types as Fortran, except that double precision floating point variables must be declared as real with a kind with a kind parameter:

F does not have intrinsic support for object-oriented programming, but it does allow for records:

Variable declarations are followed by an attribute list. The attributes allowed are parameter, public, private, allocatable, dimension, intent, optional, pointer, save and target. The attribute list is followed by ::, which is part of the syntax. F also allows for optional initialization in the list of objects. All items in a list will have the same attributes in a given type declaration statement. In addition, declarations are attribute oriented instead of entity oriented.

Statement and control flow
F supports 3 statements for control flow: if, a basic conditional, case, a switch statement, and do, a conditional while loop. The return, stop, cycle, and exit statements from Fortran may be used to break control flow.

F places a heavy emphasis on modular programming.

Placing procedures  outside of a module is prohibited. F supports most of the functions and subroutines found in the Fortran 95 standard library. All functions in F are external by default and require a result clause that returns the value of a function. F supports recursion.
All of the intrinsic procedures found in Fortran 95 may be used in F, with the exceptions of achar, iachar, lge, lgt, lle, llt, transfer, dble, dim, dprod, and mod.

References
Bibliography
Walter S. Brainerd, Charles H. Goldberg, and Jeanne C. Adams: ""Programmer's Guide to F"", Unicomp, 1996.
Michael Metcalf and John Reid: ""The F Programming Language"", Oxford University Press, Oxford and New York, 1996.
Gehrke, Wihelm (1997-05-30). The F Language Guide. Springer. ISBN 978-3-540-76165-5.
Robin A. Vowels: ""Algorithms and Data Structures in F and Fortran"", Unicomp.
Loren Meissner: ""Essential Fortran 90 & 95"", Unicomp, 1997.

External links
F Programming Language Homepage Archived 2015-01-09 at the Wayback Machine
g95 compiler Archived 2013-06-05 at the Wayback Machine",1283488,https://en.wikipedia.org/wiki/F_(programming_language)
Factor (programming language),"Factor is a stack-oriented programming language created by Slava Pestov. Factor is dynamically typed and has automatic memory management, as well as powerful metaprogramming features. The language has a single implementation featuring a self-hosted optimizing compiler and an interactive development environment. The Factor distribution includes a large standard library.","Factor is a stack-oriented programming language created by Slava Pestov. Factor is dynamically typed and has automatic memory management, as well as powerful metaprogramming features. The language has a single implementation featuring a self-hosted optimizing compiler and an interactive development environment. The Factor distribution includes a large standard library.

History
Slava Pestov created Factor in 2003 as a scripting language for a video game. The initial implementation, now referred to as JFactor, was implemented in Java and ran on the Java Virtual Machine. Though the early language resembled modern Factor superficially in terms of syntax, the modern language is very different in practical terms and the current implementation is much faster.
The language has changed significantly over time. Originally, Factor programs centered on manipulating Java objects with Java's reflection capabilities. From the beginning, the design philosophy has been to modify the language to suit programs written in it. As the Factor implementation and standard libraries grew more detailed, the need for certain language features became clear, and they were added. JFactor did not have an object system where the programmer could define their own classes, and early versions of native Factor were the same; the language was similar to Scheme in this way. Today, the object system is a central part of Factor. Other important language features such as tuple classes, combinator inlining, macros, user-defined parsing words and the modern vocabulary system were only added in a piecemeal fashion as their utility became clear.
The foreign function interface was present from very early versions to Factor, and an analogous system existed in JFactor. This was chosen over creating a plugin to the C part of the implementation for each external library that Factor should communicate with, and has the benefit of being more declarative, faster to compile and easier to write.
The Java implementation initially consisted of just an interpreter, but a compiler to Java bytecode was later added. This compiler only worked on certain procedures. The Java version of Factor was replaced by a version written in C and Factor. Initially, this consisted of just an interpreter, but the interpreter was replaced by two compilers, used in different situations. Over time, the Factor implementation has grown significantly faster.

Description
Factor is a dynamically typed, functional and object-oriented programming language. Code is structured around small procedures, called words. In typical code, these are 1–3 lines long, and a procedure more than 7 lines long is very rare. Something that would idiomatically be expressed with one procedure in another programming language would be written as several words in Factor.Each word takes a fixed number of arguments and has a fixed number of return values. Arguments to words are passed on a data stack, using reverse Polish notation. The stack is used just to organize calls to words, and not as a data structure. The stack in Factor is used in a similar way to the stack in Forth; for this, they are both considered stack languages. For example, below is a snippet of code that prints out ""hello world"" to the current output stream:

""hello world"" print

print is a word in the io vocabulary that takes a string from the stack and returns nothing.  It prints the string to the current output stream (by default, the terminal or the graphical listener).The factorial function n!{\displaystyle n!} can be implemented in Factor in the following way:

Not all data has to be passed around only with the stack. Lexically scoped local variables let one store and access temporaries used within a procedure. Dynamically scoped variables are used to pass things between procedure calls without using the stack. For example, the current input and output streams are stored in dynamically scoped variables.Factor emphasizes flexibility and the ability to extend the language.  There is a system for macros, as well as for arbitrary extension of Factor syntax. Factor's syntax is often extended to allow for new types of word definitions and new types of literals for data structures.  It is also used in the XML library to provide literal syntax for generating XML.  For example, the following word takes a string and produces an XML document object which is an HTML document emphasizing the string:

The word dup duplicates the top item on the stack. The <-> stands for filling in that part of the XML document with an item from the stack.

Implementation and libraries
Factor includes a large standard library, written entirely in the language. These include

A cross-platform GUI toolkit, built on top of OpenGL and various windowing systems, used for the development environment.
Bindings to several database libraries, including PostgreSQL and SQLite.
An HTTP server and client, with the Furnace web framework.
Efficient homogeneous arrays of integers, floats and C structs.
A library implementing regular expressions, generating machine code to do the matching.A foreign function interface is built into Factor, allowing for communication with C, Objective-C and Fortran programs. There is also support for executing and communicating with shaders written in GLSL.Factor is implemented in Factor and C++. It was originally bootstrapped from an earlier Java implementation. Today, the parser and the optimizing compiler are written in the language. Certain basic parts of the language are implemented in C++ such as the garbage collector and certain primitives.
Factor uses an image-based model, analogous to many Smalltalk implementations, where compiled code and data are stored in an image.  To compile a program, the program is loaded into an image and the image is saved. A special tool assists in the process of creating a minimal image to run a particular program, packaging the result into something that can be deployed as a standalone application.The Factor compiler implements many advanced optimizations and has been used as a target for research in new optimization techniques.

References
External links
Official website
Slava Pestov (October 27, 2008). Factor: An Extensible Interactive Language (flv) (Tech talk). Google. Archived from the original on 2021-12-22.
Zed Shaw (2008). The ACL is Dead (flv) (CUSEC 2008). CUSEC. – a presentation written in Factor which mentions and praises Factor",891398,https://en.wikipedia.org/wiki/Factor_(programming_language)
Flow chart language,"Flow chart language (FCL) is a simple imperative programming language designed for the purposes of explaining fundamental concepts of program analysis and specialization, in particular, partial evaluation. The language was first presented in 1989 by Carsten K. Gomard and Neil D. Jones. It later resurfaced in their book with Peter Sestoft in 1993, and in John Hatcliff's lecture notes in 1998. The below describes FCL as it appeared in John Hatcliff's lecture notes.
FCL is an imperative programming language close to the way a Von Neumann computer executes a program. A program is executed sequentially by following a sequence of commands, while maintaining an implicit state, i.e. the global memory. FCL has no concept of procedures, but does provide conditional and unconditional jumps. FCL lives up to its name as the abstract call-graph of an FCL program is a straightforward flow chart.
An FCL program takes as input a finite series of named values as parameters, and produces a value as a result.","Flow chart language (FCL) is a simple imperative programming language designed for the purposes of explaining fundamental concepts of program analysis and specialization, in particular, partial evaluation. The language was first presented in 1989 by Carsten K. Gomard and Neil D. Jones. It later resurfaced in their book with Peter Sestoft in 1993, and in John Hatcliff's lecture notes in 1998. The below describes FCL as it appeared in John Hatcliff's lecture notes.
FCL is an imperative programming language close to the way a Von Neumann computer executes a program. A program is executed sequentially by following a sequence of commands, while maintaining an implicit state, i.e. the global memory. FCL has no concept of procedures, but does provide conditional and unconditional jumps. FCL lives up to its name as the abstract call-graph of an FCL program is a straightforward flow chart.
An FCL program takes as input a finite series of named values as parameters, and produces a value as a result.

Syntax
We specify the syntax of FCL using Backus–Naur form.
An FCL program is a list of formal parameter declarations, an entry label, and a sequence of basic blocks:

Initially, the language only allows non-negative integer variables.
A basic block consists of a label, a list of assignments, and a jump.

An assignment assigns a variable to an expression. An expression is either a constant, a variable, or application of a built-in n-ary operator:

Note, variable names occurring throughout the program need not be declared at the top of the program. The variables declared at the top of the program designate arguments to the program.
As values can only be non-negative integers, so can constants. The list of operations in general is irrelevant, so long as they have no side effects, which includes exceptions, e.g. division by 0:

Where =, <, ... have semantics as in C. The semantics of - is such that if x-y<0, then x-y=0.

Example
We write a program that computes the nth Fibonacci number, for n>2:

(n)
(init)

init: x1 = 1
      x2 = 1

fib:  x1 = x1 + x2

      t = x1
      x1 = x2
      x2 = t

      n = -(n 1)

      if >(n 2) then fib else exit

exit: return x2

Where the loop invariant of fib is that x1 is the (i+2-1)th and x2 is the (i+2)th Fibonacci number, where i is the number of times fib has been jumped to.
We can check the correctness of the method for n=4 by presenting the execution trace of the program:
(init, [n↦4, x1↦0, x2↦0, t↦0])→(fib, [n↦4, x1↦1, x2↦1, t↦0])→(fib, [n↦3, x1↦1, x2↦2, t↦0])→(⟨halt, 3⟩, [n↦2, x1↦2, x2↦3, t↦0]){\displaystyle {\begin{aligned}&\left({\mathtt {init}},\ \left[n\mapsto 4,\ x1\mapsto 0,\ x2\mapsto 0,\ t\mapsto 0\right]\right)\\\rightarrow &\left({\mathtt {fib}},\ \left[n\mapsto 4,\ x1\mapsto 1,\ x2\mapsto 1,\ t\mapsto 0\right]\right)\\\rightarrow &\left({\mathtt {fib}},\ \left[n\mapsto 3,\ x1\mapsto 1,\ x2\mapsto 2,\ t\mapsto 0\right]\right)\\\rightarrow &\left(\left\langle {\mathtt {halt}},\ 3\right\rangle ,\ \left[n\mapsto 2,\ x1\mapsto 2,\ x2\mapsto 3,\ t\mapsto 0\right]\right)\end{aligned}}}
Where ⟨halt, v⟩{\displaystyle \left\langle {\mathtt {halt}},\ v\right\rangle } marks a final state of the program, with the return value v{\displaystyle v}.

Variants
Reversible flow chart language
Reversible flow chart language (RL) is a simple reversible imperative programming language designed for reversible computing, where each computational process is reversible. RL combines step, test, and assertion in a way that ensures the reversibility of the programs.
RL emphasizes the construction of reversible programs that permit deterministic backward computation, ensuring that no information is lost during processing. This characteristic makes it distinct from traditional flow chart languages, which usually involve irreversible operations. The syntax and example programs for RL would closely resemble traditional flow chart languages but with added constraints to ensure reversibility. These include reversible loops, reversible conditional, and invertibility of atomic computation steps. 
Due to the reversibility constraint, RL has less computational power than conventional Turing machines but is equivalent to reversible Turing machines (RTMs), laying the foundation for reversible programming. The reversible variant of the structured program theorem, for instance, can be effectively analyzed using RL, showcasing its significance in the theoretical bases of reversible computing.
There is also a structured variant of RL (SRL: structured reversible flow chart language) that combines sequence, selection, and iteration in a way that ensures the reversibility of the programs.


== References ==",39690826,https://en.wikipedia.org/wiki/Flow_chart_language
Flowcode,"Flowcode is a Microsoft Windows-based development environment commercially produced by Matrix TSL for programming embedded devices based on PIC, AVR (including Arduino), ESP32, Raspberry Pi and RP2040 and ARM technologies using graphical programming styles (such as flowcharts) and imperative programming styles (through C, State Machines and Pseudocode). It is currently in its tenth revision.
Flowcode is dedicated to simplifying complex functionality such as Bluetooth, Mobile Phones Communications, USB communications etc. by using pre-developed dedicated open source component libraries of functions. This is achieved by dragging virtual representations of hardware onto a visual panel, providing access to associated libraries. Flowcode is therefore ideal for speeding up software development times and allowing those with little programming experience to get started and help with projects. This makes it appropriate for the formal teaching of principles of programming microcontrollers.Flowcode allows the user to develop and view their program using four different visual modes. These are the Flowchart view, the Blocks view (a graphical programming paradigm inspired by Blockly), the C code view and the Pseudocode view. There is also a fifth state machine way of entering code.
Flowcode also has a mode named App Developer which is capable of creating Windows based applications via a runtime executable. This allows the software to also create applications for testing or interacting with the embedded system.
Flowcode also has compatibility with Solidworks.","Flowcode is a Microsoft Windows-based development environment commercially produced by Matrix TSL for programming embedded devices based on PIC, AVR (including Arduino), ESP32, Raspberry Pi and RP2040 and ARM technologies using graphical programming styles (such as flowcharts) and imperative programming styles (through C, State Machines and Pseudocode). It is currently in its tenth revision.
Flowcode is dedicated to simplifying complex functionality such as Bluetooth, Mobile Phones Communications, USB communications etc. by using pre-developed dedicated open source component libraries of functions. This is achieved by dragging virtual representations of hardware onto a visual panel, providing access to associated libraries. Flowcode is therefore ideal for speeding up software development times and allowing those with little programming experience to get started and help with projects. This makes it appropriate for the formal teaching of principles of programming microcontrollers.Flowcode allows the user to develop and view their program using four different visual modes. These are the Flowchart view, the Blocks view (a graphical programming paradigm inspired by Blockly), the C code view and the Pseudocode view. There is also a fifth state machine way of entering code.
Flowcode also has a mode named App Developer which is capable of creating Windows based applications via a runtime executable. This allows the software to also create applications for testing or interacting with the embedded system.
Flowcode also has compatibility with Solidworks.

Notes
External links
Official Site",38557302,https://en.wikipedia.org/wiki/Flowcode
Forth (programming language),"Forth is a procedural, concatenative, stack-oriented programming language and interactive development environment designed by Charles H. ""Chuck"" Moore and first used by other programmers in 1970. Although not an acronym, the language's name in its early years was often spelled in all capital letters as FORTH. The FORTH-79 and FORTH-83 implementations, which were not written by Moore, became de facto standards, and an official standardization of the language was published in 1994 as ANS Forth. A wide range of Forth derivatives existed before and after ANS Forth. The free software Gforth implementation is actively maintained, as are several commercially supported systems.
Forth typically combines a compiler with an integrated command shell, where the user interacts via subroutines called words. Words can be defined, tested, redefined, and debugged without recompiling or restarting the whole program. All syntactic elements, including variables, operators, and control flow, are defined as words. A stack is used to pass parameters between words, leading to a Reverse Polish Notation style.
For much of Forth's existence, the standard technique was to compile to threaded code, which can be interpreted faster than bytecode. One of the early benefits of Forth was size: an entire development environment—including compiler, editor, and user programs—could fit in memory on an 8-bit or similarly limited system. No longer constrained by space, there are modern implementations that generate optimized machine code like other language compilers. The relative simplicity of creating a basic Forth system has led to many personal and proprietary variants, such as the custom Forth used to implement the bestselling 1986 video game Starflight from Electronic Arts.Forth is used in the Open Firmware boot loader, in spaceflight applications such as the Philae spacecraft, and in other embedded systems which involve interaction with hardware. 
Moore developed a series of microprocessors for executing compiled Forth-like code directly and experimented with smaller languages based on Forth concepts, including cmForth and colorForth. Most of these languages were designed to support Moore's own projects, such as chip design.","Forth is a procedural, concatenative, stack-oriented programming language and interactive development environment designed by Charles H. ""Chuck"" Moore and first used by other programmers in 1970. Although not an acronym, the language's name in its early years was often spelled in all capital letters as FORTH. The FORTH-79 and FORTH-83 implementations, which were not written by Moore, became de facto standards, and an official standardization of the language was published in 1994 as ANS Forth. A wide range of Forth derivatives existed before and after ANS Forth. The free software Gforth implementation is actively maintained, as are several commercially supported systems.
Forth typically combines a compiler with an integrated command shell, where the user interacts via subroutines called words. Words can be defined, tested, redefined, and debugged without recompiling or restarting the whole program. All syntactic elements, including variables, operators, and control flow, are defined as words. A stack is used to pass parameters between words, leading to a Reverse Polish Notation style.
For much of Forth's existence, the standard technique was to compile to threaded code, which can be interpreted faster than bytecode. One of the early benefits of Forth was size: an entire development environment—including compiler, editor, and user programs—could fit in memory on an 8-bit or similarly limited system. No longer constrained by space, there are modern implementations that generate optimized machine code like other language compilers. The relative simplicity of creating a basic Forth system has led to many personal and proprietary variants, such as the custom Forth used to implement the bestselling 1986 video game Starflight from Electronic Arts.Forth is used in the Open Firmware boot loader, in spaceflight applications such as the Philae spacecraft, and in other embedded systems which involve interaction with hardware. 
Moore developed a series of microprocessors for executing compiled Forth-like code directly and experimented with smaller languages based on Forth concepts, including cmForth and colorForth. Most of these languages were designed to support Moore's own projects, such as chip design.

Uses
Forth has a niche in astronomical and space applications as well as a history in embedded systems. The Open Firmware boot ROMs used by Apple, IBM, Sun, and OLPC XO-1 contain a Forth environment.
Forth has often been used to bring up new hardware. Forth was the first resident software on the new Intel 8086 chip in 1978, and MacFORTH was the first resident development system for the Macintosh 128K in 1984.Atari, Inc. used an elaborate animated demo written in Forth to showcase capabilities of the Atari 400 and 800 computers in department stores. Electronic Arts published multiple video games in the 1980s that were written in Forth, including Worms? (1983), Adventure Construction Set (1984), Amnesia (1986), Starflight (1986), and Lords of Conquest (1986). Robot coding game ChipWits (1984) was written in MacFORTH.Ashton-Tate's RapidFile (1986), a flat-file database program, and VP-Planner from Paperback Software International (1983), a spreadsheet program competing with Lotus 1-2-3, were written in Forth.
The Canon Cat (1987) uses Forth for its system programming.
Rockwell produced single-chip microcomputers with resident Forth kernels: the R65F11 and R65F12. ASYST was a Forth expansion for measuring and controlling on PCs.

History
Forth evolved from Charles H. Moore's personal programming system, which had been in continuous development since 1968. Forth was first exposed to other programmers in the early 1970s, starting with Elizabeth Rather at the United States National Radio Astronomy Observatory (NRAO). After their work at NRAO, Charles Moore and Elizabeth Rather formed FORTH, Inc. in 1973, refining and porting Forth systems to dozens of other platforms in the next decade.
Forth is so-named, because in 1968 ""the file holding the interpreter was labeled FOURTH, for 4th (next) generation software, but the IBM 1130 operating system restricted file names to five characters."" Moore saw Forth as a successor to compile-link-go third-generation programming languages, or software for ""fourth generation"" hardware.
FORTH, Inc.'s microFORTH was developed for the Intel 8080, Motorola 6800, Zilog Z80, and RCA 1802 microprocessors, starting in 1976. MicroFORTH was later used by hobbyists to generate Forth systems for other architectures, such as the 6502 in 1978. The Forth Interest Group was formed in 1978. It promoted and distributed its own version of the language, FIG-Forth, for most makes of home computer.
Forth was popular in the early 1980s, because it was well suited to the limited memory of microcomputers. The ease of implementing the language led to many implementations. The Jupiter ACE home computer has Forth in its ROM-resident operating system. Insoft GraFORTH is a version of Forth with graphics extensions for the Apple II.Common practice was codified in the de facto standards FORTH-79 and FORTH-83 in the years 1979 and 1983, respectively. These standards were unified by ANSI in 1994, commonly referred to as ANS  Forth.As of 2018, the source for the original 1130 version of FORTH has been recovered, and is now being updated to run on a restored or emulated 1130 system.

Overview
Forth emphasizes the use of small, simple functions called words. Words for bigger tasks call upon many smaller words that each accomplish a distinct sub-task. A large Forth program is a hierarchy of words. These words, being distinct modules that communicate implicitly via a stack mechanism, can be prototyped, built and tested independently. The highest level of Forth code may resemble an English-language description of the application. Forth has been called a meta-application language: a language that can be used to create problem-oriented languages.Forth relies on explicit use of a data stack and reverse Polish notation which is commonly used in calculators from Hewlett-Packard. In RPN, the operator is placed after its operands, as opposed to the more common infix notation where the operator is placed between its operands. Postfix notation makes the language easier to parse and extend; Forth's flexibility makes a static BNF grammar inappropriate, and it does not have a monolithic compiler. Extending the compiler only requires writing a new word, instead of modifying a grammar and changing the underlying implementation.
Using RPN, one can get the result of the mathematical expression (25 * 10 + 50) this way:

First the numbers 25 and 10 are put on the stack.
The word * takes the top two numbers from the stack, multiplies them, and puts the product back on the stack.

Then the number 50 is placed on the stack.
The word + adds the top two values, pushing the sum. CR (carriage return) starts the output on a new line. Finally, . prints the result. As everything has completed successfully, the Forth system prints OK.
Even Forth's structural features are stack-based. For example:

The colon indicates the beginning of a new definition, in this case a new word (again, word is the term used for a subroutine) called FLOOR5. The text in parentheses is a comment, advising that this word expects a number on the stack and will return a possibly changed number (on the stack).
The subroutine uses the following commands: DUP duplicates the number on the stack; 6 pushes a 6 on top of the stack; < compares the top two numbers on the stack (6 and the DUPed input), and replaces them with a true-or-false value; IF takes a true-or-false value and chooses to execute commands immediately after it or to skip to the ELSE; DROP discards the value on the stack; 5 pushes a 5 on top of the stack; and THEN ends the conditional.
The FLOOR5 word is equivalent to this function written in the C programming language using the conditional operator '?:'

This function is written more succinctly as:

This can be run as follows:

First a number (1 or 8) is pushed onto the stack, FLOOR5 is called, which pops the number again and pushes the result. CR moves the output to a new line (again, this is only here for readability). Finally, a call to . pops the result and prints.

Facilities
Forth's grammar has no official specification. Instead, it is defined by a simple algorithm. The interpreter reads a line of input from the user input device, which is then parsed for a word using spaces as a delimiter; some systems recognise additional whitespace characters. When the interpreter finds a word, it looks the word up in the dictionary. If the word is found, the interpreter executes the code associated with the word, and then returns to parse the rest of the input stream. If the word isn't found, the word is assumed to be a number and an attempt is made to convert it into a number and push it on the stack; if successful, the interpreter continues parsing the input stream. Otherwise, if both the lookup and the number conversion fail, the interpreter prints the word followed by an error message indicating that the word is not recognised, flushes the input stream, and waits for new user input.The definition of a new word is started with the word : (colon) and ends with the word ; (semi-colon). For example,

will compile the word X, and makes the name findable in the dictionary. When executed by typing 10 X at the console this will print 11 10.Most Forth systems include an assembler to write words using the processor's facilities. Forth assemblers often use a reverse Polish syntax in which the parameters of an instruction precede the instruction. A typical reverse Polish assembler prepares the operands on the stack and the mnemonic copies the whole instruction into memory as the last step. A Forth assembler is by nature a macro assembler, so that it is easy to define an alias for registers according to their role in the Forth system: e.g. ""dsp"" for the register used as the data stack pointer.

Operating system, files, and multitasking
Most Forth systems run under a host operating system such as Microsoft Windows, Linux or a version of Unix and use the host operating system's file system for source and data files; the ANSI Forth Standard describes the words used for I/O. All modern Forth systems use normal text files for source, even if they are embedded. An embedded system with a resident compiler gets its source via a serial line.
Classic Forth systems traditionally use neither operating system nor file system. Instead of storing code in files, source code is stored in disk blocks written to physical disk addresses. The word BLOCK is employed to translate the number of a 1K-sized block of disk space into the address of a buffer containing the data, which is managed automatically by the Forth system. Block use has become rare since the mid-1990s. In a hosted system those blocks too are allocated in a normal file in any case.
Multitasking, most commonly cooperative round-robin scheduling, is normally available (although multitasking words and support are not covered by the ANSI Forth Standard). The word PAUSE is used to save the current task's execution context, to locate the next task, and restore its execution context. Each task has its own stacks, private copies of some control variables and a scratch area. Swapping tasks is simple and efficient; as a result, Forth multitaskers are available even on very simple microcontrollers, such as the Intel 8051, Atmel AVR, and TI MSP430.Other non-standard facilities include a mechanism for issuing calls to the host OS or windowing systems, and many provide extensions that employ the scheduling provided by the operating system. Typically they have a larger and different set of words from the stand-alone Forth's PAUSE word for task creation, suspension, destruction and modification of priority.

Self-compilation and cross compilation
A full-featured Forth system with all source code will compile itself, a technique commonly called meta-compilation or self-hosting, by Forth programmers (although the term doesn't exactly match meta-compilation as it is normally defined). The usual method is to redefine the handful of words that place compiled bits into memory. The compiler's words use specially named versions of fetch and store that can be redirected to a buffer area in memory. The buffer area simulates or accesses a memory area beginning at a different address than the code buffer. Such compilers define words to access both the target computer's memory, and the host (compiling) computer's memory.After the fetch and store operations are redefined for the code space, the compiler, assembler, etc. are recompiled using the new definitions of fetch and store. This effectively reuses all the code of the compiler and interpreter. Then, the Forth system's code is compiled, but this version is stored in the buffer. The buffer in memory is written to disk, and ways are provided to load it temporarily into memory for testing. When the new version appears to work, it is written over the previous version.
Numerous variations of such compilers exist for different environments. For embedded systems, the code may instead be written to another computer, a technique known as cross compilation, over a serial port or even a single TTL bit, while keeping the word names and other non-executing parts of the dictionary in the original compiling computer. The minimum definitions for such a Forth compiler are the words that fetch and store a byte, and the word that commands a Forth word to be executed. Often the most time-consuming part of writing a remote port is constructing the initial program to implement fetch, store and execute, but many modern microprocessors have integrated debugging features (such as the Motorola CPU32) that eliminate this task.

Structure of the language
The basic data structure of Forth is the ""dictionary"" which maps ""words"" to executable code or named data structures. The dictionary is laid out in memory as a tree of linked lists with the links proceeding from the latest (most recently) defined word to the oldest, until a sentinel value, usually a NULL pointer, is found. A context switch causes a list search to start at a different leaf. A linked list search continues as the branch merges into the main trunk leading eventually back to the sentinel, the root.
There can be several dictionaries. In rare cases such as meta-compilation a dictionary might be isolated and stand-alone.
The effect resembles that of nesting namespaces and can overload keywords depending on the context.
A defined word generally consists of head and body with the head consisting of the name field (NF) and the link field (LF), and body consisting of the code field (CF) and the parameter field (PF).
Head and body of a dictionary entry are treated separately because they may not be contiguous. For example, when a Forth program is recompiled for a new platform, the head may remain on the compiling computer, while the body goes to the new platform. In some environments (such as embedded systems) the heads occupy memory unnecessarily. However, some cross-compilers may put heads in the target if the target itself is expected to support an interactive Forth.The exact format of a dictionary entry is not prescribed, and implementations vary.

Structure of the compiler
The compiler itself is not a monolithic program. It consists of Forth words visible to the system, and usable by a programmer. This allows a programmer to change the compiler's words for special purposes.
The ""compile time"" flag in the name field is set for words with ""compile time"" behavior. Most simple words execute the same code whether they are typed on a command line, or embedded in code. When compiling these, the compiler simply places code or a threaded pointer to the word.The classic examples of compile-time words are the control structures such as IF and WHILE. Almost all of Forth's control structures and almost all of its compiler are implemented as compile-time words. Apart from some rarely used control flow words only found in a few implementations, such as the conditional return word ?EXIT used in Ulrich Hoffmann's preForth, all of Forth's control flow words are executed during compilation to compile various combinations of primitive words along with their branch addresses. For instance, IF and WHILE, and the words that match with those, set up BRANCH (unconditional branch) and ?BRANCH (pop a value off the stack, and branch if it is false). Counted loop control flow words work similarly but set up combinations of primitive words that work with a counter, and so on. During compilation, the data stack is used to support control structure balancing, nesting, and back-patching of branch addresses. The snippet:

would often be compiled to the following sequence inside a definition:

The numbers after BRANCH represent relative jump addresses. LIT is the primitive word for pushing a ""literal"" number onto the data stack. (Faster, shorter code would be compiled using pointers to constants instead of LIT and embedded data, if any of the numbers involved have been separately defined as constants. There would be similar changes if yet other words were used instead of constants, and so on.)

Compilation state and interpretation state
The word : (colon) parses a name as a parameter, creates a dictionary entry (a colon definition) and enters compilation state. The interpreter continues to read space-delimited words from the user input device. If a word is found, the interpreter executes the compilation semantics associated with the word, instead of the interpretation semantics. The default compilation semantics of a word are to append its interpretation semantics to the current definition.The word ; (semi-colon) finishes the current definition and returns to interpretation state. It is an example of a word whose compilation semantics differ from the default. The interpretation semantics of ; (semi-colon), most control flow words, and several other words are undefined in ANS  Forth, meaning that they must only be used inside of definitions and not on the interactive command line.The interpreter state can be changed manually with the words [ (left-bracket) and ] (right-bracket) which enter interpretation state or compilation state, respectively. These words can be used with the word LITERAL to calculate a value during a compilation and to insert the calculated value into the current colon definition. LITERAL has the compilation semantics to take an object from the data stack and to append semantics to the current colon definition to place that object on the data stack.
In ANS  Forth, the current state of the interpreter can be read from the flag STATE which contains the value true when in compilation state and false otherwise. This allows the implementation of so-called state-smart words with behavior that changes according to the current state of the interpreter.

Immediate words
The word IMMEDIATE marks the most recent colon definition as an immediate word, effectively replacing its compilation semantics with its interpretation semantics. Immediate words are normally executed during compilation, not compiled, but this can be overridden by the programmer in either state. ; is an example of an immediate word. In ANS  Forth, the word POSTPONE takes a name as a parameter and appends the compilation semantics of the named word to the current definition even if the word was marked immediate. Forth-83 defined separate words COMPILE and [COMPILE] to force the compilation of non-immediate and immediate words, respectively.
Instead of reserving space for an Immediate flag in every definition, some implementations of Forth use an Immediates Dictionary which is checked first when in compile mode.

Unnamed words and execution tokens
In ANS  Forth, unnamed words can be defined with the word :NONAME which compiles the following words up to the next ; (semi-colon) and leaves an execution token on the data stack. The execution token provides an opaque handle for the compiled semantics, similar to the function pointers of the C programming language.
Execution tokens can be stored in variables. The word EXECUTE takes an execution token from the data stack and performs the associated semantics. The word COMPILE, (compile-comma) takes an execution token from the data stack and appends the associated semantics to the current definition.
The word ' (tick) takes the name of a word as a parameter and returns the execution token associated with that word on the data stack. In interpretation state, ' RANDOM-WORD EXECUTE is equivalent to RANDOM-WORD.

Parsing words and comments
The words : (colon), POSTPONE, ' (tick) are examples of parsing words that take their arguments from the user input device instead of the data stack. Another example is the word ( (paren) which reads and ignores the following words up to and including the next right parenthesis and is used to place comments in a colon definition. Similarly, the word \ (backslash) is used for comments that continue to the end of the current line. To be parsed correctly, ( (paren) and \ (backslash) must be separated by whitespace from the following comment text.

Structure of code
In most Forth systems, the body of a code definition consists of either machine language, or some form of threaded code. The original Forth which follows the informal FIG standard (Forth Interest Group), is a TIL (Threaded Interpretive Language). This is also called indirect-threaded code, but direct-threaded and subroutine threaded Forths have also become popular in modern times. The fastest modern Forths, such as SwiftForth, VFX Forth, and iForth, compile Forth to native machine code.

Data objects
When a word is a variable or other data object, the CF points to the runtime code associated with the defining word that created it. A defining word has a characteristic ""defining behavior"" (creating a dictionary entry plus possibly allocating and initializing data space) and also specifies the behavior of an instance of the class of words constructed by this defining word. Examples include:

VARIABLE
Names an uninitialized, one-cell memory location. Instance behavior of a VARIABLE returns its address on the stack.
CONSTANT
Names a value (specified as an argument to CONSTANT). Instance behavior returns the value.
CREATE
Names a location; space may be allocated at this location, or it can be set to contain a string or other initialized value. Instance behavior returns the address of the beginning of this space.Forth also provides a facility by which a programmer can define new application-specific defining words, specifying both a custom defining behavior and instance behavior. Some examples include circular buffers, named bits on an I/O port, and automatically indexed arrays.
Data objects defined by these and similar words are global in scope. The function provided by local variables in other languages is provided by the data stack in Forth (although Forth also has real local variables). Forth programming style uses very few named data objects compared with other languages; typically such data objects are used to contain data which is used by a number of words or tasks (in a multitasked implementation).Forth does not enforce consistency of data type usage; it is the programmer's responsibility to use appropriate operators to fetch and store values or perform other operations on data.

Examples
“Hello, World!”
HELLO <cr>
Hello, World!

The word CR (Carriage Return) causes the following output to be displayed on a new line. The parsing word ."" (dot-quote) reads a double-quote delimited string and appends code to the current definition so that the parsed string will be displayed on execution. The space character separating the word ."" from the string Hello, World! is not included as part of the string. It is needed so that the parser recognizes ."" as a Forth word.
A standard Forth system is also an interpreter, and the same output can be obtained by typing the following code fragment into the Forth console:

.( (dot-paren) is an immediate word that parses a parenthesis-delimited string and displays it. As with the word ."" the space character separating .( from Hello, World! is not part of the string.
The word CR comes before the text to print. By convention, the Forth interpreter does not start output on a new line. Also by convention, the interpreter waits for input at the end of the previous line, after an ok prompt. There is no implied ""flush-buffer"" action in Forth's CR, as sometimes is in other programming languages.

Mixing states of compiling and interpreting
Here is the definition of a word EMIT-Q which when executed emits the single character Q:

This definition was written to use the ASCII value of the Q character (81) directly. The text between the parentheses is a comment and is ignored by the compiler. The word EMIT takes a value from the data stack and displays the corresponding character.
The following redefinition of EMIT-Q uses the words [ (left-bracket), ] (right-bracket), CHAR and LITERAL to temporarily switch to interpreter state, calculate the ASCII value of the Q character, return to compilation state and append the calculated value to the current colon definition:

The parsing word CHAR takes a space-delimited word as parameter and places the value of its first character on the data stack. The word [CHAR] is an immediate version of CHAR. Using [CHAR], the example definition for EMIT-Q could be rewritten like this:

This definition used \ (backslash) for the describing comment.
Both CHAR and [CHAR] are predefined in ANS  Forth. Using IMMEDIATE and POSTPONE, [CHAR] could have been defined like this:

RC4 cipher program
In 1987, Ron Rivest developed the RC4 cipher-system for RSA Data Security, Inc. Its description follows:

We have an array of 256 bytes, all different. Every time the array is used it changes by swapping two bytes. The swaps are controlled by counters i and j, each initially 0. To get a new i, add 1. To get a new j, add the array byte at the new i. Exchange the array bytes at i and j. The code is the array byte at the sum of the array bytes at i and j. This is XORed with a byte of the plaintext to encrypt, or the ciphertext to decrypt. The array is initialized by first setting it to 0 through 255. Then step through it using i and j, getting the new j by adding to it the array byte at i and a key byte, and swapping the array bytes at i and j. Finally, i and j are set to 0. All additions are modulo 256.
The following Standard Forth version uses Core and Core Extension words only.

This is one way to test the code:

Implementations
Because Forth is simple to implement and has no standard reference implementation, there are numerous versions of the language. In addition to supporting the standard varieties of desktop computer systems (POSIX, Microsoft Windows, macOS), many of these Forth systems also target a variety of embedded systems. Listed here are some of the systems which conform to the 1994 ANS  Forth standard.

ASYST, a Forth-like system for data collection and analysis 
Gforth, a portable ANS Forth implementation from the GNU Project
noForth, an ANS Forth implementation (as far as possible) for Flash microcontrollers (MSP430 & Risc-V)
Open Firmware, a bootloader and Firmware standard based on ANS Forth
pForth, portable Forth written in C
SP-Forth, ANS Forth implementation from the Russian Forth Interest Group (RuFIG)
Swift Forth, machine code generating implementation from Forth, Inc.
VFX Forth, optimizing native code Forth
Firth, an adaptation of Forth for the Little Man Stack Machine computer.

See also
RTX2010, a CPU that runs Forth natively

Notes
References
External links
Forth 2012 Standard official site
Programming a problem-oriented language unpublished book by Charles H. Moore (1970)
Annual European Forth Conference 1985–present
Forth Research at Institut für Computersprachen",11012,https://en.wikipedia.org/wiki/Forth_(programming_language)
FreeBASIC,"FreeBASIC is a free and open source multiplatform compiler and programming language based on BASIC licensed under the GNU GPL  for Microsoft Windows, protected-mode MS-DOS (DOS extender), Linux, FreeBSD and Xbox.  The Xbox version is no longer maintained.According to its official website, FreeBASIC provides syntax compatibility with programs originally written in Microsoft QuickBASIC (QB).  Unlike QuickBASIC, however, FreeBASIC is a command line only compiler, unless users manually install an external integrated development environment (IDE) of their choice.   IDEs specifically made for FreeBASIC include FBide and FbEdit, while more graphical options include WinFBE Suite and VisualFBEditor.","FreeBASIC is a free and open source multiplatform compiler and programming language based on BASIC licensed under the GNU GPL  for Microsoft Windows, protected-mode MS-DOS (DOS extender), Linux, FreeBSD and Xbox.  The Xbox version is no longer maintained.According to its official website, FreeBASIC provides syntax compatibility with programs originally written in Microsoft QuickBASIC (QB).  Unlike QuickBASIC, however, FreeBASIC is a command line only compiler, unless users manually install an external integrated development environment (IDE) of their choice.   IDEs specifically made for FreeBASIC include FBide and FbEdit, while more graphical options include WinFBE Suite and VisualFBEditor.

Compiler features
On its backend, FreeBASIC makes use of GNU Binutils in order to produce console and graphical user interface applications.  FreeBASIC supports the linking and creation of C static and dynamic libraries and has limited support for C++ libraries.  As a result, code compiled in FreeBASIC can be reused in most native development environments.
C style preprocessing, including multiline macros, conditional compiling and file inclusion, is supported.  The preprocessor also has access to symbol information and compiler settings, such as the language dialect.

Syntax
Initially, FreeBASIC emulated Microsoft QuickBASIC syntax as closely as possible. Beyond that, the language has continued its evolution. As a result, FreeBASIC combines several language dialects for maximum level of compatibility with QuickBASIC and full access to modern features.  New features include support for concepts such as objects, operator overloading, function overloading, namespaces and others.Newline characters indicate the termination of programming statements. A programming statement can be distributed on multiple consecutive lines by using the underscore line continuation char (_), whereas multiple statements may be written on a single line by separating each statement with a colon (:).
Block comments, as well as end-of-line remarks are supported.  Full line comments are made with an apostrophe ', while blocks of commented code begin with /' and end with '/.
FreeBASIC is not case-sensitive.

Graphics library
FreeBASIC provides built-in, QuickBASIC compatible graphics support through FBgfx, which is automatically included into programs that make a call to the SCREEN command.  Its backend defaults to OpenGL on Linux and DirectX on Microsoft Windows.  This abstraction makes FBgfx graphics code cross-platform compatible.  However, FBgfx is not hardware accelerated.
Users familiar with external graphics utilities such as OpenGL or the Windows API can use them without interfering with the built-in graphics library.

Language dialects
As FreeBASIC has evolved, changes have been made that required breaking older-styled syntax.  In order to continue supporting programs written using the older syntax, FreeBASIC now supports the following dialects:

The default dialect (-lang fb as a command-line argument) supports all new compiler features and disallows archaic syntax.
The FB-lite dialect (-lang fblite) permits use of most new, non-object-oriented features in addition to older-style programming.  Implicit variables, suffixes, GOSUB / RETURN, numeric labels and other features are allowed in this dialect.
The QB dialect (-lang qb) attempts to replicate QuickBASIC behavior and is able to compile many QuickBASIC programs without modification.

Example code
Standard programs, such as the ""Hello, World!"" program are done just as they were in QuickBASIC.

FreeBASIC adds to this with support for object-oriented features such as methods, constructors, dynamic memory allocation, properties and temporary allocation.

In both cases, the language is well suited for learning purposes.

References
External links

Official website
FreeBASIC on GitHub
FreeBASIC on SourceForgeIDEsWinFBE - Modern FreeBASIC Editor for Windows
VisualFBEditor - Cross-platform graphical IDE
fbide.freebasic.net  — FBIDE Integrated Development Environment for freeBASIC
FBEdit (current)  — FBEdit source code editor for FreeBASIC, version 1.0.7.6c
FBEdit source code editor for freeBASIC (outdated version: 1.0.6.8) on SourceForge",1443566,https://en.wikipedia.org/wiki/FreeBASIC
Futhark (programming language),"Futhark is a functional data parallel array programming language originally developed at UCPH Department of Computer Science (DIKU) as part of the HIPERFIT project. It focuses on enabling data parallel programs written in a functional style to be executed with high performance on massively parallel hardware, in particular on graphics processing units (GPUs). Futhark is strongly inspired by NESL, and its implementation uses a variant of the flattening transformation, but imposes constraints on how parallelism can be expressed in order to enable more aggressive compiler optimisations. In particular, irregular nested data parallelism is not supported.","Futhark is a functional data parallel array programming language originally developed at UCPH Department of Computer Science (DIKU) as part of the HIPERFIT project. It focuses on enabling data parallel programs written in a functional style to be executed with high performance on massively parallel hardware, in particular on graphics processing units (GPUs). Futhark is strongly inspired by NESL, and its implementation uses a variant of the flattening transformation, but imposes constraints on how parallelism can be expressed in order to enable more aggressive compiler optimisations. In particular, irregular nested data parallelism is not supported.

Overview
Futhark is a language in the ML family, with an indentation-insensitive syntax derived from OCaml, Standard ML, and Haskell. The type system is based on Hindley-Milner with a variety of extensions, such as uniqueness types and size-dependent types. Futhark is not intended as a general-purpose programming language for writing full applications, but is instead focused on writing computational ""kernels"" (not necessarily the same as a GPU kernel) which are then invoked from applications written in conventional languages.

Examples
Dot product
The following program computes the dot product of two vectors containing double-precision numbers.

It can also be equivalently written with explicit type annotations as follows.

This makes the size-dependent types explicit: this function can only be invoked with two arrays of the same size, and the type checker will reject any program where this cannot be statically determined.

Matrix multiplication
The following program performs matrix multiplication, using the definition of dot product above.

Note how the types enforce that the function is only invoked with matrices of compatible size. Further, this is an example of nested data parallelism.


== References ==",62334821,https://en.wikipedia.org/wiki/Futhark_(programming_language)
FX-87,"FX-87 is a polymorphic typed functional language based on a system for static program analysis in which every expression has two static properties: a type and an effect. In a study done by MIT, FX-87 yields similar performance results as functional languages on programs that do not contain side effects (Fibonacci, Factorial). FX-87 did yield a great performance increase when matching DNA sequences.KFX is the kernel language of FX-87. It was described in 'Polymorphic Effect Systems', J.M. Lucassen et al., Proceedings of the 15th Annual ACM Conference POPL, ACM 1988, pp. 47–57.


== References ==","FX-87 is a polymorphic typed functional language based on a system for static program analysis in which every expression has two static properties: a type and an effect. In a study done by MIT, FX-87 yields similar performance results as functional languages on programs that do not contain side effects (Fibonacci, Factorial). FX-87 did yield a great performance increase when matching DNA sequences.KFX is the kernel language of FX-87. It was described in 'Polymorphic Effect Systems', J.M. Lucassen et al., Proceedings of the 15th Annual ACM Conference POPL, ACM 1988, pp. 47–57.


== References ==",17139,https://en.wikipedia.org/wiki/FX-87
General-purpose programming language,"In computer software, a general-purpose programming language (GPL) is a programming language for building software in a wide variety of application domains. Conversely, a domain-specific programming language (DSL) is used within a specific area. For example, Python is a GPL, while SQL is a DSL for querying relational databases.","In computer software, a general-purpose programming language (GPL) is a programming language for building software in a wide variety of application domains. Conversely, a domain-specific programming language (DSL) is used within a specific area. For example, Python is a GPL, while SQL is a DSL for querying relational databases.

History
Early programming languages were designed for scientific computing (numerical calculations) or commercial data processing, as was computer hardware. Scientific languages such as Fortran and Algol supported floating-point calculations and multidimensional arrays, while business languages such as COBOL supported fixed-field file formats and data records. Much less widely used were specialized languages such as IPL-V and LISP for symbolic list processing; COMIT for string manipulation; APT for numerically controlled machines. Systems programming requiring pointer manipulation was typically done in assembly language, though JOVIAL was used for some military applications.IBM's System/360, announced in 1964, was designed as a unified hardware architecture supporting both scientific and commercial applications, and IBM developed PL/I for it as a single, general-purpose language that supported scientific, commercial, and systems programming. Indeed, a subset of PL/I was used as the standard systems programming language for the Multics operating system.
Since PL/I, the distinction between scientific and commercial programming languages has diminished, with most languages supporting the basic features required by both, and much of the special file format handling delegated to specialized database management systems.
Many specialized languages were also developed starting in the 1960s: GPSS and Simula for discrete event simulation; MAD, BASIC, Logo, and Pascal for teaching programming; C for systems programming; JOSS and APL\360 for interactive programming.

GPL vs. DSL
The distinction between general-purpose programming languages and domain-specific programming languages is not always clear. A programming language may be created for a specific task, but used beyond that original domain and thus be considered a general purpose programming language.  For example, COBOL, Fortran, and Lisp were created as DSLs (for business processing, numeric computation, and symbolic processing), but became GPL's over time. Inversely, a language may be designed for general use but only applied in a specific area in practice. A programming language that is well suited for a problem, whether it be general-purpose language or DSL, should minimize the level of detail required while still being expressive enough in the problem domain. As the name suggests, general-purpose language is ""general"" in that it cannot provide support for domain-specific notation while DSLs can be designed in diverse problem domains to handle this problem. General-purpose languages are preferred to DSLs when an application domain is not well understood enough to warrant its own language. In this case, a general-purpose language with an appropriate library of data types and functions for the domain may be used instead. While DSLs are usually smaller than GPL in that they offer a smaller range of notations of abstractions, some DSLs actually contain an entire GPL as a sublanguage. In these instances, the DSLs are able to offer domain-specific expressive power along with the expressive power of GPL.General Purpose programming languages are all Turing complete, meaning that they can theoretically solve any computational problem. Domain-specific languages are often similarly Turing complete but are not exclusively so.

Advantages and disadvantages
General-purpose programming languages are more commonly used by programmers. According to a study, C, Python, and Java were the most commonly used programming languages in 2021. One argument in favor of using general-purpose programming languages over domain-specific languages is that more people will be familiar with these languages, overcoming the need to learn a new language.
Additionally, for many tasks (e.g., statistical analysis, machine learning, etc.) there are libraries that are extensively tested and optimized. Theoretically, the presence of these libraries should bridge the gap between general-purpose and domain-specific languages.An empirical study in 2010 sought to measure problem-solving and productivity between GPLs and DSLs by giving users problems who were familiar with the GPL (C#) and unfamiliar with the DSL (XAML). Ultimately, users of this specific domain-specific language performed better by a factor of 15%, even though they were more familiar with GPL, warranting further research.

Examples
C
The predecessor to C, B, was developed largely for a specific purpose: systems programming. By contrast, C has found use in a variety of computational domains, such as operating systems, device drivers, application software, and embedded systems.
C is suitable for use in a variety of areas because of its generality. It provides economy of expression, flow control, data structures, and a rich set of operators, but does not constrain its users to use it in any one context. As a result, though it was first used by its creators to rewrite the kernel of the Unix operating system, it was easily adapted for use in application development, embedded systems (e.g., microprocessor programming), video games (e.g., Doom), and so on. Today, C remains one of the most popular and widely-used programming languages.

C++
Conceived as an extension to C, C++ introduced object-oriented features, as well as other conveniences like references, operator overloading, and default arguments. Like C, C++'s generality allowed it to be used in a wide range of areas. While its C++'s core area of application is in systems programming (because of C++'s ability to grant access to low-level architecture), it has been used extensively to build desktop applications, video games, databases, financial systems, and much more. Major software and finance companies, such as Microsoft, Apple, Bloomberg, and Morgan Stanley, still widely use C++ in their internal and external applications.

Python
Python was conceived as a language that emphasized code readability and extensibility. The former allowed non-software engineers to easily learn and write computer programs, while the latter allowed domain specialists to easily create libraries suited to their own use cases. For these reasons, Python has been used across a wide range of domains.
Below are some of the areas where Python is used:
Web Development: Frameworks like Django and Flask have allowed web developers to create robust web servers that can also take advantage of the wider Python ecosystem.
Science and Academia: Scientific and data libraries, like SciPy and Pandas, have enabled Python's use in scientific research.
Machine Learning: Libraries like scikit-learn and Tensorflow have increased the accessibility of machine learning to developers.
General Software Development: Developing user applications, web scraping programs, games, and other general software.

List
The following are some general-purpose programming languages:

See also
General-purpose markup language
General-purpose modeling language


== References ==",891926,https://en.wikipedia.org/wiki/General-purpose_programming_language
GEORGE (programming language),"GEORGE (General Order Generator) is a programming language invented by Charles Leonard Hamblin in 1957. It was designed around a push-down pop-up stack for arithmetic operations, and employed reverse Polish notation. The language included loops, subroutines, conditionals, vectors, and matrices.","GEORGE (General Order Generator) is a programming language invented by Charles Leonard Hamblin in 1957. It was designed around a push-down pop-up stack for arithmetic operations, and employed reverse Polish notation. The language included loops, subroutines, conditionals, vectors, and matrices.

Description
Algebraic expressions were written in reverse Polish notation; thus, a+b{\displaystyle a+b} was written a b +, and similarly for the other arithmetic operations of subtraction, multiplication, and division.
The algebraic expression ax2+bx+c{\displaystyle ax^{2}+bx+c} was written a x dup × × b x × + c +, where 'dup' meant 'duplicate the value'.
Following the reverse Polish form, an assignment statement to evaluate the formula y=ax2+bx+c{\displaystyle y=ax^{2}+bx+c} was written as a x dup × × b x × + c + (y).
The computer evaluated the expression as follows: the values of a, then x, were pushed onto the top of the accumulator stack; 'dup' caused a copy of the top-most value (x) to be pushed onto the top of the accumulator stack; Multiply (×) caused the top two values, namely, x and x, to be removed (popped) and multiplied, returning the product to the top of the accumulator stack.  The second multiply (×) then caused the top two values on the stack (namely, a and x**2) to be popped and multiplied, and the product (a×x**2) to be pushed onto the top of the accumulator stack.  And so on the remaining components of the expression.  The final operation, namely (y), returned the value of the expression to storage without changing the status of the accumulator stack.
Assuming that the value on the top of the accumulator stack was not required immediately, it would be removed (cleared) by using the operator (;).
The following program reads in eight values and forms their sum:

0,
1, 8 rep (j)
   R +
]
(P)

The first line initialises the sum by pushing the value zero onto the top of the accumulator stack.
The second line introduces a loop, is spoken as ""for 1 to 8 repeat for j"", and is terminated by the square bracket.
In the third line, R causes one number to be read in and pushed onto the top of the accumulator stack, and the plus sign (+) causes that value to be added to the (partial) sum, leaving only the partial sum on the top of the accumulator stack.
After the loop terminates, the (P) causes the final sum to be punched on a card.Manipulation of vectors and matrices requires subscript notation.  In GEORGE, the subscript(s) preceded the vector or matrix name.  Thus A(j) was written j | A.
The following program reads in vector a of 10 values, then forms the squares of those values, and finally prints those values.

1, 10 R1 (a)
1, 10 rep (j)
   j | a dup * j | (a) ;
]
1, 10 P1 (a)

In the program, the first line is a vector read that reads in the ten values into a(1) through a(10).
The second line introduces a loop to run through the ten values of j.
The third line fetches a(j), duplicates it, multiplies those two values giving the square, and then stores it in  a(j).  Note the semicolon (;), which clears (or cancels) the top entry in the accumulator stack.  Were this not done, the accumulator would gradually fill up with the squares of the values.
The final line is a vector punch (i.e., print) to write out the ten squares.The above GEORGE coding table assisted in transcribing a program onto punch cards.
Conditional operations were written as jumps, as follows:
if a > 0 go to 5 (which transfers to label 5 if a is greater than zero)
would be written

0 a > 5 ↑ 
Label 5 was indicated by including *5 elsewhere in the program.
Unconditional transfers were written 5↑
Subroutine calls were made with the down arrow, .g., to call subroutine labelled 17, write 17↓, where the label 17 was encoded using column 3 of the above table.

Historical note
In the first version running by May 1957 on an English Electric DEUCE, all values were stored in binary fixed-point form in a 32-bit word, with 16 binary places.
In the second version introduced by 1958, values were held in floating-point form, with one value per word: 22 bits for the mantissa and 10 bits for the exponent.
Some form of coding table was needed because the printing equipment of the time provided only 26 letters of the alphabet, a decimal point, plus sign, minus sign, and slash.


== References ==",36133392,https://en.wikipedia.org/wiki/GEORGE_(programming_language)
Gleam (programming language),"Gleam is a general-purpose, concurrent, functional high-level programming language that compiles to Erlang or JavaScript source code.Gleam is a statically-typed language, which is different from the most popular languages that run on Erlang’s virtual machine BEAM, Erlang and Elixir.","Gleam is a general-purpose, concurrent, functional high-level programming language that compiles to Erlang or JavaScript source code.Gleam is a statically-typed language, which is different from the most popular languages that run on Erlang’s virtual machine BEAM, Erlang and Elixir.

Example
import gleam/io

pub fn main() {
  io.println(""hello, friend!"")
}

Gleam supports tail call optimization:
pub fn factorial(x: Int) -> Int {
  // The public function calls the private tail recursive function
  factorial_loop(x, 1)
}

fn factorial_loop(x: Int, accumulator: Int) -> Int {
  case x {
    1 -> accumulator

    // The last thing this function does is call itself
    _ -> factorial_loop(x - 1, accumulator * x)
  }
}

References
External links
Official website
Gleam-lang on GitHub",76326711,https://en.wikipedia.org/wiki/Gleam_(programming_language)
Go (programming language),"Go is a statically typed, compiled high-level programming language designed at Google by Robert Griesemer, Rob Pike, and Ken Thompson. It is syntactically similar to C, but also has memory safety, garbage collection, structural typing, and CSP-style concurrency. It is often referred to as Golang because of its former domain name, golang.org, but its proper name is Go.There are two major implementations:

Google's self-hosting ""gc"" compiler toolchain, targeting multiple operating systems and WebAssembly.
gofrontend, a frontend to other compilers, with the libgo library. With GCC the combination is gccgo; with LLVM the combination is gollvm.A third-party source-to-source compiler, GopherJS, compiles Go to JavaScript for front-end web development.","Go is a statically typed, compiled high-level programming language designed at Google by Robert Griesemer, Rob Pike, and Ken Thompson. It is syntactically similar to C, but also has memory safety, garbage collection, structural typing, and CSP-style concurrency. It is often referred to as Golang because of its former domain name, golang.org, but its proper name is Go.There are two major implementations:

Google's self-hosting ""gc"" compiler toolchain, targeting multiple operating systems and WebAssembly.
gofrontend, a frontend to other compilers, with the libgo library. With GCC the combination is gccgo; with LLVM the combination is gollvm.A third-party source-to-source compiler, GopherJS, compiles Go to JavaScript for front-end web development.

History
Go was designed at Google in 2007 to improve programming productivity in an era of multicore, networked machines and large codebases. The designers wanted to address criticisms of other languages in use at Google, but keep their useful characteristics:
Static typing and run-time efficiency (like C)
Readability and usability (like Python)
High-performance networking and multiprocessingIts designers were primarily motivated by their shared dislike of C++.Go was publicly announced in November 2009, and version 1.0 was released in March 2012. Go is widely used in production at Google and in many other organizations and open-source projects.

Branding and styling
The Gopher mascot was introduced in 2009 for the open source launch of the language.  The design, by Renée French, borrowed from a c. 2000 WFMU promotion.In November 2016, the Go and Go Mono fonts were released by type designers Charles Bigelow and Kris Holmes specifically for use by the Go project. Go is a humanist sans-serif resembling Lucida Grande, and Go Mono is monospaced. Both fonts adhere to the WGL4 character set and were designed to be legible with a large x-height and distinct letterforms. Both Go and Go Mono adhere to the DIN 1450 standard by having a slashed zero, lowercase l with a tail, and an uppercase I with serifs.In April 2018, the original logo was redesigned by brand designer Adam Smith. The new logo is a modern, stylized GO slanting right with trailing streamlines. (The Gopher mascot remained the same.)

Generics
The lack of support for generic programming in initial versions of Go drew considerable criticism. The designers expressed an openness to generic programming and noted that built-in functions were in fact type-generic, but are treated as special cases; Pike called this a weakness that might be changed at some point. The Google team built at least one compiler for an experimental Go dialect with generics, but did not release it.In August 2018, the Go principal contributors published draft designs for generic programming and error handling and asked users to submit feedback. However, the error handling proposal was eventually abandoned.In June 2020, a new draft design document was published that would add the necessary syntax to Go for declaring generic functions and types. A code translation tool, go2go, was provided to allow users to try the new syntax, along with a generics-enabled version of the online Go Playground.Generics were finally added to Go in version 1.18.

Versioning
Go 1 guarantees compatibility for the language specification and major parts of the standard library. All versions up to the current Go 1.22 release have maintained this promise.
Each major Go release is supported until there are two newer major releases.

Design
Go is influenced by C (especially the Plan 9 dialect), but with an emphasis on greater simplicity and safety. It consists of:

A syntax and environment adopting patterns more common in dynamic languages:Optional concise variable declaration and initialization through type inference (x := 0 instead of var x int = 0; or var x = 0;)
Fast compilation
Remote package management (go get) and online package documentation
Distinctive approaches to particular problems:
Built-in concurrency primitives: light-weight processes (goroutines), channels, and the select statement
An interface system in place of virtual inheritance, and type embedding instead of non-virtual inheritance
A toolchain that, by default, produces statically linked native binaries without external Go dependencies
A desire to keep the language specification simple enough to hold in a programmer's head, in part by omitting features that are common in similar languages.

Syntax
Go's syntax includes changes from C aimed at keeping code concise and readable. A combined declaration/initialization operator was introduced that allows the programmer to write i := 3 or s := ""Hello, world!"", without specifying the types of variables used. This contrasts with C's int i = 3; and const char *s = ""Hello, world!"";.
Semicolons still terminate statements; but are implicit when the end of a line occurs.Methods may return multiple values, and returning a result, err pair is the conventional way a method indicates an error to its caller in Go. Go adds literal syntaxes for initializing struct parameters by name and for initializing maps and slices. As an alternative to C's three-statement for loop, Go's range expressions allow concise iteration over arrays, slices, strings, maps, and channels.

Types
Go has a number of built-in types, including numeric ones (byte, int64, float32, etc.), booleans, and byte strings (string). Strings are immutable; built-in operators and keywords (rather than functions) provide concatenation, comparison, and UTF-8 encoding/decoding. Record types can be defined with the struct keyword.For each type T and each non-negative integer constant n, there is an array type denoted [n]T; arrays of differing lengths are thus of different types. Dynamic arrays are available as ""slices"", denoted []T for some type T. These have a length and a capacity specifying when new memory needs to be allocated to expand the array. Several slices may share their underlying memory.Pointers are available for all types, and the pointer-to-T type is denoted *T. Address-taking and indirection use the & and * operators, as in C, or happen implicitly through the method call or attribute access syntax. There is no pointer arithmetic, except via the special unsafe.Pointer type in the standard library.For a pair of types K, V, the type map[K]V is the type mapping type-K keys to type-V values, though Go Programming Language specification does not give any performance guarantees or implementation requirements for map types. Hash tables are built into the language, with special syntax and built-in functions. chan  T is a channel that allows sending values of type T between concurrent Go processes.Aside from its support for interfaces, Go's type system is nominal: the type keyword can be used to define a new named type, which is distinct from other named types that have the same layout (in the case of a struct, the same members in the same order). Some conversions between types (e.g., between the various integer types) are pre-defined and adding a new type may define additional conversions, but conversions between named types must always be invoked explicitly. For example, the type keyword can be used to define a type for IPv4 addresses, based on 32-bit unsigned integers as follows:

With this type definition, ipv4addr(x) interprets the uint32 value x as an IP address. Simply assigning x to a variable of type ipv4addr is a type error.Constant expressions may be either typed or ""untyped""; they are given a type when assigned to a typed variable if the value they represent passes a compile-time check.Function types are indicated by the func keyword; they take zero or more parameters and return zero or more values, all of which are typed. The parameter and return values determine a function type; thus, func(string, int32) (int, error) is the type of functions that take a string and a 32-bit signed integer, and return a signed integer (of default width) and a value of the built-in interface type error.Any named type has a method set associated with it. The IP address example above can be extended with a method for checking whether its value is a known standard:

Due to nominal typing, this method definition adds a method to ipv4addr, but not on uint32. While methods have special definition and call syntax, there is no distinct method type.

Interface system
Go provides two features that replace class inheritance.The first is embedding, which can be viewed as an automated form of composition.The second are its interfaces, which provides runtime polymorphism.: 266  Interfaces are a class of types and provide a limited form of structural typing in the otherwise nominal type system of Go. An object which is of an interface type is also of another type, much like C++ objects being simultaneously of a base and derived class. Go interfaces were designed after protocols from the Smalltalk programming language. Multiple sources use the term duck typing when describing Go interfaces. Although the term duck typing is not precisely defined and therefore not wrong, it usually implies that type conformance is not statically checked. Because conformance to a Go interface is checked statically by the Go compiler (except when performing a type assertion), the Go authors prefer the term structural typing.The definition of an interface type lists required methods by name and type. Any object of type T for which functions exist matching all the required methods of interface type I is an object of type I as well. The definition of type T need not (and cannot) identify type I. For example, if Shape, Square and Circle are defined as

then both a Square and a Circle are implicitly a Shape and can be assigned to a Shape-typed variable.: 263–268  In formal language, Go's interface system provides structural rather than nominal typing. Interfaces can embed other interfaces with the effect of creating a combined interface that is satisfied by exactly the types that implement the embedded interface and any methods that the newly defined interface adds.: 270 The Go standard library uses interfaces to provide genericity in several places, including the input/output system that is based on the concepts of Reader and Writer.: 282–283 
Besides calling methods via interfaces, Go allows converting interface values to other types with a run-time type check. The language constructs to do so are the type assertion, which checks against a single potential type:and the type switch, which checks against multiple types:The empty interface interface{} is an important base case because it can refer to an item of any concrete type. It is similar to the Object class in Java or C# and is satisfied by any type, including built-in types like int.: 284  Code using the empty interface cannot simply call methods (or built-in operators) on the referred-to object, but it can store the interface{} value, try to convert it to a more useful type via a type assertion or type switch, or inspect it with Go's reflect package. Because interface{} can refer to any value, it is a limited way to escape the restrictions of static typing, like void* in C but with additional run-time type checks.The interface{} type can be used to model structured data of any arbitrary schema in Go, such as JSON or YAML data, by representing it as a map[string]interface{} (map of string to empty interface). This recursively describes data in the form of a dictionary with string keys and values of any type.Interface values are implemented using pointer to data and a second pointer to run-time type information. Like some other types implemented using pointers in Go, interface values are nil if uninitialized.

Generic code using parameterized types
Since version 1.18, Go supports generic code using parameterized types.Functions and types now have the ability to be generic using type parameters. These type parameters are specified within square brackets, right after the function or type name. The compiler transforms the generic function or type into non-generic by substituting type arguments for the type parameters provided, either explicitly by the user or type inference by the compiler. This transformation process is referred to as type instantiation.
Interfaces now can define a set of types (known as type set) using | (Union) operator, as well as a set of methods. These changes were made to support type constraints in generics code. For a generic function or type, a constraint can be thought of as the type of the type argument: a meta-type. This new ~T syntax will be the first use of ~ as a token in Go. ~T means the set of all types whose underlying type is T.

Enumerated types
Package system
In Go's package system, each package has a path (e.g., ""compress/bzip2"" or ""golang.org/x/net/html"") and a name (e.g., bzip2 or html). References to other packages' definitions must always be prefixed with the other package's name, and only the capitalized names from other packages are accessible: io.Reader is public but bzip2.reader is not. The go get command can retrieve packages stored in a remote repository and developers are encouraged to develop packages inside a base path corresponding to a source repository (such as example.com/user_name/package_name) to reduce the likelihood of name collision with future additions to the standard library or other external libraries.

Concurrency: goroutines and channels
The Go language has built-in facilities, as well as library support, for writing concurrent programs. Concurrency refers not only to CPU parallelism, but also to asynchrony: letting slow operations like a database or network read run while the program does other work, as is common in event-based servers.The primary concurrency construct is the goroutine, a type of green thread.: 280–281  A function call prefixed with the go keyword starts a function in a new goroutine. The language specification does not specify how goroutines should be implemented, but current implementations multiplex a Go process's goroutines onto a smaller set of operating-system threads, similar to the scheduling performed in Erlang.: 10 While a standard library package featuring most of the classical concurrency control structures (mutex locks, etc.) is available,: 151–152  idiomatic concurrent programs instead prefer channels, which send messages between goroutines. Optional buffers store messages in FIFO order: 43  and allow sending goroutines to proceed before their messages are received.: 233 Channels are typed, so that a channel of type chan T can only be used to transfer messages of type T. Special syntax is used to operate on them; <-ch is an expression that causes the executing goroutine to block until a value comes in over the channel ch, while ch <- x sends the value x (possibly blocking until another goroutine receives the value). The built-in switch-like select statement can be used to implement non-blocking communication on multiple channels; see below for an example. Go has a memory model describing how goroutines must use channels or other operations to safely share data.The existence of channels does not by itself set Go apart from actor model-style concurrent languages like Erlang, where messages are addressed directly to actors (corresponding to goroutines). In the actor model, channels are themselves actors, therefore addressing a channel just means to address an actor. The actor style can be simulated in Go by maintaining a one-to-one correspondence between goroutines and channels, but the language allows multiple goroutines to share a channel or a single goroutine to send and receive on multiple channels.: 147 From these tools one can build concurrent constructs like worker pools, pipelines (in which, say, a file is decompressed and parsed as it downloads), background calls with timeout, ""fan-out"" parallel calls to a set of services, and others. Channels have also found uses further from the usual notion of interprocess communication, like serving as a concurrency-safe list of recycled buffers, implementing coroutines (which helped inspire the name goroutine), and implementing iterators.Concurrency-related structural conventions of Go (channels and alternative channel inputs) are derived from Tony Hoare's communicating sequential processes model. Unlike previous concurrent programming languages such as Occam or Limbo (a language on which Go co-designer Rob Pike worked), Go does not provide any built-in notion of safe or verifiable concurrency. While the communicating-processes model is favored in Go, it is not the only one: all goroutines in a program share a single address space. This means that mutable objects and pointers can be shared between goroutines; see § Lack of data race safety, below.

Suitability for parallel programming
Although Go's concurrency features are not aimed primarily at parallel processing, they can be used to program shared-memory multi-processor machines. Various studies have been done into the effectiveness of this approach. One of these studies compared the size (in lines of code) and speed of programs written by a seasoned programmer not familiar with the language and corrections to these programs by a Go expert (from Google's development team), doing the same for Chapel, Cilk and Intel TBB. The study found that the non-expert tended to write divide-and-conquer algorithms with one go statement per recursion, while the expert wrote distribute-work-synchronize programs using one goroutine per processor core. The expert's programs were usually faster, but also longer.

Lack of data race safety
Go's approach to concurrency can be summarized as ""don't communicate by sharing memory; share memory by communicating"". There are no restrictions on how goroutines access shared data, making data races possible. Specifically, unless a program explicitly synchronizes via channels or other means, writes from one goroutine might be partly, entirely, or not at all visible to another, often with no guarantees about ordering of writes. Furthermore, Go's internal data structures like interface values, slice headers, hash tables, and string headers are not immune to data races, so type and memory safety can be violated in multithreaded programs that modify shared instances of those types without synchronization. Instead of language support, safe concurrent programming thus relies on conventions; for example, Chisnall recommends an idiom called ""aliases xor mutable"", meaning that passing a mutable value (or pointer) over a channel signals a transfer of ownership over the value to its receiver.: 155  The gc toolchain has an optional data race detector that can check for unsynchronized access to shared memory during runtime since version 1.1, additionally a best-effort race detector is also included by default since version 1.6 of the gc runtime for access to the map data type.

Binaries
The linker in the gc toolchain creates statically linked binaries by default; therefore all Go binaries include the Go runtime.

Omissions
Go deliberately omits certain features common in other languages, including (implementation) inheritance, assertions, pointer arithmetic, implicit type conversions, untagged unions, and tagged unions. The designers added only those facilities that all three agreed on.Of the omitted language features, the designers explicitly argue against assertions and pointer arithmetic, while defending the choice to omit type inheritance as giving a more useful language, encouraging instead the use of interfaces to achieve dynamic dispatch and composition to reuse code. Composition and delegation are in fact largely automated by struct embedding; according to researchers Schmager et al., this feature ""has many of the drawbacks of inheritance: it affects the public interface of objects, it is not fine-grained (i.e, no method-level control over embedding), methods of embedded objects cannot be hidden, and it is static"", making it ""not obvious"" whether programmers will overuse it to the extent that programmers in other languages are reputed to overuse inheritance.Exception handling was initially omitted in Go due to lack of a ""design that gives value proportionate to the complexity"". An exception-like panic/recover mechanism that avoids the usual try-catch control structure was proposed and released in the March 30, 2010 snapshot. The Go authors advise using it for unrecoverable errors such as those that should halt an entire program or server request, or as a shortcut to propagate errors up the stack within a package. Across package boundaries, Go includes a canonical error type, and multi-value returns using this type are the standard idiom.

Style
The Go authors put substantial effort into influencing the style of Go programs:

Indentation, spacing, and other surface-level details of code are automatically standardized by the gofmt tool. It uses tabs for indentation and blanks for alignment. Alignment assumes that an editor is using a fixed-width font. golint does additional style checks automatically, but has been deprecated and archived by the Go maintainers.
Tools and libraries distributed with Go suggest standard approaches to things like API documentation (godoc), testing (go test), building (go build), package management (go get), and so on.
Go enforces rules that are recommendations in other languages, for example banning cyclic dependencies, unused variables or imports, and implicit type conversions.
The omission of certain features (for example, functional-programming shortcuts like map and Java-style try/finally blocks) tends to encourage a particular explicit, concrete, and imperative programming style.
On day one the Go team published a collection of Go idioms, and later also collected code review comments, talks, and official blog posts to teach Go style and coding philosophy.

Tools
The main Go distribution includes tools for building, testing, and analyzing code:

go build, which builds Go binaries using only information in the source files themselves, no separate makefiles
go test, for unit testing and microbenchmarks as well as fuzzing
go fmt, for formatting code
go install, for retrieving and installing remote packages
go vet, a static analyzer looking for potential errors in code
go run, a shortcut for building and executing code
godoc, for displaying documentation or serving it via HTTP
gorename, for renaming variables, functions, and so on in a type-safe way
go generate, a standard way to invoke code generators
go mod, for creating a new module, adding dependencies, upgrading dependencies, etc.It also includes profiling and debugging support, fuzzing capabilities to detect bugs, runtime instrumentation (for example, to track garbage collection pauses), and a data race detector.
Another tool maintained by the Go team but is not included in Go distributions is gopls, a language server that provides IDE features such as intelligent code completion to Language Server Protocol compatible editors.An ecosystem of third-party tools adds to the standard distribution, such as gocode, which enables code autocompletion in many text editors, goimports, which automatically adds/removes package imports as needed, and errcheck, which detects code that might unintentionally ignore errors.

Examples
Hello world
where ""fmt"" is the package for formatted I/O, similar to C's C file input/output.

Concurrency
The following simple program demonstrates Go's concurrency features to implement an asynchronous program. It launches two lightweight threads (""goroutines""): one waits for the user to type some text, while the other implements a timeout. The select statement waits for either of these goroutines to send a message to the main routine, and acts on the first message to arrive (example adapted from David Chisnall's book).: 152

Testing
The testing package provides support for automated testing of go packages. Target function example:

Test code (note that assert keyword is missing in Go; tests live in <filename>_test.go at the same package):

It is possible to run tests in parallel.

Web app
The net/http package provides support for creating web applications.
This example would show ""Hello world!"" when localhost:8080 is visited.

Applications
Go has found widespread adoption in various domains due to its robust standard library and ease of use.Popular applications include: Caddy, a web server that automates the process of setting up HTTPS, Docker, which provides a platform for containerization, aiming to ease the complexities of software development and deployment, Kubernetes, which automates the deployment, scaling, and management of containerized applications, CockroachDB, a distributed SQL database engineered for scalability and strong consistency, and Hugo, a static site generator that prioritizes speed and flexibility, allowing developers to create websites efficiently.For further examples, please also see related query to Wikidata

Reception
The interface system, and the deliberate omission of inheritance, were praised by Michele Simionato, who likened these characteristics to those of Standard ML, calling it ""a shame that no popular language has followed [this] particular route"".Dave Astels at Engine Yard wrote in 2009:
Go is extremely easy to dive into. There are a minimal number of fundamental language concepts and the syntax is clean and designed to be clear and unambiguous.
Go is still experimental and still a little rough around the edges.
Go was named Programming Language of the Year by the TIOBE Programming Community Index in its first year, 2009, for having a larger 12-month increase in popularity (in only 2 months, after its introduction in November) than any other language that year, and reached 13th place by January 2010, surpassing established languages like Pascal. By June 2015, its ranking had dropped to below 50th in the index, placing it lower than COBOL and Fortran. But as of January 2017, its ranking had surged to 13th, indicating significant growth in popularity and adoption. Go was again awarded TIOBE Programming Language of the Year in 2016.Bruce Eckel has stated:
The complexity of C++ (even more complexity has been added in the new C++), and the resulting impact on productivity, is no longer justified. All the hoops that the C++ programmer had to jump through in order to use a C-compatible language make no sense anymore -- they're just a waste of time and effort. Go makes much more sense for the class of problems that C++ was originally intended to solve.
A 2011 evaluation of the language and its gc implementation in comparison to C++ (GCC), Java and Scala by a Google engineer found:

Go offers interesting language features, which also allow for a concise and standardized notation. The compilers for this language are still immature, which reflects in both performance and binary sizes.
The evaluation got a rebuttal from the Go development team. Ian Lance Taylor, who had improved the Go code for Hundt's paper, had not been aware of the intention to publish his code, and says that his version was ""never intended to be an example of idiomatic or efficient Go""; Russ Cox then optimized the Go code, as well as the C++ code, and got the Go code to run almost as fast as the C++ version and more than an order of magnitude faster than the code in the paper.
Go's nil combined with the lack of algebraic types leads to difficulty handling failures and base cases.
Go does not allow an opening brace to appear on its own line, which forces all Go programmers to use the same brace style.
Go has been criticized for focusing on simplicity of implementation rather than correctness and flexibility; as an example, the language uses POSIX file semantics on all platforms, and therefore provides incorrect information on platforms such as Windows (which do not follow the aforementioned standard).
A study showed that it is as easy to make concurrency bugs with message passing as with shared memory, sometimes even more.

Naming dispute
On November 10, 2009, the day of the general release of the language, Francis McCabe, developer of the Go! programming language (note the exclamation point), requested a name change of Google's language to prevent confusion with his language, which he had spent 10 years developing. McCabe raised concerns that ""the 'big guy' will end up steam-rollering over"" him, and this concern resonated with the more than 120 developers who commented on Google's official issues thread saying they should change the name, with some even saying the issue contradicts Google's motto of: Don't be evil.
On October 12, 2010, the filed public issue ticket was closed by Google developer Russ Cox (@rsc) with the custom status ""Unfortunate"" accompanied by the following comment: ""There are many computing products and services named Go. In the 11 months since our release, there has been minimal confusion of the two languages.""

See also
Fat pointer
Comparison of programming languages

Notes
References
Further reading
External links

Official website",25039021,https://en.wikipedia.org/wiki/Go_(programming_language)
Golo (programming language),"Golo is computer software, a programming language for the Java virtual machine (JVM). It is simple, with dynamic, weak typing. It was created in 2012 as part of the research activities of the DynaMid group of the Centre of Innovation in Telecommunications and Integration of service (CITI) Laboratory at Institut national des sciences appliquées de Lyon (INSA). It is distributed as free and open-source software under the Eclipse Public License 2.0.","Golo is computer software, a programming language for the Java virtual machine (JVM). It is simple, with dynamic, weak typing. It was created in 2012 as part of the research activities of the DynaMid group of the Centre of Innovation in Telecommunications and Integration of service (CITI) Laboratory at Institut national des sciences appliquées de Lyon (INSA). It is distributed as free and open-source software under the Eclipse Public License 2.0.

History
It has been built as a showcase on how to build a language runtime with invokedynamic. Golo is largely interoperable with the programming language Java and other JVM languages (e.g., numeric types are boxing classes from java.lang, and collection literals leverage java.util classes), that runs on the JVM.
In June 2015, Golo became an official Eclipse Foundation project. The project was terminated in September 2022.

Technical details
The language features have been initially designed around the abilities of invokedynamic – JSR 292 that appeared in Java SE 7. Golo uses ahead-of-time compilation of bytecode. While the bytecode remains stable over a program execution, the invokedynamic-based reconfigurable call sites support the adaptive dispatch mechanisms put in place for helping the HotSpot just-in-time compiler (JIT) to extract reasonable performance.

Publications
Baptiste Maingret, Frédéric Le Mouël, Julien Ponge, Nicolas Stouls, Jian Cia and Yannick Loiseau. Towards a Decoupled Context-Oriented Programming Language for the Internet of Things. To appear in the 7th International Workshop on Context-Oriented Programming hosted at ECOOP 2015. Prague, Czech Republic. July 2015.
Julien Ponge, Frédéric Le Mouël, Nicolas Stouls, Yannick Loiseau. Opportunities for a Truffle-based Golo Interpreter. Technical report arXiv:1505.06003 (cs.PL) and HAL-INRIA deposit
Julien Ponge, Frédéric Le Mouël and Nicolas Stouls. Golo, a Dynamic, Light and Efficient Language for Post-Invokedynamic JVM. In Procs. of PPPJ'13. Stuttgart, Germany. September 2013. DOI link. HAL-INRIA deposit. Slides.

See also
List of JVM languages

References
""Golo – A Lightweight Dynamic Language for the JVM"". Archived from the original on 3 July 2015. Retrieved 2 July 2015.
""Golo nominated for JAX Awards 2014"". Retrieved 2 July 2015.
""Golo entry at JAX Awards 2014"". Retrieved 2 July 2015.
""Golo mentioned at the Netbeans Weekly News Issue 587"". Archived from the original on 2015-07-04. Retrieved 2 July 2015.]

External links
Official website
Golo at GitHub repository
Golo incubation page at Eclipse.org
Eclipse integration for Golo
Netbeans module to support Golo",47051765,https://en.wikipedia.org/wiki/Golo_(programming_language)
GOLOG,GOLOG is a high-level logic programming language for the specification and execution of complex actions in dynamical domains. It is based on the situation calculus. It is a first-order logical language for reasoning about action and change. GOLOG was developed at the University of Toronto.,"GOLOG is a high-level logic programming language for the specification and execution of complex actions in dynamical domains. It is based on the situation calculus. It is a first-order logical language for reasoning about action and change. GOLOG was developed at the University of Toronto.

History
The concept of situation calculus on which the GOLOG programming language is based was first proposed by John McCarthy in 1963.

Language
A GOLOG interpreter automatically maintains a direct characterization of the dynamic world being modeled, on the basis of user supplied axioms about preconditions, effects of actions and the initial state of the world. This allows the application to reason about the condition of the world and consider the impacts of different potential actions before focusing on a specific action.Golog is a logic programming language and is very different from conventional programming languages. A procedural programming language like C defines the execution of statements in advance. The programmer creates a subroutine which consists of statements, and the computer executes each statement in a linear order. In contrast, fifth-generation programming languages like Golog are working with an abstract model with which the interpreter can generate the sequence of actions. The source code defines the problem and it is up to the solver to find the next action. This approach can facilitate the management of complex problems from the domain of robotics.
A Golog program defines the state space in which the agent is allowed to operate. A path in the symbolic domain is found with state space search. To speed up the process, Golog programs are realized as hierarchical task networks.Apart from the original Golog language, there are some extensions available. The ConGolog language provides concurrency and interrupts. Other dialects like IndiGolog and Readylog were created for real time applications in which sensor readings are updated on the fly.

Uses
Golog has been used to model the behavior of autonomous agents. In addition to a logic-based action formalism for describing the environment and the effects of basic actions, they enable the construction of complex actions using typical programming language constructs.
It is also used for applications in high level control of robots and industrial processes, virtual agents, discrete event simulation etc. It can be also used to develop BDI (Belief Desire Intention)-style agent systems.

Planning and scripting
In contrast to the Planning Domain Definition Language, Golog supports planning and scripting as well. Planning means that a goal state in the world model is defined, and the solver brings a logical system into this state. Behavior scripting implements reactive procedures, which are running as a computer program.For example, suppose the idea is to authoring a story. The user defines what should be true at the end of the plot. A solver gets started and applies possible actions to the current situation until the goal state is reached. The specification of a goal state and the possible actions are realized in the logical world model.In contrast, a hardwired reactive behavior doesn't need a solver but the action sequence is provided in a scripting language. The Golog interpreter, which is written in Prolog, executes the script and this will bring the story into the goal state.


== References ==",62806829,https://en.wikipedia.org/wiki/GOLOG
Gosu (programming language),"Gosu is a statically typed general-purpose programming language that runs on the Java Virtual Machine. Its influences include Java, C#, and ECMAScript.  Development of Gosu began in 2002 internally for Guidewire Software, and the language saw its first community release in 2010 under the Apache 2 license.Gosu can serve as a scripting language, having free-form Program types (.gsp files) for scripting as well as statically verified Template files (.gst files).  Gosu can optionally execute these and all other types directly from source without precompilation, which also distinguishes it from other static languages.","Gosu is a statically typed general-purpose programming language that runs on the Java Virtual Machine. Its influences include Java, C#, and ECMAScript.  Development of Gosu began in 2002 internally for Guidewire Software, and the language saw its first community release in 2010 under the Apache 2 license.Gosu can serve as a scripting language, having free-form Program types (.gsp files) for scripting as well as statically verified Template files (.gst files).  Gosu can optionally execute these and all other types directly from source without precompilation, which also distinguishes it from other static languages.

History
Gosu began in 2002 as a scripting language called GScript at Guidewire Software. It has been described as a Java variant that attempts to make useful improvements while retaining the fundamental utility and compatibility with Java. It was used to configure business logic in Guidewire's applications and was more of a simple rule definition language. In its original incarnation it followed ECMAScript guidelines.  Guidewire enhanced the scripting language over the next 8 years, and released Gosu 0.7 beta to the community in November 2010. The 0.8 beta was released in December 2010, and 0.8.6 beta was released in mid-2011 with additional typeloaders, making Gosu capable of loading XML schema definition files and XML documents as native Gosu types. The latest version is 1.10, released in January 2016, along with a new IntelliJ IDEA editor plugin.
Guidewire continues to support and use Gosu extensively within InsuranceSuite applications. Guidewire has decided to freeze the development of new Gosu programming language constructs at this time. Guidewire continues to evolve InsuranceSuite through RESTful APIs and Integration Frameworks that can be accessed using Java.

Philosophy
Gosu language creator and development lead, Scott McKinney, emphasizes pragmatism, found in readability and discoverability, as the overriding principle that guides the language's design. For instance, Gosu's rich static type system is a necessary ingredient toward best of breed tooling via static program analysis, rich parser feedback, code completion, deterministic refactoring, usage analysis, navigation, and the like.

Syntax and semantics
Gosu follows a syntax resembling a combination of other languages.  For instance, declarations follow more along the lines of Pascal with name-first grammar.  Gosu classes can have functions, fields, properties, and inner classes as members.  Nominal inheritance and composition via delegation are built into the type system as well as structural typing similar to the Go programming language.
Gosu supports several file types:

Class (.gs files)
Program (.gsp files)
Enhancement (*.gsx files)
Template (*.gst files)In addition to standard class types Gosu supports enums, interfaces, structures, and annotations.

Program files facilitate Gosu as a scripting language.  For example, Gosu's Hello, World! is a simple one-line program:
Gosu classes are also executable a la Java:

Data types
A unique feature of Gosu is its Open Type System, which allows the language to be easily extended to provide compile-time checking and IDE awareness of information that is typically checked only at runtime in most other languages. Enhancements let you add additional functions and properties to other types, including built-in Java types such as String, List, etc.  This example demonstrates adding a print() function to java.lang.String.Now you can tell a String to print itself:The combination of closures and enhancements provide a powerful way of coding with Collections.  The overhead of Java streams is unnecessary with Gosu:

Uses
This general-purpose programming language is used primarily in Guidewire Software's commercial products.

References
Further reading
Gross, Carson (2011-07-18). ""Language Features As A Library: Using Gosu's Open Type System With External DSLs"" (PDF). JVM Language Summit 2011. Oracle. Video

External links
Official website
Source code repository",29539307,https://en.wikipedia.org/wiki/Gosu_(programming_language)
Haggis (programming language),"Haggis is a high-level reference programming language used primarily to examine computing science for Scottish pupils taking SQA courses on the subject. Haggis is used as a tool to bridge the gap between pseudocode and typical computer programming.Haggis is not based on any one language but a mixture that is intended to allow a pupil familiar with any of the many languages used in classrooms to easily understand the syntactic construct being used in an example. It has multiple programming paradigms of functional, imperative and object-oriented to suit this purpose.There are three separate language definitions, one for each level at which computing is assessed by the SQA; these are proper subsets of each other, so for example any program contained by the National 5 level language is also well-defined at Higher and Advanced Higher levels. Higher includes the definition of procedures and functions and the use of record types and files, while Advanced Higher includes object-orientation.
Online Haggis interpreters have been developed to provide a way for examiners and teachers to check their programs are correctly defined and behave as expected.","Haggis is a high-level reference programming language used primarily to examine computing science for Scottish pupils taking SQA courses on the subject. Haggis is used as a tool to bridge the gap between pseudocode and typical computer programming.Haggis is not based on any one language but a mixture that is intended to allow a pupil familiar with any of the many languages used in classrooms to easily understand the syntactic construct being used in an example. It has multiple programming paradigms of functional, imperative and object-oriented to suit this purpose.There are three separate language definitions, one for each level at which computing is assessed by the SQA; these are proper subsets of each other, so for example any program contained by the National 5 level language is also well-defined at Higher and Advanced Higher levels. Higher includes the definition of procedures and functions and the use of record types and files, while Advanced Higher includes object-orientation.
Online Haggis interpreters have been developed to provide a way for examiners and teachers to check their programs are correctly defined and behave as expected.

Overview
In Scotland, school-level computing qualifications are awarded by the Scottish Qualifications Authority. A decision was made for computing courses that a single choice of programming language for examination should not be mandated: this allows teachers to choose languages as appropriate to context. This however leaves the issue of how to examine programming, especially in the light of recent educational research which encourages the teaching of reading and understanding code as a core discipline, which should therefore be examined.
Initially, a form of pseudocode language emerged among examiners, to avoid any such language dependency. However this led to the very undesirable situation that, while students are being taught about the importance of rigour of terms in a programming language, they can look back over previous years of examinations and see non-standard use of coding which varies  from example to example.
Haggis is the solution to this. Haggis is a formally-defined reference language, but its purpose is to examine programming, not to write programs. A further requirement is that it must not be a mandatory part of the curriculum, so students who have never previously seen the language should be able to read it. These aspects, along with an attempt to conform as far as possible with the evolved pseudocode style, directed the specification of the language. So, while Haggis is in fact a programming language (even although, in general, not all Haggis programs are executable), it is not intended as a language in which to write programs.
These concepts are more fully explained in an academic paper.

History
Haggis was commissioned by the SQA in 2010 to provide a uniform syntax and form in which to present questions to pupils in assessments. Its present form was jointly developed by Quintin Cutts (University of Glasgow), Greg Michaelson (Heriot Watt University) and Richard Connor (University of Strathclyde). The aim of developing Haggis was to emphasise the core idea of ensuring pupils could view  code and demonstrate their understanding of its behaviour, in order to develop their computational thinking and programming skills.Haggis was first introduced into the Computing Science examinations as part of the Scottish Government's Curriculum for Excellence development programme in the 2013/2014 session in National 5, 2014/2015 for the new Higher courses and into the new Advanced Higher in the 2015/2016 session. Haggis was not introduced as a language to replace other languages already used in education, not was it intended that the language should be taught or used in the normal curriculum. However some teachers have adopted it as a rigorous  pseudocode form to enhance teaching delivered in another language.

Features and philosophy
Core principles
Haggis was designed with 8 core principles in mind
Not be based on any one extant programming language
Be adaptable to programming languages already taught in the Scottish Curriculum.
Provide enough complexity for Advanced Higher teaching whilst being appropriately useful for earlier teaching years.
Provide an instinctive element, e.g. variable types are self specified.
Be concise in use but open to interpretation of multiple ways to solve a problem.
Allow different constructs to have different meanings when used in certain context.
Don't visualise the non-useful elements such as Memory being allocated.

Use within education
It was designed to be both functional/sequential and object-oriented based in order to be simple and complex for National 5 / Higher students and Advanced Higher students simultaneously.Haggis was designed to allow pupils across Scotland to enhance the learning and understanding of computer programming through reading examples, and aid the step of converting from pseudocode to full programming. It was not created with the intention of asking pupils to write it in assessments but provide a uniform language in which to present code examples to students, ensuring that all pupils have a fair understanding and is not hindered by learning a different programming language different to the one exemplified in the assessment.

Syntax
Syntax and structure in Haggis are very similar to other programming languages and can be easily learned.

Reserved words
Reserved words are capitalised; this would be generally be considered ugly for a programming language, but makes the program structure clearer for a first-time reader of the language. Similarly, the language deliberately contains a great deal of syntactic redundancy.
DECLARE, FOR, WHILE, etc.

Data types
(types are normally determined by inference except where this is not possible)

Character (a single character type, from which Strings are composed)
Integer
Real (including integers)
Boolean (true or false)

Structured types
Array: Sequence of same data types.
String: Array of Character.
Record: A labelled collection of values.
Object: as defined by Class descriptors.Arrays are included at National 5 level, Records at Higher, and Objects at Advanced Higher.

Line numbers
In some examples in examination papers line numbers are used to allow easy reference; this is not a part of the language however.

Indentation
Code within other structures should be indented so it can be properly identified by the compiler and to make it easier to read for the developer and for anyone else of who may be reading the code. Once again, this is not a part of the language definition.

Comments
Comments can be made using the “#” character for every line of commented text, this can appear either at the beginning of a new line or after a piece of code.
Large blocks of text can be specified using the “<(COMMENT TEXT>” format, this is primarily implemented for educational use to provide larger context for students.

Variable names
Variable names should be written in lowercase or, if the name is complex, in lower camelCase. Camelcase is when a name is concatenated together to form one long word, however the first letter of each word (apart from the first) is capitalised.
For example, variables could be called:

number
meaningfulName

Initialisation
Initialisation allows the declaration of a new variable.

DECLARE <variable’s name> INITIALLY <value>If the type cannot be determined from the initialising value, an optional type may be included, as for example

DECLARE myArray AS ARRAY OF INTEGER INITIALLY []

Assignment
Assignment allows the user to set values to variables. The syntax is as shown.

SET <variable’s name> TO <value>If <value> is a string, it should be written within quotation marks, like this:  SET phrase TO ""maybe""
If <value> is an integer, it doesn't need quotation marks, like this: SET number TO 23

Input
Input in Haggis is similar to pseudocode in that you state the data type of the input the program is receiving and also where the input is coming from, like so: 

RECEIVE <variable that will store input> FROM <INPUT DEVICE>The optional typing for a declaration may also be used, for example

DECLARE number AS  INTEGER INITIALLY FROM KEYBOARD

Output
Outputs in Haggis can be written similarly to inputs.

SEND <variable, value or text> TO <OUTPUT DEVICE>For example:

SEND meaningfulName TO DISPLAY

Arithmetic calculations
SET is used to assign the result of calculation.
For example:

SET number TO 32*6This is another form of assignment.

Procedures / functions
A procedure is a kind of sub-program within a program. It allows the sectioning of code to make it more readable and easier to work with. You must remember to end the procedure as shown below.

PROCEDURE <Procedure ID/Name>(<Data Type> <Variable>,<Data Type> <Variable>...)
   Haggis Commands
END PROCEDURE

Operations
Haggis includes all the operations you would expect from a programming language to be able to carry out calculations and logical operations alike.
For INTEGER and REAL data typed, the following operations are possible.

“-” is subtract
“+” is add
“*” is multiply
“/” is divide
“^” is exponentFor INTEGER data types alone, the modulo is possible which is written as MOD.
Comparison operators:

“=” is equals
“≠” is inequals
“<” is less than
“>” is greater than
“≤” is less than or equal
“≥” is greater than or equalLogical operations:

“AND” is Conjunction
“OR” is Disjunction
“NOT” is Negation

Defining a class
Defining a class in Haggis uses the syntax CLASS <id> IS {<parameters>} METHODS <statements> END CLASS .
There are various methods you can declare in Haggis such as:

    CONSTRUCTOR
        The users' '''Haggis''' code will then go here.
    END CONSTRUCTOR

    FUNCTION <Function Name>(<Parameters>) RETURN <Data Type>
        The users' '''Haggis''' code will then go here.
        RETURN THIS <Class Property>
    END FUNCTION
    '''“THIS” is used to reference the current object invoking the method.'''

    PROCEDURE <Procedure Name> (<Parameters>)
        The users' '''Haggis''' code will then go here.
    END PROCEDURE

Application and uses
Haggis was originally implemented and then expected to be used in the following ways. The students would be taught how to code in a programming language that the teacher has selected. The students would then make plans in a pseudocode format in a higher level of language than the code itself. Once the students felt comfortable with writing pseudocode they would then be introduced to Haggis as it is the language used in exam texts.Haggis was implemented in this way because research has shown the ability to understand programs is essential to developing further programming skills. Courses run by the SQA (National 5 and Higher) both include outcomes that require students to have this ability. Because Haggis is so easy to understand and pick up, it has been used in exam texts. It is noted that students were and never will be asked to write any code in Haggis during an exam, they are only required to be able to read and understand it.

Problems
There have only ever been a very small number of problems with Haggis. None are to do with the language itself but more to do with the way students view it. The first is that students had no idea why they were being taught to write a completed computer program in two languages. The other is that they were mixing up the two languages that they had been taught and were often getting syntax wrong because they were being taught the two languages at the same time which was causing some minor confusion.

Observation
Haggis was observed by the creator and was found to be used in the following ways. Haggis was being used as a planning language for the computer programs that students were being asked to create. After students had been asked to refine their code through several planning stages, a final plan was made using Haggis. After this final plan is made, the Haggis code would then be transferred into a real programming language that is specified by the teacher. This method is effective in increasing students skills as mentioned earlier to give them as much preparation as possible for the exam for when they will see Haggis applied in a context.

References
External links
Quintin Cutts Web Page
SQA Online Haggis Parser",52222071,https://en.wikipedia.org/wiki/Haggis_(programming_language)
Haxe,"Haxe is a high-level cross-platform programming language and compiler that can produce applications and source code for many different computing platforms from one code-base. It is free and open-source software, released under the MIT License. The compiler, written in OCaml, is released under the GNU General Public License (GPL) version 2.
Haxe includes a set of features and a standard library supported across all platforms, like numeric data types, strings, arrays, maps, binary, reflection, maths, Hypertext Transfer Protocol (HTTP), file system and common file formats. Haxe also includes platform-specific API's for each compiler target. Kha, OpenFL and Heaps.io are popular Haxe frameworks that enable creating multi-platform content from one codebase.Haxe originated with the idea of supporting client-side and server-side programming in one language, and simplifying the communication logic between them. Code written in the Haxe language can be compiled into JavaScript, C++, Java, JVM, PHP, C#, Python, Lua and Node.js. Haxe can also directly compile SWF, HashLink, and NekoVM bytecode and also runs in interpreted mode.Haxe supports externs (definition files) that can contain type information of existing libraries to describe target-specific interaction in a type-safe manner, like C++ header files can describe the structure of existing object files. This enables to use the values defined in the files as if they were statically typed Haxe entities. Beside externs, other solutions exist to access each platform's native capabilities.
Many popular IDEs and source code editors have support available for Haxe development. No particular development environment or tool set is officially recommended by the Haxe Foundation, although VS Code, IntelliJ IDEA and HaxeDevelop have the most support for Haxe development. The core functionalities of syntax highlighting, code completion, refactoring, debugging, etc. are available to various degrees.","Haxe is a high-level cross-platform programming language and compiler that can produce applications and source code for many different computing platforms from one code-base. It is free and open-source software, released under the MIT License. The compiler, written in OCaml, is released under the GNU General Public License (GPL) version 2.
Haxe includes a set of features and a standard library supported across all platforms, like numeric data types, strings, arrays, maps, binary, reflection, maths, Hypertext Transfer Protocol (HTTP), file system and common file formats. Haxe also includes platform-specific API's for each compiler target. Kha, OpenFL and Heaps.io are popular Haxe frameworks that enable creating multi-platform content from one codebase.Haxe originated with the idea of supporting client-side and server-side programming in one language, and simplifying the communication logic between them. Code written in the Haxe language can be compiled into JavaScript, C++, Java, JVM, PHP, C#, Python, Lua and Node.js. Haxe can also directly compile SWF, HashLink, and NekoVM bytecode and also runs in interpreted mode.Haxe supports externs (definition files) that can contain type information of existing libraries to describe target-specific interaction in a type-safe manner, like C++ header files can describe the structure of existing object files. This enables to use the values defined in the files as if they were statically typed Haxe entities. Beside externs, other solutions exist to access each platform's native capabilities.
Many popular IDEs and source code editors have support available for Haxe development. No particular development environment or tool set is officially recommended by the Haxe Foundation, although VS Code, IntelliJ IDEA and HaxeDevelop have the most support for Haxe development. The core functionalities of syntax highlighting, code completion, refactoring, debugging, etc. are available to various degrees.

History
Development of Haxe began in October 2005. The first alpha version was released on November 14, 2005. Haxe 1.0 was released in April 2006, with support for Adobe Flash, JavaScript, and NekoVM programs. Support for PHP was added in 2008, and C++ was added in 2009. More platforms such as C# and Java were added with a compiler overhaul in 2012.
Haxe was developed by Nicolas Cannasse and other contributors, and was originally named haXe because it was short, simple, and ""has an X inside"", which the author asserts humorously is needed to make any new technology a success.Haxe is the successor to the open-source ActionScript 2 compiler MTASC, also built by Nicolas Cannasse and is released under the GNU General Public License version 2 or later.

Compiler
The Haxe language can compile into bytecode that can be executed directly by the virtual machines it targets. It can compile to source code in C++, JavaScript, PHP, C#, Java, Python, and Lua. Haxe also has an interpreter called eval. This same interpreter is also used compile-time to run macros, which allow modification of the abstract syntax tree (AST).
This strategy of compiling to multiple source code languages is inspired by the write once, run anywhere paradigm. It also allows the programmer to choose the best platform for the job. Typical Haxe programs run identically on all platforms, but developers can specify platform-specific code and use conditional compilation to prevent it from compiling on other platforms.
The Haxe compiler is an optimizing compiler, and uses field and function inlining, tail recursion elimination, constant folding, loop unrolling and dead code elimination (DCE) to optimize the run-time performance of compiled programs. The Haxe compiler offers opt-in null-safety, it checks compile-time for nullable values.

Targets
In Haxe, supported platforms are known as ""targets"", which consist of the following modules:

The compiler-backends that are responsible for generating the respective code.
The run-time specific APIs that go beyond the core language support (platform-targets).The following table documents platform and language support in Haxe. The Haxe language allows developers to gain access to many platform features, but Haxe is not a full featured engine, they might need frameworks that enable create content for certain platforms.

Advantages of Haxe
Ability to target multiple platforms and devices using the same language
Ability to use strictly-typed code
Ability to use macros (syntax transformation) which can be done with Haxe language
Added language features such as extension methods and functional programming
The run-time performance of Haxe programs is at comparable speed to handwritten sources.

Language
Haxe is a general-purpose language supporting object-oriented programming, generic programming, and various functional programming constructs. Features such as iterations, exceptions, and code reflection are also built-in functions of the language and libraries. Unusual among programming languages, Haxe contains a type system which is both strong and dynamic. The compiler will check types implicitly using type inferencing and give compile-time errors, but it also enables the programmer to bypass type-checking and rely on the target platform's dynamic type-handling. All of the native target APIs can be used.

Type system
Haxe has a sophisticated and flexible type system. The type kinds it offers are classes, interfaces, function-method types, anonymous types, algebraic data types (called enum in Haxe), and abstract types. Parametric polymorphism is possible with classes, algebraic types and function types, giving the language support for generic programming based on type erasure. This includes support for variance in polymorphic functions, although not in type constructors.
The type system is static unless annotations for dynamic typing are present, for use with targets that support them. Type checking follows nominal typing with the exception of anonymous types where structural typing is used instead. Finally, type inference is supported, allowing for variable declarations without type annotations.

Modules and namespaces
All Haxe code is organized in modules, which are addressed using paths. In essence, each .hx file represents a module which may contain several types. For example, to create the type A in the package my.pack as shown, the folder structure should be my\pack and the file could be A.hx in the folder pack.

In other modules, other types can be imported by putting import statements below the package definition, e.g. import my.pack.A;
A module can contain multiple types, such as the following. It is possible to import one type at a time from that module, using import my.pack2.A;. A type may be private, in which case only its containing module can access it.

Classes
Classes (keyword class) in Haxe are similar to those in Java or TypeScript. Their fields can be either methods, variables, or properties, each static or per instance respectively. Haxe supports the accessors public and private, and more advanced methods for access control that are denoted using annotations. Methods and static constant variables can be inlined using the keyword inline. Fields can be marked as final to declare a constant that must be initialized immediately or in the constructor and cannot be written to, in case of function final will mark as non-overridable in subclasses.
Interfaces in Haxe are very similar to those in, for example, Java.

Generics
Haxe supports generic programming. The following is an example of the identity function.

Enumerated types
Enumerated types are an important feature of the language; they can have type parameters and be recursive. They provide basic support for algebraic data types, allowing the inclusion of product types, in a fashion similar to Haskell and ML. A switch expression can apply pattern matching to an enum value, allowing for elegant solutions to complex programming problems:

Examples of parametric enum types are the Haxe standard library types Option and Either:

Haxe also supports generalized algebraic data types (GADTs).

Anonymous types
Anonymous types are defined by denoting their structure explicitly, using a syntax that follows the mathematical record-based representation of a type. They can be used to implement structural typing for function arguments (see below), and can be given an alias with the keyword typedef:

Function types
Functions are first-class values in Haxe. Their type is denoted by using arrows between argument types, and between the argument type(s) and return type, as common in many functional languages. However, unlike in prominent examples like Haskell or the ML language family, not all functions are unary functions (functions with one argument only), and in Haxe, functions can't be partially applied per default. Thus, the following type signatures have different semantics than in the aforementioned languages. The type F1 is a function that takes a String as arguments and returns a value of type Float.
Types F1 and F2 denote the same type, except that F2 uses labelled parameter, which is useful for completion and documentation.
Types F4 and F5 denote the same type. Both are binary functions that return a binary function of type F3. For F5 the syntax to declare a function type within a function type is used.

Anonymous functions
Abstract types
A relatively new addition to the Haxe type system is a concept termed abstract types. As used in Haxe, this refers to something different from a conventional abstract type. They are used to make conversions between types implicit, allowing reuse of existing types for specific purposes, like implementing types for units of measurement. This greatly reduces the risk of mixing up values of the same underlying type, but with different meanings (e.g., miles vs. km).
The following example assumes that the metric system is the default, while a conversion to miles is needed for legacy data. Haxe can automatically convert miles to kilometers, but not the reverse.

As the example shows, no explicit conversion is needed for the assignment ""km = one100Miles;"" to do the right thing.
Abstract types are entirely a compile-time feature of Haxe and do not exist at all at program runtime. As an example, both variables using abstract types above Mile and Kilometer will be of the type Float at runtime.

Structural typing
In many functional programming languages, structural typing plays a major role. Haxe employs it in the presence of anonymous types, using the nominative typing of object-oriented programming, when only named types are involved. Anonymous types in Haxe are analogous to the implicit interfaces of the language Go as to typing. In contrast with Go interfaces, it is possible to construct a value using an anonymous type.

Internal architecture
Compiler
The Haxe compiler is divided into one frontend and multiple backends. The frontend creates an abstract syntax tree (AST) from the source code, and performs type checking, macro expansion, and optimization on the AST. The various backends translate the processed AST into source code or generate bytecode, depending on their target.
The compiler is written in OCaml. It can be run in server-mode to provide code completion for integrated development environments (IDEs) and maintain a cache, to further speed compiling.

See also
Dart (programming language)
Nim (programming language)
Opa (programming language)
Clojure
CoffeeScript
TypeScript
Scala (programming language)
Vala (programming language)
Emscripten
OpenFL

References
External links
Official website",5404706,https://en.wikipedia.org/wiki/Haxe
Hermes (programming language),"Hermes
is a language for distributed programming
that was developed at IBM's Thomas J. Watson Research Center from 1986 through 1992,
with an open-source compiler and run-time system.
Hermes' primary features included:
Language support of processes and interprocess communication.
Compile-time verification that operations use initialized data.
Representation-independent data aggregates called tables.
Lack of pointers.It used typestate analysis to check variables transitions errors, to rule out some semantically non meaningful transitions from one state to another (i.e. starting from a value, some sequences of operations on a variable are nonsensical), of which reading an uninitialized variable is a special case. In this role of compile-time checking of data initialization is similar to definite assignment analysis performed by Java, Cyclone and C#.
Hermes and its predecessor, NIL (Network Implementation Language), were the earliest programming languages supporting this form of initialization checking.
Typestate was actually used more extensively, to generate compiler-inserted ""delete"" operations.


== References ==","Hermes
is a language for distributed programming
that was developed at IBM's Thomas J. Watson Research Center from 1986 through 1992,
with an open-source compiler and run-time system.
Hermes' primary features included:
Language support of processes and interprocess communication.
Compile-time verification that operations use initialized data.
Representation-independent data aggregates called tables.
Lack of pointers.It used typestate analysis to check variables transitions errors, to rule out some semantically non meaningful transitions from one state to another (i.e. starting from a value, some sequences of operations on a variable are nonsensical), of which reading an uninitialized variable is a special case. In this role of compile-time checking of data initialization is similar to definite assignment analysis performed by Java, Cyclone and C#.
Hermes and its predecessor, NIL (Network Implementation Language), were the earliest programming languages supporting this form of initialization checking.
Typestate was actually used more extensively, to generate compiler-inserted ""delete"" operations.


== References ==",24136948,https://en.wikipedia.org/wiki/Hermes_(programming_language)
Io (programming language),"Io is a pure object-oriented programming language inspired by Smalltalk, Self, Lua, Lisp, Act1, and NewtonScript. Io has a prototype-based object model similar to the ones in Self and NewtonScript, eliminating the distinction between instance and class. Like Smalltalk, everything is an object and it uses dynamic typing. Like Lisp, programs are just data trees. Io uses actors for concurrency.
Remarkable features of Io are its minimal size and openness to using external code resources.  Io is executed by a small, portable virtual machine.","Io is a pure object-oriented programming language inspired by Smalltalk, Self, Lua, Lisp, Act1, and NewtonScript. Io has a prototype-based object model similar to the ones in Self and NewtonScript, eliminating the distinction between instance and class. Like Smalltalk, everything is an object and it uses dynamic typing. Like Lisp, programs are just data trees. Io uses actors for concurrency.
Remarkable features of Io are its minimal size and openness to using external code resources.  Io is executed by a small, portable virtual machine.

History
The language was created by Steve Dekorte in 2002, after trying to help a friend, Dru Nelson, with his language, Cel. He found out that he really didn't know much about how languages worked, and set out to write a tiny language to understand the problems better.

Philosophy
Io's goal is to explore conceptual unification and dynamic languages, so the tradeoffs tend to favor simplicity and flexibility over performance.

Features
Pure object-oriented based on prototypes
Code-as-data / homoiconic
Lazy evaluation of function parameters
Higher-order functions
Introspection, reflection and metaprogramming
Actor-based concurrency
Coroutines
Exception handling
Incremental garbage collecting supporting weak links
Highly portable
DLL/shared library dynamic loading on most platforms
Small virtual machine

Syntax
In its simplest form, it is composed of a single identifier:

Assuming the above doStuff is a method, it is being called with zero arguments and as a result, explicit parentheses are not required.
If doStuff had arguments, it would look like this:

Io is a message passing language, and since everything in Io is a message (excluding comments), each message is sent to a receiver. The above example demonstrates this well, but not fully. To describe this point better, let's look at the next example:

The above example demonstrates message passing in Io; the ""version"" message is sent to the ""System"" object.
Operators are a special case where the syntax is not as cut-and-dried as the above examples. The Io parser intercepts a set of operators defined by the interpreter, and translates them to method calls. For example, the following:

translates to:

All operators in Io are methods; the fact that they do not require explicit parentheses is a convenience. As you can see, there is also a little bit of operator precedence happening here, and the precedence levels are the same as with the C precedence levels.

Methods and blocks
In Io there are two ways of creating anonymous functions: methods and blocks. Between them, they are almost identical except for scope. While blocks have lexical scope, methods have dynamic scope.
Both method and block are higher-order functions.

Examples
The ubiquitous Hello world program:

New objects are created by cloning objects. In Io specifically, a new, empty object is created and only the differences between it and its parent are stored within the new object; this behavior is known as differential inheritance. An example of this behavior is shown:

A simple non-recursive factorial function, in Io:

Because assignment of res * i to res is the last action taken, the function implicitly returns the result and so an explicit return expression is not needed. The above demonstrates the usage of ranges, and doesn't use a for() loop, which would be faster.

References
External links
Io home page
Io at Synrc Research Center
Io at Curlie
Jasmine.Io BDD Testing Framework for Io",323340,https://en.wikipedia.org/wiki/Io_(programming_language)
Janus (time-reversible computing programming language),"Janus is a time-reversible programming language written at Caltech in 1982. The operational semantics of the language were formally specified, together with a program inverter and an invertible self-interpreter, in 2007 by Tetsuo Yokoyama and Robert Glück. A Janus inverter and interpreter is made freely available by the TOPPS research group at DIKU. Another Janus interpreter was implemented in Prolog in 2009. An optimizing compiler has been developed in the RC3 research group. The below summarises the language presented in the 2007 paper.Janus is a structured imperative programming language that operates on a global store without heap allocation and does not support dynamic data structures. As a reversible programming language, Janus performs deterministic computations in both forward and backward directions. An extension of Janus features procedure parameters and local variable declarations (local-delocal). Additionally, other variants of Janus support dynamic data structures such as lists.","Janus is a time-reversible programming language written at Caltech in 1982. The operational semantics of the language were formally specified, together with a program inverter and an invertible self-interpreter, in 2007 by Tetsuo Yokoyama and Robert Glück. A Janus inverter and interpreter is made freely available by the TOPPS research group at DIKU. Another Janus interpreter was implemented in Prolog in 2009. An optimizing compiler has been developed in the RC3 research group. The below summarises the language presented in the 2007 paper.Janus is a structured imperative programming language that operates on a global store without heap allocation and does not support dynamic data structures. As a reversible programming language, Janus performs deterministic computations in both forward and backward directions. An extension of Janus features procedure parameters and local variable declarations (local-delocal). Additionally, other variants of Janus support dynamic data structures such as lists.

Syntax
We specify the syntax of Janus using Backus–Naur form.
A Janus program is a sequence of one or more variable declarations, followed by a sequence of one or more procedure declarations:

Note, Janus as specified in the 2007 paper, allows zero or more variables, but a program that starts with an empty store, produces an empty store. A program that does nothing is trivially invertible, and not interesting in practice.
A variable declaration defines either a variable or a one-dimensional array:

Note, variable declarations carry no type information. This is because all values (and all constants) in Janus are non-negative 32-bit integers, so all values are between 0 and 232 − 1 = 4294967295. Note however, that the Janus interpreter hosted by TOPPS uses regular two's complement 32-bit integers, so all values there are between −231 = −2147483648 and 231 − 1 = 2147483647. All variables are initialized to the value 0.
There are no theoretical bounds to the sizes of arrays, but the said interpreter demands a size of at least 1.A procedure declaration consists of the keyword procedure, followed by a unique procedure identifier and a statement:

The entry point of a Janus program is a procedure named main. If no such procedure exists, the last procedure in the program text is the entry point.
A statement is either an assignment, a swap, an if-then-else, a loop, a procedure call, a procedure uncall, a skip, or a sequence of statements:

For assignments to be reversible, it is demanded that the variable on the left-hand side does not appear in the expressions on either side of the assignment. (Note, array cell assignment has an expression on both sides of the assignment.)
A swap (<x> ""<=>"" <x>) is trivially reversible.
For conditionals to be reversible, we provide both a test (the <e> after ""if"") and an assertion (the <e> after ""fi""). The semantics is that the test must hold before the execution of the then-branch, and the assertion must hold after it. Conversely, the test must not hold before the execution of the else-branch, and the assertion must not hold after it. In the inverted program, the assertion becomes the test, and the test becomes the assertion. (Since all values in Janus are integers, the usual C-semantics that 0 indicates false are employed.)
For loops to be reversible, we similarly provide an assertion (the <e> after ""from"") and a test (the <e> after ""until""). The semantics is that the assertion must hold only on entry to the loop, and the test must hold only on exit from the loop. In the inverted program, the assertion becomes the test, and the test becomes the assertion. An additional <e> after ""loop"" allows to perform work after the test is evaluated to false. The work should ensure that the assertion is false subsequently.
A procedure call executes the statements of a procedure in a forward direction. A procedure uncall executes the statements of a procedure in the backward direction. There are no parameters to procedures, so all variable passing is done by side-effects on the global store.
An expression is a constant (integer), a variable, an indexed variable, or an application of a binary operation:

The constants in Janus (and the Janus interpreter hosted by TOPPS) have already been discussed above.
A binary operator is one of the following, having semantics similar to their C counterparts:

The modification operators are a subset of the binary operators such that for all v, λv′.⊕(v′,v){\displaystyle \lambda v'.\oplus \left(v',v\right)} is a bijective function, and hence invertible, where ⊕{\displaystyle \oplus } is a modification operator:

The inverse functions are ""-"", ""+"", and ""^"", respectively.
The restriction that the variable assigned to does not appear in an expression on either side of the assignment allows us to prove that the inference system of Janus is forward and backward deterministic.

Semantics
The language Janus was initially conceived at Caltech in 1982. Subsequent work formalized the language semantics in the form of natural semantics and the denotational semantics. The semantics of purely reversible programming languages can also be treated reversibly at the meta level.

Example
We write a Janus procedure fib to find the n-th Fibonacci number, for n>2, i=n, x1=1, and x2=1:

procedure fib
    from i = n
    do
        x1 += x2
        x1 <=> x2
        i -= 1
    until i = 2

Upon termination, x1 is the (n−1)-th Fibonacci number and x2 is the nth Fibonacci number. i is an iterator variable that goes from n to 2. As i is decremented in every iteration, the assumption (i = n) is only true prior to the first iteration. The test is (i = 2) is only true after the last iteration of the loop (assuming n > 2).
Assuming the following prelude to the procedure, we end up with the 4th Fibonacci number in x2:

i n x1 x2
procedure main
    n += 4
    i += n
    x1 += 1
    x2 += 1
    call fib

Note, our main would have to do a bit more work if we were to make it handle n≤2, especially negative integers.
The inverse of fib is:

procedure fib
    from  i = 2
    do
        i += 1
        x1 <=> x2
        x1 -= x2
    loop
    until i = n

As you can see, Janus programs can be transformed by local inversion, where the loop test and assertion are swapped, the order of statements is reversed, and every statement in the loop is itself reversed. The inverse program can be used to find n when x1 is the (n-1)th and x2 is the nth Fibonacci number.


== References ==",50304039,https://en.wikipedia.org/wiki/Janus_(time-reversible_computing_programming_language)
Java (programming language),"Java is a high-level, class-based, object-oriented programming language that is designed to have as few implementation dependencies as possible. It is a general-purpose programming language intended to let programmers write once, run anywhere (WORA), meaning that compiled Java code can run on all platforms that support Java without the need to recompile. Java applications are typically compiled to bytecode that can run on any Java virtual machine (JVM) regardless of the underlying computer architecture. The syntax of Java is similar to C and C++, but has fewer low-level facilities than either of them. The Java runtime provides dynamic capabilities (such as reflection and runtime code modification) that are typically not available in traditional compiled languages. 
Java gained popularity shortly after its release, and has been a very popular programming language since then. Java was the third most popular programming language in 2022 according to GitHub. Although still widely popular, there has been a gradual decline in use of Java in recent years with other languages using JVM gaining popularity.Java was originally developed by James Gosling at Sun Microsystems. It was released in May 1995 as a core component of Sun's Java platform. The original and reference implementation Java compilers, virtual machines, and class libraries were originally released by Sun under proprietary licenses. As of May 2007, in compliance with the specifications of the Java Community Process, Sun had relicensed most of its Java technologies under the GPL-2.0-only license. Oracle offers its own HotSpot Java Virtual Machine, however the official reference implementation is the OpenJDK JVM which is free open-source software and used by most developers and is the default JVM for almost all Linux distributions.
As of March 2024, Java 22 is the latest version. Java 8, 11, 17, and 21 are previous LTS versions still officially supported.","Java is a high-level, class-based, object-oriented programming language that is designed to have as few implementation dependencies as possible. It is a general-purpose programming language intended to let programmers write once, run anywhere (WORA), meaning that compiled Java code can run on all platforms that support Java without the need to recompile. Java applications are typically compiled to bytecode that can run on any Java virtual machine (JVM) regardless of the underlying computer architecture. The syntax of Java is similar to C and C++, but has fewer low-level facilities than either of them. The Java runtime provides dynamic capabilities (such as reflection and runtime code modification) that are typically not available in traditional compiled languages. 
Java gained popularity shortly after its release, and has been a very popular programming language since then. Java was the third most popular programming language in 2022 according to GitHub. Although still widely popular, there has been a gradual decline in use of Java in recent years with other languages using JVM gaining popularity.Java was originally developed by James Gosling at Sun Microsystems. It was released in May 1995 as a core component of Sun's Java platform. The original and reference implementation Java compilers, virtual machines, and class libraries were originally released by Sun under proprietary licenses. As of May 2007, in compliance with the specifications of the Java Community Process, Sun had relicensed most of its Java technologies under the GPL-2.0-only license. Oracle offers its own HotSpot Java Virtual Machine, however the official reference implementation is the OpenJDK JVM which is free open-source software and used by most developers and is the default JVM for almost all Linux distributions.
As of March 2024, Java 22 is the latest version. Java 8, 11, 17, and 21 are previous LTS versions still officially supported.

History
James Gosling, Mike Sheridan, and Patrick Naughton initiated the Java language project in June 1991. Java was originally designed for interactive television, but it was too advanced for the digital cable television industry at the time. The language was initially called Oak after an oak tree that stood outside Gosling's office. Later the project went by the name Green and was finally renamed Java, from Java coffee, a type of coffee from Indonesia. Gosling designed Java with a C/C++-style syntax that system and application programmers would find familiar.Sun Microsystems released the first public implementation as Java 1.0 in 1996. It promised write once, run anywhere (WORA) functionality, providing no-cost run-times on popular platforms. Fairly secure and featuring configurable security, it allowed network- and file-access restrictions. Major web browsers soon incorporated the ability to run Java applets within web pages, and Java quickly became popular. The Java 1.0 compiler was re-written in Java by Arthur van Hoff to comply strictly with the Java 1.0 language specification. With the advent of Java 2 (released initially as J2SE 1.2 in December 1998 –  1999), new versions had multiple configurations built for different types of platforms. J2EE included technologies and APIs for enterprise applications typically run in server environments, while J2ME featured APIs optimized for mobile applications. The desktop version was renamed J2SE. In 2006, for marketing purposes, Sun renamed new J2 versions as Java EE, Java ME, and Java SE, respectively.
In 1997, Sun Microsystems approached the ISO/IEC JTC 1 standards body and later the Ecma International to formalize Java, but it soon withdrew from the process. Java remains a de facto standard, controlled through the Java Community Process. At one time, Sun made most of its Java implementations available without charge, despite their proprietary software status. Sun generated revenue from Java through the selling of licenses for specialized products such as the Java Enterprise System.
On November 13, 2006, Sun released much of its Java virtual machine (JVM) as free and open-source software (FOSS), under the terms of the GPL-2.0-only license. On May 8, 2007, Sun finished the process, making all of its JVM's core code available under free software/open-source distribution terms, aside from a small portion of code to which Sun did not hold the copyright.Sun's vice-president Rich Green said that Sun's ideal role with regard to Java was as an evangelist. Following Oracle Corporation's acquisition of Sun Microsystems in 2009–10, Oracle has described itself as the steward of Java technology with a relentless commitment to fostering a community of participation and transparency. This did not prevent Oracle from filing a lawsuit against Google shortly after that for using Java inside the Android SDK (see the Android section).
On April 2, 2010, James Gosling resigned from Oracle.In January 2016, Oracle announced that Java run-time environments based on JDK 9 will discontinue the browser plugin.Java software runs on everything from laptops to data centers, game consoles to scientific supercomputers.Oracle (and others) highly recommend uninstalling outdated and unsupported versions of Java, due to unresolved security issues in older versions.

Principles
There were five primary goals in the creation of the Java language:

It must be simple, object-oriented, and familiar.
It must be robust and secure.
It must be architecture-neutral and portable.
It must execute with high performance.
It must be interpreted, threaded, and dynamic.

Versions
As of September 2023, Java 8, 11, 17 and 21 are supported as Long-Term Support (LTS) versions.Oracle released the last zero-cost public update for the legacy version Java 8 LTS in January 2019 for commercial use, although it will otherwise still support Java 8 with public updates for personal use indefinitely. Other vendors such as Adoptium continue to offer free builds of OpenJDK's Long-Term Support (LTS) versions. These builds may include additional security patches and bug fixes.Major release versions of Java, along with their release dates:

Editions
Sun has defined and supports four editions of Java targeting different application environments and segmented many of its APIs so that they belong to one of the platforms. The platforms are:

Java Card for smart-cards.
Java Platform, Micro Edition (Java ME) – targeting environments with limited resources.
Java Platform, Standard Edition (Java SE) – targeting workstation environments.
Java Platform, Enterprise Edition (Java EE) – targeting large distributed enterprise or Internet environments.The classes in the Java APIs are organized into separate groups called packages. Each package contains a set of related interfaces, classes, subpackages and exceptions.
Sun also provided an edition called Personal Java that has been superseded by later, standards-based Java ME configuration-profile pairings.

Execution system
Java JVM and bytecode
One design goal of Java is portability, which means that programs written for the Java platform must run similarly on any combination of hardware and operating system with adequate run time support. This is achieved by compiling the Java language code to an intermediate representation called Java bytecode, instead of directly to architecture-specific machine code. Java bytecode instructions are analogous to machine code, but they are intended to be executed by a virtual machine (VM) written specifically for the host hardware. End-users commonly use a Java Runtime Environment (JRE) installed on their device for standalone Java applications or a web browser for Java applets.
Standard libraries provide a generic way to access host-specific features such as graphics, threading, and networking.
The use of universal bytecode makes porting simple. However, the overhead of interpreting bytecode into machine instructions made interpreted programs almost always run more slowly than native executables. Just-in-time (JIT) compilers that compile byte-codes to machine code during runtime were introduced from an early stage. Java's Hotspot compiler is actually two compilers in one; and with GraalVM (included in e.g. Java 11, but removed as of Java 16) allowing tiered compilation. Java itself is platform-independent and is adapted to the particular platform it is to run on by a Java virtual machine (JVM), which translates the Java bytecode into the platform's machine language.

Performance
Programs written in Java have a reputation for being slower and requiring more memory than those written in C++. However, Java programs' execution speed improved significantly with the introduction of just-in-time compilation in 1997/1998 for Java 1.1, the addition of language features supporting better code analysis (such as inner classes, the StringBuilder class, optional assertions, etc.), and optimizations in the Java virtual machine, such as HotSpot becoming Sun's default JVM in 2000. With Java 1.5, the performance was improved with the addition of the java.util.concurrent package, including lock-free implementations of the ConcurrentMaps and other multi-core collections, and it was improved further with Java 1.6.

Non-JVM
Some platforms offer direct hardware support for Java; there are micro controllers that can run Java bytecode in hardware instead of a software Java virtual machine, and some ARM-based processors could have hardware support for executing Java bytecode through their Jazelle option, though support has mostly been dropped in current implementations of ARM.

Automatic memory management
Java uses an automatic garbage collector to manage memory in the object lifecycle. The programmer determines when objects are created, and the Java runtime is responsible for recovering the memory once objects are no longer in use. Once no references to an object remain, the unreachable memory becomes eligible to be freed automatically by the garbage collector. Something similar to a memory leak may still occur if a programmer's code holds a reference to an object that is no longer needed, typically when objects that are no longer needed are stored in containers that are still in use. If methods for a non-existent object are called, a null pointer exception is thrown.One of the ideas behind Java's automatic memory management model is that programmers can be spared the burden of having to perform manual memory management. In some languages, memory for the creation of objects is implicitly allocated on the stack or explicitly allocated and deallocated from the heap. In the latter case, the responsibility of managing memory resides with the programmer. If the program does not deallocate an object, a memory leak occurs. If the program attempts to access or deallocate memory that has already been deallocated, the result is undefined and difficult to predict, and the program is likely to become unstable or crash. This can be partially remedied by the use of smart pointers, but these add overhead and complexity. Garbage collection does not prevent logical memory leaks, i.e. those where the memory is still referenced but never used.Garbage collection may happen at any time. Ideally, it will occur when a program is idle. It is guaranteed to be triggered if there is insufficient free memory on the heap to allocate a new object; this can cause a program to stall momentarily. Explicit memory management is not possible in Java.
Java does not support C/C++ style pointer arithmetic, where object addresses can be arithmetically manipulated (e.g. by adding or subtracting an offset). This allows the garbage collector to relocate referenced objects and ensures type safety and security.
As in C++ and some other object-oriented languages, variables of Java's primitive data types are either stored directly in fields (for objects) or on the stack (for methods) rather than on the heap, as is commonly true for non-primitive data types (but see escape analysis). This was a conscious decision by Java's designers for performance reasons.
Java contains multiple types of garbage collectors. Since Java 9, HotSpot uses the Garbage First Garbage Collector (G1GC) as the default. However, there are also several other garbage collectors that can be used to manage the heap. For most applications in Java, G1GC is sufficient. Previously, the Parallel Garbage Collector was used in Java 8.
Having solved the memory management problem does not relieve the programmer of the burden of handling properly other kinds of resources, like network or database connections, file handles, etc., especially in the presence of exceptions.

Syntax
The syntax of Java is largely influenced by C++ and C. Unlike C++, which combines the syntax for structured, generic, and object-oriented programming, Java was built almost exclusively as an object-oriented language. All code is written inside classes, and every data item is an object, with the exception of the primitive data types, (i.e. integers, floating-point numbers, boolean values, and characters), which are not objects for performance reasons. Java reuses some popular aspects of C++ (such as the printf method).
Unlike C++, Java does not support operator overloading or multiple inheritance for classes, though multiple inheritance is supported for interfaces.Java uses comments similar to those of C++. There are three different styles of comments: a single line style marked with two slashes (//), a multiple line style opened with /* and closed with */, and the Javadoc commenting style opened with /** and closed with */. The Javadoc style of commenting allows the user to run the Javadoc executable to create documentation for the program and can be read by some integrated development environments (IDEs) such as Eclipse to allow developers to access documentation within the IDE.

Special classes
Applet
Java applets are programs embedded in other applications, typically in a Web page displayed in a web browser. The Java applet API is now deprecated since Java 9 in 2017.

Servlet
Java servlet technology provides Web developers with a simple, consistent mechanism for extending the functionality of a Web server and for accessing existing business systems. Servlets are server-side Java EE components that generate responses to requests from clients. Most of the time, this means generating HTML pages in response to HTTP requests, although there are a number of other standard servlet classes available, for example for WebSocket communication.
The Java servlet API has to some extent been superseded (but still used under the hood) by two standard Java technologies for web services:

the Java API for RESTful Web Services (JAX-RS 2.0) useful for AJAX, JSON and REST services, and
the Java API for XML Web Services (JAX-WS) useful for SOAP Web Services.Typical implementations of these APIs on Application Servers or Servlet Containers use a standard servlet for handling all interactions with the HTTP requests and responses that delegate to the web service methods for the actual business logic.

JavaServer Pages
JavaServer Pages (JSP) are server-side Java EE components that generate responses, typically HTML pages, to HTTP requests from clients. JSPs embed Java code in an HTML page by using the special delimiters <% and %>. A JSP is compiled to a Java servlet, a Java application in its own right, the first time it is accessed. After that, the generated servlet creates the response.

Swing application
Swing is a graphical user interface library for the Java SE platform. It is possible to specify a different look and feel through the pluggable look and feel system of Swing. Clones of Windows, GTK+, and Motif are supplied by Sun. Apple also provides an Aqua look and feel for macOS. Where prior implementations of these looks and feels may have been considered lacking, Swing in Java SE 6 addresses this problem by using more native GUI widget drawing routines of the underlying platforms.

JavaFX application
JavaFX is a software platform for creating and delivering desktop applications, as well as rich web applications that can run across a wide variety of devices. JavaFX is intended to replace Swing as the standard GUI library for Java SE, but since JDK 11 JavaFX has not been in the core JDK and instead in a separate module. JavaFX has support for desktop computers and web browsers on Microsoft Windows, Linux, and macOS. JavaFX does not have support for native OS look and feels.

Generics
In 2004, generics were added to the Java language, as part of J2SE 5.0. Prior to the introduction of generics, each variable declaration had to be of a specific type. For container classes, for example, this is a problem because there is no easy way to create a container that accepts only specific types of objects. Either the container operates on all subtypes of a class or interface, usually Object, or a different container class has to be created for each contained class. Generics allow compile-time type checking without having to create many container classes, each containing almost identical code. In addition to enabling more efficient code, certain runtime exceptions are prevented from occurring, by issuing compile-time errors. If Java prevented all runtime type errors (ClassCastExceptions) from occurring, it would be type safe.
In 2016, the type system of Java was proven unsound in that it is possible to use generics to construct classes and methods that allow assignment of an instance one class to a variable of another unrelated class. Such code is accepted by the compiler, but fails at run time with a class cast exception.

Criticism
Criticisms directed at Java include the implementation of generics, speed, the handling of unsigned numbers, the implementation of floating-point arithmetic, and a history of security vulnerabilities in the primary Java VM implementation HotSpot.

Class libraries
The Java Class Library is the standard library, developed to support application development in Java. It is controlled by Oracle in cooperation with others through the Java Community Process program. Companies or individuals participating in this process can influence the design and development of the APIs. This process has been a subject of controversy during the 2010s. The class library contains features such as:

The core libraries, which include:
IO/NIO
Networking (NOTE: new HTTP Client since Java 11)
Reflection
Concurrency
Generics
Scripting/Compiler
Functional programming (Lambda, Streaming)
Collection libraries that implement data structures such as lists, dictionaries, trees, sets, queues and double-ended queue, or stacks
XML Processing (Parsing, Transforming, Validating) libraries
Security
Internationalization and localization libraries
The integration libraries, which allow the application writer to communicate with external systems. These libraries include:
The Java Database Connectivity (JDBC) API for database access
Java Naming and Directory Interface (JNDI) for lookup and discovery
Java remote method invocation (RMI) and Common Object Request Broker Architecture (CORBA) for distributed application development
Java Management Extensions (JMX) for managing and monitoring applications
User interface libraries, which include:
The (heavyweight, or native) Abstract Window Toolkit (AWT), which provides GUI components, the means for laying out those components and the means for handling events from those components
The (lightweight) Swing libraries, which are built on AWT but provide (non-native) implementations of the AWT widgetry
APIs for audio capture, processing, and playback
JavaFX
A platform dependent implementation of the Java virtual machine that is the means by which the bytecodes of the Java libraries and third-party applications are executed
Plugins, which enable applets to be run in web browsers
Java Web Start, which allows Java applications to be efficiently distributed to end users across the Internet
Licensing and documentation

Documentation
Javadoc is a comprehensive documentation system, created by Sun Microsystems. It provides developers with an organized system for documenting their code. Javadoc comments have an extra asterisk at the beginning, i.e. the delimiters are /** and */, whereas the normal multi-line comments in Java are delimited by /* and */, and single-line comments start with //.

Implementations
Oracle Corporation owns the official implementation of the Java SE platform, due to its acquisition of Sun Microsystems on January 27, 2010. This implementation is based on the original implementation of Java by Sun. The Oracle implementation is available for Windows, macOS, Linux, and Solaris. Because Java lacks any formal standardization recognized by Ecma International, ISO/IEC, ANSI, or other third-party standards organizations, the Oracle implementation is the de facto standard.
The Oracle implementation is packaged into two different distributions: The Java Runtime Environment (JRE) which contains the parts of the Java SE platform required to run Java programs and is intended for end users, and the Java Development Kit (JDK), which is intended for software developers and includes development tools such as the Java compiler, Javadoc, Jar, and a debugger. Oracle has also released GraalVM, a high performance Java dynamic compiler and interpreter.
OpenJDK is another Java SE implementation that is licensed under the GNU GPL. The implementation started when Sun began releasing the Java source code under the GPL. As of Java SE 7, OpenJDK is the official Java reference implementation.
The goal of Java is to make all implementations of Java compatible. Historically, Sun's trademark license for usage of the Java brand insists that all implementations be compatible. This resulted in a legal dispute with Microsoft after Sun claimed that the Microsoft implementation did not support Java remote method invocation (RMI) or Java Native Interface (JNI) and had added platform-specific features of their own. Sun sued in 1997, and, in 2001, won a settlement of US$20 million, as well as a court order enforcing the terms of the license from Sun. As a result, Microsoft no longer ships Java with Windows.
Platform-independent Java is essential to Java EE, and an even more rigorous validation is required to certify an implementation. This environment enables portable server-side applications.

Use outside the Java platform
The Java programming language requires the presence of a software platform in order for compiled programs to be executed.
Oracle supplies the Java platform for use with Java. The Android SDK is an alternative software platform, used primarily for developing Android applications with its own GUI system.

Android
The Java language is a key pillar in Android, an open source mobile operating system. Although Android, built on the Linux kernel, is written largely in C, the Android SDK uses the Java language as the basis for Android applications but does not use any of its standard GUI, SE, ME or other established Java standards. The bytecode language supported by the Android SDK is incompatible with Java bytecode and runs on its own virtual machine, optimized for low-memory devices such as smartphones and tablet computers. Depending on the Android version, the bytecode is either interpreted by the Dalvik virtual machine or compiled into native code by the Android Runtime.
Android does not provide the full Java SE standard library, although the Android SDK does include an independent implementation of a large subset of it. It supports Java 6 and some Java 7 features, offering an implementation compatible with the standard library (Apache Harmony).

Controversy
The use of Java-related technology in Android led to a legal dispute between Oracle and Google. On May 7, 2012, a San Francisco jury found that if APIs could be copyrighted, then Google had infringed Oracle's copyrights by the use of Java in Android devices. District Judge William Alsup ruled on May 31, 2012, that APIs cannot be copyrighted, but this was reversed by the United States Court of Appeals for the Federal Circuit in May 2014. On May 26, 2016, the district court decided in favor of Google, ruling the copyright infringement of the Java API in Android constitutes fair use. In March 2018, this ruling was overturned by the Appeals Court, which sent down the case of determining the damages to federal court in San Francisco.
Google filed a petition for writ of certiorari with the Supreme Court of the United States in January 2019 to challenge the two rulings that were made by the Appeals Court in Oracle's favor. On April 5, 2021, the Court ruled 6–2 in Google's favor, that its use of Java APIs should be considered fair use. However, the court refused to rule on the copyrightability of APIs, choosing instead to determine their ruling by considering Java's API copyrightable ""purely for argument's sake.""

See also
C#
C++
Dalvik, used in old Android versions, replaced by non-JIT Android Runtime
Java Heterogeneous Distributed Computing
List of Java APIs
List of Java frameworks
List of JVM languages
List of Java virtual machines
Comparison of C# and Java
Comparison of Java and C++
Comparison of programming languages

References
Bibliography
External links

 The dictionary definition of Java at Wiktionary
 Media related to Java at Wikimedia Commons
 Java Programming at Wikibooks
 Learning materials related to Java at Wikiversity
Java Weekly",15881,https://en.wikipedia.org/wiki/Java_(programming_language)
Java technology,"Java is a high-level, class-based, object-oriented programming language that is designed to have as few implementation dependencies as possible. It is a general-purpose programming language intended to let programmers write once, run anywhere (WORA), meaning that compiled Java code can run on all platforms that support Java without the need to recompile. Java applications are typically compiled to bytecode that can run on any Java virtual machine (JVM) regardless of the underlying computer architecture. The syntax of Java is similar to C and C++, but has fewer low-level facilities than either of them. The Java runtime provides dynamic capabilities (such as reflection and runtime code modification) that are typically not available in traditional compiled languages. 
Java gained popularity shortly after its release, and has been a very popular programming language since then. Java was the third most popular programming language in 2022 according to GitHub. Although still widely popular, there has been a gradual decline in use of Java in recent years with other languages using JVM gaining popularity.Java was originally developed by James Gosling at Sun Microsystems. It was released in May 1995 as a core component of Sun's Java platform. The original and reference implementation Java compilers, virtual machines, and class libraries were originally released by Sun under proprietary licenses. As of May 2007, in compliance with the specifications of the Java Community Process, Sun had relicensed most of its Java technologies under the GPL-2.0-only license. Oracle offers its own HotSpot Java Virtual Machine, however the official reference implementation is the OpenJDK JVM which is free open-source software and used by most developers and is the default JVM for almost all Linux distributions.
As of March 2024, Java 22 is the latest version. Java 8, 11, 17, and 21 are previous LTS versions still officially supported.","Java is a high-level, class-based, object-oriented programming language that is designed to have as few implementation dependencies as possible. It is a general-purpose programming language intended to let programmers write once, run anywhere (WORA), meaning that compiled Java code can run on all platforms that support Java without the need to recompile. Java applications are typically compiled to bytecode that can run on any Java virtual machine (JVM) regardless of the underlying computer architecture. The syntax of Java is similar to C and C++, but has fewer low-level facilities than either of them. The Java runtime provides dynamic capabilities (such as reflection and runtime code modification) that are typically not available in traditional compiled languages. 
Java gained popularity shortly after its release, and has been a very popular programming language since then. Java was the third most popular programming language in 2022 according to GitHub. Although still widely popular, there has been a gradual decline in use of Java in recent years with other languages using JVM gaining popularity.Java was originally developed by James Gosling at Sun Microsystems. It was released in May 1995 as a core component of Sun's Java platform. The original and reference implementation Java compilers, virtual machines, and class libraries were originally released by Sun under proprietary licenses. As of May 2007, in compliance with the specifications of the Java Community Process, Sun had relicensed most of its Java technologies under the GPL-2.0-only license. Oracle offers its own HotSpot Java Virtual Machine, however the official reference implementation is the OpenJDK JVM which is free open-source software and used by most developers and is the default JVM for almost all Linux distributions.
As of March 2024, Java 22 is the latest version. Java 8, 11, 17, and 21 are previous LTS versions still officially supported.

History
James Gosling, Mike Sheridan, and Patrick Naughton initiated the Java language project in June 1991. Java was originally designed for interactive television, but it was too advanced for the digital cable television industry at the time. The language was initially called Oak after an oak tree that stood outside Gosling's office. Later the project went by the name Green and was finally renamed Java, from Java coffee, a type of coffee from Indonesia. Gosling designed Java with a C/C++-style syntax that system and application programmers would find familiar.Sun Microsystems released the first public implementation as Java 1.0 in 1996. It promised write once, run anywhere (WORA) functionality, providing no-cost run-times on popular platforms. Fairly secure and featuring configurable security, it allowed network- and file-access restrictions. Major web browsers soon incorporated the ability to run Java applets within web pages, and Java quickly became popular. The Java 1.0 compiler was re-written in Java by Arthur van Hoff to comply strictly with the Java 1.0 language specification. With the advent of Java 2 (released initially as J2SE 1.2 in December 1998 –  1999), new versions had multiple configurations built for different types of platforms. J2EE included technologies and APIs for enterprise applications typically run in server environments, while J2ME featured APIs optimized for mobile applications. The desktop version was renamed J2SE. In 2006, for marketing purposes, Sun renamed new J2 versions as Java EE, Java ME, and Java SE, respectively.
In 1997, Sun Microsystems approached the ISO/IEC JTC 1 standards body and later the Ecma International to formalize Java, but it soon withdrew from the process. Java remains a de facto standard, controlled through the Java Community Process. At one time, Sun made most of its Java implementations available without charge, despite their proprietary software status. Sun generated revenue from Java through the selling of licenses for specialized products such as the Java Enterprise System.
On November 13, 2006, Sun released much of its Java virtual machine (JVM) as free and open-source software (FOSS), under the terms of the GPL-2.0-only license. On May 8, 2007, Sun finished the process, making all of its JVM's core code available under free software/open-source distribution terms, aside from a small portion of code to which Sun did not hold the copyright.Sun's vice-president Rich Green said that Sun's ideal role with regard to Java was as an evangelist. Following Oracle Corporation's acquisition of Sun Microsystems in 2009–10, Oracle has described itself as the steward of Java technology with a relentless commitment to fostering a community of participation and transparency. This did not prevent Oracle from filing a lawsuit against Google shortly after that for using Java inside the Android SDK (see the Android section).
On April 2, 2010, James Gosling resigned from Oracle.In January 2016, Oracle announced that Java run-time environments based on JDK 9 will discontinue the browser plugin.Java software runs on everything from laptops to data centers, game consoles to scientific supercomputers.Oracle (and others) highly recommend uninstalling outdated and unsupported versions of Java, due to unresolved security issues in older versions.

Principles
There were five primary goals in the creation of the Java language:

It must be simple, object-oriented, and familiar.
It must be robust and secure.
It must be architecture-neutral and portable.
It must execute with high performance.
It must be interpreted, threaded, and dynamic.

Versions
As of September 2023, Java 8, 11, 17 and 21 are supported as Long-Term Support (LTS) versions.Oracle released the last zero-cost public update for the legacy version Java 8 LTS in January 2019 for commercial use, although it will otherwise still support Java 8 with public updates for personal use indefinitely. Other vendors such as Adoptium continue to offer free builds of OpenJDK's Long-Term Support (LTS) versions. These builds may include additional security patches and bug fixes.Major release versions of Java, along with their release dates:

Editions
Sun has defined and supports four editions of Java targeting different application environments and segmented many of its APIs so that they belong to one of the platforms. The platforms are:

Java Card for smart-cards.
Java Platform, Micro Edition (Java ME) – targeting environments with limited resources.
Java Platform, Standard Edition (Java SE) – targeting workstation environments.
Java Platform, Enterprise Edition (Java EE) – targeting large distributed enterprise or Internet environments.The classes in the Java APIs are organized into separate groups called packages. Each package contains a set of related interfaces, classes, subpackages and exceptions.
Sun also provided an edition called Personal Java that has been superseded by later, standards-based Java ME configuration-profile pairings.

Execution system
Java JVM and bytecode
One design goal of Java is portability, which means that programs written for the Java platform must run similarly on any combination of hardware and operating system with adequate run time support. This is achieved by compiling the Java language code to an intermediate representation called Java bytecode, instead of directly to architecture-specific machine code. Java bytecode instructions are analogous to machine code, but they are intended to be executed by a virtual machine (VM) written specifically for the host hardware. End-users commonly use a Java Runtime Environment (JRE) installed on their device for standalone Java applications or a web browser for Java applets.
Standard libraries provide a generic way to access host-specific features such as graphics, threading, and networking.
The use of universal bytecode makes porting simple. However, the overhead of interpreting bytecode into machine instructions made interpreted programs almost always run more slowly than native executables. Just-in-time (JIT) compilers that compile byte-codes to machine code during runtime were introduced from an early stage. Java's Hotspot compiler is actually two compilers in one; and with GraalVM (included in e.g. Java 11, but removed as of Java 16) allowing tiered compilation. Java itself is platform-independent and is adapted to the particular platform it is to run on by a Java virtual machine (JVM), which translates the Java bytecode into the platform's machine language.

Performance
Programs written in Java have a reputation for being slower and requiring more memory than those written in C++. However, Java programs' execution speed improved significantly with the introduction of just-in-time compilation in 1997/1998 for Java 1.1, the addition of language features supporting better code analysis (such as inner classes, the StringBuilder class, optional assertions, etc.), and optimizations in the Java virtual machine, such as HotSpot becoming Sun's default JVM in 2000. With Java 1.5, the performance was improved with the addition of the java.util.concurrent package, including lock-free implementations of the ConcurrentMaps and other multi-core collections, and it was improved further with Java 1.6.

Non-JVM
Some platforms offer direct hardware support for Java; there are micro controllers that can run Java bytecode in hardware instead of a software Java virtual machine, and some ARM-based processors could have hardware support for executing Java bytecode through their Jazelle option, though support has mostly been dropped in current implementations of ARM.

Automatic memory management
Java uses an automatic garbage collector to manage memory in the object lifecycle. The programmer determines when objects are created, and the Java runtime is responsible for recovering the memory once objects are no longer in use. Once no references to an object remain, the unreachable memory becomes eligible to be freed automatically by the garbage collector. Something similar to a memory leak may still occur if a programmer's code holds a reference to an object that is no longer needed, typically when objects that are no longer needed are stored in containers that are still in use. If methods for a non-existent object are called, a null pointer exception is thrown.One of the ideas behind Java's automatic memory management model is that programmers can be spared the burden of having to perform manual memory management. In some languages, memory for the creation of objects is implicitly allocated on the stack or explicitly allocated and deallocated from the heap. In the latter case, the responsibility of managing memory resides with the programmer. If the program does not deallocate an object, a memory leak occurs. If the program attempts to access or deallocate memory that has already been deallocated, the result is undefined and difficult to predict, and the program is likely to become unstable or crash. This can be partially remedied by the use of smart pointers, but these add overhead and complexity. Garbage collection does not prevent logical memory leaks, i.e. those where the memory is still referenced but never used.Garbage collection may happen at any time. Ideally, it will occur when a program is idle. It is guaranteed to be triggered if there is insufficient free memory on the heap to allocate a new object; this can cause a program to stall momentarily. Explicit memory management is not possible in Java.
Java does not support C/C++ style pointer arithmetic, where object addresses can be arithmetically manipulated (e.g. by adding or subtracting an offset). This allows the garbage collector to relocate referenced objects and ensures type safety and security.
As in C++ and some other object-oriented languages, variables of Java's primitive data types are either stored directly in fields (for objects) or on the stack (for methods) rather than on the heap, as is commonly true for non-primitive data types (but see escape analysis). This was a conscious decision by Java's designers for performance reasons.
Java contains multiple types of garbage collectors. Since Java 9, HotSpot uses the Garbage First Garbage Collector (G1GC) as the default. However, there are also several other garbage collectors that can be used to manage the heap. For most applications in Java, G1GC is sufficient. Previously, the Parallel Garbage Collector was used in Java 8.
Having solved the memory management problem does not relieve the programmer of the burden of handling properly other kinds of resources, like network or database connections, file handles, etc., especially in the presence of exceptions.

Syntax
The syntax of Java is largely influenced by C++ and C. Unlike C++, which combines the syntax for structured, generic, and object-oriented programming, Java was built almost exclusively as an object-oriented language. All code is written inside classes, and every data item is an object, with the exception of the primitive data types, (i.e. integers, floating-point numbers, boolean values, and characters), which are not objects for performance reasons. Java reuses some popular aspects of C++ (such as the printf method).
Unlike C++, Java does not support operator overloading or multiple inheritance for classes, though multiple inheritance is supported for interfaces.Java uses comments similar to those of C++. There are three different styles of comments: a single line style marked with two slashes (//), a multiple line style opened with /* and closed with */, and the Javadoc commenting style opened with /** and closed with */. The Javadoc style of commenting allows the user to run the Javadoc executable to create documentation for the program and can be read by some integrated development environments (IDEs) such as Eclipse to allow developers to access documentation within the IDE.

Special classes
Applet
Java applets are programs embedded in other applications, typically in a Web page displayed in a web browser. The Java applet API is now deprecated since Java 9 in 2017.

Servlet
Java servlet technology provides Web developers with a simple, consistent mechanism for extending the functionality of a Web server and for accessing existing business systems. Servlets are server-side Java EE components that generate responses to requests from clients. Most of the time, this means generating HTML pages in response to HTTP requests, although there are a number of other standard servlet classes available, for example for WebSocket communication.
The Java servlet API has to some extent been superseded (but still used under the hood) by two standard Java technologies for web services:

the Java API for RESTful Web Services (JAX-RS 2.0) useful for AJAX, JSON and REST services, and
the Java API for XML Web Services (JAX-WS) useful for SOAP Web Services.Typical implementations of these APIs on Application Servers or Servlet Containers use a standard servlet for handling all interactions with the HTTP requests and responses that delegate to the web service methods for the actual business logic.

JavaServer Pages
JavaServer Pages (JSP) are server-side Java EE components that generate responses, typically HTML pages, to HTTP requests from clients. JSPs embed Java code in an HTML page by using the special delimiters <% and %>. A JSP is compiled to a Java servlet, a Java application in its own right, the first time it is accessed. After that, the generated servlet creates the response.

Swing application
Swing is a graphical user interface library for the Java SE platform. It is possible to specify a different look and feel through the pluggable look and feel system of Swing. Clones of Windows, GTK+, and Motif are supplied by Sun. Apple also provides an Aqua look and feel for macOS. Where prior implementations of these looks and feels may have been considered lacking, Swing in Java SE 6 addresses this problem by using more native GUI widget drawing routines of the underlying platforms.

JavaFX application
JavaFX is a software platform for creating and delivering desktop applications, as well as rich web applications that can run across a wide variety of devices. JavaFX is intended to replace Swing as the standard GUI library for Java SE, but since JDK 11 JavaFX has not been in the core JDK and instead in a separate module. JavaFX has support for desktop computers and web browsers on Microsoft Windows, Linux, and macOS. JavaFX does not have support for native OS look and feels.

Generics
In 2004, generics were added to the Java language, as part of J2SE 5.0. Prior to the introduction of generics, each variable declaration had to be of a specific type. For container classes, for example, this is a problem because there is no easy way to create a container that accepts only specific types of objects. Either the container operates on all subtypes of a class or interface, usually Object, or a different container class has to be created for each contained class. Generics allow compile-time type checking without having to create many container classes, each containing almost identical code. In addition to enabling more efficient code, certain runtime exceptions are prevented from occurring, by issuing compile-time errors. If Java prevented all runtime type errors (ClassCastExceptions) from occurring, it would be type safe.
In 2016, the type system of Java was proven unsound in that it is possible to use generics to construct classes and methods that allow assignment of an instance one class to a variable of another unrelated class. Such code is accepted by the compiler, but fails at run time with a class cast exception.

Criticism
Criticisms directed at Java include the implementation of generics, speed, the handling of unsigned numbers, the implementation of floating-point arithmetic, and a history of security vulnerabilities in the primary Java VM implementation HotSpot.

Class libraries
The Java Class Library is the standard library, developed to support application development in Java. It is controlled by Oracle in cooperation with others through the Java Community Process program. Companies or individuals participating in this process can influence the design and development of the APIs. This process has been a subject of controversy during the 2010s. The class library contains features such as:

The core libraries, which include:
IO/NIO
Networking (NOTE: new HTTP Client since Java 11)
Reflection
Concurrency
Generics
Scripting/Compiler
Functional programming (Lambda, Streaming)
Collection libraries that implement data structures such as lists, dictionaries, trees, sets, queues and double-ended queue, or stacks
XML Processing (Parsing, Transforming, Validating) libraries
Security
Internationalization and localization libraries
The integration libraries, which allow the application writer to communicate with external systems. These libraries include:
The Java Database Connectivity (JDBC) API for database access
Java Naming and Directory Interface (JNDI) for lookup and discovery
Java remote method invocation (RMI) and Common Object Request Broker Architecture (CORBA) for distributed application development
Java Management Extensions (JMX) for managing and monitoring applications
User interface libraries, which include:
The (heavyweight, or native) Abstract Window Toolkit (AWT), which provides GUI components, the means for laying out those components and the means for handling events from those components
The (lightweight) Swing libraries, which are built on AWT but provide (non-native) implementations of the AWT widgetry
APIs for audio capture, processing, and playback
JavaFX
A platform dependent implementation of the Java virtual machine that is the means by which the bytecodes of the Java libraries and third-party applications are executed
Plugins, which enable applets to be run in web browsers
Java Web Start, which allows Java applications to be efficiently distributed to end users across the Internet
Licensing and documentation

Documentation
Javadoc is a comprehensive documentation system, created by Sun Microsystems. It provides developers with an organized system for documenting their code. Javadoc comments have an extra asterisk at the beginning, i.e. the delimiters are /** and */, whereas the normal multi-line comments in Java are delimited by /* and */, and single-line comments start with //.

Implementations
Oracle Corporation owns the official implementation of the Java SE platform, due to its acquisition of Sun Microsystems on January 27, 2010. This implementation is based on the original implementation of Java by Sun. The Oracle implementation is available for Windows, macOS, Linux, and Solaris. Because Java lacks any formal standardization recognized by Ecma International, ISO/IEC, ANSI, or other third-party standards organizations, the Oracle implementation is the de facto standard.
The Oracle implementation is packaged into two different distributions: The Java Runtime Environment (JRE) which contains the parts of the Java SE platform required to run Java programs and is intended for end users, and the Java Development Kit (JDK), which is intended for software developers and includes development tools such as the Java compiler, Javadoc, Jar, and a debugger. Oracle has also released GraalVM, a high performance Java dynamic compiler and interpreter.
OpenJDK is another Java SE implementation that is licensed under the GNU GPL. The implementation started when Sun began releasing the Java source code under the GPL. As of Java SE 7, OpenJDK is the official Java reference implementation.
The goal of Java is to make all implementations of Java compatible. Historically, Sun's trademark license for usage of the Java brand insists that all implementations be compatible. This resulted in a legal dispute with Microsoft after Sun claimed that the Microsoft implementation did not support Java remote method invocation (RMI) or Java Native Interface (JNI) and had added platform-specific features of their own. Sun sued in 1997, and, in 2001, won a settlement of US$20 million, as well as a court order enforcing the terms of the license from Sun. As a result, Microsoft no longer ships Java with Windows.
Platform-independent Java is essential to Java EE, and an even more rigorous validation is required to certify an implementation. This environment enables portable server-side applications.

Use outside the Java platform
The Java programming language requires the presence of a software platform in order for compiled programs to be executed.
Oracle supplies the Java platform for use with Java. The Android SDK is an alternative software platform, used primarily for developing Android applications with its own GUI system.

Android
The Java language is a key pillar in Android, an open source mobile operating system. Although Android, built on the Linux kernel, is written largely in C, the Android SDK uses the Java language as the basis for Android applications but does not use any of its standard GUI, SE, ME or other established Java standards. The bytecode language supported by the Android SDK is incompatible with Java bytecode and runs on its own virtual machine, optimized for low-memory devices such as smartphones and tablet computers. Depending on the Android version, the bytecode is either interpreted by the Dalvik virtual machine or compiled into native code by the Android Runtime.
Android does not provide the full Java SE standard library, although the Android SDK does include an independent implementation of a large subset of it. It supports Java 6 and some Java 7 features, offering an implementation compatible with the standard library (Apache Harmony).

Controversy
The use of Java-related technology in Android led to a legal dispute between Oracle and Google. On May 7, 2012, a San Francisco jury found that if APIs could be copyrighted, then Google had infringed Oracle's copyrights by the use of Java in Android devices. District Judge William Alsup ruled on May 31, 2012, that APIs cannot be copyrighted, but this was reversed by the United States Court of Appeals for the Federal Circuit in May 2014. On May 26, 2016, the district court decided in favor of Google, ruling the copyright infringement of the Java API in Android constitutes fair use. In March 2018, this ruling was overturned by the Appeals Court, which sent down the case of determining the damages to federal court in San Francisco.
Google filed a petition for writ of certiorari with the Supreme Court of the United States in January 2019 to challenge the two rulings that were made by the Appeals Court in Oracle's favor. On April 5, 2021, the Court ruled 6–2 in Google's favor, that its use of Java APIs should be considered fair use. However, the court refused to rule on the copyrightability of APIs, choosing instead to determine their ruling by considering Java's API copyrightable ""purely for argument's sake.""

See also
C#
C++
Dalvik, used in old Android versions, replaced by non-JIT Android Runtime
Java Heterogeneous Distributed Computing
List of Java APIs
List of Java frameworks
List of JVM languages
List of Java virtual machines
Comparison of C# and Java
Comparison of Java and C++
Comparison of programming languages

References
Bibliography
External links

 The dictionary definition of Java at Wiktionary
 Media related to Java at Wikimedia Commons
 Java Programming at Wikibooks
 Learning materials related to Java at Wikiversity
Java Weekly",15881,https://en.wikipedia.org/wiki/Java_(programming_language)
Join Java,Join Java is a programming language based on the join-pattern that extends the standard Java programming language with the join semantics of the join-calculus.  It was written at the University of South Australia within the Reconfigurable Computing Lab by Dr. Von Itzstein.,"Join Java is a programming language based on the join-pattern that extends the standard Java programming language with the join semantics of the join-calculus.  It was written at the University of South Australia within the Reconfigurable Computing Lab by Dr. Von Itzstein.

Language characteristics
The Join Java extension introduces three new language constructs:

Join methods
Asynchronous methods
Order class modifiers for determining the order that patterns are matchedConcurrency in most popular programming languages is implemented using constructs such as semaphores and monitors.  Libraries are emerging (such as the Java concurrency library JSR-166) that provide higher-level concurrency semantics.  communicating sequential processes (CSP), Calculus of Communicating Systems (CCS) and Pi have higher-level synchronization behaviours defined implicitly through the composition of events at the interfaces of concurrent processes.  Join calculus, in contrast, has explicit synchronization based on a localized conjunction of events defined as reduction rules.   Join semantics try to provide explicit expressions of synchronization without breaching the object-oriented idea of modularization, including dynamic creation and destruction of processes and channels.
The Join Java language can express virtually all published concurrency patterns without explicit recourse to low-level monitor calls.  In general, Join Java programs are more concise than their Java equivalents. The overhead introduced in Join Java by the higher-level expressions derived from the Join calculus is manageable.  The synchronization expressions associated with monitors (wait and notify) which are normally located in the body of methods can be replaced by Join Java expressions (the Join methods) which form part of the method signature.

Join methods
A Join method is defined by two or more Join fragments. A Join method will
execute once all the fragments of the Join pattern have been called.
If the return type is a standard Java type then the leading fragment will
block the caller until the Join pattern is complete and the method has
executed. If the return type is of type signal then the
leading fragment will return immediately. All trailing fragments are
asynchronous so will not block the caller.
Example:

Ordering modifiers
Join fragments can be repeated in multiple Join patterns so there can be
a case when multiple Join patterns are completed when a fragment is called.
Such a case could occur in the example below if B(), C() and D() then A() are
called. The final A() fragment completes three of the patterns so there are
three possible methods that may be called. The ordered class
modifier is used here to determine which Join method will be called.
The default and when using the unordered class modifier is
to pick one of the methods at random. With the ordered
modifier the methods are prioritised according to the order they are declared.
Example:

Asynchronous methods
Asynchronous methods are defined by using the signal
return type. This has the same characteristics as the void
type except that the method will return immediately. When an asynchronous
method is called a new thread is created to execute the body of the method.
Example:

Related languages
Polyphonic C sharp is the closest related language.Cω the successor of Polyphonic C sharp.
Hardware Join Java language further extended Join Java to implement Hardware semantics.  This language extended the semantics of Join Java to FPGA applications.

References
von Itzstein, G, Stewart. and Jasiunas, M (2003). On Implementing High Level Concurrency in Java. Advances in Computer Systems Architecture 2003, Aizu Japan, Springer Verlag.
von Itzstein, G, Stewart. and D. Kearney (2002). Applications of Join Java. Proceedings of the Seventh Asia Pacific Computer Systems Architecture Conference ACSAC'2002. Melbourne, Australia, Australian Computer Society: 1-20.
von Itzstein, G, Stewart. and D. Kearney (2004). The Expression of Common Concurrency Patterns in Join Java. International Conference on Parallel and Distributed Processing Techniques and Applications, Las Vegas.
Hopf, J., von Itzstein, G, Stewart, et al. (2002). Hardware Join Java: A High Level Language For Reconfigurable Hardware Development. International Conference on Field Programmable Technology, Hong Kong.

External links
Website",2225745,https://en.wikipedia.org/wiki/Join_Java
Jolie (programming language),"Jolie (Java Orchestration Language Interpreter Engine) is an open-source programming language for developing distributed applications based on microservices. In the programming paradigm proposed with Jolie, each program is a service that can communicate with other programs by sending and receiving messages over a network. Jolie supports an abstraction layer that allows services to communicate using different mediums, ranging from TCP/IP sockets to local in-memory communications between processes.Jolie is currently supported by an interpreter implemented in the Java language, which can be run in multiple operating systems including Linux-based operating systems, OS X, and Windows. The language comes with formal semantics, meaning that the execution of Jolie programs is mathematically defined. For this reason, Jolie is used in research for the investigation of language-based techniques for the development of distributed systems, and it is also used for teaching at some universities.The Jolie open source project was started by Fabrizio Montesi in 2006, as part of his studies at the University of Bologna. The project initially began as an implementation of the SOCK process calculus, a formal model proposed by Claudio Guidi et al. at the University of Bologna inspired by the CCS process calculus and the WS-BPEL programming language. Jolie extends SOCK with support for, e.g., tree-like data structures (inspired by XML, but with a syntax resembling that of C and Java), message types, typed session programming, integration with Java and JavaScript, code mobility, application containment, and web programming. A complete list of the project contributors is available at.The project is currently maintained by Fabrizio Montesi and its evolution is driven by Fabrizio Montesi and Claudio Guidi.
Since it supports the orchestration of web services, Jolie is an alternative to XML-based orchestration languages such as WS-BPEL as it offers a concise (C-like) syntax for accessing XML-like data structures.","Jolie (Java Orchestration Language Interpreter Engine) is an open-source programming language for developing distributed applications based on microservices. In the programming paradigm proposed with Jolie, each program is a service that can communicate with other programs by sending and receiving messages over a network. Jolie supports an abstraction layer that allows services to communicate using different mediums, ranging from TCP/IP sockets to local in-memory communications between processes.Jolie is currently supported by an interpreter implemented in the Java language, which can be run in multiple operating systems including Linux-based operating systems, OS X, and Windows. The language comes with formal semantics, meaning that the execution of Jolie programs is mathematically defined. For this reason, Jolie is used in research for the investigation of language-based techniques for the development of distributed systems, and it is also used for teaching at some universities.The Jolie open source project was started by Fabrizio Montesi in 2006, as part of his studies at the University of Bologna. The project initially began as an implementation of the SOCK process calculus, a formal model proposed by Claudio Guidi et al. at the University of Bologna inspired by the CCS process calculus and the WS-BPEL programming language. Jolie extends SOCK with support for, e.g., tree-like data structures (inspired by XML, but with a syntax resembling that of C and Java), message types, typed session programming, integration with Java and JavaScript, code mobility, application containment, and web programming. A complete list of the project contributors is available at.The project is currently maintained by Fabrizio Montesi and its evolution is driven by Fabrizio Montesi and Claudio Guidi.
Since it supports the orchestration of web services, Jolie is an alternative to XML-based orchestration languages such as WS-BPEL as it offers a concise (C-like) syntax for accessing XML-like data structures.

References
External links
Official website
jolie on GitHub",39210326,https://en.wikipedia.org/wiki/Jolie_(programming_language)
Joy (programming language),"The Joy programming language in computer science is a purely functional programming language that was produced by Manfred von Thun of La Trobe University in Melbourne, Australia. Joy is based on composition of functions rather than lambda calculus. It has turned out to have many similarities to Forth, due not to design but to an independent evolution and convergence. It was also inspired by the function-level programming style of John Backus's FP.","The Joy programming language in computer science is a purely functional programming language that was produced by Manfred von Thun of La Trobe University in Melbourne, Australia. Joy is based on composition of functions rather than lambda calculus. It has turned out to have many similarities to Forth, due not to design but to an independent evolution and convergence. It was also inspired by the function-level programming style of John Backus's FP.

How it works
Joy is unusual among functional programming languages (except for function-level programming languages and some esoteric ones, such as Unlambda) in its lack of a lambda operator, and therefore lack of formal parameters. To illustrate this with a common example, here is how the square function might be defined in an imperative programming language (C):

The variable x is a parameter which is replaced by the argument to be squared when the function is called.
In a functional language (Scheme), the same function could be defined:

This is different in many ways, but it still uses the parameter x in the same way.
In Joy, the square function is defined:

DEFINE square == dup * .

In Joy, everything is a function that takes a stack as an argument and returns a stack as a result. For instance, the numeral '5' does not represent an integer constant, but instead a short program that pushes the number 5 onto the stack.

The dup operator simply duplicates the top element of the stack by pushing a copy of it.
The * operator pops two numbers off the stack and pushes their product.So the square function makes a copy of the top element, and then multiplies the two top elements of the stack, leaving the square of the original top element at the top of the stack, with no need for a formal parameter. This makes Joy concise, as illustrated by this definition of quicksort:

DEFINE qsort ==
  [small]
  []
  [uncons [>] split]
  [enconcat]
  binrec.

""binrec"" is one of Joy's many recursive combinators, implementing binary recursion. It expects four quoted programs on top of the stack which represent:

the termination condition (if a list is ""small"" (1 or 0 elements) it is already sorted),
what to do if the termination condition is met (in this case nothing),
what to do by default (split the list into two halves by comparing each element with the pivot), and finally
what to do at the end (insert the pivot between the two sorted halves).

Mathematical purity
In Joy, the meaning function is a homomorphism from the syntactic monoid onto the semantic monoid. That is, the syntactic relation of concatenation of symbols maps directly onto the semantic relation of composition of functions. It is a homomorphism rather than an isomorphism, because it is onto but not one-to-one; that is, no symbol has more than one meaning, but some sequences of symbols have the same meaning (e.g. ""dup +"" and ""2 *"").
Joy is a concatenative programming language: ""The concatenation of two programs denotes the composition of the functions denoted by the two programs"".Its library routines mirror those of ISO C, though the current implementation is not easily extensible with functions written in C.

See also
RPL
Concatenative programming language

References
External links
Official Joy Programming Language Website (La Trobe University) at the Wayback Machine (archived 2012-09-07)
ZIP of Official Joy Programming Language Website (La Trobe University)
Joy homepage mirror
Joy source code (GitHub-Archive)
Freneger, Paul (August 2003). ""The JOY of forth"". ACM SIGPLAN Notices. 38 (8): 15–17. doi:10.1145/944579.944583.
von Thun, Manfred; Thomas, Reuben (October 9, 2001). ""Joy: Forth's Functional Cousin"" (PDF). Proceedings of the 17th EuroForth Conference.
Christopher Diggins (December 31, 2008). ""What is a Concatenative Language"". Dr. Dobbs.
Apter, Stevan. ""Functional Programming in Joy and K"". Vector. Archived from the original on 2008-08-28. Retrieved 2011-02-28.
mjoy, an interpreter in Lazarus for drawings with turtle graphics (Subset of Joy)",696166,https://en.wikipedia.org/wiki/Joy_(programming_language)
Jq (programming language),"jq is a very high-level lexically scoped functional programming language in which every JSON value is a constant. jq supports backtracking and managing indefinitely long streams of JSON data. It is related to the Icon and Haskell programming languages. The language supports a namespace-based module system and has some support for closures. In particular, functions and functional expressions can be used as parameters of other functions. 
The original implementation of jq was in Haskell before being immediately ported to C.","jq is a very high-level lexically scoped functional programming language in which every JSON value is a constant. jq supports backtracking and managing indefinitely long streams of JSON data. It is related to the Icon and Haskell programming languages. The language supports a namespace-based module system and has some support for closures. In particular, functions and functional expressions can be used as parameters of other functions. 
The original implementation of jq was in Haskell before being immediately ported to C.

History
jq was created by Stephen Dolan, and released in October 2012. 
It was described as being ""like sed for JSON data"".  Support for regular expressions was added in jq version 1.5.
A ""wrapper"" program for jq named yq adds support for YAML, XML and TOML. It was first released in 2017.The Go implementation, gojq, was initially released in 2019. gojq notably extends jq to include support for YAML.
The Rust implementation, jaq, has as its project goals a faster and more correct implementation of jq, while preserving compatibility with jq in most cases. Explicitly excluded from the project goals as of March 2024 are certain advanced features of jq such as modules, SQL-style operators, and a streaming parser for very large JSON documents.The jq implementation, jqjq, was initially released in 2022. jqjq notably can run itself, has a REPL and supports eval.

Usage
Command-line usage
jq is typically used at the command line and can be used with other command-line utilities, such as curl. Here is an example showing how the output of a curl command can be piped to a jq filter to determine the category names associated with this Wikipedia page:

The output produced by this pipeline consists of a stream of JSON strings, the first few of which are:

The curl command above uses the MediaWiki API for this page to produce a JSON response. 
The pipe | allows the output of curl to be accessed by jq, a standard Unix shell mechanism.The jq filter shown is an abbreviation for the jq pipeline:

This corresponds to the nested JSON structure produced by the call to curl. Notice that the jq pipeline is constructed in the same manner using the | character as the Unix-style pipeline.

Embedded usage
Both the C and the Go implementations provide libraries so that jq functionality can be embedded in other applications and programming environments.
For example, gojq has been integrated with SQLite so that a jq function is available in SQL statements. This function is marked as
""deterministic"" and
can therefore be used in ""CREATE INDEX"" commands.

Modes of operation
jq by default acts as a ""stream editor"" for JSON inputs, much
like the sed utility can be thought of as a ""stream editor"" for lines of text.
However jq has several other modes of operation: 

it can treat its input from one or more sources as lines of text;
it can gather a stream of inputs from a specified source into a JSON array;
it can parse its JSON inputs using a so-called ""streaming parser"" that produces a stream of [path, value] arrays for all ""leaf"" paths.The ""streaming parser"" is particularly useful when one of more of the
JSON inputs is too large to fit into memory, since its memory requirements
are typically quite small.  For example, for an arbitrarily large array of JSON objects,
the peak memory requirement is not much more than required to handle the largest
top-level object.
These modes of operation can, within certain limitations, be combined.

Syntax and semantics
Types
Every JSON value is itself a value in jq, which accordingly has the types shown in the table below.  The gojq and jaq implementations distinguish between integers and non-integer numbers. The gojq implementation supports unbounded-precision integer arithmetic, as did the original implementation of jq in Haskell.

null is a value, just like any other JSON scalar; it is not a pointer or a ""null-pointer"".
nan (corresponding to NaN) and infinite (see IEEE 754) are the only two jq scalars that are not also JSON values.

Forms
There are special syntactic forms for function creation, conditionals, stream reduction, and the module system.

Filters
Here is an example which shows how to define a named, parameterized filter for formatting an integer in any base
from 2 to 36 inclusive.
The implementation illustrates tacit (or point-free) programming:

The next example demonstrates the use of generators in the classic ""SEND MORE MONEY"" verbal arithmetic game:

Parsing expression grammars
There is a very close relationship between jq and the parsing expression grammar (PEG) formalism.

The relationship stems from the equivalence of the seven basic PEG operations and the jq constructs shown in the following table.

Ports and Variants
gojq is a ""pure Go"" implementation. There is also a Rust implementation of a dialect of jq named jaq for which a denotational semantics has been specified.

Notes
References
Bibliography
Others
External links
jq homepage
gojq - the Pure Go implementation
jaq - the Rust implementation
jqjq - the jq implementation
jq FAQ
Awesome jq - curated listing of jq-related resources
The jq Programming Language page on the Rosetta Code comparative programming tasks project site",72526819,https://en.wikipedia.org/wiki/Jq_(programming_language)
JS++,"JS++ is a proprietary programming language for web development that extends JavaScript with a sound type system. It includes imperative, object-oriented, functional, and generic programming features.","JS++ is a proprietary programming language for web development that extends JavaScript with a sound type system. It includes imperative, object-oriented, functional, and generic programming features.

History
JS++ first appeared on October 8, 2011. The modern implementation was announced at DeveloperWeek 2016 and released on May 31, 2016. The language is designed by Roger Poon and Anton Rapetov.

Syntax
Type annotations
Since JS++ is a superset of JavaScript, declaring types for variables is optional.

Features
JS++ features a type system that is sound.JS++ is able to efficiently analyze out-of-bounds errors at compile time.

Development tools
Compiler
The JS++ compiler is available for Windows, Mac OS X, and Linux. The compiler generates JavaScript output.

Editor integration
JS++ integrates with various code editors including Visual Studio Code, Atom, and Sublime Text.

Build tools
JS++ can be integrated with third-party build tools like Webpack.

Release history
See also
TypeScript
PureScript


== References ==",59825919,https://en.wikipedia.org/wiki/JS%2B%2B
Julia (programming language),"Julia is a high-level, general-purpose dynamic programming language, most commonly used for numerical analysis and computational science. Distinctive aspects of Julia's design include a type system with parametric polymorphism and the use of multiple dispatch as a core programming paradigm, efficient garbage collection, and a just-in-time (JIT) compiler (with support for ahead-of-time compilation).
Julia can be run similar to (interpreted) scripting languages (i.e. Julia has a REPL), and does by default using its runtime (when preinstalled), but Julia programs/source code can also optionally be sent to users in one ready-to-install/run file, which can be made quickly, not needing anything preinstalled. Julia programs can also be (separately) compiled to binary executables, even allowing no-source-code distribution. Such compilation is not needed for speed, since Julia is also compiled when running interactively, but it can help with hiding source code. Features of the language can be separately compiled, so Julia can be used, for example, with its runtime or without it (which allows for smaller executables and libraries but is limited in capabilities).
Julia programs can reuse libraries from other languages by calling them, e.g. calling C or Rust libraries, and Julia (libraries) can also be called from other languages, e.g. Python and R, and several Julia packages have been made easily available from those languages, in the form of Python and R libraries for corresponding Julia packages. Calling in either direction has been implemented for many languages such as all of these.
Julia's Visual Studio Code extension provides a fully-featured integrated development environment with support for debugging, linting, and profiling.","Julia is a high-level, general-purpose dynamic programming language, most commonly used for numerical analysis and computational science. Distinctive aspects of Julia's design include a type system with parametric polymorphism and the use of multiple dispatch as a core programming paradigm, efficient garbage collection, and a just-in-time (JIT) compiler (with support for ahead-of-time compilation).
Julia can be run similar to (interpreted) scripting languages (i.e. Julia has a REPL), and does by default using its runtime (when preinstalled), but Julia programs/source code can also optionally be sent to users in one ready-to-install/run file, which can be made quickly, not needing anything preinstalled. Julia programs can also be (separately) compiled to binary executables, even allowing no-source-code distribution. Such compilation is not needed for speed, since Julia is also compiled when running interactively, but it can help with hiding source code. Features of the language can be separately compiled, so Julia can be used, for example, with its runtime or without it (which allows for smaller executables and libraries but is limited in capabilities).
Julia programs can reuse libraries from other languages by calling them, e.g. calling C or Rust libraries, and Julia (libraries) can also be called from other languages, e.g. Python and R, and several Julia packages have been made easily available from those languages, in the form of Python and R libraries for corresponding Julia packages. Calling in either direction has been implemented for many languages such as all of these.
Julia's Visual Studio Code extension provides a fully-featured integrated development environment with support for debugging, linting, and profiling.

History
Work on Julia began in 2009, when Jeff Bezanson, Stefan Karpinski, Viral B. Shah, and Alan Edelman set out to create a free language that was both high-level and fast. On 14 February 2012, the team launched a website with a blog post explaining the language's mission. In an interview with InfoWorld in April 2012, Karpinski said of the name ""Julia"": ""There's no good reason, really. It just seemed like a pretty name."" Bezanson said he chose the name on the recommendation of a friend, then years later wrote:

Maybe julia stands for ""Jeff's uncommon lisp is automated""?
Julia's syntax is now considered stable, since version 1.0 in 2018, and Julia has a backward compatibility guarantee for 1.x and also a stability promise for the documented (stable) API, while in the years before in the early development prior to 0.7 the syntax (and semantics) was changed in new versions. All of the (registered package) ecosystem uses the new and improved syntax, and in most cases relies on new APIs that have been added regularly, and in some cases minor additional syntax added in a forward compatible way e.g. in Julia 1.7.
In the 10 years since the 2012 launch of pre-1.0 Julia, the community has grown. The Julia package ecosystem has over 11.8 million lines of code (including docs and tests). The JuliaCon academic conference for Julia users and developers has been held annually since 2014 with JuliaCon2020 welcoming over 28,900 unique viewers, and then JuliaCon2021 breaking all previous records (with more than 300 JuliaCon2021 presentations available for free on YouTube, up from 162 the year before), and 43,000 unique viewers during the conference.Three of the Julia co-creators are the recipients of the 2019 James H. Wilkinson Prize for Numerical Software (awarded every four years) ""for the creation of Julia, an innovative environment for the creation of high-performance tools that enable the analysis and solution of computational science problems."" Also, Alan Edelman, professor of applied mathematics at MIT, has been selected to receive the 2019 IEEE Computer Society Sidney Fernbach Award ""for outstanding breakthroughs in high-performance computing, linear algebra, and computational science and for contributions to the Julia programming language.""Both Julia 0.7 and version 1.0 were released on 8 August 2018. Work on Julia 0.7 was a ""huge undertaking"" (e.g., because of an ""entirely new optimizer""), and some changes were made to semantics, e.g. the iteration interface was simplified. Julia 1.1 was released in January 2019 with a new ""exception stack"" feature. Julia 1.2 was released in August 2019 with some built-in support for web browsers. Julia 1.3 added composable multi-threaded parallelism and a binary artifacts system for Julia packages. Julia 1.4 added syntax for generic array indexing to handle e.g. 0-based arrays. The memory model was also changed. Julia 1.5 released in August 2020 added record and replay debugging support, for Mozilla's rr tool.  The release changed the behavior in the REPL (soft scope) to the one used in Jupyter, but fully compatible with non-REPL code. Most of the thread API was marked as stable, and with this release ""arbitrary immutable objects—regardless of whether they have fields that reference mutable objects or not—can now be stack allocated"", reducing heap allocations, e.g. views are no longer allocating.  Julia 1.5 targeted so-called ""time-to-first-plot"" (TTFP, also called TTFX, for first X, the more general problem) performance, in general, the speed of compilation itself (as opposed to performance of the generated code), and added tools for developers to improve package loading. Julia 1.6 was the largest release since 1.0, faster on many fronts, e.g. introduced parallel precompilation and faster loading of packages, in some cases ""50x speedup in load times for large trees of binary artifacts"". As of version 1.7 Julia development is back to time-based releases. Julia 1.7.0 was released in November 2021 with many changes, e.g. a new faster random-number generator. Julia 1.7.3 was released on 25 May 2022, fixing some issues, including at least one security update, and 1.7.x is no longer supported. Julia 1.8 was released in 2022 (and versions up to 1.8.5 as a followup in January 2023, both fixing bugs (backporting) and ""invalidations"", thus compiling faster), with improvements for distributing Julia programs without source code,  and compiler speedup, in some cases by 25%,  and more controllable inlining (i.e. now also allowing applying @inline at the call site, not just on the function itself). Julia 1.9.0 was released on 7 May 2023 (and later 1.9.4, the latest stable version). It has many improvements, such as solving the TTFX/TTFP problem; older releases have precompilation for packages, but they were not precompiled fully to native code until 1.9, leading to slower first use. Precompiled packages, since version 1.9, can be up to hundreds of times faster on first use (e.g. for CSV.jl and DataFrames.jl), and to improve precompilation of packages a new package PrecompileTools.jl has been introduced.
Julia 1.10.0 was released on 25 December 2023 (and Julia 1.10.1 update on 14 February 2024) with many new features, e.g. improved package load times and a new parser with better error messages and improved stacktrace rendering.Julia 1.10.1 and 1.10.0 had a number of regressions, some with workarounds such as for plotting, and 1.10.2 was since released on 1 March 2024. 1.10.3 is upcoming with some fixes.

JuliaCon
Since 2014, the Julia Community has hosted an annual Julia Conference focused on developers and users. The first JuliaCon took place in Chicago and kickstarted the annual occurrence of the conference. Since 2014, the conference has taken place across a number of locations including MIT and the University of Maryland, Baltimore. The event audience has grown from a few dozen people to over 28,900 unique attendees during JuliaCon 2020, which took place virtually. JuliaCon 2021 also took place virtually with keynote addresses from professors William Kahan, the primary architect of the IEEE 754 floating-point standard (which virtually all CPUs and languages, including Julia, use), Jan Vitek, Xiaoye Sherry Li, and Soumith Chintala, a co-creator of PyTorch. JuliaCon grew to 43,000 unique attendees and more than 300 presentations (still freely accessible, plus for older years). JuliaCon 2022 will also be virtual held between July 27 and July 29, 2022, for the first time in several languages, not just in English.

Sponsors
The Julia language became a NumFOCUS fiscally sponsored project in 2014 in an effort to ensure the project's long-term sustainability. Jeremy Kepner at MIT Lincoln Laboratory was the founding sponsor of the Julia project in its early days. In addition, funds from the Gordon and Betty Moore Foundation, the Alfred P. Sloan Foundation, Intel, and agencies such as NSF, DARPA, NIH, NASA, and FAA have been essential to the development of Julia. Mozilla, the maker of Firefox web browser, with its research grants for H1 2019, sponsored ""a member of the official Julia team"" for the project ""Bringing Julia to the Browser"", meaning to Firefox  and other web browsers. The Julia language is also supported by individual donors on GitHub.

The Julia company
JuliaHub, Inc. was founded in 2015 as Julia Computing, Inc. by Viral B. Shah, Deepak Vinchhi, Alan Edelman, Jeff Bezanson, Stefan Karpinski and Keno Fischer.In June 2017, Julia Computing raised US$4.6 million in seed funding from General Catalyst and Founder Collective, the same month was ""granted $910,000 by the Alfred P. Sloan Foundation to support open-source Julia development, including $160,000 to promote diversity in the Julia community"", and in December 2019 the company got $1.1 million funding from the US government to ""develop a neural component machine learning tool to reduce the total energy consumption of heating, ventilation, and air conditioning (HVAC) systems in buildings"". In July 2021, Julia Computing announced they raised a $24 million Series A round led by Dorilton Ventures, which also owns Formula 1 team Williams Racing, that partnered with Julia Computing. Williams' Commercial Director said: ""Investing in companies building best-in-class cloud technology is a strategic focus for Dorilton and Julia's versatile platform, with revolutionary capabilities in simulation and modelling, is hugely relevant to our business. We look forward to embedding Julia Computing in the world's most technologically advanced sport"". In June 2023, JuliaHub received (again, now under its new name) a $13 million strategic new investment led by AE Industrial Partners HorizonX (""AEI HorizonX""). AEI HorizonX is a venture capital investment platform formed in partnership with The Boeing Company, which uses Julia. Tim Holy's work (at Washington University in St. Louis's Holy Lab) on Julia 1.9 (improving responsiveness) was funded by the Chan Zuckerberg Initiative.

Language features
Julia is a general-purpose programming language, while also originally designed for numerical/technical computing. It is also useful for low-level systems programming, as a specification language, high-level synthesis (HLS) tool (for hardware, e.g. FPGAs), and for web programming at both server and client side.
The main features of the language are:

Multiple dispatch: providing ability to define function behavior across combinations of argument types
Dynamic type system: types for documentation, optimization, and dispatch
Performance approaching that of statically-typed languages like C
A built-in package manager
Lisp-like macros and other metaprogramming facilities
Designed for parallel and distributed computing
Coroutines: lightweight green threading
Automatic generation of code for different argument types
Extensible conversions and promotions for numeric and other typesMultiple dispatch (also termed multimethods in Lisp) is a generalization of single dispatch –  the polymorphic mechanism used in common object-oriented programming (OOP) languages, such as Python, C++, Java, JavaScript, and Smalltalk –  that uses inheritance. In Julia, all concrete types are subtypes of abstract types, directly or indirectly subtypes of the Any type, which is the top of the type hierarchy. Concrete types can not themselves be subtyped the way they can in other languages; composition is used instead (see also inheritance vs subtyping).
By default, the Julia runtime must be pre-installed as user-provided source code is run. Alternatively, Julia (GUI) apps can be quickly bundled up into a single file with AppBundler.jl for ""building Julia GUI applications in modern desktop application installer formats. It uses Snap for Linux, MSIX for Windows, and DMG for MacOS as targets. It bundles full Julia within the app"". PackageCompiler.jl can build standalone executables that need no Julia source code to run.In Julia, everything is an object, much like object-oriented languages; however, unlike most object-oriented languages, all functions use multiple dispatch to select methods, rather than single dispatch. 
Most programming paradigms can be implemented using Julia's homoiconic macros and packages. Julia's syntactic macros (used for metaprogramming), like Lisp macros, are more powerful than text-substitution macros used in the preprocessor of some other languages such as C, because they work at the level of abstract syntax trees (ASTs). Julia's macro system is hygienic, but also supports deliberate capture when desired (like for anaphoric macros) using the esc construct.
Julia draws inspiration from various dialects of Lisp, including Scheme and Common Lisp, and it shares many features with Dylan, also a multiple-dispatch-oriented dynamic language (which features an ALGOL-like free-form infix syntax rather than a Lisp-like prefix syntax, while in Julia ""everything"" is an expression), and with Fortress, another numerical programming language (which features multiple dispatch and a sophisticated parametric type system). While Common Lisp Object System (CLOS) adds multiple dispatch to Common Lisp, not all functions are generic functions.
In Julia, Dylan, and Fortress, extensibility is the default, and the system's built-in functions are all generic and extensible. In Dylan, multiple dispatch is as fundamental as it is in Julia: all user-defined functions and even basic built-in operations like + are generic. Dylan's type system, however, does not fully support parametric types, which are more typical of the ML lineage of languages. By default, CLOS does not allow for dispatch on Common Lisp's parametric types; such extended dispatch semantics can only be added as an extension through the CLOS Metaobject Protocol. By convergent design, Fortress also features multiple dispatch on parametric types; unlike Julia, however, Fortress is statically rather than dynamically typed, with separate compiling and executing phases. The language features are summarized in the following table:

An example of the extensibility of Julia, the Unitful.jl package adds support for physical units of measurement to the language.

Interoperability
Julia has built-in support for calling C or Fortran language libraries using the @ccall macro. Additional libraries allow users to work with Python, R, C++, Java, and SQL.

Separately-compiled executables option
Julia can be compiled to binary executables with PackageCompiler.jl. Smaller executables can also be written using a static subset of the language provided by StaticCompiler.jl that does not support runtime dispatch (nor garbage collection, since excludes the runtime that provides it).

Interaction
The Julia official distribution includes an interactive command-line read–eval–print loop (REPL), with a searchable history, tab completion, and dedicated help and shell modes, which can be used to experiment and test code quickly. The following fragment represents a sample session example where strings are concatenated automatically by println:

The REPL gives user access to the system shell and to help mode, by pressing ; or ? after the prompt (preceding each command), respectively. It also keeps the history of commands, including between sessions. Code can be tested inside Julia's interactive session or saved into a file with a .jl extension and run from the command line by typing:

Julia uses UTF-8 and LaTeX codes, allowing it to support common math symbols for many operators, such as ∈ for the in operator, typable with \in then pressing Tab ↹ (i.e. uses LaTeX codes, or also possible by simply copy-pasting, e.g. √ and ∛ possible for sqrt and cbrt functions). Julia has support for the latest major release Unicode 15.0 (Julia 1.11-DEV supports latest 15.1 point release) for the languages of the world, even for source code, e.g. variable names (while it's recommened to use English for public code, and e.g. package names).
Julia is supported by Jupyter, an online interactive ""notebooks"" environment, and Pluto.jl, a ""reactive notebook"" (where notebooks are saved as pure Julia files), a possible replacement for the former kind. In addition Posit's (formerly RStudio Inc's) Quarto publishing system supports Julia, Python, R and Observable JavaScript (those languages have official support by the company, and can even be weaved together in the same notebook document, more languages are unofficially supported).The REPL can be extended with additional modes, and has been with packages, e.g. with an SQL mode, for database access, and RCall.jl adds an R mode, to work with the R language.

Use with other languages
Julia is in practice interoperable with other languages (e.g. majority of top 10–20 languages in popular use).  is used to call shared library functions individually (such as for written in C or Fortran), and packages are available to allow calling other languages (which do not provide C-exported functions directly) e.g. Python (with PythonCall.jl), R, MATLAB, C# (and other .NET languages with DotNET.jl, from them with JdotNET), JavaScript, Java (and other JVM languages, such as Scala with JavaCall.jl). And packages for other languages allow to call to Julia, e.g. from Python, R, Rust, Ruby, or C#. Such as with juliacall (part of PythonCall.jl, pyjulia is a different option) to call from Python and a different JuliaCall package for calling from R. Julia has also been used for hardware, i.e. to compile to VHDL, as a high-level synthesis (HLS) tool (for e.g. FPGAs).Julia has packages supporting markup languages such as HTML (and also for HTTP), XML, JSON and BSON, and for databases (such as PostgreSQL, Mongo, Oracle, including for TimesTen, MySQL, SQLite, Microsoft SQL Server, Amazon Redshift, Vertica, ODBC) and web use in general.

Package system
Julia has a built-in package manager and includes a default registry system. Packages are most often distributed as source code hosted on GitHub, though alternatives can also be used just as well. Packages can also be installed as binaries, using artifacts. Julia's package manager is used to query and compile packages, as well as managing environments. Federated package registries are supported, allowing registries other than the official to be added locally.

Implementation
Julia's core is implemented in Julia and C, together with C++ for the LLVM dependency. The code parsing, code-lowering, and bootstrapping were implemented in FemtoLisp, a Scheme dialect, up to version 1.10. Since that version the new pure-Julia package JuliaSyntax.jl, is used for the parsing (while the old one can still be chosen) which improves speed and ""greatly improves parser error messages in various cases"". The LLVM compiler infrastructure project is used as the back end for generating optimized machine code for all commonly-used platforms. With some exceptions, the standard library is implemented in Julia.

Current and future platforms
Julia has tier 1 macOS support, for 64-bit Apple Silicon Macs, natively (previously Apple M1-based Macs were only supported by running in Rosetta 2 emulation), and also fully supports Intel-based Macs. Julia 1.6 LTS however does not fully support the Arm-based Macs (was then marked experimental), and that support got first upgraded to tier 2 with Julia 1.8, then to tier 1. Windows on ARM has no official support yet.
Julia has four support tiers. All IA-32 processors completely implementing the i686 subarchitecture are supported and all 64-bit x86-64 (aka amd64), i.e. all less than about a decade old are supported. Armv8 (AArch64) processors are supported on second tier, and ARMv7 (AArch32) on third tier. Hundreds of packages are GPU-accelerated: CUDA (i.e. Nvidia GPUs; implementing PTX) has tier 1 support, with the help of an external package (and older versions of the package support down to CUDA 9). There are also additionally packages supporting other accelerators, such as Google's TPUs, and some Intel (integrated) GPUs, through oneAPI.jl, and AMD's GPUs have support with e.g. OpenCL; and experimental support for the AMD ROCm stack.On some platforms, Julia may need to be compiled from source code (e.g., the original Raspberry Pi), with specific build options, which has been done and unofficial pre-built binaries (and build instructions) are available. Julia has been built 
for several ARM platforms, from small Raspberry Pis to (recent) top-1 supercomputer Fugaku's ARM-based A64FX. PowerPC (64-bit) has tier 3 support, meaning it ""may or may not build"".
Julia is now supported in Raspbian while support is better for newer Pis, e.g., those with Armv7 or newer; the Julia support is promoted by the Raspberry Pi Foundation.While Julia requires an operating system by default, and has no official support to run without or on embedded system platforms such as Arduino, Julia code has still been run on it, with some limitations, i.e. on a baremetal 16 MHz 8-bit (ATmega328P) AVR-microcontroller Arduino with 2 KB RAM (plus 32 KB of flash memory).

Adoption
Julia has been adopted at many universities including MIT, Stanford, UC Berkeley and the University of Cape Town. Large private firms across many sectors have adopted the language including Amazon, IBM, JP Morgan AI Research, and ASML. Julia has also been used by government agencies including NASA and the FAA, as well as every US national energy laboratory.

Scientific computing and engineering
Amazon, for quantum computing and machine learning through Amazon SageMaker
ASML, for hard real-time programming with their machines
The Climate Modeling Alliance for climate change modeling
CERN, to analyze data from the Large Hadron Collider (LHCb experiment)
NASA and the Jet Propulsion Laboratory use Julia to model spacecraft separation dynamics, analyze TRAPPIST exoplanet datasets, and analyze cosmic microwave background data from the Big Bang
The Brazilian INPE, for space missions and satellite simulations
Embedded hardware to plan and execute flight of autonomous U.S. Air Force Research Laboratory VTOL drones

Pharmaceuticals and drug development
Julia is widely used for drug development in the pharmaceutical industry, having been adopted by Moderna, Pfizer, AstraZeneca, Procter & Gamble, and United Therapeutics.

Economics, finance, and political science
The Federal Reserve Bank of New York, for macroeconomic modeling in Julia since 2015, including estimates of COVID-19 shocks in 2021
Also the Bank of Canada, central bank, for macroeconomic modeling
BlackRock, the world's largest asset manager, for financial time-series analysis
Aviva, the UK's largest general insurer, for actuarial calculations
Mitre Corporation, for verification of published election results
Nobel laureate Thomas J. Sargent, for macroeconometric modeling

See also
Comparison of numerical-analysis software
Comparison of statistical packages
Differentiable programming
JuMP – an algebraic modeling language for mathematical optimization embedded in Julia
Python
Nim
Ring
Mojo

References
Further reading
Nagar, Sandeep (2017). Beginning Julia Programming: For Engineers and Scientists. Springer. ISBN 978-1-4842-3171-5.
Bezanson, J; Edelman, A; Karpinski, S; Shah, V. B (2017). ""Julia: A fresh approach to numerical computing"". SIAM Review. 59 (1): 65–98. arXiv:1411.1607. CiteSeerX 10.1.1.760.8894. doi:10.1137/141000671. S2CID 13026838.
Joshi, Anshul (2016). Julia for Data Science － Explore the world of data science from scratch with Julia by your side. Packt. ISBN 978-1-78355-386-0.
Tobin A Driscoll and Richard J. Braun (Aug. 2022). ""Fundamentals of Numerical Computation: Julia Edition"". SIAM. ISBN 978-1-611977-00-4.
C. T. Kelley (2022). ""Solving Nonlinear Equations with Iterative Methods: Solvers and Examples in Julia"", SIAM. ISBN 978-1-611977-26-4.
Kalicharan, Noel (2021). Julia - Bit by Bit. Undergraduate Topics in Computer Science. Springer. doi:10.1007/978-3-030-73936-2. ISBN 978-3-030-73936-2. S2CID 235917112.
Clemens Heitzinger (2022): ""Algorithms with Julia"", Springer, ISBN 978-3-031-16559-7.

External links

Official website
Julia on GitHub",38455554,https://en.wikipedia.org/wiki/Julia_(programming_language)
K (programming language),"K is a proprietary array processing programming language developed by Arthur Whitney and commercialized by Kx Systems. The language serves as the foundation for kdb+, an in-memory, column-based database, and other related financial products. The language, originally developed in 1993, is a variant of APL and contains elements of Scheme. Advocates of the language emphasize its speed, facility in handling arrays, and expressive syntax.","K is a proprietary array processing programming language developed by Arthur Whitney and commercialized by Kx Systems. The language serves as the foundation for kdb+, an in-memory, column-based database, and other related financial products. The language, originally developed in 1993, is a variant of APL and contains elements of Scheme. Advocates of the language emphasize its speed, facility in handling arrays, and expressive syntax.

History
Before developing K, Arthur Whitney had worked extensively with APL, first at I. P. Sharp Associates alongside Ken Iverson and Roger Hui, and later at Morgan Stanley developing financial applications. At Morgan Stanley, Whitney helped to develop A+, a variant of APL, to facilitate migrating APL applications from IBM mainframe computers to a network of Sun workstations. A+ had a smaller set of primitive functions and was designed for speed and to handle large sets of time series data.In 1993, Whitney left Morgan Stanley and developed the first version of the K language. At the same time he formed Kx Systems to commercialize the product and signed an exclusive contract with Union Bank of Switzerland (UBS). For the next four years he developed various financial and trading applications using K for UBS.
The contract ended in 1997 when UBS merged with Swiss Bank. In 1998, Kx Systems released kdb+, a database built on K. kdb was an in-memory, column-oriented database and included ksql, a query language with an SQL-like syntax. Since then, several financial products have been developed with K and kdb+. kdb+/tick and kdb+/taq were developed in 2001. kdb+, a 64-bit version of kdb+ was released in 2003 and kdb+/tick and kdb+/taq were released in 2004. kdb+ included Q, a language that merged the functions of the underlying K language and ksql.Whitney released a derivative of K called Shakti in 2018.

Overview
K shares key features with APL. They are both interpreted, interactive languages noted for concise and expressive syntax. They have simple rules of precedence based on right to left evaluation.  The languages contain a rich set of primitive functions designed for processing arrays. These primitive functions include mathematical operations that work on arrays as whole data objects, and array operations, such as sorting or reversing the order of an array. In addition, the language contains special operators that combine with primitive functions to perform types of iteration and recursion.  As a result, complex and extended transformations of a dataset can be expressed as a chain of sub-expressions, with each link performing a segment of the calculation and passing the results to the next link in the chain.
Like APL, the primitive functions and operators are represented by single or double characters; however, unlike APL, K restricts itself to the ASCII character set (as does another APL variant, J). To allow for this, the set of primitive functions for K is smaller and heavily overloaded, with each of the ASCII symbols representing two or more distinct functions or operations. In a given expression, the actual function referenced is determined by the context. As a result, K expressions can be opaque and difficult to parse for humans. For example, in the following contrived expression the exclamation point ! refers to three distinct functions:

2!!7!4
Reading from right to left the first ! is modulo division that is performed on 7 and 4 resulting in 3. The next ! is enumeration and lists the integers less than 3, resulting in the list 0 1 2. The final ! is rotation where the list on the right is rotated two times to the left producing the final result of 2 0 1.
The second core distinction of K is that functions are first-class objects, a concept borrowed from Scheme. First-class functions can be used in the same contexts where a data value can be used.  Functions can be specified as anonymous expressions and used directly with other expressions. Function expressions are specified in K using curly brackets. For example, in the following expression a quadratic expression is defined as a function and applied to the values 0 1 2 and 3:

In K, named functions are simply function expressions stored to a variable in the same way any data value is stored to a variable.

Functions can be passed as an argument to another function or returned as a result from a function.

Examples
K is an interpreted language where every statement is evaluated and its results displayed immediately. Literal expressions such as strings evaluate to themselves. Consequently, the Hello world-program is trivial:

""Hello world!""

The following expression sorts a list of strings by their lengths:

The expression is evaluated from right to left as follows:

#:'x returns the length of each word in the list x.
> returns the indices that would sort a list of values in descending order.
@ uses the integer values on the right to index into the original list of strings.A function to determine if a number is prime can be written as:

The function is evaluated from right to left:

!x enumerate the positive integers less than x.
2_ drops the first two elements of the enumeration (0 and 1).
x!/: performs modulo division between the original integer and each value in the truncated list.
&/ find the minimum value of the list of modulo result.If x is not prime then one of the values returned by the modulo operation will be 0 and consequently the minimal value of the list. If x is prime then the minimal value will be 1, because x mod 2 is 1 for any prime greater than 2.
The function below can be used to list all of the prime numbers between 1 and R with:

The expression is evaluated from right to left

!R enumerate the integers less than R.
' apply each value of the enumeration to the prime number function on the left. This will return a list of 0's and 1's.
& return the indices of the list where the value is 1.
2_ drop the first two elements of the enumeration (0 and 1)

K financial products
K is the foundation for a family of financial products. Kdb+ is an in-memory, column-based database with much of the same functions of a relational database management system. The database supports SQL, SQL-92 and ksql, a query language with a syntax similar to SQL and designed for column based queries and array analysis.
Kdb+ is available for several operating systems, including Solaris, Linux, macOS, and Windows (32-bit or 64-bit).

See also
J, another APL-inspired language
Q, the language of kdb+ and a new merged version of K and ksql.

References
External links
Official website, Kx Systems
Official website, kdb+
Overview of K (with a link to K reference card)
Dennis Shasha - K as a Prototyping Language
K by Arthur Whitney (2005)
oK REPL for a K clone
Kona an open-source K3 implementation",890956,https://en.wikipedia.org/wiki/K_(programming_language)
Kinetic Rule Language,"Kinetic Rule Language (KRL) is a rule-based programming language for creating applications on the Live Web. KRL programs, or rulesets, comprise a number of rules that respond to particular events.  KRL has been promoted as language for building personal clouds.KRL is part of an open-source project called KRE, for Kinetic Rules Engine, developed by Kynetx, Inc.","Kinetic Rule Language (KRL) is a rule-based programming language for creating applications on the Live Web. KRL programs, or rulesets, comprise a number of rules that respond to particular events.  KRL has been promoted as language for building personal clouds.KRL is part of an open-source project called KRE, for Kinetic Rules Engine, developed by Kynetx, Inc.

History
KRL was designed by Phil Windley at Kynetx, beginning in 2007. Development of the language has since expanded to include libraries and modules for a variety of web services, including Twitter, Facebook, and Twilio.

Philosophy and design
KRL is event-based with strict evaluation, single assignment, and dynamic typing. In event-driven programming, events, a notification that something happened, control the flow of execution. KRL supports a programming model based on three key ideas:Entity orientation – The programming model of KRL has identity as a core feature. KRL programs execute on behalf of a particular entity. The idea of entity is built into the underlying semantics of the language. The entity orientation of KRL is supported by the underlying KRE (Kynetx Rules Engine) and so is usable by any program running in the engine—even one not written in KRL. The next two features illustrate why identity is crucial to the programming model.
Entity orientation requires that KRL execution environments support the notion of entity. Rulesets are installed for each entity.
Event binding – rules in KRL bind event patterns to actions. Event patterns are specified using event expressions. Events and actions are both extensible so that programmers are free to define events and actions that are relevant to their problem space.
Events are rarely addressed to a specific ruleset. Rather events are raised on behalf of a particular entity and thus any rule selected from the entity's installed rulesets runs on behalf of that same entity. This concept is called “salience.” An event is salient for a given entity if that entity has installed a rule that listens for that event.
A single event can fire rules from multiple rulesets within the entity's execution environment. Which rules are selected and run depends on the rulesets installed.
Persistent data values – KRL has a class of variables called “persistent variables” or just “persistents”. There are two kinds of persistents: application variables and entity variables. Both are closed over the ruleset they are in, meaning that they are only visible to code executing within the ruleset. Application variables are stored for the ruleset and are available to any entity executing the ruleset. Entity variable values are only visible to the entity for whom they were stored. Application variables are roughly analogous to class variables. Entity variables are like instance variables.
Entity variables, in particular, are a very powerful concept since they provide KRL programmers with the ability to store persistent values without the headache of configuring, linking, and using a database for most things. Because a ruleset represents a closure over its entity variables, every ruleset potentially represents a persistent data object.

Event-Condition-Action
KRL is called an event condition action or ECA rule language because of the roles that those three fundamental parts of a rule play:

Events – Events trigger specific things to occur. Events are like the trigger of the ""gun""—the rule. Without the event to trigger the rule, nothing happens.
Conditions – Conditions are similar to the safety of a gun. If the conditional expression does not return true, the rule does not fire. Just as a gun either shoots or doesn't shoot based upon the safety, there is no else statement on conditionals. If you want a rule to fire in the opposite case, you can use the not fired postlude to trigger another event, or you can have a rule with a conditional which tests for the opposite case.
Actions – Actions are like the bullet coming out of the gun; they are the final result of the rule. A rule may have multiple actions.Besides a collection of rules, KRL rulesets also contain a meta section for specifying information about the ruleset, a dispatch section for providing clues about event salience, and a global section for global definitions. Each rule conforms to the pattern for ECA rule languages given above with some significant additions.
The basic structure of a KRL rule is as follows:

rule <name> {
  select when <eventexpr>
  pre {
    <declarations>
  }
  if <expr> then
    <action>
  fired {
    <effects>
  } else {
    <effects>
  }
}

Event expressions in the select statement declare the conditions under which the rule will be selected.
Declarations in the rule prelude allow values to be calculated and store for use later in the rule
Conditional expressions determine whether a selected rule fires.
Actions can be either built-in or user defined and specify the action of the rule
Statements in the rule's postlude (fired...else...) affect persistent variables and raise further events.

Event generators
KRL events are raised by other rules of event generators commonly referred to as ""endpoints"". Events are commonly raised over HTTP using a model that conforms to the Evented API, but KRL is transport agnostic. For example, events could be transported by email, SMS, MQTT, or any other system supporting push-style notifications. Because the Evented API is a specialization of the webhook concept, any system that supports webhooks can raise events for KRL.
KRL uses event channels to identify the entity for which the event is raised. An entity can have any number of event channels. Event channels are encoded in the URL for events transported over HTTP.
An endpoint that generates an event may be observing some activity directly and reporting salient state changes or it might just be reporting or transforming event data from another source (e.g., a webhook).
Endpoints are responsible for

raising relevant events to the event processor,
responding to directives from the event processor, and
maintaining state to link separate interactions with the event processor together in meaningful ways to create context.

Rules and rule execution
KRL is a deterministic rule language. This means that KRL programs consist of a set of rules that take an action when triggered. Just as functional, object-oriented, and imperative languages are all different, rule languages also require a different way of thinking. Consequently, writing a KRL ruleset is not a traditional programming task.
At its simplest, a rule is a conditional action. The action can be anything appropriate to the domain. For augmenting web pages, actions are page modifiers. In other domains, the action can be whatever the endpoint can consume. When a rule's action is taken, we say that the rule ""fired."" Note that the action is conditional: the action is taken only when the rule is selected and its premise is true.
In the first stage, the rule is either selected or not, based on the event pattern in the event expression. The event expression of a rule follows the select keyword in the rule. For example, in the web domain, this most often consists of a regular expression to match with the URL of the page being augmented. Thus, in the first stage the rule is selected only for certain web pages.
The second stage of the conditional firing of the rule is testing its premise, which consists of a predicate that is used to test the context in which the rule is being evaluated. This check is done after the rule's prelude section, where values are declared, so that it has the benefit of any computation needed to create or manipulate the context. The predicate of the conditional is optional, so it is possible to write a rule that always fires because its selector always selects. However, most interesting rulesets will contain rules that only fire under certain circumstances.
The following example shows a simple KRL rule:

rule good_morning {
  select when pageview url #example.com#
  if morning() then
    notify(“Welcome!”, “Good morning!”)
}

This rule would send a “good morning” notification to visitors of any page in the archives of a web site (as denoted by the URL path) if it's morning where the user is.

Events and evented systems
Events are the notification of a detectable condition in a computer system.  The detectable condition will typically be seen as a state change.
These are three required parts of event detection and notification:

A change of state
A process notices the state change
The process sends a notification of the state changeNotifications are data transfers, not transfers of execution control. This is one of the hallmarks of evented systems that distinguishes them from other types of systems.  Interrogatory-style systems use a request-response mode of interaction: “Will you do this?”  Imperative-style systems use an RPC mode of interaction: “Do this!” In contrast, event interactions are declarative, stating only that a specific state change happened: “This happened”.
Because they are declarative, event notifications impose the semantics of what an event means on the processor rather than a generator. The event generator doesn’t know how a given processor will interpret the event. What’s more, it is not even required that an event processor take any action whatsoever.  Each processor is free to interpret the event independently of other processors and generators in the system according to its context and particular purpose.
The event generator “raises an event”; in other words, it sends a notification that a state change occurred. The event processor “listens for” or “handles” these events.

References
External links
KRL Documentation
Kinetic Rules Engine, the open-source implementation hosted on GitHub
Articles on KRL at Phil Windley's blog",7303776,https://en.wikipedia.org/wiki/Kinetic_Rule_Language
Kojo (learning environment),"Kojo is a programming language and integrated development environment (IDE) for computer programming and learning. It has many different features that enable playing, exploring, creating, and learning in the areas of computer programming, mental skills, (interactive) math, graphics, art, music, science, animation, games, and electronics. Kojo draws ideas from the programming languages Logo and Processing.Kojo is open-source software. It was created, and is actively developed, by Lalit Pant, a computer programmer and teacher living in Dehradun, India. Kojo provides domain-specific languages (DSLs) for its different areas of learning, and as such can be considered an educational programming language.
Kojo is written in, and its approach is based on, the programming language Scala, where users begin with a simple subset of the language and progress in steps. Its graphical user interface is based on Java Swing; a former version was based on the Java NetBeans platform.
Lalit chose Scala as the underlying language for Kojo because of its low barrier to entry and potential power.Kojo has been used in schools and classes around the world. Some of these include:

The State of Goa, within its ICT/coding curriculum.
Himjyoti School, Dehradun, India.
Mondrian House School, Dehradun, India.
Rishi Valley School, Madanapalle, India.
Cardinal Forest Elementary School, Springfield, Virginia, USA.
Diablo Valley College, Pleasant Hill, California, USA.
Our Lady's Catholic High School, Preston, England.
A Swedish 4th grade class consisting of 10-year-old children. Kojo has been featured by Dagens Nyheter (DN) and Computer Sweden as a result of the work done by this class.
Events like Silicon Valley Code Camp, CoderDojo, Hack The Future, and Meetups.The development of Kojo is partly sponsored by Lightbend, formerly TypeSafe, and Lund University, Computer Science Department, where Kojo is used to introduce children and teachers to computer programming. Professor Björn Regnell of Lund University has an informative presentation on the subject. Professor Regnell writes, in translation: ""Kojo is the best tool, with a low barrier of entry, I have seen for making real text based programming available for children, that is also usable all the way up to university level"".Kojo provides rich support for programming and learning in the Turkish language as of the latest release in 2021 and beyond.","Kojo is a programming language and integrated development environment (IDE) for computer programming and learning. It has many different features that enable playing, exploring, creating, and learning in the areas of computer programming, mental skills, (interactive) math, graphics, art, music, science, animation, games, and electronics. Kojo draws ideas from the programming languages Logo and Processing.Kojo is open-source software. It was created, and is actively developed, by Lalit Pant, a computer programmer and teacher living in Dehradun, India. Kojo provides domain-specific languages (DSLs) for its different areas of learning, and as such can be considered an educational programming language.
Kojo is written in, and its approach is based on, the programming language Scala, where users begin with a simple subset of the language and progress in steps. Its graphical user interface is based on Java Swing; a former version was based on the Java NetBeans platform.
Lalit chose Scala as the underlying language for Kojo because of its low barrier to entry and potential power.Kojo has been used in schools and classes around the world. Some of these include:

The State of Goa, within its ICT/coding curriculum.
Himjyoti School, Dehradun, India.
Mondrian House School, Dehradun, India.
Rishi Valley School, Madanapalle, India.
Cardinal Forest Elementary School, Springfield, Virginia, USA.
Diablo Valley College, Pleasant Hill, California, USA.
Our Lady's Catholic High School, Preston, England.
A Swedish 4th grade class consisting of 10-year-old children. Kojo has been featured by Dagens Nyheter (DN) and Computer Sweden as a result of the work done by this class.
Events like Silicon Valley Code Camp, CoderDojo, Hack The Future, and Meetups.The development of Kojo is partly sponsored by Lightbend, formerly TypeSafe, and Lund University, Computer Science Department, where Kojo is used to introduce children and teachers to computer programming. Professor Björn Regnell of Lund University has an informative presentation on the subject. Professor Regnell writes, in translation: ""Kojo is the best tool, with a low barrier of entry, I have seen for making real text based programming available for children, that is also usable all the way up to university level"".Kojo provides rich support for programming and learning in the Turkish language as of the latest release in 2021 and beyond.

See also
Thonny
Microsoft Small Basic
BASIC-256
Toolbox
JUDO


== References ==",30843423,https://en.wikipedia.org/wiki/Kojo_(learning_environment)
KOMPILER,"In computing, the KOMPILER was one of the first language compilation and runtime systems for International Business Machines' IBM 701, the fastest commercial U.S. computer available in 1955.
Information on KOMPILER is listed on page 16 of Volume 2, Number 5 (May 1959) of the Communications of the ACM. Known versions are KOMPILER 2 for IBM 701 and KOMPILER 3 for the IBM 704. KOMPILER was eventually replaced by a Fortran compiler on the IBM 704.","In computing, the KOMPILER was one of the first language compilation and runtime systems for International Business Machines' IBM 701, the fastest commercial U.S. computer available in 1955.
Information on KOMPILER is listed on page 16 of Volume 2, Number 5 (May 1959) of the Communications of the ACM. Known versions are KOMPILER 2 for IBM 701 and KOMPILER 3 for the IBM 704. KOMPILER was eventually replaced by a Fortran compiler on the IBM 704.

See also
PACT (compiler)

References
External links
HOPL: Kompiler.",17212,https://en.wikipedia.org/wiki/KOMPILER
Kotlin (programming language),"Kotlin () is a cross-platform, statically typed, general-purpose high-level programming language with type inference. Kotlin is designed to interoperate fully with Java, and the JVM version of Kotlin's standard library depends on the Java Class Library,
but type inference allows its syntax to be more concise. Kotlin mainly targets the JVM, but also compiles to JavaScript (e.g., for frontend web applications using React) or native code via LLVM (e.g., for native iOS apps sharing business logic with Android apps). Language development costs are borne by JetBrains, while the Kotlin Foundation protects the Kotlin trademark.On 7 May 2019, Google announced that the Kotlin programming language was now its preferred language for Android app developers. Since the release of Android Studio 3.0 in October 2017, Kotlin has been included as an alternative to the standard Java compiler. The Android Kotlin compiler produces Java 8 bytecode by default (which runs in any later JVM), but lets the programmer choose to target Java 9 up to 20, for optimization, or allows for more features; has bidirectional record class interoperability support for JVM, introduced in Java 16, considered stable as of Kotlin 1.5.
Kotlin has support for the web with Kotlin/JS, either through a classic interpreter-based backend which has been declared stable since version 1.3, or an intermediate representation-based backend which has been declared stable since version 1.8. Kotlin/Native (for e.g. Apple silicon support) is considered beta since version 1.3.","Kotlin () is a cross-platform, statically typed, general-purpose high-level programming language with type inference. Kotlin is designed to interoperate fully with Java, and the JVM version of Kotlin's standard library depends on the Java Class Library,
but type inference allows its syntax to be more concise. Kotlin mainly targets the JVM, but also compiles to JavaScript (e.g., for frontend web applications using React) or native code via LLVM (e.g., for native iOS apps sharing business logic with Android apps). Language development costs are borne by JetBrains, while the Kotlin Foundation protects the Kotlin trademark.On 7 May 2019, Google announced that the Kotlin programming language was now its preferred language for Android app developers. Since the release of Android Studio 3.0 in October 2017, Kotlin has been included as an alternative to the standard Java compiler. The Android Kotlin compiler produces Java 8 bytecode by default (which runs in any later JVM), but lets the programmer choose to target Java 9 up to 20, for optimization, or allows for more features; has bidirectional record class interoperability support for JVM, introduced in Java 16, considered stable as of Kotlin 1.5.
Kotlin has support for the web with Kotlin/JS, either through a classic interpreter-based backend which has been declared stable since version 1.3, or an intermediate representation-based backend which has been declared stable since version 1.8. Kotlin/Native (for e.g. Apple silicon support) is considered beta since version 1.3.

History
In July 2011, JetBrains unveiled Project Kotlin, a new language for the JVM, which had been under development for a year. JetBrains lead Dmitry Jemerov said that most languages did not have the features they were looking for, with the exception of Scala. However, he cited the slow compilation time of Scala as a deficiency. One of the stated goals of Kotlin is to compile as quickly as Java. In February 2012, JetBrains open sourced the project under the Apache 2 license.The name comes from Kotlin Island, near St. Petersburg. Andrey Breslav mentioned that the team decided to name it after an island, just like Java was named after the Indonesian island of Java (though Java, the programming language's name, is said to have been inspired by ""java"" the American slang term for coffee, which itself derives from the island name).JetBrains hoped that the new language would drive IntelliJ IDEA sales.The first commit to the Kotlin Git repository was on November 8, 2010.Kotlin 1.0 was released on February 15, 2016. This is considered to be the first officially stable release and JetBrains has committed to long-term backwards compatibility starting with this version.
At Google I/O 2017, Google announced first-class support for Kotlin on Android.Kotlin 1.2 was released on November 28, 2017. Sharing code between JVM and JavaScript platforms feature was newly added to this release (multiplatform programming is by now a beta feature upgraded from ""experimental""). A full-stack demo has been made with the new Kotlin/JS Gradle Plugin.Kotlin 1.3 was released on 29 October 2018, bringing coroutines for asynchronous programming.On 7 May 2019, Google announced that the Kotlin programming language is now its preferred language for Android app developers.Kotlin 1.4 was released in August 2020, with e.g. some slight changes to the support for Apple's platforms, i.e. to the Objective-C/Swift interop.Kotlin 1.5 was released in May 2021.
Kotlin 1.6 was released in November 2021.
Kotlin 1.7 was released in June 2022, including the alpha version of the new Kotlin K2 compiler.Kotlin 1.8 was released in December 2022, 1.8.0 was released on January 11, 2023.Kotlin 1.9 was released in July 2023, 1.9.0 was released on July 6, 2023.

Design
Development lead Andrey Breslav has said that Kotlin is designed to be an industrial-strength object-oriented language, and a ""better language"" than Java, but still be fully interoperable with Java code, allowing companies to make a gradual migration from Java to Kotlin.Semicolons are optional as a statement terminator; in most cases a newline is sufficient for the compiler to deduce that the statement has ended.Kotlin variable declarations and parameter lists have the data type come after the variable name (and with a colon separator), similar to Ada, BASIC, Pascal, TypeScript and Rust. This, according to an article from Roman Elizarov, current project lead, results in alignment of variable names and is more pleasing to eyes, especially when there are a few variable declarations in succession, and one or more of the types is too complex for type inference, or needs to be declared explicitly for human readers to understand.Variables in Kotlin can be read-only, declared with the val keyword, or mutable, declared with the var keyword.Class members are public by default, and classes themselves are final by default, meaning that creating a derived class is disabled unless the base class is declared with the open keyword.
In addition to the classes and member functions (which are equivalent to methods) of object-oriented programming, Kotlin also supports procedural programming with the use of functions.
Kotlin functions and constructors support default arguments, variable-length argument lists, named arguments, and overloading by unique signature. Class member functions are virtual, i.e. dispatched based on the runtime type of the object they are called on.
Kotlin 1.3 added support for contracts, which are stable for the standard library declarations, but still experimental for user-defined declarations. Contracts are inspired by Eiffel's design by contract programming paradigm.
Kotlin code may be compiled to JavaScript, allowing for interoperability between code written in the two languages. This can be used either to write full web applications in Kotlin, or to share code between a Kotlin backend and a JavaScript frontend.

Syntax
Procedural programming style
Kotlin relaxes Java's restriction of allowing static methods and variables to exist only within a class body. Static objects and functions can be defined at the top level of the package without needing a redundant class level. For compatibility with Java, Kotlin provides a JvmName annotation which specifies a class name used when the package is viewed from a Java project. For example, @file:JvmName(""JavaClassName"").

Main entry point
As in C, C++, C#, Java, and Go, the entry point to a Kotlin program is a function named ""main"", which may be passed an array containing any command-line arguments. This is optional since Kotlin 1.3. Perl, PHP, and Unix shell–style string interpolation is supported. Type inference is also supported.

Extension functions
Similar to C#, Kotlin allows adding an extension function to any class without the formalities of creating a derived class with new functions. An extension function has access to all the public interface of a class, which it can use to create a new function interface to a target class. An extension function will appear exactly like a function of the class and will be shown in code completion inspection of class functions. For example:

By placing the preceding code in the top-level of a package, the String class is extended to include a lastChar function that was not included in the original definition of the String class.

Unpack arguments with spread operator
Similar to Python, the spread operator asterisk (*) unpacks an array's contents as individual arguments to a function, e.g:

Destructuring declarations
Destructuring declarations decompose an object into multiple variables at once, e.g. a 2D coordinate object might be destructured into two integers, x and y.
For example, the Map.Entry object supports destructuring to simplify access to its key and value fields:

Nested functions
Kotlin allows local functions to be declared inside of other functions or methods.

Classes are final by default
In Kotlin, to derive a new class from a base class type, the base class needs to be explicitly marked as ""open"".  This is in contrast to most object-oriented languages such as Java where classes are open by default.
Example of a base class that is open to deriving a new subclass from it:

Abstract classes are open by default
Abstract classes define abstract or ""pure virtual"" placeholder functions that will be defined in a derived class. Abstract classes are open by default.

Classes are public by default
Kotlin provides the following keywords to restrict visibility for top-level declaration, such as classes, and for class members: public, internal, protected, and private.
When applied to a class member:

When applied to a top-level declaration:

Example:

Primary constructor vs. secondary constructors
Kotlin supports the specification of a ""primary constructor"" as part of the class definition itself, consisting of an argument list following the class name. This argument list supports an expanded syntax on Kotlin's standard function argument lists that enables declaration of class properties in the primary constructor, including visibility, extensibility, and mutability attributes. Additionally, when defining a subclass, properties in super-interfaces and super-classes can be overridden in the primary constructor.

However, in cases where more than one constructor is needed for a class, a more general constructor can be defined using secondary constructor syntax, which closely resembles the constructor syntax used in most object-oriented languages like C++, C#, and Java.

Sealed classes
Sealed classes and interfaces restrict subclass hierarchies, meaning more control over the inheritance hierarchy.
Declaration of sealed interface and class:

All the subclasses of the sealed class are defined at compile time. 
No new subclasses can be added to it after the compilation of the module having the sealed class.
For example, a sealed class in a compiled jar file cannot be subclassed.

Data classes
Kotlin's data class construct defines classes whose primary purpose is storing data. This construct is similar to normal classes except that the key functions equals, toString, and hashCode are automatically generated from the class properties. In Java, such classes are expected to provide a standard assortment of functions including those. Data classes are not required to declare any methods, though each must have at least one property. A data class often is written without a body, though it is possible to give a data class any methods or secondary constructors that are valid for any other class. The data keyword is used before the class keyword to define a data class.

Kotlin interactive shell
Kotlin as a scripting language
Kotlin can also be used as a scripting language. A script is a Kotlin source file using the .kts filename extension, with executable source code at the top-level scope:

Scripts can be run by passing the -script option and the corresponding script file to the compiler.

Null safety
Kotlin makes a distinction between nullable and non-nullable data types. All nullable objects must be declared with a ""?"" postfix after the type name. Operations on nullable objects need special care from developers: a null-check must be performed before using the value, either explicitly, or with the aid of Kotlin's null-safe operators:

?. (the safe navigation operator) can be used to safely access a method or property of a possibly null object. If the object is null, the method will not be called and the expression evaluates to null.  Example:

?: (the null coalescing operator) is a binary operator that returns the first operand, if non-null, else the second operand. It is often referred to as the Elvis operator, due to its resemblance to an emoticon representation of Elvis Presley.

Lambdas
Kotlin provides support for higher-order functions and anonymous functions, or lambdas.

Lambdas are declared using braces, {  }. If a lambda takes parameters, they are declared within the braces and followed by the -> operator.

Complex ""hello world"" example
Tools
Android Studio  (based on IntelliJ IDEA) has official support for Kotlin, starting from Android Studio 3.
Integration with common Java build tools is supported, including Apache Maven, Apache Ant, and Gradle.
Emacs has a Kotlin Mode in its MELPA package repository.
JetBrains also provides a plugin for Eclipse.
IntelliJ IDEA has plug-in support for Kotlin. IntelliJ IDEA 15 was the first version to bundle the Kotlin plugin in the IntelliJ Installer, and to provide Kotlin support out of the box.

Applications
When Kotlin was announced as an official Android development language at Google I/O in May 2017, it became the third language fully supported for Android, after Java and C++. As of 2020, Kotlin is the most widely used language on Android, with Google estimating that 70% of the top 1,000 apps on the Play Store are written in Kotlin. Google itself has 60 apps written in Kotlin, including Maps and Drive. Many Android apps, such as Google Home, are in the process of being migrated to Kotlin, and therefore use both Kotlin and Java. Kotlin on Android is seen as beneficial for its null-pointer safety, as well as for its features that make for shorter, more readable code.In addition to its prominent use on Android, Kotlin is gaining traction in server-side development. The Spring Framework officially added Kotlin support with version 5, on 4 January 2017. To further support Kotlin, Spring has translated all its documentation to Kotlin, and added built-in support for many Kotlin-specific features such as coroutines. In addition to Spring, JetBrains has produced a Kotlin-first framework called Ktor for building web applications.In 2020, JetBrains found in a survey of developers who use Kotlin that 56% were using Kotlin for mobile apps, while 47% were using it for a web back-end. Just over a third of all Kotlin developers said that they were migrating to Kotlin from another language. Most Kotlin users were targeting Android (or otherwise on the JVM), with only 6% using Kotlin Native.

Adoption
In 2018, Kotlin was the fastest growing language on GitHub, with 2.6 times more developers compared to 2017. It is the fourth most loved programming language according to the 2020 Stack Overflow Developer Survey.Kotlin was also awarded the O'Reilly Open Source Software Conference Breakout Award for 2019.Many companies / organizations have used Kotlin for backend development:

Allegro
Amazon
Atlassian
Cash App
Flux
Google
Gradle
JetBrains
Meshcloud
Norwegian Tax Administration
OLX
Pivotal
Rocket Travel
Shazam
ZalandoSome companies / organizations have used Kotlin for web development:

Barclay's Bank
Data2viz
Fritz2
JetBrainsA number of companies have publicly stated they were using Kotlin:

Basecamp
Corda, a distributed ledger developed by a consortium of well-known banks (such as Goldman Sachs, Wells Fargo, J.P. Morgan, Deutsche Bank, UBS, HSBC, BNP Paribas, and Société Générale), has over 90% Kotlin code in its codebase.
Coursera
DripStat
Duolingo
Netflix
Pinterest
Trello
Uber

See also
Comparison of programming languages

References
This article contains quotations from Kotlin tutorials which are released under an Apache 2.0 license.

External links
Official website",41819039,https://en.wikipedia.org/wiki/Kotlin_(programming_language)
Language interoperability,"Language interoperability is the capability of two different programming languages to natively interact as part of the same system and operate on the same kind of data structures.There are many ways programming languages are interoperable with one another. HTML, CSS, and JavaScript are interoperable as they are used in tandem in webpages. Some object oriented languages are interoperable thanks to their shared hosting virtual machine (e.g. .NET CLI compliant languages in the Common Language Runtime and JVM compliant languages in the Java Virtual Machine).","Language interoperability is the capability of two different programming languages to natively interact as part of the same system and operate on the same kind of data structures.There are many ways programming languages are interoperable with one another. HTML, CSS, and JavaScript are interoperable as they are used in tandem in webpages. Some object oriented languages are interoperable thanks to their shared hosting virtual machine (e.g. .NET CLI compliant languages in the Common Language Runtime and JVM compliant languages in the Java Virtual Machine).

Methods for interoperability
Object models
Object models are standardized models which allow objects to be represented in a language-agnostic way, such that the same objects may be used across programs and across languages. CORBA and the COM are the most popular object models.

Virtual machines
A virtual machine (VM) is a specialised intermediate language that several different languages compile down to. Languages that use the same virtual machine can interoperate, as they will share a memory model and compiler and thus libraries from one language can be re-used for others on the same VM. VMs can incorporate type systems to ensure the correctness of participating languages and give languages a common ground for their type information. The use of an intermediate language during compilation or interpretation can provide more opportunities for optimisation.

Foreign function interfaces
Foreign function interfaces (FFI) allow programs written in one language to call functions written in another language. There are often considerations that preclude simply treating foreign functions as functions written in the host language, such as differences in types and execution model. Foreign function interfaces enable building wrapper libraries that provide functionality from a library from another language in the host language, often in a style that is more idiomatic for the language. Most languages have FFIs to C, which is the ""lingua franca"" of programming today.

Challenges
Object model differences
Object oriented languages attempt to pair containers of data with code, but how each language chooses how to do that may be slightly different. Those design decisions do not always map to other languages easily. For instance, classes using multiple inheritance from a language that permits it will not translate well to a language that does not permit multiple inheritance. A common approach to this issue is defining a subset of a language that is compatible with another language's features. This approach does mean in order for the code using features outside the subset to interoperate it will need to wrap some of its interfaces into classes that can be understood by the subset.

Memory models
Differences in how programming languages handle de-allocation of memory is another issue when trying create interoperability. Languages with automatic de-allocation will not interoperate well with those with manual de-allocation, and those with deterministic destruction will be incompatible with those with nondeterministic destruction. Based on the constraints of the language there are many different strategies for bridging the different behaviors. For example: C++ programs, which normally use manual de-allocation, could interoperate with a Java style garbage collector by changing de-allocation behavior to delete the object, but not reclaim the memory. This requires that each object will have to manually be de-allocated, in order for the garbage collector to release the memory safely.

Mutability
Mutability becomes an issue when trying to create interoperability between pure functional and procedural languages. Languages like Haskell have no mutable types, whereas C++ does not provide such rigorous guarantees. Many functional types when bridged to object oriented languages can not guarantee that the underlying objects won't be modified.

See also
Foreign function interface
Language-independent specification
Language binding
Glue language
API reuse
JVM languages
CLI Languages
SWIG


== References ==",36509863,https://en.wikipedia.org/wiki/Language_interoperability
LFE (programming language),"Lisp Flavored Erlang (LFE) is a functional, concurrent, garbage collected, general-purpose programming language and Lisp dialect built on Core Erlang and the Erlang virtual machine (BEAM). LFE builds on Erlang to provide a Lisp syntax for writing distributed, fault-tolerant, soft real-time, non-stop applications. LFE also extends Erlang to support metaprogramming with Lisp macros and an improved developer experience with a feature-rich read–eval–print loop (REPL). LFE is actively supported on all recent releases of Erlang; the oldest version of Erlang supported is R14.","Lisp Flavored Erlang (LFE) is a functional, concurrent, garbage collected, general-purpose programming language and Lisp dialect built on Core Erlang and the Erlang virtual machine (BEAM). LFE builds on Erlang to provide a Lisp syntax for writing distributed, fault-tolerant, soft real-time, non-stop applications. LFE also extends Erlang to support metaprogramming with Lisp macros and an improved developer experience with a feature-rich read–eval–print loop (REPL). LFE is actively supported on all recent releases of Erlang; the oldest version of Erlang supported is R14.

History
Initial release
Initial work on LFE began in 2007, when Robert Virding started creating a prototype of Lisp running on Erlang. This work was focused primarily on parsing and exploring what an implementation might look like. No version control system was being used at the time, so tracking exact initial dates is somewhat problematic.Virding announced the first release of LFE on the Erlang Questions mail list in March 2008. This release of LFE was very limited: it did not handle recursive letrecs, binarys, receive, or try; it also did not support a Lisp shell.Initial development of LFE was done with version R12B-0 of Erlang on a Dell XPS laptop.

Motives
Robert Virding has stated that there were several reasons why he started the LFE programming language:
He had prior experience programming in Lisp.
Given his prior experience, he was interested in implementing his own Lisp.
In particular, he wanted to implement a Lisp in Erlang: not only was he curious to see how it would run on and integrate with Erlang, he wanted to see what it would look like.
Since helping to create the Erlang programming language, he had had the goal of making a Lisp which was specifically designed to run on the BEAM and able to fully interact with Erlang/OTP.
He wanted to experiment with compiling another language on Erlang. As such, he saw LFE as a means to explore this by generating Core Erlang and plugging it into the backend of the Erlang compiler.

Features
A language targeting Erlang virtual machine (BEAM)
Seamless Erlang integration: zero-penalty Erlang function calls (and vice versa)
Metaprogramming via Lisp macros and the homoiconicity of a Lisp
Common Lisp-style documentation via both source code comments and docstrings
Shared-nothing architecture concurrent programming via message passing (Actor model)
Emphasis on recursion and higher-order functions instead of side-effect-based looping
A full read–eval–print loop (REPL) for interactive development and testing (unlike Erlang's shell, the LFE REPL supports function and macro definitions)
Pattern matching
Hot loading of code
A Lisp-2 separation of namespaces for variables and functions
Java inter-operation via JInterface and Erjang
Scripting abilities with both lfe and lfescript

Syntax and semantics
Symbolic expressions (S-expressions)
Like Lisp, LFE is an expression-oriented language. Unlike non-homoiconic programming languages, Lisps make no or little syntactic distinction between expressions and statements: all code and data are written as expressions. LFE brought homoiconicity to the Erlang VM.

Lists
In LFE, the list data type is written with its elements separated by whitespace, and surrounded by parentheses. For example, (list 1 2 'foo) is a list whose elements are the integers 1 and 2, and the atom [[foo|foo]]. These values are implicitly typed: they are respectively two integers and a Lisp-specific data type called a symbolic atom, and need not be declared as such.
As seen in the example above, LFE expressions are written as lists, using prefix notation. The first element in the list is the name of a form, i.e., a function, operator, or macro. The remainder of the list are the arguments.

Operators
The LFE-Erlang operators are used in the same way. The expression

evaluates to 42. Unlike functions in Erlang and LFE, arithmetic operators in Lisp are variadic (or n-ary), able to take any number of arguments.

Lambda expressions and function definition
LFE has lambda, just like Common Lisp. It also, however, has lambda-match to account for Erlang's pattern-matching abilities in anonymous function calls.

Erlang idioms in LFE
This section does not represent a complete comparison between Erlang and LFE, but should give a taste.

Pattern matching
Erlang:

LFE:

List comprehensions
Erlang:

LFE:

Or idiomatic functional style:

Guards
Erlang:

LFE:

cons'ing in function heads
Erlang:

LFE:

or using a ``cons`` literal instead of the constructor form:

Matching records in function heads
Erlang:

LFE:

Receiving messages
Erlang:

LFE:

or:

Examples
Erlang interoperability
Calls to Erlang functions take the form (<module>:<function> <arg1> ... <argn>):

Functional paradigm
Using recursion to define the Ackermann function:

Composing functions:

Concurrency
Message-passing with Erlang's light-weight ""processes"":

Multiple simultaneous HTTP requests:

References
External links
Official website
LFE on GitHub
LFE Quick Start
LFE User Guide
LFE on Rosetta Code",41671035,https://en.wikipedia.org/wiki/LFE_(programming_language)
Linda (coordination language),"In computer science, Linda is a coordination model that aids communication in parallel computing environments. Developed by David Gelernter, it is meant to be used alongside a full-fledged computation language like Fortran or C where Linda's role is to ""create computational activities and to support communication among them"".","In computer science, Linda is a coordination model that aids communication in parallel computing environments. Developed by David Gelernter, it is meant to be used alongside a full-fledged computation language like Fortran or C where Linda's role is to ""create computational activities and to support communication among them"".

History
David Gelernter wrote the first version of Linda as a Ph.D. candidate in 1979, naming it after Linda Lovelace, who appeared in the pornographic film Deep Throat. At the time, the main language for parallel processing was Ada, developed by the U.S. Department of Defense and a tribute to Ada Lovelace, which Gelernter considered an ""inelegant and bulky"" language.It was widely released in 1986, when Gelernter, along with his Yale colleague Nicholas Carriero and Sudhir Ahuja at AT&T Bell Laboratories, published ""Linda and Friends"" in an IEEE journal.By the early 1990s, Linda was widely used by corporations to more efficiently conduct big data analyses, including Wall Street brokerages as well as AT&T, Boeing, and United Technologies. There were even companies that specialized in creating specialized parallel computing applications based on Linda, the largest of which was Scientific Computing Associates, a New Haven-based company founded by several Yale computer scientists (Gelernter occasionally consulted for them but did not work there). Interest in Linda dropped in the mid-1990s, only to make a comeback in the late 1990s with several corporations implementing Linda in Java, including Sun Microsystems and IBM.

Overview
Model
The Linda model provides a distributed shared memory, known as a tuple space because its basic addressable unit is a tuple, an ordered sequence of typed data objects; specifically in Linda, a tuple is a sequence of up to 16 typed fields enclosed in parentheses"". The tuple space is ""logically shared by processes"" which are referred to as workers that store and retrieve tuples.

Operations
One of Linda's main advantages is that it's simple, with only six operations that workers perform on the tuples to access tuplespace:
out: Puts a tuple into the tuplespace
in: Takes out a tuple that matches a given pattern from the tuplespace (if there's no match, the operation is blocked)
rd: Copies a tuple that matches a given pattern from the tuplespace (if there's no match, the operation is blocked)
eval: Creates a new process to evaluate tuples
inp: A non-blocking version of in (if there's no match, an error message is returned)
rdp: A non-blocking version of rd (if there's no match, an error message is returned)

Comparison
Compared to other parallel-processing models, Linda is more orthogonal in treating process coordination as a separate activity from computation, and it is more general in being able to subsume various levels of concurrency—uniprocessor, multi-threaded multiprocessor, or networked—under a single model. Its orthogonality allows processes computing in different languages and platforms to interoperate using the same primitives. Its generality allows a multi-threaded Linda system to be distributed across multiple computers without change.
Whereas message-passing models require tightly coupled processes sending messages to each other in some sequence or protocol, Linda processes are decoupled from other processes, communicating only through the tuplespace; a process need have no notion of other processes except for the kinds of tuples consumed or produced. Criticisms of Linda from the multiprocessing community tend to focus on the decreased speed of operations in Linda systems as compared to Message Passing Interface (MPI) systems. While not without justification, these claims were largely refuted for an important class of problems.  Detailed criticisms of the Linda model can also be found in Steven Ericsson-Zenith's book Process Interaction Models.Researchers have proposed more primitives to support different types of communication and co-ordination between (open distributed) computer systems, and to solve particular problems arising from various uses of the model. Researchers have also experimented with various means of implementing the virtual shared memory for this model. Many of these researchers proposed larger modifications to the original Linda model, developing a family of systems known as Linda-like systems and implemented as orthogonal technology (unlike original version). An example of this is the language Ease designed by Steven Ericsson-Zenith.
Linda's approach has also been compared to that of flow-based programming.

Linda-calculus
The Linda-calculus is a formalisation of the above model with the difference that in the following outeval{\displaystyle \mathrm {outeval} } subsumes both out and eval operations.

Syntax
We abstract the concrete representation of tuples.
We just assume that we have a set of tuples t∈T{\displaystyle t\in {\mathcal {T}}} and
we are allowed to form and apply a substitution function σ{\displaystyle \sigma } on tuples substituting variables for terms that yields a tuple.
For example, given we have a tuple t=(hello,x){\displaystyle t=({\mathit {hello}},x)}, then
applying a substitution σ={world/x}{\displaystyle \sigma =\{{\mathit {world}}/x\}} on t{\displaystyle t} yields (hello,world){\displaystyle ({\mathit {hello}},{\mathit {world}})}
The Linda-calculus processes are defined by the following grammar.
P,Q::=t|outeval(P).Q|rd(t).P|in(t).P|P+Q|recX.P|X{\displaystyle P,Q::=t\;|\;\mathrm {outeval} (P).Q\;|\;\mathrm {rd} (t).P\;|\;\mathrm {in} (t).P\;|\;P+Q\;|\;\mathbf {rec} X.P\;|\;X}
The syntax includes the aftermentioned Linda operations, non-deterministic choice, and recursion. The substitution function is extended to processes recursively.

Semantics
A tuple space is represented as a multiset of the processes. We write M|P{\displaystyle M\,|\,P} for M⊎{P}{\displaystyle M\uplus \{P\}} where M{\displaystyle M} is a multiset, {P}{\displaystyle \{P\}} a singleton multiset, and ⊎{\displaystyle \uplus } is the multiset union operation. The semantics is then defined as a reduction relation on a multiset M→M′{\displaystyle M\rightarrow M'} as follows.
(outeval)M|outeval(P).Q→M|P|Q(read)M|rd(t).P|t′→M|Pσ|t′if exists σ such that tσ=t′(input)M|in(t).P|t′→M|Pσif exists σ such that tσ=t′(left choice)M|P+Q→M|P(right choice)M|P+Q→M|Q(recursion)M|recX.P→M|P{recX.P/X}{\displaystyle {\begin{array}{lrcll}{\text{(outeval)}}&M\,|\,\mathrm {outeval} (P).Q&\rightarrow &M\,|\,P\,|\,Q&\\{\text{(read)}}&M\,|\,\mathrm {rd} (t).P\,|\,t'&\rightarrow &M\,|\,P\sigma \,|\,t'&{\text{if exists }}\sigma {\text{ such that }}t\sigma =t'\\{\text{(input)}}&M\,|\,\mathrm {in} (t).P\,|\,t'&\rightarrow &M\,|\,P\sigma &{\text{if exists }}\sigma {\text{ such that }}t\sigma =t'\\{\text{(left choice)}}&M\,|\,P+Q&\rightarrow &M\,|\,P&\\{\text{(right choice)}}&M\,|\,P+Q&\rightarrow &M\,|\,Q&\\{\text{(recursion)}}&M\,|\,\mathbf {rec} X.P&\rightarrow &M\,|\,P\{\mathbf {rec} X.P/X\}&\\\end{array}}}
Note that (input) consumes the tuple t′{\displaystyle t'} from the tuple space whereas (read) only reads it.
The resulting operational semantics is synchronous.

Implementations
Linda was originally implemented in C and Fortran, but has since been implemented in many programming languages, including:

C: C-Linda, TCP-Linda, LinuxTuples
C++: CppLinda, Boreas
C#: pSpaces
Erlang: Erlinda
Go: pSpaces
Java: JavaSpaces, jRESP, TSpaces, LightTS, LIME, pSpaces
JavaScript: pSpaces
Lisp
Lua: LuaTS Lua Lanes
Prolog: SICStus Prolog Linda
Python: PyLinda
Ruby: Rinda
Swift: pSpacesSome of the more notable Linda implementations include:

C-Linda or TCP-Linda - the earliest commercial and a widespread implementation of virtual shared memory for supercomputers and clustered systems from Scientific Computing Associates, founded by Martin Schultz.
JavaSpaces - a Java-based tuplespace implementation that helped popularize distributed computing.
TSpaces - a Java-based tuplespace platform from IBM.

See also
Dataflow
Data flow diagram
Dataflow programming
Flow-based programming
Parallel computing


== References ==",957598,https://en.wikipedia.org/wiki/Linda_(coordination_language)
LINGO (mathematical modeling language),"LINGO is a mathematical modeling language designed for formulating and solving optimization problems, including linear, integer, and nonlinear programming problems.


== References ==","LINGO is a mathematical modeling language designed for formulating and solving optimization problems, including linear, integer, and nonlinear programming problems.


== References ==",45712630,https://en.wikipedia.org/wiki/LINGO_(mathematical_modeling_language)
Lisp (programming language),"Lisp (historically LISP, an abbreviation of ""list processing"") is a family of programming languages with a long history and a distinctive, fully parenthesized prefix notation.
Originally specified in 1960, it is the third-oldest high-level programming language still in common use, after Fortran and COBOL. Lisp has changed since its early days, and many dialects have existed over its history. Today, the best-known general-purpose Lisp dialects are Common Lisp, Scheme, Racket, and Clojure.Lisp was originally created as a practical mathematical notation for computer programs, influenced by (though not originally derived from) the notation of Alonzo Church's lambda calculus. It quickly became a favored programming language for artificial intelligence (AI) research. As one of the earliest programming languages, Lisp pioneered many ideas in computer science, including tree data structures, automatic storage management, dynamic typing, conditionals, higher-order functions, recursion, the self-hosting compiler, and the read–eval–print loop.The name LISP derives from ""LISt Processor"". Linked lists are one of Lisp's major data structures, and Lisp source code is made of lists. Thus, Lisp programs can manipulate source code as a data structure, giving rise to the macro systems that allow programmers to create new syntax or new domain-specific languages embedded in Lisp.
The interchangeability of code and data gives Lisp its instantly recognizable syntax. All program code is written as s-expressions, or parenthesized lists. A function call or syntactic form is written as a list with the function or operator's name first, and the arguments following; for instance, a function f that takes three arguments would be called as (f arg1 arg2 arg3).","Lisp (historically LISP, an abbreviation of ""list processing"") is a family of programming languages with a long history and a distinctive, fully parenthesized prefix notation.
Originally specified in 1960, it is the third-oldest high-level programming language still in common use, after Fortran and COBOL. Lisp has changed since its early days, and many dialects have existed over its history. Today, the best-known general-purpose Lisp dialects are Common Lisp, Scheme, Racket, and Clojure.Lisp was originally created as a practical mathematical notation for computer programs, influenced by (though not originally derived from) the notation of Alonzo Church's lambda calculus. It quickly became a favored programming language for artificial intelligence (AI) research. As one of the earliest programming languages, Lisp pioneered many ideas in computer science, including tree data structures, automatic storage management, dynamic typing, conditionals, higher-order functions, recursion, the self-hosting compiler, and the read–eval–print loop.The name LISP derives from ""LISt Processor"". Linked lists are one of Lisp's major data structures, and Lisp source code is made of lists. Thus, Lisp programs can manipulate source code as a data structure, giving rise to the macro systems that allow programmers to create new syntax or new domain-specific languages embedded in Lisp.
The interchangeability of code and data gives Lisp its instantly recognizable syntax. All program code is written as s-expressions, or parenthesized lists. A function call or syntactic form is written as a list with the function or operator's name first, and the arguments following; for instance, a function f that takes three arguments would be called as (f arg1 arg2 arg3).

History
John McCarthy began developing Lisp in 1958 while he was at the Massachusetts Institute of Technology (MIT). McCarthy published its design in a paper in Communications of the ACM in April 1960, entitled ""Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I"". He showed that with a few simple operators and a notation for anonymous functions borrowed from Church, one can build a Turing-complete language for algorithms.
Information Processing Language was the first AI language, from 1955 or 1956, and already included many of the concepts, such as list-processing and recursion, which came to be used in Lisp.
McCarthy's original notation used bracketed ""M-expressions"" that would be translated into S-expressions. As an example, the M-expression car[cons[A,B]] is equivalent to the S-expression (car (cons A B)). Once Lisp was implemented, programmers rapidly chose to use S-expressions, and M-expressions were abandoned. M-expressions surfaced again with short-lived attempts of MLisp by Horace Enea and CGOL by Vaughan Pratt.
Lisp was first implemented by Steve Russell on an IBM 704 computer using punched cards. Russell had read McCarthy's paper and realized (to McCarthy's surprise) that the Lisp eval function could be implemented in machine code.
According to McCarthy
Steve Russell said, look, why don't I program this eval ... and I said to him, ho, ho, you're confusing theory with practice, this eval is intended for reading, not for computing. But he went ahead and did it. That is, he compiled the eval in my paper into IBM 704 machine code, fixing bugs, and then advertised this as a Lisp interpreter, which it certainly was. So at that point Lisp had essentially the form that it has today ...
The result was a working Lisp interpreter which could be used to run Lisp programs, or more properly, ""evaluate Lisp expressions"".
Two assembly language macros for the IBM 704 became the primitive operations for decomposing lists: car (Contents of the Address part of Register number) and cdr (Contents of the Decrement part of Register number), where ""register"" refers to registers of the computer's central processing unit (CPU). Lisp dialects still use car and cdr ( and ) for the operations that return the first item in a list and the rest of the list, respectively.
The first complete Lisp compiler, written in Lisp, was implemented in 1962 by Tim Hart and Mike Levin at MIT, and could be compiled by simply having an existing LISP interpreter interpret the compiler code, producing machine code output able to be executed at a 40-fold improvement in speed over that of the interpreter. This compiler introduced the Lisp model of incremental compilation, in which compiled and interpreted functions can intermix freely. The language used in Hart and Levin's memo is much closer to modern Lisp style than McCarthy's earlier code.
Garbage collection routines were developed by MIT graduate student Daniel Edwards, prior to 1962.During the 1980s and 1990s, a great effort was made to unify the work on new Lisp dialects (mostly successors to Maclisp such as ZetaLisp and NIL (New Implementation of Lisp) into a single language. The new language, Common Lisp, was somewhat compatible with the dialects it replaced (the book Common Lisp the Language notes the compatibility of various constructs). In 1994, ANSI published the Common Lisp standard, ""ANSI X3.226-1994 Information Technology Programming Language Common Lisp"".

Timeline
Connection to artificial intelligence
Since inception, Lisp was closely connected with the artificial intelligence research community, especially on PDP-10 systems. Lisp was used as the implementation of the language Micro Planner, which was used in the famous AI system SHRDLU. In the 1970s, as AI research spawned commercial offshoots, the performance of existing Lisp systems became a growing issue, as programmers needed to be familiar with the performance ramifications of the various techniques and choices involved in the implementation of Lisp.

Genealogy and variants
Over its sixty-year history, Lisp has spawned many variations on the core theme of an S-expression language. Moreover, each given dialect may have several implementations—for instance, there are more than a dozen implementations of Common Lisp.
Differences between dialects may be quite visible—for instance, Common Lisp uses the keyword defun to name a function, but Scheme uses define. Within a dialect that is standardized, however, conforming implementations support the same core language, but with different extensions and libraries.

Historically significant dialects
LISP 1 – First implementation.
LISP 1.5 – First widely distributed version, developed by McCarthy and others at MIT. So named because it contained several improvements on the original ""LISP 1"" interpreter, but was not a major restructuring as the planned LISP 2 would be.
Stanford LISP 1.6 – This was a successor to LISP 1.5 developed at the Stanford AI Lab, and widely distributed to PDP-10 systems running the TOPS-10 operating system. It was rendered obsolete by Maclisp and InterLisp.
MACLISP – developed for MIT's Project MAC, MACLISP is a direct descendant of LISP 1.5. It ran on the PDP-10 and Multics systems. MACLISP would later come to be called Maclisp, and is often referred to as MacLisp. The ""MAC"" in MACLISP is related neither to Apple's Macintosh nor to McCarthy.
Interlisp – developed at BBN Technologies for PDP-10 systems running the TENEX operating system, later adopted as a ""West coast"" Lisp for the Xerox Lisp machines as InterLisp-D. A small version called ""InterLISP 65"" was published for the 6502-based Atari 8-bit family computer line. For quite some time, Maclisp and InterLisp were strong competitors.
Franz Lisp – originally a University of California, Berkeley project; later developed by Franz Inc. The name is a humorous deformation of the name ""Franz Liszt"", and does not refer to Allegro Common Lisp, the dialect of Common Lisp sold by Franz Inc., in more recent years.
XLISP, which AutoLISP was based on.
Standard Lisp and Portable Standard Lisp were widely used and ported, especially with the Computer Algebra System REDUCE.
ZetaLisp, also termed Lisp Machine Lisp – used on the Lisp machines, direct descendant of Maclisp. ZetaLisp had a big influence on Common Lisp.
LeLisp is a French Lisp dialect. One of the first Interface Builders (called SOS Interface) was written in LeLisp.
Scheme (1975).
Common Lisp (1984), as described by Common Lisp the Language – a consolidation of several divergent attempts (ZetaLisp, Spice Lisp, NIL, and S-1 Lisp) to create successor dialects to Maclisp, with substantive influences from the Scheme dialect as well. This version of Common Lisp was available for wide-ranging platforms and was accepted by many as a de facto standard until the publication of ANSI Common Lisp (ANSI X3.226-1994). Among the most widespread sub-dialects of Common Lisp are Steel Bank Common Lisp (SBCL), CMU Common Lisp (CMU-CL), Clozure OpenMCL (not to be confused with Clojure!), GNU CLisp, and later versions of Franz Lisp; all of them adhere to the later ANSI CL standard (see below).
Dylan was in its first version a mix of Scheme with the Common Lisp Object System.
EuLisp – attempt to develop a new efficient and cleaned-up Lisp.
ISLISP – attempt to develop a new efficient and cleaned-up Lisp. Standardized as ISO/IEC 13816:1997 and later revised as ISO/IEC 13816:2007: Information technology – Programming languages, their environments and system software interfaces – Programming language ISLISP.
IEEE Scheme – IEEE standard, 1178–1990 (R1995).
ANSI Common Lisp – an American National Standards Institute (ANSI) standard for Common Lisp, created by subcommittee X3J13, chartered to begin with Common Lisp: The Language as a base document and to work through a public consensus process to find solutions to shared issues of portability of programs and compatibility of Common Lisp implementations. Although formally an ANSI standard, the implementation, sale, use, and influence of ANSI Common Lisp has been and continues to be seen worldwide.
ACL2 or ""A Computational Logic for Applicative Common Lisp"", an applicative (side-effect free) variant of Common LISP. ACL2 is both a programming language which can model computer systems, and a tool to help proving properties of those models.
Clojure, a recent dialect of Lisp which compiles to the Java virtual machine and has a particular focus on concurrency.
Game Oriented Assembly Lisp (or GOAL) is a video game programming language developed by Andy Gavin at Naughty Dog. It was written using Allegro Common Lisp and used in the development of the entire Jak and Daxter series of games developed by Naughty Dog.

2000 to present
After having declined somewhat in the 1990s, Lisp has experienced a resurgence of interest after 2000. Most new activity has been focused around implementations of Common Lisp, Scheme, Emacs Lisp, Clojure, and Racket, and includes development of new portable libraries and applications.
Many new Lisp programmers were inspired by writers such as Paul Graham and Eric S. Raymond to pursue a language others considered antiquated. New Lisp programmers often describe the language as an eye-opening experience and claim to be substantially more productive than in other languages. This increase in awareness may be contrasted to the ""AI winter"" and Lisp's brief gain in the mid-1990s.As of 2010, there were eleven actively maintained Common Lisp implementations.The open source community has created new supporting infrastructure: CLiki is a wiki that collects Common Lisp related information, the Common Lisp directory lists resources, #lisp is a popular IRC channel and allows the sharing and commenting of code snippets (with support by lisppaste, an IRC bot written in Lisp), Planet Lisp collects the contents of various Lisp-related blogs, on LispForum users discuss Lisp topics, Lispjobs is a service for announcing job offers and there is a weekly news service, Weekly Lisp News. Common-lisp.net is a hosting site for open source Common Lisp projects. Quicklisp is a library manager for Common Lisp.
Fifty years of Lisp (1958–2008) was celebrated at LISP50@OOPSLA. There are regular local user meetings in Boston, Vancouver, and Hamburg. Other events include the European Common Lisp Meeting, the European Lisp Symposium and an International Lisp Conference.
The Scheme community actively maintains over twenty implementations. Several significant new implementations (Chicken, Gambit, Gauche, Ikarus, Larceny, Ypsilon) have been developed in the 2000s (decade). The Revised5 Report on the Algorithmic Language Scheme standard of Scheme was widely accepted in the Scheme community. The Scheme Requests for Implementation process has created a lot of quasi standard libraries and extensions for Scheme. User communities of individual Scheme implementations continue to grow. A new language standardization process was started in 2003 and led to the R6RS Scheme standard in 2007. Academic use of Scheme for teaching computer science seems to have declined somewhat. Some universities are no longer using Scheme in their computer science introductory courses; MIT now uses Python instead of Scheme for its undergraduate computer science program and MITx massive open online course.There are several new dialects of Lisp: Arc, Hy, Nu, Liskell, and LFE (Lisp Flavored Erlang). The parser for Julia is implemented in Femtolisp, a dialect of Scheme (Julia is inspired by Scheme, which in turn is a Lisp dialect).
In October 2019, Paul Graham released a specification for Bel, ""a new dialect of Lisp.""

Major dialects
Common Lisp and Scheme represent two major streams of Lisp development. These languages embody significantly different design choices.
Common Lisp is a successor to Maclisp. The primary influences were Lisp Machine Lisp, Maclisp, NIL, S-1 Lisp, Spice Lisp, and Scheme. It has many of the features of Lisp Machine Lisp (a large Lisp dialect used to program Lisp Machines), but was designed to be efficiently implementable on any personal computer or workstation. Common Lisp is a general-purpose programming language and thus has a large language standard including many built-in data types, functions, macros and other language elements, and an object system (Common Lisp Object System). Common Lisp also borrowed certain features from Scheme such as lexical scoping and lexical closures. Common Lisp implementations are available for targeting different platforms such as the LLVM, the Java virtual machine,
x86-64, PowerPC, Alpha, ARM, Motorola 68000, and MIPS, and operating systems such as Windows, macOS, Linux, Solaris, FreeBSD, NetBSD, OpenBSD, Dragonfly BSD, and Heroku.Scheme is a statically scoped and properly tail-recursive dialect of the Lisp programming language invented by Guy L. Steele, Jr. and Gerald Jay Sussman. It was designed to have exceptionally clear and simple semantics and few different ways to form expressions. Designed about a decade earlier than Common Lisp, Scheme is a more minimalist design. It has a much smaller set of standard features but with certain implementation features (such as tail-call optimization and full continuations) not specified in Common Lisp. A wide variety of programming paradigms, including imperative, functional, and message passing styles, find convenient expression in Scheme. Scheme continues to evolve with a series of standards (Revisedn Report on the Algorithmic Language Scheme) and a series of Scheme Requests for Implementation.
Clojure is a dialect of Lisp that targets mainly the Java virtual machine, and the Common Language Runtime (CLR), the Python VM, the Ruby VM YARV, and compiling to JavaScript. It is designed to be a pragmatic general-purpose language. Clojure draws considerable influences from Haskell and places a very strong emphasis on immutability. Clojure provides access to Java frameworks and libraries, with optional type hints and type inference, so that calls to Java can avoid reflection and enable fast primitive operations. Clojure is not designed to be backwards compatible with other Lisp dialects.Further, Lisp dialects are used as scripting languages in many applications, with the best-known being Emacs Lisp in the Emacs editor, AutoLISP and later Visual Lisp in AutoCAD, Nyquist in Audacity, and Scheme in LilyPond. The potential small size of a useful Scheme interpreter makes it particularly popular for embedded scripting. Examples include SIOD and TinyScheme, both of which have been successfully embedded in the GIMP image processor under the generic name ""Script-fu"". LIBREP, a Lisp interpreter by John Harper originally based on the Emacs Lisp language, has been embedded in the Sawfish window manager.

Standardized dialects
Lisp has officially standardized dialects: R6RS Scheme, R7RS Scheme, IEEE Scheme, ANSI Common Lisp and ISO ISLISP.

Language innovations
Paul Graham identifies nine important aspects of Lisp that distinguished it from existing languages like Fortran:
Conditionals not limited to goto
First-class functions
Recursion
Treating variables uniformly as pointers, leaving types to values
Garbage collection
Programs made entirely of expressions with no statements
The symbol data type, distinct from the string data type
Notation for code made of trees of symbols (using many parentheses)
Full language available at load time, compile time, and run timeLisp was the first language where the structure of program code is represented faithfully and directly in a standard data structure—a quality much later dubbed ""homoiconicity"". Thus, Lisp functions can be manipulated, altered or even created within a Lisp program without lower-level manipulations. This is generally considered one of the main advantages of the language with regard to its expressive power, and makes the language suitable for syntactic macros and meta-circular evaluation.
A conditional using an if–then–else syntax was invented by McCarthy for a chess program written in Fortran. He proposed its inclusion in ALGOL, but it was not made part of the Algol 58 specification. For Lisp, McCarthy used the more general cond-structure. Algol 60 took up if–then–else and popularized it.
Lisp deeply influenced Alan Kay, the leader of the research team that developed Smalltalk at Xerox PARC; and in turn Lisp was influenced by Smalltalk, with later dialects adopting object-oriented programming features (inheritance classes, encapsulating instances, message passing, etc.) in the 1970s. The Flavors object system introduced the concept of multiple inheritance and the mixin. The Common Lisp Object System provides multiple inheritance, multimethods with multiple dispatch, and first-class generic functions, yielding a flexible and powerful form of dynamic dispatch. It has served as the template for many subsequent Lisp (including Scheme) object systems, which are often implemented via a metaobject protocol, a reflective meta-circular design in which the object system is defined in terms of itself: Lisp was only the second language after Smalltalk (and is still one of the very few languages) to possess such a metaobject system. Many years later, Alan Kay suggested that as a result of the confluence of these features, only Smalltalk and Lisp could be regarded as properly conceived object-oriented programming systems.Lisp introduced the concept of automatic garbage collection, in which the system walks the heap looking for unused memory. Progress in modern sophisticated garbage collection algorithms such as generational garbage collection was stimulated by its use in Lisp.Edsger W. Dijkstra in his 1972 Turing Award lecture said,

With a few very basic principles at its foundation, it [LISP] has shown a remarkable stability. Besides that, LISP has been the carrier for a considerable number of in a sense our most sophisticated computer applications. LISP has jokingly been described as ""the most intelligent way to misuse a computer"". I think that description a great compliment because it transmits the full flavour of liberation: it has assisted a number of our most gifted fellow humans in thinking previously impossible thoughts.
Largely because of its resource requirements with respect to early computing hardware (including early microprocessors), Lisp did not become as popular outside of the AI community as Fortran and the ALGOL-descended C language. Because of its suitability to complex and dynamic applications, Lisp enjoyed some resurgence of popular interest in the 2010s.

Syntax and semantics
This article's examples are written in Common Lisp (though most are also valid in Scheme).

Symbolic expressions (S-expressions)
Lisp is an expression oriented language. Unlike most other languages, no distinction is made between ""expressions"" and ""statements""; all code and data are written as expressions. When an expression is evaluated, it produces a value (possibly multiple values), which can then be embedded into other expressions. Each value can be any data type.
McCarthy's 1958 paper introduced two types of syntax: Symbolic expressions (S-expressions, sexps), which mirror the internal representation of code and data; and Meta expressions (M-expressions), which express functions of S-expressions. M-expressions never found favor, and almost all Lisps today use S-expressions to manipulate both code and data.
The use of parentheses is Lisp's most immediately obvious difference from other programming language families. As a result, students have long given Lisp nicknames such as Lost In Stupid Parentheses, or Lots of Irritating Superfluous Parentheses. However, the S-expression syntax is also responsible for much of Lisp's power: the syntax is simple and consistent, which facilitates manipulation by computer. However, the syntax of Lisp is not limited to traditional parentheses notation. It can be extended to include alternative notations. For example, XMLisp is a Common Lisp extension that employs the metaobject protocol to integrate S-expressions with the Extensible Markup Language (XML).
The reliance on expressions gives the language great flexibility. Because Lisp functions are written as lists, they can be processed exactly like data. This allows easy writing of programs which manipulate other programs (metaprogramming). Many Lisp dialects exploit this feature using macro systems, which enables extension of the language almost without limit.

Lists
A Lisp list is written with its elements separated by whitespace, and surrounded by parentheses. For example, (1 2 foo) is a list whose elements are the three atoms 1, 2, and foo. These values are implicitly typed: they are respectively two integers and a Lisp-specific data type called a ""symbol"", and do not have to be declared as such.
The empty list () is also represented as the special atom nil. This is the only entity in Lisp which is both an atom and a list.
Expressions are written as lists, using prefix notation. The first element in the list is the name of a function, the name of a macro, a lambda expression or the name of a ""special operator"" (see below). The remainder of the list are the arguments. For example, the function list returns its arguments as a list, so the expression

evaluates to the list (1 2 foo). The ""quote"" before the foo in the preceding example is a ""special operator"" which returns its argument without evaluating it. Any unquoted expressions are recursively evaluated before the enclosing expression is evaluated. For example,

evaluates to the list (1 2 (3 4)). The third argument is a list; lists can be nested.

Operators
Arithmetic operators are treated similarly. The expression

evaluates to 10. The equivalent under infix notation would be ""1 + 2 + 3 + 4"".
Lisp has no notion of operators as implemented in Algol-derived languages. Arithmetic operators in Lisp are variadic functions (or n-ary), able to take any number of arguments. A C-style '++' increment operator is sometimes implemented under the name incf giving syntax

equivalent to (setq x (+ x 1)), returning the new value of x.
""Special operators"" (sometimes called ""special forms"") provide Lisp's control structure. For example, the special operator if takes three arguments. If the first argument is non-nil, it evaluates to the second argument; otherwise, it evaluates to the third argument. Thus, the expression

evaluates to (3 4 ""bar""). Of course, this would be more useful if a non-trivial expression had been substituted in place of nil.
Lisp also provides logical operators and, or and not. The and and or operators do short-circuit evaluation and will return their first nil and non-nil argument respectively.

will evaluate to ""James"".

Lambda expressions and function definition
Another special operator, lambda, is used to bind variables to values which are then evaluated within an expression. This operator is also used to create functions: the arguments to lambda are a list of arguments, and the expression or expressions to which the function evaluates (the returned value is the value of the last expression that is evaluated). The expression

evaluates to a function that, when applied, takes one argument, binds it to arg and returns the number one greater than that argument. Lambda expressions are treated no differently from named functions; they are invoked the same way. Therefore, the expression

evaluates to 6. Here, we're doing a function application: we execute the anonymous function by passing to it the value 5.
Named functions are created by storing a lambda expression in a symbol using the defun macro.

(defun f (a) b...) defines a new function named f in the global environment. It is conceptually similar to the expression:

where setf is a macro used to set the value of the first argument fdefinition 'f to a new function object. fdefinition is a global function definition for the function named f. #' is an abbreviation for function special operator, returning a function object.

Atoms
In the original LISP there were two fundamental data types: atoms and lists. A list was a finite ordered sequence of elements, where each element is either an atom or a list, and an atom was a number or a symbol. A symbol was essentially a unique named item, written as an alphanumeric string in source code, and used either as a variable name or as a data item in symbolic processing. For example, the list (FOO (BAR 1) 2) contains three elements: the symbol FOO, the list (BAR 1), and the number 2.
The essential difference between atoms and lists was that atoms were immutable and unique. Two atoms that appeared in different places in source code but were written in exactly the same way represented the same object, whereas each list was a separate object that could be altered independently of other lists and could be distinguished from other lists by comparison operators.
As more data types were introduced in later Lisp dialects, and programming styles evolved, the concept of an atom lost importance. Many dialects still retained the predicate atom for legacy compatibility, defining it true for any object which is not a cons.

Conses and lists
A Lisp list is implemented as a singly linked list. Each cell of this list is called a cons (in Scheme, a pair) and is composed of two pointers, called the car and cdr. These are respectively equivalent to the data and next fields discussed in the article linked list.
Of the many data structures that can be built out of cons cells, one of the most basic is called a proper list. A proper list is either the special nil (empty list) symbol, or a cons in which the car points to a datum (which may be another cons structure, such as a list), and the cdr points to another proper list.
If a given cons is taken to be the head of a linked list, then its car points to the first element of the list, and its cdr points to the rest of the list. For this reason, the car and cdr functions are also called first and rest when referring to conses which are part of a linked list (rather than, say, a tree).
Thus, a Lisp list is not an atomic object, as an instance of a container class in C++ or Java would be. A list is nothing more than an aggregate of linked conses. A variable that refers to a given list is simply a pointer to the first cons in the list. Traversal of a list can be done by cdring down the list; that is, taking successive cdrs to visit each cons of the list; or by using any of several higher-order functions to map a function over a list.
Because conses and lists are so universal in Lisp systems, it is a common misconception that they are Lisp's only data structures. In fact, all but the most simplistic Lisps have other data structures, such as vectors (arrays), hash tables, structures, and so forth.

S-expressions represent lists
Parenthesized S-expressions represent linked list structures. There are several ways to represent the same list as an S-expression. A cons can be written in dotted-pair notation as (a . b), where a is the car and b the cdr. A longer proper list might be written (a . (b . (c . (d . nil)))) in dotted-pair notation. This is conventionally abbreviated as (a b c d) in list notation. An improper list may be written in a combination of the two – as (a b c . d) for the list of three conses whose last cdr is d (i.e., the list (a . (b . (c . d))) in fully specified form).

List-processing procedures
Lisp provides many built-in procedures for accessing and controlling lists. Lists can be created directly with the list procedure, which takes any number of arguments, and returns the list of these arguments.

Because of the way that lists are constructed from cons pairs, the cons procedure can be used to add an element to the front of a list. The cons procedure is asymmetric in how it handles list arguments, because of how lists are constructed.

The append procedure appends two (or more) lists to one another. Because Lisp lists are linked lists, appending two lists has asymptotic time complexity O(n){\displaystyle O(n)}

Shared structure
Lisp lists, being simple linked lists, can share structure with one another. That is to say, two lists can have the same tail, or final sequence of conses. For instance, after the execution of the following Common Lisp code:

the lists foo and bar are (a b c) and (x b c) respectively. However, the tail (b c) is the same structure in both lists. It is not a copy; the cons cells pointing to b and c are in the same memory locations for both lists.
Sharing structure rather than copying can give a dramatic performance improvement. However, this technique can interact in undesired ways with functions that alter lists passed to them as arguments. Altering one list, such as by replacing the c with a goose, will affect the other:

This changes foo to (a b goose), but thereby also changes bar to (x b goose) – a possibly unexpected result. This can be a source of bugs, and functions which alter their arguments are documented as destructive for this very reason.
Aficionados of functional programming avoid destructive functions. In the Scheme dialect, which favors the functional style, the names of destructive functions are marked with a cautionary exclamation point, or ""bang""—such as set-car! (read set car bang), which replaces the car of a cons. In the Common Lisp dialect, destructive functions are commonplace; the equivalent of set-car! is named rplaca for ""replace car"". This function is rarely seen, however, as Common Lisp includes a special facility, setf, to make it easier to define and use destructive functions. A frequent style in Common Lisp is to write code functionally (without destructive calls) when prototyping, then to add destructive calls as an optimization where it is safe to do so.

Self-evaluating forms and quoting
Lisp evaluates expressions which are entered by the user. Symbols and lists evaluate to some other (usually, simpler) expression – for instance, a symbol evaluates to the value of the variable it names; (+ 2 3) evaluates to 5. However, most other forms evaluate to themselves: if entering 5 into Lisp, it returns 5.
Any expression can also be marked to prevent it from being evaluated (as is necessary for symbols and lists). This is the role of the quote special operator, or its abbreviation ' (one quotation mark). For instance, usually if entering the symbol foo, it returns the value of the corresponding variable (or an error, if there is no such variable). To refer to the literal symbol, enter (quote foo) or, usually, 'foo.
Both Common Lisp and Scheme also support the backquote operator (termed quasiquote in Scheme), entered with the ` character (grave accent). This is almost the same as the plain quote, except it allows expressions to be evaluated and their values interpolated into a quoted list with the comma , unquote and comma-at ,@ splice operators. If the variable snue has the value (bar baz) then `(foo ,snue) evaluates to (foo (bar baz)), while `(foo ,@snue) evaluates to (foo bar baz). The backquote is most often used in defining macro expansions.Self-evaluating forms and quoted forms are Lisp's equivalent of literals. It may be possible to modify the values of (mutable) literals in program code. For instance, if a function returns a quoted form, and the code that calls the function modifies the form, this may alter the behavior of the function on subsequent invocations.

Modifying a quoted form like this is generally considered bad style, and is defined by ANSI Common Lisp as erroneous (resulting in ""undefined"" behavior in compiled files, because the file-compiler can coalesce similar constants, put them in write-protected memory, etc.).
Lisp's formalization of quotation has been noted by Douglas Hofstadter (in Gödel, Escher, Bach) and others as an example of the philosophical idea of self-reference.

Scope and closure
The Lisp family splits over the use of dynamic or static (a.k.a. lexical) scope. Clojure, Common Lisp and Scheme make use of static scoping by default, while newLISP, Picolisp and the embedded languages in Emacs and AutoCAD use dynamic scoping. Since version 24.1, Emacs uses both dynamic and lexical scoping.

List structure of program code; exploitation by macros and compilers
A fundamental distinction between Lisp and other languages is that in Lisp, the textual representation of a program is simply a human-readable description of the same internal data structures (linked lists, symbols, number, characters, etc.) as would be used by the underlying Lisp system.
Lisp uses this to implement a very powerful macro system. Like other macro languages such as the one defined by the C preprocessor (the macro preprocessor for the C, Objective-C and C++ programming languages), a macro returns code that can then be compiled. However, unlike C preprocessor macros, the macros are Lisp functions and so can exploit the full power of Lisp.
Further, because Lisp code has the same structure as lists, macros can be built with any of the list-processing functions in the language. In short, anything that Lisp can do to a data structure, Lisp macros can do to code. In contrast, in most other languages, the parser's output is purely internal to the language implementation and cannot be manipulated by the programmer.
This feature makes it easy to develop efficient languages within languages. For example, the Common Lisp Object System can be implemented cleanly as a language extension using macros. This means that if an application needs a different inheritance mechanism, it can use a different object system. This is in stark contrast to most other languages; for example, Java does not support multiple inheritance and there is no reasonable way to add it.
In simplistic Lisp implementations, this list structure is directly interpreted to run the program; a function is literally a piece of list structure which is traversed by the interpreter in executing it. However, most substantial Lisp systems also include a compiler. The compiler translates list structure into machine code or bytecode for execution. This code can run as fast as code compiled in conventional languages such as C.
Macros expand before the compilation step, and thus offer some interesting options. If a program needs a precomputed table, then a macro might create the table at compile time, so the compiler need only output the table and need not call code to create the table at run time. Some Lisp implementations even have a mechanism, eval-when, that allows code to be present during compile time (when a macro would need it), but not present in the emitted module.

Evaluation and the read–eval–print loop
Lisp languages are often used with an interactive command line, which may be combined with an integrated development environment (IDE). The user types in expressions at the command line, or directs the IDE to transmit them to the Lisp system. Lisp reads the entered expressions, evaluates them, and prints the result. For this reason, the Lisp command line is called a read–eval–print loop (REPL).
The basic operation of the REPL is as follows. This is a simplistic description which omits many elements of a real Lisp, such as quoting and macros.
The read function accepts textual S-expressions as input, and parses them into an internal data structure. For instance, if you type the text (+ 1 2) at the prompt, read translates this into a linked list with three elements: the symbol +, the number 1, and the number 2. It so happens that this list is also a valid piece of Lisp code; that is, it can be evaluated. This is because the car of the list names a function—the addition operation.
A foo will be read as a single symbol. 123 will be read as the number one hundred and twenty-three. ""123"" will be read as the string ""123"".
The eval function evaluates the data, returning zero or more other Lisp data as a result. Evaluation does not have to mean interpretation; some Lisp systems compile every expression to native machine code. It is simple, however, to describe evaluation as interpretation: To evaluate a list whose car names a function, eval first evaluates each of the arguments given in its cdr, then applies the function to the arguments. In this case, the function is addition, and applying it to the argument list (1 2) yields the answer 3. This is the result of the evaluation.
The symbol foo evaluates to the value of the symbol foo. Data like the string ""123"" evaluates to the same string. The list (quote (1 2 3)) evaluates to the list (1 2 3).
It is the job of the print function to represent output to the user. For a simple result such as 3 this is trivial. An expression which evaluated to a piece of list structure would require that print traverse the list and print it out as an S-expression.
To implement a Lisp REPL, it is necessary only to implement these three functions and an infinite-loop function. (Naturally, the implementation of eval will be complex, since it must also implement all special operators like if or lambda.) This done, a basic REPL is one line of code: (loop (print (eval (read)))).
The Lisp REPL typically also provides input editing, an input history, error handling and an interface to the debugger.
Lisp is usually evaluated eagerly. In Common Lisp, arguments are evaluated in applicative order ('leftmost innermost'), while in Scheme order of arguments is undefined, leaving room for optimization by a compiler.

Control structures
Lisp originally had very few control structures, but many more were added during the language's evolution. (Lisp's original conditional operator, cond, is the precursor to later if-then-else structures.)
Programmers in the Scheme dialect often express loops using tail recursion. Scheme's commonality in academic computer science has led some students to believe that tail recursion is the only, or the most common, way to write iterations in Lisp, but this is incorrect. All oft-seen Lisp dialects have imperative-style iteration constructs, from Scheme's do loop to Common Lisp's complex loop expressions. Moreover, the key issue that makes this an objective rather than subjective matter is that Scheme makes specific requirements for the handling of tail calls, and thus the reason that the use of tail recursion is generally encouraged for Scheme is that the practice is expressly supported by the language definition. By contrast, ANSI Common Lisp does not require the optimization commonly termed a tail call elimination. Thus, the fact that tail recursive style as a casual replacement for the use of more traditional iteration constructs (such as do, dolist or loop) is discouraged in Common Lisp is not just a matter of stylistic preference, but potentially one of efficiency (since an apparent tail call in Common Lisp may not compile as a simple jump) and program correctness (since tail recursion may increase stack use in Common Lisp, risking stack overflow).
Some Lisp control structures are special operators, equivalent to other languages' syntactic keywords. Expressions using these operators have the same surface appearance as function calls, but differ in that the arguments are not necessarily evaluated—or, in the case of an iteration expression, may be evaluated more than once.
In contrast to most other major programming languages, Lisp allows implementing control structures using the language. Several control structures are implemented as Lisp macros, and can even be macro-expanded by the programmer who wants to know how they work.
Both Common Lisp and Scheme have operators for non-local control flow. The differences in these operators are some of the deepest differences between the two dialects. Scheme supports re-entrant continuations using the call/cc procedure, which allows a program to save (and later restore) a particular place in execution. Common Lisp does not support re-entrant continuations, but does support several ways of handling escape continuations.
Often, the same algorithm can be expressed in Lisp in either an imperative or a functional style. As noted above, Scheme tends to favor the functional style, using tail recursion and continuations to express control flow. However, imperative style is still quite possible. The style preferred by many Common Lisp programmers may seem more familiar to programmers used to structured languages such as C, while that preferred by Schemers more closely resembles pure-functional languages such as Haskell.
Because of Lisp's early heritage in list processing, it has a wide array of higher-order functions relating to iteration over sequences. In many cases where an explicit loop would be needed in other languages (like a for loop in C) in Lisp the same task can be accomplished with a higher-order function. (The same is true of many functional programming languages.)
A good example is a function which in Scheme is called map and in Common Lisp is called mapcar. Given a function and one or more lists, mapcar applies the function successively to the lists' elements in order, collecting the results in a new list:

This applies the + function to each corresponding pair of list elements, yielding the result (11 22 33 44 55).

Examples
Here are examples of Common Lisp code.
The basic ""Hello, World!"" program:

Lisp syntax lends itself naturally to recursion. Mathematical problems such as the enumeration of recursively defined sets are simple to express in this notation. For example, to evaluate a number's factorial:

An alternative implementation takes less stack space than the previous version if the underlying Lisp system optimizes tail recursion:

Contrast the examples above with an iterative version which uses Common Lisp's loop macro:

The following function reverses a list. (Lisp's built-in reverse function does the same thing.)

Object systems
Various object systems and models have been built on top of, alongside, or into Lisp, including

The Common Lisp Object System, CLOS, is an integral part of ANSI Common Lisp. CLOS descended from New Flavors and CommonLOOPS. ANSI Common Lisp was the first standardized object-oriented programming language (1994, ANSI X3J13).
ObjectLisp or Object Lisp, used by Lisp Machines Incorporated and early versions of Macintosh Common Lisp
LOOPS (Lisp Object-Oriented Programming System) and the later CommonLoops
Flavors, built at MIT, and its descendant New Flavors (developed by Symbolics).
KR (short for Knowledge Representation), a constraints-based object system developed to aid the writing of Garnet, a GUI library for Common Lisp.
Knowledge Engineering Environment (KEE) used an object system named UNITS and integrated it with an inference engine and a truth maintenance system (ATMS).

Operating systems
Several operating systems, including language-based systems, are based on Lisp (use Lisp features, conventions, methods, data structures, etc.), or are written in Lisp, including
Genera, renamed Open Genera, by Symbolics; Medley, written in Interlisp, originally a family of graphical operating systems that ran on Xerox's later Star workstations; Mezzano; Interim; ChrysaLisp, by developers of Tao Systems' TAOS.

See also
Self-modifying code

References
Further reading
External links

HistoryHistory of Lisp – John McCarthy's history of 12 February 1979
Lisp History – Herbert Stoyan's history compiled from the documents (acknowledged by McCarthy as more complete than his own, see: McCarthy's history links)
History of LISP at the Computer History Museum
Bell, Adam Gordon (2 May 2022). LISP in Space, with Ron Garret. CoRecursive (podcast, transcript, photos). about the use of LISP software on NASA robots.
Cassel, David (22 May 2022). ""NASA Programmer Remembers Debugging Lisp in Deep Space"". The New Stack.Associations and meetingsAssociation of Lisp Users
European Common Lisp Meeting
European Lisp Symposium
International Lisp ConferenceBooks and tutorialsCasting SPELs in Lisp, a comic-book style introductory tutorial
On Lisp, a free book by Paul Graham
Practical Common Lisp, freeware edition by Peter Seibel
Lisp for the web
Land of Lisp
Let over LambdaInterviewsOral history interview with John McCarthy at Charles Babbage Institute, University of Minnesota, Minneapolis. McCarthy discusses his role in the development of time-sharing at the Massachusetts Institute of Technology. He also describes his work in artificial intelligence (AI) funded by the Advanced Research Projects Agency, including logic-based AI (LISP) and robotics.
Interview with Richard P. Gabriel (Podcast)ResourcesCLiki: the Common Lisp wiki
The Common Lisp Directory (via the Wayback Machine; archived from the original)
Lisp FAQ Index
lisppaste
Planet Lisp
Weekly Lisp News
newLISP - A modern, general-purpose scripting language
Lisp Weekly
Lisp at Curlie",18016,https://en.wikipedia.org/wiki/Lisp_(programming_language)
Little b (programming language),"Little b is a domain-specific programming language, more specifically, a modeling language, designed to build modular mathematical models of biological systems.  It was designed and authored by Aneil Mallavarapu.  Little b is being developed in the Virtual Cell Program at Harvard Medical School, headed by mathematician Jeremy Gunawardena.
This language is based on Lisp and is meant to allow modular programming to model biological systems.  It will allow more flexibility to facilitate rapid change that is required to accurately capture complex biological systems.
The language draws on techniques from artificial intelligence and symbolic mathematics, and provides  syntactic conveniences derived from object-oriented languages.  The language was originally denoted with a lowercase b (distinguishing it from B, the predecessor to the widely used C programming language), but the name was eventually changed to ""little b"" to avoid confusion and to pay homage to Smalltalk.","Little b is a domain-specific programming language, more specifically, a modeling language, designed to build modular mathematical models of biological systems.  It was designed and authored by Aneil Mallavarapu.  Little b is being developed in the Virtual Cell Program at Harvard Medical School, headed by mathematician Jeremy Gunawardena.
This language is based on Lisp and is meant to allow modular programming to model biological systems.  It will allow more flexibility to facilitate rapid change that is required to accurately capture complex biological systems.
The language draws on techniques from artificial intelligence and symbolic mathematics, and provides  syntactic conveniences derived from object-oriented languages.  The language was originally denoted with a lowercase b (distinguishing it from B, the predecessor to the widely used C programming language), but the name was eventually changed to ""little b"" to avoid confusion and to pay homage to Smalltalk.

References
Krieger K. ""Life in Silico: A Different Kind of Intelligent Design"". Science. 312(5771):189–190.
https://arstechnica.com/uncategorized/2008/07/little-b-project-creates-biology-specific-programming-system/
https://www.computerworld.com/article/2551598/big-things-from-little-b.html

External links
Biology enters 'The Matrix' through new computer language EurekAlert article",4740151,https://en.wikipedia.org/wiki/Little_b_(programming_language)
LiveCode,"LiveCode (formerly Revolution and MetaCard) is a cross-platform rapid application development runtime system inspired by HyperCard. It features the LiveCode Script (formerly MetaTalk) programming language which belongs to the family of xTalk scripting languages like HyperCard's HyperTalk.The environment was introduced in 2001.  The ""Revolution"" development system was based on the MetaCard engine technology which Runtime Revolution later acquired from MetaCard Corporation in 2003. The platform won the Macworld Annual Editor's Choice Award for ""Best Development Software"" in 2004.  ""Revolution"" was renamed ""LiveCode"" in the fall of 2010.  ""LiveCode"" is developed and sold by Runtime Revolution Ltd., based in Edinburgh, Scotland. In March 2015, the company was renamed ""LiveCode Ltd."", to unify the company name with the product. In April 2013, a free/open source version 'LiveCode Community Edition 6.0' was published after a successful crowdfunding campaign at Kickstarter. The code base was re-licensed and made available as free and open source software with a version in April 2013.
LiveCode runs on iOS, Android, OS X, Windows 95 through Windows 10, Raspberry Pi and several variations of Unix, including Linux, Solaris, and BSD. It can be used for mobile, desktop and server/CGI applications. The iOS (iPhone and iPad) version was released in December 2010. The first version to deploy to the Web was released in 2009. It is the most widely used HyperCard/HyperTalk clone, and the only one that runs on all major operating systems.
A developer release of v.8 was announced in New York on March 12, 2015. This major enhancement to the product includes a new, separate development language, known as ""LiveCode Builder"",  which is capable of creating new object classes called ""widgets"". In earlier versions, the set of object classes was fixed, and could be enhanced only via the use of ordinary procedural languages such as C. The new language, which runs in its own IDE, is a departure from the transitional x-talk paradigm in that it permits typing of variables. But the two environments are fully integrated, and apart from the ability to create new objects, development in LiveCode proceeds in the normal way, within the established IDE.
A second crowdfunding campaign to Bring HTML5 to LiveCode reached funding goals of nearly US$400,000 on July 31, 2014. LiveCode developer release 8.0 DP4 (August 31, 2015) was the first to include a standalone deployment option to HTML5.
On 31 August 2021, starting with version 9.6.4, LiveCode Community edition, licensed under GPL, was discontinued.","LiveCode (formerly Revolution and MetaCard) is a cross-platform rapid application development runtime system inspired by HyperCard. It features the LiveCode Script (formerly MetaTalk) programming language which belongs to the family of xTalk scripting languages like HyperCard's HyperTalk.The environment was introduced in 2001.  The ""Revolution"" development system was based on the MetaCard engine technology which Runtime Revolution later acquired from MetaCard Corporation in 2003. The platform won the Macworld Annual Editor's Choice Award for ""Best Development Software"" in 2004.  ""Revolution"" was renamed ""LiveCode"" in the fall of 2010.  ""LiveCode"" is developed and sold by Runtime Revolution Ltd., based in Edinburgh, Scotland. In March 2015, the company was renamed ""LiveCode Ltd."", to unify the company name with the product. In April 2013, a free/open source version 'LiveCode Community Edition 6.0' was published after a successful crowdfunding campaign at Kickstarter. The code base was re-licensed and made available as free and open source software with a version in April 2013.
LiveCode runs on iOS, Android, OS X, Windows 95 through Windows 10, Raspberry Pi and several variations of Unix, including Linux, Solaris, and BSD. It can be used for mobile, desktop and server/CGI applications. The iOS (iPhone and iPad) version was released in December 2010. The first version to deploy to the Web was released in 2009. It is the most widely used HyperCard/HyperTalk clone, and the only one that runs on all major operating systems.
A developer release of v.8 was announced in New York on March 12, 2015. This major enhancement to the product includes a new, separate development language, known as ""LiveCode Builder"",  which is capable of creating new object classes called ""widgets"". In earlier versions, the set of object classes was fixed, and could be enhanced only via the use of ordinary procedural languages such as C. The new language, which runs in its own IDE, is a departure from the transitional x-talk paradigm in that it permits typing of variables. But the two environments are fully integrated, and apart from the ability to create new objects, development in LiveCode proceeds in the normal way, within the established IDE.
A second crowdfunding campaign to Bring HTML5 to LiveCode reached funding goals of nearly US$400,000 on July 31, 2014. LiveCode developer release 8.0 DP4 (August 31, 2015) was the first to include a standalone deployment option to HTML5.
On 31 August 2021, starting with version 9.6.4, LiveCode Community edition, licensed under GPL, was discontinued.

Description
The LiveCode software creates applications that run in many supported environments, using a compile-free workflow. The same computer code in LiveCode can play across multiple devices and platforms. LiveCode uses a high level, English-like programming language called Transcript that is dynamically typed. Transcript and compile-free workflow generates code that is self-documenting and easy for casual programmers to comprehend. For example, if the following script was executed when the system clock was at 9:00:00 AM:

Ten lines will be loaded into the first text field. (denoted as ""field 1""), and seen as:

Hello world at 9:00:00 AM
Hello world at 9:00:01 AM
Hello world at 9:00:02 AM
...

Notes:

repeat (and the associated end repeat) is a control structure, illustrated here in just one of its various forms.
put is a command
""Hello World at"" is a literal
the long time is a function that calls the system time
return is a constant equal to ASCII character 10 (linefeed)
after is a keyword that is involved with an extremely powerful and intuitive system known as ""chunking"", a hallmark of xTalk languages.
field 1 is an object reference, here denoted by the layer number of a text field. Almost all standard object classes are supported, and may be referred to in several, highly-intuitive ways.LiveCode's natural English-like syntax is easy for beginners to learn. Variables are typeless, and are typed at compile time based purely on context. This makes the language simple to read and maintain, with relatively minimal loss of speed. The language contains advanced features including associative arrays, regular expressions, multimedia, support for a variety of SQL databases, and TCP/IP libraries. The LiveCode engine supports several common image formats (including BMP, PNG, GIF, and JPEG,), anti-aliased vector graphics, HTML-style text hyperlinks, chained behaviors and embedded web browsers. Accessing these higher-level functions is designed to be straightforward.

Examples
To load the source code of a web page into a variable takes one line of code:
Uploading a file to an FTP server uses similar syntax:

Depth
LiveCode has around 2,950 built-in language terms and keywords, which may be extended by external libraries written in C and other lower level languages.

Outcomes
LiveCode project files are binary-compatible across platforms. They inherit each platform's look-and-feel and behaviors. Buttons, scroll bars, progress bars and menus behave as expected on the target platform without any intervention on the part of the one authoring a LiveCode application.
Compiling a LiveCode ""standalone"" produces a single, executable file (minimum size ~1.5MB) for each platform targeted. There is no separate runtime necessary.
The Wikipedia article on HyperCard contains a more detailed discussion about the basics of a similar development environment and scripting language. Modern LiveCode is a vast superset of the former HyperCard yet retains its simplicity. LiveCode includes a number of features missing from the original HyperCard program, including multiple platform deployment, communication with external devices and many fundamental language extensions. The LiveCode toolkit, as compared to HyperCard, has the ability to access internet-based text and media resources, which allows the creation of internet-enabled desktop applications.

Compatibility
iOS and Android targets are available in some versions.
Note: Complete Linux requirements for 4.5.x-6.x are the following:

32-bit installation, or a 64-bit linux distribution that has a 32-bit compatibility layer
2.4.x or later kernel
X11R5 capable Xserver running locally on a 24-bit display
glibc 2.3.2 or later
gtk/gdk/glib (optional – required for native theme support)
pango/xft (optional – required for pdf printing, anti-aliased text and unicode font support)
lcms (optional – required for color profile support in JPEGs and PNGs)
gksu (optional – required for elevate process support)

See also
MetaCard, Runtime Revolution acquired the MetaCard technology, on which its development system is based, in 2003.
HyperCard, Progenitor of all xTalk languages.

References
Bibliography
External links
Official website",30890362,https://en.wikipedia.org/wiki/LiveCode
Logo (programming language),"Logo is an educational programming language, designed in 1967 by Wally Feurzeig, Seymour Papert, and Cynthia Solomon. Logo is not an acronym: the name was coined by Feurzeig while he was at Bolt, Beranek and Newman, and derives from the Greek logos, meaning word or thought.
A general-purpose language, Logo is widely known for its use of turtle graphics, in which commands for movement and drawing produced line or vector graphics, either on screen or with a small robot termed a turtle. The language was conceived to teach concepts of programming related to Lisp and only later to enable what Papert called ""body-syntonic reasoning"", where students could understand, predict, and reason about the turtle's motion by imagining what they would do if they were the turtle. There are substantial differences among the many dialects of Logo, and the situation is confused by the regular appearance of turtle graphics programs that are named Logo.
Logo is a multi-paradigm adaptation and dialect of Lisp, a functional programming language. There is no standard Logo, but UCBLogo has the best facilities for handling lists, files, I/O, and recursion in scripts, and can be used to teach all computer science concepts, as UC Berkeley lecturer Brian Harvey did in his Computer Science Logo Style trilogy.Logo is usually an interpreted language, although compiled Logo dialects (such as Lhogho and Liogo) have been developed. Logo is not case-sensitive but retains the case used for formatting purposes.","Logo is an educational programming language, designed in 1967 by Wally Feurzeig, Seymour Papert, and Cynthia Solomon. Logo is not an acronym: the name was coined by Feurzeig while he was at Bolt, Beranek and Newman, and derives from the Greek logos, meaning word or thought.
A general-purpose language, Logo is widely known for its use of turtle graphics, in which commands for movement and drawing produced line or vector graphics, either on screen or with a small robot termed a turtle. The language was conceived to teach concepts of programming related to Lisp and only later to enable what Papert called ""body-syntonic reasoning"", where students could understand, predict, and reason about the turtle's motion by imagining what they would do if they were the turtle. There are substantial differences among the many dialects of Logo, and the situation is confused by the regular appearance of turtle graphics programs that are named Logo.
Logo is a multi-paradigm adaptation and dialect of Lisp, a functional programming language. There is no standard Logo, but UCBLogo has the best facilities for handling lists, files, I/O, and recursion in scripts, and can be used to teach all computer science concepts, as UC Berkeley lecturer Brian Harvey did in his Computer Science Logo Style trilogy.Logo is usually an interpreted language, although compiled Logo dialects (such as Lhogho and Liogo) have been developed. Logo is not case-sensitive but retains the case used for formatting purposes.

History
Logo was created in 1967 at Bolt, Beranek and Newman (BBN), a Cambridge, Massachusetts research firm, by Wally Feurzeig, Cynthia Solomon, and Seymour Papert. Its intellectual roots are in artificial intelligence, mathematical logic and developmental psychology. For the first four years of Logo research, development and teaching work was done at BBN. The first implementation of Logo, called Ghost, was written in LISP on a PDP-1. The goal was to create a mathematical land where children could play with words and sentences. Modeled on LISP, the design goals of Logo included accessible power  and informative error messages. The use of virtual Turtles allowed for immediate visual feedback and debugging of graphic programming.
The first working Logo turtle robot was created in 1969. A display turtle preceded the physical floor turtle. Modern Logo has not changed very much from the basic concepts predating the first turtle. The first turtle was a tethered floor roamer, not radio-controlled or wireless. At BBN Paul Wexelblat developed a turtle named Irving that had touch sensors and could move forwards, backwards, rotate, and ding its bell. The earliest year-long school users of Logo were in 1968–69 at Muzzey Jr. High in Lexington, Massachusetts. The virtual and physical turtles were first used by fifth-graders at the Bridge School in the same city in 1970–71.

Turtle and graphics
Logo's most-known feature is the turtle (derived originally from a robot of the same name), an on-screen ""cursor"" that shows output from commands for movement and small retractable pen, together producing line graphics. It has traditionally been displayed either as a triangle or a turtle icon (though it can be represented by any icon). Turtle graphics were added to the Logo language by Seymour Papert in the late 1960s to support Papert's version of the turtle robot, a simple robot controlled from the user's workstation that is designed to carry out the drawing functions assigned to it using a small retractable pen set into or attached to the robot's body.
As a practical matter, the use of turtle geometry instead of a more traditional model mimics the actual movement logic of the turtle robot. The turtle moves with commands that are relative to its own position, LEFT 90 means spin left by 90 degrees. Some Logo implementations, particularly those that allow the use of concurrency and multiple turtles, support collision detection and allow the user to redefine the appearance of the turtle cursor, essentially allowing the Logo turtles to function as sprites.
Turtle geometry is also sometimes used in environments other than Logo as an alternative to a strictly coordinate-addressed graphics system. For instance, the idea of turtle graphics is also useful in Lindenmayer system for generating fractals.

Implementations
Some modern derivatives of Logo allow thousands of independently moving turtles. There are two popular implementations: Massachusetts Institute of Technology's StarLogo and Northwestern University Center for Connected Learning's (CCL) NetLogo. They allow exploring emergent phenomena and come with many experiments in social studies, biology, physics, and other areas. NetLogo is widely used in agent-based simulation in the biological and social sciences.
Although there is no agreed-upon standard, there is a broad consensus on core aspects of the language. In March 2020, there were counted 308 implementations and dialects of Logo, each with its own strengths. Most of those 308 are no longer in wide use, but many are still under development. Commercial implementations widely used in schools include MicroWorlds Logo and Imagine Logo.
Legacy and current implementations include:

First released in 1980s
Apple Logo for the Apple II Plus and Apple Logo Writer for the Apple IIe, developed by Logo Computer Systems, Inc. (LCSI), were the most broadly used and prevalent early implementations of Logo that peaked in the early to mid-1980s.
Aquarius LOGO was released in 1982 on cartridge by Mattel for the Aquarius home computer.
Atari Logo was released on cartridge by Atari for the Atari 8-bit family.
Color Logo was released in 1983 on cartridge (26-2722) and disk (26-2721) by Tandy for the TRS-80 Color Computer.
Commodore Logo was released, with the subtitle ""A Language for Learning"", by Commodore International. It was based on MIT Logo and enhanced by Terrapin, Inc. The Commodore 64 version (C64105) was released on diskette in 1983; the Plus/4 version (T263001) was released on cartridge in 1984.
ExperLogo was released in 1985 on floppy by Expertelligence Inc. for the Macintosh 128K.
Hot-Logo was released in the mid-1980s by EPCOM for the MSX 8-bit computers with its own set of commands in Brazilian Portuguese.
TI Logo (for the TI-99/4A computer) was used in primary schools, emphasizing Logo's usefulness in teaching computing fundamentals to novice programmers.
Sprite Logo, also developed by Logo Computer Systems Inc., had ten turtles that could run as independent processes. It ran on Apple II computers, with the aid of a Sprite Card inserted in one of the computer's slots.
IBM marketed their own version of Logo (P/N 6024076), developed jointly by Logo Computer Systems, Inc. (LCSI), for their then-new IBM PC.
ObjectLOGO is a variant of Logo with object-oriented programming extensions and lexical scoping. Version 2.7 was sold by Digitool, Inc.  It is no longer being developed or supported, and does not run on versions of the Mac operating system later than version 7.5.
Dr. Logo was developed by Digital Research and distributed in computers including the IBM PCjr, Atari ST and the Amstrad CPC.
Acornsoft Logo was released in 1985. It is a commercial implementation of Logo for the 8-bit BBC Micro and Acorn Electron computers. It was developed for Acorn Computers as a full implementation of Logo. It features multiple screen turtles and four-channel sound. It was provided on two 16kB ROMs, with utilities and drivers as accompanying software.First released in 1990s
In February 1990, Electron User published Timothy Grantham's simple implementation of Logo for the Acorn Electron under the article ""Talking Turtle"".
Comenius Logo is an implementation of Logo developed by Comenius University Faculty of Mathematics and Physics. It started development in December 1991, and is also known in other countries as SuperLogo, MultiLogo and MegaLogo.
Lego Logo is a version of Logo that can manipulate robotic Lego bricks attached to a computer. It was implemented on the Apple II computing platform and was used in American and other grade schools in the late 1980s and early 1990s. Lego Logo is a precursor to Scratch.
UCBLogo, also known as Berkeley Logo, is a free, cross-platform implementation of standard Logo last released in 2009. George Mills at MIT used UCBLogo as the basis for MSWLogo which is more refined and also free. Jim Muller wrote a book, The Great Logo Adventure, which was a complete Logo manual and which used MSWLogo as the demonstration language. MSWLogo has evolved into FMSLogo.First released from 2000 onwards
aUCBLogo is a rewrite and enhancement of UCBLogo.
Imagine Logo is a successor of Comenius Logo, implemented in 2000. The English version was released by Logotron Ltd. in 2001.
LibreLogo is an extension to some versions of LibreOffice. Released in 2012, it is written in Python. It allows vector graphics to be written in Writer.
Logo3D is a tridimensional version of Logo.
POOL is a dialect of Logo with object-oriented extensions, implemented in 2014. POOL programs are compiled and run in the graphical IDE on Microsoft Windows. A simplified, cross-platform environment is available for systems supporting .NET Framework.
QLogo is an open-source and cross-platform rewrite of UCBLogo with nearly full UCB compatibility that uses hardware-accelerated graphics.
Lynx is an online version of Logo developed by Logo Computer Systems Inc. It can run a large number of turtles, supports animation, parallel processes, colour and collision detection.
LogoMor is an open-source online 3D Logo interpreter based on JavaScript and p5.js. It supports 3D drawings, animations, multimedia, 3D models and various tools. It also includes a fully-featured code editor based on CodeMirror
LbyM is an open-source online Logo interpreter based on JavaScript, created and actively developed (as of 2021) for Sonoma State University's Learning by Making program. It features traditional Logo programming, connectivity with a customized microcontroller and integration with a modern code editor.

Influence
Logo was a primary influence on the Smalltalk programming language. It is also the main influence on the Etoys educational programming environment and language, which is essentially a Logo variant written in Squeak (itself a variant of Smalltalk). Logo influenced the procedure/method model in AgentSheets and AgentCubes to program agents similar to the notion of a turtle in Logo. Logo provided the underlying language for Boxer. Boxer was developed at University of California, Berkeley and MIT and is based on a literacy model, making it easier to use for nontechnical people.KTurtle is a variation of Logo implemented at Qt for the KDE environment loosely based on Logo.Two more results of Logo's influence are Kojo, a variant of Scala, and Scratch, a visual, drag-and-drop language which runs in a web browser.

References
Further reading
External links
 Media related to Logo (programming language) at Wikimedia Commons
 Logo Programming at Wikibooks",18334,https://en.wikipedia.org/wiki/Logo_(programming_language)
Lua (programming language),"Lua ( LOO-ə; from Portuguese: lua [ˈlu(w)ɐ] meaning moon) is a lightweight, high-level, multi-paradigm programming language designed primarily for embedded use in applications. Lua is cross-platform, since the interpreter of compiled bytecode is written in ANSI C, and Lua has a relatively simple C API to embed it into applications.Lua originated in 1993 as a language for extending software applications to meet the increasing demand for customization at the time. It provided the basic facilities of most procedural programming languages, but more complicated or domain-specific features were not included; rather, it included mechanisms for extending the language, allowing programmers to implement such features. As Lua was intended to be a general embeddable extension language, the designers of Lua focused on improving its speed, portability, extensibility and ease-of-use in development.","Lua ( LOO-ə; from Portuguese: lua [ˈlu(w)ɐ] meaning moon) is a lightweight, high-level, multi-paradigm programming language designed primarily for embedded use in applications. Lua is cross-platform, since the interpreter of compiled bytecode is written in ANSI C, and Lua has a relatively simple C API to embed it into applications.Lua originated in 1993 as a language for extending software applications to meet the increasing demand for customization at the time. It provided the basic facilities of most procedural programming languages, but more complicated or domain-specific features were not included; rather, it included mechanisms for extending the language, allowing programmers to implement such features. As Lua was intended to be a general embeddable extension language, the designers of Lua focused on improving its speed, portability, extensibility and ease-of-use in development.

History
Lua was created in 1993 by Roberto Ierusalimschy, Luiz Henrique de Figueiredo and Waldemar Celes, members of the Computer Graphics Technology Group (Tecgraf) at the Pontifical Catholic University of Rio de Janeiro, in Brazil.
From 1977 until 1992, Brazil had a policy of strong trade barriers (called a market reserve) for computer hardware and software, believing that Brazil could and should produce its own hardware and software. In that atmosphere, Tecgraf's clients could not afford, either politically or financially, to buy customized software from abroad; under the market reserve, clients would have to go through a complicated bureaucratic process to prove their needs couldn't be met by Brazilian companies. Those reasons led Tecgraf to implement the basic tools it needed from scratch.Lua's predecessors were the data-description/configuration languages SOL (Simple Object Language) and DEL (data-entry language). They had been independently developed at Tecgraf in 1992–1993 to add some flexibility into two different projects (both were interactive graphical programs for engineering applications at Petrobras company). There was a lack of any flow-control structures in SOL and DEL, and Petrobras felt a growing need to add full programming power to them.
In The Evolution of Lua, the language's authors wrote:
In 1993, the only real contender was Tcl, which had been explicitly designed to be embedded into applications. However, Tcl had unfamiliar syntax, did not offer good support for data description, and ran only on Unix platforms. We did not consider LISP or Scheme because of their unfriendly syntax. Python was still in its infancy. In the free, do-it-yourself atmosphere that then reigned in Tecgraf, it was quite natural that we should try to develop our own scripting language ... Because many potential users of the language were not professional programmers, the language should avoid cryptic syntax and semantics. The implementation of the new language should be highly portable, because Tecgraf's clients had a very diverse collection of computer platforms. Finally, since we expected that other Tecgraf products would also need to embed a scripting language, the new language should follow the example of SOL and be provided as a library with a C API.
Lua 1.0 was designed in such a way that its object constructors, being then slightly different from the current light and flexible style, incorporated the data-description syntax of SOL (hence the name Lua: Sol meaning ""Sun"" in Portuguese, and Lua meaning ""Moon""). Lua syntax for control structures was mostly borrowed from Modula (if, while, repeat/until), but also had taken influence from CLU (multiple assignments and multiple returns from function calls, as a simpler alternative to reference parameters or explicit pointers), C++ (""neat idea of allowing a local variable to be declared only where we need it""), SNOBOL and AWK (associative arrays). In an article published in Dr. Dobb's Journal, Lua's creators also state that LISP and Scheme with their single, ubiquitous data-structure mechanism (the list) were a major influence on their decision to develop the table as the primary data structure of Lua.Lua semantics have been increasingly influenced by Scheme over time, especially with the introduction of anonymous functions and full lexical scoping. Several features were added in new Lua versions.
Versions of Lua prior to version 5.0 were released under a license similar to the BSD license. From version 5.0 onwards, Lua has been licensed under the MIT License. Both are permissive free software licences and are almost identical.

Features
Lua is commonly described as a ""multi-paradigm"" language, providing a small set of general features that can be extended to fit different problem types. Lua does not contain explicit support for inheritance, but allows it to be implemented with metatables. Similarly, Lua allows programmers to implement namespaces, classes and other related features using its single table implementation; first-class functions allow the employment of many techniques from functional programming and full lexical scoping allows fine-grained information hiding to enforce the principle of least privilege.
In general, Lua strives to provide simple, flexible meta-features that can be extended as needed, rather than supply a feature-set specific to one programming paradigm. As a result, the base language is light; the full reference interpreter is only about 247 kB compiled and easily adaptable to a broad range of applications. 
As a dynamically typed language intended for use as an extension language or scripting language, Lua is compact enough to fit on a variety of host platforms. It supports only a small number of atomic data structures such as Boolean values, numbers (double-precision floating point and 64-bit integers by default) and strings. Typical data structures such as arrays, sets, lists and records can be represented using Lua's single native data structure, the table, which is essentially a heterogeneous associative array.
Lua implements a small set of advanced features such as first-class functions, garbage collection, closures, proper tail calls, coercion (automatic conversion between string and number values at run time), coroutines (cooperative multitasking) and dynamic module loading.

Syntax
The classic ""Hello, World!"" program can be written as follows, with or without parentheses:

A comment in Lua starts with a double-hyphen and runs to the end of the line, similar to Ada, Eiffel, Haskell, SQL and VHDL. Multi-line strings and comments are adorned with double square brackets.

The factorial function is implemented as a function in this example:

Control flow
Lua has one type of conditional test: if then end with optional else and elseif then execution control constructs.
The generic if then end statement requires all three keywords:

The else keyword may be added with an accompanying statement block to control execution when the if condition evaluates to false:

Execution may also be controlled according to multiple conditions using the elseif then keywords:

Lua has four types of conditional loops: the while loop, the repeat loop (similar to a do while loop), the numeric for loop and the generic for loop.

This generic for loop would iterate over the table _G using the standard iterator function pairs, until it returns nil:

Loops can also be nested (put inside of another loop).

Functions
Lua's treatment of functions as first-class values is shown in the following example, where the print function's behavior is modified:

Any future calls to print will now be routed through the new function, and because of Lua's lexical scoping, the old print function will only be accessible by the new, modified print.
Lua also supports closures, as demonstrated below:

A new closure for the variable x is created every time addto is called, so that each new anonymous function returned will always access its own x parameter. The closure is managed by Lua's garbage collector, just like any other object.

Tables
Tables are the most important data structures (and, by design, the only built-in composite data type) in Lua and are the foundation of all user-created types. They are associative arrays with addition of automatic numeric key and special syntax.
A table is a collection of key and data pairs, where the data is referenced by key; in other words, it is a hashed heterogeneous associative array.
Tables are created using the {} constructor syntax.

Tables are always passed by reference (see Call by sharing).
A key (index) can be any value except nil and NaN, including functions.

A table is often used as structure (or record) by using strings as keys. Because such use is very common, Lua features a special syntax for accessing such fields.

By using a table to store related functions, it can act as a namespace.

Tables are automatically assigned a numerical key, enabling them to be used as an array data type. The first automatic index is 1 rather than 0 as it is for many other programming languages (though an explicit index of 0 is allowed).
A numeric key 1 is distinct from a string key ""1"".

The length of a table t is defined to be any integer index n such that t[n] is not nil and t[n+1] is nil; moreover, if t[1] is nil, n can be zero. For a regular array, with non-nil values from 1 to a given n, its length is exactly that n, the index of its last value. If the array has ""holes"" (that is, nil values between other non-nil values), then #t can be any of the indices that directly precedes a nil value (that is, it may consider any such nil value as the end of the array).

A table can be an array of objects.

Using a hash map to emulate an array is normally slower than using an actual array; however, Lua tables are optimized for use as arrays to help avoid this issue.

Metatables
Extensible semantics is a key feature of Lua, and the metatable concept allows powerful customization of tables. The following example demonstrates an ""infinite"" table. For any n, fibs[n] will give the n-th Fibonacci number using dynamic programming and memoization.

Object-oriented programming
Although Lua does not have a built-in concept of classes, object-oriented programming can be emulated using functions and tables. An object is formed by putting methods and fields in a table. Inheritance (both single and multiple) can be implemented with metatables, delegating nonexistent methods and fields to a parent object.
There is no such concept as ""class"" with these techniques; rather, prototypes are used, similar to Self or JavaScript. New objects are created either with a factory method (that constructs new objects from scratch) or by cloning an existing object.
Creating a basic vector object:

Here, setmetatable tells Lua to look for an element in the Vector table if it is not present in the vec table. vec.magnitude, which is equivalent to vec[""magnitude""], first looks in the vec table for the magnitude element. The vec table does not have a magnitude element, but its metatable delegates to the Vector table for the magnitude element when it's not found in the vec table.
Lua provides some syntactic sugar to facilitate object orientation. To declare member functions inside a prototype table, one can use function table:func(args), which is equivalent to function table.func(self, args). Calling class methods also makes use of the colon: object:func(args) is equivalent to object.func(object, args).
That in mind, here is a corresponding class with : syntactic sugar:

Inheritance
Lua supports using metatables to give Lua class inheritance. In this example, we allow vectors to have their values multiplied by a constant in a derived class.

Lua also supports multiple inheritance; __index can either be a function or a table. Operator overloading can also be done; Lua metatables can have elements such as __add, __sub and so on.

Implementation
Lua programs are not interpreted directly from the textual Lua file, but are compiled into bytecode, which is then run on the Lua virtual machine. The compilation process is typically invisible to the user and is performed during run-time, especially when a JIT compiler is used, but it can be done offline in order to increase loading performance or reduce the memory footprint of the host environment by leaving out the compiler. Lua bytecode can also be produced and executed from within Lua, using the dump function from the string library and the load/loadstring/loadfile functions. Lua version 5.3.4 is implemented in approximately 24,000 lines of C code.Like most CPUs, and unlike most virtual machines (which are stack-based), the Lua VM is register-based, and therefore more closely resembles an actual hardware design. The register architecture both avoids excessive copying of values and reduces the total number of instructions per function. The virtual machine of Lua 5 is one of the first register-based pure VMs to have a wide use. Parrot and Android's Dalvik are two other well-known register-based VMs.  PCScheme's VM was also register-based.This example is the bytecode listing of the factorial function defined above (as shown by the luac 5.1 compiler):
function <factorial.lua:1,7> (9 instructions, 36 bytes at 0x8063c60)
1 param, 6 slots, 0 upvalues, 6 locals, 2 constants, 0 functions
	1	[2]	LOADK    	1 -1	; 1
	2	[3]	LOADK    	2 -2	; 2
	3	[3]	MOVE     	3 0
	4	[3]	LOADK    	4 -1	; 1
	5	[3]	FORPREP  	2 1	; to 7
	6	[4]	MUL      	1 1 5
	7	[3]	FORLOOP  	2 -2	; to 6
	8	[6]	RETURN   	1 2
	9	[7]	RETURN   	0 1

C API
Lua is intended to be embedded into other applications, and provides a C API for this purpose. The API is divided into two parts: the Lua core and the Lua auxiliary library. The Lua API's design eliminates the need for manual reference management in C code, unlike Python's API. The API, like the language, is minimalistic. Advanced functionality is provided by the auxiliary library, which consists largely of preprocessor macros which assist with complex table operations.
The Lua C API is stack based. Lua provides functions to push and pop most simple C data types (integers, floats, etc.) to and from the stack, as well as functions for manipulating tables through the stack. The Lua stack is somewhat different from a traditional stack; the stack can be indexed directly, for example. Negative indices indicate offsets from the top of the stack. For example, −1 is the top (most recently pushed value), while positive indices indicate offsets from the bottom (oldest value). Marshalling data between C and Lua functions is also done using the stack. To call a Lua function, arguments are pushed onto the stack, and then the lua_call is used to call the actual function. When writing a C function to be directly called from Lua, the arguments are read from the stack.
Here is an example of calling a Lua function from C:

Running this example gives:

The C API also provides some special tables, located at various ""pseudo-indices"" in the Lua stack. At LUA_GLOBALSINDEX prior to Lua 5.2 is the globals table, _G from within Lua, which is the main namespace. There is also a registry located at LUA_REGISTRYINDEX where C programs can store Lua values for later retrieval.

Modules
Besides standard library (core) modules it is possible to write extensions using the Lua API. Extension modules are shared objects which can be used to extend the functionality of the interpreter by providing native facilities to Lua scripts. Lua scripts may load extension modules using require, just like modules written in Lua itself, or with package.loadlib. When a C library is loaded via require('foo') Lua will look for the function luaopen_foo and call it, which acts as any C function callable from Lua and generally returns a table filled with methods . A growing collection of modules known as rocks are available through a package management system called LuaRocks, in the spirit of CPAN, RubyGems and Python eggs. Prewritten Lua bindings exist for most popular programming languages, including other scripting languages. For C++, there are a number of template-based approaches and some automatic binding generators.

Applications
In video game development, Lua is widely used as a scripting language by programmers, mainly due to its perceived easiness to embed, fast execution, and short learning curve. Notable games which use Lua include Roblox, Garry's Mod,  World of Warcraft, Payday 2,  Phantasy Star Online 2, Dota 2, Crysis, and many others. Some games that do not natively support Lua programming or scripting, have this functionality added by mods, such as ComputerCraft does for Minecraft. In addition, Lua is also used in non-video game software, such as Adobe Lightroom, Moho, iClone, Aerospike and certain system software in FreeBSD and NetBSD, and is used as a template scripting language on MediaWiki using the Scribunto extension.In 2003, a poll conducted by GameDev.net showed Lua was the most popular scripting language for game programming. On 12 January 2012, Lua was announced as a winner of the Front Line Award 2011 from the magazine Game Developer in the category Programming Tools.A large number of non-game applications also use Lua for extensibility, such as LuaTeX, an implementation of the TeX type-setting language, Redis, a key-value database, ScyllaDB, a Wide-column store, Neovim, a text editor, Nginx, a web server, and Wireshark, a network packet analyzer.
Through the Scribunto extension, Lua is available as a server-side scripting language in the MediaWiki software that powers Wikipedia and other wikis. Among its uses are allowing the integration of data from Wikidata into articles, and powering the automated taxobox system.

Derived languages
Languages that compile to Lua
MoonScript is a dynamic, whitespace-sensitive scripting language inspired by CoffeeScript, which is compiled into Lua. This means that instead of using do and end (or { and }) to delimit sections of code it uses line breaks and indentation style. A notable usage of MoonScript is the video game distribution website Itch.io.
Haxe supports compilation to a Lua target, supporting Lua 5.1-5.3 as well as LuaJIT 2.0 and 2.1.
Fennel, a Lisp dialect that targets Lua.
Urn, a Lisp dialect that is built on Lua.
Amulet, an ML-like functional language, whose compiler outputs Lua files.

Dialects
LuaJIT, a just-in-time compiler of Lua 5.1.
Luau from Roblox, a Lua 5.1 language with gradual typing and ergonomic additions.
Ravi, a JIT-enabled Lua 5.3 language with optional static typing. JIT is guided by type information.
Shine, a fork of LuaJIT with many extensions, including a module system and a macro system.
Glua, a modified version embedded into the game Garry's Mod as its scripting language.
Teal, a statically typed lua dialect written in Lua.In addition, the Lua users community provides some power patches on top of the reference C implementation.

See also
Comparison of programming languages

Notes
References
Further reading
Ierusalimschy, R. (2013). Programming in Lua (3rd ed.). Lua.org. ISBN 978-85-903798-5-0. (The 1st ed. is available online.)
Gutschmidt, T. (2003). Game Programming with Python, Lua, and Ruby. Course Technology PTR. ISBN 978-1-59200-077-7.
Schuytema, P.; Manyen, M. (2005). Game Development with Lua. Charles River Media. ISBN 978-1-58450-404-7.
Jung, K.; Brown, A. (2007). Beginning Lua Programming. Wrox Press. ISBN 978-0-470-06917-2. Archived from the original on 8 July 2018. Retrieved 7 July 2018.
Figueiredo, L. H.; Celes, W.; Ierusalimschy, R., eds. (2008). Lua Programming Gems. Lua.org. ISBN 978-85-903798-4-3.
Takhteyev, Yuri (2012). Coding Places: Software Practice in a South American City. The MIT Press. ISBN 978-0-262-01807-4. Archived from the original on 2 November 2012. Chapters 6 and 7 are dedicated to Lua, while others look at software in Brazil more broadly.
Varma, Jayant (2012). Learn Lua for iOS Game Development. Apress. ISBN 978-1-4302-4662-6.
Matheson, Ash (29 April 2003). ""An Introduction to Lua"". GameDev.net. Archived from the original on 18 December 2012. Retrieved 3 January 2013.
Fieldhouse, Keith (16 February 2006). ""Introducing Lua"". ONLamp.com. O'Reilly Media. Archived from the original on 12 March 2006. Retrieved 28 February 2006.
Streicher, Martin (28 April 2006). ""Embeddable scripting with Lua"". developerWorks. IBM. Archived from the original on 2 July 2009. Retrieved 7 July 2018.
Quigley, Joseph (1 June 2007). ""A Look at Lua"". Linux Journal.
Hamilton, Naomi (11 September 2008). ""The A-Z of Programming Languages: Lua"". Computerworld. IDG. Archived from the original on 8 July 2018. Retrieved 7 July 2018. Interview with Roberto Ierusalimschy.
Ierusalimschy, Roberto; de Figueiredo, Luiz Henrique; Celes, Waldemar (12 May 2011). ""Passing a Language through the Eye of a Needle"". ACM Queue. 9 (5): 20–29. doi:10.1145/1978862.1983083. S2CID 19484689. How the embeddability of Lua impacted its design.
Ierusalimschy, Roberto; de Figueiredo, Luiz Henrique; Celes, Waldemar (November 2018). ""A Look at the Design of Lua"". Communications of the ACM. 61 (11): 114–123. doi:10.1145/3186277. S2CID 53114923.
Lua papers and theses

External links

Official website 
Lua Users Archived 16 December 2010 at the Wayback Machine, Community
Lua Forum Archived 28 September 2021 at the Wayback Machine
LuaDist
Lua Rocks - Package manager
Projects in Lua",46150,https://en.wikipedia.org/wiki/Lua_(programming_language)
Macroprogramming,"In computer science, macroprogramming is a programming paradigm 
aimed at expressing the macroscopic, global behaviour of an entire system of agents or computing devices.
In macroprogramming, the local programs for the individual components of a distributed system are compiled or interpreted from a macro-program typically expressed by a system-level perspective or in terms of the intended global goal.
The aim of macroprogramming approaches is to support expressing the macroscopic interactive behaviour of a whole distributed system of computing devices or agents in a single program, or, similarly, to promote their collective intelligence.
It has not to be confused with macros, the mechanism often found in programming languages (like C or Scala) to express substitution rules for program pieces.
Macroprogramming originated in the context of wireless sensor network programming
and found renewed interest in the context of the Internet of Things and swarm robotics.Macroprogramming shares similar goals (related to  programming a system by a global perspective) with multitier programming, choreographic programming, and aggregate computing.","In computer science, macroprogramming is a programming paradigm 
aimed at expressing the macroscopic, global behaviour of an entire system of agents or computing devices.
In macroprogramming, the local programs for the individual components of a distributed system are compiled or interpreted from a macro-program typically expressed by a system-level perspective or in terms of the intended global goal.
The aim of macroprogramming approaches is to support expressing the macroscopic interactive behaviour of a whole distributed system of computing devices or agents in a single program, or, similarly, to promote their collective intelligence.
It has not to be confused with macros, the mechanism often found in programming languages (like C or Scala) to express substitution rules for program pieces.
Macroprogramming originated in the context of wireless sensor network programming
and found renewed interest in the context of the Internet of Things and swarm robotics.Macroprogramming shares similar goals (related to  programming a system by a global perspective) with multitier programming, choreographic programming, and aggregate computing.

Context and motivation
Programming distributed systems, multi-agent systems, and collectives of software agents (e.g., robotic swarms) is difficult, for many issues (like communication, concurrency, and failure) have to be properly considered. In particular, a general recurrent problem is how to induce the intended global behaviour by defining the behaviour of the individual components or agents involved. The problem can be addressed through learning approaches, such as multi-agent reinforcement learning, or by manually defining the control program driving each component. However, addressing the problem by a fully individual (or single-node) perspective may be error-prone, because it is generally difficult to foresee the overall behaviour emerging from complex networks of activities and interactions (cf. complex systems and emergence). Therefore, researchers have started investigated ways to raise the abstraction level, promoting programming of distributed systems by a more global perspective or in terms of the overall goal to be collectively attained.

Examples
ScaFi
The following program in the ScaFi aggregate programming language  [1] defines the loop control logic needed to compute a channel (a Boolean field where the devices yielding true are those connecting, through a hop-by-hop path, a source device to a target device)  across a large set of situated devices interacting with neighbours.

What is interesting to note is that the channel function, as well as the functions that are used to implement it, namely distanceTo, distanceBetween, dilate, broadcast etc.
can be interpreted not just in terms of the individual behaviour of a device, but rather by a macroscopic perspective.
In fact, for instance, distanceTo(s) is used to compute the field of minimum distances from the closest device for which expression s yields true: this is effectively a distributed data structure that is sustained through processing and communication with neighbours, in a self-organising way.
Semantically, such functions define  a macro-level (or collective) behaviour that yields a macro-level (or collective) data structure. Such macro-level functions/behaviours can be composed together to obtain another more complex macro-level function/behaviours.

Regiment
The following program in the Regiment language  can be used to compute the mean temperature perceived by the whole system:

PyoT
The following program in PyoT  can be used to turn on a fan if the mean temperature computed by several sensors exceeds a certain threshold.

TinyDB
In TinyDB, a data-oriented macroprogramming approach is used where the programmer writes a query which turns into single-node operations and routing in a wireless sensor network.

See also
Multitier programming
Choreographic programming
Aggregate computing
Distributed computing


== References ==",73047769,https://en.wikipedia.org/wiki/Macroprogramming
MATH-MATIC,"MATH-MATIC is the marketing name for the AT-3 (Algebraic Translator 3) compiler, an early programming language for the UNIVAC I and UNIVAC II.
MATH-MATIC was written beginning around 1955 by a team led by Charles Katz under the direction of Grace Hopper. A preliminary manual was produced in 1957 and a final manual the following year.
Syntactically, MATH-MATIC was similar to Univac's contemporaneous business-oriented language, FLOW-MATIC, differing in providing algebraic-style expressions and floating-point arithmetic, and arrays rather than record structures.","MATH-MATIC is the marketing name for the AT-3 (Algebraic Translator 3) compiler, an early programming language for the UNIVAC I and UNIVAC II.
MATH-MATIC was written beginning around 1955 by a team led by Charles Katz under the direction of Grace Hopper. A preliminary manual was produced in 1957 and a final manual the following year.
Syntactically, MATH-MATIC was similar to Univac's contemporaneous business-oriented language, FLOW-MATIC, differing in providing algebraic-style expressions and floating-point arithmetic, and arrays rather than record structures.

Notable features
Expressions in MATH-MATIC could contain numeric exponents, including decimals and fractions, by way of a custom typewriter.MATH-MATIC programs could include inline assembler sections of ARITH-MATIC code and UNIVAC machine code.The UNIVAC I had only 1000 words of memory, and the successor UNIVAC II as little as 2000. MATH-MATIC allowed for larger programs, automatically generating code to read overlay segments from UNISERVO tape as required. The compiler attempted to avoid splitting loops across segments.

Influence
In proposing the collaboration with the ACM that led to ALGOL 58, the Gesellschaft für Angewandte Mathematik und Mechanik wrote that it considered MATH-MATIC the closest available language to its own proposal.In contrast to Backus' FORTRAN, MATH-MATIC did not emphasise execution speed of compiled programs. The UNIVAC machines did not have floating-point hardware, and MATH-MATIC was translated via A-3 (ARITH-MATIC) pseudo-assembler code rather than directly to UNIVAC machine code, limiting its usefulness.

MATH-MATIC Sample program
A sample MATH-MATIC program:
(2)  TYPE-IN ALPHA . 
(2A) READ A B C SERVO 4 STORAGE A IF SENTINEL JUMP TO SENTENCE 8 . 
(3)  READ D F SERVO 5 . 
(4)  VARY Y 1 (0.1) 3 SENTENCE 5 THRU 6 . 
(5)  X1 = (7*103*Y*A*SIN ALPHA)3 / (B POW D+C POW E) . 
(6)  WRITE AND EDIT A Y D E X1 SERVO 6 . 
(7)  JUMP TO SENTENCE 2A . 
(8)  CLOSE-INPUT AND REWIND SENTENCE 3 . 
(9)  CLOSE-OUTPUT SENTENCE 6 . 
(10) READ F G H N SERVO 4 STORAGE A IF SENTINEL JUMP TO SENTENCE 20 . 
(11) EXECUTE SENTENCE 3 . 
(12) X2 = (3 ROOT (E-G)+LOG (D+N)) / (F2.6*EXP H) . 
(13) WRITE EDIT F D F X2 SERVO 6 . 
(16) JUMP TO SENTENCE 10 . 
(20) STOP .

Notes
References
Ash, R.; Broadwin, E.; Della Valle, V.; Greene, M.; Jenny, A.; Katz, C.; Yu, L. (1957-04-19). Preliminary Manual for MATH-MATIC and ARITH-MATIC Systems for Algebraic Translation and Compilation for UNIVAC I and II (PDF) (Technical report). Philadelphia: Remington Rand Univac. Archived from the original (PDF) on 2014-12-26. Retrieved 2016-03-19.Bemer, Robert W. (1969), A Politico-Social History of Algol (With a Chronology in the Form of a Log Book) (PDF), retrieved 2016-03-20Knuth, Donald; Trabb Pardo, Luis (August 1976). The Early Development of Programming Languages (Technical report). Computer Science Department, School of Humanities and Sciences, Stanford University. Retrieved 2016-03-19.Sammet, Jean (1969). Programming Languages: History and Fundamentals. Prentice-Hall. pp. 132, 135–137. ISBN 978-0-13-729988-1.Univac MATH-MATIC Programming System (PDF) (Technical report). Remington Rand Univac. 1958. Retrieved 2016-03-19.""MATH-MATIC — Mathematically oriented autocode (Computer Language)"". Online Historical Encyclopaedia of Programming Languages. Archived from the original on 2016-04-02. Retrieved 2016-03-20.""UNICODE — UNIVAC hybrid of FORTRAN and MATH-MATIC"". Online Historical Encyclopaedia of Programming Languages. Archived from the original on 2016-04-03. Retrieved 2016-03-20.",202110,https://en.wikipedia.org/wiki/MATH-MATIC
Mercury (RemObjects BASIC programming language),"Mercury (promoted as Modern Visual Basic) is a programming language developed by RemObjects Software. RemObjects extends VB.Net underlying language and plans to add more features to it.Mercury is a commercial product and is the sixth language supported by  RemObjects Elements Compiler toolchain, next to C#, Swift, Java, Go and Oxygene. It integrates with Microsoft's Visual Studio on Windows, as well as  RemObjects Elements IDE called Water on Windows and Fire on macOS.  


== References ==","Mercury (promoted as Modern Visual Basic) is a programming language developed by RemObjects Software. RemObjects extends VB.Net underlying language and plans to add more features to it.Mercury is a commercial product and is the sixth language supported by  RemObjects Elements Compiler toolchain, next to C#, Swift, Java, Go and Oxygene. It integrates with Microsoft's Visual Studio on Windows, as well as  RemObjects Elements IDE called Water on Windows and Fire on macOS.  


== References ==",70564140,https://en.wikipedia.org/wiki/Mercury_(RemObjects_BASIC_programming_language)
MiniKanren,"miniKanren is a family of programming languages for relational programming. As relations are bidirectional, if miniKanren is given an expression and a desired output, miniKanren can run the expression ""backward"", finding all possible inputs to the expression that produce the desired output. This bidirectional behavior allows the user to constrain both the input to the program and the result of the program simultaneously. miniKanren performs an interleaved search which will eventually find any solution that exists, even if any one branch of the search tree is infinitely long and contains no solutions. If no solution exists, miniKanren may search forever if the search tree is infinite.
An example of miniKanren code is evalo, a relational goal that relates expressions to the values that they evaluate to. When evalo is called in miniKanren like so: (evalo q q), it will generate quines, that is, expressions q that when run will evaluate to themselves.The book The Reasoned Schemer uses miniKanren to demonstrate relational programming, and provides a complete implementation in Scheme. The core of the language fits on two printed pages. The Scheme implementation of miniKanren is designed to be easily understood, modified, and extended.
αleanTAP is a program written in αKanren, an extension of miniKanren for nominal logic. Given a theorem, it can find a proof, making it a theorem-prover. Given a proof, it can find the theorem, making it a theorem-checker. Given part of a proof and part of a theorem, it will fill in the missing parts of the proof and the theorem, making it a theorem-explorer.There are implementations of miniKanren in Haskell, Racket, Ruby, Clojure, JavaScript, Scala, Swift, Dart and Python. The canonical implementation is an embedded language in Scheme. The Clojure core.logic library was inspired by miniKanren.
The name kanren comes from a Japanese word (関連) meaning ""relation"".","miniKanren is a family of programming languages for relational programming. As relations are bidirectional, if miniKanren is given an expression and a desired output, miniKanren can run the expression ""backward"", finding all possible inputs to the expression that produce the desired output. This bidirectional behavior allows the user to constrain both the input to the program and the result of the program simultaneously. miniKanren performs an interleaved search which will eventually find any solution that exists, even if any one branch of the search tree is infinitely long and contains no solutions. If no solution exists, miniKanren may search forever if the search tree is infinite.
An example of miniKanren code is evalo, a relational goal that relates expressions to the values that they evaluate to. When evalo is called in miniKanren like so: (evalo q q), it will generate quines, that is, expressions q that when run will evaluate to themselves.The book The Reasoned Schemer uses miniKanren to demonstrate relational programming, and provides a complete implementation in Scheme. The core of the language fits on two printed pages. The Scheme implementation of miniKanren is designed to be easily understood, modified, and extended.
αleanTAP is a program written in αKanren, an extension of miniKanren for nominal logic. Given a theorem, it can find a proof, making it a theorem-prover. Given a proof, it can find the theorem, making it a theorem-checker. Given part of a proof and part of a theorem, it will fill in the missing parts of the proof and the theorem, making it a theorem-explorer.There are implementations of miniKanren in Haskell, Racket, Ruby, Clojure, JavaScript, Scala, Swift, Dart and Python. The canonical implementation is an embedded language in Scheme. The Clojure core.logic library was inspired by miniKanren.
The name kanren comes from a Japanese word (関連) meaning ""relation"".

See also
Logic programming
Tree traversal

References
External links
Official website
Dart implementation",39116526,https://en.wikipedia.org/wiki/MiniKanren
Mocklisp,"Gosling Emacs (often shortened to ""Gosmacs"" or ""gmacs"") is a discontinued Emacs implementation written in 1981 by James Gosling in C.Gosling initially allowed Gosling Emacs to be redistributed with no formal restrictions, as required by the ""Emacs commune"" since the 1970s,  only asking for a letter acknowledging his authorship. Later, wishing to move on, he sold his version of Emacs to UniPress. The dispute between Richard Stallman and UniPress inspired the creation of the first formal license for Emacs, which later became the GPL, as Congress had introduced copyright for software in 1980.","Gosling Emacs (often shortened to ""Gosmacs"" or ""gmacs"") is a discontinued Emacs implementation written in 1981 by James Gosling in C.Gosling initially allowed Gosling Emacs to be redistributed with no formal restrictions, as required by the ""Emacs commune"" since the 1970s,  only asking for a letter acknowledging his authorship. Later, wishing to move on, he sold his version of Emacs to UniPress. The dispute between Richard Stallman and UniPress inspired the creation of the first formal license for Emacs, which later became the GPL, as Congress had introduced copyright for software in 1980.

Features
Gosling Emacs was especially noteworthy because of the effective redisplay code, which used a dynamic programming technique to solve the classical string-to-string correction problem. The algorithm was quite sophisticated; that section of the source was headed by a skull-and-crossbones in ASCII art, warning any would-be improver that even if they thought they understood how the display code worked, they probably did not.

Distribution
Since Gosling had permitted its unrestricted redistribution, Richard Stallman used some Gosling Emacs code in the initial version of GNU Emacs. Among other things, he rewrote part of the Gosling code headed by the skull-and-crossbones comment and made it ""...shorter, faster, clearer and more extensible.""In 1983 UniPress began selling Gosling Emacs on Unix for $395 and on VMS for $2,500, marketing it as ""EMACS–multi-window text editor (Gosling version)"".Controversially, Unipress asked Stallman to stop distributing his version of Emacs for Unix.
UniPress never took legal action against Stallman or his nascent Free Software Foundation, believing ""hobbyists and academics could never produce an Emacs that could compete"" with their product. All Gosling Emacs code was removed from GNU Emacs by version 16.56 (July 1985), with the possible exception of a few particularly involved sections of the display code. The latest versions of GNU Emacs (since August 2004) do not feature the skull-and-crossbones warning.

Extension language
Its extension language, Mocklisp, has a syntax that appears similar to Lisp, but Mocklisp does not have lists, only strings and arrays. The Mocklisp interpreter, built by Gosling and a collaborator, was replaced by a full Lisp interpreter in GNU Emacs.

References

Christopher Kelty, ""EMACS, grep, and UNIX: authorship, invention and translation in software"", https://web.archive.org/web/20110728022656/http://www.burlingtontelecom.net/~ashawley/gnu/emacs/ConText-Kelty.pdf",59666,https://en.wikipedia.org/wiki/Gosling_Emacs
Mojo (programming language),"Mojo is a proprietary programming language that is currently under development. It is available both in browsers via Jupyter notebooks, and locally on both Linux and macOS.","Mojo is a proprietary programming language that is currently under development. It is available both in browsers via Jupyter notebooks, and locally on both Linux and macOS.

See also
List of programming languages for artificial intelligence
Python
Nim
Ring
Carbon
Zig
Julia
Rust

References
External links
Official website
Mojo manual
mojo on GitHub
All about mojo programming language
Introduction to Mojo programming language
Mojo may be the biggest programming language advance in decades
Mojo: The Future of AI Programming",73729965,https://en.wikipedia.org/wiki/Mojo_(programming_language)
Multi-adjoint logic programming,"Multi-adjoint logic programming defines syntax and semantics of a logic programming program in such a way that the underlying maths justifying the results are a residuated lattice and/or MV-algebra.
The definition of a multi-adjoint logic program is given, as usual in fuzzy logic programming, as a set of weighted rules and facts of a given formal language F. Notice that we are allowed to use different implications in our rules.
Definition: A multi-adjoint logic program is a set P of rules of the form <(A ←i B), δ> such that:
1. The rule (A ←i B) is a formula of F;
2. The confidence factor δ is an element (a truth-value) of L;
3. The head A is an atom;
4. The body B is a formula built from atoms B1, …, Bn (n ≥ 0) by the use of conjunctors, disjunctors, and aggregators.
5. Facts are rules with body ┬.
6. A query (or goal) is an atom intended as a question ?A prompting the system.","Multi-adjoint logic programming defines syntax and semantics of a logic programming program in such a way that the underlying maths justifying the results are a residuated lattice and/or MV-algebra.
The definition of a multi-adjoint logic program is given, as usual in fuzzy logic programming, as a set of weighted rules and facts of a given formal language F. Notice that we are allowed to use different implications in our rules.
Definition: A multi-adjoint logic program is a set P of rules of the form <(A ←i B), δ> such that:
1. The rule (A ←i B) is a formula of F;
2. The confidence factor δ is an element (a truth-value) of L;
3. The head A is an atom;
4. The body B is a formula built from atoms B1, …, Bn (n ≥ 0) by the use of conjunctors, disjunctors, and aggregators.
5. Facts are rules with body ┬.
6. A query (or goal) is an atom intended as a question ?A prompting the system.

Implementations
Implementations of Multi-adjoint logic programming:
Rfuzzy,
Floper, 
and more we do not remember now.


== References ==",2099529,https://en.wikipedia.org/wiki/Multi-adjoint_logic_programming
Nemerle,"Nemerle is a general-purpose, high-level, statically typed programming language designed for platforms using the Common Language Infrastructure (.NET/Mono). It offers functional, object-oriented, aspect-oriented, reflective and imperative features. It has a simple C#-like syntax and a powerful metaprogramming system. 
In June 2012, the core developers of Nemerle were hired by the Czech software development company JetBrains. The team was focusing on developing Nitra, a framework to implement extant and new programming languages. Both the Nemerle language and Nitra have seemingly been abandoned or discontinued by JetBrains; Nitra has not been updated by its original creators since 2017 and Nemerle is now maintained entirely by the Russian Software Development Network, independently from JetBrains, although no major updates have been released yet and development is progressing very slowly. Neither Nemerle, nor Nitra have been mentioned or referenced by JetBrains for years.
Nemerle is named after the Archmage Nemmerle, a character in the fantasy novel A Wizard of Earthsea by Ursula K. Le Guin.","Nemerle is a general-purpose, high-level, statically typed programming language designed for platforms using the Common Language Infrastructure (.NET/Mono). It offers functional, object-oriented, aspect-oriented, reflective and imperative features. It has a simple C#-like syntax and a powerful metaprogramming system. 
In June 2012, the core developers of Nemerle were hired by the Czech software development company JetBrains. The team was focusing on developing Nitra, a framework to implement extant and new programming languages. Both the Nemerle language and Nitra have seemingly been abandoned or discontinued by JetBrains; Nitra has not been updated by its original creators since 2017 and Nemerle is now maintained entirely by the Russian Software Development Network, independently from JetBrains, although no major updates have been released yet and development is progressing very slowly. Neither Nemerle, nor Nitra have been mentioned or referenced by JetBrains for years.
Nemerle is named after the Archmage Nemmerle, a character in the fantasy novel A Wizard of Earthsea by Ursula K. Le Guin.

Features
Nemerle's most notable feature is the ability to mix styles of programming that are object-oriented and functional. Programs may be structured using object-oriented concepts such as classes and namespaces, while methods can (optionally) be written in a functional style. Other notable features include:

strong type inference
a flexible metaprogramming subsystem (using macros)
full support for object-oriented programming (OOP), in the style of C#, Java, and C++
full support for functional programming, in the style of ML, OCaml, and Haskell, with these features:
higher-order functions
pattern matching
algebraic types
local functions
tuples and anonymous types
partial application of functionsThe metaprogramming system allows for great compiler extensibility, embedding domain-specific languages, partial evaluation, and aspect-oriented programming, taking a high-level approach to lift as much of the burden as possible from programmers. The language combines all Common Language Infrastructure (CLI) standard features, including parametric polymorphism, lambdas, extension methods etc. Accessing the libraries included in the .NET or Mono platforms is as easy as in C#.

Type inference
Everything is an expression
Tuples
Pattern matching
Functional types and local functions
Variants
Variants (called data types or sum types in SML and OCaml) are forms of expressing data of several different kinds:

Metaprogramming
Nemerle's macro system allows for creating, analysing, and modifying program code during compiling. Macros can be used in the form of a method call or as a new language construct. Many constructs within the language are implemented using macros (if, for, foreach, while, using etc.).
""if"" macro example:

Braceless syntax
Similarly to the braceless syntax later added to Scala, Nemerle allows the programmer to optionally use a whitespace-sensitive syntax based on the off-side rule, similarly to Python. 
The following curly-brace snippet:

could be rewritten as:

Notably, it is not possible to break expressions or alternative clauses in matches over multiple lines without using a backslash \:

In order to activate this syntax, the user must add #pragma indent to the top of the file or use the compiler option -i.

IDE
Nemerle can be integrated into the integrated development environment (IDE) Visual Studio 2008. It also has a fully free IDE based on Visual Studio 2008 Shell (like Visual Studio Express Editions) and SharpDevelop (link to plugin source code).
Nemerle can be also integrated into Visual Studio (up until 2017) using add-ins and extensions.

Examples
Hello, World!
The traditional Hello World! can be implemented in a more C#-like fashion:

or more simply:

Examples of macros
Macros allow generating boilerplate code with added static checks performed by the compiler. They reduce the amount of code that must be written by hand, make code generation safer, and allow programs to generate code with compiler checks, while keeping source code relatively small and readable.

String formatting
The string formatting macro simplifies variables to string manipulations using $ notation:

Declarative code generation
StructuralEquality, Memoize, json, and with are macros which generate code in compile time. Though some of them (StructuralEquality, Memoize) can look like C# attributes, during compiling, they will be examined by the compiler and transformed to appropriate code using logic predefined by their macros.

Database accessibility
Using Nemerle macros for SQL you can write:

instead of

and this is not just hiding some operations in a library, but additional work performed by the compiler to understand the query string, the variables used there, and the columns returned from the database. The ExecuteReaderLoop macro will generate code roughly equivalent to what you would have to type manually. Moreover, it connects to the database at compilation time to check that your SQL query really makes sense.

New language constructs
With Nemerle macros you can also introduce some new syntax into the language:

defines a macro introducing the ford (EXPR ; EXPR) EXPR syntax and can be used like

ford (i ; n) print (i);

Nemerle with ASP.NET
Nemerle can be either embedded directly into ASP.NET:

...Or stored in a separate file and entered with a single line:

PInvoke
Nemerle can take advantage of native platform libraries. The syntax is very similar to C#'s and other .NET languages. Here is the simplest example:

References
Further reading
Publications about Nemerle in RSDN Magazine, Russian official science magazine
Moskal, Michał (27 June 2005). ""Type Inference with Deferral"" (PDF). Institute of Computer Science, University of Wrocław. {{cite journal}}: Cite journal requires |journal= (help)
Presentation ""Nemerle is notable"" by Denis Rystsov
Article ""Unconventional languages for unconventional supercomputers"" by Andrey Adinetz

External links
Official website
GitHub project and repository (new development)
Google Code project and repository (old development)
Nemerle Forum
Nemerle presentation on Microsoft Research SSCLI RFP II Capstone 2005 workshop
Nemerle at 99 Bottles of Beer",30883042,https://en.wikipedia.org/wiki/Nemerle
Nim (programming language),"Nim is a general-purpose, multi-paradigm, statically typed, compiled high-level systems programming language, designed and developed by a team around Andreas Rumpf. Nim is designed to be ""efficient, expressive, and elegant"", supporting metaprogramming, functional, message passing, procedural, and object-oriented programming styles by providing several features such as compile time code generation, algebraic data types, a foreign function interface (FFI) with C, C++, Objective-C, and JavaScript, and supporting compiling to those same languages as intermediate representations.","Nim is a general-purpose, multi-paradigm, statically typed, compiled high-level systems programming language, designed and developed by a team around Andreas Rumpf. Nim is designed to be ""efficient, expressive, and elegant"", supporting metaprogramming, functional, message passing, procedural, and object-oriented programming styles by providing several features such as compile time code generation, algebraic data types, a foreign function interface (FFI) with C, C++, Objective-C, and JavaScript, and supporting compiling to those same languages as intermediate representations.

Description
Nim is statically typed. It supports compile-time metaprogramming features such as syntactic macros and term rewriting macros. Term rewriting macros enable library implementations of common data structures, such as bignums and matrices, to be implemented efficiently and with syntactic integration, as if they were built-in language facilities. Iterators are supported and can be used as first class entities, as can functions, allowing for the use of functional programming methods. Object-oriented programming is supported by inheritance and multiple dispatch. Functions can be generic and overloaded, and generics are further enhanced by Nim's support for type classes. Operator overloading is also supported. Nim includes multiple tunable memory management strategies, including tracing garbage collection, reference counting, and fully manual systems, with the default being deterministic reference counting with optimizations via move semantics and cycle collection via trial deletion.[Nim] ... presents a most original design that straddles Pascal and Python and compiles to C code or JavaScript.
As of August 2023, Nim compiles to C, C++, JavaScript, Objective-C, and LLVM.

History
Nim's initial development was started in 2005 by Andreas Rumpf. It was originally named Nimrod when the project was made public in 2008.: 4–11 The first version of the Nim compiler was written in Pascal using the Free Pascal compiler. In 2008, a version of the compiler written in Nim was released. The compiler is free and open-source software, and is being developed by a community of volunteers working with Andreas Rumpf. The language was officially renamed from Nimrod to Nim with the release of version 0.10.2 in December 2014. On September 23, 2019, version 1.0 of Nim was released, signifying the maturing of the language and its toolchain. On August 1st, 2023, version 2.0 of Nim was released, signifying the completion, stabilization of, and switch to the ARC/ORC memory model.

Language design
Syntax
The syntax of Nim resembles that of Python. Code blocks and nesting statements are identified through use of whitespace, according to the offside-rule. Many keywords are identical to their Python equivalents, which are mostly English keywords, whereas other programming languages usually use punctuation. With the goal of improving upon its influence languages, even though Nim supports indentation-based syntax like Python, it introduced additional flexibility. For example, a single statement may span multiple lines if a comma or binary operator is at the end of each line. Nim also supports user-defined operators.
Unlike Python, Nim implements (native) static typing. Nim's type system allows for easy type conversion, casting, and provides syntax for generic programming. Nim notably provides type classes which can stand in for multiple types, and provides several such type classes 'out of the box'. Type classes allow working with several types as if they were a single type. For example:

openarray – Represents arrays of different sizes, sequences, and strings
SomeSignedInt – Represents all the signed integer types
SomeInteger – Represents all the Integer types, signed or not
SomeOrdinal – Represents all the basic countable and ordered types, except of non integer number
This code sample demonstrates the use of typeclasses in Nim

Influence
According to the language creator, Nim was conceived to combine the best parts of Ada typing system, Python flexibility, and powerful Lisp macro system.Nim was influenced by specific characteristics of existing languages, including the following:

Modula-3: traced vs untraced pointers
Object Pascal: type safe bit sets (set of char), case statement syntax, various type names and filenames in the standard library
Ada: subrange types, distinct type, safe variants – case objects
C++: operator overloading, generic programming
Python: Off-side rule
Lisp: Macro system, AST manipulation, homoiconicity
Oberon: export marker
C#: async/await, lambda macros
ParaSail: pointer-free programming

Uniform Function Call Syntax
Nim supports Uniform Function Call Syntax (UFCS) and identifier equality, which provides a large degree of flexibility in use.
For example, each of these lines print ""hello world"", just with different syntax:

Identifier equality
Nim is almost fully style-insensitive; two identifiers are considered equal if they only differ by capitalization and underscores, as long as the first characters are identical. This is to enable a mixture of styles across libraries: one user can write a library using snake_case as a convention, and it can be used by a different user in a camelCase style without issue.

Stropping
The stropping feature allows the use of any name for variables or functions, even when the names are reserved words for keywords. An example of stropping is the ability to define a variable named if, without clashing with the keyword if. Nim's implementation of this is achieved via backticks, allowing any reserved word to be used as an identifier.

Compiler
The Nim compiler emits fast, optimized C code by default. It defers compiling-to-object code to an external C compiler to leverage existing compiler optimization and portability. Many C compilers are supported, including Clang, Microsoft Visual C++ (MSVC), MinGW, and GNU Compiler Collection (GCC). The Nim compiler can also emit C++, Objective-C, and JavaScript code to allow easy interfacing with application programming interfaces (APIs) written in those languages; developers can simply write in Nim, then compile to any supported language. This also allows writing applications for iOS and Android. There is also an unofficial LLVM backend, allowing use of the Nim compiler in a stand-alone way.The Nim compiler is self-hosting, meaning it is written in the Nim language. The compiler supports cross-compiling, so it is able to compile software for any of the supported operating systems, no matter the development machine. This is useful for compiling applications for embedded systems, and for uncommon and obscure computer architectures.

Compiler options
By default, the Nim compiler creates a debug build. 
With the option -d:release a release build can be created, which is optimized for speed and contains fewer runtime checks. 
With the option -d:danger all runtime checks can be disabled, if maximum speed is desired.

Memory management
Nim supports multiple memory management strategies, including the following:
--gc:refc – Standard deferred reference counting based garbage collector with a simple mark-and-sweep backup GC in order to collect cycles. Heaps are thread-local.
--gc:markAndSweep – Simple mark-and-sweep based garbage collector. Heaps are thread-local.
--gc:boehm – Boehm based garbage collector, it offers a shared heap.
--gc:go – Go's garbage collector, useful for interoperability with Go. Offers a shared heap.
--gc:arc – Automatic reference counting (ARC) with move semantics optimizations, offers a shared heap. It offers fully deterministic performance for hard realtime systems. Reference cycles may cause memory leaks: these may be dealt with by manually annotating {.acyclic.} pragmas or by using --gc:orc.
--gc:orc – Same as --gc:arc but adds a cycle collector (the ""O"") based on ""trial deletion"". The cycle collector only analyzes types if they are potentially cyclic.
--gc:none – No memory management strategy nor a garbage collector. Allocated memory is simply never freed, unless manually freed by the developer's code.As of Nim 2.0, ORC is the default GC.

Development tools
Bundled
Many tools are bundled with the Nim install package, including:

Nimble
Nimble is the standard package manager used by Nim to package Nim modules. It was initially developed by Dominik Picheta, who is also a core Nim developer. Nimble has been included as Nim's official package manager since Oct 27, 2015, the v0.12.0 release.Nimble packages are defined by .nimble files, which contain information about the package version, author, license, description, dependencies, and more.: 132  These files support a limited subset of the Nim syntax called NimScript, with the main limitation being the access to the FFI. These scripts allow changing of test procedure, or for custom tasks to be written.
The list of packages is stored in a JavaScript Object Notation (JSON) file which is freely accessible in the nim-lang/packages repository on GitHub. This JSON file provides Nimble with a mapping between the names of packages and their Git or Mercurial repository URLs.
Nimble comes with the Nim compiler. Thus, it is possible to test the Nimble environment by running:
nimble -v.
This command will reveal the version number, compiling date and time, and Git hash of nimble. Nimble uses the Git package, which must be available for Nimble to function properly. The Nimble command-line is used as an interface for installing, removing (uninstalling), and upgrading–patching module packages.: 130–131

c2nim
c2nim is a source-to-source compiler (transcompiler or transpiler) meant to be used on C/C++ headers to help generate new Nim bindings. The output is human-readable Nim code that is meant to be edited by hand after the translation process.

koch
koch is a maintenance script that is used to build Nim, and provide HTML documentation.

nimgrep
nimgrep is a generic tool for manipulating text. It is used to search for regex, peg patterns, and contents of directories, and it can be used to replace tasks. It is included to assist with searching Nim's style-insensitive identifiers.

nimsuggest
nimsuggest is a tool that helps any source code editor query a .nim source file to obtain useful information like definition of symbols or suggestions for completions.

niminst
niminst is a tool to generate an installer for a Nim program. 
It creates .msi installers for Windows via Inno Setup, and install and uninstall scripts for Linux, macOS, and Berkeley Software Distribution (BSD).

nimpretty
nimpretty is a source code beautifier, used to format code according to the official Nim style guide.

Testament
Testament is an advanced automatic unit tests runner for Nim tests. Used in developing Nim, it offers process isolation tests, generates statistics about test cases, supports multiple targets and simulated Dry-Runs, has logging, can generate HTML reports, can skip tests from a file, and more.

Other notable tools
Some notable tools not included in the Nim distribution include:

choosenim
choosenim was developed by Dominik Picheta, creator of the Nimble package manager, as a tool to enable installing and using multiple versions of the Nim compiler. It downloads any Nim stable or development compiler version from the command line, enabling easy switching between them.

nimpy
nimpy is a library that enables convenient Python integration in Nim programs.

pixie
pixie is a feature-rich 2D graphics library, similar to Cairo or the Skia. It uses SIMD acceleration to speed-up image manipulation drastically. It supports many image formats, blending, masking, blurring, and can be combined with the boxy library to do hardware accelerated rendering.

nimterop
nimterop is a tool focused on automating the creation of C/C++ wrappers needed for Nim's foreign function interface.

Libraries
Pure/impure libraries
Pure libraries are modules written in Nim only. They include no wrappers to access libraries written in other programming languages.
Impure libraries are modules of Nim code which depend on external libraries that are written in other programming languages such as C.

Standard library
The Nim standard library includes modules for all basic tasks, including:
System and core modules
Collections and algorithms
String handling
Time handling
Generic Operating System Services
Math libraries
Internet Protocols and Support
Threading
Parsers
Docutils
XML Processing
XML and HTML code generator
Hashing
Database support (PostgreSQL, MySQL and SQLite)
Wrappers (Win32 API, POSIX)

Use of other libraries
A Nim program can use any library which can be used in a C, C++, or JavaScript program. Language bindings exist for many libraries, including GTK, Qt QML, wxWidgets, SDL 2, Cairo, OpenGL, WinAPI, zlib, libzip, OpenSSL, Vulkan and cURL. Nim works with PostgreSQL, MySQL, and SQLite databases.
There are open source tools of various degree of support that can be used to interface Nim with Lua, Julia, Rust,C#,
and Python programming languages or transpile Nim to TypeScript.

Examples
Hello world
The ""Hello, World!"" program in Nim:

Another version of ""Hello World"" can be accomplished by calling the write function with the stdout stream:

Fibonacci
Several implementations of the Fibonacci function, showcasing implicit returns, default parameters, iterators, recursion, and while loops:

Factorial
Program to calculate the factorial of a positive integer using the iterative approach, showcasing try/catch error handling and for loops:Using the module math from Nim's standard library:

Reversing a string
A simple demonstration showing the implicit result variable and the use of iterators.

One of Nim's more exotic features is the implicit result variable. Every procedure in Nim with a non-void return type has an implicit result variable that represents the value to be returned. In the for loop we see an invocation of countdown which is an iterator. If an iterator is omitted, the compiler will attempt to use an items iterator, if one is defined for the type specified.

Graphical user interface
Using GTK 3 with GObject introspection through the gintro module:

This code requires the gintro module to work, which is not part of the standard library. To install the module gintro and many others you can use the tool nimble, which comes as part of Nim. To install the gintro module with nimble you do the following:
nimble install gintro

Programming paradigms
Functional programming
Functional programming is supported in Nim through first-class functions and code without side effects via the noSideEffect pragma or the func keyword. Nim will perform side effect analysis and raise compilation errors for code that does not obey the contract of producing no side effects when compiled with the experimental feature strictFuncs, planned to become the default in later versions.Contrary to purely functional programming languages, Nim is a multi-paradigm programming language, so functional programming restrictions are opt-in on a function-by-function basis.

First-class functions
Nim supports first-class functions by allowing functions to be stored in variables or passed anonymously as parameters to be invoked by other functions. The std/sugar module provides syntactic sugar for anonymous functions in type declarations and instantiation.

Side effects
Side effects of functions annotated with the noSideEffect pragma are checked, and the compiler will refuse to compile functions failing to meet those. Side effects in Nim include mutation, global state access or modification, asynchronous code, threaded code, and IO. Mutation of parameters may occur for functions taking parameters of var or ref type: this is expected to fail to compile with the currently-experimental strictFuncs in the future. The func keyword introduces a shortcut for a noSideEffect pragma.

Function composition
Uniform function call syntax allows for the chaining of arbitrary functions, perhaps best exemplified with the std/sequtils library.

Algebraic data types and pattern matching
Nim has support for product types via the object type, and for sum types via object variants: raw representations of tagged unions, with an enumerated type tag that must be safely matched upon before fields of variants can be accessed. These types can be composed algebraically. Structural pattern matching is available, but regulated to macros in various third-party libraries.

Object-oriented programming
Despite being primarily an imperative and functional language, Nim supports various features for enabling object-oriented paradigms.

Subtyping and inheritance
Nim supports limited inheritance by use of ref objects and the of keyword. To enable inheritance, any initial (""root"") object must inherit from RootObj. Inheritance is of limited use within idiomatic Nim code: with the notable exception of Exceptions.Subtyping relations can also be queried with the of keyword.

Method calls and encapsulation
Nim's uniform function call syntax enables calling ordinary functions with syntax similar to method call invocations in other programming languages. This is functional for ""getters"": and Nim also provides syntax for the creation of such ""setters"" as well. Objects may be made public on a per-field basis, providing for encapsulation.

Dynamic dispatch
Static dispatch is preferred, more performant, and standard even among method-looking routines. Nonetheless, if dynamic dispatch is so desired, Nim provides the method keyword for enabling dynamic dispatch on reference types.

Metaprogramming
Templates
Nim supports simple substitution on the abstract syntax tree via its templates.

The genType is invoked at compile-time and a Test type is created.

Generics
Nim supports both constrained and unconstrained generic programming.
Generics may be used in procedures, templates and macros. Unconstrained generic identifiers (T in this example) are defined after the routine's name in square brackets. Constrained generics can be placed on generic identifiers, or directly on parameters. 

One can further clarify which types the procedure will accept by specifying a type class (in the example above, SomeSignedInt).

Macros
Macros can rewrite parts of the code at compile-time. Nim macros are powerful and can operate on the abstract syntax tree before or after semantic checking.
Here's a simple example that creates a macro to call code twice:
The twice macro in this example takes the echo statement in the form of an abstract syntax tree as input. In this example we decided to return this syntax tree without any manipulations applied to it. But we do it twice, hence the name of the macro. The result is that the code gets rewritten by the macro to look like the following code at compile time:

Foreign function interface (FFI)
Nim's FFI is used to call functions written in the other programming languages that it can compile to. This means that libraries written in C, C++, Objective-C, and JavaScript can be used in the Nim source code. One should be aware that both JavaScript and C, C++, or Objective-C libraries cannot be combined in the same program, as they are not as compatible with JavaScript as they are with each other. Both C++ and Objective-C are based on and compatible with C, but JavaScript is incompatible, as a dynamic, client-side web-based language.: 226 The following program shows the ease with which external C code can be used directly in Nim.

In this code the printf function is imported into Nim and then used.
Basic example using 'console.log' directly for the JavaScript compilation target:

The JavaScript code produced by the Nim compiler can be executed with Node.js or a web browser.

Parallelism
To activate threading support in Nim, a program should be compiled with --threads:on command line argument. Each thread has a separate garbage collected heap and sharing of memory is restricted, which helps with efficiency and stops race conditions by the threads.Nim also has a channels module that simplifies passing data between threads.

Concurrency
Asynchronous IO is supported either via the asyncdispatch module in the standard library or the external chronos library. Both libraries add async/await syntax via the macro system, without need for special language support. An example of an asynchronous HTTP server:

Community
Online
Nim has an active community on the self-hosted, self-developed official forum. Further, the project uses a Git repository, bug tracker, RFC tracker, and wiki hosted by GitHub, where the community engages with the language. There are also official online chat rooms, bridged between IRC, Matrix, Discord, Gitter, and Telegram.

Conventions
The first Nim conference, NimConf, took place on June 20, 2020. It was held digitally due to COVID-19, with an open call for contributor talks in the form of YouTube videos. The conference began with language overviews by Nim developers Andreas Rumpf and Dominik Picheta. Presentation topics included talks about web frameworks, mobile development, Internet of things (IoT) devices, and game development, including a talk about writing Nim for Game Boy Advance. NimConf 2020 is available as a YouTube playlist. NimConf 2021 occurred the following year, was also held digitally, and included talks about game development, REPLs, real-time operating systems, Nim in the industry, object-relational mapping (ORM), language design, and graphics libraries.In addition to official conferences, Nim has been featured at various other conventions. A presentation on Nim was given at the O'Reilly Open Source Convention (OSCON) in 2015. Four speakers represented Nim at FOSDEM 2020, including the creator of the language, Andreas Rumpf. At FOSDEM 2022, Nim hosted their own developer room virtually due to the COVID-19 pandemic. Talks were held on concurrency, embedded programming, programming for GPUs, entity-component systems, game development, rules engines, Python interop, and metaprogramming.

See also
C (programming language)
C++ (programming language)
Crystal (programming language)
D (programming language)
Go (programming language)
Rust (programming language)
Fat pointer

References
External links
Official website 
Nim on GitHub
Information about Nim on Stack Overflow
Computer Programming with the Nim Programming Language  A gentle Introduction by Stefan Salewski",45413679,https://en.wikipedia.org/wiki/Nim_(programming_language)
OpenQASM,"Open Quantum Assembly Language (OpenQASM; pronounced open kazm) is a programming language designed for describing quantum circuits and algorithms for execution on quantum computers. It is designed to be an intermediate representation that can be used by higher-level compilers to communicate with quantum hardware, and allows for the description of a wide range of quantum operations, as well as classical feed-forward flow control based on measurement outcomes.
The language includes a mechanism for describing explicit timing of instructions, and allows for the attachment of low-level definitions to gates for tasks such as calibration. OpenQASM is not intended for general-purpose classical computation, and hardware implementations of the language may not support the full range of data manipulation described in the specification. Compilers for OpenQASM are expected to support a wide range of classical operations for compile-time constants, but the support for these operations on runtime values may vary between implementations.The language was first described in a paper published in July 2017, and a reference source code implementation was released as part of IBM's Quantum Information Software Kit (Qiskit) for use with their IBM Quantum Experience cloud quantum computing platform. The language has similar qualities to traditional hardware description languages such as Verilog.

OpenQASM defines its version at the head of a source file as a number, as in the declaration: 
The level of OpenQASM's original published implementations is OpenQASM 2.0. Version 3.0 of the specification is the current one and can be viewed at the OpenQASM repository on GitHub.","Open Quantum Assembly Language (OpenQASM; pronounced open kazm) is a programming language designed for describing quantum circuits and algorithms for execution on quantum computers. It is designed to be an intermediate representation that can be used by higher-level compilers to communicate with quantum hardware, and allows for the description of a wide range of quantum operations, as well as classical feed-forward flow control based on measurement outcomes.
The language includes a mechanism for describing explicit timing of instructions, and allows for the attachment of low-level definitions to gates for tasks such as calibration. OpenQASM is not intended for general-purpose classical computation, and hardware implementations of the language may not support the full range of data manipulation described in the specification. Compilers for OpenQASM are expected to support a wide range of classical operations for compile-time constants, but the support for these operations on runtime values may vary between implementations.The language was first described in a paper published in July 2017, and a reference source code implementation was released as part of IBM's Quantum Information Software Kit (Qiskit) for use with their IBM Quantum Experience cloud quantum computing platform. The language has similar qualities to traditional hardware description languages such as Verilog.

OpenQASM defines its version at the head of a source file as a number, as in the declaration: 
The level of OpenQASM's original published implementations is OpenQASM 2.0. Version 3.0 of the specification is the current one and can be viewed at the OpenQASM repository on GitHub.

Examples
The following is an example of OpenQASM source code from the official library. The program adds two four-bit numbers.

References
External links
Official website
openqasm on GitHub",55836870,https://en.wikipedia.org/wiki/OpenQASM
Pencil Code (programming language),"Pencil Code is an educational programming language and website.  It allows programming using either Scratch-style block coding, or CoffeeScript.  Code runs directly in the web browser and can be shared with others.  The language centers on a model of a pencil programmatically drawing on a 2-dimensional screen, with the pencil cursor depicted visually as a turtle.","Pencil Code is an educational programming language and website.  It allows programming using either Scratch-style block coding, or CoffeeScript.  Code runs directly in the web browser and can be shared with others.  The language centers on a model of a pencil programmatically drawing on a 2-dimensional screen, with the pencil cursor depicted visually as a turtle.

History
Pencil Code was created by David Bau and his son in 2013.  It was inspired by Logo, the 1967 programming language for drawing on a screen using a Lisp-like programming language.Google has funded improvements to Pencil Code via Google Summer of Code projects.

References
External links
Pencil Code official website",73001932,https://en.wikipedia.org/wiki/Pencil_Code_(programming_language)
Perl,"Perl is a high-level, general-purpose, interpreted, dynamic programming language. Though Perl is not officially an acronym, there are various backronyms in use, including ""Practical Extraction and Reporting Language"".Perl was developed by Larry Wall in 1987 as a general-purpose Unix scripting language to make report processing easier. Since then, it has undergone many changes and revisions. Perl originally was not capitalized and the name was changed to being capitalized by the time Perl 4 was released. The latest release is Perl 5, first released in 1994. From 2000 to October 2019 a sixth version of Perl was in development, before the latter's name was officially changed to Raku. Both languages continue to be developed independently by different development teams which liberally borrow ideas from each other.
Perl borrows features from other programming languages including C, sh, AWK, and sed. It provides text processing facilities without the arbitrary data-length limits of many contemporary Unix command line tools. Perl is a highly expressive programming language: source code for a given algorithm can be short and highly compressible.Perl gained widespread popularity in the mid-1990s as a CGI scripting language, in part due to its powerful regular expression and string parsing abilities. In addition to CGI, Perl 5 is used for system administration, network programming, finance, bioinformatics, and other applications, such as for GUIs. It has been nicknamed ""the Swiss Army chainsaw of scripting languages"" because of its flexibility and power. In 1998, it was also referred to as the ""duct tape that holds the Internet together"", in reference to both its ubiquitous use as a glue language and its perceived inelegance.","Perl is a high-level, general-purpose, interpreted, dynamic programming language. Though Perl is not officially an acronym, there are various backronyms in use, including ""Practical Extraction and Reporting Language"".Perl was developed by Larry Wall in 1987 as a general-purpose Unix scripting language to make report processing easier. Since then, it has undergone many changes and revisions. Perl originally was not capitalized and the name was changed to being capitalized by the time Perl 4 was released. The latest release is Perl 5, first released in 1994. From 2000 to October 2019 a sixth version of Perl was in development, before the latter's name was officially changed to Raku. Both languages continue to be developed independently by different development teams which liberally borrow ideas from each other.
Perl borrows features from other programming languages including C, sh, AWK, and sed. It provides text processing facilities without the arbitrary data-length limits of many contemporary Unix command line tools. Perl is a highly expressive programming language: source code for a given algorithm can be short and highly compressible.Perl gained widespread popularity in the mid-1990s as a CGI scripting language, in part due to its powerful regular expression and string parsing abilities. In addition to CGI, Perl 5 is used for system administration, network programming, finance, bioinformatics, and other applications, such as for GUIs. It has been nicknamed ""the Swiss Army chainsaw of scripting languages"" because of its flexibility and power. In 1998, it was also referred to as the ""duct tape that holds the Internet together"", in reference to both its ubiquitous use as a glue language and its perceived inelegance.

Name and logos
Perl was originally named ""Pearl"". Wall wanted to give the language a short name with positive connotations. It is also a Christian reference to the Parable of the Pearl from the Gospel of Matthew. However, Wall discovered the existing PEARL programming language before Perl's official release and changed the spelling of the name and dropped the ""a"" from the name.The name is occasionally expanded as a backronym: Practical Extraction and Report Language and Wall's own Pathologically Eclectic Rubbish Lister, which is in the manual page for perl.Programming Perl, published by O'Reilly Media, features a picture of a dromedary camel on the cover and is commonly called the ""Camel Book"". This image has become an unofficial symbol of Perl as well as a general hacker emblem, appearing on T-shirts and other clothing items. O'Reilly owns the image as a trademark but licenses it for non-commercial use, requiring only an acknowledgement and a link to www.perl.com. Licensing for commercial use is decided on a case-by-case basis. O'Reilly also provides ""Programming Republic of Perl"" logos for non-commercial sites and ""Powered by Perl"" buttons for any site that uses Perl.The Perl Foundation owns an alternative symbol, an onion, which it licenses to its subsidiaries, Perl Mongers, PerlMonks, Perl.org, and others. The symbol is a visual pun on pearl onion.Sebastian Riedel, the creator of Mojolicious, created a logo depicting a raptor dinosaur, which is available under a CC-SA License, Version 4.0. The analogue of the raptor comes from a series of talks given by Matt S Trout beginning in 2010.

History
Early versions
Larry Wall began work on Perl in 1987, while employed as a programmer at Unisys; he released version 1.0 on December 18, 1987. The early language of Perl that Wall based it off of was the use of existing languages that would help with text manipulation.Perl 2, released in June 1988, featured a better regular expression engine. Perl 3, released in October 1989, added support for binary data streams.

1990s
Originally, the only documentation for Perl was a single lengthy man page. In 1991, Programming Perl, known to many Perl programmers as the ""Camel Book"" because of its cover, was published and became the de facto reference for the language. At the same time, the Perl version number was bumped to 4, not to mark a major change in the language but to identify the version that was well documented by the book. Perl 4 was released in March 1991.Perl 4 went through a series of maintenance releases, culminating in Perl 4.036 in 1993, whereupon Wall abandoned Perl 4 to begin work on Perl 5. Initial design of Perl 5 continued into 1994. The perl5-porters mailing list was established in May 1994 to coordinate work on porting Perl 5 to different platforms. It remains the primary forum for development, maintenance, and porting of Perl 5.Perl 5.000 was released on October 17, 1994. It was a nearly complete rewrite of the interpreter, and it added many new features to the language, including objects, references, lexical (my) variables, and modules. Importantly, modules provided a mechanism for extending the language without modifying the interpreter. This allowed the core interpreter to stabilize, even as it enabled ordinary Perl programmers to add new language features. Perl 5 has been in active development since then.
Perl 5.001 was released on March 13, 1995. Perl 5.002 was released on February 29, 1996 with the new prototypes feature. This allowed module authors to make subroutines that behaved like Perl builtins. Perl 5.003 was released June 25, 1996, as a security release.One of the most important events in Perl 5 history took place outside of the language proper and was a consequence of its module support. On October 26, 1995, the Comprehensive Perl Archive Network (CPAN) was established as a repository for the Perl language and Perl modules; as of December 2022, it carries over 211,850 modules in 43,865 distributions, written by more than 14,324 authors, and is mirrored worldwide at more than 245 locations.Perl 5.004 was released on May 15, 1997, and included, among other things, the UNIVERSAL package, giving Perl a base object from which all classes were automatically derived and the ability to require versions of modules. Another significant development was the inclusion of the CGI.pm module, which contributed to Perl's popularity as a CGI scripting language.Perl 5.004 added support for Microsoft Windows, Plan 9, QNX, and AmigaOS.Perl 5.005 was released on July 22, 1998. This release included several enhancements to the regex engine, new hooks into the backend through the B::* modules, the qr// regex quote operator, a large selection of other new core modules, and added support for several more operating systems, including BeOS.

2000–2020
Perl 5.6 was released on March 22, 2000.  Major changes included 64-bit support, Unicode string representation, support for files over 2 GiB, and the ""our"" keyword.  When developing Perl 5.6, the decision was made to switch the versioning scheme to one more similar to other open source projects; after 5.005_63, the next version became 5.5.640, with plans for development versions to have odd numbers and stable versions to have even numbers.In 2000, Wall put forth a call for suggestions for a new version of Perl from the community. The process resulted in 361 RFC (request for comments) documents that were to be used in guiding development of Perl 6. In 2001, work began on the ""Apocalypses"" for Perl 6, a series of documents meant to summarize the change requests and present the design of the next generation of Perl. They were presented as a digest of the RFCs, rather than a formal document. At this point, Perl 6 existed only as a description of a language.Perl 5.8 was first released on July 18, 2002, and further 5.X versions have been released approximately yearly since then. Perl 5.8 improved Unicode support, added a new I/O implementation, added a new thread implementation, improved numeric accuracy, and added several new modules. As of 2013 this version still remained the most popular version of Perl and was used by Red Hat 5, Suse 10, Solaris 10, HP-UX 11.31 and AIX 5.
In 2004, work began on the ""Synopses"" – documents that originally summarized the Apocalypses, but which became the specification for the Perl 6 language. In February 2005, Audrey Tang began work on Pugs, a Perl 6 interpreter written in Haskell. This was the first concerted effort toward making Perl 6 a reality. This effort stalled in 2006.PONIE is an acronym for Perl On New Internal Engine. The PONIE Project existed from 2003 until 2006 and was to be a bridge between Perl 5 and Perl 6. It was an effort to rewrite the Perl 5 interpreter to run on Parrot, the Perl 6 virtual machine. The goal was to ensure the future of the millions of lines of Perl 5 code at thousands of companies around the world. The PONIE project ended in 2006 and is no longer being actively developed.  Some of the improvements made to the Perl 5 interpreter as part of PONIE were folded into that project.On December 18, 2007, the 20th anniversary of Perl 1.0, Perl 5.10.0 was released. Perl 5.10.0 included notable new features, which brought it closer to Perl 6. These included a switch statement (called ""given""/""when""), regular expressions updates, and the smart match operator (~~).
Around this same time, development began in earnest on another implementation of Perl 6 known as Rakudo Perl, developed in tandem with the Parrot virtual machine. As of November 2009, Rakudo Perl has had regular monthly releases and now is the most complete implementation of Perl 6.
A major change in the development process of Perl 5 occurred with Perl 5.11; the development community has switched to a monthly release cycle of development releases, with a yearly schedule of stable releases. By that plan, bugfix point releases will follow the stable releases every three months.On April 12, 2010, Perl 5.12.0 was released. Notable core enhancements include new package NAME VERSION syntax, the yada yada operator (intended to mark placeholder code that is not yet implemented), implicit strictures, full Y2038 compliance, regex conversion overloading, DTrace support, and Unicode 5.2.On May 14, 2011, Perl 5.14 was released with JSON support built-in.On May 20, 2012, Perl 5.16 was released. Notable new features include the ability to specify a given version of Perl that one wishes to emulate, allowing users to upgrade their version of Perl, but still run old scripts that would normally be incompatible. Perl 5.16 also updates the core to support Unicode 6.1.On May 18, 2013, Perl 5.18 was released. Notable new features include the new dtrace hooks, lexical subs, more CORE:: subs, overhaul of the hash for security reasons, support for Unicode 6.2.On May 27, 2014, Perl 5.20 was released. Notable new features include subroutine signatures, hash slices/new slice syntax, postfix dereferencing (experimental), Unicode 6.3, and a rand() function using a consistent random number generator.Some observers credit the release of Perl 5.10 with the start of the Modern Perl movement. In particular, this phrase describes a style of development that embraces the use of the CPAN, takes advantage of recent developments in the language, and is rigorous about creating high quality code. While the book ""Modern Perl"" may be the most visible standard-bearer of this idea, other groups such as the Enlightened Perl Organization have taken up the cause.
In late 2012 and 2013, several projects for alternative implementations for Perl 5 started: Perl5 in Perl6 by the Rakudo Perl team, moe by Stevan Little and friends, p2 by the Perl11 team under Reini Urban, gperl by goccy, and rperl, a Kickstarter project led by Will Braswell and affiliated with the Perll11 project.

Perl 6 and Raku
At the 2000 Perl Conference, Jon Orwant made a case for a major new language-initiative. This led to a decision to begin work on a redesign of the language, to be called Perl 6. Proposals for new language features were solicited from the Perl community at large, which submitted more than 300 RFCs.Wall spent the next few years digesting the RFCs and synthesizing them into a coherent framework for Perl 6. He presented his design for Perl 6 in a series of documents called ""apocalypses"" – numbered to correspond to chapters in Programming Perl. As of January 2011, the developing specification of Perl 6 was encapsulated in design documents called Synopses – numbered to correspond to Apocalypses.Thesis work by Bradley M. Kuhn, overseen by Wall, considered the possible use of the Java virtual machine as a runtime for Perl. Kuhn's thesis showed this approach to be problematic. In 2001, it was decided that Perl 6 would run on a cross-language virtual machine called Parrot. This will mean that other languages targeting the Parrot will gain native access to CPAN, allowing some level of cross-language development.In 2005, Audrey Tang created the Pugs project, an implementation of Perl 6 in Haskell. This acted as, and continues to act as, a test platform for the Perl 6 language (separate from the development of the actual implementation) – allowing the language designers to explore. The Pugs project spawned an active Perl/Haskell cross-language community centered around the Libera Chat #raku IRC channel. Many functional programming influences were absorbed by the Perl 6 design team.In 2012, Perl 6 development was centered primarily on two compilers:
Rakudo, an implementation running on the Parrot virtual machine and the Java virtual machine.
Niecza, which targets the Common Language Runtime.In 2013, MoarVM (""Metamodel On A Runtime""), a C language-based virtual machine designed primarily for Rakudo was announced.In October 2019, Perl 6 was renamed to Raku.As of 2017 only the Rakudo implementation and MoarVM are under active development, and other virtual machines, such as the Java Virtual Machine and JavaScript, are supported.

Perl 7
In June 2020, Perl 7 was announced as the successor to Perl 5. Perl 7 was to initially be based on Perl 5.32 with a release expected in first half of 2021, and release candidates sooner.This plan was revised in May 2021, without any release timeframe or version of Perl 5 for use as a baseline specified. When Perl 7 is released, Perl 5 will go into long term maintenance. Supported Perl 5 versions however will continue to get important security and bug fixes.Perl 7 was announced on 24 June 2020 at ""The Perl Conference in the Cloud"" as the successor to Perl 5. Based on Perl 5.32, Perl 7 was planned to be backward compatible with modern Perl 5 code; Perl 5 code, without boilerplate (pragma) header needs adding use compat::perl5; to stay compatible, but modern code can drop some of the boilerplate. 
The plan to go to Perl 7 brought up more discussion, however, and the Perl Steering Committee canceled it to avoid issues with backward compatibility for scripts that were not written to the pragmas and modules that would become the default in Perl 7. Perl 7 will only come out when the developers add enough features to warrant a major release upgrade.

Design
Philosophy
According to Wall, Perl has two slogans. The first is ""There's more than one way to do it,"" commonly known as TMTOWTDI, (pronounced Tim Toady). As proponents of this motto argue, this philosophy makes it easy to write concise statements.The second slogan is ""Easy things should be easy and hard things should be possible"".The design of Perl can be understood as a response to three broad trends in the computer industry: falling hardware costs, rising labor costs, and improvements in compiler technology. Many earlier computer languages, such as Fortran and C, aimed to make efficient use of expensive computer hardware. In contrast, Perl was designed so that computer programmers could write programs more quickly and easily.Perl has many features that ease the task of the programmer at the expense of greater CPU and memory requirements. These include automatic memory management; dynamic typing; strings, lists, and hashes; regular expressions; introspection; and an eval() function. Perl follows the theory of ""no built-in limits"", an idea similar to the Zero One Infinity rule.
Wall was trained as a linguist, and the design of Perl is very much informed by linguistic principles. Examples include Huffman coding (common constructions should be short), good end-weighting (the important information should come first), and a large collection of language primitives. Perl favors language constructs that are concise and natural for humans to write, even where they complicate the Perl interpreter.Perl's syntax reflects the idea that ""things that are different should look different."" For example, scalars, arrays, and hashes have different leading sigils. Array indices and hash keys use different kinds of braces. Strings and regular expressions have different standard delimiters. This approach can be contrasted with a language such as Lisp, where the same basic syntax, composed of simple and universal symbolic expressions, is used for all purposes.There is a broad practical bent to both the Perl language and the community and culture that surround it. The preface to Programming Perl begins: ""Perl is a language for getting your job done."" One consequence of this is that Perl is not a tidy language. It includes many features, tolerates exceptions to its rules, and employs heuristics to resolve syntactical ambiguities. Because of the forgiving nature of the compiler, bugs can sometimes be hard to find. Perl's function documentation remarks on the variant behavior of built-in functions in list and scalar contexts by saying, ""In general, they do what you want, unless you want consistency.""

Features
The overall structure of Perl derives broadly from C. Perl is procedural in nature, with variables, expressions, assignment statements, brace-delimited blocks, control structures, and subroutines.Perl also takes features from shell programming. All variables are marked with leading sigils, which allow variables to be interpolated directly into strings. However, unlike the shell, Perl uses sigils on all accesses to variables, and unlike most other programming languages that use sigils, the sigil doesn't denote the type of the variable but the type of the expression. So for example, while an array is denoted by the sigil ""@"" (for example @arrayname), an individual member of the array is denoted by the scalar sigil ""$"" (for example $arrayname[3]). Perl also has many built-in functions that provide tools often used in shell programming (although many of these tools are implemented by programs external to the shell) such as sorting, and calling operating system facilities.Perl takes hashes (""associative arrays"") from AWK and regular expressions from sed. These simplify many parsing, text-handling, and data-management tasks. Shared with Lisp is the implicit return of the last value in a block, and all statements are also expressions which can be used in larger expressions themselves.Perl 5 added features that support complex data structures, first-class functions (that is, closures as values), and an object-oriented programming model. These include references, packages, class-based method dispatch, and lexically scoped variables, along with compiler directives (for example, the strict pragma). A major additional feature introduced with Perl 5 was the ability to package code as reusable modules. Wall later stated that ""The whole intent of Perl 5's module system was to encourage the growth of Perl culture rather than the Perl core.""All versions of Perl do automatic data-typing and automatic memory management. The interpreter knows the type and storage requirements of every data object in the program; it allocates and frees storage for them as necessary using reference counting (so it cannot deallocate circular data structures without manual intervention). Legal type conversions — for example, conversions from number to string — are done automatically at run time; illegal type conversions are fatal errors.

Syntax
Perl has been referred to as ""line noise"" and a write-only language by its critics. The earliest such mention was in the first edition of the book Learning Perl, a Perl 4 tutorial book written by Randal L. Schwartz, in the first chapter of which he states: ""Yes, sometimes Perl looks like line noise to the uninitiated, but to the seasoned Perl programmer, it looks like checksummed line noise with a mission in life."" He also stated that the accusation that Perl is a write-only language could be avoided by coding with ""proper care"". The Perl overview document perlintro states that the names of built-in ""magic"" scalar variables ""look like punctuation or line noise"". However, the English module provides  both long and short English alternatives. perlstyle document states that line noise in regular expressions could be mitigated using the /x modifier to add whitespace.According to the Perl 6 FAQ, Perl 6 was designed to mitigate ""the usual suspects"" that elicit the ""line noise"" claim from Perl 5 critics, including the removal of ""the majority of the punctuation variables"" and the sanitization of the regex syntax. The Perl 6 FAQ also states that what is sometimes referred to as Perl's line noise is ""the actual syntax of the language"" just as gerunds and prepositions are a part of the English language. In a December 2012 blog posting, despite claiming that ""Rakudo Perl 6 has failed and will continue to fail unless it gets some adult supervision"", chromatic stated that the design of Perl 6 has a ""well-defined grammar"" as well as an ""improved type system, a unified object system with an intelligent metamodel, metaoperators, and a clearer system of context that provides for such niceties as pervasive laziness"". He also stated that ""Perl 6 has a coherence and a consistency that Perl 5 lacks.""In Perl, one could write the ""Hello, World!"" program as:

Here is a more complex Perl program, that counts down seconds from a given starting value:

The Perl interpreter can also be used for one-off scripts on the command line. The following example (as invoked from an sh-compatible shell, such as Bash) translates the string ""Bob"" in all files ending with .txt in the current directory to ""Robert"":

Implementation
No written specification or standard for the Perl language exists for Perl versions through Perl 5, and there are no plans to create one for the current version of Perl. There has been only one implementation of the interpreter, and the language has evolved along with it. That interpreter, together with its functional tests, stands as a de facto specification of the language. Perl 6, however, started with a specification, and several projects aim to implement some or all of the specification.Perl is implemented as a core interpreter, written in C, together with a large collection of modules, written in Perl and C. As of 2010, the interpreter is 150,000 lines of C code and compiles to a 1 MB executable on typical machine architectures. Alternatively, the interpreter can be compiled to a link library and embedded in other programs. There are nearly 500 modules in the distribution, comprising 200,000 lines of Perl and an additional 350,000 lines of C code (much of the C code in the modules consists of character encoding tables).The interpreter has an object-oriented architecture. All of the elements of the Perl language—scalars, arrays, hashes, coderefs, file handles—are represented in the interpreter by C structs. Operations on these structs are defined by a large collection of macros, typedefs, and functions; these constitute the Perl C API. The Perl API can be bewildering to the uninitiated, but its entry points follow a consistent naming scheme, which provides guidance to those who use it.The life of a Perl interpreter divides broadly into a compile phase and a run phase.  In Perl, the phases are the major stages in the interpreter's life-cycle. Each interpreter goes through each phase only once, and the phases follow in a fixed sequence.Most of what happens in Perl's compile phase is compilation, and most of what happens in Perl's run phase is execution, but there are significant exceptions. Perl makes important use of its capability to execute Perl code during the compile phase. Perl will also delay compilation into the run phase. The terms that indicate the kind of processing that is actually occurring at any moment are compile time and run time.  Perl is in compile time at most points during the compile phase, but compile time may also be entered during the run phase. The compile time for code in a string argument passed to the eval built-in occurs during the run phase. Perl is often in run time during the compile phase and spends most of the run phase in run time.  Code in BEGIN blocks executes at run time but in the compile phase.
At compile time, the interpreter parses Perl code into a syntax tree. At run time, it executes the program by walking the tree. Text is parsed only once, and the syntax tree is subject to optimization before it is executed, so that execution is relatively efficient. Compile-time optimizations on the syntax tree include constant folding and context propagation, but peephole optimization is also performed.Perl has a Turing-complete grammar because parsing can be affected by run-time code executed during the compile phase. Therefore, Perl cannot be parsed by a straight Lex/Yacc lexer/parser combination. Instead, the interpreter implements its own lexer, which coordinates with a modified GNU bison parser to resolve ambiguities in the language.It is often said that ""Only perl can parse Perl"", meaning that only the Perl interpreter (perl) can parse the Perl language (Perl), but even this is not, in general, true. Because the Perl interpreter can simulate a Turing machine during its compile phase, it would need to decide the halting problem in order to complete parsing in every case. It is a longstanding result that the halting problem is undecidable, and therefore not even Perl can always parse Perl. Perl makes the unusual choice of giving the user access to its full programming power in its own compile phase. The cost in terms of theoretical purity is high, but practical inconvenience seems to be rare.Other programs that undertake to parse Perl, such as source-code analyzers and auto-indenters, have to contend not only with ambiguous syntactic constructs but also with the undecidability of Perl parsing in the general case. Adam Kennedy's PPI project focused on parsing Perl code as a document (retaining its integrity as a document), instead of parsing Perl as executable code (that not even Perl itself can always do). It was Kennedy who first conjectured that ""parsing Perl suffers from the 'halting problem',"" which was later proved.Perl is distributed with over 250,000 functional tests for core Perl language and over 250,000 functional tests for core modules. These run as part of the normal build process and extensively exercise the interpreter and its core modules. Perl developers rely on the functional tests to ensure that changes to the interpreter do not introduce software bugs; additionally, Perl users who see that the interpreter passes its functional tests on their system can have a high degree of confidence that it is working properly.

Ports
Perl is dual licensed under both the Artistic License 1.0 and the GNU General Public License. Distributions are available for most operating systems. It is particularly prevalent on Unix and Unix-like systems, but it has been ported to most modern (and many obsolete) platforms. With only six reported exceptions, Perl can be compiled from source code on all POSIX-compliant, or otherwise-Unix-compatible, platforms.Because of unusual changes required for the classic Mac OS environment, a special port called MacPerl was shipped independently.The Comprehensive Perl Archive Network carries a complete list of supported platforms with links to the distributions available on each. CPAN is also the source for publicly available Perl modules that are not part of the core Perl distribution.ActivePerl is a closed-source distribution from ActiveState that has regular releases that track the core Perl releases. The distribution previously included the Perl package manager (PPM), a popular tool for installing, removing, upgrading, and managing the use of common Perl modules; however, this tool was discontinued as of ActivePerl 5.28. Included also is PerlScript, a Windows Script Host (WSH) engine implementing the Perl language.  Visual Perl is an ActiveState tool that adds Perl to the Visual Studio .NET development suite.  A VBScript-to-Perl converter, as well as a Perl compiler for Windows, and converters of awk and sed to Perl have also been produced by this company and included on the ActiveState CD for Windows, which includes all of their distributions plus the Komodo IDE and all but the first on the Unix/Linux/Posix variant thereof in 2002 and subsequently.

Performance
The Computer Language Benchmarks Game compares the performance of implementations of typical programming problems in several programming languages. The submitted Perl implementations typically perform toward the high end of the memory-usage spectrum and give varied speed results. Perl's performance in the benchmarks game is typical for interpreted languages.Large Perl programs start more slowly than similar programs in compiled languages because Perl has to compile the source every time it runs. In a talk at the YAPC::Europe 2005 conference and subsequent article ""A Timely Start"", Jean-Louis Leroy found that his Perl programs took much longer to run than expected because the perl interpreter spent significant time finding modules within his over-large include path. Unlike Java, Python, and Ruby, Perl has only experimental support for pre-compiling. Therefore, Perl programs pay this overhead penalty on every execution. The run phase of typical programs is long enough that amortized startup time is not substantial, but benchmarks that measure very short execution times are likely to be skewed due to this overhead.A number of tools have been introduced to improve this situation. The first such tool was Apache's mod_perl, which sought to address one of the most-common reasons that small Perl programs were invoked rapidly: CGI Web development. ActivePerl, via Microsoft ISAPI, provides similar performance improvements.Once Perl code is compiled, there is additional overhead during the execution phase that typically isn't present for programs written in compiled languages such as C or C++. Examples of such overhead include bytecode interpretation, reference-counting memory management, and dynamic type-checking.The most critical routines can be written in other languages (such as C), which can be connected to Perl via simple Inline modules or the more complex, but flexible, XS mechanism.

Applications
Perl has many and varied applications, compounded by the availability of many standard and third-party modules.
Perl has chiefly been used to write CGI scripts: large projects written in Perl include cPanel, Slash, Bugzilla, RT, TWiki, and Movable Type; high-traffic websites that use Perl extensively include Priceline.com, Craigslist, IMDb, LiveJournal, DuckDuckGo, Slashdot and Ticketmaster. 
It is also an optional component of the popular LAMP technology stack for Web development, in lieu of PHP or Python. Perl is used extensively as a system programming language in the Debian Linux distribution.Perl is often used as a glue language, tying together systems and interfaces that were not specifically designed to interoperate, and for ""data munging"", that is, converting or processing large amounts of data for tasks such as creating reports. In fact, these strengths are intimately linked. The combination makes Perl a popular all-purpose language for system administrators, particularly because short programs, often called ""one-liner programs"", can be entered and run on a single command line.Perl code can be made portable across Windows and Unix; such code is often used by suppliers of software (both COTS and bespoke) to simplify packaging and maintenance of software build- and deployment-scripts.Perl/Tk and wxPerl are commonly used to add graphical user interfaces to Perl scripts.
Perl's text-handling capabilities can be used for generating SQL queries; arrays, hashes, and automatic memory management make it easy to collect and process the returned data. For example, in Tim Bunce's Perl DBI application programming interface (API), the arguments to the API can be the text of SQL queries; thus it is possible to program in multiple languages at the same time (e.g., for generating a Web page using HTML, JavaScript, and SQL in a here document). The use of Perl variable interpolation to programmatically customize each of the SQL queries, and the specification of Perl arrays or hashes as the structures to programmatically hold the resulting data sets from each SQL query, allows a high-level mechanism for handling large amounts of data for post-processing by a Perl subprogram.
In early versions of Perl, database interfaces were created by relinking the interpreter with a client-side database library. This was sufficiently difficult that it was done for only a few of the most-important and most widely used databases, and it restricted the resulting perl executable to using just one database interface at a time.In Perl 5, database interfaces are implemented by Perl DBI modules. The DBI (Database Interface) module presents a single, database-independent interface to Perl applications, while the DBD (Database Driver) modules handle the details of accessing some 50 different databases; there are DBD drivers for most ANSI SQL databases.DBI provides caching for database handles and queries, which can greatly improve performance in long-lived execution environments such as mod_perl, helping high-volume systems avert load spikes as in the Slashdot effect.In modern Perl applications, especially those written using web frameworks such as Catalyst, the DBI module is often used indirectly via object-relational mappers such as DBIx::Class, Class::DBI or Rose::DB::Object that generate SQL queries and handle data transparently to the application author.

Community
Perl's culture and community has developed alongside the language itself. Usenet was the first public venue in which Perl was introduced, but over the course of its evolution, Perl's community was shaped by the growth of broadening Internet-based services including the introduction of the World Wide Web. The community that surrounds Perl was, in fact, the topic of Wall's first ""State of the Onion"" talk.State of the Onion is the name for Wall's yearly keynote-style summaries on the progress of Perl and its community.  They are characterized by his hallmark humor, employing references to Perl's culture, the wider hacker culture, Wall's linguistic background, sometimes his family life, and occasionally even his Christian background. Each talk is first given at various Perl conferences and is eventually also published online.
In email, Usenet, and message board postings, ""Just another Perl hacker"" (JAPH) programs are a common trend, originated by Randal L. Schwartz, one of the earliest professional Perl trainers. In the parlance of Perl culture, Perl programmers are known as Perl hackers, and from this derives the practice of writing short programs to print out the phrase ""Just another Perl hacker"". In the spirit of the original concept, these programs are moderately obfuscated and short enough to fit into the signature of an email or Usenet message. The ""canonical"" JAPH as developed by Schwartz includes the comma at the end, although this is often omitted.
Perl ""golf"" is the pastime of reducing the number of characters (key ""strokes"") used in a Perl program to the bare minimum, much in the same way that golf players seek to take as few shots as possible in a round. The phrase's first use emphasized the difference between pedestrian code meant to teach a newcomer and terse hacks likely to amuse experienced Perl programmers, an example of the latter being JAPHs that were already used in signatures in Usenet postings and elsewhere. Similar stunts had been an unnamed pastime in the language APL in previous decades. The use of Perl to write a program that performed RSA encryption prompted a widespread and practical interest in this pastime. In subsequent years, the term ""code golf"" has been applied to the pastime in other languages. A Perl Golf Apocalypse was held at Perl Conference 4.0 in Monterey, California in July 2000.
As with C, obfuscated code competitions were a well known pastime in the late 1990s. The Obfuscated Perl Contest was a competition held by The Perl Journal from 1996 to 2000 that made an arch virtue of Perl's syntactic flexibility. Awards were given for categories such as ""most powerful""—programs that made efficient use of space—and ""best four-line signature"" for programs that fit into four lines of 76 characters in the style of a Usenet signature block.Perl poetry is the practice of writing poems that can be compiled as legal Perl code, for example the piece known as Black Perl. Perl poetry is made possible by the large number of English words that are used in the Perl language. New poems are regularly submitted to the community at PerlMonks.

See also
Outline of Perl
Perl Data Language
Perl Object Environment
Plain Old Documentation

References
Further reading
Learning Perl 6th Edition (2011), O'Reilly. Beginner-level introduction to Perl.
Beginning Perl 1st Edition (2012), Wrox. A beginner's tutorial for those new to programming or just new to Perl.
Modern Perl Archived December 22, 2011, at the Wayback Machine 2nd Edition (2012), Onyx Neon. Describes Modern Perl programming techniques.
Programming Perl 4th Edition (2012), O'Reilly. The definitive Perl reference.
Effective Perl Programming 2nd Edition (2010), Addison-Wesley. Intermediate- to advanced-level guide to writing idiomatic Perl.
Perl Cookbook, ISBN 0-596-00313-7. Practical Perl programming examples.
Dominus, Mark Jason (2005). Higher Order Perl. Morgan Kaufmann. ISBN 978-1-55860-701-9. Functional programming techniques in Perl.

External links

Official website",23939,https://en.wikipedia.org/wiki/Perl
Algorithm,"In mathematics and computer science, an algorithm ( ) is a finite sequence of rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. More advanced algorithms can use conditionals to divert the code execution through various routes (referred to as automated decision-making) and deduce valid inferences (referred to as automated reasoning), achieving automation eventually. Using human characteristics as descriptors of machines in metaphorical ways was already practiced by Alan Turing with terms such as ""memory"", ""search"" and ""stimulus"".In contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.  For example, social media recommender systems rely on heuristics in such a way that, although widely characterized as ""algorithms"" in 21st century popular media, cannot deliver correct results due to the nature of the problem.
As an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing ""output"" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.","In mathematics and computer science, an algorithm ( ) is a finite sequence of rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. More advanced algorithms can use conditionals to divert the code execution through various routes (referred to as automated decision-making) and deduce valid inferences (referred to as automated reasoning), achieving automation eventually. Using human characteristics as descriptors of machines in metaphorical ways was already practiced by Alan Turing with terms such as ""memory"", ""search"" and ""stimulus"".In contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.  For example, social media recommender systems rely on heuristics in such a way that, although widely characterized as ""algorithms"" in 21st century popular media, cannot deliver correct results due to the nature of the problem.
As an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing ""output"" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.

History
Ancient algorithms
Since antiquity, step-by-step procedures for solving mathematical problems have been attested. This includes Babylonian mathematics (around 2500 BC), Egyptian mathematics (around 1550 BC), Indian mathematics (around 800 BC and later; e.g. Shulba Sutras, Kerala School, and Brāhmasphuṭasiddhānta), The Ifa Oracle (around 500 BC), Greek mathematics (around 240 BC, e.g. sieve of Eratosthenes and Euclidean algorithm), and Arabic mathematics (9th century, e.g. cryptographic algorithms for code-breaking based on frequency analysis).

Al-Khwārizmī and the term algorithm
Around 825, Persian scientist and polymath Muḥammad ibn Mūsā al-Khwārizmī wrote kitāb al-ḥisāb al-hindī (""Book of Indian computation"") and kitab al-jam' wa'l-tafriq al-ḥisāb al-hindī (""Addition and subtraction in Indian arithmetic""). Both of these texts are lost in the original Arabic at this time. (However, his other book on algebra remains.)In the early 12th century, Latin translations of said al-Khwarizmi texts involving the Hindu–Arabic numeral system and arithmetic appeared: Liber Alghoarismi de practica arismetrice (attributed to John of Seville) and Liber Algorismi de numero Indorum (attributed to Adelard of Bath). Hereby, alghoarismi or algorismi is the Latinization of Al-Khwarizmi's name; the text starts with the phrase Dixit Algorismi (""Thus spoke Al-Khwarizmi"").In 1240, Alexander of Villedieu writes a Latin text titled Carmen de Algorismo. It begins with:

Haec algorismus ars praesens dicitur, in qua / Talibus Indorum fruimur bis quinque figuris.
which translates to:

Algorism is the art by which at present we use those Indian figures, which number two times five.
The poem is a few hundred lines long and summarizes the art of calculating with the new styled Indian dice (Tali Indorum), or Hindu numerals.

English evolution of the word
Around 1230, the English word algorism is attested and then by Chaucer in 1391. English adopted the French term.In the 15th century, under the influence of the Greek word ἀριθμός (arithmos, ""number""; cf. ""arithmetic""), the Latin word was altered to algorithmus.
In 1656, in the English dictionary Glossographia, it says:

Algorism ([Latin] algorismus) the Art or use of Cyphers, or of numbering by Cyphers; skill in accounting.
Augrime ([Latin] algorithmus) skil in accounting or numbring.

In 1658, in the first edition of The New World of English Words, it says:

Algorithme, (a word compounded of Arabick and Spanish,) the art of reckoning by Cyphers.

In 1706, in the sixth edition of The New World of English Words, it says:

Algorithm, the Art of computing or reckoning by numbers, which contains the five principle Rules of Arithmetick, viz. Numeration, Addition, Subtraction, Multiplication and Division; to which may be added Extraction of Roots: It is also call'd Logistica Numeralis.
Algorism, the practical Operation in the several Parts of Specious Arithmetick or Algebra; sometimes it is taken for the Practice of Common Arithmetick by the ten Numeral Figures.

In 1751, in the Young Algebraist's Companion, Daniel Fenning contrasts the terms algorism and algorithm as follows:

Algorithm signifies the first Principles, and Algorism the practical Part, or knowing how to put the Algorithm in Practice.

Since at least 1811, the term algorithm is attested to mean a ""step-by-step procedure"" in English.In 1842, in the Dictionary of Science, Literature and Art, it says:

ALGORITHM, signifies the art of computing in reference to some particular subject, or in some particular way; as the algorithm of numbers; the algorithm of the differential calculus.

Machine usage
In 1928, a partial formalization of the modern concept of algorithms began with attempts to solve the Entscheidungsproblem (decision problem) posed by David Hilbert. Later formalizations were framed as attempts to define ""effective calculability"" or ""effective method"". Those formalizations included the Gödel–Herbrand–Kleene recursive functions of 1930, 1934 and 1935, Alonzo Church's lambda calculus of 1936, Emil Post's Formulation 1 of 1936, and Alan Turing's Turing machines of 1936–37 and 1939.

Informal definition
One informal definition is ""a set of rules that precisely defines a sequence of operations"", which would include all computer programs (including programs that do not perform numeric calculations), and (for example) any prescribed bureaucratic procedure
or cook-book recipe.In general, a program is an algorithm only if it stops eventually—even though infinite loops may sometimes prove desirable.
A prototypical example of an algorithm is the Euclidean algorithm, which is used to determine the maximum common divisor of two integers; an example (there are others) is described by the flowchart above and as an example in a later section.
Boolos, Jeffrey & 1974, 1999 offer an informal meaning of the word ""algorithm"" in the following quotation:

No human being can write fast enough, or long enough, or small enough† ( †""smaller and smaller without limit ... you'd be trying to write on molecules, on atoms, on electrons"") to list all members of an enumerably infinite set by writing out their names, one after another, in some notation. But humans can do something equally useful, in the case of certain enumerably infinite sets: They can give explicit instructions for determining the nth member of the set, for arbitrary finite n. Such instructions are to be given quite explicitly, in a form in which they could be followed by a computing machine, or by a human who is capable of carrying out only very elementary operations on symbols.
An ""enumerably infinite set"" is one whose elements can be put into one-to-one correspondence with the integers. Thus Boolos and Jeffrey are saying that an algorithm implies instructions for a process that ""creates"" output integers from an arbitrary ""input"" integer or integers that, in theory, can be arbitrarily large. For example, an algorithm can be an algebraic equation such as y = m + n (i.e., two arbitrary ""input variables"" m and n that produce an output y), but various authors' attempts to define the notion indicate that the word implies much more than this, something on the order of (for the addition example):

Precise instructions (in a language understood by ""the computer"") for a fast, efficient, ""good"" process that specifies the ""moves"" of ""the computer"" (machine or human, equipped with the necessary internally contained information and capabilities) to find, decode, and then process arbitrary input integers/symbols m and n, symbols + and = ... and ""effectively"" produce, in a ""reasonable"" time, output-integer y at a specified place and in a specified format.The concept of algorithm is also used to define the notion of decidability—a notion that is central for explaining how formal systems come into being starting from a small set of axioms and rules. In logic, the time that an algorithm requires to complete cannot be measured, as it is not apparently related to the customary physical dimension. From such uncertainties, that characterize ongoing work, stems the unavailability of a definition of algorithm that suits both concrete (in some sense) and abstract usage of the term.
Most algorithms are intended to be implemented as computer programs. However, algorithms are also implemented by other means, such as in a biological neural network (for example, the human brain implementing arithmetic or an insect looking for food), in an electrical circuit, or in a mechanical device.

Formalization
Algorithms are essential to the way computers process data. Many computer programs contain algorithms that detail the specific instructions a computer should perform—in a specific order—to carry out a specified task, such as calculating employees' paychecks or printing students' report cards. Thus, an algorithm can be considered to be any sequence of operations that can be simulated by a Turing-complete system. Authors who assert this thesis include Minsky (1967), Savage (1987), and Gurevich (2000):

 Minsky: ""But we will also maintain, with Turing ... that any procedure which could ""naturally"" be called effective, can, in fact, be realized by a (simple) machine. Although this may seem extreme, the arguments ... in its favor are hard to refute"".
 Gurevich: ""… Turing's informal argument in favor of his thesis justifies a stronger thesis: every algorithm can be simulated by a Turing machine … according to Savage [1987], an algorithm is a computational process defined by a Turing machine"".Turing machines can define computational processes that do not terminate. The informal definitions of algorithms generally require that the algorithm always terminates. This requirement renders the task of deciding whether a formal procedure is an algorithm impossible in the general case—due to a major theorem of computability theory known as the halting problem.
Typically, when an algorithm is associated with processing information, data can be read from an input source, written to an output device and stored for further processing. Stored data is regarded as part of the internal state of the entity performing the algorithm. In practice, the state is stored in one or more data structures.
For some of these computational processes, the algorithm must be rigorously defined and specified in the way it applies in all possible circumstances that could arise. This means that any conditional steps must be systematically dealt with, case by case; the criteria for each case must be clear (and computable).
Because an algorithm is a precise list of precise steps, the order of computation is always crucial to the functioning of the algorithm. Instructions are usually assumed to be listed explicitly, and are described as starting ""from the top"" and going ""down to the bottom""—an idea that is described more formally by flow of control.
So far, the discussion on the formalization of an algorithm has assumed the premises of imperative programming. This is the most common conception—one that attempts to describe a task in discrete, ""mechanical"" terms. Associated with this conception of formalized algorithms is the assignment operation, which sets the value of a variable. It derives from the intuition of ""memory"" as a scratchpad. An example of such an assignment can be found below.
For some alternate conceptions of what constitutes an algorithm, see functional programming and logic programming.

Expressing algorithms
Algorithms can be expressed in many kinds of notation, including natural languages, pseudocode, flowcharts, drakon-charts, programming languages or control tables (processed by interpreters). Natural language expressions of algorithms tend to be verbose and ambiguous and are rarely used for complex or technical algorithms. Pseudocode, flowcharts, drakon-charts and control tables are structured ways to express algorithms that avoid many of the ambiguities common in statements based on natural language. Programming languages are primarily intended for expressing algorithms in a form that can be executed by a computer, but they are also often used as a way to define or document algorithms.
There is a wide variety of representations possible and one can express a given Turing machine program as a sequence of machine tables (see finite-state machine, state-transition table and control table for more), as flowcharts and drakon-charts (see state diagram for more), or as a form of rudimentary machine code or assembly code called ""sets of quadruples"" (see Turing machine for more).
Representations of algorithms can be classified into three accepted levels of Turing machine description, as follows:
1 High-level description
""...prose to describe an algorithm, ignoring the implementation details. At this level, we do not need to mention how the machine manages its tape or head.""
2 Implementation description
""...prose used to define the way the Turing machine uses its head and the way that it stores data on its tape. At this level, we do not give details of states or transition function.""
3 Formal description
Most detailed, ""lowest level"", gives the Turing machine's ""state table"".For an example of the simple algorithm ""Add m+n"" described in all three levels, see Examples.

Design
Algorithm design refers to a method or a mathematical process for problem-solving and engineering algorithms. The design of algorithms is part of many solution theories, such as divide-and-conquer or dynamic programming within operation research. Techniques for designing and implementing algorithm designs are also called algorithm design patterns, with examples including the template method pattern and the decorator pattern.
One of the most important aspects of algorithm design is resource (run-time, memory usage) efficiency; the big O notation is used to describe e.g., an algorithm's run-time growth as the size of its input increases.
Typical steps in the development of algorithms:

Problem definition
Development of a model
Specification of the algorithm
Designing an algorithm
Checking the correctness of the algorithm
Analysis of algorithm
Implementation of algorithm
Program testing
Documentation preparation

Computer algorithms
""Elegant"" (compact) programs, ""good"" (fast) programs: The notion of ""simplicity and elegance"" appears informally in Knuth and precisely in Chaitin:

Knuth: "" ... we want good algorithms in some loosely defined aesthetic sense. One criterion ... is the length of time taken to perform the algorithm .... Other criteria are adaptability of the algorithm to computers, its simplicity, and elegance, etc.""Chaitin: "" ... a program is 'elegant,' by which I mean that it's the smallest possible program for producing the output that it does""Chaitin prefaces his definition with: ""I'll show you can't prove that a program is 'elegant'""—such a proof would solve the Halting problem (ibid).
Algorithm versus function computable by an algorithm: For a given function multiple algorithms may exist. This is true even without expanding the available instruction set available to the programmer. Rogers observes that ""It is ... important to distinguish between the notion of algorithm, i.e. procedure and the notion of function computable by algorithm, i.e. mapping yielded by procedure. The same function may have several different algorithms"".Unfortunately, there may be a tradeoff between goodness (speed) and elegance (compactness)—an elegant program may take more steps to complete a computation than one that is less elegant. An example that uses Euclid's algorithm appears below.
Computers (and computors), models of computation: A computer (or human ""computer"") is a restricted type of machine, a ""discrete deterministic mechanical device"" that blindly follows its instructions. Melzak's and Lambek's primitive models reduced this notion to four elements: (i) discrete, distinguishable locations, (ii) discrete, indistinguishable counters (iii) an agent, and (iv) a list of instructions that are effective relative to the capability of the agent.Minsky describes a more congenial variation of Lambek's ""abacus"" model in his ""Very Simple Bases for Computability"". Minsky's machine proceeds sequentially through its five (or six, depending on how one counts) instructions unless either a conditional IF-THEN GOTO or an unconditional GOTO changes program flow out of sequence. Besides HALT, Minsky's machine includes three assignment (replacement, substitution) operations: ZERO (e.g. the contents of the location replaced by 0: L ← 0), SUCCESSOR (e.g. L ← L+1), and DECREMENT (e.g. L ← L − 1). Rarely must a programmer write ""code"" with such a limited instruction set. But Minsky shows (as do Melzak and Lambek) that his machine is Turing complete with only four general types of instructions: conditional GOTO, unconditional GOTO, assignment/replacement/substitution, and HALT. However, a few different assignment instructions (e.g. DECREMENT, INCREMENT, and ZERO/CLEAR/EMPTY for a Minsky machine) are also required for Turing-completeness; their exact specification is somewhat up to the designer. The unconditional GOTO is convenient; it can be constructed by initializing a dedicated location to zero e.g. the instruction "" Z ← 0 ""; thereafter the instruction IF Z=0 THEN GOTO xxx is unconditional.
Simulation of an algorithm: computer (computor) language: Knuth advises the reader that ""the best way to learn an algorithm is to try it . . . immediately take pen and paper and work through an example"". But what about a simulation or execution of the real thing? The programmer must translate the algorithm into a language that the simulator/computer/computor can effectively execute. Stone gives an example of this: when computing the roots of a quadratic equation the computer must know how to take a square root. If they do not, then the algorithm, to be effective, must provide a set of rules for extracting a square root.This means that the programmer must know a ""language"" that is effective relative to the target computing agent (computer/computor).
But what model should be used for the simulation? Van Emde Boas observes ""even if we base complexity theory on abstract instead of concrete machines, the arbitrariness of the choice of a model remains. It is at this point that the notion of simulation enters"". When speed is being measured, the instruction set matters. For example, the subprogram in Euclid's algorithm to compute the remainder would execute much faster if the programmer had a ""modulus"" instruction available rather than just subtraction (or worse: just Minsky's ""decrement"").
Structured programming, canonical structures: Per the Church–Turing thesis, any algorithm can be computed by a model known to be Turing complete, and per Minsky's demonstrations, Turing completeness requires only four instruction types—conditional GOTO, unconditional GOTO, assignment, HALT. Kemeny and Kurtz observe that, while ""undisciplined"" use of unconditional GOTOs and conditional IF-THEN GOTOs can result in ""spaghetti code"", a programmer can write structured programs using only these instructions; on the other hand ""it is also possible, and not too hard, to write badly structured programs in a structured language"". Tausworthe augments the three Böhm-Jacopini canonical structures: SEQUENCE, IF-THEN-ELSE, and WHILE-DO, with two more: DO-WHILE and CASE. An additional benefit of a structured program is that it lends itself to proofs of correctness using mathematical induction.Canonical flowchart symbols: The graphical aid called a flowchart offers a way to describe and document an algorithm (and a computer program corresponding to it). Like the program flow of a Minsky machine, a flowchart always starts at the top of a page and proceeds down. Its primary symbols are only four: the directed arrow showing program flow, the rectangle (SEQUENCE, GOTO), the diamond (IF-THEN-ELSE), and the dot (OR-tie). The Böhm–Jacopini canonical structures are made of these primitive shapes. Sub-structures can ""nest"" in rectangles, but only if a single exit occurs from the superstructure. The symbols and their use to build the canonical structures are shown in the diagram.

Examples
Algorithm example
One of the simplest algorithms is to find the largest number in a list of numbers of random order. Finding the solution requires looking at every number in the list. From this follows a simple algorithm, which can be stated in a high-level description in English prose, as:
High-level description:

If there are no numbers in the set, then there is no highest number.
Assume the first number in the set is the largest number in the set.
For each remaining number in the set: if this number is larger than the current largest number, consider this number to be the largest number in the set.
When there are no numbers left in the set to iterate over, consider the current largest number to be the largest number of the set.(Quasi-)formal description:
Written in prose but much closer to the high-level language of a computer program, the following is the more formal coding of the algorithm in pseudocode or pidgin code:

Euclid's algorithm
In mathematics, the Euclidean algorithm or Euclid's algorithm, is an efficient method for computing the greatest common divisor (GCD) of two integers (numbers), the largest number that divides them both without a remainder. It is named after the ancient Greek mathematician Euclid, who first described it in his Elements (c. 300 BC). It is one of the oldest algorithms in common use. It can be used to reduce fractions to their simplest form, and is a part of many other number-theoretic and cryptographic calculations.

Euclid poses the problem thus: ""Given two numbers not prime to one another, to find their greatest common measure"". He defines ""A number [to be] a multitude composed of units"": a counting number, a positive integer not including zero. To ""measure"" is to place a shorter measuring length s successively (q times) along longer length l until the remaining portion r is less than the shorter length s. In modern words, remainder r = l − q×s, q being the quotient, or remainder r is the ""modulus"", the integer-fractional part left over after the division.For Euclid's method to succeed, the starting lengths must satisfy two requirements: (i) the lengths must not be zero, AND (ii) the subtraction must be ""proper""; i.e., a test must guarantee that the smaller of the two numbers is subtracted from the larger (or the two can be equal so their subtraction yields zero).
Euclid's original proof adds a third requirement: the two lengths must not be prime to one another. Euclid stipulated this so that he could construct a reductio ad absurdum proof that the two numbers' common measure is in fact the greatest. While Nicomachus' algorithm is the same as Euclid's, when the numbers are prime to one another, it yields the number ""1"" for their common measure. So, to be precise, the following is really Nicomachus' algorithm.

Computer language for Euclid's algorithm
Only a few instruction types are required to execute Euclid's algorithm—some logical tests (conditional GOTO), unconditional GOTO, assignment (replacement), and subtraction.

A location is symbolized by upper case letter(s), e.g. S, A, etc.
The varying quantity (number) in a location is written in lower case letter(s) and (usually) associated with the location's name. For example, location L at the start might contain the number l = 3009.

An inelegant program for Euclid's algorithm
The following algorithm is framed as Knuth's four-step version of Euclid's and Nicomachus', but, rather than using division to find the remainder, it uses successive subtractions of the shorter length s from the remaining length r until r is less than s. The high-level description, shown in boldface, is adapted from Knuth 1973:2–4:
INPUT:

1 [Into two locations L and S put the numbers l and s that represent the two lengths]:
INPUT L, S
2 [Initialize R: make the remaining length r equal to the starting/initial/input length l]:
R ← L

E0: [Ensure r ≥ s.]

3 [Ensure the smaller of the two numbers is in S and the larger in R]:
IF R > S THEN
the contents of L is the larger number so skip over the exchange-steps 4, 5 and 6:
GOTO step 7
ELSE
swap the contents of R and S.
4 L ← R (this first step is redundant, but is useful for later discussion).
5 R ← S
6 S ← L

E1: [Find remainder]: Until the remaining length r in R is less than the shorter length s in S, repeatedly subtract the measuring number s in S from the remaining length r in R.

7 IF S > R THEN
done measuring so
GOTO 10
ELSE
measure again,
8 R ← R − S
9 [Remainder-loop]:
GOTO 7.

E2: [Is the remainder zero?]: EITHER (i) the last measure was exact, the remainder in R is zero, and the program can halt, OR (ii) the algorithm must continue: the last measure left a remainder in R less than measuring number in S.

10 IF R = 0 THEN
done so
GOTO step 15
ELSE
CONTINUE TO step 11,

E3: [Interchange s and r]: The nut of Euclid's algorithm. Use remainder r to measure what was previously smaller number s; L serves as a temporary location.

11 L ← R
12 R ← S
13 S ← L
14 [Repeat the measuring process]:
GOTO 7

OUTPUT:

15 [Done. S contains the greatest common divisor]:
PRINT S

DONE:

16 HALT, END, STOP.

An elegant program for Euclid's algorithm
The following version of Euclid's algorithm requires only six core instructions to do what thirteen are required to do by ""Inelegant""; worse, ""Inelegant"" requires more types of instructions. The flowchart of ""Elegant"" can be found at the top of this article. In the (unstructured) Basic language, the steps are numbered, and the instruction LET [] = [] is the assignment instruction symbolized by ←.

How ""Elegant"" works: instead of an outer ""Euclid loop"", ""Elegant"" calculates the remainder of a division using modulo and shifts the variables A and B in each iteration. The following algorithm can be used with programming languages from the C-family:

The standard function abs changes negative integer to positive integer
When input A or B has the value 0, the algorithm stops and the result is 0
If input A is greater than input B, the algorithm will automatically swap variables A and B during the first iteration via modulo
The iteration (a do while loop) starts and only stops when the variable B is set to 0:
% calculates the modulo of division A and B, which reduces the number (e.g.: 23 = 3 × 6 + remainder 5)
A is equated with B
B is equated with the modulo-result
The iteration continues as long as B is greater than 0
When the iteration stops, variable A always contains the greatest common divisor

Testing the Euclid algorithms
Does an algorithm do what its author wants it to do? A few test cases usually give some confidence in the core functionality. But tests are not enough. For test cases, one source uses 3009 and 884. Knuth suggested 40902, 24140. Another interesting case is the two relatively prime numbers 14157 and 5950.
But ""exceptional cases"" must be identified and tested. Will ""Inelegant"" perform properly when R > S, S > R, R = S? Ditto for ""Elegant"": B > A, A > B, A = B? (Yes to all). What happens when one number is zero, both numbers are zero? (""Inelegant"" computes forever in all cases; ""Elegant"" computes forever when A = 0.) What happens if negative numbers are entered? Fractional numbers? If the input numbers, i.e. the domain of the function computed by the algorithm/program, is to include only positive integers including zero, then the failures at zero indicate that the algorithm (and the program that instantiates it) is a partial function rather than a total function. A notable failure due to exceptions is the Ariane 5 Flight 501 rocket failure (June 4, 1996).
Proof of program correctness by use of mathematical induction: Knuth demonstrates the application of mathematical induction to an ""extended"" version of Euclid's algorithm, and he proposes ""a general method applicable to proving the validity of any algorithm"". Tausworthe proposes that a measure of the complexity of a program be the length of its correctness proof.

Measuring and improving the Euclid algorithms
Elegance (compactness) versus goodness (speed): With only six core instructions, ""Elegant"" is the clear winner, compared to ""Inelegant"" at thirteen instructions. However, ""Inelegant"" is faster (it arrives at HALT in fewer steps). Algorithm analysis indicates why this is the case: ""Elegant"" does two conditional tests in every subtraction loop, whereas ""Inelegant"" only does one. As the algorithm (usually) requires many loop-throughs, on average much time is wasted doing a ""B = 0?"" test that is needed only after the remainder is computed.
Can the algorithms be improved?: Once the programmer judges a program ""fit"" and ""effective""—that is, it computes the function intended by its author—then the question becomes, can it be improved?
The compactness of ""Inelegant"" can be improved by the elimination of five steps. But Chaitin proved that compacting an algorithm cannot be automated by a generalized algorithm; rather, it can only be done heuristically; i.e., by exhaustive search (examples to be found at Busy beaver), trial and error, cleverness, insight, application of inductive reasoning, etc. Observe that steps 4, 5 and 6 are repeated in steps 11, 12 and 13. Comparison with ""Elegant"" provides a hint that these steps, together with steps 2 and 3, can be eliminated. This reduces the number of core instructions from thirteen to eight, which makes it ""more elegant"" than ""Elegant"", at nine steps.
The speed of ""Elegant"" can be improved by moving the ""B=0?"" test outside of the two subtraction loops. This change calls for the addition of three instructions (B = 0?, A = 0?, GOTO). Now ""Elegant"" computes the example-numbers faster; whether this is always the case for any given A, B, and R, S would require a detailed analysis.

Algorithmic analysis
It is frequently important to know how much of a particular resource (such as time or storage) is theoretically required for a given algorithm. Methods have been developed for the analysis of algorithms to obtain such quantitative answers (estimates); for example, an algorithm which adds up the elements of a list of n numbers would have a time requirement of O(n){\displaystyle O(n)}, using big O notation. At all times the algorithm only needs to remember two values: the sum of all the elements so far, and its current position in the input list. Therefore, it is said to have a space requirement of O(1){\displaystyle O(1)}, if the space required to store the input numbers is not counted, or O(n){\displaystyle O(n)} if it is counted.
Different algorithms may complete the same task with a different set of instructions in less or more time, space, or 'effort' than others. For example, a binary search algorithm (with cost O(log⁡n){\displaystyle O(\log n)}) outperforms a sequential search (cost O(n){\displaystyle O(n)} ) when used for table lookups on sorted lists or arrays.

Formal versus empirical
The analysis, and study of algorithms is a discipline of computer science, and is often practiced abstractly without the use of a specific programming language or implementation. In this sense, algorithm analysis resembles other mathematical disciplines in that it focuses on the underlying properties of the algorithm and not on the specifics of any particular implementation. Usually pseudocode is used for analysis as it is the simplest and most general representation. However, ultimately, most algorithms are usually implemented on particular hardware/software platforms and their algorithmic efficiency is eventually put to the test using real code. For the solution of a ""one off"" problem, the efficiency of a particular algorithm may not have significant consequences (unless n is extremely large) but for algorithms designed for fast interactive, commercial or long life scientific usage it may be critical. Scaling from small n to large n frequently exposes inefficient algorithms that are otherwise benign.
Empirical testing is useful because it may uncover unexpected interactions that affect performance. Benchmarks may be used to compare before/after potential improvements to an algorithm after program optimization.
Empirical tests cannot replace formal analysis, though, and are not trivial to perform in a fair manner.

Execution efficiency
To illustrate the potential improvements possible even in well-established algorithms, a recent significant innovation, relating to FFT algorithms (used heavily in the field of image processing), can decrease processing time up to 1,000 times for applications like medical imaging. In general, speed improvements depend on special properties of the problem, which are very common in practical applications. Speedups of this magnitude enable computing devices that make extensive use of image processing (like digital cameras and medical equipment) to consume less power.

Classification
There are various ways to classify algorithms, each with its own merits.

By implementation
One way to classify algorithms is by implementation means.

Recursion
A recursive algorithm is one that invokes (makes reference to) itself repeatedly until a certain condition (also known as termination condition) matches, which is a method common to functional programming. Iterative algorithms use repetitive constructs like loops and sometimes additional data structures like stacks to solve the given problems. Some problems are naturally suited for one implementation or the other. For example, towers of Hanoi is well understood using recursive implementation. Every recursive version has an equivalent (but possibly more or less complex) iterative version, and vice versa.
Serial, parallel or distributed
Algorithms are usually discussed with the assumption that computers execute one instruction of an algorithm at a time. Those computers are sometimes called serial computers. An algorithm designed for such an environment is called a serial algorithm, as opposed to parallel algorithms or distributed algorithms. Parallel algorithms are algorithms that take advantage of computer architectures where multiple processors can work on a problem at the same time. Distributed algorithms are algorithms that use multiple machines connected with a computer network. Parallel and distributed algorithms divide the problem into more symmetrical or asymmetrical subproblems and collect the results back together. For example, a CPU would be an example of a parallel algorithm. The resource consumption in such algorithms is not only processor cycles on each processor but also the communication overhead between the processors. Some sorting algorithms can be parallelized efficiently, but their communication overhead is expensive. Iterative algorithms are generally parallelizable, but some problems have no parallel algorithms and are called inherently serial problems.
Deterministic or non-deterministic
Deterministic algorithms solve the problem with exact decision at every step of the algorithm whereas non-deterministic algorithms solve problems via guessing although typical guesses are made more accurate through the use of heuristics.
Exact or approximate
While many algorithms reach an exact solution, approximation algorithms seek an approximation that is closer to the true solution. The approximation can be reached by either using a deterministic or a random strategy. Such algorithms have practical value for many hard problems. One of the examples of an approximate algorithm is the Knapsack problem, where there is a set of given items. Its goal is to pack the knapsack to get the maximum total value. Each item has some weight and some value. Total weight that can be carried is no more than some fixed number X. So, the solution must consider weights of items as well as their value.
Quantum algorithm
Quantum algorithms run on a realistic model of quantum computation. The term is usually used for those algorithms which seem inherently quantum, or use some essential feature of Quantum computing such as quantum superposition or quantum entanglement.

By design paradigm
Another way of classifying algorithms is by their design methodology or paradigm. There is a certain number of paradigms, each different from the other. Furthermore, each of these categories includes many different types of algorithms. Some common paradigms are:

Brute-force or exhaustive search
Brute force is a method of problem-solving that involves systematically trying every possible option until the optimal solution is found. This approach can be very time consuming, as it requires going through every possible combination of variables. However, it is often used when other methods are not available or too complex. Brute force can be used to solve a variety of problems, including finding the shortest path between two points and cracking passwords.
Divide and conquer
A divide-and-conquer algorithm repeatedly reduces an instance of a problem to one or more smaller instances of the same problem (usually recursively) until the instances are small enough to solve easily. One such example of divide and conquer is merge sorting. Sorting can be done on each segment of data after dividing data into segments and sorting of entire data can be obtained in the conquer phase by merging the segments. A simpler variant of divide and conquer is called a decrease-and-conquer algorithm, which solves an identical subproblem and uses the solution of this subproblem to solve the bigger problem. Divide and conquer divides the problem into multiple subproblems and so the conquer stage is more complex than decrease and conquer algorithms. An example of a decrease and conquer algorithm is the binary search algorithm.
Search and enumeration
Many problems (such as playing chess) can be modeled as problems on graphs. A graph exploration algorithm specifies rules for moving around a graph and is useful for such problems. This category also includes search algorithms, branch and bound enumeration and backtracking.
Randomized algorithm
Such algorithms make some choices randomly (or pseudo-randomly). They can be very useful in finding approximate solutions for problems where finding exact solutions can be impractical (see heuristic method below). For some of these problems, it is known that the fastest approximations must involve some randomness. Whether randomized algorithms with polynomial time complexity can be the fastest algorithms for some problems is an open question known as the P versus NP problem. There are two large classes of such algorithms:Monte Carlo algorithms return a correct answer with high-probability. E.g. RP is the subclass of these that run in polynomial time.
Las Vegas algorithms always return the correct answer, but their running time is only probabilistically bound, e.g. ZPP.Reduction of complexity
This technique involves solving a difficult problem by transforming it into a better-known problem for which we have (hopefully) asymptotically optimal algorithms. The goal is to find a reducing algorithm whose complexity is not dominated by the resulting reduced algorithm's. For example, one selection algorithm for finding the median in an unsorted list involves first sorting the list (the expensive portion) and then pulling out the middle element in the sorted list (the cheap portion). This technique is also known as transform and conquer.
Back tracking
In this approach, multiple solutions are built incrementally and abandoned when it is determined that they cannot lead to a valid full solution.

Optimization problems
For optimization problems there is a more specific classification of algorithms; an algorithm for such problems may fall into one or more of the general categories described above as well as into one of the following:

Linear programming
When searching for optimal solutions to a linear function bound to linear equality and inequality constraints, the constraints of the problem can be used directly in producing the optimal solutions. There are algorithms that can solve any problem in this category, such as the popular simplex algorithm. Problems that can be solved with linear programming include the maximum flow problem for directed graphs. If a problem additionally requires that one or more of the unknowns must be an integer then it is classified in integer programming. A linear programming algorithm can solve such a problem if it can be proved that all restrictions for integer values are superficial, i.e., the solutions satisfy these restrictions anyway. In the general case, a specialized algorithm or an algorithm that finds approximate solutions is used, depending on the difficulty of the problem.
Dynamic programming
When a problem shows optimal substructures—meaning the optimal solution to a problem can be constructed from optimal solutions to subproblems—and overlapping subproblems, meaning the same subproblems are used to solve many different problem instances, a quicker approach called dynamic programming avoids recomputing solutions that have already been computed. For example, Floyd–Warshall algorithm, the shortest path to a goal from a vertex in a weighted graph can be found by using the shortest path to the goal from all adjacent vertices. Dynamic programming and memoization go together. The main difference between dynamic programming and divide and conquer is that subproblems are more or less independent in divide and conquer, whereas subproblems overlap in dynamic programming. The difference between dynamic programming and straightforward recursion is in caching or memoization of recursive calls. When subproblems are independent and there is no repetition, memoization does not help; hence dynamic programming is not a solution for all complex problems. By using memoization or maintaining a table of subproblems already solved, dynamic programming reduces the exponential nature of many problems to polynomial complexity.
The greedy method
A greedy algorithm is similar to a dynamic programming algorithm in that it works by examining substructures, in this case not of the problem but of a given solution. Such algorithms start with some solution, which may be given or have been constructed in some way, and improve it by making small modifications. For some problems they can find the optimal solution while for others they stop at local optima, that is, at solutions that cannot be improved by the algorithm but are not optimum. The most popular use of greedy algorithms is for finding the minimal spanning tree where finding the optimal solution is possible with this method. Huffman Tree, Kruskal, Prim, Sollin are greedy algorithms that can solve this optimization problem.
The heuristic method
In optimization problems, heuristic algorithms can be used to find a solution close to the optimal solution in cases where finding the optimal solution is impractical. These algorithms work by getting closer and closer to the optimal solution as they progress. In principle, if run for an infinite amount of time, they will find the optimal solution. Their merit is that they can find a solution very close to the optimal solution in a relatively short time. Such algorithms include local search, tabu search, simulated annealing, and genetic algorithms. Some of them, like simulated annealing, are non-deterministic algorithms while others, like tabu search, are deterministic. When a bound on the error of the non-optimal solution is known, the algorithm is further categorized as an approximation algorithm.

By field of study
Every field of science has its own problems and needs efficient algorithms. Related problems in one field are often studied together. Some example classes are search algorithms, sorting algorithms, merge algorithms, numerical algorithms, graph algorithms, string algorithms, computational geometric algorithms, combinatorial algorithms, medical algorithms, machine learning, cryptography, data compression algorithms and parsing techniques.
Fields tend to overlap with each other, and algorithm advances in one field may improve those of other, sometimes completely unrelated, fields. For example, dynamic programming was invented for optimization of resource consumption in industry but is now used in solving a broad range of problems in many fields.

By complexity
Algorithms can be classified by the amount of time they need to complete compared to their input size:

Constant time: if the time needed by the algorithm is the same, regardless of the input size. E.g. an access to an array element.
Logarithmic time: if the time is a logarithmic function of the input size. E.g. binary search algorithm.
Linear time: if the time is proportional to the input size. E.g. the traverse of a list.
Polynomial time: if the time is a power of the input size. E.g. the bubble sort algorithm has quadratic time complexity.
Exponential time: if the time is an exponential function of the input size. E.g. Brute-force search.Some problems may have multiple algorithms of differing complexity, while other problems might have no algorithms or no known efficient algorithms. There are also mappings from some problems to other problems. Owing to this, it was found to be more suitable to classify the problems themselves instead of the algorithms into equivalence classes based on the complexity of the best possible algorithms for them.

Continuous algorithms
The adjective ""continuous"" when applied to the word ""algorithm"" can mean:

An algorithm operating on data that represents continuous quantities, even though this data is represented by discrete approximations—such algorithms are studied in numerical analysis; or
An algorithm in the form of a differential equation that operates continuously on the data, running on an analog computer.

Algorithm = Logic + Control
In logic programming, algorithms are viewed as having both ""a logic component, which specifies the knowledge to be  used in solving problems, and a control component, which determines the problem-solving strategies by means of which that knowledge is used.""The Euclidean algorithm illustrates this view of an algorithm. Here is a logic programming representation, using :- to represent ""if"", and the relation gcd(A, B, C) to represent the function gcd(A, B) = C: 

In the logic programming language Ciao the gcd relation can be represented directly in functional notation:

The Ciao implementation translates the functional notation into a relational representation in   Prolog, extracting the embedded subtractions, A-B and B-A, as separate conditions:

The resulting program has a purely logical (and ""declarative"") reading, as a recursive (or inductive) definition, which is independent of how the logic is used to solve problems:

Different problem-solving strategies turn the logic into different algorithms. In theory, given a pair of integers A and B, forward (or ""bottom-up"") reasoning could be used to generate all instances of the gcd relation, terminating when the desired gcd of A and B is generated. Of course, forward reasoning is entirely useless in this case. But in other cases, such as the definition of the Fibonacci sequence and Datalog, forward reasoning can be an efficient problem solving strategy. (See for example the logic program for computing fibonacci numbers in Algorithm = Logic + Control).
In contrast with the inefficiency of forward reasoning in this example, backward (or ""top-down"") reasoning using SLD resolution turns the logic into the Euclidean algorithm:

One of the advantages of the logic programming representation of the algorithm is that its purely logical reading makes it easier to verify that the algorithm is correct relative to the standard non-recursive definition of gcd. Here is the standard definition written in Prolog:

This definition, which is the specification of the Euclidean algorithm, is also executable in Prolog: Backward reasoning treats the specification as the brute-force algorithm that iterates through all of the integers C between 1 and A, checking whether C divides both A and B, and then for each such C iterates again through all of the integers D between 1 and A, until it finds a C such that C is greater than or equal to all of the D that also divide both A and B. Although this algorithm is hopelessly inefficient, it shows that formal specifications can often be written in logic programming form, and they can be executed by Prolog, to check that they correctly represent informal requirements.

Legal issues
Algorithms, by themselves, are not usually patentable. In the United States, a claim consisting solely of simple manipulations of abstract concepts, numbers, or signals does not constitute ""processes"" (USPTO 2006), so algorithms are not patentable (as in Gottschalk v. Benson). However practical applications of algorithms are sometimes patentable. For example, in Diamond v. Diehr, the application of a simple feedback algorithm to aid in the curing of synthetic rubber was deemed patentable. The patenting of software is controversial, and there are criticized patents involving algorithms, especially data compression algorithms, such as Unisys's LZW patent.
Additionally, some cryptographic algorithms have export restrictions (see export of cryptography).

History: Development of the notion of ""algorithm""
Ancient Near East
The earliest evidence of algorithms is found in the Babylonian mathematics of ancient Mesopotamia (modern Iraq). A Sumerian clay tablet found in Shuruppak near Baghdad and dated to c. 2500 BC described the earliest division algorithm. During the Hammurabi dynasty c. 1800 – c. 1600 BC, Babylonian clay tablets described algorithms for computing formulas. Algorithms were also used in Babylonian astronomy. Babylonian clay tablets describe and employ algorithmic procedures to compute the time and place of significant astronomical events.Algorithms for arithmetic are also found in ancient Egyptian mathematics, dating back to the Rhind Mathematical Papyrus c. 1550 BC. Algorithms were later used in ancient Hellenistic mathematics. Two examples are the Sieve of Eratosthenes, which was described in the Introduction to Arithmetic by Nicomachus,: Ch 9.2  and the Euclidean algorithm, which was first described in Euclid's Elements (c. 300 BC).: Ch 9.1

Discrete and distinguishable symbols
Tally-marks: To keep track of their flocks, their sacks of grain and their money the ancients used tallying: accumulating stones or marks scratched on sticks or making discrete symbols in clay. Through the Babylonian and Egyptian use of marks and symbols, eventually Roman numerals and the abacus evolved (Dilson, p. 16–41). Tally marks appear prominently in unary numeral system arithmetic used in Turing machine and Post–Turing machine computations.

Manipulation of symbols as ""place holders"" for numbers: algebra
Muhammad ibn Mūsā al-Khwārizmī, a Persian mathematician, wrote the Al-jabr in the 9th century. The terms ""algorism"" and ""algorithm"" are derived from the name al-Khwārizmī, while the term ""algebra"" is derived from the book Al-jabr. In Europe, the word ""algorithm"" was originally used to refer to the sets of rules and techniques used by Al-Khwarizmi to solve algebraic equations, before later being generalized to refer to any set of rules or techniques. This eventually culminated in Leibniz's notion of the calculus ratiocinator (c. 1680):

A good century and a half ahead of his time, Leibniz proposed an algebra of logic, an algebra that would specify the rules for manipulating logical concepts in the manner that ordinary algebra specifies the rules for manipulating numbers.

Cryptographic algorithms
The first cryptographic algorithm for deciphering encrypted code was developed by Al-Kindi, a 9th-century Arab mathematician, in A Manuscript On Deciphering Cryptographic Messages. He gave the first description of cryptanalysis by frequency analysis, the earliest codebreaking algorithm.

Mechanical contrivances with discrete states
The clock: Bolter credits the invention of the weight-driven clock as ""The key invention [of Europe in the Middle Ages]"", in particular, the verge escapement that provides us with the tick and tock of a mechanical clock. ""The accurate automatic machine"" led immediately to ""mechanical automata"" beginning in the 13th century and finally to ""computational machines""—the difference engine and analytical engines of Charles Babbage and Countess Ada Lovelace, mid-19th century. Lovelace is credited with the first creation of an algorithm intended for processing on a computer—Babbage's analytical engine, the first device considered a real Turing-complete computer instead of just a calculator—and is sometimes called ""history's first programmer"" as a result, though a full implementation of Babbage's second device would not be realized until decades after her lifetime.
Logical machines 1870 – Stanley Jevons' ""logical abacus"" and ""logical machine"": The technical problem was to reduce Boolean equations when presented in a form similar to what is now known as Karnaugh maps. Jevons (1880) describes first a simple ""abacus"" of ""slips of wood furnished with pins, contrived so that any part or class of the [logical] combinations can be picked out mechanically ... More recently, however, I have reduced the system to a completely mechanical form, and have thus embodied the whole of the indirect process of inference in what may be called a Logical Machine"" His machine came equipped with ""certain moveable wooden rods"" and ""at the foot are 21 keys like those of a piano [etc.] ..."". With this machine he could analyze a ""syllogism or any other simple logical argument"".This machine he displayed in 1870 before the Fellows of the Royal Society. Another logician John Venn, however, in his 1881 Symbolic Logic, turned a jaundiced eye to this effort: ""I have no high estimate myself of the interest or importance of what are sometimes called logical machines ... it does not seem to me that any contrivances at present known or likely to be discovered really deserve the name of logical machines""; see more at Algorithm characterizations. But not to be outdone he too presented ""a plan somewhat analogous, I apprehend, to Prof. Jevon's abacus ... [And] [a]gain, corresponding to Prof. Jevons's logical machine, the following contrivance may be described. I prefer to call it merely a logical-diagram machine ... but I suppose that it could do very completely all that can be rationally expected of any logical machine"".Jacquard loom, Hollerith punch cards, telegraphy and telephony – the electromechanical relay: Bell and Newell (1971) indicate that the Jacquard loom (1801), precursor to Hollerith cards (punch cards, 1887), and ""telephone switching technologies"" were the roots of a tree leading to the development of the first computers. By the mid-19th century the telegraph, the precursor of the telephone, was in use throughout the world, its discrete and distinguishable encoding of letters as ""dots and dashes"" a common sound. By the late 19th century the ticker tape (c. 1870s) was in use, as was the use of Hollerith cards in the 1890 U.S. census. Then came the teleprinter (c. 1910) with its punched-paper use of Baudot code on tape.
Telephone-switching networks of electromechanical relays (invented 1835) was behind the work of George Stibitz (1937), the inventor of the digital adding device. As he worked in Bell Laboratories, he observed the ""burdensome' use of mechanical calculators with gears. ""He went home one evening in 1937 intending to test his idea... When the tinkering was over, Stibitz had constructed a binary adding device"".The mathematician Martin Davis observes the particular importance of the electromechanical relay (with its two ""binary states"" open and closed):

It was only with the development, beginning in the 1930s, of electromechanical calculators using electrical relays, that machines were built having the scope Babbage had envisioned.""

Mathematics during the 19th century up to the mid-20th century
Symbols and rules: In rapid succession, the mathematics of George Boole (1847, 1854), Gottlob Frege (1879), and Giuseppe Peano (1888–1889) reduced arithmetic to a sequence of symbols manipulated by rules. Peano's The principles of arithmetic, presented by a new method (1888) was ""the first attempt at an axiomatization of mathematics in a symbolic language"".But Heijenoort gives Frege (1879) this kudos: Frege's is ""perhaps the most important single work ever written in logic. ... in which we see a ""'formula language', that is a lingua characterica, a language written with special symbols, ""for pure thought"", that is, free from rhetorical embellishments ... constructed from specific symbols that are manipulated according to definite rules"". The work of Frege was further simplified and amplified by Alfred North Whitehead and Bertrand Russell in their Principia Mathematica (1910–1913).
The paradoxes: At the same time a number of disturbing paradoxes appeared in the literature, in particular, the Burali-Forti paradox (1897), the Russell paradox (1902–03), and the Richard Paradox. The resultant considerations led to Kurt Gödel's paper (1931)—he specifically cites the paradox of the liar—that completely reduces rules of recursion to numbers.
Effective calculability: In an effort to solve the Entscheidungsproblem defined precisely by Hilbert in 1928, mathematicians first set about to define what was meant by an ""effective method"" or ""effective calculation"" or ""effective calculability"" (i.e., a calculation that would succeed). In rapid succession the following appeared: Alonzo Church, Stephen Kleene and J.B. Rosser's λ-calculus a finely honed definition of ""general recursion"" from the work of Gödel acting on suggestions of Jacques Herbrand (cf. Gödel's Princeton lectures of 1934) and subsequent simplifications by Kleene. Church's proof that the Entscheidungsproblem was unsolvable, Emil Post's definition of effective calculability as a worker mindlessly following a list of instructions to move left or right through a sequence of rooms and while there either mark or erase a paper or observe the paper and make a yes-no decision about the next instruction. Alan Turing's proof of that the Entscheidungsproblem was unsolvable by use of his ""a- [automatic-] machine""—in effect almost identical to Post's ""formulation"", J. Barkley Rosser's definition of ""effective method"" in terms of ""a machine"". Kleene's proposal of a precursor to ""Church thesis"" that he called ""Thesis I"", and a few years later Kleene's renaming his Thesis ""Church's Thesis"" and proposing ""Turing's Thesis"".

Emil Post (1936) and Alan Turing (1936–37, 1939)
Emil Post (1936) described the actions of a ""computer"" (human being) as follows:

""...two concepts are involved: that of a symbol space in which the work leading from problem to answer is to be carried out, and a fixed unalterable set of directions.His symbol space would be

""a two-way infinite sequence of spaces or boxes ... The problem solver or worker is to move and work in this symbol space, being capable of being in, and operating in but one box at a time. ... a box is to admit of but two possible conditions, i.e., being empty or unmarked, and having a single mark in it, say a vertical stroke.""One box is to be singled out and called the starting point. ... a specific problem is to be given in symbolic form by a finite number of boxes [i.e., INPUT] being marked with a stroke. Likewise, the answer [i.e., OUTPUT] is to be given in symbolic form by such a configuration of marked boxes...""A set of directions applicable to a general problem sets up a deterministic process when applied to each specific problem. This process terminates only when it comes to the direction of type (C ) [i.e., STOP]"". See more at Post–Turing machineAlan Turing's work preceded that of Stibitz (1937); it is unknown whether Stibitz knew of the work of Turing. Turing's biographer believed that Turing's use of a typewriter-like model derived from a youthful interest: ""Alan had dreamt of inventing typewriters as a boy; Mrs. Turing had a typewriter, and he could well have begun by asking himself what was meant by calling a typewriter 'mechanical'"". Given the prevalence at the time of Morse code, telegraphy, ticker tape machines, and teletypewriters, it is quite possible that all were influences on Turing during his youth.
Turing—his model of computation is now called a Turing machine—begins, as did Post, with an analysis of a human computer that he whittles down to a simple set of basic motions and ""states of mind"". But he continues a step further and creates a machine as a model of computation of numbers.
""Computing is normally done by writing certain symbols on paper. We may suppose this paper is divided into squares like a child's arithmetic book...I assume then that the computation is carried out on one-dimensional paper, i.e., on a tape divided into squares. I shall also suppose that the number of symbols which may be printed is finite...""The behavior of the computer at any moment is determined by the symbols which he is observing, and his ""state of mind"" at that moment. We may suppose that there is a bound B to the number of symbols or squares that the computer can observe at one moment. If he wishes to observe more, he must use successive observations. We will also suppose that the number of states of mind which need be taken into account is finite...""Let us imagine that the operations performed by the computer to be split up into 'simple operations' which are so elementary that it is not easy to imagine them further divided.""Turing's reduction yields the following:

""The simple operations must therefore include:
""(a) Changes of the symbol on one of the observed squares
""(b) Changes of one of the squares observed to another square within L squares of one of the previously observed squares.""It may be that some of these change necessarily invoke a change of state of mind. The most general single operation must, therefore, be taken to be one of the following:

""(A) A possible change (a) of symbol together with a possible change of state of mind.
""(B) A possible change (b) of observed squares, together with a possible change of state of mind""""We may now construct a machine to do the work of this computer.""A few years later, Turing expanded his analysis (thesis, definition) with this forceful expression of it:

""A function is said to be ""effectively calculable"" if its values can be found by some purely mechanical process. Though it is fairly easy to get an intuitive grasp of this idea, it is nevertheless desirable to have some more definite, mathematical expressible definition ... [he discusses the history of the definition pretty much as presented above with respect to Gödel, Herbrand, Kleene, Church, Turing, and Post] ... We may take this statement literally, understanding by a purely mechanical process one which could be carried out by a machine. It is possible to give a mathematical description, in a certain normal form, of the structures of these machines. The development of these ideas leads to the author's definition of a computable function, and to an identification of computability † with effective calculability...
""† We shall use the expression ""computable function"" to mean a function calculable by a machine, and we let ""effectively calculable"" refer to the intuitive idea without particular identification with any one of these definitions"".

J. B. Rosser (1939) and S. C. Kleene (1943)
J. Barkley Rosser defined an ""effective [mathematical] method"" in the following manner (italicization added):

""'Effective method' is used here in the rather special sense of a method each step of which is precisely determined and which is certain to produce the answer in a finite number of steps. With this special meaning, three different precise definitions have been given to date. [his footnote #5; see discussion immediately below]. The simplest of these to state (due to Post and Turing) says essentially that an effective method of solving certain sets of problems exists if one can build a machine which will then solve any problem of the set with no human intervention beyond inserting the question and (later) reading the answer. All three definitions are equivalent, so it doesn't matter which one is used. Moreover, the fact that all three are equivalent is a very strong argument for the correctness of any one."" (Rosser 1939:225–226)Rosser's footnote No. 5 references the work of (1) Church and Kleene and their definition of λ-definability, in particular, Church's use of it in his An Unsolvable Problem of Elementary Number Theory (1936); (2) Herbrand and Gödel and their use of recursion, in particular, Gödel's use in his famous paper On Formally Undecidable Propositions of Principia Mathematica and Related Systems I (1931); and (3) Post (1936) and Turing (1936–37) in their mechanism-models of computation.
Stephen C. Kleene defined as his now-famous ""Thesis I"" known as the Church–Turing thesis. But he did this in the following context (boldface in original):

""12. Algorithmic theories... In setting up a complete algorithmic theory, what we do is to describe a procedure, performable for each set of values of the independent variables, which procedure necessarily terminates and in such manner that from the outcome we can read a definite answer, ""yes"" or ""no,"" to the question, ""is the predicate value true?"""" (Kleene 1943:273)

History after 1950
A number of efforts have been directed toward further refinement of the definition of ""algorithm"", and activity is on-going because of issues surrounding, in particular, foundations of mathematics (especially the Church–Turing thesis) and philosophy of mind (especially arguments about artificial intelligence). For more, see Algorithm characterizations.

See also
Notes
Bibliography
Zaslavsky, C. (1970). Mathematics of the Yoruba People and of Their Neighbors in Southern Nigeria. The Two-Year College Mathematics Journal, 1(2), 76–99. https://doi.org/10.2307/3027363

Further reading
External links

""Algorithm"". Encyclopedia of Mathematics. EMS Press. 2001 [1994].
Algorithms at Curlie
Weisstein, Eric W. ""Algorithm"". MathWorld.
Dictionary of Algorithms and Data Structures – National Institute of Standards and TechnologyAlgorithm repositoriesThe Stony Brook Algorithm Repository – State University of New York at Stony Brook
Collected Algorithms of the ACM – Associations for Computing Machinery
The Stanford GraphBase Archived December 6, 2015, at the Wayback Machine – Stanford University",775,https://en.wikipedia.org/wiki/Algorithm
Coded exposure photography,"Coded exposure photography, also known as a flutter shutter, is the name given to any mathematical algorithm that reduces the effects of motion blur in photography. The key element of the coded exposure process is the mathematical formula that affects the shutter frequency. This involves the calculation of the relationship between the photon exposure of the light sensor and the randomized code. The camera is made to take a series of snapshots with random time intervals using a simple computer, this creates a blurred image that can be reconciled into a clear image using the algorithm.
Motion de-blurring technology grew due to increasing demand for clearer images in sporting events and other digital media. The relative inexpensiveness of the coded exposure technology makes it a viable alternative to expensive cameras and equipment that are built to take millions of images per second.","Coded exposure photography, also known as a flutter shutter, is the name given to any mathematical algorithm that reduces the effects of motion blur in photography. The key element of the coded exposure process is the mathematical formula that affects the shutter frequency. This involves the calculation of the relationship between the photon exposure of the light sensor and the randomized code. The camera is made to take a series of snapshots with random time intervals using a simple computer, this creates a blurred image that can be reconciled into a clear image using the algorithm.
Motion de-blurring technology grew due to increasing demand for clearer images in sporting events and other digital media. The relative inexpensiveness of the coded exposure technology makes it a viable alternative to expensive cameras and equipment that are built to take millions of images per second.

History
Photography was developed to enable imaging of the visible world. Early cameras used film made of plastic coated with compounds of silver. The film is highly sensitive to light. When photons (light) hit the film a reaction occurs which semi-permanently stores the data on its surface. This film is then developed by exposing it to several chemicals to create the image. The film is highly sensitive and the process is complicated. It must be stored away from light to prevent spoilage.Digital cameras use digital technologies to create images. This process involves exposing light-sensitive material to photons, creating electrical signals that are recorded in computer files. This process is simple and has improved the availability of photography. One problem that digital cameras have faced is motion blur. Motion blur occurs when the camera or the subject are in motion. When motion blur happens, the resulting image is blurry, fuzzy edges and indistinct features. One solution to remove motion blur in photography is to increase the shutter speed of the camera. Unlike the coded exposure process, shutter speed is a purely physical process where the camera shutter is opened and closed more quickly, resulting in short exposure time. This reduces the amount of motion that occupies each frame. However shorter exposure times increase the 'noise', which can affect image quality.

Coded exposure
Coded exposure solves the motion blur problem without the negative effects of shorter exposure times. It is an algorithm designed to open the camera's shutter in a pattern that enables the image to be processed in such a way that motion blur and noise are almost completely removed. Contrary to other methods of de-blurring, coded exposure does not require additional hardware beyond a digital camera.The key element of the coded exposure process is the formula that affects the shutter frequency. The process calculates the relationship between the exposure of the light sensor and the randomized code. The digital camera takes a series of snapshots at random intervals. This creates a blurred image that can be clarified given the code or the algorithm. Together with compressed sensing, this technique can be effective.

Application
The relative inexpensiveness of the coded exposure technology makes it a viable alternative to expensive cameras and equipment that take millions of images per second. However, the algorithm and subsequent de-blurring is a complicated process that requires specialists who can write the programs and create templates for companies to work from. Ownership of the technology is subject to dispute; no patent covers it.Coded exposure could have application on live television. Accurate footage of sporting events requires a clear image and detail. Short exposure cameras have been used, but coded exposure is typically available at a lower cost. As of October 2019, the technology had not been widely used outside of a research environment.


== References ==",60746548,https://en.wikipedia.org/wiki/Coded_exposure_photography
Hub labels,"In computer science, hub labels or the hub-labelling algorithm is a speedup technique that consumes much fewer resources than the lookup table but is still extremely fast for finding the shortest paths between nodes in a graph, which may represent, for example, road networks.This method allows at the most with two SELECT statements and the analysis of two strings to compute the shortest path between two vertices of a graph.
For a graph that is oriented like a road graph, this technique requires the prior computation of two tables from structures constructed using the method of the contraction hierarchies. 
In the end, these two computed tables will have as many rows as nodes present within the graph. For each row (each node), a label will be calculated.
A label is a string containing the distance information between the current node (the node of the row) and all the other nodes that can be reached with an ascending search on the relative multi-level structure. The advantage of these distances is that they all represent the shortest paths. 
So, for future queries, the search of a shortest path will start from the source on the first table and the destination on the second table, from which it will search within the labels for the common nodes with the associated distance information. Only the smallest sum of distances will be kept as the shortest path result.","In computer science, hub labels or the hub-labelling algorithm is a speedup technique that consumes much fewer resources than the lookup table but is still extremely fast for finding the shortest paths between nodes in a graph, which may represent, for example, road networks.This method allows at the most with two SELECT statements and the analysis of two strings to compute the shortest path between two vertices of a graph.
For a graph that is oriented like a road graph, this technique requires the prior computation of two tables from structures constructed using the method of the contraction hierarchies. 
In the end, these two computed tables will have as many rows as nodes present within the graph. For each row (each node), a label will be calculated.
A label is a string containing the distance information between the current node (the node of the row) and all the other nodes that can be reached with an ascending search on the relative multi-level structure. The advantage of these distances is that they all represent the shortest paths. 
So, for future queries, the search of a shortest path will start from the source on the first table and the destination on the second table, from which it will search within the labels for the common nodes with the associated distance information. Only the smallest sum of distances will be kept as the shortest path result.

See also
Transit nodes
Contraction Hierarchies
Highway dimension


== References ==",55213052,https://en.wikipedia.org/wiki/Hub_labels
List of algorithm general topics,"This is a list of algorithm general topics.

Analysis of algorithms
Ant colony algorithm
Approximation algorithm
Best and worst cases
Big O notation
Combinatorial search
Competitive analysis
Computability theory
Computational complexity theory
Embarrassingly parallel problem
Emergent algorithm
Evolutionary algorithm
Fast Fourier transform
Genetic algorithm
Graph exploration algorithm
Heuristic
Hill climbing
Implementation
Las Vegas algorithm
Lock-free and wait-free algorithms
Monte Carlo algorithm
Numerical analysis
Online algorithm
Polynomial time approximation scheme
Problem size
Pseudorandom number generator
Quantum algorithm
Random-restart hill climbing
Randomized algorithm
Running time
Sorting algorithm
Search algorithm
Stable algorithm (disambiguation)
Super-recursive algorithm
Tree search algorithm","This is a list of algorithm general topics.

Analysis of algorithms
Ant colony algorithm
Approximation algorithm
Best and worst cases
Big O notation
Combinatorial search
Competitive analysis
Computability theory
Computational complexity theory
Embarrassingly parallel problem
Emergent algorithm
Evolutionary algorithm
Fast Fourier transform
Genetic algorithm
Graph exploration algorithm
Heuristic
Hill climbing
Implementation
Las Vegas algorithm
Lock-free and wait-free algorithms
Monte Carlo algorithm
Numerical analysis
Online algorithm
Polynomial time approximation scheme
Problem size
Pseudorandom number generator
Quantum algorithm
Random-restart hill climbing
Randomized algorithm
Running time
Sorting algorithm
Search algorithm
Stable algorithm (disambiguation)
Super-recursive algorithm
Tree search algorithm

See also
List of algorithms for specific algorithms
List of computability and complexity topics for more abstract theory
List of complexity classes, complexity class
List of data structures.",632487,https://en.wikipedia.org/wiki/List_of_algorithm_general_topics
List of algorithms,"== Broad definition of the term algorithm ==
An algorithm is fundamentally a set of rules or defined procedures that is typically designed and used to solve a specific problem or a broad set of problems. 
Broadly, algorithms define process(es), sets of rules, or methodologies that are to be followed in calculations, data processing, data mining, pattern recognition, automated reasoning or other problem-solving operations. With the increasing automation of services, more and more decisions are being made by algorithms. Some general examples are; risk assessments, anticipatory policing, and pattern recognition technology.The following is a list of well-known algorithms along with one-line descriptions for each.","== Broad definition of the term algorithm ==
An algorithm is fundamentally a set of rules or defined procedures that is typically designed and used to solve a specific problem or a broad set of problems. 
Broadly, algorithms define process(es), sets of rules, or methodologies that are to be followed in calculations, data processing, data mining, pattern recognition, automated reasoning or other problem-solving operations. With the increasing automation of services, more and more decisions are being made by algorithms. Some general examples are; risk assessments, anticipatory policing, and pattern recognition technology.The following is a list of well-known algorithms along with one-line descriptions for each.

Automated planning
Combinatorial algorithms
General combinatorial algorithms
Brent's algorithm: finds a cycle in function value iterations using only two iterators
Floyd's cycle-finding algorithm: finds a cycle in function value iterations
Gale–Shapley algorithm: solves the stable marriage problem
Pseudorandom number generators (uniformly distributed—see also List of pseudorandom number generators for other PRNGs with varying degrees of convergence and varying statistical quality):ACORN generator
Blum Blum Shub
Lagged Fibonacci generator
Linear congruential generator
Mersenne Twister

Graph algorithms
Coloring algorithm: Graph coloring algorithm.
Hopcroft–Karp algorithm: convert a bipartite graph to a maximum cardinality matching
Hungarian algorithm: algorithm for finding a perfect matching
Prüfer coding: conversion between a labeled tree and its Prüfer sequence
Tarjan's off-line lowest common ancestors algorithm: computes lowest common ancestors for pairs of nodes in a tree
Topological sort: finds linear order of nodes (e.g. jobs) based on their dependencies.

Graph drawing
Force-based algorithms (also known as force-directed algorithms or spring-based algorithm)
Spectral layout

Network theory
Network analysis
Link analysis
Girvan–Newman algorithm: detect communities in complex systems
Web link analysis
Hyperlink-Induced Topic Search (HITS) (also known as Hubs and authorities)
PageRank
TrustRank
Flow networks
Dinic's algorithm: is a strongly polynomial algorithm for computing the maximum flow in a flow network.
Edmonds–Karp algorithm: implementation of Ford–Fulkerson
Ford–Fulkerson algorithm: computes the maximum flow in a graph
Karger's algorithm: a Monte Carlo method to compute the minimum cut of a connected graph
Push–relabel algorithm: computes a maximum flow in a graph

Routing for graphs
Edmonds' algorithm (also known as Chu–Liu/Edmonds' algorithm): find maximum or minimum branchings
Euclidean minimum spanning tree: algorithms for computing the minimum spanning tree of a set of points in the plane
Longest path problem: find a simple path of maximum length in a given graph
Minimum spanning tree
Borůvka's algorithm
Kruskal's algorithm
Prim's algorithm
Reverse-delete algorithm
Nonblocking minimal spanning switch say, for a telephone exchange
Shortest path problem
Bellman–Ford algorithm: computes shortest paths in a weighted graph (where some of the edge weights may be negative)
Dijkstra's algorithm: computes shortest paths in a graph with non-negative edge weights
Floyd–Warshall algorithm: solves the all pairs shortest path problem in a weighted, directed graph
Johnson's algorithm: all pairs shortest path algorithm in sparse weighted directed graph
Transitive closure problem: find the transitive closure of a given binary relation
Traveling salesman problem
Christofides algorithm
Nearest neighbour algorithm
Warnsdorff's rule: a heuristic method for solving the Knight's tour problem

Graph search
A*: special case of best-first search that uses heuristics to improve speed
B*: a best-first graph search algorithm that finds the least-cost path from a given initial node to any goal node (out of one or more possible goals)
Backtracking: abandons partial solutions when they are found not to satisfy a complete solution
Beam search: is a heuristic search algorithm that is an optimization of best-first search that reduces its memory requirement
Beam stack search: integrates backtracking with beam search
Best-first search: traverses a graph in the order of likely importance using a priority queue
Bidirectional search: find the shortest path from an initial vertex to a goal vertex in a directed graph
Breadth-first search: traverses a graph level by level
Brute-force search: an exhaustive and reliable search method, but computationally inefficient in many applications
D*: an incremental heuristic search algorithm
Depth-first search: traverses a graph branch by branch
Dijkstra's algorithm: a special case of A* for which no heuristic function is used
General Problem Solver: a seminal theorem-proving algorithm intended to work as a universal problem solver machine.
Iterative deepening depth-first search (IDDFS): a state space search strategy
Jump point search: an optimization to A* which may reduce computation time by an order of magnitude using further heuristics
Lexicographic breadth-first search (also known as Lex-BFS): a linear time algorithm for ordering the vertices of a graph
Uniform-cost search: a tree search that finds the lowest-cost route where costs vary
SSS*: state space search traversing a game tree in a best-first fashion similar to that of the A* search algorithm
F*: special algorithm to merge the two arrays

Subgraphs
Cliques
Bron–Kerbosch algorithm: a technique for finding maximal cliques in an undirected graph
MaxCliqueDyn maximum clique algorithm: find a maximum clique in an undirected graph
Strongly connected components
Path-based strong component algorithm
Kosaraju's algorithm
Tarjan's strongly connected components algorithm
Subgraph isomorphism problem

Sequence algorithms
Approximate sequence matching
Bitap algorithm: fuzzy algorithm that determines if strings are approximately equal.
Phonetic algorithms
Daitch–Mokotoff Soundex: a Soundex refinement which allows matching of Slavic and Germanic surnames
Double Metaphone: an improvement on Metaphone
Match rating approach: a phonetic algorithm developed by Western Airlines
Metaphone: an algorithm for indexing words by their sound, when pronounced in English
NYSIIS: phonetic algorithm, improves on Soundex
Soundex: a phonetic algorithm for indexing names by sound, as pronounced in English
String metrics: computes a similarity or dissimilarity (distance) score between two pairs of text strings
Damerau–Levenshtein distance: computes a distance measure between two strings, improves on Levenshtein distance
Dice's coefficient (also known as the Dice coefficient): a similarity measure related to the Jaccard index
Hamming distance: sum number of positions which are different
Jaro–Winkler distance: is a measure of similarity between two strings
Levenshtein edit distance: computes a metric for the amount of difference between two sequences
Trigram search: search for text when the exact syntax or spelling of the target object is not precisely known

Selection algorithms
Quickselect
Introselect

Sequence search
Linear search: locates an item in an unsorted sequence
Selection algorithm: finds the kth largest item in a sequence
Ternary search: a technique for finding the minimum or maximum of a function that is either strictly increasing and then strictly decreasing or vice versa
Sorted lists
Binary search algorithm: locates an item in a sorted sequence
Fibonacci search technique: search a sorted sequence using a divide and conquer algorithm that narrows down possible locations with the aid of Fibonacci numbers
Jump search (or block search): linear search on a smaller subset of the sequence
Predictive search: binary-like search which factors in magnitude of search term versus the high and low values in the search.  Sometimes called dictionary search or interpolated search.
Uniform binary search: an optimization of the classic binary search algorithm
Eytzinger binary search: cache friendly binary search algorithm

Sequence merging
Simple merge algorithm
k-way merge algorithm
Union (merge, with elements on the output not repeated)

Sequence permutations
Fisher–Yates shuffle (also known as the Knuth shuffle): randomly shuffle a finite set
Schensted algorithm: constructs a pair of Young tableaux from a permutation
Steinhaus–Johnson–Trotter algorithm (also known as the Johnson–Trotter algorithm): generates permutations by transposing elements
Heap's permutation generation algorithm: interchange elements to generate next permutation

Sequence combinations
Sequence alignment
Dynamic time warping: measure similarity between two sequences which may vary in time or speed
Hirschberg's algorithm: finds the least cost sequence alignment between two sequences, as measured by their Levenshtein distance
Needleman–Wunsch algorithm: find global alignment between two sequences
Smith–Waterman algorithm: find local sequence alignment

Sequence sorting
Exchange sorts
Bubble sort: for each pair of indices, swap the items if out of order
Cocktail shaker sort or bidirectional bubble sort, a bubble sort traversing the list alternately from front to back and back to front
Comb sort
Gnome sort
Odd–even sort
Quicksort: divide list into two, with all items on the first list coming before all items on the second list.; then sort the two lists. Often the method of choice
Humorous or ineffective
Bogosort
Slowsort
Stooge sort
Hybrid
Flashsort
Introsort: begin with quicksort and switch to heapsort when the recursion depth exceeds a certain level
Timsort: adaptative algorithm derived from merge sort and insertion sort. Used in Python 2.3 and up, and Java SE 7.
Insertion sorts
Insertion sort: determine where the current item belongs in the list of sorted ones, and insert it there
Library sort
Patience sorting
Shell sort: an attempt to improve insertion sort
Tree sort (binary tree sort): build binary tree, then traverse it to create sorted list
Cycle sort: in-place with theoretically optimal number of writes
Merge sorts
Merge sort: sort the first and second half of the list separately, then merge the sorted lists
Slowsort
Strand sort
Non-comparison sorts
Bead sort
Bucket sort
Burstsort: build a compact, cache efficient burst trie and then traverse it to create sorted output
Counting sort
Pigeonhole sort
Postman sort: variant of Bucket sort which takes advantage of hierarchical structure
Radix sort: sorts strings letter by letter
Selection sorts
Heapsort: convert the list into a heap, keep removing the largest element from the heap and adding it to the end of the list
Selection sort: pick the smallest of the remaining elements, add it to the end of the sorted list
Smoothgamersort
Other
Bitonic sorter
Pancake sorting
Spaghetti sort
Topological sort
Unknown class
Samplesort

Subsequences
Longest common subsequence problem: Find the longest subsequence common to all sequences in a set of sequences
Longest increasing subsequence problem: Find the longest increasing subsequence of a given sequence
Ruzzo–Tompa algorithm: Find all non-overlapping, contiguous, maximal scoring subsequences in a sequence of real numbers
Shortest common supersequence problem: Find the shortest supersequence that contains two or more sequences as subsequences

Substrings
Kadane's algorithm: finds the contiguous subarray with largest sum in an array of numbers
Longest common substring problem: find the longest string (or strings) that is a substring (or are substrings) of two or more strings
Substring search
Aho–Corasick string matching algorithm: trie based algorithm for finding all substring matches to any of a finite set of strings
Boyer–Moore string-search algorithm: amortized linear (sublinear in most times) algorithm for substring search
Boyer–Moore–Horspool algorithm: Simplification of Boyer–Moore
Knuth–Morris–Pratt algorithm: substring search which bypasses reexamination of matched characters
Rabin–Karp string search algorithm: searches multiple patterns efficiently
Zhu–Takaoka string matching algorithm: a variant of Boyer–Moore
Ukkonen's algorithm: a linear-time, online algorithm for constructing suffix trees
Matching wildcards
Rich Salz' wildmat: a widely used open-source recursive algorithm
Krauss matching wildcards algorithm: an open-source non-recursive algorithm

Computational mathematics
Abstract algebra
Chien search: a recursive algorithm for determining roots of polynomials defined over a finite field
Schreier–Sims algorithm: computing a base and strong generating set (BSGS) of a permutation group
Todd–Coxeter algorithm: Procedure for generating cosets.

Computer algebra
Buchberger's algorithm: finds a Gröbner basis
Cantor–Zassenhaus algorithm: factor polynomials over finite fields
Faugère F4 algorithm: finds a Gröbner basis (also mentions the F5 algorithm)
Gosper's algorithm: find sums of hypergeometric terms that are themselves hypergeometric terms
Knuth–Bendix completion algorithm: for rewriting rule systems
Multivariate division algorithm: for polynomials in several indeterminates
Pollard's kangaroo algorithm (also known as Pollard's lambda algorithm ): an algorithm for solving the discrete logarithm problem
Polynomial long division: an algorithm for dividing a polynomial by another polynomial of the same or lower degree
Risch algorithm: an algorithm for the calculus operation of indefinite integration (i.e. finding antiderivatives)

Geometry
Closest pair problem: find the pair of points (from a set of points) with the smallest distance between them
Collision detection algorithms: check for the collision or intersection of two given solids
Cone algorithm: identify surface points
Convex hull algorithms: determining the convex hull of a set of points
Graham scan
Quickhull
Gift wrapping algorithm or Jarvis march
Chan's algorithm
Kirkpatrick–Seidel algorithm
Euclidean distance transform: computes the distance between every point in a grid and a discrete collection of points.
Geometric hashing: a method for efficiently finding two-dimensional objects represented by discrete points that have undergone an affine transformation
Gilbert–Johnson–Keerthi distance algorithm: determining the smallest distance between two convex shapes.
Jump-and-Walk algorithm: an algorithm for point location in triangulations
Laplacian smoothing: an algorithm to smooth a polygonal mesh
Line segment intersection: finding whether lines intersect, usually with a sweep line algorithm
Bentley–Ottmann algorithm
Shamos–Hoey algorithm
Minimum bounding box algorithms: find the oriented minimum bounding box enclosing a set of points
Nearest neighbor search: find the nearest point or points to a query point
Nesting algorithm: make the most efficient use of material or space
Point in polygon algorithms: tests whether a given point lies within a given polygon
Point set registration algorithms: finds the transformation between two point sets to optimally align them.
Rotating calipers: determine all antipodal pairs of points and vertices on a convex polygon or convex hull.
Shoelace algorithm: determine the area of a polygon whose vertices are described by ordered pairs in the plane
Triangulation
Delaunay triangulation
Ruppert's algorithm (also known as Delaunay refinement): create quality Delaunay triangulations
Chew's second algorithm: create quality constrained Delaunay triangulations
Marching triangles: reconstruct two-dimensional surface geometry from an unstructured point cloud
Polygon triangulation algorithms: decompose a polygon into a set of triangles
Voronoi diagrams, geometric dual of Delaunay triangulation
Bowyer–Watson algorithm: create voronoi diagram in any number of dimensions
Fortune's Algorithm: create voronoi diagram
Quasitriangulation

Number theoretic algorithms
Binary GCD algorithm: Efficient way of calculating GCD.
Booth's multiplication algorithm
Chakravala method: a cyclic algorithm to solve indeterminate quadratic equations, including Pell's equation
Discrete logarithm:
Baby-step giant-step
Index calculus algorithm
Pollard's rho algorithm for logarithms
Pohlig–Hellman algorithm
Euclidean algorithm: computes the greatest common divisor
Extended Euclidean algorithm: also solves the equation ax + by = c
Integer factorization: breaking an integer into its prime factors
Congruence of squares
Dixon's algorithm
Fermat's factorization method
General number field sieve
Lenstra elliptic curve factorization
Pollard's p − 1 algorithm
Pollard's rho algorithm
prime factorization algorithm
Quadratic sieve
Shor's algorithm
Special number field sieve
Trial division
Multiplication algorithms: fast multiplication of two numbers
Karatsuba algorithm
Schönhage–Strassen algorithm
Toom–Cook multiplication
Modular square root: computing square roots modulo a prime number
Tonelli–Shanks algorithm
Cipolla's algorithm
Berlekamp's root finding algorithm
Odlyzko–Schönhage algorithm: calculates nontrivial zeroes of the Riemann zeta function
Lenstra–Lenstra–Lovász algorithm (also known as LLL algorithm): find a short, nearly orthogonal lattice basis in polynomial time
Primality tests: determining whether a given number is prime
AKS primality test
Baillie–PSW primality test
Fermat primality test
Lucas primality test
Miller–Rabin primality test
Sieve of Atkin
Sieve of Eratosthenes
Sieve of Sundaram

Numerical algorithms
Differential equation solving
Euler method
Backward Euler method
Trapezoidal rule (differential equations)
Linear multistep methods
Runge–Kutta methods
Euler integration
Multigrid methods (MG methods), a group of algorithms for solving differential equations using a hierarchy of discretizations
Partial differential equation:
Finite difference method
Crank–Nicolson method for diffusion equations
Lax–Wendroff for wave equations
Verlet integration (French pronunciation: [vɛʁˈlɛ]): integrate Newton's equations of motion

Elementary and special functions
Computation of π:
Borwein's algorithm: an algorithm to calculate the value of 1/π
Gauss–Legendre algorithm: computes the digits of pi
Chudnovsky algorithm: a fast method for calculating the digits of π
Bailey–Borwein–Plouffe formula: (BBP formula) a spigot algorithm for the computation of the nth binary digit of π
Division algorithms: for computing quotient and/or remainder of two numbers
Long division
Restoring division
Non-restoring division
SRT division
Newton–Raphson division: uses Newton's method to find the reciprocal of D, and multiply that reciprocal by N to find the final quotient Q.
Goldschmidt division
Hyperbolic and Trigonometric Functions:
BKM algorithm: computes elementary functions using a table of logarithms
CORDIC: computes hyperbolic and trigonometric functions using a table of arctangents
Exponentiation:
Addition-chain exponentiation: exponentiation by positive integer powers that requires a minimal number of multiplications
Exponentiating by squaring: an algorithm used for the fast computation of large integer powers of a number
Montgomery reduction: an algorithm that allows modular arithmetic to be performed efficiently when the modulus is large
Multiplication algorithms: fast multiplication of two numbers
Booth's multiplication algorithm: a multiplication algorithm that multiplies two signed binary numbers in two's complement notation
Fürer's algorithm: an integer multiplication algorithm for very large numbers possessing a very low asymptotic complexity
Karatsuba algorithm: an efficient procedure for multiplying large numbers
Schönhage–Strassen algorithm: an asymptotically fast multiplication algorithm for large integers
Toom–Cook multiplication: (Toom3) a multiplication algorithm for large integers
Multiplicative inverse Algorithms: for computing a number's multiplicative inverse (reciprocal).
Newton's method
Rounding functions: the classic ways to round numbers
Spigot algorithm: a way to compute the value of a mathematical constant without knowing preceding digits
Square and Nth root of a number:
Alpha max plus beta min algorithm: an approximation of the square-root of the sum of two squares
Methods of computing square roots
nth root algorithm
Shifting nth-root algorithm: digit by digit root extraction
Summation:
Binary splitting: a divide and conquer technique which speeds up the numerical evaluation of many types of series with rational terms
Kahan summation algorithm: a more accurate method of summing floating-point numbers
Unrestricted algorithm

Geometric
Filtered back-projection: efficiently computes the inverse 2-dimensional Radon transform.
Level set method (LSM): a numerical technique for tracking interfaces and shapes

Interpolation and extrapolation
Birkhoff interpolation: an extension of polynomial interpolation
Cubic interpolation
Hermite interpolation
Lagrange interpolation: interpolation using Lagrange polynomials
Linear interpolation: a method of curve fitting using linear polynomials
Monotone cubic interpolation: a variant of cubic interpolation that preserves monotonicity of the data set being interpolated.
Multivariate interpolation
Bicubic interpolation: a generalization of cubic interpolation to two dimensions
Bilinear interpolation: an extension of linear interpolation for interpolating functions of two variables on a regular grid
Lanczos resampling (""Lanzosh""): a multivariate interpolation method used to compute new values for any digitally sampled data
Nearest-neighbor interpolation
Tricubic interpolation: a generalization of cubic interpolation to three dimensions
Pareto interpolation: a method of estimating the median and other properties of a population that follows a Pareto distribution.
Polynomial interpolation
Neville's algorithm
Spline interpolation: Reduces error with Runge's phenomenon.
De Boor algorithm: B-splines
De Casteljau's algorithm: Bézier curves
Trigonometric interpolation

Linear algebra
Eigenvalue algorithms
Arnoldi iteration
Inverse iteration
Jacobi method
Lanczos iteration
Power iteration
QR algorithm
Rayleigh quotient iteration
Gram–Schmidt process: orthogonalizes a set of vectors
Matrix multiplication algorithms
Cannon's algorithm: a distributed algorithm for matrix multiplication especially suitable for computers laid out in an N × N mesh
Coppersmith–Winograd algorithm: square matrix multiplication
Freivalds' algorithm: a randomized algorithm used to verify matrix multiplication
Strassen algorithm: faster matrix multiplication

Solving systems of linear equations
Biconjugate gradient method: solves systems of linear equations
Conjugate gradient: an algorithm for the numerical solution of particular systems of linear equations
Gaussian elimination
Gauss–Jordan elimination: solves systems of linear equations
Gauss–Seidel method: solves systems of linear equations iteratively
Levinson recursion: solves equation involving a Toeplitz matrix
Stone's method: also known as the strongly implicit procedure or SIP, is an algorithm for solving a sparse linear system of equations
Successive over-relaxation (SOR): method used to speed up convergence of the Gauss–Seidel method
Tridiagonal matrix algorithm (Thomas algorithm): solves systems of tridiagonal equations
Sparse matrix algorithms
Cuthill–McKee algorithm: reduce the bandwidth of a symmetric sparse matrix
Minimum degree algorithm: permute the rows and columns of a symmetric sparse matrix before applying the Cholesky decomposition
Symbolic Cholesky decomposition: Efficient way of storing sparse matrix

Monte Carlo
Gibbs sampling: generates a sequence of samples from the joint probability distribution of two or more random variables
Hybrid Monte Carlo: generates a sequence of samples using Hamiltonian weighted Markov chain Monte Carlo, from a probability distribution which is difficult to sample directly.
Metropolis–Hastings algorithm: used to generate a sequence of samples from the probability distribution of one or more variables
Wang and Landau algorithm: an extension of Metropolis–Hastings algorithm sampling

Numerical integration
MISER algorithm: Monte Carlo simulation, numerical integration

Root finding
Bisection method
False position method: and Illinois method: 2-point, bracketing
Halley's method: uses first and second derivatives
ITP method: minmax optimal and superlinear convergence simultaneously
Muller's method: 3-point, quadratic interpolation
Newton's method: finds zeros of functions with calculus
Ridder's method: 3-point, exponential scaling
Secant method: 2-point, 1-sided

Optimization algorithms
Hybrid Algorithms
Alpha–beta pruning: search to reduce number of nodes in minimax algorithm
Branch and bound
Bruss algorithm: see odds algorithm
Chain matrix multiplication
Combinatorial optimization: optimization problems where the set of feasible solutions is discrete
Greedy randomized adaptive search procedure (GRASP): successive constructions of a greedy randomized solution and subsequent iterative improvements of it through a local search
Hungarian method: a combinatorial optimization algorithm which solves the assignment problem in polynomial time
Constraint satisfaction
General algorithms for the constraint satisfaction
AC-3 algorithm
Difference map algorithm
Min conflicts algorithm
Chaff algorithm: an algorithm for solving instances of the Boolean satisfiability problem
Davis–Putnam algorithm: check the validity of a first-order logic formula
Davis–Putnam–Logemann–Loveland algorithm (DPLL): an algorithm for deciding the satisfiability of propositional logic formula in conjunctive normal form, i.e. for solving the CNF-SAT problem
Exact cover problem
Algorithm X: a nondeterministic algorithm
Dancing Links: an efficient implementation of Algorithm X
Cross-entropy method: a general Monte Carlo approach to combinatorial and continuous multi-extremal optimization and importance sampling
Differential evolution
Dynamic Programming: problems exhibiting the properties of overlapping subproblems and optimal substructure
Ellipsoid method: is an algorithm for solving convex optimization problems
Evolutionary computation: optimization inspired by biological mechanisms of evolution
Evolution strategy
Gene expression programming
Genetic algorithms
Fitness proportionate selection – also known as roulette-wheel selection
Stochastic universal sampling
Truncation selection
Tournament selection
Memetic algorithm
Swarm intelligence
Ant colony optimization
Bees algorithm: a search algorithm which mimics the food foraging behavior of swarms of honey bees
Particle swarm
Frank-Wolfe algorithm: an iterative first-order optimization algorithm for constrained convex optimization
Golden-section search: an algorithm for finding the maximum of a real function
Gradient descent
Grid Search
Harmony search (HS): a metaheuristic algorithm mimicking the improvisation process of musicians
Interior point method
Linear programming
Benson's algorithm: an algorithm for solving linear vector optimization problems
Dantzig–Wolfe decomposition: an algorithm for solving linear programming problems with special structure
Delayed column generation
Integer linear programming: solve linear programming problems where some or all the unknowns are restricted to integer values
Branch and cut
Cutting-plane method
Karmarkar's algorithm: The first reasonably efficient algorithm that solves the linear programming problem in polynomial time.
Simplex algorithm: an algorithm for solving linear programming problems
Line search
Local search: a metaheuristic for solving computationally hard optimization problems
Random-restart hill climbing
Tabu search
Minimax used in game programming
Nearest neighbor search (NNS): find closest points in a metric space
Best Bin First: find an approximate solution to the nearest neighbor search problem in very-high-dimensional spaces
Newton's method in optimization
Nonlinear optimization
BFGS method: a nonlinear optimization algorithm
Gauss–Newton algorithm: an algorithm for solving nonlinear least squares problems
Levenberg–Marquardt algorithm: an algorithm for solving nonlinear least squares problems
Nelder–Mead method (downhill simplex method): a nonlinear optimization algorithm
Odds algorithm (Bruss algorithm): Finds the optimal strategy to predict a last specific event in a random sequence event
Random Search
Simulated annealing
Stochastic tunneling
Subset sum algorithm
A hybrid HS-LS conjugate gradient algorithm (see https://doi.org/10.1016/j.cam.2023.115304)
A hybrid BFGS-Like method (see more https://doi.org/10.1016/j.cam.2024.115857)
Conjugate gradient methods (see more https://doi.org/10.1016/j.jksus.2022.101923)

Computational science
Astronomy
Doomsday algorithm: day of the week
Zeller's congruence is an algorithm to calculate the day of the week for any Julian or Gregorian calendar date
various Easter algorithms are used to calculate the day of Easter

Bioinformatics
Basic Local Alignment Search Tool also known as BLAST: an algorithm for comparing primary biological sequence information
Kabsch algorithm: calculate the optimal alignment of two sets of points in order to compute the root mean squared deviation between two protein structures.
Velvet: a set of algorithms manipulating de Bruijn graphs for genomic sequence assembly
Sorting by signed reversals: an algorithm for understanding genomic evolution.
Maximum parsimony (phylogenetics): an algorithm for finding the simplest phylogenetic tree to explain a given character matrix.
UPGMA: a distance-based phylogenetic tree construction algorithm.
Bloom Filter: probabilistic data structure used to test for the existence of an element within a set. Primarily used in bioinformatics to test for the existence of a k-mer in a sequence or sequences.

Geoscience
Vincenty's formulae: a fast algorithm to calculate the distance between two latitude/longitude points on an ellipsoid
Geohash: a public domain algorithm that encodes a decimal latitude/longitude pair as a hash string

Linguistics
Lesk algorithm: word sense disambiguation
Stemming algorithm: a method of reducing words to their stem, base, or root form
Sukhotin's algorithm: a statistical classification algorithm for classifying characters in a text as vowels or consonants

Medicine
ESC algorithm for the diagnosis of heart failure
Manning Criteria for irritable bowel syndrome
Pulmonary embolism diagnostic algorithms
Texas Medication Algorithm Project

Physics
Constraint algorithm: a class of algorithms for satisfying constraints for bodies that obey Newton's equations of motion
Demon algorithm: a Monte Carlo method for efficiently sampling members of a microcanonical ensemble with a given energy
Featherstone's algorithm: computes the effects of forces applied to a structure of joints and links
Ground state approximation
Variational method
Ritz method
n-body problems
Barnes–Hut simulation: Solves the n-body problem in an approximate way that has the order O(n log n) instead of O(n2) as in a direct-sum simulation.
Fast multipole method (FMM): speeds up the calculation of long-ranged forces
Rainflow-counting algorithm: Reduces a complex stress history to a count of elementary stress-reversals for use in fatigue analysis
Sweep and prune: a broad phase algorithm used during collision detection to limit the number of pairs of solids that need to be checked for collision
VEGAS algorithm: a method for reducing error in Monte Carlo simulations
Glauber dynamics: a method for simulating the Ising Model on a computer

Statistics
Algorithms for calculating variance: avoiding instability and numerical overflow
Approximate counting algorithm: allows counting large number of events in a small register
Bayesian statistics
Nested sampling algorithm: a computational approach to the problem of comparing models in Bayesian statistics
Clustering Algorithms
Average-linkage clustering: a simple agglomerative clustering algorithm
Canopy clustering algorithm: an unsupervised pre-clustering algorithm related to the K-means algorithm
Complete-linkage clustering: a simple agglomerative clustering algorithm
DBSCAN: a density based clustering algorithm
Expectation-maximization algorithm
Fuzzy clustering: a class of clustering algorithms where each point has a degree of belonging to clusters
Fuzzy c-means
FLAME clustering (Fuzzy clustering by Local Approximation of MEmberships): define clusters in the dense parts of a dataset and perform cluster assignment solely based on the neighborhood relationships among objects
KHOPCA clustering algorithm: a local clustering algorithm, which produces hierarchical multi-hop clusters in static and mobile environments.
k-means clustering: cluster objects based on attributes into partitions
k-means++: a variation of this, using modified random seeds
k-medoids: similar to k-means, but chooses datapoints or medoids as centers
Linde–Buzo–Gray algorithm: a vector quantization algorithm to derive a good codebook
Lloyd's algorithm (Voronoi iteration or relaxation): group data points into a given number of categories, a popular algorithm for k-means clustering
OPTICS: a density based clustering algorithm with a visual evaluation method
Single-linkage clustering: a simple agglomerative clustering algorithm
SUBCLU: a subspace clustering algorithm
Ward's method: an agglomerative clustering algorithm, extended to more general Lance–Williams algorithms
WACA clustering algorithm: a local clustering algorithm with potentially multi-hop structures; for dynamic networks
Estimation Theory
Expectation-maximization algorithm A class of related algorithms for finding maximum likelihood estimates of parameters in probabilistic models
Ordered subset expectation maximization (OSEM): used in medical imaging for positron emission tomography, single-photon emission computed tomography and X-ray computed tomography.
Odds algorithm (Bruss algorithm) Optimal online search for distinguished value in sequential random input
Kalman filter: estimate the state of a linear dynamic system from a series of noisy measurements
False nearest neighbor algorithm (FNN) estimates fractal dimension
Hidden Markov model
Baum–Welch algorithm: computes maximum likelihood estimates and posterior mode estimates for the parameters of a hidden Markov model
Forward-backward algorithm: a dynamic programming algorithm for computing the probability of a particular observation sequence
Viterbi algorithm: find the most likely sequence of hidden states in a hidden Markov model
Partial least squares regression: finds a linear model describing some predicted variables in terms of other observable variables
Queuing theory
Buzen's algorithm: an algorithm for calculating the normalization constant G(K) in the Gordon–Newell theorem
RANSAC (an abbreviation for ""RANdom SAmple Consensus""): an iterative method to estimate parameters of a mathematical model from a set of observed data which contains outliers
Scoring algorithm: is a form of Newton's method used to solve maximum likelihood equations numerically
Yamartino method: calculate an approximation to the standard deviation σθ of wind direction θ during a single pass through the incoming data
Ziggurat algorithm: generates random numbers from a non-uniform distribution

Computer science
Computer architecture
Tomasulo algorithm: allows sequential instructions that would normally be stalled due to certain dependencies to execute non-sequentially

Computer graphics
Clipping
Line clipping
Cohen–Sutherland
Cyrus–Beck
Fast-clipping
Liang–Barsky
Nicholl–Lee–Nicholl
Polygon clipping
Sutherland–Hodgman
Vatti
Weiler–Atherton
Contour lines and Isosurfaces
Marching cubes: extract a polygonal mesh of an isosurface from a three-dimensional scalar field (sometimes called voxels)
Marching squares: generates contour lines for a two-dimensional scalar field
Marching tetrahedrons: an alternative to Marching cubes
Discrete Green's Theorem: is an algorithm for computing double integral over a generalized rectangular domain in constant time.  It is a natural extension to the summed area table algorithm
Flood fill: fills a connected region of a multi-dimensional array with a specified symbol
Global illumination algorithms: Considers direct illumination and reflection from other objects.
Ambient occlusion
Beam tracing
Cone tracing
Image-based lighting
Metropolis light transport
Path tracing
Photon mapping
Radiosity
Ray tracing
Hidden-surface removal or Visual surface determination
Newell's algorithm: eliminate polygon cycles in the depth sorting required in hidden-surface removal
Painter's algorithm: detects visible parts of a 3-dimensional scenery
Scanline rendering: constructs an image by moving an imaginary line over the image
Warnock algorithm
Line Drawing: graphical algorithm for approximating a line segment on discrete graphical media.
Bresenham's line algorithm: plots points of a 2-dimensional array to form a straight line between 2 specified points (uses decision variables)
DDA line algorithm: plots points of a 2-dimensional array to form a straight line between 2 specified points (uses floating-point math)
Xiaolin Wu's line algorithm: algorithm for line antialiasing.
Midpoint circle algorithm: an algorithm used to determine the points needed for drawing a circle
Ramer–Douglas–Peucker algorithm: Given a 'curve' composed of line segments to find a curve not too dissimilar but that has fewer points
Shading
Gouraud shading: an algorithm to simulate the differing effects of light and colour across the surface of an object in 3D computer graphics
Phong shading: an algorithm to interpolate surface normal-vectors for surface shading in 3D computer graphics
Slerp (spherical linear interpolation): quaternion interpolation for the purpose of animating 3D rotation
Summed area table (also known as an integral image): an algorithm for computing the sum of values in a rectangular subset of a grid in constant time
Binary space partitioning

Cryptography
Asymmetric (public key) encryption:
ElGamal
Elliptic curve cryptography
MAE1
NTRUEncrypt
RSA
Digital signatures (asymmetric authentication):
DSA, and its variants:
ECDSA and Deterministic ECDSA
EdDSA (Ed25519)
RSA
Cryptographic hash functions (see also the section on message authentication codes):
BLAKE
MD5 – Note that there is now a method of generating collisions for MD5
RIPEMD-160
SHA-1 – Note that there is now a method of generating collisions for SHA-1
SHA-2 (SHA-224, SHA-256, SHA-384, SHA-512)
SHA-3 (SHA3-224, SHA3-256, SHA3-384, SHA3-512, SHAKE128, SHAKE256)
Tiger (TTH), usually used in Tiger tree hashes
WHIRLPOOL
Cryptographically secure pseudo-random number generators
Blum Blum Shub – based on the hardness of factorization
Fortuna, intended as an improvement on Yarrow algorithm
Linear-feedback shift register (note: many LFSR-based algorithms are weak or have been broken)
Yarrow algorithm
Key exchange
Diffie–Hellman key exchange
Elliptic-curve Diffie–Hellman (ECDH)
Key derivation functions, often used for password hashing and key stretching
bcrypt
PBKDF2
scrypt
Argon2
Message authentication codes (symmetric authentication algorithms, which take a key as a parameter):
HMAC: keyed-hash message authentication
Poly1305
SipHash
Secret sharing, Secret Splitting, Key Splitting, M of N algorithms
Blakey's Scheme
Shamir's Scheme
Symmetric (secret key) encryption:
Advanced Encryption Standard (AES), winner of NIST competition, also known as Rijndael
Blowfish
Twofish
Threefish
Data Encryption Standard (DES), sometimes DE Algorithm, winner of NBS selection competition, replaced by AES for most purposes
IDEA
RC4 (cipher)
Tiny Encryption Algorithm (TEA)
Salsa20, and its updated variant ChaCha20
Post-quantum cryptography
Proof-of-work algorithms

Digital logic
Boolean minimization
Quine–McCluskey algorithm: also called as Q-M algorithm, programmable method for simplifying the Boolean equations
Petrick's method: another algorithm for Boolean simplification
Espresso heuristic logic minimizer: a fast algorithm for Boolean function minimization

Machine learning and statistical classification
Almeida–Pineda recurrent backpropagation: Adjust a matrix of synaptic weights to generate desired outputs given its inputs
ALOPEX: a correlation-based machine-learning algorithm
Association rule learning: discover interesting relations between variables, used in data mining
Apriori algorithm
Eclat algorithm
FP-growth algorithm
One-attribute rule
Zero-attribute rule
Boosting (meta-algorithm): Use many weak learners to boost effectiveness
AdaBoost: adaptive boosting
BrownBoost: a boosting algorithm that may be robust to noisy datasets
LogitBoost: logistic regression boosting
LPBoost: linear programming boosting
Bootstrap aggregating (bagging): technique to improve stability and classification accuracy
Computer Vision
Grabcut based on Graph cuts
Decision Trees
C4.5 algorithm: an extension to ID3
ID3 algorithm (Iterative Dichotomiser 3): use heuristic to generate small decision trees
Clustering: a class of unsupervised learning algorithms for grouping and bucketing related input vector.
k-nearest neighbors (k-NN): a method for classifying objects based on closest training examples in the feature space
Linde–Buzo–Gray algorithm: a vector quantization algorithm used to derive a good codebook
Locality-sensitive hashing (LSH): a method of performing probabilistic dimension reduction of high-dimensional data
Neural Network
Backpropagation: a supervised learning method which requires a teacher that knows, or can calculate, the desired output for any given input
Hopfield net: a Recurrent neural network in which all connections are symmetric
Perceptron: the simplest kind of feedforward neural network: a linear classifier.
Pulse-coupled neural networks (PCNN): Neural models proposed by modeling a cat's visual cortex and developed for high-performance biomimetic image processing.
Radial basis function network: an artificial neural network that uses radial basis functions as activation functions
Self-organizing map: an unsupervised network that produces a low-dimensional representation of the input space of the training samples
Random forest: classify using many decision trees
Reinforcement learning:
Q-learning: learns an action-value function that gives the expected utility of taking a given action in a given state and following a fixed policy thereafter
State–Action–Reward–State–Action (SARSA): learn a Markov decision process policy
Temporal difference learning
Relevance-Vector Machine (RVM): similar to SVM, but provides probabilistic classification
Supervised learning: Learning by examples (labelled data-set split into training-set and test-set)
Support Vector Machine (SVM): a set of methods which divide multidimensional data by finding a dividing hyperplane with the maximum margin between the two sets
Structured SVM: allows training of a classifier for general structured output labels.
Winnow algorithm: related to the perceptron, but uses a multiplicative weight-update scheme

Programming language theory
C3 linearization: an algorithm used primarily to obtain a consistent linearization of a multiple inheritance hierarchy in object-oriented programming
Chaitin's algorithm: a bottom-up, graph coloring register allocation algorithm that uses cost/degree as its spill metric
Hindley–Milner type inference algorithm
Rete algorithm: an efficient pattern matching algorithm for implementing production rule systems
Sethi-Ullman algorithm: generates optimal code for arithmetic expressions

Parsing
CYK algorithm: an O(n3) algorithm for parsing context-free grammars in Chomsky normal form
Earley parser: another O(n3) algorithm for parsing any context-free grammar
GLR parser: an algorithm for parsing any context-free grammar by Masaru Tomita. It is tuned for deterministic grammars, on which it performs almost linear time and O(n3) in worst case.
Inside-outside algorithm: an O(n3) algorithm for re-estimating production probabilities in probabilistic context-free grammars
LL parser: a relatively simple linear time parsing algorithm for a limited class of context-free grammars
LR parser: A more complex linear time parsing algorithm for a larger class of context-free grammars.  Variants:
Canonical LR parser
LALR (look-ahead LR) parser
Operator-precedence parser
SLR (Simple LR) parser
Simple precedence parser
Packrat parser: a linear time parsing algorithm supporting some context-free grammars and parsing expression grammars
Recursive descent parser: a top-down parser suitable for LL(k) grammars
Shunting-yard algorithm: converts an infix-notation math expression to postfix
Pratt parser
Lexical analysis

Quantum algorithms
Deutsch–Jozsa algorithm: criterion of balance for Boolean function
Grover's algorithm: provides quadratic speedup for many search problems
Shor's algorithm: provides exponential speedup (relative to currently known non-quantum algorithms) for factoring a number
Simon's algorithm: provides a provably exponential speedup (relative to any non-quantum algorithm) for a black-box problem

Theory of computation and automata
Hopcroft's algorithm, Moore's algorithm, and Brzozowski's algorithm: algorithms for minimizing the number of states in a deterministic finite automaton
Powerset construction: algorithm to convert nondeterministic automaton to deterministic automaton.
Tarski–Kuratowski algorithm: a non-deterministic algorithm which provides an upper bound for the complexity of formulas in the arithmetical hierarchy and analytical hierarchy

Information theory and signal processing
Coding theory
Error detection and correction
BCH Codes
Berlekamp–Massey algorithm
Peterson–Gorenstein–Zierler algorithm
Reed–Solomon error correction
BCJR algorithm: decoding of error correcting codes defined on trellises (principally convolutional codes)
Forward error correction
Gray code
Hamming codes
Hamming(7,4): a Hamming code that encodes 4 bits of data into 7 bits by adding 3 parity bits
Hamming distance: sum number of positions which are different
Hamming weight (population count): find the number of 1 bits in a binary word
Redundancy checks
Adler-32
Cyclic redundancy check
Damm algorithm
Fletcher's checksum
Longitudinal redundancy check (LRC)
Luhn algorithm: a method of validating identification numbers
Luhn mod N algorithm: extension of Luhn to non-numeric characters
Parity: simple/fast error detection technique
Verhoeff algorithm

Lossless compression algorithms
Burrows–Wheeler transform: preprocessing useful for improving lossless compression
Context tree weighting
Delta encoding: aid to compression of data in which sequential data occurs frequently
Dynamic Markov compression: Compression using predictive arithmetic coding
Dictionary coders
Byte pair encoding (BPE)
Deflate
Lempel–Ziv
LZ77 and LZ78
Lempel–Ziv Jeff Bonwick (LZJB)
Lempel–Ziv–Markov chain algorithm (LZMA)
Lempel–Ziv–Oberhumer (LZO): speed oriented
Lempel–Ziv–Stac (LZS)
Lempel–Ziv–Storer–Szymanski (LZSS)
Lempel–Ziv–Welch (LZW)
LZWL: syllable-based variant
LZX
Lempel–Ziv Ross Williams (LZRW)
Entropy encoding: coding scheme that assigns codes to symbols so as to match code lengths with the probabilities of the symbols
Arithmetic coding: advanced entropy coding
Range encoding: same as arithmetic coding, but looked at in a slightly different way
Huffman coding: simple lossless compression taking advantage of relative character frequencies
Adaptive Huffman coding: adaptive coding technique based on Huffman coding
Package-merge algorithm: Optimizes Huffman coding subject to a length restriction on code strings
Shannon–Fano coding
Shannon–Fano–Elias coding: precursor to arithmetic encoding
Entropy coding with known entropy characteristics
Golomb coding: form of entropy coding that is optimal for alphabets following geometric distributions
Rice coding: form of entropy coding that is optimal for alphabets following geometric distributions
Truncated binary encoding
Unary coding: code that represents a number n with n ones followed by a zero
Universal codes: encodes positive integers into binary code words
Elias delta, gamma, and omega coding
Exponential-Golomb coding
Fibonacci coding
Levenshtein coding
Fast Efficient & Lossless Image Compression System (FELICS): a lossless image compression algorithm
Incremental encoding: delta encoding applied to sequences of strings
Prediction by partial matching (PPM): an adaptive statistical data compression technique based on context modeling and prediction
Run-length encoding: lossless data compression taking advantage of strings of repeated characters
SEQUITUR algorithm: lossless compression by incremental grammar inference on a string

Lossy compression algorithms
3Dc: a lossy data compression algorithm for normal maps
Audio and Speech compression
A-law algorithm: standard companding algorithm
Code-excited linear prediction (CELP): low bit-rate speech compression
Linear predictive coding (LPC): lossy compression by representing the spectral envelope of a digital signal of speech in compressed form
Mu-law algorithm: standard analog signal compression or companding algorithm
Warped Linear Predictive Coding (WLPC)
Image compression
Block Truncation Coding (BTC): a type of lossy image compression technique for greyscale images
Embedded Zerotree Wavelet (EZW)
Fast Cosine Transform algorithms (FCT algorithms): computes Discrete Cosine Transform (DCT) efficiently
Fractal compression: method used to compress images using fractals
Set Partitioning in Hierarchical Trees (SPIHT)
Wavelet compression: form of data compression well suited for image compression (sometimes also video compression and audio compression)
Transform coding: type of data compression for ""natural"" data like audio signals or photographic images
Video compression
Vector quantization: technique often used in lossy data compression

Digital signal processing
Adaptive-additive algorithm (AA algorithm): find the spatial frequency phase of an observed wave source
Discrete Fourier transform: determines the frequencies contained in a (segment of a) signal
Bluestein's FFT algorithm
Bruun's FFT algorithm
Cooley–Tukey FFT algorithm
Fast Fourier transform
Prime-factor FFT algorithm
Rader's FFT algorithm
Fast folding algorithm: an efficient algorithm for the detection of approximately periodic events within time series data
Gerchberg–Saxton algorithm: Phase retrieval algorithm for optical planes
Goertzel algorithm: identify a particular frequency component in a signal.  Can be used for DTMF digit decoding.
Karplus-Strong string synthesis: physical modelling synthesis to simulate the sound of a hammered or plucked string or some types of percussion

Image processing
Contrast Enhancement
Histogram equalization: use histogram to improve image contrast
Adaptive histogram equalization: histogram equalization which adapts to local changes in contrast
Connected-component labeling: find and label disjoint regions
Dithering and half-toning
Error diffusion
Floyd–Steinberg dithering
Ordered dithering
Riemersma dithering
Elser difference-map algorithm: a search algorithm for general constraint satisfaction problems.  Originally used for X-Ray diffraction microscopy
Feature detection
Canny edge detector: detect a wide range of edges in images
Generalised Hough transform
Hough transform
Marr–Hildreth algorithm: an early edge detection algorithm
SIFT (Scale-invariant feature transform): is an algorithm to detect and describe local features in images.
SURF (Speeded Up Robust Features): is a robust local feature detector, first presented by Herbert Bay et al. in 2006, that can be used in computer vision tasks like object recognition or 3D reconstruction. It is partly inspired by the SIFT descriptor. The standard version of SURF is several times faster than SIFT and claimed by its authors to be more robust against different image transformations than SIFT.
Richardson–Lucy deconvolution: image de-blurring algorithm
Blind deconvolution: image de-blurring algorithm when point spread function is unknown.
Median filtering
Seam carving: content-aware image resizing algorithm
Segmentation: partition a digital image into two or more regions
GrowCut algorithm: an interactive segmentation algorithm
Random walker algorithm
Region growing
Watershed transformation: a class of algorithms based on the watershed analogy

Software engineering
Cache algorithms
CHS conversion: converting between disk addressing systems
Double dabble: Convert binary numbers to BCD
Hash Function: convert a large, possibly variable-sized amount of data into a small datum, usually a single integer that may serve as an index into an array
Fowler–Noll–Vo hash function: fast with low collision rate
Pearson hashing: computes 8 bit value only, optimized for 8 bit computers
Zobrist hashing: used in the implementation of transposition tables
Unicode Collation Algorithm
Xor swap algorithm: swaps the values of two variables without using a buffer

Database algorithms
Algorithms for Recovery and Isolation Exploiting Semantics (ARIES): transaction recovery
Join algorithms
Block nested loop
Hash join
Nested loop join
Sort-Merge Join
 The Chase

Distributed systems algorithms
Clock synchronization
Berkeley algorithm
Cristian's algorithm
Intersection algorithm
Marzullo's algorithm
Consensus (computer science): agreeing on a single value or history among unreliable processors
Chandra–Toueg consensus algorithm
Paxos algorithm
Raft (computer science)
Detection of Process Termination
Dijkstra-Scholten algorithm
Huang's algorithm
Lamport ordering: a partial ordering of events based on the happened-before relation
Leader election: a method for dynamically selecting a coordinator
Bully algorithm
Mutual exclusion
Lamport's Distributed Mutual Exclusion Algorithm
Naimi-Trehel's log(n) Algorithm
Maekawa's Algorithm
Raymond's Algorithm
Ricart–Agrawala Algorithm
Snapshot algorithm: record a consistent global state for an asynchronous system
Chandy–Lamport algorithm
Vector clocks: generate a partial ordering of events in a distributed system and detect causality violations

Memory allocation and deallocation algorithms
Buddy memory allocation: an algorithm to allocate memory such with less fragmentation
Garbage collectors
Cheney's algorithm: an improvement on the Semi-space collector
Generational garbage collector: Fast garbage collectors that segregate memory by age
Mark-compact algorithm: a combination of the mark-sweep algorithm and Cheney's copying algorithm
Mark and sweep
Semi-space collector: an early copying collector
Reference counting

Networking
Karn's algorithm: addresses the problem of getting accurate estimates of the round-trip time for messages when using TCP
Luleå algorithm: a technique for storing and searching internet routing tables efficiently
Network congestion
Exponential backoff
Nagle's algorithm: improve the efficiency of TCP/IP networks by coalescing packets
Truncated binary exponential backoff

Operating systems algorithms
Banker's algorithm: algorithm used for deadlock avoidance
Page replacement algorithms: for selecting the victim page under low memory conditions
Adaptive replacement cache: better performance than LRU
Clock with Adaptive Replacement (CAR): a page replacement algorithm with performance comparable to adaptive replacement cache

Process synchronization
Dekker's algorithm
Lamport's Bakery algorithm
Peterson's algorithm

Scheduling
Earliest deadline first scheduling
Fair-share scheduling
Least slack time scheduling
List scheduling
Multi level feedback queue
Rate-monotonic scheduling
Round-robin scheduling
Shortest job next
Shortest remaining time
Top-nodes algorithm: resource calendar management

I/O scheduling
Disk scheduling
Elevator algorithm: Disk scheduling algorithm that works like an elevator.
Shortest seek first: Disk scheduling algorithm to reduce seek time.

Other
'For You' algorithm: a proprietary algorithm developed by the social media network Tik-Tok. Uploaded videos are released first to a selection of users who have been identified by the algorithm as being likely to engage with the video, based on their previous web-site viewing patterns.

See also
List of data structures
List of machine learning algorithms
List of pathfinding algorithms
List of algorithm general topics
List of terms relating to algorithms and data structures
Heuristic


== References ==",18568,https://en.wikipedia.org/wiki/List_of_algorithms
Unrestricted algorithm,"An unrestricted algorithm is an algorithm for the computation of a mathematical function that puts no restrictions on the range of the argument or on the precision that may be demanded in the result. The idea of such an algorithm was put forward by C. W. Clenshaw and F. W. J. Olver in a paper published in 1980.In the problem of developing algorithms for computing, as regards the values of a real-valued function of a real variable (e.g., g[x] in ""restricted"" algorithms), the error that can be tolerated in the result is specified in advance. An interval on the real line would also be specified for values when the values of a function are to be evaluated. Different algorithms may have to be applied for evaluating functions outside the interval. An unrestricted algorithm envisages a situation in which a user may stipulate the value of x and also the precision required in g(x) quite arbitrarily. The algorithm should then produce an acceptable result without failure.


== References ==","An unrestricted algorithm is an algorithm for the computation of a mathematical function that puts no restrictions on the range of the argument or on the precision that may be demanded in the result. The idea of such an algorithm was put forward by C. W. Clenshaw and F. W. J. Olver in a paper published in 1980.In the problem of developing algorithms for computing, as regards the values of a real-valued function of a real variable (e.g., g[x] in ""restricted"" algorithms), the error that can be tolerated in the result is specified in advance. An interval on the real line would also be specified for values when the values of a function are to be evaluated. Different algorithms may have to be applied for evaluating functions outside the interval. An unrestricted algorithm envisages a situation in which a user may stipulate the value of x and also the precision required in g(x) quite arbitrarily. The algorithm should then produce an acceptable result without failure.


== References ==",54117020,https://en.wikipedia.org/wiki/Unrestricted_algorithm
Adaptive algorithm,"An adaptive algorithm is an algorithm that changes its behavior at the time it is run, based on information available and on a priori defined reward mechanism (or criterion). Such information could be the story of recently received data, information on the available computational resources, or other run-time acquired (or a priori known) information related to the environment in which it operates.
Among the most used adaptive algorithms is the Widrow-Hoff’s least mean squares (LMS), which represents a class of stochastic gradient-descent algorithms used in adaptive filtering and machine learning. In adaptive filtering the LMS is used to mimic a desired filter by finding the filter coefficients that relate to producing the least mean square  of the error signal (difference between the desired and the actual signal).
For example, stable partition, using no additional memory is O(n lg n) but given O(n) memory, it can be O(n) in time. As implemented by the C++ Standard Library, stable_partition is adaptive and so it acquires as much memory as it can get (up to what it would need at most) and applies the algorithm using that available memory.  Another example is adaptive sort, whose behavior changes upon the presortedness of its input.
An example of an adaptive algorithm in radar systems is the constant false alarm rate (CFAR) detector.
In machine learning and optimization, many algorithms are adaptive or have adaptive variants, which usually means that the algorithm parameters such as learning rate are automatically adjusted according to statistics about the optimisation thus far (e.g. the rate of convergence). Examples include adaptive simulated annealing, adaptive coordinate descent, adaptive quadrature, AdaBoost, Adagrad, Adadelta, RMSprop, and Adam.In data compression, adaptive coding algorithms such as Adaptive Huffman coding or Prediction by partial matching can take a stream of data as input, and adapt their compression technique based on the symbols that they have already encountered.In signal processing, the Adaptive Transform Acoustic Coding (ATRAC) codec used in MiniDisc recorders is called ""adaptive"" because the window length (the size of an audio ""chunk"") can change according to the nature of the sound being compressed, to try to achieve the best-sounding compression strategy.","An adaptive algorithm is an algorithm that changes its behavior at the time it is run, based on information available and on a priori defined reward mechanism (or criterion). Such information could be the story of recently received data, information on the available computational resources, or other run-time acquired (or a priori known) information related to the environment in which it operates.
Among the most used adaptive algorithms is the Widrow-Hoff’s least mean squares (LMS), which represents a class of stochastic gradient-descent algorithms used in adaptive filtering and machine learning. In adaptive filtering the LMS is used to mimic a desired filter by finding the filter coefficients that relate to producing the least mean square  of the error signal (difference between the desired and the actual signal).
For example, stable partition, using no additional memory is O(n lg n) but given O(n) memory, it can be O(n) in time. As implemented by the C++ Standard Library, stable_partition is adaptive and so it acquires as much memory as it can get (up to what it would need at most) and applies the algorithm using that available memory.  Another example is adaptive sort, whose behavior changes upon the presortedness of its input.
An example of an adaptive algorithm in radar systems is the constant false alarm rate (CFAR) detector.
In machine learning and optimization, many algorithms are adaptive or have adaptive variants, which usually means that the algorithm parameters such as learning rate are automatically adjusted according to statistics about the optimisation thus far (e.g. the rate of convergence). Examples include adaptive simulated annealing, adaptive coordinate descent, adaptive quadrature, AdaBoost, Adagrad, Adadelta, RMSprop, and Adam.In data compression, adaptive coding algorithms such as Adaptive Huffman coding or Prediction by partial matching can take a stream of data as input, and adapt their compression technique based on the symbols that they have already encountered.In signal processing, the Adaptive Transform Acoustic Coding (ATRAC) codec used in MiniDisc recorders is called ""adaptive"" because the window length (the size of an audio ""chunk"") can change according to the nature of the sound being compressed, to try to achieve the best-sounding compression strategy.

See also
Adaptation (computer science)
Adaptive filter
Adaptive grammar
Adaptive optimization


== References ==",8286430,https://en.wikipedia.org/wiki/Adaptive_algorithm
Algorism,"Algorism is the technique of performing basic arithmetic by writing numbers in place value form and applying a set of memorized rules and facts to the digits. One who practices algorism is known as an algorist. This positional notation system has largely superseded earlier calculation systems that used a different set of symbols for each numerical magnitude, such as Roman numerals, and in some cases required a device such as an abacus.","Algorism is the technique of performing basic arithmetic by writing numbers in place value form and applying a set of memorized rules and facts to the digits. One who practices algorism is known as an algorist. This positional notation system has largely superseded earlier calculation systems that used a different set of symbols for each numerical magnitude, such as Roman numerals, and in some cases required a device such as an abacus.

Etymology
The word algorism comes from the name Al-Khwārizmī (c. 780–850), a Persian mathematician, astronomer, geographer and scholar in the House of Wisdom in Baghdad, whose name means ""the native of Khwarezm"", which is now in modern-day Uzbekistan. He wrote a treatise in Arabic language in the 9th century, which was translated into Latin in the 12th century under the title Algoritmi de numero Indorum. This title means ""Algoritmi on the numbers of the Indians"", where ""Algoritmi"" was the translator's Latinization of Al-Khwarizmi's name. Al-Khwarizmi was the most widely read mathematician in Europe in the late Middle Ages, primarily through his other book, the Algebra. In late medieval Latin, algorismus, the corruption of his name, simply meant the ""decimal number system"" that is still the meaning of modern English algorism. During the 17th century, the French form for the word – but not its meaning – was changed to algorithm, following the model of the word logarithm, this form alluding to the ancient Greek arithmos = number. English adopted the French very soon afterwards, but it wasn't until the late 19th century that ""algorithm"" took on the meaning that it has in modern English. In English, it was first used about 1230 and then by Chaucer in 1391. Another early use of the word is from 1240, in a manual titled Carmen de Algorismo composed by Alexandre de Villedieu. It begins thus:

Haec algorismus ars praesens dicitur, in qua / Talibus Indorum fruimur bis quinque figuris.
which translates as:

This present art, in which we use those twice five Indian figures, is called algorismus.
The word algorithm also derives from algorism, a generalization of the meaning to any set of rules specifying a computational procedure. Occasionally algorism is also used in this generalized meaning, especially in older texts.

History
Starting with the integer arithmetic developed in India using base 10 notation, Al-Khwārizmī along with other mathematicians in medieval Islam, documented new arithmetic methods and made many other contributions to decimal arithmetic (see the articles linked below). These included the concept of the decimal fractions as an extension of the notation, which in turn led to the notion of the decimal point. This system was popularized in Europe by Leonardo of Pisa, now known as Fibonacci.

See also
Algorithmic art
Positional notation
Hindu–Arabic numeral system
History of the Hindu–Arabic numeral system
Johannes de Sacrobosco


== References ==",417534,https://en.wikipedia.org/wiki/Algorism
The Algorithm Auction,"The Algorithm Auction is the world's first auction of computer algorithms. Created by Ruse Laboratories, the initial auction featured seven lots and was held at the Cooper Hewitt, Smithsonian Design Museum on March 27, 2015.Five lots were physical representations of famous code or algorithms, including a signed, handwritten copy of the original Hello, World! C program by its creator Brian Kernighan on dot-matrix printer paper, a printed copy of 5,000 lines of Assembly code comprising the earliest known version of Turtle Graphics, signed by its creator Hal Abelson, a necktie containing the six-line qrpff algorithm capable of decrypting content on a commercially produced DVD video disc, and a pair of drawings representing OkCupid's original Compatibility Calculation algorithm, signed by the company founders. The qrpff lot sold for $2,500.Two other lots were “living algorithms,” including a set of JavaScript tools for building applications that are accessible to the visually impaired and the other is for a program that converts lines of software code into music. Winning bidders received, along with artifacts related to the algorithms, a full intellectual property license to use, modify, or open-source the code. All lots were sold, with Hello World receiving the most bids.Exhibited alongside the auction lots were a facsimile of the Plimpton 322 tablet on loan from Columbia University, and Nigella, an art-world facing computer virus named after Nigella Lawson and created by cypherpunk and hacktivist Richard Jones.Sebastian Chan, Director of Digital & Emerging Media at the Cooper–Hewitt, attended the event remotely from Milan, Italy via a Beam Pro telepresence robot.","The Algorithm Auction is the world's first auction of computer algorithms. Created by Ruse Laboratories, the initial auction featured seven lots and was held at the Cooper Hewitt, Smithsonian Design Museum on March 27, 2015.Five lots were physical representations of famous code or algorithms, including a signed, handwritten copy of the original Hello, World! C program by its creator Brian Kernighan on dot-matrix printer paper, a printed copy of 5,000 lines of Assembly code comprising the earliest known version of Turtle Graphics, signed by its creator Hal Abelson, a necktie containing the six-line qrpff algorithm capable of decrypting content on a commercially produced DVD video disc, and a pair of drawings representing OkCupid's original Compatibility Calculation algorithm, signed by the company founders. The qrpff lot sold for $2,500.Two other lots were “living algorithms,” including a set of JavaScript tools for building applications that are accessible to the visually impaired and the other is for a program that converts lines of software code into music. Winning bidders received, along with artifacts related to the algorithms, a full intellectual property license to use, modify, or open-source the code. All lots were sold, with Hello World receiving the most bids.Exhibited alongside the auction lots were a facsimile of the Plimpton 322 tablet on loan from Columbia University, and Nigella, an art-world facing computer virus named after Nigella Lawson and created by cypherpunk and hacktivist Richard Jones.Sebastian Chan, Director of Digital & Emerging Media at the Cooper–Hewitt, attended the event remotely from Milan, Italy via a Beam Pro telepresence robot.

Effects
Following the auction, the Museum of Modern Art held a salon titled The Way of the Algorithm highlighting algorithms as ""a ubiquitous and indispensable component of our lives.""


== References ==",46493377,https://en.wikipedia.org/wiki/The_Algorithm_Auction
Algorithm characterizations,"Algorithm characterizations are attempts to formalize the word algorithm. Algorithm does not have a generally accepted formal definition. Researchers are actively working on this problem. This article will present some of the ""characterizations"" of the notion of ""algorithm"" in more detail.","Algorithm characterizations are attempts to formalize the word algorithm. Algorithm does not have a generally accepted formal definition. Researchers are actively working on this problem. This article will present some of the ""characterizations"" of the notion of ""algorithm"" in more detail.

The problem of definition
Over the last 200 years, the definition of the algorithm has become more complicated and detailed as researchers have tried to pin down the term. Indeed, there may be more than one type of ""algorithm"". But most agree that algorithm has something to do with defining generalized processes for the creation of ""output"" integers from other ""input"" integers – ""input parameters"" arbitrary and infinite in extent, or limited in extent but still variable—by the manipulation of distinguishable symbols (counting numbers) with finite collections of rules that a person can perform with paper and pencil.
The most common number-manipulation schemes—both in formal mathematics and in routine life—are: (1) the recursive functions calculated by a person with paper and pencil, and (2) the Turing machine or its Turing equivalents—the primitive register-machine or ""counter-machine"" model, the random-access machine model (RAM), the random-access stored-program machine model (RASP) and its functional equivalent ""the computer"".
When we are doing ""arithmetic"" we are really calculating by the use of ""recursive functions"" in the shorthand algorithms we learned in grade school, for example, adding and subtracting.
The proofs that every ""recursive function"" we can calculate by hand we can compute by machine and vice versa—note the usage of the words calculate versus compute—is remarkable. But this equivalence together with the thesis (unproven assertion) that this includes every calculation/computation indicates why so much emphasis has been placed upon the use of Turing-equivalent machines in the definition of specific algorithms, and why the definition of ""algorithm"" itself often refers back to ""the Turing machine"". This is discussed in more detail under Stephen Kleene's characterization.
The following are summaries of the more famous characterizations (Kleene, Markov, Knuth) together with those that introduce novel elements—elements that further expand the definition or contribute to a more precise definition.
[
A mathematical problem and its result can be considered as two points in a space, and the solution consists of a sequence of steps or a path linking them. Quality of the solution is a function of the path. There might be more than one attribute defined for the path, e.g. length, complexity of shape, an ease of generalizing, difficulty, and so on.
]

Chomsky hierarchy
There is more consensus on the ""characterization"" of the notion of ""simple algorithm"".
All algorithms need to be specified in a formal language, and the ""simplicity notion"" arises from the simplicity of the language. The Chomsky (1956) hierarchy is a containment hierarchy of classes of formal grammars that generate formal languages. It is used for classifying of programming languages and abstract machines.
From the Chomsky hierarchy perspective, if the algorithm can be specified on a simpler language (than  unrestricted), it can be  characterized by this kind of language, else it is a typical ""unrestricted algorithm"".
Examples: a ""general purpose"" macro language, like M4 is unrestricted (Turing complete), but the C preprocessor macro language is not, so any algorithm expressed in C preprocessor is a ""simple algorithm"".
See also Relationships between complexity classes.

Features of a good algorithm
The following are desirable features of a well-defined algorithm, as discussed in Scheider and Gersting (1995):

Unambiguous Operations: an algorithm must have specific, outlined steps. The steps should be exact enough to precisely specify what to do at each step.
Well-Ordered: The exact order of operations performed in an algorithm should be concretely defined.
Feasibility: All steps of an algorithm should be possible (also known as effectively computable).
Input: an algorithm should be able to accept a well-defined set of inputs.
Output: an algorithm should produce some result as an output, so that its correctness can be reasoned about.
Finiteness: an algorithm should terminate after a finite number of instructions.Properties of specific algorithms that may be desirable include space and time efficiency, generality (i.e. being able to handle many inputs), or determinism.

1881 John Venn's negative reaction to W. Stanley Jevons's Logical Machine of 1870
In early 1870 W. Stanley Jevons presented a ""Logical Machine"" (Jevons 1880:200) for analyzing a syllogism or other logical form e.g. an argument reduced to a Boolean equation. By means of what Couturat (1914) called a ""sort of logical piano [,] ... the equalities which represent the premises ... are ""played"" on a keyboard like that of a typewriter. ... When all the premises have been ""played"", the panel shows only those constituents whose sum is equal to 1, that is, ... its logical whole. This mechanical method has the advantage over VENN's geometrical method..."" (Couturat 1914:75).
For his part John Venn, a logician contemporary to Jevons, was less than thrilled, opining that ""it does not seem to me that any contrivances at present known or likely to be discovered really deserve the name of logical machines"" (italics added, Venn 1881:120). But of historical use to the developing notion of ""algorithm"" is his explanation for his negative reaction with respect to a machine that ""may subserve a really valuable purpose by enabling us to avoid otherwise inevitable labor"":

(1) ""There is, first, the statement of our data in accurate logical language"",
(2) ""Then secondly, we have to throw these statements into a form fit for the engine to work with – in this case the reduction of each proposition to its elementary denials"",
(3) ""Thirdly, there is the combination or further treatment of our premises after such reduction,""
(4) ""Finally, the results have to be interpreted or read off. This last generally gives rise to much opening for skill and sagacity.""He concludes that ""I cannot see that any machine can hope to help us except in the third of these steps; so that it seems very doubtful whether any thing of this sort really deserves the name of a logical engine.""(Venn 1881:119–121).

1943, 1952 Stephen Kleene's characterization
This section is longer and more detailed than the others because of its importance to the topic: Kleene was the first to propose that all calculations/computations—of every sort, the totality of—can equivalently be (i) calculated by use of five ""primitive recursive operators"" plus one special operator called the mu-operator, or be (ii) computed by the actions of a Turing machine or an equivalent model.
Furthermore, he opined that either of these would stand as a definition of algorithm.
A reader first confronting the words that follow may well be confused, so a brief explanation is in order. Calculation means done by hand, computation means done by Turing machine (or equivalent).  (Sometimes an author slips and interchanges the words). A ""function"" can be thought of as an ""input-output box"" into which a person puts natural numbers called ""arguments"" or ""parameters"" (but only the counting numbers including 0—the nonnegative integers) and gets out a single nonnegative integer (conventionally called ""the answer""). Think of the ""function-box"" as a little man either calculating by hand using ""general recursion"" or computing by Turing machine (or an equivalent machine).
""Effectively calculable/computable"" is more generic and means ""calculable/computable by some procedure, method, technique ... whatever..."".  ""General recursive"" was Kleene's way of writing what today is called just ""recursion""; however, ""primitive recursion""—calculation by use of the five recursive operators—is a lesser form of recursion that lacks access to the sixth, additional, mu-operator that is needed only in rare instances. Thus most of life goes on requiring only the ""primitive recursive functions.""

1943 ""Thesis I"", 1952 ""Church's Thesis""
In 1943 Kleene proposed what has come to be known as Church's thesis:

""Thesis I. Every effectively calculable function (effectively decidable predicate) is general recursive"" (First stated by Kleene in 1943 (reprinted page 274 in Davis, ed. The Undecidable; appears also verbatim in Kleene (1952) p.300)In a nutshell: to calculate any function the only operations a person needs (technically, formally) are the 6 primitive operators of ""general"" recursion (nowadays called the operators of the mu recursive functions).
Kleene's first statement of this was under the section title ""12. Algorithmic theories"". He would later amplify it in his text (1952) as follows:

""Thesis I and its converse provide the exact definition of the notion of a calculation (decision) procedure or algorithm, for the case of a function (predicate) of natural numbers"" (p. 301, boldface added for emphasis)(His use of the word ""decision"" and ""predicate"" extends the notion of calculability to the more general manipulation of symbols such as occurs in mathematical ""proofs"".)
This is not as daunting as it may sound – ""general"" recursion is just a way of making our everyday arithmetic operations from the five ""operators"" of the primitive recursive functions together with the additional mu-operator as needed. Indeed, Kleene gives 13 examples of primitive recursive functions and Boolos–Burgess–Jeffrey add some more, most of which will be familiar to the reader—e.g. addition, subtraction, multiplication and division, exponentiation, the CASE function, concatenation, etc., etc.; for a list see Some common primitive recursive functions.
Why general-recursive functions rather than primitive-recursive functions?
Kleene et al. (cf §55 General recursive functions p. 270 in Kleene 1952) had to add a sixth recursion operator called the minimization-operator (written as μ-operator or mu-operator) because Ackermann (1925) produced a hugely growing function—the Ackermann function—and Rózsa Péter (1935) produced a general method of creating recursive functions using Cantor's diagonal argument, neither of which could be described by the 5 primitive-recursive-function operators. With respect to the Ackermann function:

""...in a certain sense, the length of the computation algorithm of a recursive function which is not also primitive recursive grows faster with the arguments than the value of any primitive recursive function"" (Kleene (1935) reprinted p. 246 in The Undecidable, plus footnote 13 with regards to the need for an additional operator, boldface added).But the need for the mu-operator is a rarity. As indicated above by Kleene's list of common calculations, a person goes about their life happily computing primitive recursive functions without fear of encountering the monster numbers created by Ackermann's function (e.g. super-exponentiation).

1952 ""Turing's thesis""
Turing's Thesis hypothesizes the computability of ""all computable functions"" by the Turing machine model and its equivalents.
To do this in an effective manner, Kleene extended the notion of ""computable"" by casting the net wider—by allowing into the notion of ""functions"" both ""total functions"" and ""partial functions"". A total function is one that is defined for all natural numbers (positive integers including 0). A partial function is defined for some natural numbers but not all—the specification of ""some"" has to come ""up front"". Thus the inclusion of ""partial function"" extends the notion of function to ""less-perfect"" functions. Total- and partial-functions may either be calculated by hand or computed by machine.

Examples:
""Functions"": include ""common subtraction m − n"" and ""addition m + n""""Partial function"": ""Common subtraction"" m − n is undefined when only natural numbers (positive integers and zero) are allowed as input – e.g. 6 − 7 is undefinedTotal function: ""Addition"" m + n is defined for all positive integers and zero.
We now observe Kleene's definition of ""computable"" in a formal sense:

Definition: ""A partial function φ is computable, if there is a machine M which computes it"" (Kleene (1952) p. 360)""Definition 2.5. An n-ary function f(x1, ..., xn) is partially computable if there exists a Turing machine Z such that
f(x1, ..., xn) = ΨZ(n)(x1, ..., [xn)
In this case we say that [machine] Z computes f. If, in addition, f(x1, ..., xn) is a total function, then it is called computable"" (Davis (1958) p. 10)Thus we have arrived at Turing's Thesis:

""Every function which would naturally be regarded as computable is computable ... by one of his machines..."" (Kleene (1952) p.376)Although Kleene did not give examples of ""computable functions"" others have. For example, Davis (1958) gives Turing tables for the Constant, Successor and Identity functions, three of the five operators of the primitive recursive functions:

Computable by Turing machine:
Addition (also is the Constant function if one operand is 0)
Increment (Successor function)
Common subtraction (defined only if x ≥ y). Thus ""x − y"" is an example of a partially computable function.
Proper subtraction x┴y (as defined above)
The identity function: for each i, a function UZn =  ΨZn(x1, ..., xn) exists that plucks xi out of the set of arguments (x1, ..., xn)
MultiplicationBoolos–Burgess–Jeffrey (2002) give the following as prose descriptions of Turing machines for:

Doubling: 2p
Parity
Addition
MultiplicationWith regards to the counter machine, an abstract machine model equivalent to the Turing machine:

Examples Computable by Abacus machine (cf Boolos–Burgess–Jeffrey (2002))
Addition
Multiplication
Exponention: (a flow-chart/block diagram description of the algorithm)Demonstrations of computability by abacus machine (Boolos–Burgess–Jeffrey (2002)) and by counter machine (Minsky 1967):

The six recursive function operators:
Zero function
Successor function
Identity function
Composition function
Primitive recursion (induction)
MinimizationThe fact that the abacus/counter-machine models can simulate the recursive functions provides the proof that: If a function is ""machine computable"" then it is ""hand-calculable by partial recursion"". Kleene's Theorem XXIX :

""Theorem XXIX: ""Every computable partial function φ is partial recursive..."" (italics in original, p. 374).The converse appears as his Theorem XXVIII. Together these form the proof of their equivalence, Kleene's Theorem XXX.

1952 Church–Turing Thesis
With his Theorem XXX Kleene proves the equivalence of the two ""Theses""—the Church Thesis and the Turing Thesis. (Kleene can only hypothesize (conjecture) the truth of both thesis – these he has not proven):

THEOREM XXX: The following classes of partial functions ... have the same members: (a) the partial recursive functions, (b) the computable functions ...""(p. 376)Definition of ""partial recursive function"": ""A partial function φ is partial recursive in [the partial functions] ψ1, ... ψn if there is a system of equations E which defines φ recursively from [partial functions] ψ1, ... ψn"" (p. 326)Thus by Kleene's Theorem XXX: either method of making numbers from input-numbers—recursive functions calculated by hand or computated by Turing-machine or equivalent—results in an ""effectively calculable/computable function"". If we accept the hypothesis that every calculation/computation can be done by either method equivalently we have accepted both Kleene's Theorem XXX (the equivalence) and the Church–Turing Thesis (the hypothesis of ""every"").

A note of dissent: ""There's more to algorithm..."" Blass and Gurevich (2003)
The notion of separating out Church's and Turing's theses from the ""Church–Turing thesis"" appears not only in Kleene (1952) but in Blass-Gurevich (2003) as well. But while there are agreements, there are disagreements too:

""...we disagree with Kleene that the notion of algorithm is that well understood. In fact the notion of algorithm is richer these days than it was in Turing's days. And there are algorithms, of modern and classical varieties, not covered directly by Turing's analysis, for example, algorithms that interact with their environments, algorithms whose inputs are abstract structures, and geometric or, more generally, non-discrete algorithms"" (Blass-Gurevich (2003) p. 8, boldface added)

1954 A. A. Markov Jr.'s characterization
Andrey Markov Jr. (1954) provided the following definition of algorithm:

""1. In mathematics, ""algorithm"" is commonly understood to be an exact prescription, defining a computational process, leading from various initial data to the desired result....""""The following three features are characteristic of algorithms and determine their role in mathematics:
""a) the precision of the prescription, leaving no place to arbitrariness, and its universal comprehensibility -- the definiteness of the algorithm;
""b) the possibility of starting out with initial data, which may vary within given limits -- the generality of the algorithm;
""c) the orientation of the algorithm toward obtaining some desired result, which is indeed obtained in the end with proper initial data -- the conclusiveness of the algorithm."" (p.1)He admitted that this definition ""does not pretend to mathematical precision"" (p. 1). His 1954 monograph was his attempt to define algorithm more accurately; he saw his resulting definition—his ""normal"" algorithm—as ""equivalent to the concept of a recursive function"" (p. 3). His definition included four major components (Chapter II.3 pp. 63ff):

""1. Separate  elementary steps, each of which will be performed according to one of [the substitution] rules... [rules given at the outset]""2. ... steps of local nature ... [Thus the algorithm won't change more than a certain number of symbols to the left or right of the observed word/symbol]""3. Rules for the substitution formulas ... [he called the list of these ""the scheme"" of the algorithm]""4. ...a means to distinguish a ""concluding substitution"" [i.e. a distinguishable ""terminal/final"" state or states]In his Introduction Markov observed that ""the entire significance for mathematics"" of efforts to define algorithm more precisely would be ""in connection with the problem of a constructive foundation for mathematics"" (p. 2). Ian Stewart (cf Encyclopædia Britannica) shares a similar belief: ""...constructive analysis is very much in the same algorithmic spirit as computer science..."". For more see constructive mathematics and Intuitionism.
Distinguishability and Locality: Both notions first appeared with Turing (1936–1937) --

""The new observed squares must be immediately recognizable by the computer [sic: a computer was a person in 1936]. I think it reasonable to suppose that they can only be squares whose distance from the closest of the immediately observed squares does not exceed a certain fixed amount. Let us stay that each of the new observed squares is within L squares of one of the previously observed squares."" (Turing (1936) p. 136 in Davis ed. Undecidable)Locality appears prominently in the work of Gurevich and Gandy (1980) (whom Gurevich cites). Gandy's ""Fourth Principle for Mechanisms"" is ""The Principle of Local Causality"":

""We now come to the most important of our principles. In Turing's analysis the requirement that the action depend only on a bounded portion of the record was based on a human limitiation. We replace this by a physical limitation which we call the principle of local causation. Its justification lies in the finite velocity of propagation of effects and signals: contemporary physics rejects the possibility of instantaneous action at a distance."" (Gandy (1980) p. 135 in J. Barwise et al.)

1936, 1963, 1964 Gödel's characterization
1936: A rather famous quote from Kurt Gödel appears in a ""Remark added in proof [of the original German publication] in his paper ""On the Length of Proofs"" translated by Martin Davis appearing on pp. 82–83 of The Undecidable. A number of authors—Kleene, Gurevich, Gandy etc. -- have quoted the following:

""Thus, the concept of ""computable"" is in a certain definite sense ""absolute,"" while practically all other familiar metamathematical concepts (e.g. provable, definable, etc.) depend quite essentially on the system with respect to which they are defined."" (p. 83)1963: In a ""Note"" dated 28 August 1963 added to his famous paper On Formally Undecidable Propositions (1931) Gödel states (in a footnote) his belief that ""formal systems"" have ""the characteristic property that reasoning in them, in principle, can be completely replaced by mechanical devices"" (p. 616 in van Heijenoort). "". . . due to ""A. M. Turing's work a precise and unquestionably adequate definition of the general notion of formal system can now be given [and] a completely general version of Theorems VI and XI is now possible."" (p. 616). In a 1964 note to another work he expresses the same opinion more strongly and in more detail.
1964: In a Postscriptum, dated 1964, to a paper presented to the Institute for Advanced Study in spring 1934, Gödel amplified his conviction that ""formal systems"" are those that can be mechanized:

""In consequence of later advances, in particular of the fact that, due to A. M. Turing's work, a precise and unquestionably adequate definition of the general concept of formal system can now be given . . . Turing's work gives an analysis of the concept of ""mechanical procedure"" (alias ""algorithm"" or ""computational procedure"" or ""finite combinatorial procedure""). This concept is shown to be equivalent with that of a ""Turing machine"".* A formal system can simply be defined to be any mechanical procedure for producing formulas, called provable formulas . . . ."" (p. 72 in Martin Davis ed. The Undecidable: ""Postscriptum"" to ""On Undecidable Propositions of Formal Mathematical Systems"" appearing on p. 39, loc. cit.)The * indicates a footnote in which Gödel cites the papers by Alan Turing (1937) and Emil Post (1936) and then goes on to make the following intriguing statement:

""As for previous equivalent definitions of computability, which however, are much less suitable for our purpose, see Alonzo Church, Am. J. Math., vol. 58 (1936) [appearing in The Undecidable pp. 100-102]).Church's definitions encompass so-called ""recursion"" and the ""lambda calculus"" (i.e. the λ-definable functions). His footnote 18 says that he discussed the relationship of ""effective calculatibility"" and ""recursiveness"" with Gödel but that he independently questioned ""effectively calculability"" and ""λ-definability"":

""We now define the notion . . . of an effectively calculable function of positive integers by identifying it with the notion of a recursive function of positive integers18 (or of a λ-definable function of positive integers.
""It has already been pointed out that, for every function of positive integers which is effectively calculable in the sense just defined, there exists an algorithm for the calculation of its value.
""Conversely it is true . . ."" (p. 100, The Undecidable).It would appear from this, and the following, that far as Gödel was concerned, the Turing machine was sufficient and the lambda calculus was ""much less suitable."" He goes on to make the point that, with regards to limitations on human reason, the jury is still out:

(""Note that the question of whether there exist finite non-mechanical procedures** not equivalent with any algorithm, has nothing whatsoever to do with the adequacy of the definition of ""formal system"" and of ""mechanical procedure."") (p. 72, loc. cit.)""(For theories and procedures in the more general sense indicated in footnote ** the situation may be different. Note that the results mentioned in the postscript do not establish any bounds for the powers of human reason, but rather for the potentialities of pure formalism in mathematics.) (p. 73 loc. cit.)Footnote **: ""I.e., such as involve the use of abstract terms on the basis of their meaning. See my paper in Dial. 12(1958), p. 280."" (this footnote appears on p. 72, loc. cit).

1967 Minsky's characterization
Minsky (1967) baldly asserts that ""an algorithm is ""an effective procedure"" and declines to use the word ""algorithm"" further in his text; in fact his index makes it clear what he feels about ""Algorithm, synonym for Effective procedure""(p. 311):

""We will use the latter term [an effective procedure] in the sequel. The terms are roughly synonymous, but there are a number of shades of meaning used in different contexts, especially for 'algorithm'"" (italics in original, p. 105)Other writers (see Knuth below) use the word ""effective procedure"". This leads one to wonder: What is Minsky's notion of ""an effective procedure""? He starts off with:

""...a set of rules which tell us, from moment to moment, precisely how to behave"" (p. 106)But he recognizes that this is subject to a criticism:

""... the criticism that the interpretation of the rules is left to depend on some person or agent"" (p. 106)His refinement? To ""specify, along with the statement of the rules, the details of the mechanism that is to interpret them"". To avoid the ""cumbersome"" process of ""having to do this over again for each individual procedure"" he hopes to identify a ""reasonably uniform family of rule-obeying mechanisms"". His ""formulation"":

""(1) a language in which sets of behavioral rules are to be expressed, and""(2) a single machine which can interpret statements in the language and thus carry out the steps of each specified process."" (italics in original, all quotes this para. p. 107)In the end, though, he still worries that ""there remains a subjective aspect to the matter. Different people may not agree on whether a certain procedure should be called effective"" (p. 107)
But Minsky is undeterred. He immediately introduces ""Turing's Analysis of Computation Process"" (his chapter 5.2). He quotes what he calls ""Turing's thesis""

""Any process which could naturally be called an effective procedure can be realized by a Turing machine"" (p. 108. (Minsky comments that in a more general form this is called ""Church's thesis"").After an analysis of ""Turing's Argument"" (his chapter 5.3)
he observes that ""equivalence of many intuitive formulations"" of Turing, Church, Kleene, Post, and Smullyan ""...leads us to suppose that there is really here an 'objective' or 'absolute' notion. As Rogers [1959] put it:

""In this sense, the notion of effectively computable function is one of the few 'absolute' concepts produced by modern work in the foundations of mathematics'"" (Minsky p. 111 quoting Rogers, Hartley Jr (1959) The present theory of Turing machine computability, J. SIAM 7, 114-130.)

1967 Rogers' characterization
In his 1967 Theory of Recursive Functions and Effective Computability Hartley Rogers' characterizes ""algorithm"" roughly as ""a clerical (i.e., deterministic, bookkeeping) procedure . . . applied to . . . symbolic inputs and which will eventually yield, for each such input, a corresponding symbolic output""(p. 1). He then goes on to describe the notion ""in approximate and intuitive terms"" as having 10 ""features"", 5 of which he asserts that ""virtually all mathematicians would agree [to]"" (p. 2). The remaining 5 he asserts ""are less obvious than *1 to *5 and about which we might find less general agreement"" (p. 3).
The 5 ""obvious"" are:

1 An algorithm is a set of instructions of finite size,
2 There is a capable computing agent,
3 ""There are facilities for making, storing, and retrieving steps in a computation""
4 Given #1 and #2 the agent computes in ""discrete stepwise fashion"" without use of continuous methods or analogue devices"",
5 The computing agent carries the computation forward ""without resort to random methods or devices, e.g., dice"" (in a footnote Rogers wonders if #4 and #5 are really the same)The remaining 5 that he opens to debate, are:

6 No fixed bound on the size of the inputs,
7 No fixed bound on the size of the set of instructions,
8 No fixed bound on the amount of memory storage available,
9 A fixed finite bound on the capacity or ability of the computing agent (Rogers illustrates with example simple mechanisms similar to a Post–Turing machine or a counter machine),
10 A bound on the length of the computation -- ""should we have some idea, 'ahead of time', how long the computationwill take?"" (p. 5). Rogers requires ""only that a computation terminate after some finite number of steps; we do not insist on an a priori ability to estimate this number."" (p. 5).

1968, 1973 Knuth's characterization
Knuth (1968, 1973) has given a list of five properties that are widely accepted as requirements for an algorithm:

Finiteness: ""An algorithm must always terminate after a finite number of steps ... a very finite number, a reasonable number""
Definiteness: ""Each step of an algorithm must be precisely defined; the actions to be carried out must be rigorously and unambiguously specified for each case""
Input: ""...quantities which are given to it initially before the algorithm begins. These inputs are taken from specified sets of objects""
Output: ""...quantities which have a specified relation to the inputs""
Effectiveness: ""... all of the operations to be performed in the algorithm must be sufficiently basic that they can in principle be done exactly and in a finite length of time by a man using paper and pencil""Knuth offers as an example the Euclidean algorithm for determining the greatest common divisor of two natural numbers (cf. Knuth Vol. 1 p. 2).
Knuth admits that, while his description of an algorithm may be intuitively clear, it lacks formal rigor, since it is not exactly clear what ""precisely defined"" means, or ""rigorously and unambiguously specified"" means, or ""sufficiently basic"", and so forth. He makes an effort in this direction in his first volume where he defines in detail what he calls the ""machine language"" for his ""mythical MIX...the world's first polyunsaturated computer"" (pp. 120ff). Many of the algorithms in his books are written in the MIX language. He also uses tree diagrams, flow diagrams and state diagrams.
""Goodness"" of an algorithm, ""best"" algorithms: Knuth states that ""In practice, we not only want algorithms, we want good algorithms...."" He suggests that some criteria of an algorithm's goodness are the number of steps to perform the algorithm, its ""adaptability to computers, its simplicity and elegance, etc."" Given a number of algorithms to perform the same computation, which one is ""best""? He calls this sort of inquiry ""algorithmic analysis: given an algorithm, to determine its performance characteristcis"" (all quotes this paragraph: Knuth Vol. 1 p. 7)

1972 Stone's characterization
Stone (1972) and Knuth (1968, 1973) were professors at Stanford University at the same time so it is not surprising if there are similarities in their definitions (boldface added for emphasis):

""To summarize ... we define an algorithm to be a set of rules that precisely defines a sequence of operations such that each rule is effective and definite and such that the sequence terminates in a finite time."" (boldface added, p. 8)Stone is noteworthy because of  his detailed discussion of what constitutes an “effective” rule – his robot, or person-acting-as-robot, must have some information and abilities within them, and if not the information and the ability must be provided in ""the algorithm"":

""For people to follow the rules of an algorithm, the rules must be formulated so that they can be followed in a robot-like manner, that is, without the need for thought... however, if the instructions [to solve the quadratic equation, his example] are to be obeyed by someone who knows how to perform arithmetic operations but does not know how to extract a square root, then we must also provide a set of rules for extracting a square root in order to satisfy the definition of algorithm"" (p. 4-5)Furthermore, ""...not all instructions are acceptable, because they may require the robot to have abilities beyond those that we consider reasonable.” He gives the example of a robot confronted with the question is “Henry VIII a King of England?” and to print 1 if yes and 0 if no, but the robot has not been previously provided with this information. And worse, if the robot is asked if Aristotle was a King of England and the robot only had been provided with five names, it would not know how to answer. Thus:

“an intuitive definition of an acceptable sequence of instructions is one in which each instruction is precisely defined so that the robot is guaranteed to be able to obey it” (p. 6)After providing us with his definition, Stone introduces the Turing machine model and states that the set of five-tuples that are the machine's instructions are “an algorithm ... known as a Turing machine program” (p. 9). Immediately thereafter he goes on say that a “computation of a Turing machine is described by stating:

""1. The tape alphabet
""2. The form in which the [input] parameters are presented on the tape
""3. The initial state of the Turing machine
""4. The form in which answers [output] will be represented on the tape when the Turing machine halts
""5. The machine program"" (italics added, p. 10)This precise prescription of what is required for ""a computation"" is in the spirit of what will follow in the work of Blass and Gurevich.

1995 Soare's characterization
""A computation is a process whereby we proceed from initially given objects, called inputs, according to a fixed set of rules, called a program, procedure, or algorithm, through a series of steps and arrive at the end of these steps with a final result, called the output. The algorithm, as a set of rules proceeding from inputs to output, must be precise and definite with each successive step clearly determined. The concept of computability concerns those objects which may be specified in principle by computations . . .""(italics in original, boldface added p. 3)

2000 Berlinski's characterization
While a student at Princeton in the mid-1960s, David Berlinski was a student of Alonzo Church (cf p. 160). His year-2000 book The Advent of the Algorithm: The 300-year Journey from an Idea to the Computer contains the following definition of algorithm:

""In the logician's voice:
""an algorithm is
a finite procedure,
written in a fixed symbolic vocabulary,
governed by precise instructions,
moving in discrete steps, 1, 2, 3, . . .,
whose execution requires no insight, cleverness,
intuition, intelligence, or perspicuity,
and that sooner or later comes to an end."" (boldface and italics in the original, p. xviii)

2000, 2002 Gurevich's characterization
A careful reading of Gurevich 2000 leads one to conclude (infer?) that he believes that ""an algorithm"" is actually ""a Turing machine"" or ""a pointer machine"" doing a computation. An ""algorithm"" is not just the symbol-table that guides the behavior of the machine, nor is it just one instance of a machine doing a computation given a particular set of input parameters, nor is it a suitably programmed machine with the power off; rather an algorithm is the machine actually doing any computation of which it is capable. Gurevich does not come right out and say this, so as worded above this conclusion (inference?) is certainly open to debate:

"" . . . every algorithm can be simulated by a Turing machine . . . a program can be simulated and therefore given a precise meaning by a Turing machine."" (p. 1)"" It is often thought that the problem of formalizing the notion of sequential algorithm was solved by Church [1936] and Turing [1936]. For example, according to Savage [1987], an algorithm is a computational process defined by a Turing machine. Church and Turing did not solve the problem of formalizing the notion of sequential algorithm. Instead they gave (different but equivalent) formalizations of the notion of computable function, and there is more to an algorithm than the function it computes. (italics added p. 3)""Of course, the notions of algorithm and computable function are intimately related: by definition, a computable function is a function computable by an algorithm. . . . (p. 4)
In Blass and Gurevich 2002 the authors invoke a dialog between ""Quisani"" (""Q"") and ""Authors"" (A), using Yiannis Moshovakis as a foil, where they come right out and flatly state:

""A: To localize the disagreement, let's first mention two points of agreement. First, there are some things that are obviously algorithms by anyone's definition -- Turing machines, sequential-time ASMs [Abstract State Machines], and the like. . . .Second, at the other extreme are specifications that would not be regarded as algorithms under anyone's definition, since they give no indication of how to compute anything . . . The issue is how detailed the information has to be in order to count as an algorithm. . . . Moshovakis allows some things that we would call only declarative specifications, and he would probably use the word ""implementation"" for things that we call algorithms."" (paragraphs joined for ease of readability, 2002:22)This use of the word ""implementation"" cuts straight to the heart of the question. Early in the paper, Q states his reading of Moshovakis:

""...[H]e would probably think that your practical work [Gurevich works for Microsoft] forces you to think of implementations more than of algorithms. He is quite willing to identify implementations with machines, but he says that algorithms are something more general. What it boils down to is that you say an algorithm is a machine and Moschovakis says it is not."" (2002:3)But the authors waffle here, saying ""[L]et's stick to ""algorithm"" and ""machine"", and the reader is left, again, confused. We have to wait until Dershowitz and Gurevich 2007 to get the following footnote comment:

"" . . . Nevertheless, if one accepts Moshovakis's point of view, then it is the ""implementation"" of algorithms that we have set out to characterize.""(cf Footnote 9 2007:6)

2003 Blass and Gurevich's characterization
Blass and Gurevich describe their work as evolved from consideration of Turing machines and pointer machines, specifically Kolmogorov-Uspensky machines (KU machines), Schönhage Storage Modification Machines (SMM), and linking automata as defined by Knuth. The work of Gandy and Markov are also described as influential precursors.
Gurevich offers a 'strong' definition of an algorithm (boldface added):

""...Turing's informal argument in favor of his thesis justifies a stronger thesis: every algorithm can be simulated by a Turing machine....In practice, it would be ridiculous...[Nevertheless,] [c]an one generalize Turing machines so that any algorithm, never mind how abstract, can be modeled by a generalized machine?...But suppose such generalized Turing machines exist. What would their states be?...a first-order structure ... a particular small instruction set suffices in all cases ... computation as an evolution of the state ... could be nondeterministic... can interact with their environment ... [could be] parallel and multi-agent ... [could have] dynamic semantics ... [the two underpinings of their work are:] Turing's thesis ...[and] the notion of (first order) structure of [Tarski 1933]"" (Gurevich 2000, p. 1-2)The above phrase computation as an evolution of the state differs markedly from the definition of Knuth and Stone—the ""algorithm"" as a Turing machine program. Rather, it corresponds to what Turing called the complete configuration (cf Turing's definition in Undecidable, p. 118) -- and includes both the current instruction (state) and the status of the tape. [cf Kleene (1952) p. 375 where he shows an example of a tape with 6 symbols on it—all other squares are blank—and how to Gödelize its combined table-tape status].
In Algorithm examples we see the evolution of the state first-hand.

1995 – Daniel Dennett: evolution as an algorithmic process
Philosopher Daniel Dennett analyses the importance of evolution as an algorithmic process in his 1995 book Darwin's Dangerous Idea. Dennett identifies three key features of an algorithm:

Substrate neutrality: an algorithm relies on its logical structure. Thus, the particular form in which an algorithm is manifested is not important (Dennett's example is long division: it works equally well on paper, on parchment, on a computer screen, or using neon lights or in skywriting). (p. 51)
Underlying mindlessness: no matter how complicated the end-product of the algorithmic process may be, each step in the algorithm is sufficiently simple to be performed by a non-sentient, mechanical device. The algorithm does not require a ""brain"" to maintain or operate it. ""The standard textbook analogy notes that algorithms are recipes of sorts, designed to be followed by novice cooks.""(p. 51)
Guaranteed results: If the algorithm is executed correctly, it will always produce the same results. ""An algorithm is a foolproof recipe."" (p. 51)It is on the basis of this analysis that Dennett concludes that ""According to Darwin, evolution is an algorithmic process"". (p. 60).
However, in the previous page he has gone out on a much-further limb. In the context of his chapter titled ""Processes as Algorithms"", he states:

""But then . . are there any limits at all on what may be considered an algorithmic process? I guess the answer is NO; if you wanted to, you can treat any process at the abstract level as an algorithmic process. . . If what strikes you as puzzling is the uniformity of the [ocean's] sand grains or the strength of the [tempered-steel] blade, an algorithmic explanation is what will satisfy your curiosity -- and it will be the truth. . . .""No matter how impressive the products of an algorithm, the underlying process always consists of nothing but a set of individualy [sic] mindless steps succeeding each other without the help of any intelligent supervision; they are 'automatic' by definition: the workings of an automaton."" (p. 59)It is unclear from the above whether Dennett is stating that the physical world by itself and without observers is intrinsically algorithmic (computational) or whether a symbol-processing observer is what is adding ""meaning"" to the observations.

2002 John Searle adds a clarifying caveat to Dennett's characterization
Daniel Dennett is a proponent of strong artificial intelligence: the idea that the logical structure of an algorithm is sufficient to explain mind. John Searle, the creator of the Chinese room thought experiment, claims that ""syntax [that is, logical structure] is by itself not sufficient for semantic content [that is, meaning]"" (Searle 2002, p. 16). In other words, the ""meaning"" of symbols is relative to the mind that is using them; an algorithm—a logical construct—by itself is insufficient for a mind.
Searle cautions those who claim that algorithmic (computational) processes are intrinsic to nature (for example, cosmologists, physicists, chemists, etc.):

Computation [...] is observer-relative, and this is because computation is defined in terms of symbol manipulation, but the notion of a 'symbol' is not a notion of physics or chemistry. Something is a symbol only if it is used, treated or regarded as a symbol. The Chinese room argument showed that semantics is not intrinsic to syntax. But what this shows is that syntax is not intrinsic to physics. [...] Something is a symbol only relative to some observer, user or agent who assigns a symbolic interpretation to it [...] you can assign a computational interpretation to anything. But if the question asks, ""Is consciousness intrinsically computational?"" the answer is: nothing is intrinsically computational [italics added for emphasis]. Computation exists only relative to some agent or observer who imposes a computational interpretation on some phenomenon. This is an obvious point. I should have seen it ten years ago but I did not.

2002: Boolos-Burgess-Jeffrey specification of Turing machine calculation
For examples of this specification-method applied to the addition algorithm ""m+n"" see Algorithm examples.An example in Boolos-Burgess-Jeffrey (2002) (pp. 31–32) demonstrates the precision required in a complete specification of an algorithm, in this case to add two numbers: m+n. It is similar to the Stone requirements above.
(i) They have discussed the role of ""number format"" in the computation and selected the ""tally notation"" to represent numbers:

""Certainly computation can be harder in practice with some notations than others... But... it is possible in principle to do in any other notation, simply by translating the data... For purposes of framing a rigorously defined notion of computability, it is convenient to use monadic or tally notation"" (p. 25-26)(ii) At the outset of their example they specify the machine to be used in the computation as a Turing machine. They have previously specified (p. 26) that the Turing-machine will be of the 4-tuple, rather than 5-tuple, variety. For more on this convention see Turing machine.
(iii) Previously the authors have specified that the tape-head's position will be indicated by a subscript to the right of the scanned symbol. For more on this convention see Turing machine. (In the following, boldface is added for emphasis):

""We have not given an official definition of what it is for a numerical function to be computable by a Turing machine, specifying how inputs or arguments are to be represented on the machine, and how outputs or values represented. Our specifications for a k-place function from positive integers to positive integers are as follows:
""(a) [Initial number format:] The arguments m1, ... mk,  ... will be represented in monadic [unary] notation by blocks of those numbers of strokes, each block separated from the next by a single blank, on an otherwise blank tape.
Example: 3+2, 111B11
""(b) [Initial head location, initial state:] Initially, the machine will be scanning the leftmost 1 on the tape, and will be in its initial state, state 1.
Example: 3+2, 11111B11
""(c) [Successful computation -- number format at Halt:] If the function to be computed assigns a value n to the arguments that are represented initially on the tape, then the machine will eventually halt on a tape containing a block of strokes, and otherwise blank...
Example: 3+2, 11111
""(d) [Successful computation -- head location at Halt:] In this case [c] the machine will halt scanning the left-most 1 on the tape...
Example: 3+2, 1n1111
""(e) [Unsuccessful computation -- failure to Halt or Halt with non-standard number format:] If the function that is to be computed assigns no value to the arguments that are represented initially on the tape, then the machine either will never halt, or will halt in some nonstandard configuration...""(ibid)
Example: Bn11111 or B11n111 or B11111nThis specification is incomplete: it requires the location of where the instructions are to be placed and their format in the machine--

(iv) in the finite state machine's TABLE or, in the case of a Universal Turing machine on the tape, and
(v) the Table of instructions in a specified formatThis later point is important. Boolos-Burgess-Jeffrey give a demonstration (p. 36) that the predictability of the entries in the table allow one to ""shrink"" the table by putting the entries in sequence and omitting the input state and the symbol. Indeed, the example Turing machine computation required only the 4 columns as shown in the table below (but note: these were presented to the machine in rows):

2006: Sipser's assertion and his three levels of description
For examples of this specification-method applied to the addition algorithm ""m+n"" see Algorithm examples.Sipser begins by defining '""algorithm"" as follows:

""Informally speaking, an algorithm is a collection of simple instructions for carrying out some task. Commonplace in everyday life, algorithms sometimes are called procedures or recipes (italics in original, p. 154)""...our real focus from now on is on algorithms. That is, the Turing machine merely serves as a precise model for the definition of algorithm .... we need only to be comfortable enough with Turing machines to believe that they capture all algorithms"" ( p. 156)Does Sipser mean that ""algorithm"" is just ""instructions"" for a Turing machine, or is the combination of ""instructions + a (specific variety of) Turing machine""? For example, he defines the two standard variants (multi-tape and non-deterministic) of his particular variant (not the same as Turing's original) and goes on, in his Problems (pages 160–161), to describe four more variants (write-once, doubly infinite tape (i.e. left- and right-infinite), left reset, and ""stay put instead of left). In addition, he imposes some constraints. First, the input must be encoded as a string (p. 157) and says of numeric encodings in the context of complexity theory:

""But note that unary notation for encoding numbers (as in the number 17 encoded by the unary number 11111111111111111) isn't reasonable because it is exponentially larger than truly reasonable encodings, such as base k notation for any k ≥ 2."" (p. 259)Van Emde Boas comments on a similar problem with respect to the random-access machine (RAM) abstract model of computation sometimes used in place of the Turing machine when doing ""analysis of algorithms"":
""The absence or presence of multiplicative and parallel bit manipulation operations is of relevance for the correct understanding of some results in the analysis of algorithms.
"". . . [T]here hardly exists such as a thing as an ""innocent"" extension of the standard RAM model in the uniform time measures; either one only has additive arithmetic or one might as well include all reasonable multiplicative and/or bitwise Boolean instructions on small operands."" (Van Emde Boas, 1990:26)
With regard to a ""description language"" for algorithms Sipser finishes the job that Stone and Boolos-Burgess-Jeffrey started (boldface added). He offers us three levels of description of Turing machine algorithms (p. 157):

High-level description: ""wherein we use ... prose to describe an algorithm, ignoring the implementation details. At this level we do not need to mention how the machine manages its tape or head.""Implementation description: ""in which we use ... prose to describe the way that the Turing machine moves its head and the way that it stores data on its tape. At this level we do not give details of states or transition function.""Formal description: ""... the lowest, most detailed, level of description... that spells out in full the Turing machine's states, transition function, and so on.""

2011: Yanofsky
In Yanofsky (2011) an algorithm is defined to be the set of programs that implement that algorithm: the set of all programs is partitioned into equivalence classes. Although the set of programs does not form a category, the set of algorithms form a category with extra structure. The conditions that describe when two programs are equivalent turn out to be coherence relations which give the extra structure to the category of algorithms.

Notes
References
David Berlinski (2000), The Advent of the Algorithm: The 300-Year Journey from an Idea to the Computer, Harcourt, Inc., San Diego, ISBN 0-15-601391-6 (pbk.)
George Boolos, John P. Burgess, Richard Jeffrey (2002), Computability and Logic: Fourth Edition, Cambridge University Press, Cambridge, UK. ISBN 0-521-00758-5 (pbk).
Andreas Blass and Yuri Gurevich (2003), Algorithms: A Quest for Absolute Definitions, Bulletin of European Association for Theoretical Computer Science 81, 2003. Includes an excellent bibliography of 56 references.
Burgin, M. Super-recursive algorithms, Monographs in computer science, Springer, 2005. ISBN 0-387-95569-0
Davis, Martin (1958). Computability & Unsolvability. New York: McGraw-Hill Book Company, Inc.. A source of important definitions and some Turing machine-based algorithms for a few recursive functions.
Davis, Martin (1965). The Undecidable: Basic Papers On Undecidable Propositions, Unsolvable Problems and Computable Functions. New York: Raven Press. Davis gives commentary before each article. Papers of Gödel, Alonzo Church, Turing, Rosser, Kleene, and Emil Post are included.
Dennett, Daniel (1995). Darwin's Dangerous Idea. New York: Touchstone/Simon & Schuster.
Robin Gandy, Church's Thesis and principles for Mechanisms, in J. Barwise, H. J. Keisler and K. Kunen, eds., The Kleene Symposium, North-Holland Publishing Company 1980) pp. 123–148. Gandy's famous ""4 principles of [computational] mechanisms"" includes ""Principle IV -- The Principle of Local Causality"".
Yuri Gurevich, Sequential Abstract State Machines Capture Sequential Algorithms, ACM Transactions on Computational Logic, Vol 1, no 1 (July 2000), pages 77–111. Includes bibliography of 33 sources.
Kleene C., Stephen (1943). ""Recursive Predicates and Quantifiers"". Transactions of the American Mathematical Society. 54 (1): 41–73. doi:10.2307/1990131. JSTOR 1990131. Reprinted in The Undecidable, p. 255ff. Kleene refined his definition of ""general recursion"" and proceeded in his chapter ""12. Algorithmic theories"" to posit ""Thesis I"" (p. 274); he would later repeat this thesis (in Kleene 1952:300) and name it ""Church's Thesis""(Kleene 1952:317) (i.e., the Church Thesis).
Kleene, Stephen C. (1991) [1952]. Introduction to Metamathematics (Tenth ed.). North-Holland Publishing Company. Excellent — accessible, readable — reference source for mathematical ""foundations"".
Knuth, Donald E.. (1973) [1968]. The Art of Computer Programming Second Edition, Volume 1/Fundamental Algorithms (2nd ed.). Addison-Wesley Publishing Company. The first of Knuth's famous series of three texts.
Lewis, H.R. and Papadimitriou, C.H. Elements of the Theory of Computation, Prentice-Hall, Uppre Saddle River, N.J., 1998
A. A. Markov (1954) Theory of algorithms. [Translated by Jacques J. Schorr-Kon and PST staff] Imprint Moscow, Academy of Sciences of the USSR, 1954 [i.e. Jerusalem, Israel Program for Scientific Translations, 1961; available from the Office of Technical Services, U.S. Dept. of Commerce, Washington] Description 444 p. 28 cm. Added t.p. in Russian Translation of Works of the Mathematical Institute, Academy of Sciences of the USSR, v. 42. Original title: Teoriya algerifmov. [QA248.M2943 Dartmouth College library. U.S. Dept. of Commerce, Office of Technical Services, number OTS 60-51085.]
Minsky, Marvin (1967). Computation: Finite and Infinite Machines (First ed.). Prentice-Hall, Englewood Cliffs, NJ. Minsky expands his ""...idea of an algorithm — an effective procedure..."" in chapter 5.1 Computability, Effective Procedures and Algorithms. Infinite machines.
Hartley Rogers, Jr, (1967), Theory of Recursive Functions and Effective Computability, MIT Press (1987), Cambridge MA, ISBN 0-262-68052-1 (pbk.)
Searle, John (2002). Consciousness and Language. Cambridge UK: Cambridge University Press. ISBN 0-521-59744-7.
Robert Soare, (1995 to appear in Proceedings of the 10th International Congress of Logic, Methodology, and Philosophy of Science, August 19–25, 1995, Florence Italy), Computability and Recursion), on the web at ??.
Michael Sipser, (2006), Introduction to the Theory of Computation: Second Edition, Thompson Course Technology div. of Thompson Learning, Inc. Boston, MA. ISBN 978-0-534-95097-2.
Ian Stewart, Algorithm, Encyclopædia Britannica 2006.
Stone, Harold S. Introduction to Computer Organization and Data Structures (1972 ed.). McGraw-Hill, New York. Cf in particular the first chapter titled: Algorithms, Turing Machines, and Programs. His succinct informal definition: ""...any sequence of instructions that can be obeyed by a robot, is called an algorithm"" (p. 4).
Peter van Emde Boas (1990), ""Machine Models and Simulations"" pp 3–66, appearing in Jan van Leeuwen (1990), Handbook of Theoretical Computer Science. Volume A: Algorithms & Complexity, The MIT Press/Elsevier, 1990, ISBN 0-444-88071-2 (Volume A)",6901703,https://en.wikipedia.org/wiki/Algorithm_characterizations
Algorithm engineering,"Algorithm engineering focuses on the design, analysis, implementation, optimization, profiling and experimental evaluation of computer algorithms, bridging the gap between algorithmics theory and practical applications of algorithms in software engineering.
It is a general methodology for algorithmic research.","Algorithm engineering focuses on the design, analysis, implementation, optimization, profiling and experimental evaluation of computer algorithms, bridging the gap between algorithmics theory and practical applications of algorithms in software engineering.
It is a general methodology for algorithmic research.

Origins
In 1995, a report from an NSF-sponsored workshop ""with the purpose of assessing the current goals and directions of the Theory of Computing (TOC) community"" identified the slow speed of adoption of theoretical insights by practitioners as an important issue and suggested measures to

reduce the uncertainty by practitioners whether a certain theoretical breakthrough will translate into practical gains in their field of work, and
tackle the lack of ready-to-use algorithm libraries, which provide stable, bug-free and well-tested implementations for algorithmic problems and expose an easy-to-use interface for library consumers.But also, promising algorithmic approaches have been neglected due to difficulties in mathematical analysis.The term ""algorithm engineering"" was first used with specificity in 1997, with the first Workshop on Algorithm Engineering (WAE97), organized by Giuseppe F. Italiano.

Difference from algorithm theory
Algorithm engineering does not intend to replace or compete with algorithm theory, but tries to enrich, refine and reinforce its formal approaches with experimental algorithmics (also called empirical algorithmics).
This way it can provide new insights into the efficiency and performance of algorithms in cases where

the algorithm at hand is less amenable to algorithm theoretic analysis,
formal analysis pessimistically suggests bounds which are unlikely to appear on inputs of practical interest,
the algorithm relies on the intricacies of modern hardware architectures like data locality, branch prediction, instruction stalls, instruction latencies which the machine model used in Algorithm Theory is unable to capture in the required detail,
the crossover between competing algorithms with different constant costs and asymptotic behaviors needs to be determined.

Methodology
Some researchers describe algorithm engineering's methodology as a cycle consisting of algorithm design, analysis, implementation and experimental evaluation, joined by further aspects like machine models or realistic inputs.
They argue that equating algorithm engineering with experimental algorithmics is too limited, because viewing design and analysis, implementation and experimentation as separate activities ignores the crucial feedback loop between those elements of algorithm engineering.

Realistic models and real inputs
While specific applications are outside the methodology of algorithm engineering, they play an important role in shaping realistic models of the problem and the underlying machine, and supply real inputs and other design parameters for experiments.

Design
Compared to algorithm theory, which usually focuses on the asymptotic behavior of algorithms, algorithm engineers need to keep further requirements in mind: Simplicity of the algorithm, implementability in programming languages on real hardware, and allowing code reuse.
Additionally, constant factors of algorithms have such a considerable impact on real-world inputs that sometimes an algorithm with worse asymptotic behavior performs better in practice due to lower constant factors.

Analysis
Some problems can be solved with heuristics and randomized algorithms in a simpler and more efficient fashion than with deterministic algorithms. Unfortunately, this makes even simple randomized algorithms difficult to analyze because there are subtle dependencies to be taken into account.

Implementation
Huge semantic gaps between theoretical insights, formulated algorithms, programming languages and hardware pose a challenge to efficient implementations of even simple algorithms, because small implementation details can have rippling effects on execution behavior.
The only reliable way to compare several implementations of an algorithm is to spend an considerable amount of time on tuning and profiling, running those algorithms on multiple architectures, and looking at the generated machine code.

Experiments
See: Experimental algorithmics

Application engineering
Implementations of algorithms used for experiments differ in significant ways from code usable in applications.
While the former prioritizes fast prototyping, performance and instrumentation for measurements during experiments, the latter requires thorough testing, maintainability, simplicity, and tuning for particular classes of inputs.

Algorithm libraries
Stable, well-tested algorithm libraries like LEDA play an important role in technology transfer by speeding up the adoption of new algorithms in applications. 
Such libraries reduce the required investment and risk for practitioners, because it removes the burden of understanding and implementing the results of academic research.

Conferences
Two main conferences on Algorithm Engineering are organized annually, namely:

Symposium on Experimental Algorithms (SEA), established in 1997 (formerly known as WEA).
SIAM Meeting on Algorithm Engineering and Experiments (ALENEX), established in 1999.The 1997 Workshop on Algorithm Engineering (WAE'97) was held in Venice (Italy) on September 11–13, 1997. The Third International Workshop on Algorithm Engineering (WAE'99) was held in London, UK in July 1999.
The first Workshop on Algorithm Engineering and Experimentation (ALENEX99) was held in Baltimore, Maryland on January 15–16, 1999. It was sponsored by DIMACS, the Center for Discrete Mathematics and Theoretical Computer Science (at Rutgers University), with additional support from SIGACT, the ACM Special Interest Group on Algorithms and Computation Theory, and SIAM, the Society for Industrial and Applied Mathematics.


== References ==",10140499,https://en.wikipedia.org/wiki/Algorithm_engineering
Algorithmic game theory,"Algorithmic game theory (AGT) is an area in the intersection of game theory and computer science, with the objective of understanding and design of algorithms in strategic environments.
Typically, in Algorithmic Game Theory problems, the input to a given algorithm is distributed among many players who have a personal interest in the output. In those situations, the agents might not report the input truthfully because of their own personal interests. We can see Algorithmic Game Theory from two perspectives:

Analysis: given the currently implemented algorithms, analyze them using Game Theory tools (e.g., calculate and prove properties on their Nash equilibria, price of anarchy, and best-response dynamics)
Design: design games that have both good game-theoretical and algorithmic properties. This area is called algorithmic mechanism design.On top of the usual requirements in classical algorithm design (e.g., polynomial-time running time, good approximation ratio), the designer must also care about incentive constraints.","Algorithmic game theory (AGT) is an area in the intersection of game theory and computer science, with the objective of understanding and design of algorithms in strategic environments.
Typically, in Algorithmic Game Theory problems, the input to a given algorithm is distributed among many players who have a personal interest in the output. In those situations, the agents might not report the input truthfully because of their own personal interests. We can see Algorithmic Game Theory from two perspectives:

Analysis: given the currently implemented algorithms, analyze them using Game Theory tools (e.g., calculate and prove properties on their Nash equilibria, price of anarchy, and best-response dynamics)
Design: design games that have both good game-theoretical and algorithmic properties. This area is called algorithmic mechanism design.On top of the usual requirements in classical algorithm design (e.g., polynomial-time running time, good approximation ratio), the designer must also care about incentive constraints.

History
Nisan-Ronen: a new framework for studying algorithms
In 1999, the seminal paper of Nisan and Ronen  drew the attention of the Theoretical Computer Science community to designing algorithms for selfish (strategic) users. As they claim in the abstract:

We consider algorithmic problems in a distributed setting where the participants cannot be assumed to follow the algorithm but rather their own self-interest. As such participants, termed agents, are capable of manipulating the algorithm, the algorithm designer should ensure in advance that the agents’ interests are best served by behaving correctly.
Following notions from the field of mechanism design, we suggest a framework for studying such algorithms. In this model the algorithmic solution is adorned with payments to the participants and is termed a mechanism. The payments should be carefully chosen as to motivate all participants to act as the algorithm designer wishes. We apply the standard tools of mechanism design to algorithmic problems and in particular to the shortest path problem.
This paper coined the term algorithmic mechanism design and was recognized by the 2012 Gödel Prize committee as one of ""three papers laying foundation of growth in Algorithmic Game Theory"".

Price of Anarchy
The other two papers cited in the 2012 Gödel Prize for fundamental contributions to Algorithmic Game Theory introduced and developed the concept of ""Price of Anarchy"". 
In their 1999 paper ""Worst-case Equilibria"", Koutsoupias and Papadimitriou proposed a new measure of the degradation of system efficiency due to the selfish behavior of its agents: the ratio of between system efficiency at an optimal configuration, and its efficiency at the worst Nash equilibrium. (The term ""Price of Anarchy"" only appeared a couple of years later.)

The Internet as a catalyst
The Internet created a new economy—both as a foundation for exchange and commerce, and in its own right. The computational nature of the Internet allowed for the use of computational tools in this new emerging economy. On the other hand, the Internet itself is the outcome of actions of many. This was new to the classic, ‘top-down’ approach to computation that held till then. Thus, game theory is a natural way to view the Internet and interactions within it, both human and mechanical.
Game theory studies equilibria (such as the Nash equilibrium). An equilibrium is generally defined as a state in which no player has an incentive to change their strategy. Equilibria are found in several fields related to the Internet, for instance financial interactions and communication load-balancing. Game theory provides tools to analyze equilibria, and a common approach is then to ‘find the game’—that is, to formalize specific Internet interactions as a game, and to derive the associated equilibria.
Rephrasing problems in terms of games allows the analysis of Internet-based interactions and the construction of mechanisms to meet specified demands. If equilibria can be shown to exist, a further question must be answered: can an equilibrium be found, and in reasonable time? This leads to the analysis of algorithms for finding equilibria. Of special importance is the complexity class PPAD, which includes many problems in algorithmic game theory.

Areas of research
Algorithmic mechanism design
Mechanism design is the subarea of economics that deals with optimization under incentive constraints. Algorithmic mechanism design considers the optimization of economic systems under computational efficiency requirements. Typical objectives studied include revenue maximization and social welfare maximization.

Inefficiency of equilibria
The concepts of price of anarchy and price of stability were introduced to capture the loss in performance of a system due to the selfish behavior of its participants. The price of anarchy captures the worst-case performance of the system at equilibrium relative to the optimal performance possible. The price of stability, on the other hand, captures the relative performance of the best equilibrium of the system. These concepts are counterparts to the notion of approximation ratio in algorithm design.

Complexity of finding equilibria
The existence of an equilibrium in a game is typically established using non-constructive fixed point theorems. There are no efficient algorithms known for computing Nash equilibria. The problem is complete for the complexity class PPAD even in 2-player games. In contrast, correlated equilibria can be computed efficiently using linear programming, as well as learned via no-regret strategies.

Computational social choice
Computational social choice studies computational aspects of social choice, the aggregation of individual agents' preferences. Examples include algorithms and computational complexity of voting rules and coalition formation.Other topics include:

Algorithms for computing Market equilibria
Fair division
Multi-agent systemsAnd the area counts with diverse practical applications:
Sponsored search auctions
Spectrum auctions
Cryptocurrencies
Prediction markets
Reputation systems
Sharing economy
Matching markets such as kidney exchange and school choice
Crowdsourcing and peer grading
Economics of the cloud

Journals and newsletters
ACM Transactions on Economics and Computation (TEAC) 
SIGEcom Exchanges Algorithmic Game Theory papers are often also published in Game Theory journals such as GEB, Economics journals such as Econometrica, and Computer Science journals such as SICOMP.

See also
Auction Theory
Computational social choice
Gamification
Load balancing (computing)
Mechanism design
Multi-agent system
Voting in game theory

References
John von Neumann, Oskar Morgenstern (1944) Theory of Games and Economic Behavior. Princeton Univ. Press. 2007 edition: ISBN 978-0-691-13061-3
Vazirani, Vijay V.; Nisan, Noam; Roughgarden, Tim; Tardos, Éva (2007), Algorithmic Game Theory (PDF), Cambridge, UK: Cambridge University Press, ISBN 978-0-521-87282-9.

External links
gambit.sourceforge.net - a library of game theory software and tools for the construction and analysis of finite extensive and strategic games.
gamut.stanford.edu - a suite of game generators designated for testing game-theoretic algorithms.",16334749,https://en.wikipedia.org/wiki/Algorithmic_game_theory
Algorithmic logic,"Algorithmic logic is a calculus of programs that allows the expression of semantic properties of programs by appropriate logical formulas. It provides a framework that enables proving the formulas from the axioms of program constructs such as assignment, iteration and composition instructions and from the axioms of the data structures in question see Mirkowska & Salwicki (1987), Banachowski et al. (1977).
The following diagram helps to locate algorithmic logic among other logics.
[Propositional logicorSentential calculus]⊂[Predicate calculusorFirst order logic]⊂[Calculus of programsorAlgorithmic logic]{\displaystyle \qquad \left[{\begin{array}{l}\mathrm {Propositional\ logic} \\or\\\mathrm {Sentential\ calculus} \end{array}}\right]\subset \left[{\begin{array}{l}\mathrm {Predicate\ calculus} \\or\\\mathrm {First\ order\ logic} \end{array}}\right]\subset \left[{\begin{array}{l}\mathrm {Calculus\ of\ programs} \\or\\{\mbox{Algorithmic logic}}\end{array}}\right]}
The formalized language of algorithmic logic (and of algorithmic theories of various data structures) contains three types of well formed expressions: Terms - i.e. expressions denoting operations on elements of data structures, 
formulas - i.e. expressions denoting the relations among elements of data structures,  programs - i.e. algorithms - these expressions describe the computations.
For semantics of terms and formulas consult pages on first-order logic and Tarski's semantics. The meaning of a program K{\displaystyle K} is the set of possible computations of the program.
Algorithmic logic is one of many logics of programs.
Another logic of programs is dynamic logic, see dynamic logic, Harel, Kozen & Tiuryn (2000).","Algorithmic logic is a calculus of programs that allows the expression of semantic properties of programs by appropriate logical formulas. It provides a framework that enables proving the formulas from the axioms of program constructs such as assignment, iteration and composition instructions and from the axioms of the data structures in question see Mirkowska & Salwicki (1987), Banachowski et al. (1977).
The following diagram helps to locate algorithmic logic among other logics.
[Propositional logicorSentential calculus]⊂[Predicate calculusorFirst order logic]⊂[Calculus of programsorAlgorithmic logic]{\displaystyle \qquad \left[{\begin{array}{l}\mathrm {Propositional\ logic} \\or\\\mathrm {Sentential\ calculus} \end{array}}\right]\subset \left[{\begin{array}{l}\mathrm {Predicate\ calculus} \\or\\\mathrm {First\ order\ logic} \end{array}}\right]\subset \left[{\begin{array}{l}\mathrm {Calculus\ of\ programs} \\or\\{\mbox{Algorithmic logic}}\end{array}}\right]}
The formalized language of algorithmic logic (and of algorithmic theories of various data structures) contains three types of well formed expressions: Terms - i.e. expressions denoting operations on elements of data structures, 
formulas - i.e. expressions denoting the relations among elements of data structures,  programs - i.e. algorithms - these expressions describe the computations.
For semantics of terms and formulas consult pages on first-order logic and Tarski's semantics. The meaning of a program K{\displaystyle K} is the set of possible computations of the program.
Algorithmic logic is one of many logics of programs.
Another logic of programs is dynamic logic, see dynamic logic, Harel, Kozen & Tiuryn (2000).

Bibliography
Mirkowska, Grażyna; Salwicki, Andrzej (1987). Algorithmic Logic (PDF). Warszawa  & Boston: PWN & D. Reidel Publ. p. 372. ISBN 8301068590.]
[Banachowski et al.]  |Banachowski, Lech; Kreczmar, Antoni; Mirkowska, Grażyna; Rasiowa, Helena; Salwicki, Andrzej (1977). An introduction to Algorithmic Logic - Metamathematical Investigations of Theory of Programs. Banach Center Publications. Vol. 2. Warszawa: PWN. pp. 7–99.
Harel, David; Kozen, Dexter; Tiuryn, Jerzy (2000). Dynamic Logic. Cambridge Massachusetts: MIT Press. pp. 459.",42360188,https://en.wikipedia.org/wiki/Algorithmic_logic
Algorithmic management,"Algorithmic management is a term used to describe certain labor management practices in the contemporary digital economy. In scholarly uses, the term was initially coined in 2015 by Min Kyung Lee, Daniel Kusbit, Evan Metsky, and Laura Dabbish to describe the managerial role played by algorithms on the Uber and Lyft platforms, but has since been taken up by other scholars to describe more generally the managerial and organisational characteristics of platform economies. However, digital direction of labor was present in manufacturing already since the 1970s and algorithmic management is becoming increasingly widespread across a wide range of industries.The concept of algorithmic management can be broadly defined as the delegation of managerial functions to algorithmic and automated systems.  Algorithmic management has been enabled by recent advances in digital technologies which allow for the real-time and ""large-scale collection of data"" which is then used to ""improve learning algorithms that carry out learning and control functions traditionally performed by managers"".In the contemporary workplace, firms employ an ecology of accounting devices, such as “rankings, lists, classifications, stars and other symbols’ in order to effectively manage their operations and create value without the need for traditional forms of hierarchical control.” Many of these devices fall under the label of what is called algorithmic management, and were first developed by companies operating in the sharing economy or gig economy, functioning as effective labor and cost cutting measures. The Data&Society explainer of the term, for example, describes algorithmic management as ‘a diverse set of technological tools and techniques that structure the conditions of work and remotely manage workforces. Data&Society also provides a list of five typical features of algorithmic management:

Prolific data collection and surveillance of workers through technology;
Real-time responsiveness to data that informs management decisions;
Automated or semi-automated decision-making;
Transfer of performance evaluations to rating systems or other metrics; and
The use of “nudges” and penalties to indirectly incentivize worker behaviors.Proponents of algorithmic management claim that it “creates new employment opportunities, better and cheaper consumer services, transparency and fairness in parts of the labour market that are characterised by inefficiency, opacity and capricious human bosses.” On the other hand, critics of algorithmic management claim that the practice leads to several issues, especially as it impacts the employment status of workers managed by its new array of tools and techniques.","Algorithmic management is a term used to describe certain labor management practices in the contemporary digital economy. In scholarly uses, the term was initially coined in 2015 by Min Kyung Lee, Daniel Kusbit, Evan Metsky, and Laura Dabbish to describe the managerial role played by algorithms on the Uber and Lyft platforms, but has since been taken up by other scholars to describe more generally the managerial and organisational characteristics of platform economies. However, digital direction of labor was present in manufacturing already since the 1970s and algorithmic management is becoming increasingly widespread across a wide range of industries.The concept of algorithmic management can be broadly defined as the delegation of managerial functions to algorithmic and automated systems.  Algorithmic management has been enabled by recent advances in digital technologies which allow for the real-time and ""large-scale collection of data"" which is then used to ""improve learning algorithms that carry out learning and control functions traditionally performed by managers"".In the contemporary workplace, firms employ an ecology of accounting devices, such as “rankings, lists, classifications, stars and other symbols’ in order to effectively manage their operations and create value without the need for traditional forms of hierarchical control.” Many of these devices fall under the label of what is called algorithmic management, and were first developed by companies operating in the sharing economy or gig economy, functioning as effective labor and cost cutting measures. The Data&Society explainer of the term, for example, describes algorithmic management as ‘a diverse set of technological tools and techniques that structure the conditions of work and remotely manage workforces. Data&Society also provides a list of five typical features of algorithmic management:

Prolific data collection and surveillance of workers through technology;
Real-time responsiveness to data that informs management decisions;
Automated or semi-automated decision-making;
Transfer of performance evaluations to rating systems or other metrics; and
The use of “nudges” and penalties to indirectly incentivize worker behaviors.Proponents of algorithmic management claim that it “creates new employment opportunities, better and cheaper consumer services, transparency and fairness in parts of the labour market that are characterised by inefficiency, opacity and capricious human bosses.” On the other hand, critics of algorithmic management claim that the practice leads to several issues, especially as it impacts the employment status of workers managed by its new array of tools and techniques.

History of the term
“Algorithmic management” was first described by Lee, Kusbit, Metsky, and Dabbish in 2015 in their study of the Uber and Lyft platforms. In their study, Lee et al. termed “software algorithms that assume managerial functions and surrounding institutional devices that support algorithms in practice” algorithmic management. Software algorithms, it was said, are increasingly used to “allocate, optimize, and evaluate work” by platforms in managing their vast workforces. In Lee et al.’s paper on Uber and Lyft this included the use of algorithms to assign work to drivers, as mechanisms to optimise pricing for services, and as systems for evaluating driver performance.   In 2016, Alex Rosenblat and Luke Stark sought to extend on this understanding of algorithmic management “to elucidate on the automated implementation of company policies on the behaviours and practices of Uber drivers.” Rosenblat and Stark found in their study that algorithmic management practices contributed to a system beset by power asymmetries, where drivers had little control over “critical aspects of their work”, whereas Uber had far greater control over the labor of its drivers.Since this time, studies of algorithmic management have extended the use of the term to describe the management practices of various firms, where, for example, algorithms “are taking over scheduling work in fast food restaurants and grocery stores, using various forms of performance metrics ad even mood... to assign the fastest employees to work in peak times.” Algorithmic management is seen to be especially prevalent in gig work on platforms, such as on Upwork and Deliveroo, and in the sharing economy, such as in the case of Airbnb.Furthermore, recent research has defined sub-constructs that fall under the umbrella term of algorithmic management, for example, ""algorithmic nudging"". A Harvard Business Review article by Mareike Möhlmann published in 2021 explains: ""Companies are increasingly using algorithms to manage and control individuals not by force, but rather by nudging them into desirable behavior — in other words, learning from their personalized data and altering their choices in some subtle way."" While the concept builds on nudging theory popularized by University of Chicago economist Richard Thaler and Harvard Law School professor Cass Sunstein, ""due to recent advances in AI and machine learning, algorithmic nudging is much more powerful than its non-algorithmic counterpart. With so much data about workers’ behavioral patterns at their fingertips, companies can now develop personalized strategies for changing individuals’ decisions and behaviors at large scale. These algorithms can be adjusted in real-time, making the approach even more effective.""

Relationships with other labor management practices
Algorithmic management has been compared and contrasted with other forms of management, such as Scientific management approaches, as pioneered by Frederick Taylor in the early 1900s. Henri Schildt has called algorithmic management “Scientific management 2.0”, where management “is no longer a human practice, but a process embedded in technology.”  Similarly, Kathleen Griesbach, Adam Reich, Luke Elliott-Negri, and Ruth Milkman suggest that, while “algorithmic control over labor may be relatively new, it replicates many features of older mechanisms of labor control.”On the other hand, some commentators have argued that algorithmic management is not simply a new form of Scientific management or digital Taylorism, but represents a distinct approach to labor control in platform economies. David Stark and Ivana Pais, for example, state that,
""In contrast to Scientific Management at the turn of the twentieth century, in the algorithmic management of the twenty-first century there are rules but these are not bureaucratic, there are rankings but not ranks, and there is monitoring but it is not disciplinary. Algorithmic management does not automate bureaucratic structures and practices to create some new form of algorithmic bureaucracy. Whereas the devices and practices of Taylorism were part of a system of hierarchical supervision, the devices and practices of algorithmic management take place within a different economy of attention and a new regime of visibility. Triangular rather than vertical, and not as a panopticon, the lines of vision in algorithmic management are not lines of supervision.""Similarly, Data&Society’s explainer for algorithmic management claims that the practice represents a marked departure from earlier management structures that more strongly rely on human supervisors to direct workers.

Issues
Algorithmic management can provide an effective and efficient means of workforce control and value creation in the contemporary digital economy. However, commentators have highlighted several issues that algorithmic management poses, especially for the workers it manages. Criticisms of the practice often highlight several key issues pertaining to algorithmic management practices, such as the imperfection and scope of its surveillance and control measures, which also threaten to lock workers out of key decision-making processes; its lack of transparency for users and information asymmetries; its potential for bias and discrimination; its dehumanizing tendencies; and its potential to create conditions which sidestep traditional employer-employee accountability. This last point has been especially contentious, as algorithmic management practices have been utilised by firms to reclassify workforces as independent contractors rather than employees. These negative consequences particularly affect migrant workers, who are integrated into existing labour processes under worse conditions utilising linguistically configurable algorithmic management. Another critical issue is related to the lack of transparency of these devices, which is worse in the employment context as it increases the already existent information asymmetries between the parties to a contract of employment. These issues in some cases led to public criticism, lawsuits, and wildcat strikes by workers. However, employment and data protection laws, at least in Europe, seems to have many regulatory antibodies to foster algorithmic transparency in the workplace and consequently uncover the violation of those rules already limiting abuses of managerial prerogatives by employers.


== References ==",67039572,https://en.wikipedia.org/wiki/Algorithmic_management
Algorithmic mechanism design,"Algorithmic mechanism design (AMD) lies at the intersection of economic game theory, optimization, and computer science. The prototypical problem in mechanism design is to design a system for multiple self-interested participants, such that the participants' self-interested actions at equilibrium lead to good system performance. Typical objectives studied include revenue maximization and social welfare maximization. Algorithmic mechanism design differs from classical economic mechanism design in several respects. It typically employs the analytic tools of theoretical computer science, such as worst case analysis and approximation ratios, in contrast to classical mechanism design in economics which often makes distributional assumptions about the agents. It also considers computational constraints to be of central importance: mechanisms that cannot be efficiently implemented in polynomial time are not considered to be viable solutions to a mechanism design problem. This often, for example, rules out the classic economic mechanism, the Vickrey–Clarke–Groves auction.","Algorithmic mechanism design (AMD) lies at the intersection of economic game theory, optimization, and computer science. The prototypical problem in mechanism design is to design a system for multiple self-interested participants, such that the participants' self-interested actions at equilibrium lead to good system performance. Typical objectives studied include revenue maximization and social welfare maximization. Algorithmic mechanism design differs from classical economic mechanism design in several respects. It typically employs the analytic tools of theoretical computer science, such as worst case analysis and approximation ratios, in contrast to classical mechanism design in economics which often makes distributional assumptions about the agents. It also considers computational constraints to be of central importance: mechanisms that cannot be efficiently implemented in polynomial time are not considered to be viable solutions to a mechanism design problem. This often, for example, rules out the classic economic mechanism, the Vickrey–Clarke–Groves auction.

History
Noam Nisan and Amir Ronen first coined ""Algorithmic mechanism design"" in a research paper published in 1999.

See also
Algorithmic game theory
Computational social choice
Metagame
Incentive compatible
Vickrey–Clarke–Groves mechanism

References and notes
Further reading
Vazirani, Vijay V.; Nisan, Noam; Roughgarden, Tim; Tardos, Éva (2007). Algorithmic Game Theory (PDF). Cambridge, UK: Cambridge University Press. ISBN 0-521-87282-0.
Dütting, Paul; Geiger, Andreas (May 9, 2007), Algorithmic Mechanism Design (PDF), Seminar Report, University of Karlsruhe, Fakultät für Informatik, archived from the original (PDF) on June 13, 2015, retrieved June 11, 2015.",15875500,https://en.wikipedia.org/wiki/Algorithmic_mechanism_design
Algorithmic paradigm,"An algorithmic paradigm or algorithm design paradigm is a generic model or framework which underlies the design of a class of algorithms. An algorithmic paradigm is an abstraction higher than the notion of an algorithm, just as an algorithm is an abstraction higher than a computer program.","An algorithmic paradigm or algorithm design paradigm is a generic model or framework which underlies the design of a class of algorithms. An algorithmic paradigm is an abstraction higher than the notion of an algorithm, just as an algorithm is an abstraction higher than a computer program.

List of well-known paradigms
General
Backtracking
Branch and bound
Brute-force search
Divide and conquer
Dynamic programming
Greedy algorithm
Recursion
Prune and search

Parameterized complexity
Kernelization
Iterative compression

Computational geometry
Sweep line algorithms
Rotating calipers
Randomized incremental construction


== References ==",51411922,https://en.wikipedia.org/wiki/Algorithmic_paradigm
Algorithmic Puzzles,"Algorithmic Puzzles is a book of puzzles based on computational thinking. It was written by computer scientists Anany and Maria Levitin, and published in 2011 by Oxford University Press.","Algorithmic Puzzles is a book of puzzles based on computational thinking. It was written by computer scientists Anany and Maria Levitin, and published in 2011 by Oxford University Press.

Topics
The book begins with a ""tutorial"" introducing classical algorithm design techniques including backtracking, divide-and-conquer algorithms, and dynamic programming, methods for the analysis of algorithms, and their application in example puzzles. The puzzles themselves are grouped into three sets of 50 puzzles, in increasing order of difficulty. A final two chapters provide brief hints and more detailed solutions to the puzzles, with the solutions forming the majority of pages of the book.Some of the puzzles are well known classics, some are variations of known puzzles making them more algorithmic, and some are new. They include:

Puzzles involving chessboards, including the eight queens puzzle, knight's tours, and the mutilated chessboard problem
Balance puzzles
River crossing puzzles
The Tower of Hanoi
Finding the missing element in a data stream
The geometric median problem for Manhattan distance

Audience and reception
The puzzles in the book cover a wide range of difficulty, and in general do not require more than a high school level of mathematical background.William Gasarch notes that grouping the puzzles only by their difficulty and not by their themes is actually an advantage, as it provides readers with fewer clues about their solutions.Reviewer Narayanan Narayanan recommends the book to any puzzle aficionado, or to anyone who wants to develop their powers of algorithmic thinking. Reviewer Martin Griffiths suggests another group of readers, schoolteachers and university instructors in search of examples to illustrate the power of algorithmic thinking.
Gasarch recommends the book to any computer scientist, evaluating it as ""a delight"".


== References ==",64447976,https://en.wikipedia.org/wiki/Algorithmic_Puzzles
Algorithmic transparency,"Algorithmic transparency is the principle that the factors that influence the decisions made by algorithms should be visible, or transparent, to the people who use, regulate, and are affected by systems that employ those algorithms. Although the phrase was coined in 2016 by Nicholas Diakopoulos and Michael Koliska about the role of algorithms in deciding the content of digital journalism services, the underlying principle dates back to the 1970s and the rise of automated systems for scoring consumer credit.
The phrases ""algorithmic transparency"" and ""algorithmic accountability"" are sometimes used interchangeably – especially since they were coined by the same people – but they have subtly different meanings. Specifically, ""algorithmic transparency"" states that the inputs to the algorithm and the algorithm's use itself must be known, but they need not be fair.  ""Algorithmic accountability"" implies that the organizations that use algorithms must be accountable for the decisions made by those algorithms, even though the decisions are being made by a machine, and not by a human being.Current research around algorithmic transparency interested in both societal effects of accessing remote services running algorithms., as well as mathematical and computer science approaches that can be used to achieve algorithmic transparency In the United States, the Federal Trade Commission's Bureau of Consumer Protection studies how algorithms are used by consumers by conducting its own research on algorithmic transparency and by funding external research. In the European Union, the data protection laws that came into effect in May 2018 include a ""right to explanation"" of decisions made by algorithms, though it is unclear what this means. Furthermore, the European Union founded The European Center for Algoritmic Transparency (ECAT).","Algorithmic transparency is the principle that the factors that influence the decisions made by algorithms should be visible, or transparent, to the people who use, regulate, and are affected by systems that employ those algorithms. Although the phrase was coined in 2016 by Nicholas Diakopoulos and Michael Koliska about the role of algorithms in deciding the content of digital journalism services, the underlying principle dates back to the 1970s and the rise of automated systems for scoring consumer credit.
The phrases ""algorithmic transparency"" and ""algorithmic accountability"" are sometimes used interchangeably – especially since they were coined by the same people – but they have subtly different meanings. Specifically, ""algorithmic transparency"" states that the inputs to the algorithm and the algorithm's use itself must be known, but they need not be fair.  ""Algorithmic accountability"" implies that the organizations that use algorithms must be accountable for the decisions made by those algorithms, even though the decisions are being made by a machine, and not by a human being.Current research around algorithmic transparency interested in both societal effects of accessing remote services running algorithms., as well as mathematical and computer science approaches that can be used to achieve algorithmic transparency In the United States, the Federal Trade Commission's Bureau of Consumer Protection studies how algorithms are used by consumers by conducting its own research on algorithmic transparency and by funding external research. In the European Union, the data protection laws that came into effect in May 2018 include a ""right to explanation"" of decisions made by algorithms, though it is unclear what this means. Furthermore, the European Union founded The European Center for Algoritmic Transparency (ECAT).

See also
Black box
Explainable AI
Regulation of algorithms
Reverse engineering
Right to explanation
Algorithmic accountability


== References ==",52773150,https://en.wikipedia.org/wiki/Algorithmic_transparency
Algorithms and Combinatorics,"Algorithms and Combinatorics (ISSN 0937-5511) is a book series in mathematics, and particularly in combinatorics and the design and analysis of algorithms. It is published by Springer Science+Business Media, and was founded in 1987.","Algorithms and Combinatorics (ISSN 0937-5511) is a book series in mathematics, and particularly in combinatorics and the design and analysis of algorithms. It is published by Springer Science+Business Media, and was founded in 1987.

Books
As of 2018, the books published in this series include:
The Simplex Method: A Probabilistic Analysis (Karl Heinz Borgwardt, 1987, vol. 1)
Geometric Algorithms and Combinatorial Optimization (Martin Grötschel, László Lovász, and Alexander Schrijver, 1988, vol. 2; 2nd ed., 1993)
Systems Analysis by Graphs and Matroids (Kazuo Murota, 1987, vol. 3)
Greedoids (Bernhard Korte, László Lovász, and Rainer Schrader, 1991, vol. 4)
Mathematics of Ramsey Theory (Jaroslav Nešetřil and Vojtěch Rödl, eds., 1990, vol. 5)
Matroid Theory and its Applications in Electric Network Theory and in Statics (Andras Recszki, 1989, vol. 6)
Irregularities of Partitions: Papers from the meeting held in Fertőd, July 7–11, 1986 (Gábor Halász and Vera T. Sós, eds., 1989, vol. 8)
Paths, Flows, and VLSI-Layout: Papers from the meeting held at the University of Bonn, Bonn, June 20–July 1, 1988 (Bernhard Korte, László Lovász, Hans Jürgen Prömel, and Alexander Schrijver, eds., 1990, vol. 9)
New Trends in Discrete and Computational Geometry (János Pach, ed., 1993, vol. 10)
Discrete Images, Objects, and Functions in Zn{\displaystyle \mathbb {Z} ^{n}} (Klaus Voss, 1993, vol. 11)
Linear Optimization and Extensions (Manfred Padberg, 1999, vol. 12)
The Mathematics of Paul Erdös I (Ronald Graham and Jaroslav Nešetřil, eds., 1997, vol. 13)
The Mathematics of Paul Erdös II (Ronald Graham and Jaroslav Nešetřil, eds., 1997, vol. 14)
Geometry of Cuts and Metrics (Michel Deza and Monique Laurent, 1997, vol. 15)
Probabilistic Methods for Algorithmic Discrete Mathematics (M. Habib, C. McDiarmid, J. Ramirez-Alfonsin, and B. Reed, 1998, vol. 16)
Modern Cryptography, Probabilistic Proofs and Pseudorandomness (Oded Goldreich, 1999, vol. 17)
Geometric Discrepancy: An Illustrated Guide (Jiří Matoušek, 1999, vol. 18)
Applied Finite Group Actions (Adalbert Kerber, 1999, vol. 19)
Matrices and Matroids for Systems Analysis (Kazuo Murota, 2000, vol. 20; corrected ed., 2010)
Combinatorial Optimization (Bernhard Korte and Jens Vygen, 2000, vol. 21; 5th ed., 2012)
The Strange Logic of Random Graphs (Joel Spencer, 2001, vol. 22)
Graph Colouring and the Probabilistic Method (Michael Molloy and Bruce Reed, 2002, Vol. 23)
Combinatorial Optimization: Polyhedra and Efficiency (Alexander Schrijver, 2003, vol. 24. In three volumes: A. Paths, flows, matchings; B. Matroids, trees, stable sets; C. Disjoint paths, hypergraphs)
Discrete and Computational Geometry: The Goodman-Pollack Festschrift (B. Aronov, S. Basu, J. Pach, and M. Sharir, eds., 2003, vol. 25)
Topics in Discrete Mathematics: Dedicated to Jarik Nešetril on the Occasion of his 60th birthday (M. Klazar, J. Kratochvíl, M. Loebl, J. Matoušek, R. Thomas, and P. Valtr, eds., 2006, vol. 26)
Boolean Function Complexity: Advances and Frontiers (Stasys Jukna, 2012, Vol. 27)
Sparsity: Graphs, Structures, and Algorithms (Jaroslav Nešetřil and Patrice Ossona de Mendez, 2012, vol. 28)
Optimal Interconnection Trees in the Plane (Marcus Brazil and Martin Zachariasen, 2015, vol. 29)
Combinatorics and Complexity of Partition Functions (Alexander Barvinok, 2016, vol. 30)


== References ==",57504451,https://en.wikipedia.org/wiki/Algorithms_and_Combinatorics
Algorithms of Oppression,"Algorithms of Oppression: How Search Engines Reinforce Racism is a 2018 book by Safiya Umoja Noble in the fields of information science, machine learning, and human-computer interaction.","Algorithms of Oppression: How Search Engines Reinforce Racism is a 2018 book by Safiya Umoja Noble in the fields of information science, machine learning, and human-computer interaction.

Background
Noble earned an undergraduate degree in sociology from California State University, Fresno in the 1990s, then worked in advertising and marketing for fifteen years before going to the University of Illinois Urbana-Champaign for a Master of Library and Information Science degree in the early 2000s. The book's first inspiration came in 2011, when Noble Googled the phrase ""black girls"" and saw results for pornography on the first page. Noble's doctoral thesis, completed in 2012, was titled ""Searching for Black girls: Old traditions in new media."" At this time, Noble thought of the title ""Algorithms of Oppression"" for the eventual book. By this time, changes to Google's algorithm had changed the most common results for a search of ""black girls,"" though the underlying biases remain influential. Noble became an assistant professor at University of California, Los Angeles in 2014. In 2017, she published an article on racist and sexist bias in search engines in The Chronicle of Higher Education. The book was published on February 20, 2018.

Overview
Algorithms of Oppression is a text based on over six years of academic research on Google search algorithms, examining search results from 2009 to 2015. The book addresses the relationship between search engines and discriminatory biases. Noble argues that search algorithms are racist and perpetuate societal problems because they reflect the negative biases that exist in society and the people who create them.  Noble dismantles the idea that search engines are inherently neutral by explaining how algorithms in search engines privilege whiteness by depicting positive cues when key words like “white” are searched as opposed to “asian,”  “hispanic,”  or “Black.” Her main example surrounds the search results of ""Black girls"" versus ""white girls"" and the biases that are depicted in the results. These algorithms can then have negative biases against women of color and other marginalized populations, while also affecting Internet users in general by leading to ""racial and gender profiling, misrepresentation, and even economic redlining."" The book argues that algorithms perpetuate oppression and discriminate against People of Color, specifically women of color.   
Noble takes a Black intersectional feminist approach to her work in studying how google algorithms affect people differently by race and gender. Intersectional Feminism takes into account the diverse experiences of women of different races and sexualities when discussing their oppression society, and how their distinct backgrounds affect their struggles. Additionally, Noble's argument addresses how racism infiltrates the google algorithm itself, something that is true throughout many coding systems including facial recognition, and medical care programs.  While many new technological systems promote themselves as progressive and unbiased, Noble is arguing against this point and saying that many technologies, including google's algorithm ""reflect and reproduce existing inequities.""

Chapter Summaries
Chapter 1
In Chapter 1 of Algorithms of Oppression, Safiya Noble explores how Google search's auto suggestion feature is demoralizing. On September 18, 2011, a mother googled “black girls” attempting to find fun activities to show her stepdaughter and nieces. To her surprise, the results encompassed websites and images of porn. This result encloses the data failures specific to people of color and women which Noble coins algorithmic oppression. Noble also adds that as a society we must have a feminist lens, with racial awareness to understand the “problematic positions about the benign instrumentality of technologies.”Noble also discusses how Google can remove the human curation from the first page of results to eliminate any potential racial slurs or inappropriate imaging. Another example discussed in this text is a public dispute of the results that were returned when  “Jew” was searched on Google. The results included a number of anti-Semitic pages and Google claimed little ownership for the way it provided these identities. Google instead encouraged people to use “Jews” or “Jewish people” and claimed the actions of White supremacist groups are out of Google's control. Unless pages are unlawful, Google will allow its algorithm to continue to act without removing pages.
Noble reflects on AdWords which is Google's advertising tool and how this tool can add to the biases on Google. Adwords allows anyone to advertise on Google's search pages and is highly customizable. First, Google ranks ads on relevance and then displays the ads on pages which it believes are relevant to the search query taking place. An advertiser can also set a maximum amount of money per day to spend on advertising. The more you spend on ads, the higher probability your ad will be closer to the top. Therefore, if an advertiser is passionate about his/her topic but it is controversial it may be the first to appear on a Google search.

Chapter 2
In Chapter 2 of Algorithms of Oppression, Noble explains that Google has exacerbated racism and how they continue to deny responsibility for it. Google puts the blame on those who have created the content and as well as those who are actively seeking this information. Google's algorithm has maintained social inequalities and stereotypes for Black, Latina, and Asian women, mostly due in part to Google's design and infrastructure that normalizes whiteness and men. She explains that the Google algorithm categorizes information which exacerbates stereotypes while also encouraging white hegemonic norms. Noble found that after searching for black girls, the first search results were common stereotypes of black girls, or the categories that Google created based on their own idea of a black girl. Google hides behind their algorithm that has been proven to perpetuate inequalities.

Chapter 3
In Chapter 3 of Algorithms of Oppression, Safiya Noble discusses how Google's search engine combines multiple sources to create threatening narratives about minorities. She explains a case study where she searched “black on white crimes” on Google. Noble highlights that the sources and information that were found after the search pointed to conservative sources that skewed information. These sources displayed racist and anti-black information from white supremacist sources. Ultimately, she believes this readily-available, false information fueled the actions of white supremacist Dylann Roof, who committed a massacre

Chapter 4
In Chapter 4 of Algorithms of Oppression, Noble furthers her argument by discussing the way in which Google has oppressive control over identity. This chapter highlights multiple examples of women being shamed due to their activity in the porn industry, regardless if it was consensual or not. She critiques the internet's ability to influence one's future due to its permanent nature and compares U.S. privacy laws to those of the European Union, which provides citizens with “the right to forget or be forgotten.” When utilizing search engines such as Google, these breaches of privacy disproportionately affect women and people of color. Google claims that they safeguard our data in order to protect us from losing our information, but fails to address what happens when you want your data to be deleted.

Chapter 5
In Chapter 5 of Algorithms of Oppression, Noble moves the discussion away from google and onto other information sources deemed credible and neutral. Noble says that prominent libraries, including the Library of Congress, encourage whiteness, heteronormativity, patriarchy and other societal standards as correct, and alternatives as problematic. She explains this problem by discussing a case between Dartmouth College and the Library of Congress where ""student-led organization the Coalition for Immigration Reform, Equality (CoFired) and DREAMers"" engaged in a two-year battle to change the Library's terminology from 'illegal aliens' to 'noncitizen' or 'unauthorised immigrants.' Noble later discusses the problems that ensue from misrepresentation and classification which allows her to enforce the importance of contextualisation. Noble argues that it is not just google, but all digital search engines that reinforce societal structures and discriminatory biases and by doing so she points out just how interconnected technology and society are.

Chapter 6
In Chapter 6 of Algorithms of Oppression, Safiya Noble discusses possible solutions for the problem of algorithmic bias. She first argues that public policies enacted by local and federal governments will reduce Google's “information monopoly” and regulate the ways in which search engines filter their results. She insists that governments and corporations bear the most responsibility to reform the systemic issues leading to algorithmic bias. 
Simultaneously, Noble condemns the common neoliberal argument that algorithmic biases will disappear if more women and racial minorities enter the industry as software engineers. She calls this argument “complacent” because it places responsibility on individuals, who have less power than media companies, and indulges a mindset she calls “big-data optimism,” or a failure to challenge the notion that the institutions themselves do not always solve, but sometimes perpetuate inequalities. To illustrate this point, she uses the example of Kandis, a Black hairdresser whose business faces setbacks because the review site Yelp has used biased advertising practices and searching strategies against her. 
She closes the chapter by calling upon the Federal Communications Commission (FCC) and the Federal Trade Commission (FTC) to “regulate decency,” or to limit the amount of racist, homophobic, or prejudiced rhetoric on the Internet. She urges the public to shy away from “colorblind” ideologies toward race because it has historically erased the struggles faced by racial minorities. Lastly, she points out that big-data optimism leaves out discussion about the harms that big data can disproportionately enact upon minority communities.

Conclusion
In Algorithms of Oppression, Safiya Noble explores the social and political implications of the results from our Google searches and our search patterns online. Noble challenges the idea of the internet being a fully democratic or post-racial environment. Each chapter examines different layers to the algorithmic biases formed by search engines. By outlining crucial points and theories throughout the book, Algorithms of Oppression is not limited to only academic readers. This allows for Noble's writing to reach a wider and more inclusive audience.

Critical reception
Critical reception for Algorithms of Oppression has been largely positive. In the Los Angeles Review of Books, Emily Drabinski writes, ""What emerges from these pages is the sense that Google’s algorithms of oppression comprise just one of the hidden infrastructures that govern our daily lives, and that the others are likely just as hard-coded with white supremacy and misogyny as the one that Noble explores."" In PopMatters, Hans Rollman writes that Algorithms of Oppression ""demonstrate[s] that search engines, and in particular Google, are not simply imperfect machines, but systems designed by humans in ways that replicate the power structures of the western countries where they are built, complete with all the sexism and racism that are built into those structures."" In Booklist, reviewer Lesley Williams states, ""Noble’s study should prompt some soul-searching about our reliance on commercial search engines and about digital social equity.""In early February 2018, Algorithms of Oppression received press attention when the official Twitter account for the Institute of Electrical and Electronics Engineers expressed criticism of the book, saying that the results of a Google search suggested in its blurb did not match Noble's predictions. IEEE's outreach historian, Alexander Magoun, later revealed that he had not read the book, and issued an apology.

See also
Algorithmic bias
Techlash

References
External links
Algorithms of Oppression: How Search Engines Reinforce Racism",56463048,https://en.wikipedia.org/wiki/Algorithms_of_Oppression
Automate This,"Automate This: How Algorithms Came to Rule Our World is a book written by Christopher Steiner and published by Penguin Group. Steiner begins his study of algorithms on Wall Street in the 1980s but also provides examples from other industries.  For example, he explains the history of Pandora Radio and the use of algorithms in music identification.  He expresses concern that such use of algorithms may lead to the homogenization of music over time. Steiner also discusses the algorithms that eLoyalty (now owned by Mattersight Corporation following divestiture of the technology) was created by dissecting 2 million speech patterns and can now identify a caller's personality style and direct the caller with a compatible customer support representative.Steiner's book shares both the warning and the opportunity that algorithms bring to just about every industry in the world, and the pros and cons of the societal impact of automation (e.g. impact on employment).","Automate This: How Algorithms Came to Rule Our World is a book written by Christopher Steiner and published by Penguin Group. Steiner begins his study of algorithms on Wall Street in the 1980s but also provides examples from other industries.  For example, he explains the history of Pandora Radio and the use of algorithms in music identification.  He expresses concern that such use of algorithms may lead to the homogenization of music over time. Steiner also discusses the algorithms that eLoyalty (now owned by Mattersight Corporation following divestiture of the technology) was created by dissecting 2 million speech patterns and can now identify a caller's personality style and direct the caller with a compatible customer support representative.Steiner's book shares both the warning and the opportunity that algorithms bring to just about every industry in the world, and the pros and cons of the societal impact of automation (e.g. impact on employment).

See also
Technological unemployment
Race Against The Machine: How the Digital Revolution is Accelerating Innovation, Driving Productivity, and Irreversibly Transforming Employment and the Economy


== References ==",39045480,https://en.wikipedia.org/wiki/Automate_This
AVT Statistical filtering algorithm,"AVT Statistical filtering algorithm is an approach to improving quality of raw data collected from various sources. It is most effective in cases when there is inband noise present. In those cases AVT is better at filtering data then, band-pass filter or any digital filtering based on variation of.
Conventional filtering is useful when signal/data has different frequency than noise and signal/data is separated/filtered by frequency discrimination of noise. Frequency discrimination filtering is done using Low Pass, High Pass and Band Pass filtering which refers to relative frequency filtering criteria target for such configuration. Those filters are created using passive and active components and sometimes are implemented using software algorithms based on Fast Fourier transform (FFT).
AVT filtering is implemented in software and its inner working is based on statistical analysis of raw data.
When signal frequency/(useful data distribution frequency) coincides with noise frequency/(noisy data distribution frequency) we have inband noise. In this situations frequency discrimination filtering does not work since the noise and useful signal are indistinguishable and where AVT excels. To achieve filtering in such conditions there are several methods/algorithms available which are briefly described below.","AVT Statistical filtering algorithm is an approach to improving quality of raw data collected from various sources. It is most effective in cases when there is inband noise present. In those cases AVT is better at filtering data then, band-pass filter or any digital filtering based on variation of.
Conventional filtering is useful when signal/data has different frequency than noise and signal/data is separated/filtered by frequency discrimination of noise. Frequency discrimination filtering is done using Low Pass, High Pass and Band Pass filtering which refers to relative frequency filtering criteria target for such configuration. Those filters are created using passive and active components and sometimes are implemented using software algorithms based on Fast Fourier transform (FFT).
AVT filtering is implemented in software and its inner working is based on statistical analysis of raw data.
When signal frequency/(useful data distribution frequency) coincides with noise frequency/(noisy data distribution frequency) we have inband noise. In this situations frequency discrimination filtering does not work since the noise and useful signal are indistinguishable and where AVT excels. To achieve filtering in such conditions there are several methods/algorithms available which are briefly described below.

Averaging algorithm
Collect n samples of data
Calculate average value of collected data
Present/record result as actual data

Median algorithm
Collect n samples of data
Sort the data in ascending or descending order. Note that order does not matter
Select the data that happen to be in n/2 position and present/record it as final result representing data sample

AVT algorithm
AVT algorithm stands for Antonyan Vardan Transform and its implementation explained below.

Collect n samples of data
Calculate the standard deviation and average value
Drop any data that is greater or less than average ± one standard deviation
Calculate average value of remaining data
Present/record result as actual value representing data sampleThis algorithm is based on amplitude discrimination and can easily reject any noise that is not like actual signal, otherwise statistically different then 1 standard deviation of the signal. Note that this type of filtering can be used in situations where the actual environmental noise is not known in advance. Notice that it is preferable to use the median in above steps than average. Originally the AVT algorithm used average value to compare it with results of median on the data window.

Filtering algorithms comparison
Using a system that has signal value of 1 and has noise added at 0.1% and 1% levels will simplify quantification of algorithm performance. The R script is used to create pseudo random noise added to signal and analyze the results of filtering using several algorithms. Please refer to ""Reduce Inband Noise with the AVT Algorithm""  article for details.
This graphs show that AVT algorithm provides best results compared with Median and Averaging algorithms while using data sample size of 32, 64 and 128 values. Note that this graph was created by analyzing random data array of 10000 values. Sample of this data is graphically represented below. From this graph it is apparent that AVT outperforms other filtering algorithms by providing 5% to 10% more accurate data when analyzing same datasets. Considering random nature of noise used in this numerical experiment that borderlines worst case situation where actual signal level is below ambient noise the precision improvements of processing data with AVT algorithm are significant.

AVT algorithm variations
Cascaded AVT
In some situations better results can be obtained by cascading several stages of AVT filtering. This will produce singular constant value which can be used for equipment that has known stable characteristics like thermometers, thermistors and other slow acting sensors.

Reverse AVT
Collect n samples of data
Calculate the standard deviation and average value
Drop any data that is within one standard deviation ± average band
Calculate average value of remaining data
Present/record result as actual dataThis is useful for detecting minute signals that are close to background noise level.

Possible applications and uses
Use to filter data that is near or below noise level
Used in planet detection to filter out raw data from Kepler (spacecraft)
Filter out noise from sound sources where all other filtering methods (Low-pass filter, High-pass filter, Band-pass filter, Digital filter) fail.
Pre-process scientific data for data analysis (Smoothness) before plotting see (Plot (graphics))
Used in SETI (Search for extraterrestrial intelligence) for detecting/distinguishing extraterrestrial signals from cosmic background
Use AVT as image filtering algorithm to detect altered images, please see Python program that is available for download. This image of Jupiter generated from this program, detecting alterations in original picture that was modified to be visually appealing by applying filters.Another version of this comparison is the Reverse AVT filter applied to the same original Jupiter Image, where we only see that altered portion as Noise that was eliminated by AVT algorithm.

Use AVT as image filtering algorithm to estimate data density  from images, please see Python program program. Picture of Pillars of Creation Nebula shows data density in filtered images from Hubble and Webb. Note that image on the left has big patches of missing data marked with simpler color patterns.

References

Joseph, Favis; Balinadoa, C.; Paolo Dar Santos, Gerald; Escanilla, Rio; Darell C. Aguda, John; Ramona A. Alcantara, Ma.; Belen M. Roble, Mariela; F. Bueser, Jomalyn (May 5, 2020). ""Design and implementation of water velocity monitoring system based on hydropower generation and antonyan vardan transform (AVT) statistics"". 13Th International Engineering Research Conference (13Th Eureca 2019). Vol. 2233. p. 050003. doi:10.1063/5.0002323.
Vinicius, Cene; Mauricio, Tosin; J., Machado; A., Balbinot (April 2019). ""Open Database for Accurate Upper-Limb Intent Detection Using Electromyography and Reliable Extreme Learning Machines"". Sensors. 19 (8): 1864. Bibcode:2019Senso..19.1864C. doi:10.3390/s19081864. PMC 6515272. PMID 31003524.
HornCene, Vinicius; Balbinot, Alexandr (August 10, 2018), ""Using the sEMG signal representativity improvement towards upper-limb movement classification reliability"", Biomedical Signal Processing and Control, 46: 182–191, doi:10.1016/j.bspc.2018.07.014, ISSN 1746-8094, S2CID 52071917
Horn Cene, Vinicius; Ruschel dos Santos, Raphael; Balbinot, Alexandre (July 18, 2018). 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). Honolulu, HI, USA: IEEE. pp. 5224–5227. doi:10.1109/EMBC.2018.8513468. ISBN 978-1-5386-3646-6.
AVT image Filtering algorithm in python",44995795,https://en.wikipedia.org/wiki/AVT_Statistical_filtering_algorithm
Bartels–Stewart algorithm,"In numerical linear algebra, the Bartels–Stewart algorithm is used to numerically solve the Sylvester matrix equation AX−XB=C{\displaystyle AX-XB=C}. Developed by R.H. Bartels and G.W. Stewart in 1971, it was the first numerically stable method that could be systematically applied to solve such equations. The algorithm works by using the real Schur decompositions of A{\displaystyle A} and B{\displaystyle B} to transform AX−XB=C{\displaystyle AX-XB=C} into a triangular system that can then be solved using forward or backward substitution. In 1979, G. Golub, C. Van Loan and S. Nash introduced an improved version of the algorithm, known as the Hessenberg–Schur algorithm. It remains a standard approach for solving  Sylvester equations when X{\displaystyle X} is of small to moderate size.","In numerical linear algebra, the Bartels–Stewart algorithm is used to numerically solve the Sylvester matrix equation AX−XB=C{\displaystyle AX-XB=C}. Developed by R.H. Bartels and G.W. Stewart in 1971, it was the first numerically stable method that could be systematically applied to solve such equations. The algorithm works by using the real Schur decompositions of A{\displaystyle A} and B{\displaystyle B} to transform AX−XB=C{\displaystyle AX-XB=C} into a triangular system that can then be solved using forward or backward substitution. In 1979, G. Golub, C. Van Loan and S. Nash introduced an improved version of the algorithm, known as the Hessenberg–Schur algorithm. It remains a standard approach for solving  Sylvester equations when X{\displaystyle X} is of small to moderate size.

The algorithm
Let X,C∈Rm×n{\displaystyle X,C\in \mathbb {R} ^{m\times n}}, and assume that the eigenvalues of A{\displaystyle A} are distinct from the eigenvalues of B{\displaystyle B}. Then, the matrix equation AX−XB=C{\displaystyle AX-XB=C} has a unique solution. The Bartels–Stewart algorithm computes X{\displaystyle X} by applying the following steps:1.Compute the real Schur decompositions

R=UTAU,{\displaystyle R=U^{T}AU,}S=VTBTV.{\displaystyle S=V^{T}B^{T}V.}The matrices R{\displaystyle R} and S{\displaystyle S} are block-upper triangular matrices, with diagonal blocks of size 1×1{\displaystyle 1\times 1} or 2×2{\displaystyle 2\times 2}.
2. Set F=UTCV.{\displaystyle F=U^{T}CV.}
3. Solve the  simplified system RY−YST=F{\displaystyle RY-YS^{T}=F}, where Y=UTXV{\displaystyle Y=U^{T}XV}. This can be done using forward substitution on the blocks. Specifically, if sk−1,k=0{\displaystyle s_{k-1,k}=0}, then

(R−skkI)yk=fk+∑j=k+1nskjyj,{\displaystyle (R-s_{kk}I)y_{k}=f_{k}+\sum _{j=k+1}^{n}s_{kj}y_{j},}where yk{\displaystyle y_{k}}is the k{\displaystyle k}th column of Y{\displaystyle Y}. When sk−1,k≠0{\displaystyle s_{k-1,k}\neq 0}, columns [yk−1∣yk]{\displaystyle [y_{k-1}\mid y_{k}]}  should be concatenated and solved for simultaneously. 
4. Set X=UYVT.{\displaystyle X=UYV^{T}.}

Computational cost
Using the QR algorithm, the  real Schur decompositions in step 1 require approximately 10(m3+n3){\displaystyle 10(m^{3}+n^{3})} flops, so that the overall computational cost is  10(m3+n3)+2.5(mn2+nm2){\displaystyle 10(m^{3}+n^{3})+2.5(mn^{2}+nm^{2})}.

Simplifications and special cases
In the special case where B=−AT{\displaystyle B=-A^{T}} and C{\displaystyle C} is symmetric, the solution X{\displaystyle X} will also be symmetric. This symmetry can be exploited so that Y{\displaystyle Y} is found more efficiently in step 3 of the algorithm.

The Hessenberg–Schur algorithm
The Hessenberg–Schur algorithm replaces the decomposition R=UTAU{\displaystyle R=U^{T}AU} in step 1 with the decomposition H=QTAQ{\displaystyle H=Q^{T}AQ}, where H{\displaystyle H} is an  upper-Hessenberg matrix. This leads to a system of the form HY−YST=F{\displaystyle HY-YS^{T}=F} that can be solved using forward substitution. The advantage of this approach is that H=QTAQ{\displaystyle H=Q^{T}AQ} can be found using  Householder reflections at a cost of (5/3)m3{\displaystyle (5/3)m^{3}} flops, compared to the 10m3{\displaystyle 10m^{3}} flops required to compute the real Schur decomposition of A{\displaystyle A}.

Software and implementation
The subroutines required for the Hessenberg-Schur variant of the Bartels–Stewart  algorithm are implemented in the SLICOT library. These are used in the MATLAB control system toolbox.

Alternative approaches
For large systems, the O(m3+n3){\displaystyle {\mathcal {O}}(m^{3}+n^{3})} cost of the Bartels–Stewart algorithm can be prohibitive. When A{\displaystyle A} and B{\displaystyle B} are sparse or structured, so that linear solves and matrix vector multiplies involving them are efficient, iterative algorithms can potentially perform better. These include projection-based methods, which use Krylov subspace iterations, methods based on the alternating direction implicit (ADI) iteration, and hybridizations that involve both projection and ADI.  Iterative methods can also be used to directly construct low rank approximations to X{\displaystyle X} when solving AX−XB=C{\displaystyle AX-XB=C}. 


== References ==",58536963,https://en.wikipedia.org/wiki/Bartels%E2%80%93Stewart_algorithm
Behavior selection algorithm,"In artificial intelligence, a behavior selection algorithm, or action selection algorithm, is an algorithm that selects appropriate behaviors or actions for one or more intelligent agents. In game artificial intelligence, it selects behaviors or actions for one or more non-player characters. Common behavior selection algorithms include:

Finite-state machines
Hierarchical finite-state machines
Decision trees
Behavior trees
Hierarchical task networks
Hierarchical control systems
Utility systems
Dialogue tree (for selecting what to say)","In artificial intelligence, a behavior selection algorithm, or action selection algorithm, is an algorithm that selects appropriate behaviors or actions for one or more intelligent agents. In game artificial intelligence, it selects behaviors or actions for one or more non-player characters. Common behavior selection algorithms include:

Finite-state machines
Hierarchical finite-state machines
Decision trees
Behavior trees
Hierarchical task networks
Hierarchical control systems
Utility systems
Dialogue tree (for selecting what to say)

Related concepts
In application programming, run-time selection of the behavior of a specific method is referred to as the strategy design pattern.

See also
AI alignment
Artificial intelligence detection software
Cognitive model - all cognitive models exhibit behavior in terms of making decisions (taking action), making errors, and with various reaction times.
Behavioral modeling, in systems theory
Behavioral modeling in hydrology
Behavioral modeling in computer-aided design
Behavioral modeling language
Case-based reasoning, solving new problems based on solutions of past problems
Model-based reasoning
Synthetic intelligence
Weak AI


== References ==",47893974,https://en.wikipedia.org/wiki/Behavior_selection_algorithm
Berlekamp–Rabin algorithm,"In number theory, Berlekamp's root finding algorithm, also called the Berlekamp–Rabin algorithm, is the probabilistic method of finding roots of polynomials over the field Fp{\displaystyle \mathbb {F} _{p}} with p{\displaystyle p} elements. The method was discovered by Elwyn Berlekamp in 1970 as an auxiliary to the algorithm for polynomial factorization over finite fields. The algorithm was later modified by Rabin for arbitrary finite fields in 1979. The method was also independently discovered before Berlekamp by other researchers.","In number theory, Berlekamp's root finding algorithm, also called the Berlekamp–Rabin algorithm, is the probabilistic method of finding roots of polynomials over the field Fp{\displaystyle \mathbb {F} _{p}} with p{\displaystyle p} elements. The method was discovered by Elwyn Berlekamp in 1970 as an auxiliary to the algorithm for polynomial factorization over finite fields. The algorithm was later modified by Rabin for arbitrary finite fields in 1979. The method was also independently discovered before Berlekamp by other researchers.

History
The method was proposed by Elwyn Berlekamp in his 1970 work on polynomial factorization over finite fields. His original work lacked a formal correctness proof and was later refined and modified for arbitrary finite fields by Michael Rabin. In 1986 René Peralta proposed a similar algorithm for finding square roots in Fp{\displaystyle \mathbb {F} _{p}}. In 2000 Peralta's method was generalized for cubic equations.

Statement of problem
Let p{\displaystyle p} be an odd prime number. Consider the polynomial f(x)=a0+a1x+⋯+anxn{\textstyle f(x)=a_{0}+a_{1}x+\cdots +a_{n}x^{n}} over the field Fp≃Z/pZ{\displaystyle \mathbb {F} _{p}\simeq \mathbb {Z} /p\mathbb {Z} } of remainders modulo p{\displaystyle p}. The algorithm should find all λ{\displaystyle \lambda } in Fp{\displaystyle \mathbb {F} _{p}} such that f(λ)=0{\textstyle f(\lambda )=0} in Fp{\displaystyle \mathbb {F} _{p}}.

Algorithm
Randomization
Let f(x)=(x−λ1)(x−λ2)⋯(x−λn){\textstyle f(x)=(x-\lambda _{1})(x-\lambda _{2})\cdots (x-\lambda _{n})}. Finding all roots of this polynomial is equivalent to finding its factorization into linear factors. To find such factorization it is sufficient to split the polynomial into any two non-trivial divisors and factorize them recursively. To do this, consider the polynomial fz(x)=f(x−z)=(x−λ1−z)(x−λ2−z)⋯(x−λn−z){\textstyle f_{z}(x)=f(x-z)=(x-\lambda _{1}-z)(x-\lambda _{2}-z)\cdots (x-\lambda _{n}-z)} where z{\displaystyle z} is some any element of Fp{\displaystyle \mathbb {F} _{p}}. If one can represent this polynomial as the product fz(x)=p0(x)p1(x){\displaystyle f_{z}(x)=p_{0}(x)p_{1}(x)} then in terms of the initial polynomial it means that f(x)=p0(x+z)p1(x+z){\displaystyle f(x)=p_{0}(x+z)p_{1}(x+z)}, which provides needed factorization of f(x){\displaystyle f(x)}.

Classification of Fp{\displaystyle \mathbb {F} _{p}} elements
Due to Euler's criterion, for every monomial (x−λ){\displaystyle (x-\lambda )} exactly one of following properties holds:
The monomial is equal to x{\displaystyle x} if λ=0{\displaystyle \lambda =0},
The monomial divides g0(x)=(x(p−1)/2−1){\textstyle g_{0}(x)=(x^{(p-1)/2}-1)} if λ{\displaystyle \lambda } is quadratic residue modulo p{\displaystyle p},
The monomial divides g1(x)=(x(p−1)/2+1){\textstyle g_{1}(x)=(x^{(p-1)/2}+1)} if λ{\displaystyle \lambda } is quadratic non-residual modulo p{\displaystyle p}.Thus if fz(x){\displaystyle f_{z}(x)} is not divisible by x{\displaystyle x}, which may be checked separately, then fz(x){\displaystyle f_{z}(x)} is equal to the product of greatest common divisors gcd(fz(x);g0(x)){\displaystyle \gcd(f_{z}(x);g_{0}(x))} and gcd(fz(x);g1(x)){\displaystyle \gcd(f_{z}(x);g_{1}(x))}.

Berlekamp's method
The property above leads to the following algorithm:
Explicitly calculate coefficients of fz(x)=f(x−z){\displaystyle f_{z}(x)=f(x-z)},
Calculate remainders of x,x2,x22,x23,x24,…,x2⌊log2⁡p⌋{\textstyle x,x^{2},x^{2^{2}},x^{2^{3}},x^{2^{4}},\ldots ,x^{2^{\lfloor \log _{2}p\rfloor }}} modulo fz(x){\displaystyle f_{z}(x)} by squaring the current polynomial and taking remainder modulo fz(x){\displaystyle f_{z}(x)},
Using exponentiation by squaring and polynomials calculated on the previous steps calculate the remainder of x(p−1)/2{\textstyle x^{(p-1)/2}} modulo fz(x){\textstyle f_{z}(x)},
If x(p−1)/2≢±1(modfz(x)){\textstyle x^{(p-1)/2}\not \equiv \pm 1{\pmod {f_{z}(x)}}} then gcd{\displaystyle \gcd } mentioned above provide a non-trivial factorization of fz(x){\displaystyle f_{z}(x)},
Otherwise all roots of fz(x){\displaystyle f_{z}(x)} are either residues or non-residues simultaneously and one has to choose another z{\displaystyle z}.If f(x){\displaystyle f(x)} is divisible by some non-linear primitive polynomial g(x){\displaystyle g(x)} over Fp{\displaystyle \mathbb {F} _{p}} then when calculating gcd{\displaystyle \gcd } with g0(x){\displaystyle g_{0}(x)} and g1(x){\displaystyle g_{1}(x)} one will obtain a non-trivial factorization of fz(x)/gz(x){\displaystyle f_{z}(x)/g_{z}(x)}, thus algorithm allows to find all roots of arbitrary polynomials over Fp{\displaystyle \mathbb {F} _{p}}.

Modular square root
Consider equation x2≡a(modp){\textstyle x^{2}\equiv a{\pmod {p}}} having elements β{\displaystyle \beta } and −β{\displaystyle -\beta } as its roots. Solution of this equation is equivalent to factorization of polynomial f(x)=x2−a=(x−β)(x+β){\textstyle f(x)=x^{2}-a=(x-\beta )(x+\beta )} over Fp{\displaystyle \mathbb {F} _{p}}. In this particular case problem it is sufficient to calculate only gcd(fz(x);g0(x)){\displaystyle \gcd(f_{z}(x);g_{0}(x))}. For this polynomial exactly one of the following properties will hold:

GCD is equal to 1{\displaystyle 1} which means that z+β{\displaystyle z+\beta } and z−β{\displaystyle z-\beta } are both quadratic non-residues,
GCD is equal to fz(x){\displaystyle f_{z}(x)}which means that both numbers are quadratic residues,
GCD is equal to (x−t){\displaystyle (x-t)}which means that exactly one of these numbers is quadratic residue.In the third case GCD is equal to either (x−z−β){\displaystyle (x-z-\beta )} or (x−z+β){\displaystyle (x-z+\beta )}. It allows to write the solution as β=(t−z)(modp){\textstyle \beta =(t-z){\pmod {p}}}.

Example
Assume we need to solve the equation x2≡5(mod11){\textstyle x^{2}\equiv 5{\pmod {11}}}. For this we need to factorize f(x)=x2−5=(x−β)(x+β){\displaystyle f(x)=x^{2}-5=(x-\beta )(x+\beta )}. Consider some possible values of z{\displaystyle z}:

Let z=3{\displaystyle z=3}. Then fz(x)=(x−3)2−5=x2−6x+4{\displaystyle f_{z}(x)=(x-3)^{2}-5=x^{2}-6x+4}, thus gcd(x2−6x+4;x5−1)=1{\displaystyle \gcd(x^{2}-6x+4;x^{5}-1)=1}. Both numbers 3±β{\displaystyle 3\pm \beta } are quadratic non-residues, so we need to take some other z{\displaystyle z}.Let z=2{\displaystyle z=2}. Then fz(x)=(x−2)2−5=x2−4x−1{\displaystyle f_{z}(x)=(x-2)^{2}-5=x^{2}-4x-1}, thus gcd(x2−4x−1;x5−1)≡x−9(mod11){\textstyle \gcd(x^{2}-4x-1;x^{5}-1)\equiv x-9{\pmod {11}}}. From this follows x−9=x−2−β{\textstyle x-9=x-2-\beta }, so β≡7(mod11){\displaystyle \beta \equiv 7{\pmod {11}}} and −β≡−7≡4(mod11){\textstyle -\beta \equiv -7\equiv 4{\pmod {11}}}.A manual check shows that, indeed, 72≡49≡5(mod11){\textstyle 7^{2}\equiv 49\equiv 5{\pmod {11}}} and 42≡16≡5(mod11){\textstyle 4^{2}\equiv 16\equiv 5{\pmod {11}}}.

Correctness proof
The algorithm finds factorization of fz(x){\displaystyle f_{z}(x)} in all cases except for ones when all numbers z+λ1,z+λ2,…,z+λn{\displaystyle z+\lambda _{1},z+\lambda _{2},\ldots ,z+\lambda _{n}} are quadratic residues or non-residues simultaneously. According to theory of cyclotomy, the probability of such an event for the case when λ1,…,λn{\displaystyle \lambda _{1},\ldots ,\lambda _{n}} are all residues or non-residues simultaneously (that is, when z=0{\displaystyle z=0} would fail) may be estimated as 2−k{\displaystyle 2^{-k}} where k{\displaystyle k} is the number of distinct values in λ1,…,λn{\displaystyle \lambda _{1},\ldots ,\lambda _{n}}. In this way even for the worst case of k=1{\displaystyle k=1} and f(x)=(x−λ)n{\displaystyle f(x)=(x-\lambda )^{n}}, the probability of error may be estimated as 1/2{\displaystyle 1/2} and for modular square root case error probability is at most 1/4{\displaystyle 1/4}.

Complexity
Let a polynomial have degree n{\displaystyle n}. We derive the algorithm's complexity as follows:

Due to the binomial theorem (x−z)k=∑i=0k(ki)(−z)k−ixi{\textstyle (x-z)^{k}=\sum \limits _{i=0}^{k}{\binom {k}{i}}(-z)^{k-i}x^{i}}, we may transition from f(x){\displaystyle f(x)} to f(x−z){\displaystyle f(x-z)} in O(n2){\displaystyle O(n^{2})} time.
Polynomial multiplication and taking remainder of one polynomial modulo another one may be done in O(n2){\textstyle O(n^{2})}, thus calculation of x2kmodfz(x){\textstyle x^{2^{k}}{\bmod {f}}_{z}(x)} is done in O(n2log⁡p){\textstyle O(n^{2}\log p)}.
Binary exponentiation works in O(n2log⁡p){\displaystyle O(n^{2}\log p)}.
Taking the gcd{\displaystyle \gcd } of two polynomials via Euclidean algorithm works in O(n2){\displaystyle O(n^{2})}.Thus the whole procedure may be done in O(n2log⁡p){\displaystyle O(n^{2}\log p)}. Using the fast Fourier transform and Half-GCD algorithm, the algorithm's complexity may be improved to O(nlog⁡nlog⁡pn){\displaystyle O(n\log n\log pn)}. For the modular square root case, the degree is n=2{\displaystyle n=2}, thus the whole complexity of algorithm in such case is bounded by O(log⁡p){\displaystyle O(\log p)} per iteration.


== References ==",61379828,https://en.wikipedia.org/wiki/Berlekamp%E2%80%93Rabin_algorithm
Birkhoff algorithm,"Birkhoff's algorithm (also called Birkhoff-von-Neumann algorithm) is an algorithm for decomposing a bistochastic matrix into a convex combination of permutation matrices. It was published by Garrett Birkhoff in 1946.: 36  It has many applications. One such application is for the problem of fair random assignment: given a randomized allocation of items, Birkhoff's algorithm can decompose it into a lottery on deterministic allocations.","Birkhoff's algorithm (also called Birkhoff-von-Neumann algorithm) is an algorithm for decomposing a bistochastic matrix into a convex combination of permutation matrices. It was published by Garrett Birkhoff in 1946.: 36  It has many applications. One such application is for the problem of fair random assignment: given a randomized allocation of items, Birkhoff's algorithm can decompose it into a lottery on deterministic allocations.

Terminology
A bistochastic matrix (also called: doubly-stochastic) is a matrix in which all elements are greater than or equal to 0 and the sum of the elements in each row and column equals 1. An example is the following 3-by-3 matrix:

A permutation matrix is a special case of a bistochastic matrix, in which each element is either 0 or 1 (so there is exactly one ""1"" in each row and each column). An example is the following 3-by-3 matrix:

A Birkhoff decomposition (also called: Birkhoff-von-Neumann decomposition) of a bistochastic matrix is a presentation of it as a sum of permutation matrices with non-negative weights. For example, the above matrix can be presented as the following sum:

Birkhoff's algorithm receives as input a bistochastic matrix and returns as output a Birkhoff decomposition.

Tools
A permutation set of an n-by-n matrix X is a set of n entries of X containing exactly one entry from each row and from each column. A theorem by Dénes Kőnig says that:: 35  Every bistochastic matrix has a permutation-set in which all entries are positive.The positivity graph of an n-by-n matrix X is a bipartite graph with 2n vertices, in which the vertices on one side are n rows and the vertices on the other side are the n columns, and there is an edge between a row and a column iff the entry at that row and column is positive. A permutation set with positive entries is equivalent to a perfect matching in the positivity graph. A perfect matching in a bipartite graph can be found in polynomial time, e.g. using any algorithm for maximum cardinality matching. Kőnig's theorem is equivalent to the following:The positivity graph of any bistochastic matrix admits a perfect matching.A matrix is called scaled-bistochastic if all elements are non-negative, and the sum of each row and column equals c, where c is some positive constant. In other words, it is c times a bistochastic matrix. Since the positivity graph is not affected by scaling:The positivity graph of any scaled-bistochastic matrix admits a perfect matching.

Algorithm
Birkhoff's algorithm is a greedy algorithm: it greedily finds perfect matchings and removes them from the fractional matching. It works as follows.: app.B 
Let i = 1.
Construct the positivity graph GX of  X.
Find a perfect matching in GX, corresponding to a positive permutation set in X.
Let z[i] > 0 be the smallest entry in the permutation set.
Let P[i] be a permutation matrix with 1 in the positive permutation set.
Let X := X − z[i] P[i].
If X contains nonzero elements, Let i = i + 1 and go back to step 2.
Otherwise, return the sum: z[1] P[1] + ... + z[2] P[2] + ... + z[i] P[i].The algorithm is correct because, after step 6, the sum in each row and each column drops by z[i]. Therefore, the matrix X remains scaled-bistochastic. Therefore, in step 3, a perfect matching always exists.

Run-time complexity
By the selection of z[i] in step 4, in each iteration at least one element of X becomes 0. Therefore, the algorithm must end after at most n2 steps. However, the last step must simultaneously make n elements 0, so the algorithm ends after at most n2 − n + 1 steps, which implies O(n2){\displaystyle O(n^{2})}.
In 1960, Joshnson, Dulmage and Mendelsohn showed that Birkhoff's algorithm actually ends after at most n2 − 2n + 2 steps, which is tight in general (that is, in some cases n2 − 2n + 2 permutation matrices may be required).

Application in fair division
In the fair random assignment problem, there are n objects and n people with different preferences over the objects. It is required to give an object to each person. To attain fairness, the allocation is randomized: for each (person, object) pair, a probability is calculated, such that the sum of probabilities for each person and for each object is 1. The probabilistic-serial procedure can compute the probabilities such that each agent, looking at the matrix of probabilities, prefers his row of probabilities over the rows of all other people (this property is called envy-freeness). This raises the question of how to implement this randomized allocation in practice? One cannot just randomize for each object separately, since this may result in allocations in which some people get many objects while other people get no objects.
Here, Birkhoff's algorithm is useful. The matrix of probabilities, calculated by the probabilistic-serial algorithm, is bistochastic. Birkhoff's algorithm can decompose it into a convex combination of permutation matrices. Each permutation matrix represents a deterministic assignment, in which every agent receives exactly one object. The coefficient of each such matrix is interpreted as a probability; based on the calculated probabilities, it is possible to pick one assignment at random and implement it.

Extensions
The problem of computing the Birkhoff decomposition with the minimum number of terms has been shown to be NP-hard, but some heuristics for computing it are known. This theorem can be extended for the general stochastic matrix with deterministic transition matrices.Budish, Che, Kojima and Milgrom generalize Birkhoff's algorithm to non-square matrices, with some constraints on the feasible assignments. They also present a decomposition algorithm that minimizes the variance in the expected values.
Vazirani  generalizes Birkhoff's algorithm to non-bipartite graphs.
Valls et al. showed that it is possible to obtain an ϵ{\displaystyle \epsilon }
-approximate decomposition with O(log⁡(1/ϵ2)){\displaystyle O(\log(1/\epsilon ^{2}))} permutations.

See also
Birkhoff polytope
Birkhoff decomposition (disambiguation)
Gordan's lemma - states that certain sets of vectors can be generated by a finite subset.


== References ==",64692455,https://en.wikipedia.org/wiki/Birkhoff_algorithm
Bisection (software engineering),Bisection is a method used in software development to identify change sets that result in a specific behavior change. It is mostly employed for finding the patch that introduced a bug. Another application area is finding the patch that indirectly fixed a bug.,"Bisection is a method used in software development to identify change sets that result in a specific behavior change. It is mostly employed for finding the patch that introduced a bug. Another application area is finding the patch that indirectly fixed a bug.

Overview
The process of locating the changeset that introduced a specific regression was described as ""source change isolation"" in 1997 by Brian Ness and Viet Ngo of Cray Research. Regression testing was performed on Cray's compilers in editions comprising one or more changesets. Editions with known regressions could not be validated until developers addressed the problem. Source change isolation narrowed the cause to a single changeset that could then be excluded from editions, unblocking them with respect to this problem, while the author of the change worked on a fix. Ness and Ngo outlined linear search and binary search methods of performing this isolation.Code bisection has the goal of minimizing the effort to find a specific change set.
It employs a divide and conquer algorithm that
depends on having access to the code history which is usually preserved by
revision control in a code repository.

Bisection method
Code bisection algorithm
Code history has the structure of a directed acyclic graph which can be topologically sorted. This makes it possible to use a divide and conquer search algorithm which:

splits up the search space of candidate revisions
tests for the behavior in question
reduces the search space depending on the test result
re-iterates the steps above until a range with at most one bisectable patch candidate remains

Algorithmic complexity
Bisection is in LSPACE having an algorithmic complexity of O(log⁡N){\displaystyle O(\log N)} with N{\displaystyle N} denoting the number of revisions in the search space, and is similar to a binary search.

Desirable repository properties
For code bisection it is desirable that each revision in the search space can be built and tested independently.

Monotonicity
For the bisection algorithm to identify a single changeset which caused the behavior being tested to change, the behavior must change monotonically across the search space. For a Boolean function such as a pass/fail test, this means that it only changes once across all changesets between the start and end of the search space.
If there are multiple changesets across the search space where the behavior being tested changes between false and true, then the bisection algorithm will find one of them, but it will not necessarily be the root cause of the change in behavior between the start and the end of the search space. The root cause could be a different changeset, or a combination of two or more changesets across the search space. To help deal with this problem, automated tools allow specific changesets to be ignored during a bisection search.

Automation support
Although the bisection method can be completed manually, one of its main advantages is that it can be easily automated. It can thus fit into existing test automation processes: failures in exhaustive automated regression tests can trigger automated bisection to localize faults. Ness and Ngo focused on its potential in Cray's continuous delivery-style environment in which the automatically isolated bad changeset could be automatically excluded from builds.The revision control systems Fossil, Git and Mercurial have built-in functionality for code bisection. The user can start a bisection session with a specified range of revisions from which the revision control system proposes a revision to test, the user tells the system whether the revision tested as ""good"" or ""bad"", and the process repeats until the specific ""bad"" revision has been identified. Other revision control systems, such as Bazaar or Subversion, support bisection through plugins or external scripts.Phoronix Test Suite can do bisection automatically to find performance regressions.

See also
Delta debugging (generalization of finding a minimal cause of a bug)
Annotation § Source control (determining changesets that edited a line in a file)


== References ==",36033877,https://en.wikipedia.org/wiki/Bisection_(software_engineering)
Block swap algorithms,"In computer algorithms, Block swap algorithms swap two regions of elements of an array. It is simple to swap two non-overlapping regions of an array of equal size. However, it is not simple to swap two non-overlapping regions of an array in-place that are next to each other, but are of unequal sizes (such swapping is equivalent to Array Rotation). Three algorithms are known to accomplish this: Bentley's Juggling (also known as Dolphin Algorithm ), Gries-Mills, and Reversal. All three algorithms are linear time 
O(n), (see Time complexity).","In computer algorithms, Block swap algorithms swap two regions of elements of an array. It is simple to swap two non-overlapping regions of an array of equal size. However, it is not simple to swap two non-overlapping regions of an array in-place that are next to each other, but are of unequal sizes (such swapping is equivalent to Array Rotation). Three algorithms are known to accomplish this: Bentley's Juggling (also known as Dolphin Algorithm ), Gries-Mills, and Reversal. All three algorithms are linear time 
O(n), (see Time complexity).

Reversal algorithm
The reversal algorithm is the simplest to explain, using rotations. A rotation is an in-place reversal of array elements. This method swaps two elements of an array from outside in within a range. The rotation works for an even or odd number of array elements. The reversal algorithm uses three in-place rotations to accomplish an in-place block swap:

Rotate region A
Rotate region B
Rotate region ABGries-Mills and Reversal algorithms perform better than Bentley's Juggling, because of their cache-friendly memory access pattern behavior.
The Reversal algorithm parallelizes well, because rotations can be split into sub-regions, which can be rotated independently of others.


== References ==",61176336,https://en.wikipedia.org/wiki/Block_swap_algorithms
British Museum algorithm,"The British Museum algorithm is a general approach to finding a solution by checking all possibilities one by one, beginning with the smallest. The term refers to a conceptual, not a practical, technique where the number of possibilities is enormous.
Newell, Shaw, and Simon 
called this procedure the British Museum algorithm 

""... since it seemed to them as sensible as placing monkeys in front of typewriters in order to reproduce all the books in the British Museum.""","The British Museum algorithm is a general approach to finding a solution by checking all possibilities one by one, beginning with the smallest. The term refers to a conceptual, not a practical, technique where the number of possibilities is enormous.
Newell, Shaw, and Simon 
called this procedure the British Museum algorithm 

""... since it seemed to them as sensible as placing monkeys in front of typewriters in order to reproduce all the books in the British Museum.""

See also
Bogosort
Branch and bound
Breadth-first search
Brute-force search

Sources
 This article incorporates public domain material from Paul E. Black. ""British Museum technique"". Dictionary of Algorithms and Data Structures. NIST..


== References ==",920295,https://en.wikipedia.org/wiki/British_Museum_algorithm
Broadcast (parallel pattern),"Broadcast is a collective communication primitive in parallel programming to distribute programming instructions or data to nodes in a cluster. It is the reverse operation of reduction. The broadcast operation is widely used in parallel algorithms, such as matrix-vector multiplication, Gaussian elimination and shortest paths.The Message Passing Interface implements broadcast in MPI_Bcast.","Broadcast is a collective communication primitive in parallel programming to distribute programming instructions or data to nodes in a cluster. It is the reverse operation of reduction. The broadcast operation is widely used in parallel algorithms, such as matrix-vector multiplication, Gaussian elimination and shortest paths.The Message Passing Interface implements broadcast in MPI_Bcast.

Definition
A message M[1..m]{\displaystyle M[1..m]}of length m{\displaystyle m} should be distributed from one node to all other p−1{\displaystyle p-1} nodes.
Tbyte{\displaystyle T_{\text{byte}}}is the time it takes to send one byte.
Tstart{\displaystyle T_{\text{start}}}is the time it takes for a message to travel to another node, independent of its length.
Therefore, the time to send a package from one node to another is t=size×Tbyte+Tstart{\displaystyle t=\mathrm {size} \times T_{\text{byte}}+T_{\text{start}}}.p{\displaystyle p} is the number of nodes and the number of processors.

Binomial Tree Broadcast
With Binomial Tree Broadcast the whole message is sent at once. Each node that has already received the message sends it on further. This grows exponentially as each time step the amount of sending nodes is doubled. The algorithm is ideal for short messages but falls short with longer ones as during the time when the first transfer happens only one node is busy.
Sending a message to all nodes takes log2⁡(p)t{\displaystyle \log _{2}(p)t} time which results in a runtime of log2⁡(p)(mTbyte+Tstart){\displaystyle \log _{2}(p)(mT_{\text{byte}}+T_{\text{start}})}

Linear Pipeline Broadcast
The message is split up into k{\displaystyle k} packages and send piecewise from node n{\displaystyle n} to node n+1{\displaystyle n+1}. The time needed to distribute the first message piece is pt=mkTbyte+Tstart{\textstyle pt={\frac {m}{k}}T_{\text{byte}}+T_{\text{start}}} whereby t{\displaystyle t} is the time needed to send a package from one processor to another.
Sending a whole message takes (p+k)(mTbytek+Tstart)=(p+k)t=pt+kt{\displaystyle (p+k)\left({\frac {mT_{\text{byte}}}{k}}+T_{\text{start}}\right)=(p+k)t=pt+kt}.
Optimal is to choose k=m(p−2)TbyteTstart{\displaystyle k={\sqrt {\frac {m(p-2)T_{\text{byte}}}{T_{\text{start}}}}}} resulting in a runtime of approximately 
The run time is  dependent on not only message length but also the number of processors that play roles. This approach shines when the length of the message is much larger than the amount of processors.

Pipelined Binary Tree Broadcast
This algorithm combines Binomial Tree Broadcast and Linear Pipeline Broadcast, which makes the algorithm work well for both short and long messages. The aim is to have as many nodes work as possible while maintaining the ability to send short messages quickly. A good approach is to use Fibonacci trees for splitting up the tree, which are a good choice as a message cannot be sent to both children at the same time. This results in a binary tree structure.
We will assume in the following that communication is full-duplex. The Fibonacci tree structure has a depth of about d≈logΦ⁡(p){\displaystyle d\approx \log _{\Phi }(p)}whereby Φ=1+52{\displaystyle \Phi ={\frac {1+{\sqrt {5}}}{2}}}the golden ratio.
The resulting runtime is (mkTbyte+Tstart)(d+2k−2){\textstyle ({\frac {m}{k}}T_{\text{byte}}+T_{\text{start}})(d+2k-2)}. Optimal is k=n(d−2)Tbyte3Tstart{\displaystyle k={\sqrt {\frac {n(d-2)T_{\text{byte}}}{3T_{\text{start}}}}}}.
This results in a runtime of 2mTbyte+TstartlogΦ⁡(p)+2mlogΦ⁡(p)TstartTbyte{\displaystyle 2mT_{\text{byte}}+T_{\text{start}}\log _{\Phi }(p)+{\sqrt {2m\log _{\Phi }(p)T_{\text{start}}T_{\text{byte}}}}}.

Two Tree Broadcast (23-Broadcast)
Definition
This algorithm aims to improve on some disadvantages of tree structure models with pipelines. Normally in tree structure models with pipelines (see above methods), leaves receive just their data and cannot contribute to send and spread data.
The algorithm concurrently uses two binary trees to communicate over. Those trees will be called tree A and B. Structurally in binary trees there are relatively more leave nodes than inner nodes. Basic Idea of this algorithm is to make a leaf node of tree A be an inner node of tree B. It has also the same technical function in opposite side from B to A tree. This means, two packets are sent and received by inner nodes and leaves in different steps.

Tree construction
The number of steps needed to construct two parallel-working binary trees is dependent on the amount of processors. Like with other structures one processor can is the root node who sends messages to two trees. It is not necessary to set a root node, because it is not hard to recognize that the direction of sending messages in binary tree is normally top to bottom. There is no limitation on the number of processors to build two binary trees. Let the height of the combined tree be h = ⌈log(p + 2)⌉. Tree A and B can have a height of h−1{\displaystyle h-1}. Especially, if the number of processors correspond to p=2h−1{\displaystyle p=2^{h}-1}, we can make both sides trees and a root node.
To construct this model efficiently and easily with a fully built tree, we can use two methods called ""Shifting"" and ""Mirroring"" to get second tree. Let assume tree A is already modeled and tree B is supposed to be constructed based on tree A. We assume that we have p{\displaystyle p} processors ordered from 0 to p−1{\displaystyle p-1}.

Shifting
The ""Shifting"" method, first copies tree A and moves every node one position to the left to get tree B. The node, which will be located on -1, becomes a child of processor p−2{\displaystyle p-2}.

Mirroring
""Mirroring"" is ideal for an even number of processors. With this method tree B can be more easily constructed by tree A, because there are no structural transformations in order to create the new tree. In addition, a symmetric process makes this approach simple. This method can also handle an odd number of processors, in this case, we can set processor p−1{\displaystyle p-1} as root node for both trees. For the remaining processors ""Mirroring"" can be used.

Coloring
We need to find a schedule in order to make sure that no processor has to send or receive two messages from two trees in a step. The edge, is a communication connection to connect two nodes, and can be labelled as either 0 or 1 to make sure that every processor can alternate between 0 and 1-labelled edges. The edges of A and B can be colored with two colors (0 and 1) such that

no processor is connected to its parent nodes in A and B using edges of the same color-
no processor is connected to its children nodes in A or B using edges of the same color.In every even step the edges with 0 are activated and edges with 1 are activated in every odd step.

Time complexity
In this case the number of packet k is divided in half for each tree. Both trees are working together the total number of packets k=k/2+k/2{\displaystyle k=k/2+k/2} (upper tree + bottom tree)
In each binary tree sending a message to another nodes takes 2i{\displaystyle 2i} steps until a processor has at least a packet in step i{\displaystyle i}. Therefore, we can calculate all steps as d:=log2⁡(p+1)⇒log2⁡(p+1)≈log2⁡(p){\displaystyle d:=\log _{2}(p+1)\Rightarrow \log _{2}(p+1)\approx \log _{2}(p)}.
The resulting run time is T(m,p,k)≈(mkTbyte+Tstart)(2d+k−1){\textstyle T(m,p,k)\approx ({\frac {m}{k}}T_{\text{byte}}+T_{\text{start}})(2d+k-1)}. (Optimal  k=m(2d−1)Tbyte/Tstart{\textstyle k={\sqrt {{m(2d-1)T_{\text{byte}}}/{T_{\text{start}}}}}})
This results in a run time of T(m,p)≈mTbyte+Tstart⋅2log2⁡(p)+m⋅2log2⁡(p)TstartTbyte{\displaystyle T(m,p)\approx mT_{\text{byte}}+T_{\text{start}}\cdot 2\log _{2}(p)+{\sqrt {m\cdot 2\log _{2}(p)T_{\text{start}}T_{\text{byte}}}}}.

ESBT-Broadcasting (Edge-disjoint Spanning Binomial Trees)
In this section, another broadcasting algorithm with an underlying telephone communication model will be introduced. A Hypercube creates network system with p=2d(d=0,1,2,3,...){\displaystyle p=2^{d}(d=0,1,2,3,...)}. Every node is represented by binary 0,1{\displaystyle {0,1}} depending on the number of dimensions. Fundamentally ESBT(Edge-disjoint Spanning Binomial Trees) is based on hypercube graphs, pipelining(m{\displaystyle m} messages are divided by k{\displaystyle k} packets) and binomial trees. The Processor 0d{\displaystyle 0^{d}} cyclically spreads packets to roots of ESBTs. The roots of ESBTs broadcast data with binomial tree. To leave all of k{\displaystyle k} from p0{\displaystyle p_{0}}, k{\displaystyle k} steps are required, because all packets are distributed by p0{\displaystyle p_{0}}. It takes another d steps until the last leaf node receives the packet. In total d+k{\displaystyle d+k} steps are necessary to broadcast m{\displaystyle m} message through ESBT.
The resulting run time is T(m,p,k)=(mkTbyte+Tstart)(k+d){\textstyle T(m,p,k)=({\frac {m}{k}}T_{\text{byte}}+T_{\text{start}})(k+d)}. (k=mdTbyte/Tstart){\textstyle (k={\sqrt {{mdT_{\text{byte}}}/{T_{\text{start}}}}})}.
This results in a run time of T(m,p):=mTbyte+dTstart+mdTstartTbyte{\displaystyle T(m,p):=mT_{\text{byte}}+dT_{\text{start}}+{\sqrt {mdT_{\text{start}}T_{\text{byte}}}}}.

See also
Reduction operator


== References ==",60378307,https://en.wikipedia.org/wiki/Broadcast_(parallel_pattern)
Car–Parrinello molecular dynamics,"Car–Parrinello molecular dynamics or CPMD refers to either a method used in molecular dynamics (also known as the Car–Parrinello method) or the computational chemistry software package used to implement this method.The CPMD method is one of the major methods for calculating ab-initio molecular dynamics (ab-initio MD or AIMD).
Ab initio molecular dynamics (ab initio MD) is a computational method that uses first principles, or fundamental laws of nature, to simulate the motion of atoms in a system. It is a type of molecular dynamics (MD) simulation that does not rely on empirical potentials or force fields to describe the interactions between atoms, but rather calculates these interactions directly from the electronic structure of the system using quantum mechanics.
In an ab initio MD simulation, the total energy of the system is calculated at each time step using density functional theory (DFT) or another method of quantum chemistry. The forces acting on each atom are then determined from the gradient of the energy with respect to the atomic coordinates, and the equations of motion are solved to predict the trajectory of the atoms.
AIMD permits chemical bond breaking and forming events to occur and accounts for electronic polarization effect. Therefore, Ab initio MD simulations can be used to study a wide range of phenomena, including the structural, thermodynamic, and dynamic properties of materials and chemical reactions. They are particularly useful for systems that are not well described by empirical potentials or force fields, such as systems with strong electronic correlation or systems with many degrees of freedom. However, ab initio MD simulations are computationally demanding and require significant computational resources.
The CPMD method is related to the more common Born–Oppenheimer molecular dynamics (BOMD) method in that the quantum mechanical effect of the electrons is included in the calculation of energy and forces for the classical motion of the nuclei. CPMD and BOMD are different types of AIMD. However, whereas BOMD treats the electronic structure problem within the time-independent Schrödinger equation, CPMD explicitly includes the electrons as active degrees of freedom, via (fictitious) dynamical variables.
The software is a parallelized plane wave / pseudopotential implementation of density functional theory, particularly designed for ab initio molecular dynamics.","Car–Parrinello molecular dynamics or CPMD refers to either a method used in molecular dynamics (also known as the Car–Parrinello method) or the computational chemistry software package used to implement this method.The CPMD method is one of the major methods for calculating ab-initio molecular dynamics (ab-initio MD or AIMD).
Ab initio molecular dynamics (ab initio MD) is a computational method that uses first principles, or fundamental laws of nature, to simulate the motion of atoms in a system. It is a type of molecular dynamics (MD) simulation that does not rely on empirical potentials or force fields to describe the interactions between atoms, but rather calculates these interactions directly from the electronic structure of the system using quantum mechanics.
In an ab initio MD simulation, the total energy of the system is calculated at each time step using density functional theory (DFT) or another method of quantum chemistry. The forces acting on each atom are then determined from the gradient of the energy with respect to the atomic coordinates, and the equations of motion are solved to predict the trajectory of the atoms.
AIMD permits chemical bond breaking and forming events to occur and accounts for electronic polarization effect. Therefore, Ab initio MD simulations can be used to study a wide range of phenomena, including the structural, thermodynamic, and dynamic properties of materials and chemical reactions. They are particularly useful for systems that are not well described by empirical potentials or force fields, such as systems with strong electronic correlation or systems with many degrees of freedom. However, ab initio MD simulations are computationally demanding and require significant computational resources.
The CPMD method is related to the more common Born–Oppenheimer molecular dynamics (BOMD) method in that the quantum mechanical effect of the electrons is included in the calculation of energy and forces for the classical motion of the nuclei. CPMD and BOMD are different types of AIMD. However, whereas BOMD treats the electronic structure problem within the time-independent Schrödinger equation, CPMD explicitly includes the electrons as active degrees of freedom, via (fictitious) dynamical variables.
The software is a parallelized plane wave / pseudopotential implementation of density functional theory, particularly designed for ab initio molecular dynamics.

Car–Parrinello method
The Car–Parrinello method is a type of molecular dynamics, usually employing periodic boundary conditions, planewave basis sets, and density functional theory, proposed by Roberto Car and Michele Parrinello in 1985, who were subsequently awarded the Dirac Medal by ICTP in 2009.
In contrast to Born–Oppenheimer molecular dynamics wherein the nuclear (ions) degree of freedom are propagated using ionic forces which are calculated at each iteration by approximately solving the electronic problem with conventional matrix diagonalization methods, the Car–Parrinello method explicitly introduces the electronic degrees of freedom as (fictitious) dynamical variables, writing an extended Lagrangian for the system which leads to a system of coupled equations of motion for both ions and electrons. In this way, an explicit electronic minimization at each time step, as done in Born–Oppenheimer MD, is not needed: after an initial standard electronic minimization, the fictitious dynamics of the electrons keeps them on the electronic ground state corresponding to each new ionic configuration visited along the dynamics, thus yielding accurate ionic forces. In order to maintain this adiabaticity condition, it is necessary that the fictitious mass of the electrons is chosen small enough to avoid a significant energy transfer from the ionic to the electronic degrees of freedom. This small fictitious mass in turn requires that the equations of motion are integrated using a smaller time step than the one (1–10 fs) commonly used in Born–Oppenheimer molecular dynamics.
Currently, the CPMD method can be applied to systems that consist of a few tens or hundreds of atoms and access timescales on the order of tens of picoseconds.

General approach
In CPMD the core electrons are usually described by a pseudopotential and the wavefunction of the valence electrons are approximated by a plane wave basis set.
The ground state electronic density (for fixed nuclei) is calculated self-consistently, usually using the density functional theory method. Kohn-Sham equations are often used to calculate the electronic structure, where electronic orbitals are expanded in a plane-wave basis set. Then, using that density, forces on the nuclei can be computed, to update the trajectories (using, e.g. the Verlet integration algorithm). In addition, however, the coefficients used to obtain the electronic orbital functions can be treated as a set of extra spatial dimensions, and trajectories for the orbitals can be calculated in this context.

Fictitious dynamics
CPMD is an approximation of the Born–Oppenheimer MD (BOMD) method. In BOMD, the electrons' wave function must be minimized via matrix diagonalization at every step in the trajectory. CPMD uses fictitious dynamics to keep the electrons close to the ground state, preventing the need for a costly self-consistent iterative minimization at each time step. The fictitious dynamics relies on the use of a fictitious electron mass (usually in the range of 400 – 800 a.u.) to ensure that there is very little energy transfer from nuclei to electrons, i.e. to ensure adiabaticity. Any increase in the fictitious electron mass resulting in energy transfer would cause the system to leave the ground-state BOMD surface.

Lagrangian
L=12(∑Inuclei MIR˙I2+μ∑iorbitals∫dr |ψ˙i(r,t)|2)−E[{ψi},{RI}]+∑ijΛij(∫dr ψiψj−δij),{\displaystyle {\mathcal {L}}={\frac {1}{2}}\left(\sum _{I}^{\mathrm {nuclei} }\ M_{I}{\dot {\mathbf {R} }}_{I}^{2}+\mu \sum _{i}^{\mathrm {orbitals} }\int d\mathbf {r} \ |{\dot {\psi }}_{i}(\mathbf {r} ,t)|^{2}\right)-E\left[\{\psi _{i}\},\{\mathbf {R} _{I}\}\right]+\sum _{ij}\Lambda _{ij}\left(\int d\mathbf {r} \ \psi _{i}\psi _{j}-\delta _{ij}\right),}where μ{\displaystyle \mu } is the fictitious mass parameter; E[{ψi},{RI}] is the Kohn–Sham energy density functional, which outputs energy values when given Kohn–Sham orbitals and nuclear positions.

Orthogonality constraint
∫dr ψi∗(r,t)ψj(r,t)=δij,{\displaystyle \int d\mathbf {r} \ \psi _{i}^{*}(\mathbf {r} ,t)\psi _{j}(\mathbf {r} ,t)=\delta _{ij},}where δij is the Kronecker delta.

Equations of motion
The equations of motion are obtained by finding the stationary point of the Lagrangian under variations of ψi and RI, with the orthogonality constraint.
MIR¨I=−∇IE[{ψi},{RI}]{\displaystyle M_{I}{\ddot {\mathbf {R} }}_{I}=-\nabla _{I}\,E\left[\{\psi _{i}\},\{\mathbf {R} _{I}\}\right]}μψ¨i(r,t)=−δEδψi∗(r,t)+∑jΛijψj(r,t),{\displaystyle \mu {\ddot {\psi }}_{i}(\mathbf {r} ,t)=-{\frac {\delta E}{\delta \psi _{i}^{*}(\mathbf {r} ,t)}}+\sum _{j}\Lambda _{ij}\psi _{j}(\mathbf {r} ,t),}where Λij is a Lagrangian multiplier matrix to comply with the orthonormality constraint.

Born–Oppenheimer limit
In the formal limit where μ → 0, the equations of motion approach Born–Oppenheimer molecular dynamics.

Software packages
There are a number of software packages available for performing AIMD simulations. Some of the most widely used packages include:

CP2K: an open-source software package for AIMD.
Quantum Espresso: an open-source package for performing DFT calculations. It includes a module for AIMD.
VASP: a commercial software package for performing DFT calculations. It includes a module for AIMD.
Gaussian: a commercial software package that can perform AIMD.
NWChem: an open-source software package for AIMD.
LAMMPS: an open-source software package for performing classical and ab initio MD simulations.
SIESTA: an open-source software package for AIMD.

Application
Studying the behavior of water near a hydrophobic graphene sheet.
Investigating the structure and dynamics of liquid water at ambient temperature.
Solving the heat transfer problems (heat conduction and thermal radiation) between Si/Ge superlattices.
Probing the proton transfer along 1D water chains inside carbon nanotubes.
Evaluating the critical point of aluminum.
Predicting the amorphous phase of the phase-change memory material GeSbTe.
Studying the combustion process of lignite-water systems. 
Computing and analyzing the IR spectra in terms of H-bond interactions.

See also
Computational physics
Density functional theory
Computational chemistry
Molecular dynamics
Quantum chemistry
Ab initio quantum chemistry methods
Quantum chemistry computer programs
List of software for molecular mechanics modeling
List of quantum chemistry and solid-state physics software
CP2K

References
External links
http://www.cpmd.org/
http://www.cp2k.org/",6770335,https://en.wikipedia.org/wiki/Car%E2%80%93Parrinello_molecular_dynamics
Certifying algorithm,"In theoretical computer science, a certifying algorithm is an algorithm that outputs, together with a solution to the problem it solves, a proof that the solution is correct. A certifying algorithm is said to be efficient if the combined runtime of the algorithm and a proof checker is slower by at most a constant factor than the best known non-certifying algorithm for the same problem.The proof produced by a certifying algorithm should be in some sense simpler than the algorithm itself, for otherwise any algorithm could be considered certifying (with its output verified by running the same algorithm again). Sometimes this is formalized by requiring that a verification of the proof take less time than the original algorithm, while for other problems (in particular those for which the solution can be found in linear time) simplicity of the output proof is considered in a less formal sense. For instance, the validity of the output proof may be more apparent to human users than the correctness of the algorithm, or a checker for the proof may be more amenable to formal verification.Implementations of certifying algorithms that also include a checker for the proof generated by the algorithm may be considered to be more reliable than non-certifying algorithms. For, whenever the algorithm is run, one of three things happens: it produces a correct output (the desired case), it detects a bug in the algorithm or its implication (undesired, but generally preferable to continuing without detecting the bug), or both the algorithm and the checker are faulty in a way that masks the bug and prevents it from being detected (undesired, but unlikely as it depends on the existence of two independent bugs).","In theoretical computer science, a certifying algorithm is an algorithm that outputs, together with a solution to the problem it solves, a proof that the solution is correct. A certifying algorithm is said to be efficient if the combined runtime of the algorithm and a proof checker is slower by at most a constant factor than the best known non-certifying algorithm for the same problem.The proof produced by a certifying algorithm should be in some sense simpler than the algorithm itself, for otherwise any algorithm could be considered certifying (with its output verified by running the same algorithm again). Sometimes this is formalized by requiring that a verification of the proof take less time than the original algorithm, while for other problems (in particular those for which the solution can be found in linear time) simplicity of the output proof is considered in a less formal sense. For instance, the validity of the output proof may be more apparent to human users than the correctness of the algorithm, or a checker for the proof may be more amenable to formal verification.Implementations of certifying algorithms that also include a checker for the proof generated by the algorithm may be considered to be more reliable than non-certifying algorithms. For, whenever the algorithm is run, one of three things happens: it produces a correct output (the desired case), it detects a bug in the algorithm or its implication (undesired, but generally preferable to continuing without detecting the bug), or both the algorithm and the checker are faulty in a way that masks the bug and prevents it from being detected (undesired, but unlikely as it depends on the existence of two independent bugs).

Examples
Many examples of problems with checkable algorithms come from graph theory.
For instance, a classical algorithm for testing whether a graph is bipartite would simply output a Boolean value: true if the graph is bipartite, false otherwise. In contrast, a certifying algorithm might output a 2-coloring of the graph in the case that it is bipartite, or a cycle of odd length if it is not. Any graph is bipartite if and only if it can be 2-colored, and non-bipartite if and only if it contains an odd cycle. Both checking whether a 2-coloring is valid and checking whether a given odd-length sequence of vertices is a cycle may be performed more simply than testing bipartiteness.Analogously, it is possible to test whether a given directed graph is acyclic by a certifying algorithm that outputs either a topological order or a directed cycle. It is possible to test whether an undirected graph is a chordal graph by a certifying algorithm that outputs either an elimination ordering (an ordering of all vertices such that, for every vertex, the neighbors that are later in the ordering form a clique) or a chordless cycle. And it is possible to test whether a graph is planar by a certifying algorithm that outputs either a planar embedding or a Kuratowski subgraph.The extended Euclidean algorithm for the greatest common divisor of two integers x and y is certifying: it outputs three integers g (the divisor), a, and b, such that ax + by = g. This equation can only be true of multiples of the greatest common divisor, so testing that g is the greatest common divisor may be performed by checking that g divides both x and y and that this equation is correct.

See also
Sanity check, a simple test of the correctness of an output or intermediate result that is not required to be a complete proof of correctness


== References ==",51386092,https://en.wikipedia.org/wiki/Certifying_algorithm
Chandy–Misra–Haas algorithm resource model,"The Chandy–Misra–Haas algorithm resource model checks for deadlock in a distributed system. It was developed by K. Mani Chandy, Jayadev Misra and Laura M Haas.","The Chandy–Misra–Haas algorithm resource model checks for deadlock in a distributed system. It was developed by K. Mani Chandy, Jayadev Misra and Laura M Haas.

Locally dependent
Consider the n processes P1, P2, P3, P4, P5,, ... ,Pn which are performed in a single system (controller). P1 is locally dependent on Pn, if P1 depends on P2, P2 on P3, so on and Pn−1 on Pn. That is, if P1→P2→P3→…→Pn{\displaystyle P_{1}\rightarrow P_{2}\rightarrow P_{3}\rightarrow \ldots \rightarrow P_{n}}, then P1{\displaystyle P_{1}} is locally dependent on Pn{\displaystyle P_{n}}. If P1 is said to be locally dependent to itself if it is locally dependent on Pn and Pn depends on P1: i.e. if P1→P2→P3→…→Pn→P1{\displaystyle P_{1}\rightarrow P_{2}\rightarrow P_{3}\rightarrow \ldots \rightarrow P_{n}\rightarrow P_{1}}, then P1{\displaystyle P_{1}} is locally dependent on itself.

Description
The algorithm uses a message called probe(i,j,k) to transfer a message from controller of process Pj to controller of process Pk. It specifies a message started by process Pi to find whether a deadlock has occurred or not.  Every process Pj maintains a boolean array dependent which contains the information about the processes that depend on it. Initially the values of each array are all ""false"".

Controller sending a probe
Before sending, the probe checks whether Pj is locally dependent on itself.  If so, a deadlock occurs. Otherwise it checks whether Pj, and Pk are in different controllers, are locally dependent and Pj is waiting for the resource that is locked by Pk. Once all the conditions are satisfied it sends the probe.

Controller receiving a probe
On the receiving side, the controller checks whether Pk is performing a task. If so, it neglects the probe. Otherwise, it checks the responses given Pk to Pj and dependentk(i) is false. Once it is verified, it assigns true to dependentk(i). Then it checks whether k is equal to i. If both are equal, a deadlock occurs, otherwise it sends the probe to next dependent process.

Algorithm
In pseudocode, the algorithm works as follows:

Controller sending a probe
if Pj is locally dependent on itself
    then declare deadlock
else for all Pj,Pk  such that
    (i) Pi is locally dependent on Pj,
    (ii) Pj is waiting for 'Pk and
    (iii) Pj, Pk are on different controllers.
send probe(i, j, k). to home site of Pk

Controller receiving a probe
if
    (i)Pk is idle / blocked
    (ii) dependentk(i) = false, and
    (iii) Pk has not replied to all requests of to Pjthen begin
    ""dependents""""k""(i) = true;
    if k == i
    then declare that Pi is deadlocked
    else for all Pa,Pb such that
        (i) Pk is locally dependent on Pa,
        (ii) Pa is waiting for 'Pb and
        (iii) Pa, Pb are on different controllers.
    send probe(i, a, b). to home site of Pbend

Example
P1 initiates deadlock detection. C1 sends the probe saying P2 depends on P3. Once the message is received by C2, it checks whether P3 is idle. P3 is idle because it is locally dependent on P4 and updates dependent3(2) to True.
As above, C2 sends probe to C3 and C3 sends probe to C1. At C1, P1 is idle so it update dependent1(1) to True. Therefore, deadlock can be declared.

Complexity
Consider that there are ""m"" controllers and ""p"" process to perform, to declare whether a deadlock has occurred or not, the worst case for controllers and processes must be visited. Therefore, the solution is O(m+p). The time complexity is O(n).


== References ==",39093307,https://en.wikipedia.org/wiki/Chandy%E2%80%93Misra%E2%80%93Haas_algorithm_resource_model
Chinese whispers (clustering method),"Chinese whispers is a clustering method used in network science named after the famous whispering game. Clustering methods are basically used to identify communities of nodes or links in a given network. This algorithm was designed by Chris Biemann and Sven Teresniak in 2005. The name comes from the fact that the process can be modeled as a separation of communities where the nodes send the same type of information to each other.Chinese whispers is a hard partitioning, randomized, flat clustering (no hierarchical relations between clusters) method. The random property means that running the process on the same network several times can lead to different results, while because of hard partitioning one node can belong to only one cluster at a given moment. The original algorithm is applicable to undirected, weighted and unweighted graphs. Chinese whispers runs in linear time, which means that it is extremely fast even if there are very many nodes and links in the network.","Chinese whispers is a clustering method used in network science named after the famous whispering game. Clustering methods are basically used to identify communities of nodes or links in a given network. This algorithm was designed by Chris Biemann and Sven Teresniak in 2005. The name comes from the fact that the process can be modeled as a separation of communities where the nodes send the same type of information to each other.Chinese whispers is a hard partitioning, randomized, flat clustering (no hierarchical relations between clusters) method. The random property means that running the process on the same network several times can lead to different results, while because of hard partitioning one node can belong to only one cluster at a given moment. The original algorithm is applicable to undirected, weighted and unweighted graphs. Chinese whispers runs in linear time, which means that it is extremely fast even if there are very many nodes and links in the network.

Algorithm
The algorithm works in the following way in an undirected unweighted graph:
All nodes are assigned to a distinct class, so that the number of initial classes equals the number of nodes.
All of the network nodes are selected one by one in a random order. For each selected node, its cluster label is changed to the cluster with which it has the most connections. If there is a tie, one is picked randomly from the tied clusters.
Step two repeats itself until a predetermined number of iterations or until the process converges. In the end the emerging classes represent the clusters of the network.The predetermined threshold for the number of the iterations is needed because it is possible that process does not converge. On the other hand in a network with approximately 10000 nodes the clusters does not change significantly after 40-50 iterations even if there is no convergence.

Strengths and weaknesses
The main strength of Chinese whispers lies in its time linear property. Because the processing time increases linearly with the number of nodes, the algorithm is capable of identifying communities in a network very fast. For this reason Chinese whispers is a good tool to analyze community structures in graph with a very high number of nodes. The effectiveness of the method increases further if the network has the small world property.On the other hand because the algorithm is not deterministic in the case of small node number the resulting clusters often significantly differ from each other. The reason for this is that in the case of a small network it matters more from which node the iteration process starts while in large networks the relevance of starting points disappears. For this reason for small graphs other clustering methods are recommended.

Applications
Chinese whispers is used in many subfield of network science. Most frequently it is mentioned in the context of natural language processing problems. On the other hand the algorithm is applicable to any kind of community identification problem which is related to a network framework. Chinese whispers is available for personal use as an extension package for Gephi which is an open source program designed for network analysis.

References
External links
Implementation in Python",46877898,https://en.wikipedia.org/wiki/Chinese_whispers_(clustering_method)
Collaborative diffusion,"Collaborative Diffusion is a type of pathfinding algorithm which uses the concept of antiobjects, objects within a computer program that function opposite to what would be conventionally expected. Collaborative Diffusion is typically used in video games, when multiple agents must path towards a single target agent. For example, the ghosts in Pac-Man. In this case, the background tiles serve as antiobjects, carrying out the necessary calculations for creating a path and having the foreground objects react accordingly, whereas having foreground objects be responsible for their own pathing would be conventionally expected.
Collaborative Diffusion is favored for its efficiency over other pathfinding algorithms, such as A*, when handling multiple agents. Also, this method allows elements of competition and teamwork to easily be incorporated between tracking agents. Notably, the time taken to calculate paths remains constant as the number of agents increases.


== References ==","Collaborative Diffusion is a type of pathfinding algorithm which uses the concept of antiobjects, objects within a computer program that function opposite to what would be conventionally expected. Collaborative Diffusion is typically used in video games, when multiple agents must path towards a single target agent. For example, the ghosts in Pac-Man. In this case, the background tiles serve as antiobjects, carrying out the necessary calculations for creating a path and having the foreground objects react accordingly, whereas having foreground objects be responsible for their own pathing would be conventionally expected.
Collaborative Diffusion is favored for its efficiency over other pathfinding algorithms, such as A*, when handling multiple agents. Also, this method allows elements of competition and teamwork to easily be incorporated between tracking agents. Notably, the time taken to calculate paths remains constant as the number of agents increases.


== References ==",47341174,https://en.wikipedia.org/wiki/Collaborative_diffusion
Collective operation,"Collective operations are building blocks for interaction patterns, that are often used in SPMD algorithms in the parallel programming context. Hence, there is an interest in efficient realizations of these operations.
A realization of the collective operations is provided by the Message Passing Interface (MPI).","Collective operations are building blocks for interaction patterns, that are often used in SPMD algorithms in the parallel programming context. Hence, there is an interest in efficient realizations of these operations.
A realization of the collective operations is provided by the Message Passing Interface (MPI).

Definitions
In all asymptotic runtime functions, we denote the latency α{\displaystyle \alpha } (or startup time per message, independent of message size), the communication cost per word β{\displaystyle \beta }, the number of processing units p{\displaystyle p} and the input size per node n{\displaystyle n}. In cases where we have initial messages on more than one node we assume that all local messages are of the same size. To address individual processing units we use pi∈{p0,p1,…,pp−1}{\displaystyle p_{i}\in \{p_{0},p_{1},\dots ,p_{p-1}\}}.
If we do not have an equal distribution, i.e. node pi{\displaystyle p_{i}} has a message of size ni{\displaystyle n_{i}}, we get an upper bound for the runtime by setting n=max(n0,n1,…,np−1){\displaystyle n=\max(n_{0},n_{1},\dots ,n_{p-1})}.
A distributed memory model is assumed. The concepts are similar for the shared memory model. However, shared memory systems can provide hardware support for some operations like broadcast (§ Broadcast) for example, which allows convenient concurrent read. Thus, new algorithmic possibilities can become available.

Broadcast
The broadcast pattern is used to distribute data from one processing unit to all processing units, which is often needed in SPMD parallel programs to dispense input or global values. Broadcast can be interpreted as an inverse version of the reduce pattern (§ Reduce). Initially only root r{\displaystyle r} with id{\displaystyle id} 0{\displaystyle 0} stores message m{\displaystyle m}. During broadcast m{\displaystyle m} is sent to the remaining processing units, so that eventually m{\displaystyle m} is available to all processing units.
Since an implementation by means of a sequential for-loop with p−1{\displaystyle p-1} iterations becomes a bottleneck, divide-and-conquer approaches are common. One possibility is to utilize a binomial tree structure with the requirement that p{\displaystyle p} has to be a power of two. When a processing unit is responsible for sending m{\displaystyle m} to processing units i..j{\displaystyle i..j}, it sends m{\displaystyle m} to processing unit ⌈(i+j)/2⌉{\displaystyle \left\lceil (i+j)/2\right\rceil } and delegates responsibility for the processing units ⌈(i+j)/2⌉..j{\displaystyle \left\lceil (i+j)/2\right\rceil ..j} to it, while its own responsibility is cut down to i..⌈(i+j)/2⌉−1{\displaystyle i..\left\lceil (i+j)/2\right\rceil -1}.
Binomial trees have a problem with long messages m{\displaystyle m}. The receiving unit of m{\displaystyle m} can only propagate the message to other units, after it received the whole message. In the meantime, the communication network is not utilized. Therefore pipelining on binary trees is used, where m{\displaystyle m} is split into an array of k{\displaystyle k} packets of size ⌈n/k⌉{\displaystyle \left\lceil n/k\right\rceil }. The packets are then broadcast one after another, so that data is distributed fast in the communication network.
Pipelined broadcast on balanced binary tree is possible in O(αlog⁡p+βn){\displaystyle {\mathcal {O}}(\alpha \log p+\beta n)}, whereas for the non-pipelined case it takes O((α+βn)log⁡p){\displaystyle {\mathcal {O}}((\alpha +\beta n)\log p)} cost.

Reduce
The reduce pattern is used to collect data or partial results from different processing units and to combine them into a global result by a chosen operator.  Given p{\displaystyle p} processing units, message mi{\displaystyle m_{i}} is on processing unit pi{\displaystyle p_{i}} initially. All mi{\displaystyle m_{i}} are aggregated by ⊗{\displaystyle \otimes } and the result is eventually stored on p0{\displaystyle p_{0}}. The reduction operator ⊗{\displaystyle \otimes } must be associative at least. Some algorithms require a commutative operator with a neutral element. Operators like sum{\displaystyle sum}, min{\displaystyle min}, max{\displaystyle max} are common.
Implementation considerations are similar to broadcast (§ Broadcast). For pipelining on binary trees the message must be representable as a vector of smaller object for component-wise reduction.
Pipelined reduce on a balanced binary tree is possible in O(αlog⁡p+βn){\displaystyle {\mathcal {O}}(\alpha \log p+\beta n)}.

All-Reduce
The all-reduce pattern (also called allreduce) is used if the result of a reduce operation (§ Reduce) must be distributed to all processing units. Given p{\displaystyle p} processing units, message mi{\displaystyle m_{i}} is on processing unit pi{\displaystyle p_{i}} initially. All mi{\displaystyle m_{i}} are aggregated by an operator ⊗{\displaystyle \otimes } and the result is eventually stored on all pi{\displaystyle p_{i}}. Analog to the reduce operation, the operator ⊗{\displaystyle \otimes } must be at least associative.
All-reduce can be interpreted as a reduce operation with a subsequent broadcast (§ Broadcast). For long messages a corresponding implementation is suitable, whereas for short messages, the latency can be reduced by using a hypercube (Hypercube (communication pattern) § All-Gather/ All-Reduce) topology, if p{\displaystyle p} is a power of two. All-reduce can also be implemented with a butterfly algorithm and achieve optimal latency and bandwidth.All-reduce is possible in O(αlog⁡p+βn){\displaystyle {\mathcal {O}}(\alpha \log p+\beta n)}, since reduce and broadcast are possible in O(αlog⁡p+βn){\displaystyle {\mathcal {O}}(\alpha \log p+\beta n)} with pipelining on balanced binary trees. All-reduce implemented with a butterfly algorithm achieves the same asymptotic runtime.

Prefix-Sum/Scan
The prefix-sum or scan operation is used to collect data or partial results from different processing units and to compute intermediate results by an operator, which are stored on those processing units. It can be seen as a generalization of the reduce operation (§ Reduce). Given p{\displaystyle p} processing units, message mi{\displaystyle m_{i}} is on processing unit pi{\displaystyle p_{i}}. The operator ⊗{\displaystyle \otimes } must be at least associative, whereas some algorithms require also a commutative operator and a neutral element. Common operators are sum{\displaystyle sum}, min{\displaystyle min} and max{\displaystyle max}. Eventually processing unit pi{\displaystyle p_{i}} stores the prefix sum ⊗i′<=i{\displaystyle \otimes _{i'<=i}}mi′{\displaystyle m_{i'}}. In the case of the so-called exclusive prefix sum, processing unit pi{\displaystyle p_{i}} stores the prefix sum ⊗i′<i{\displaystyle \otimes _{i'<i}}mi′{\displaystyle m_{i'}}. Some algorithms require to store the overall sum at each processing unit in addition to the prefix sums.
For short messages, this can be achieved with a hypercube topology if p{\displaystyle p} is a power of two. For long messages, the hypercube (Hypercube (communication pattern) § Prefix sum, Prefix sum § Distributed memory: Hypercube algorithm) topology is not suitable, since all processing units are active in every step and therefore pipelining can't be used. A binary tree topology is better suited for arbitrary p{\displaystyle p} and long messages (Prefix sum § Large Message Sizes: Pipelined Binary Tree).
Prefix-sum on a binary tree can be implemented with an upward and downward phase. In the upward phase reduction is performed, while the downward phase is similar to broadcast, where the prefix sums are computed by sending different data to the left and right children. With this approach pipelining is possible, because the operations are equal to reduction (§ Reduce) and broadcast (§ Broadcast).
Pipelined prefix sum on a binary tree is possible in O(αlog⁡p+βn){\displaystyle {\mathcal {O}}(\alpha \log p+\beta n)}.

Barrier
The barrier as a collective operation is a generalization of the concept of a barrier, that can be used in distributed computing. When a processing unit calls barrier, it waits until all other processing units have called barrier as well. Barrier is thus used to achieve global synchronization in distributed computing.
One way to implement barrier is to call all-reduce (§ All-Reduce) with an empty/ dummy operand. We know the runtime of All-reduce is O(αlog⁡p+βn){\displaystyle {\mathcal {O}}(\alpha \log p+\beta n)}. Using a dummy operand reduces size n{\displaystyle n} to a constant factor and leads to a runtime of O(αlog⁡p){\displaystyle {\mathcal {O}}(\alpha \log p)}.

Gather
The gather communication pattern is used to store data from all processing units on a single processing unit. Given p{\displaystyle p} processing units, message mi{\displaystyle m_{i}} on processing unit pi{\displaystyle p_{i}}. For a fixed processing unit pj{\displaystyle p_{j}}, we want to store the message m1⋅m2⋅…⋅mp{\displaystyle m_{1}\cdot m_{2}\cdot \ldots \cdot m_{p}} on pj{\displaystyle p_{j}}. Gather can be thought of as a reduce operation (§ Reduce) that uses the concatenation operator. This works due to the fact that concatenation is associative. By using the same binomial tree reduction algorithm we get a runtime of O(αlog⁡p+βpn){\displaystyle {\mathcal {O}}(\alpha \log p+\beta pn)}. We see that the asymptotic runtime is similar to the asymptotic runtime of reduce O(αlog⁡p+βn){\displaystyle {\mathcal {O}}(\alpha \log p+\beta n)}, but with the addition of a factor p to the term βn{\displaystyle \beta n}. This additional factor is due to the message size increasing in each step as messages get concatenated. Compare this to reduce where message size is a constant for operators like min{\displaystyle min}.

All-Gather
The all-gather communication pattern is used to collect data from all processing units and to store the collected data on all processing units. Given p{\displaystyle p} processing units pi{\displaystyle p_{i}}, message mi{\displaystyle m_{i}} initially stored on pi{\displaystyle p_{i}}, we want to store the message m1⋅m2⋅…⋅mp{\displaystyle m_{1}\cdot m_{2}\cdot \ldots \cdot m_{p}} on each pj{\displaystyle p_{j}}.
It can be thought of in multiple ways. The first is as an all-reduce operation (§ All-Reduce) with concatenation as the operator, in the same way that gather can be represented by reduce. The second is as a gather-operation followed by a broadcast of the new message of size pn{\displaystyle pn}. With this we see that all-gather in O(αlog⁡p+βpn){\displaystyle {\mathcal {O}}(\alpha \log p+\beta pn)} is possible.

Scatter
The scatter communication pattern is used to distribute data from one processing unit to all the processing units. It differs from broadcast, in that it does not send the same message to all processing units. Instead it splits the message and delivers one part of it to each processing unit.
Given p{\displaystyle p} processing units pi{\displaystyle p_{i}}, a fixed processing unit pj{\displaystyle p_{j}} that holds the message m=m1⋅m2⋅…⋅mp{\displaystyle m=m_{1}\cdot m_{2}\cdot \ldots \cdot m_{p}}. We want to transport the message mi{\displaystyle m_{i}} onto pi{\displaystyle p_{i}}. The same implementation concerns as for gather (§ Gather) apply. This leads to an optimal runtime in O(αlog⁡p+βpn){\displaystyle {\mathcal {O}}(\alpha \log p+\beta pn)}.

All-to-all
All-to-all is the most general communication pattern. For 0≤i,j<p{\displaystyle 0\leq i,j<p}, message mi,j{\displaystyle m_{i,j}} is the message that is initially stored on node i{\displaystyle i} and has to be delivered to node j{\displaystyle j}. We can express all communication primitives that do not use operators through all-to-all. For example, broadcast of message m{\displaystyle m} from node pk{\displaystyle p_{k}} is emulated by setting mi,j=m{\displaystyle m_{i,j}=m} for i=k{\displaystyle i=k} and setting ml,j{\displaystyle m_{l,j}} empty for l≠k{\displaystyle l\neq k}.
Assuming we have a fully connected network, the best possible runtime for all-to-all is in O(p(α+βn)){\displaystyle {\mathcal {O}}(p(\alpha +\beta n))} . This is achieved through p{\displaystyle p}  rounds of direct message exchange. For p{\displaystyle p} power of 2, in communication round k{\displaystyle k} , node pi{\displaystyle p_{i}} exchanges messages with node pj,j=i⊕k{\displaystyle p_{j},j=i\oplus k} .

If the message size is small and latency dominates the communication, a hypercube algorithm can be used to distribute the messages in time O(log⁡p(α+βpn)){\displaystyle {\mathcal {O}}(\log p(\alpha +\beta pn))} .

Runtime Overview
This table gives an overview over the best known asymptotic runtimes, assuming we have free choice of network topology.
Example topologies we want for optimal runtime are binary tree, binomial tree, hypercube.
In practice, we have to adjust to the available physical topologies, e.g. dragonfly, fat tree, grid network (references other topologies, too).
More information under Network topology.
For each operation, the optimal algorithm can depend on the input sizes n{\displaystyle n}. For example, broadcast for short messages is best implemented using a binomial tree whereas for long messages a pipelined communication on a balanced binary tree is optimal.
The complexities stated in the table depend on the latency α{\displaystyle \alpha } and the communication cost per word β{\displaystyle \beta } in addition to the number of processing units p{\displaystyle p} and the input message size per node n{\displaystyle n}. The # senders and # receivers columns represent the number of senders and receivers that are involved in the operation respectively. The # messages column lists the number of input messages and the Computations? column indicates if any computations are done on the messages or if the messages are just delivered without processing. Complexity gives the asymptotic runtime complexity of an optimal implementation under free choice of topology.

Notes
References
Sanders, Peter; Mehlhorn, Kurt; Dietzfelbinger, Martin; Dementiev, Roman (2019). Sequential and Parallel Algorithms and Data Structures - The Basic Toolbox. Springer Nature Switzerland AG. ISBN 978-3-030-25208-3.",23515853,https://en.wikipedia.org/wiki/Collective_operation
Collision problem,"The r-to-1 collision problem is an important theoretical problem in complexity theory, quantum computing, and computational mathematics. The collision problem most often refers to the 2-to-1 version: given n{\displaystyle n} even and a function f:{1,…,n}→{1,…,n}{\displaystyle f:\,\{1,\ldots ,n\}\rightarrow \{1,\ldots ,n\}}, we are promised that f is either 1-to-1 or 2-to-1. We are only allowed to make queries about the value of f(i){\displaystyle f(i)} for any i∈{1,…,n}{\displaystyle i\in \{1,\ldots ,n\}}. The problem then asks how many such queries we need to make to determine with certainty whether f is 1-to-1 or 2-to-1.","The r-to-1 collision problem is an important theoretical problem in complexity theory, quantum computing, and computational mathematics. The collision problem most often refers to the 2-to-1 version: given n{\displaystyle n} even and a function f:{1,…,n}→{1,…,n}{\displaystyle f:\,\{1,\ldots ,n\}\rightarrow \{1,\ldots ,n\}}, we are promised that f is either 1-to-1 or 2-to-1. We are only allowed to make queries about the value of f(i){\displaystyle f(i)} for any i∈{1,…,n}{\displaystyle i\in \{1,\ldots ,n\}}. The problem then asks how many such queries we need to make to determine with certainty whether f is 1-to-1 or 2-to-1.

Classical solutions
Deterministic
Solving the 2-to-1 version deterministically requires n2+1{\textstyle {\frac {n}{2}}+1} queries, and in general distinguishing r-to-1 functions from 1-to-1 functions requires nr+1{\textstyle {\frac {n}{r}}+1} queries.
This is a straightforward application of the pigeonhole principle: if a function is r-to-1, then after nr+1{\textstyle {\frac {n}{r}}+1} queries we are guaranteed to have found a collision. If a function is 1-to-1, then no collision exists. Thus, nr+1{\textstyle {\frac {n}{r}}+1} queries suffice. If we are unlucky, then the first n/r{\displaystyle n/r} queries could return distinct answers, so nr+1{\textstyle {\frac {n}{r}}+1} queries is also necessary.

Randomized
If we allow randomness, the problem is easier. By the birthday paradox, if we choose (distinct) queries at random, then with high probability we find a collision in any fixed 2-to-1 function after Θ(n){\displaystyle \Theta ({\sqrt {n}})} queries.

Quantum solution
The BHT algorithm, which uses Grover's algorithm, solves this problem optimally by only making O(n1/3){\displaystyle O(n^{1/3})} queries to f.


== References ==",11857532,https://en.wikipedia.org/wiki/Collision_problem
Communication-avoiding algorithm,"Communication-avoiding algorithms minimize movement of data within a memory hierarchy for improving its running-time and energy consumption. These minimize the total of two costs (in terms of time and energy): arithmetic and communication. Communication, in this context refers to moving data, either between levels of memory or between multiple processors over a network. It is much more expensive than arithmetic.","Communication-avoiding algorithms minimize movement of data within a memory hierarchy for improving its running-time and energy consumption. These minimize the total of two costs (in terms of time and energy): arithmetic and communication. Communication, in this context refers to moving data, either between levels of memory or between multiple processors over a network. It is much more expensive than arithmetic.

Formal theory
Two-level memory model
A common computational model in analyzing communication-avoiding algorithms is the two-level memory model:

There is one processor and two levels of memory.
Level 1 memory is infinitely large. Level 0 memory (""cache"") has size M{\displaystyle M}.
In the beginning, input resides in level 1. In the end, the output resides in level 1.
Processor can only operate on data in cache.
The goal is to minimize data transfers between the two levels of memory.

Matrix multiplication
Corollary 6.2:

More general results for other numerical linear algebra operations can be found in. The following proof is from.

Motivation
Consider the following running-time model:
Measure of computation = Time per FLOP = γ
Measure of communication = No. of words of data moved = β⇒ Total running time = γ·(no. of FLOPs) + β·(no. of words)
From the fact that β >> γ as measured in time and energy, communication cost dominates computation cost. Technological trends indicate that the relative cost of communication is increasing on a variety of platforms, from cloud computing to supercomputers to mobile devices. The report also predicts that gap between DRAM access time and FLOPs will increase 100× over coming decade to balance power usage between processors and DRAM.
Energy consumption increases by orders of magnitude as we go higher in the memory hierarchy.
United States president Barack Obama cited communication-avoiding algorithms in the FY 2012 Department of Energy budget request to Congress: New Algorithm Improves Performance and Accuracy on Extreme-Scale Computing Systems. On modern computer architectures, communication between processors takes longer than the performance of a floating-point arithmetic operation by a given processor. ASCR researchers have developed a new method, derived from commonly used linear algebra methods, to minimize communications between processors and the memory hierarchy, by reformulating the communication patterns specified within the algorithm. This method has been implemented in the TRILINOS framework, a highly-regarded suite of software, which provides functionality for researchers around the world to solve large scale, complex multi-physics problems.

Objectives
Communication-avoiding algorithms are designed with the following objectives:

Reorganize algorithms to reduce communication across all memory hierarchies.
Attain the lower-bound on communication when possible.The following simple example demonstrates how these are achieved.

Matrix multiplication example
Let A, B and C be square matrices of order n × n. The following naive algorithm implements C = C + A * B:

 for i = 1 to n
     for j = 1 to n
         for k = 1 to n
             C(i,j) = C(i,j) + A(i,k) * B(k,j)

Arithmetic cost (time-complexity): n2(2n − 1) for sufficiently large n or O(n3).
Rewriting this algorithm with communication cost labelled at each step

 for i = 1 to n
     {read row i of A into fast memory}               - n² reads
     for j = 1 to n
         {read C(i,j) into fast memory}               - n² reads
         {read column j of B into fast memory}        - n³ reads
         for k = 1 to n
             C(i,j) = C(i,j) + A(i,k) * B(k,j)
         {write C(i,j) back to slow memory}           - n² writes

Fast memory may be defined as the local processor memory (CPU cache) of size M and slow memory may be defined as the DRAM.
Communication cost (reads/writes): n3 + 3n2 or O(n3)
Since total running time = γ·O(n3) + β·O(n3) and β >> γ the communication cost is dominant. The blocked (tiled) matrix multiplication algorithm reduces this dominant term:

Blocked (tiled) matrix multiplication
Consider A, B and C to be n/b-by-n/b matrices of b-by-b sub-blocks where b is called the block size; assume three b-by-b blocks fit in fast memory.

 for i = 1 to n/b
     for j = 1 to n/b
         {read block C(i,j) into fast memory}           - b² × (n/b)² = n² reads
         for k = 1 to n/b
             {read block A(i,k) into fast memory}       - b² × (n/b)³ = n³/b reads 
             {read block B(k,j) into fast memory}       - b² × (n/b)³ = n³/b reads
             C(i,j) = C(i,j) + A(i,k) * B(k,j)          - {do a matrix multiply on blocks}
         {write block C(i,j) back to slow memory}       - b² × (n/b)² = n² writes

Communication cost: 2n3/b + 2n2 reads/writes << 2n3 arithmetic cost
Making b as large possible:

3b2 ≤ Mwe achieve the following communication lower bound:

31/2n3/M1/2 + 2n2  or Ω (no. of FLOPs / M1/2)

Previous approaches for reducing communication
Most of the approaches investigated in the past to address this problem rely on scheduling or tuning techniques that aim at overlapping communication with computation. However, this approach can lead to an improvement of at most a factor of two. Ghosting is a different technique for reducing communication, in which a processor stores and computes redundantly data from neighboring processors for future computations. Cache-oblivious algorithms represent a different approach introduced in 1999 for fast Fourier transforms, and then extended to graph algorithms, dynamic programming, etc. They were also applied to several operations in linear algebra as dense LU and QR factorizations. The design of architecture specific algorithms is another approach that can be used for reducing the communication in parallel algorithms, and there are many examples in the literature of algorithms that are adapted to a given communication topology.

See also
Data locality


== References ==",48786651,https://en.wikipedia.org/wiki/Communication-avoiding_algorithm
Decrease-and-conquer,"In computer science, divide and conquer is an algorithm design paradigm. A divide-and-conquer algorithm recursively breaks down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem.
The divide-and-conquer technique is the basis of efficient algorithms for many problems, such as sorting (e.g., quicksort, merge sort), multiplying large numbers (e.g., the Karatsuba algorithm), finding the closest pair of points, syntactic analysis (e.g., top-down parsers), and computing the discrete Fourier transform (FFT).Designing efficient divide-and-conquer algorithms can be difficult. As in mathematical induction, it is often necessary to generalize the problem to make it amenable to a recursive solution. The correctness of a divide-and-conquer algorithm is usually proved by mathematical induction, and its computational cost is often determined by solving recurrence relations.","In computer science, divide and conquer is an algorithm design paradigm. A divide-and-conquer algorithm recursively breaks down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem.
The divide-and-conquer technique is the basis of efficient algorithms for many problems, such as sorting (e.g., quicksort, merge sort), multiplying large numbers (e.g., the Karatsuba algorithm), finding the closest pair of points, syntactic analysis (e.g., top-down parsers), and computing the discrete Fourier transform (FFT).Designing efficient divide-and-conquer algorithms can be difficult. As in mathematical induction, it is often necessary to generalize the problem to make it amenable to a recursive solution. The correctness of a divide-and-conquer algorithm is usually proved by mathematical induction, and its computational cost is often determined by solving recurrence relations.

Divide and conquer
The divide-and-conquer paradigm is often used to find an optimal solution of a problem. Its basic idea is to decompose a given problem into two or more similar, but simpler, subproblems, to solve them in turn, and to compose their solutions to solve the given problem. Problems of sufficient simplicity are solved directly. 
For example, to sort a given list of n natural numbers, split it into two lists of about n/2 numbers each, sort each of them in turn, and interleave both results appropriately to obtain the sorted version of the given list (see the picture). This approach is known as the merge sort algorithm.
The name ""divide and conquer"" is sometimes applied to algorithms that reduce each problem to only one sub-problem, such as the binary search algorithm for finding a record in a sorted list (or its analogue in numerical computing, the bisection algorithm for root finding).  These algorithms can be implemented more efficiently than general divide-and-conquer algorithms; in particular, if they use tail recursion, they can be converted into simple loops.  Under this broad definition, however, every algorithm that uses recursion or loops could be regarded as a ""divide-and-conquer algorithm"".  Therefore, some authors consider that the name ""divide and conquer"" should be used only when each problem may generate two or more subproblems. The name decrease and conquer has been proposed instead for the single-subproblem class.An important application of divide and conquer is in optimization, where if the search space is reduced (""pruned"") by a constant factor at each step, the overall algorithm has the same asymptotic complexity as the pruning step, with the constant depending on the pruning factor (by summing the geometric series); this is known as prune and search.

Early historical examples
Early examples of these algorithms are primarily decrease and conquer – the original problem is successively broken down into single subproblems, and indeed can be solved iteratively.
Binary search, a decrease-and-conquer algorithm where the subproblems are of roughly half the original size, has a long history. While a clear description of the algorithm on computers appeared in 1946 in an article by John Mauchly, the idea of using a sorted list of items to facilitate searching dates back at least as far as Babylonia in 200 BC. Another ancient decrease-and-conquer algorithm is the Euclidean algorithm to compute the greatest common divisor of two numbers by reducing the numbers to smaller and smaller equivalent subproblems, which dates to several centuries BC.
An early example of a divide-and-conquer algorithm with multiple subproblems is Gauss's 1805 description of what is now called the Cooley–Tukey fast Fourier transform (FFT) algorithm, although he did not analyze its operation count quantitatively, and FFTs did not become widespread until they were rediscovered over a century later.
An early two-subproblem D&C algorithm that was specifically developed for computers and properly analyzed is the merge sort algorithm, invented by John von Neumann in 1945.Another notable example is the algorithm invented by Anatolii A. Karatsuba in 1960 that could multiply two n-digit numbers in O(nlog2⁡3){\displaystyle O(n^{\log _{2}3})} operations (in Big O notation). This algorithm disproved Andrey Kolmogorov's 1956 conjecture that Ω(n2){\displaystyle \Omega (n^{2})} operations would be required for that task.
As another example of a divide-and-conquer algorithm that did not originally involve computers, Donald Knuth gives the method a post office typically uses to route mail: letters are sorted into separate bags for different geographical areas, each of these bags is itself sorted into batches for smaller sub-regions, and so on until they are delivered. This is related to a radix sort, described for punch-card sorting machines as early as 1929.

Advantages
Solving difficult problems
Divide and conquer is a powerful tool for solving conceptually difficult problems: all it requires is a way of breaking the problem into sub-problems, of solving the trivial cases, and of combining sub-problems to the original problem. Similarly, decrease and conquer only requires reducing the problem to a single smaller problem, such as the classic Tower of Hanoi puzzle, which reduces moving a tower of height n{\displaystyle n} to move a tower of height n−1{\displaystyle n-1}.

Algorithm efficiency
The divide-and-conquer paradigm often helps in the discovery of efficient algorithms.  It was the key, for example, to Karatsuba's fast multiplication method, the quicksort and mergesort algorithms, the Strassen algorithm for matrix multiplication, and fast Fourier transforms.
In all these examples, the D&C approach led to an improvement in the asymptotic cost of the solution. For example, if (a) the base cases have constant-bounded size, the work of splitting the problem and combining the partial solutions is proportional to the problem's size n{\displaystyle n}, and (b) there is a bounded number p{\displaystyle p} of sub-problems of size ~ n/p{\displaystyle n/p} at each stage, then the cost of the divide-and-conquer algorithm will be O(nlogp⁡n){\displaystyle O(n\log _{p}n)}.

Parallelism
Divide-and-conquer algorithms are naturally adapted for execution in multi-processor machines, especially shared-memory systems where the communication of data between processors does not need to be planned in advance because distinct sub-problems can be executed on different processors.

Memory access
Divide-and-conquer algorithms naturally tend to make efficient use of memory caches. The reason is that once a sub-problem is small enough, it and all its sub-problems can, in principle, be solved within the cache, without accessing the slower main memory. An algorithm designed to exploit the cache in this way is called cache-oblivious, because it does not contain the cache size as an explicit parameter. Moreover, D&C algorithms can be designed for important algorithms (e.g., sorting, FFTs, and matrix multiplication) to be optimal cache-oblivious algorithms–they use the cache in a probably optimal way, in an asymptotic sense, regardless of the cache size. In contrast, the traditional approach to exploiting the cache is blocking, as in loop nest optimization, where the problem is explicitly divided into chunks of the appropriate size—this can also use the cache optimally, but only when the algorithm is tuned for the specific cache sizes of a particular machine.
The same advantage exists with regards to other hierarchical storage systems, such as NUMA or virtual memory, as well as for multiple levels of cache: once a sub-problem is small enough, it can be solved within a given level of the hierarchy, without accessing the higher (slower) levels.

Roundoff control
In computations with rounded arithmetic, e.g. with floating-point numbers, a divide-and-conquer algorithm may yield more accurate results than a superficially equivalent iterative method. For example, one can add N numbers either by a simple loop that adds each datum to a single variable, or by a D&C algorithm called pairwise summation that breaks the data set into two halves, recursively computes the sum of each half, and then adds the two sums.  While the second method performs the same number of additions as the first and pays the overhead of the recursive calls, it is usually more accurate.

Implementation issues
Recursion
Divide-and-conquer algorithms are naturally implemented as recursive procedures. In that case, the partial sub-problems leading to the one currently being solved are automatically stored in the procedure call stack. A recursive function is a function that calls itself within its definition.

Explicit stack
Divide-and-conquer algorithms can also be implemented by a non-recursive program that stores the partial sub-problems in some explicit data structure, such as a stack, queue, or priority queue.  This approach allows more freedom in the choice of the sub-problem that is to be solved next, a feature that is important in some applications — e.g. in breadth-first recursion and the branch-and-bound method for function optimization. This approach is also the standard solution in programming languages that do not provide support for recursive procedures.

Stack size
In recursive implementations of D&C algorithms, one must make sure that there is sufficient memory allocated for the recursion stack, otherwise, the execution may fail because of stack overflow.  D&C algorithms that are time-efficient often have relatively small recursion depth.  For example, the quicksort algorithm can be implemented so that it never requires more than log2⁡n{\displaystyle \log _{2}n} nested recursive calls to sort n{\displaystyle n} items.
Stack overflow may be difficult to avoid when using recursive procedures since many compilers assume that the recursion stack is a contiguous area of memory, and some allocate a fixed amount of space for it.  Compilers may also save more information in the recursion stack than is strictly necessary, such as return address, unchanging parameters, and the internal variables of the procedure.  Thus, the risk of stack overflow can be reduced by minimizing the parameters and internal variables of the recursive procedure or by using an explicit stack structure.

Choosing the base cases
In any recursive algorithm, there is considerable freedom in the choice of the base cases, the small subproblems that are solved directly in order to terminate the recursion.
Choosing the smallest or simplest possible base cases is more elegant and usually leads to simpler programs, because there are fewer cases to consider and they are easier to solve. For example, an FFT algorithm could stop the recursion when the input is a single sample, and the quicksort list-sorting algorithm could stop when the input is the empty list; in both examples, there is only one base case to consider, and it requires no processing.
On the other hand, efficiency often improves if the recursion is stopped at relatively large base cases, and these are solved non-recursively, resulting in a hybrid algorithm. This strategy avoids the overhead of recursive calls that do little or no work and may also allow the use of specialized non-recursive algorithms that, for those base cases, are more efficient than explicit recursion. A general procedure for a simple hybrid recursive algorithm is short-circuiting the base case, also known as arm's-length recursion. In this case, whether the next step will result in the base case is checked before the function call, avoiding an unnecessary function call. For example, in a tree, rather than recursing to a child node and then checking whether it is null, checking null before recursing; avoids half the function calls in some algorithms on binary trees. Since a D&C algorithm eventually reduces each problem or sub-problem instance to a large number of base instances, these often dominate the overall cost of the algorithm, especially when the splitting/joining overhead is low. Note that these considerations do not depend on whether recursion is implemented by the compiler or by an explicit stack.
Thus, for example, many library implementations of quicksort will switch to a simple loop-based insertion sort (or similar) algorithm once the number of items to be sorted is sufficiently small. Note that, if the empty list were the only base case, sorting a list with n{\displaystyle n} entries would entail maximally n{\displaystyle n} quicksort calls that would do nothing but return immediately.  Increasing the base cases to lists of size 2 or less will eliminate most of those do-nothing calls, and more generally a base case larger than 2 is typically used to reduce the fraction of time spent in function-call overhead or stack manipulation.
Alternatively, one can employ large base cases that still use a divide-and-conquer algorithm, but implement the algorithm for predetermined set of fixed sizes where the algorithm can be completely unrolled into code that has no recursion, loops, or conditionals (related to the technique of partial evaluation).  For example, this approach is used in some efficient FFT implementations, where the base cases are unrolled implementations of divide-and-conquer FFT algorithms for a set of fixed sizes.Source-code generation methods may be used to produce the large number of separate base cases desirable to implement this strategy efficiently.The generalized version of this idea is known as recursion ""unrolling"" or ""coarsening"", and various techniques have been proposed for automating the procedure of enlarging the base case.

Dynamic programming for overlapping subproblems
For some problems, the branched recursion may end up evaluating the same sub-problem many times over.  In such cases it may be worth identifying and saving the solutions to these overlapping subproblems, a technique which is commonly known as memoization.  Followed to the limit, it leads to bottom-up divide-and-conquer algorithms such as dynamic programming.

See also

Akra–Bazzi method
Decomposable aggregation function
""Divide and conquer""
Fork–join model
Master theorem (analysis of algorithms)
Mathematical induction
MapReduce
Heuristic (computer science)


== References ==",201154,https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm
Devex algorithm,"In applied mathematics, the devex algorithm is a pivot rule for the simplex method developed by Paula M. J. Harris. It identifies the steepest-edge approximately in its search for the optimal solution.


== References ==","In applied mathematics, the devex algorithm is a pivot rule for the simplex method developed by Paula M. J. Harris. It identifies the steepest-edge approximately in its search for the optimal solution.


== References ==",40129720,https://en.wikipedia.org/wiki/Devex_algorithm
Distributed tree search,"Distributed tree search (DTS) algorithm is a class of algorithms for searching values in an efficient and distributed manner. Their purpose is to iterate through a tree by working along multiple branches in parallel and merging the results of each branch into one common solution, in order to minimize time spent searching for a value in a tree-like data structure.
The original paper was written in 1988 by Chris Ferguson and Richard E. Korf, from the University of California's Computer Science Department. They used multiple other chess AIs to develop this wider range algorithm.","Distributed tree search (DTS) algorithm is a class of algorithms for searching values in an efficient and distributed manner. Their purpose is to iterate through a tree by working along multiple branches in parallel and merging the results of each branch into one common solution, in order to minimize time spent searching for a value in a tree-like data structure.
The original paper was written in 1988 by Chris Ferguson and Richard E. Korf, from the University of California's Computer Science Department. They used multiple other chess AIs to develop this wider range algorithm.

Overview
The Distributed Tree Search Algorithm (also known as Korf–Ferguson algorithm) was created to solve the following problem: ""Given a tree with non-uniform branching factor and depth, search it in parallel with an arbitrary number of processors as fast as possible.""
The top-level part of this algorithm is general and does not use a particular existing type of tree-search, but it can be easily specialized to fit any type of non-distributed tree-search.
DTS consists of using multiple processes, each with a node and a set of processors attached, with the goal of searching the sub-tree below the said node. Each process then divides itself into multiple coordinated sub-processes which recursively divide themselves again until an optimal way to search the tree has been found based on the number of processors available to each process. Once a process finishes, DTS dynamically reassigns the processors to other processes as to keep the efficiency to a maximum through good load-balancing, especially in irregular trees.
Once a process finishes searching, it recursively sends and merges a resulting signal to its parent-process, until all the different sub-answers have been merged and the entire problem has been solved.

Applications
DTS is only applicable under two major conditions: the data structure to search through is a tree, and the algorithm can make use of at least one computation unit (Although it cannot be considered as distributed if there is only one).
One major example of the everyday use of DTS is network routing. The Internet can be seen as a tree of IP addresses, and an analogy to a routing protocol could be how post offices work in the real world. Since there are over 4.3 billion IP addresses currently, society heavily depends on the time the data takes to find its way to its destination. As such, IP-routing divides the work into multiple sub-units which each have different scales of calculation capabilities and use each other's result to find the route in a very efficient manner. This is an instance of DTS that affects over 43% of the world's population, for reasons going from entertainment to national security.

Alternatives
Although DTS is currently one of the most widely used algorithms, many of its applications have alternatives to them which could potentially develop into more efficient, less resource-demanding solutions, were they more researched.
One of the more controversial examples is Big-Data processing. In applications like Google Search Engine, Facebook, YouTube, search needs to be optimized to keep waiting time inside a reasonable window. This could be achieved through the plain use of DTS, but other algorithms are used in place (for example data-hashing in SQL databases), or in conjunction (Facebook's Haystack algorithm groups parallel tree-search, data-hashing and memory-ordering/sorting).One of the more important limits of DTS is the fact that it requires a tree as input. Trees are a sub-instance of a data structure known as Graphs, which means every Graph can be converted into a tree. Although there currently exists no better way to search through trees than Korf-Ferguson's algorithm, each task has different particularities and in most cases, there will exist more efficient data structures to represent the problem and solve it than through tree-search. And so there exist instances of tree structures with cycles that cannot possibly be faster than a graph-search on the same structure with the same processing power.

Controversy
There are few controversies around Korf-Ferguson's DTS algorithm, since it is recognized as very complete, but simple. It is very often used as a stepping stone for students to discover the fundamentals and key concepts of distributed problem-solving.
The most important challenge to this algorithmic concept was an article by Kröll B, « Balanced Distributed Search Trees Do Not Exist », which does not attack the veracity or current efficiency of the algorithm, but rather the fact that DTS itself, no matter how many improvements are made to it (for example balancing the input tree before-hand), will never be able to reach optimal resolution-time. This opens a new view point: are too many resources used into the completion of DTS, which blocks new algorithms with higher efficiency-potential from getting researched and developed? Another limit of DTS is the fact that no matter how efficient the division, coordination and merging of the solutions is, it will always be limited by the material number or processors and their processing power.

See also
Tree (data structure)
Search tree
Binary search tree
Tree traversal
Monte Carlo tree search
Parallel computingColbrook A., Brewer E., Dellarocas C., Weihl W., ""Algorithms for Search Trees on Message-Passing Architectures"" (1996)
Colbrook A., Smythe C., Efficient implementations of search trees on parallel distributed memory architectures"" (1990)
Bayer R., McCreight E., Organization and Maintenance of Large Ordered Indices. Acta Informatica 1 (1972)
Comer D., The Ubiquitous B-Tree (1979)


== References ==",50546680,https://en.wikipedia.org/wiki/Distributed_tree_search
Divide-and-conquer algorithm,"In computer science, divide and conquer is an algorithm design paradigm. A divide-and-conquer algorithm recursively breaks down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem.
The divide-and-conquer technique is the basis of efficient algorithms for many problems, such as sorting (e.g., quicksort, merge sort), multiplying large numbers (e.g., the Karatsuba algorithm), finding the closest pair of points, syntactic analysis (e.g., top-down parsers), and computing the discrete Fourier transform (FFT).Designing efficient divide-and-conquer algorithms can be difficult. As in mathematical induction, it is often necessary to generalize the problem to make it amenable to a recursive solution. The correctness of a divide-and-conquer algorithm is usually proved by mathematical induction, and its computational cost is often determined by solving recurrence relations.","In computer science, divide and conquer is an algorithm design paradigm. A divide-and-conquer algorithm recursively breaks down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem.
The divide-and-conquer technique is the basis of efficient algorithms for many problems, such as sorting (e.g., quicksort, merge sort), multiplying large numbers (e.g., the Karatsuba algorithm), finding the closest pair of points, syntactic analysis (e.g., top-down parsers), and computing the discrete Fourier transform (FFT).Designing efficient divide-and-conquer algorithms can be difficult. As in mathematical induction, it is often necessary to generalize the problem to make it amenable to a recursive solution. The correctness of a divide-and-conquer algorithm is usually proved by mathematical induction, and its computational cost is often determined by solving recurrence relations.

Divide and conquer
The divide-and-conquer paradigm is often used to find an optimal solution of a problem. Its basic idea is to decompose a given problem into two or more similar, but simpler, subproblems, to solve them in turn, and to compose their solutions to solve the given problem. Problems of sufficient simplicity are solved directly. 
For example, to sort a given list of n natural numbers, split it into two lists of about n/2 numbers each, sort each of them in turn, and interleave both results appropriately to obtain the sorted version of the given list (see the picture). This approach is known as the merge sort algorithm.
The name ""divide and conquer"" is sometimes applied to algorithms that reduce each problem to only one sub-problem, such as the binary search algorithm for finding a record in a sorted list (or its analogue in numerical computing, the bisection algorithm for root finding).  These algorithms can be implemented more efficiently than general divide-and-conquer algorithms; in particular, if they use tail recursion, they can be converted into simple loops.  Under this broad definition, however, every algorithm that uses recursion or loops could be regarded as a ""divide-and-conquer algorithm"".  Therefore, some authors consider that the name ""divide and conquer"" should be used only when each problem may generate two or more subproblems. The name decrease and conquer has been proposed instead for the single-subproblem class.An important application of divide and conquer is in optimization, where if the search space is reduced (""pruned"") by a constant factor at each step, the overall algorithm has the same asymptotic complexity as the pruning step, with the constant depending on the pruning factor (by summing the geometric series); this is known as prune and search.

Early historical examples
Early examples of these algorithms are primarily decrease and conquer – the original problem is successively broken down into single subproblems, and indeed can be solved iteratively.
Binary search, a decrease-and-conquer algorithm where the subproblems are of roughly half the original size, has a long history. While a clear description of the algorithm on computers appeared in 1946 in an article by John Mauchly, the idea of using a sorted list of items to facilitate searching dates back at least as far as Babylonia in 200 BC. Another ancient decrease-and-conquer algorithm is the Euclidean algorithm to compute the greatest common divisor of two numbers by reducing the numbers to smaller and smaller equivalent subproblems, which dates to several centuries BC.
An early example of a divide-and-conquer algorithm with multiple subproblems is Gauss's 1805 description of what is now called the Cooley–Tukey fast Fourier transform (FFT) algorithm, although he did not analyze its operation count quantitatively, and FFTs did not become widespread until they were rediscovered over a century later.
An early two-subproblem D&C algorithm that was specifically developed for computers and properly analyzed is the merge sort algorithm, invented by John von Neumann in 1945.Another notable example is the algorithm invented by Anatolii A. Karatsuba in 1960 that could multiply two n-digit numbers in O(nlog2⁡3){\displaystyle O(n^{\log _{2}3})} operations (in Big O notation). This algorithm disproved Andrey Kolmogorov's 1956 conjecture that Ω(n2){\displaystyle \Omega (n^{2})} operations would be required for that task.
As another example of a divide-and-conquer algorithm that did not originally involve computers, Donald Knuth gives the method a post office typically uses to route mail: letters are sorted into separate bags for different geographical areas, each of these bags is itself sorted into batches for smaller sub-regions, and so on until they are delivered. This is related to a radix sort, described for punch-card sorting machines as early as 1929.

Advantages
Solving difficult problems
Divide and conquer is a powerful tool for solving conceptually difficult problems: all it requires is a way of breaking the problem into sub-problems, of solving the trivial cases, and of combining sub-problems to the original problem. Similarly, decrease and conquer only requires reducing the problem to a single smaller problem, such as the classic Tower of Hanoi puzzle, which reduces moving a tower of height n{\displaystyle n} to move a tower of height n−1{\displaystyle n-1}.

Algorithm efficiency
The divide-and-conquer paradigm often helps in the discovery of efficient algorithms.  It was the key, for example, to Karatsuba's fast multiplication method, the quicksort and mergesort algorithms, the Strassen algorithm for matrix multiplication, and fast Fourier transforms.
In all these examples, the D&C approach led to an improvement in the asymptotic cost of the solution. For example, if (a) the base cases have constant-bounded size, the work of splitting the problem and combining the partial solutions is proportional to the problem's size n{\displaystyle n}, and (b) there is a bounded number p{\displaystyle p} of sub-problems of size ~ n/p{\displaystyle n/p} at each stage, then the cost of the divide-and-conquer algorithm will be O(nlogp⁡n){\displaystyle O(n\log _{p}n)}.

Parallelism
Divide-and-conquer algorithms are naturally adapted for execution in multi-processor machines, especially shared-memory systems where the communication of data between processors does not need to be planned in advance because distinct sub-problems can be executed on different processors.

Memory access
Divide-and-conquer algorithms naturally tend to make efficient use of memory caches. The reason is that once a sub-problem is small enough, it and all its sub-problems can, in principle, be solved within the cache, without accessing the slower main memory. An algorithm designed to exploit the cache in this way is called cache-oblivious, because it does not contain the cache size as an explicit parameter. Moreover, D&C algorithms can be designed for important algorithms (e.g., sorting, FFTs, and matrix multiplication) to be optimal cache-oblivious algorithms–they use the cache in a probably optimal way, in an asymptotic sense, regardless of the cache size. In contrast, the traditional approach to exploiting the cache is blocking, as in loop nest optimization, where the problem is explicitly divided into chunks of the appropriate size—this can also use the cache optimally, but only when the algorithm is tuned for the specific cache sizes of a particular machine.
The same advantage exists with regards to other hierarchical storage systems, such as NUMA or virtual memory, as well as for multiple levels of cache: once a sub-problem is small enough, it can be solved within a given level of the hierarchy, without accessing the higher (slower) levels.

Roundoff control
In computations with rounded arithmetic, e.g. with floating-point numbers, a divide-and-conquer algorithm may yield more accurate results than a superficially equivalent iterative method. For example, one can add N numbers either by a simple loop that adds each datum to a single variable, or by a D&C algorithm called pairwise summation that breaks the data set into two halves, recursively computes the sum of each half, and then adds the two sums.  While the second method performs the same number of additions as the first and pays the overhead of the recursive calls, it is usually more accurate.

Implementation issues
Recursion
Divide-and-conquer algorithms are naturally implemented as recursive procedures. In that case, the partial sub-problems leading to the one currently being solved are automatically stored in the procedure call stack. A recursive function is a function that calls itself within its definition.

Explicit stack
Divide-and-conquer algorithms can also be implemented by a non-recursive program that stores the partial sub-problems in some explicit data structure, such as a stack, queue, or priority queue.  This approach allows more freedom in the choice of the sub-problem that is to be solved next, a feature that is important in some applications — e.g. in breadth-first recursion and the branch-and-bound method for function optimization. This approach is also the standard solution in programming languages that do not provide support for recursive procedures.

Stack size
In recursive implementations of D&C algorithms, one must make sure that there is sufficient memory allocated for the recursion stack, otherwise, the execution may fail because of stack overflow.  D&C algorithms that are time-efficient often have relatively small recursion depth.  For example, the quicksort algorithm can be implemented so that it never requires more than log2⁡n{\displaystyle \log _{2}n} nested recursive calls to sort n{\displaystyle n} items.
Stack overflow may be difficult to avoid when using recursive procedures since many compilers assume that the recursion stack is a contiguous area of memory, and some allocate a fixed amount of space for it.  Compilers may also save more information in the recursion stack than is strictly necessary, such as return address, unchanging parameters, and the internal variables of the procedure.  Thus, the risk of stack overflow can be reduced by minimizing the parameters and internal variables of the recursive procedure or by using an explicit stack structure.

Choosing the base cases
In any recursive algorithm, there is considerable freedom in the choice of the base cases, the small subproblems that are solved directly in order to terminate the recursion.
Choosing the smallest or simplest possible base cases is more elegant and usually leads to simpler programs, because there are fewer cases to consider and they are easier to solve. For example, an FFT algorithm could stop the recursion when the input is a single sample, and the quicksort list-sorting algorithm could stop when the input is the empty list; in both examples, there is only one base case to consider, and it requires no processing.
On the other hand, efficiency often improves if the recursion is stopped at relatively large base cases, and these are solved non-recursively, resulting in a hybrid algorithm. This strategy avoids the overhead of recursive calls that do little or no work and may also allow the use of specialized non-recursive algorithms that, for those base cases, are more efficient than explicit recursion. A general procedure for a simple hybrid recursive algorithm is short-circuiting the base case, also known as arm's-length recursion. In this case, whether the next step will result in the base case is checked before the function call, avoiding an unnecessary function call. For example, in a tree, rather than recursing to a child node and then checking whether it is null, checking null before recursing; avoids half the function calls in some algorithms on binary trees. Since a D&C algorithm eventually reduces each problem or sub-problem instance to a large number of base instances, these often dominate the overall cost of the algorithm, especially when the splitting/joining overhead is low. Note that these considerations do not depend on whether recursion is implemented by the compiler or by an explicit stack.
Thus, for example, many library implementations of quicksort will switch to a simple loop-based insertion sort (or similar) algorithm once the number of items to be sorted is sufficiently small. Note that, if the empty list were the only base case, sorting a list with n{\displaystyle n} entries would entail maximally n{\displaystyle n} quicksort calls that would do nothing but return immediately.  Increasing the base cases to lists of size 2 or less will eliminate most of those do-nothing calls, and more generally a base case larger than 2 is typically used to reduce the fraction of time spent in function-call overhead or stack manipulation.
Alternatively, one can employ large base cases that still use a divide-and-conquer algorithm, but implement the algorithm for predetermined set of fixed sizes where the algorithm can be completely unrolled into code that has no recursion, loops, or conditionals (related to the technique of partial evaluation).  For example, this approach is used in some efficient FFT implementations, where the base cases are unrolled implementations of divide-and-conquer FFT algorithms for a set of fixed sizes.Source-code generation methods may be used to produce the large number of separate base cases desirable to implement this strategy efficiently.The generalized version of this idea is known as recursion ""unrolling"" or ""coarsening"", and various techniques have been proposed for automating the procedure of enlarging the base case.

Dynamic programming for overlapping subproblems
For some problems, the branched recursion may end up evaluating the same sub-problem many times over.  In such cases it may be worth identifying and saving the solutions to these overlapping subproblems, a technique which is commonly known as memoization.  Followed to the limit, it leads to bottom-up divide-and-conquer algorithms such as dynamic programming.

See also

Akra–Bazzi method
Decomposable aggregation function
""Divide and conquer""
Fork–join model
Master theorem (analysis of algorithms)
Mathematical induction
MapReduce
Heuristic (computer science)


== References ==",201154,https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm
Domain reduction algorithm,"Domain reduction algorithms are algorithms used to reduce constraints and degrees of freedom in order to provide solutions for partial differential equations.


== References ==","Domain reduction algorithms are algorithms used to reduce constraints and degrees of freedom in order to provide solutions for partial differential equations.


== References ==",45194398,https://en.wikipedia.org/wiki/Domain_reduction_algorithm
DONE,"The Data-based Online Nonlinear Extremumseeker (DONE) algorithm is a black-box optimization algorithm.
DONE models the unknown cost function and attempts to find an optimum of the underlying function.
The DONE algorithm is suitable for optimizing costly and noisy functions and does not require derivatives.
An advantage of DONE over similar algorithms, such as Bayesian optimization, is that the computational cost per iteration is independent of the number of function evaluations.","The Data-based Online Nonlinear Extremumseeker (DONE) algorithm is a black-box optimization algorithm.
DONE models the unknown cost function and attempts to find an optimum of the underlying function.
The DONE algorithm is suitable for optimizing costly and noisy functions and does not require derivatives.
An advantage of DONE over similar algorithms, such as Bayesian optimization, is that the computational cost per iteration is independent of the number of function evaluations.

Methods
The DONE algorithm was first proposed by Hans Verstraete and Sander Wahls. The algorithm fits a surrogate model based on random Fourier features and then uses a well-known L-BFGS algorithm to find an optimum of the surrogate model.

Applications
DONE was first demonstrated for maximizing the signal in optical coherence tomography measurements, but has since then been applied to various other applications. For example, it was used to help extending the field of view in light sheet fluorescence microscopy.


== References ==",51017812,https://en.wikipedia.org/wiki/DONE
Driver scheduling problem,"The driver scheduling problem (DSP) is type of problem in operations research and theoretical computer science.
The DSP consists of selecting a set of duties (assignments) for the drivers or pilots of vehicles (e.g., buses, trains, boats, or planes) involved in the transportation of passengers or goods, within the constraints of various legislative and logistical criteria.","The driver scheduling problem (DSP) is type of problem in operations research and theoretical computer science.
The DSP consists of selecting a set of duties (assignments) for the drivers or pilots of vehicles (e.g., buses, trains, boats, or planes) involved in the transportation of passengers or goods, within the constraints of various legislative and logistical criteria.

Criteria and modelling
This very complex problem involves several constraints related to labour and company rules and also different evaluation criteria and objectives. Being able to solve this problem efficiently can have a great impact on costs and quality of service for public transportation companies. There is a large number of different rules that a feasible duty might be required to satisfy, such as

Minimum and maximum stretch duration
Minimum and maximum break duration
Minimum and maximum work duration
Minimum and maximum total duration
Maximum extra work duration
Maximum number of vehicle changes
Minimum driving duration of a particular vehicleOperations research has provided optimization models and algorithms that lead to efficient solutions for this problem. Among the most common models proposed to solve the DSP are the Set Covering and Set Partitioning Models (SPP/SCP). In the SPP model, each work piece (task) is covered by only one duty. In the SCP model, it is possible to have more than one duty covering a given work piece.
In both models, the set of work pieces that needs to be covered is laid out in rows, and the set of previously defined feasible duties available for covering specific work pieces is arranged in columns. The DSP resolution, based on either of these models, is the selection of the set of feasible duties that guarantees that there is one (SPP) or more (SCP) duties covering each work piece while minimizing the total cost of the final schedule.

See also
Crew scheduling
Deadheading (employee)


== References ==",39456471,https://en.wikipedia.org/wiki/Driver_scheduling_problem
EdgeRank,"EdgeRank is the name commonly given to the algorithm that Facebook uses to determine what articles should be displayed in a user's News Feed. As of 2011, Facebook has stopped using the EdgeRank system and uses a machine learning algorithm that, as of 2013, takes more than 100,000 factors into account.EdgeRank was developed and implemented by Serkan Piantino.","EdgeRank is the name commonly given to the algorithm that Facebook uses to determine what articles should be displayed in a user's News Feed. As of 2011, Facebook has stopped using the EdgeRank system and uses a machine learning algorithm that, as of 2013, takes more than 100,000 factors into account.EdgeRank was developed and implemented by Serkan Piantino.

Formula and factors
In 2010, a simplified version of the EdgeRank algorithm was presented as:

∑edgeseuewede{\displaystyle \sum _{\mathrm {edges\,} e}u_{e}w_{e}d_{e}}where:

ue{\displaystyle u_{e}} is user affinity.
we{\displaystyle w_{e}} is how the content is weighted.
de{\displaystyle d_{e}} is a time-based decay parameter.User Affinity: The User Affinity part of the algorithm in Facebook's EdgeRank looks at the relationship and proximity of the user and the content (post/status update).
Content Weight: What action was taken by the user on the content.
Time-Based Decay Parameter: New or old. Newer posts tend to hold a higher place than older posts.Some of the methods that Facebook uses to adjust the parameters are proprietary and not available to the public.A study has shown that it is possible to hypothesize a disadvantage of the ""like"" reaction and advantages of other interactions (e.g., the ""haha"" reaction or ""comments"") in content algorithmic ranking on Facebook. The ""like"" button can decrease the organic reach as a ""brake effect of viral reach"".  The ""haha"" reaction, ""comments"" and the ""love"" reaction could achieve the highest increase in total organic reach.

Impact
EdgeRank and its successors have a broad impact on what users actually see out of what they ostensibly follow: for instance, the selection can produce a filter bubble (if users are exposed to updates which confirm their opinions etc.) or alter people's mood (if users are shown a disproportionate amount of positive or negative updates).As a result, for Facebook pages, the typical engagement rate is less than 1% (or less than 0.1% for the bigger ones), and organic reach 10% or less for most non-profits.As a consequence, for pages, it may be nearly impossible to reach any significant audience without paying to promote their content.

See also
PageRank, the ranking algorithm used by Google's search engine

References
External links
edgerank.net
Facebook - How News Feed Works",38090349,https://en.wikipedia.org/wiki/EdgeRank
Emergent algorithm,"An emergent algorithm is an algorithm that exhibits emergent behavior.  In essence an emergent algorithm implements a set of simple building block behaviors that when combined exhibit more complex behaviors.  One example of this is the implementation of fuzzy motion controllers used to adapt robot movement in response to environmental obstacles.An emergent algorithm has the following characteristics:
it achieves predictable global effects
it does not require global visibility
it does not assume any kind of centralized control
it is self-stabilizingOther examples of emergent algorithms and models include cellular automata, artificial neural networks and swarm intelligence systems (ant colony optimization, bees algorithm, etc.).","An emergent algorithm is an algorithm that exhibits emergent behavior.  In essence an emergent algorithm implements a set of simple building block behaviors that when combined exhibit more complex behaviors.  One example of this is the implementation of fuzzy motion controllers used to adapt robot movement in response to environmental obstacles.An emergent algorithm has the following characteristics:
it achieves predictable global effects
it does not require global visibility
it does not assume any kind of centralized control
it is self-stabilizingOther examples of emergent algorithms and models include cellular automata, artificial neural networks and swarm intelligence systems (ant colony optimization, bees algorithm, etc.).

See also
AI alignment
Artificial intelligence detection software
Emergence
Evolutionary computation
Fuzzy logic
Genetic algorithm
Heuristic


== References ==",214269,https://en.wikipedia.org/wiki/Emergent_algorithm
Enumeration algorithm,"In computer science, an enumeration algorithm is an algorithm that enumerates the answers to a computational problem. Formally, such an algorithm applies to problems that take an input and produce a list of solutions, similarly to function problems. For each input, the enumeration algorithm must produce the list of all solutions, without duplicates, and then halt. The performance of an enumeration algorithm is measured in terms of the time required to produce the solutions, either in terms of the total time required to produce all solutions, or in terms of the maximal delay between two consecutive solutions and in terms of a preprocessing time, counted as the time before outputting the first solution. This complexity can be expressed in terms of the size of the input, the size of each individual output, or the total size of the set of all outputs, similarly to what is done with output-sensitive algorithms.","In computer science, an enumeration algorithm is an algorithm that enumerates the answers to a computational problem. Formally, such an algorithm applies to problems that take an input and produce a list of solutions, similarly to function problems. For each input, the enumeration algorithm must produce the list of all solutions, without duplicates, and then halt. The performance of an enumeration algorithm is measured in terms of the time required to produce the solutions, either in terms of the total time required to produce all solutions, or in terms of the maximal delay between two consecutive solutions and in terms of a preprocessing time, counted as the time before outputting the first solution. This complexity can be expressed in terms of the size of the input, the size of each individual output, or the total size of the set of all outputs, similarly to what is done with output-sensitive algorithms.

Formal definitions
An enumeration problem P{\displaystyle P} is defined as a relation R{\displaystyle R} over strings of an arbitrary alphabet Σ{\displaystyle \Sigma }:
R⊆Σ∗×Σ∗{\displaystyle R\subseteq \Sigma ^{*}\times \Sigma ^{*}}
An algorithm solves P{\displaystyle P} if for every input x{\displaystyle x} the algorithm produces the (possibly infinite) sequence y{\displaystyle y} such that y{\displaystyle y} has no duplicate and z∈y{\displaystyle z\in y} if and only if (x,z)∈R{\displaystyle (x,z)\in R}. The algorithm should halt if the sequence y{\displaystyle y} is finite.

Common complexity classes
Enumeration problems have been studied in the context of computational complexity theory, and several complexity classes have been introduced for such problems.
A very general such class is EnumP, the class of problems for which the correctness of a possible output can be checked in polynomial time in the input and output. Formally, for such a problem, there must exist an algorithm A which takes as input the problem input x, the candidate output y, and solves the decision problem of whether y is a correct output for the input x, in polynomial time in x and y. For instance, this class contains all problems that amount to enumerating the witnesses of a problem in the class NP.
Other classes that have been defined include the following. In the case of problems that are also in EnumP, these problems are ordered from least to most specific:

Output polynomial, the class of problems whose complete output can be computed in polynomial time.
Incremental polynomial time, the class of problems where, for all i, the i-th output can be produced in polynomial time in the input size and in the number i.
Polynomial delay, the class of problems where the delay between two consecutive outputs is polynomial in the input (and independent from the output).
Strongly polynomial delay, the class of problems where the delay before each output is polynomial in the size of this specific output (and independent from the input or from the other outputs). The preprocessing is generally assumed to be polynomial.
Constant delay, the class of problems where the delay before each output is constant, i.e., independent from the input and output. The preprocessing phase is generally assumed to be polynomial in the input.

Common techniques
Backtracking: The simplest way to enumerate all solutions is by systematically exploring the space of possible results (partitioning it at each successive step). However, performing this may not give good guarantees on the delay, i.e., a backtracking algorithm may spend a long time exploring parts of the space of possible results that do not give rise to a full solution.
Flashlight search: This technique improves on backtracking by exploring the space of all possible solutions but solving at each step the problem of whether the current partial solution can be extended to a partial solution. If the answer is no, then the algorithm can immediately backtrack and avoid wasting time, which makes it easier to show guarantees on the delay between any two complete solutions. In particular, this technique applies well to self-reducible problems.
Closure under set operations: If we wish to enumerate the disjoint union of two sets, then we can solve the problem by enumerating the first set and then the second set. If the union is non disjoint but the sets can be enumerated in sorted order, then the enumeration can be performed in parallel on both sets while eliminating duplicates on the fly. If the union is not disjoint and both sets are not sorted then duplicates can be eliminated at the expense of a higher memory usage, e.g., using a hash table. Likewise, the cartesian product of two sets can be enumerated efficiently by enumerating one set and joining each result with all results obtained when enumerating the second step.

Examples of enumeration problems
The vertex enumeration problem, where we are given a polytope described as a system of linear inequalities and we must enumerate the vertices of the polytope.
Enumerating the minimal transversals of a hypergraph. This problem is related to monotone dualization and is connected to many applications in database theory and graph theory.
Enumerating the answers to a database query, for instance a conjunctive query or a query expressed in monadic second-order. There have been characterizations in database theory of which conjunctive queries could be enumerated with linear preprocessing and constant delay.
The problem of enumerating maximal cliques in an input graph, e.g., with the Bron–Kerbosch algorithm
Listing all elements of structures such as matroids and greedoids
Several problems on graphs, e.g., enumerating independent sets, paths, cuts, etc.
Enumerating the satisfying assignments of representations of Boolean functions, e.g., a Boolean formula written in conjunctive normal form or disjunctive normal form, a binary decision diagram such as an OBDD, or a Boolean circuit in restricted classes studied in knowledge compilation, e.g., NNF.

Connection to computability theory
The notion of enumeration algorithms is also used in the field of computability theory to define some high complexity classes such as RE, the class of all recursively enumerable problems. This is the class of sets for which there exist an enumeration algorithm that will produce all elements of the set: the algorithm may run forever if the set is infinite, but each solution must be produced by the algorithm after a finite time.


== References ==",60842845,https://en.wikipedia.org/wiki/Enumeration_algorithm
External memory algorithm,"In computing, external memory algorithms or out-of-core algorithms are algorithms that are designed to process data that are too large to fit into a computer's main memory at once. Such algorithms must be optimized to efficiently fetch and access data stored in slow bulk memory (auxiliary memory) such as hard drives or tape drives, or when memory is on a computer network. External memory algorithms are analyzed in the external memory model.","In computing, external memory algorithms or out-of-core algorithms are algorithms that are designed to process data that are too large to fit into a computer's main memory at once. Such algorithms must be optimized to efficiently fetch and access data stored in slow bulk memory (auxiliary memory) such as hard drives or tape drives, or when memory is on a computer network. External memory algorithms are analyzed in the external memory model.

Model
External memory algorithms are analyzed in an idealized model of computation called the external memory model (or I/O model, or disk access model). The external memory model is an abstract machine similar to the RAM machine model, but with a cache in addition to main memory. The model captures the fact that read and write operations are much faster in a cache than in main memory, and that reading long contiguous blocks is faster than reading randomly using a disk read-and-write head. The running time of an algorithm in the external memory model is defined by the number of reads and writes to memory required. The model was introduced by Alok Aggarwal and Jeffrey Vitter in 1988. The external memory model is related to the cache-oblivious model, but algorithms in the external memory model may know both the block size and the cache size. For this reason, the model is sometimes referred to as the cache-aware model.The model consists of a processor with an internal memory or cache of size M, connected to an unbounded external memory. Both the internal and external memory are divided into blocks of size B. One input/output or memory transfer operation consists of moving a block of B contiguous elements from external to internal memory, and the running time of an algorithm is determined by the number of these input/output operations.

Algorithms
Algorithms in the external memory model take advantage of the fact that retrieving one object from external memory retrieves an entire block of size B. This property is sometimes referred to as locality.
Searching for an element among N objects is possible in the external memory model using a B-tree with branching factor B. Using a B-tree, searching, insertion, and deletion can be achieved in O(logB⁡N){\displaystyle O(\log _{B}N)} time (in Big O notation). Information theoretically, this is the minimum running time possible for these operations, so using a B-tree is asymptotically optimal.External sorting is sorting in an external memory setting. External sorting can be done via distribution sort, which is similar to quicksort, or via a MB{\displaystyle {\tfrac {M}{B}}}-way merge sort. Both variants achieve the asymptotically optimal runtime of O(NBlogMB⁡NB){\displaystyle O\left({\frac {N}{B}}\log _{\frac {M}{B}}{\frac {N}{B}}\right)} to sort N objects. This bound also applies to the fast Fourier transform in the external memory model.The permutation problem is to rearrange N elements into a specific permutation. This can either be done either by sorting, which requires the above sorting runtime, or inserting each element in order and ignoring the benefit of locality. Thus, permutation can be done in O(min(N,NBlogMB⁡NB)){\displaystyle O\left(\min \left(N,{\frac {N}{B}}\log _{\frac {M}{B}}{\frac {N}{B}}\right)\right)} time.

Applications
The external memory model captures the memory hierarchy, which is not modeled in other common models used in analyzing data structures, such as the random-access machine, and is useful for proving lower bounds for data structures. The model is also useful for analyzing algorithms that work on datasets too big to fit in internal memory.A typical example is geographic information systems, especially digital elevation models, where the full data set easily exceeds several gigabytes or even terabytes of data.
This methodology extends beyond general purpose CPUs and also includes GPU computing as well as classical digital signal processing. In general-purpose computing on graphics processing units (GPGPU), powerful graphics cards (GPUs) with little memory (compared with the more familiar system memory, which is most often referred to simply as RAM) are utilized with relatively slow CPU-to-GPU memory transfer (when compared with computation bandwidth).

History
An early use of the term ""out-of-core"" as an adjective is in 1962 in reference to devices that are other than the core memory of an IBM 360. An early use of the term ""out-of-core"" with respect to algorithms appears in 1971.

See also
Cache-oblivious algorithm
External memory graph traversal
Online algorithm
Parallel external memory
Streaming algorithm

References
External links
Out of Core SVD and QR
Out of core graphics
Scalapack design",1881722,https://en.wikipedia.org/wiki/External_memory_algorithm
Flajolet–Martin algorithm,"The Flajolet–Martin algorithm is an algorithm for approximating the number of distinct elements in a stream with a single pass and space-consumption logarithmic in the maximal number of possible distinct elements in the stream (the count-distinct problem). The algorithm was introduced by Philippe Flajolet and G. Nigel Martin in their 1984 article ""Probabilistic Counting Algorithms for Data Base Applications"". Later it has been refined in ""LogLog counting of large cardinalities"" by Marianne Durand and Philippe Flajolet, and ""HyperLogLog: The analysis of a near-optimal cardinality estimation algorithm"" by Philippe Flajolet et al.In their 2010 article ""An optimal algorithm for the distinct elements problem"", Daniel M. Kane, Jelani Nelson and David P. Woodruff give an improved algorithm, which uses nearly optimal space and has optimal O(1) update and reporting times.","The Flajolet–Martin algorithm is an algorithm for approximating the number of distinct elements in a stream with a single pass and space-consumption logarithmic in the maximal number of possible distinct elements in the stream (the count-distinct problem). The algorithm was introduced by Philippe Flajolet and G. Nigel Martin in their 1984 article ""Probabilistic Counting Algorithms for Data Base Applications"". Later it has been refined in ""LogLog counting of large cardinalities"" by Marianne Durand and Philippe Flajolet, and ""HyperLogLog: The analysis of a near-optimal cardinality estimation algorithm"" by Philippe Flajolet et al.In their 2010 article ""An optimal algorithm for the distinct elements problem"", Daniel M. Kane, Jelani Nelson and David P. Woodruff give an improved algorithm, which uses nearly optimal space and has optimal O(1) update and reporting times.

The algorithm
Assume that we are given a hash function hash(x){\displaystyle \mathrm {hash} (x)} that maps input x{\displaystyle x} to integers in the range [0;2L−1]{\displaystyle [0;2^{L}-1]}, and where the outputs are sufficiently uniformly distributed. Note that the set of integers from 0 to 2L−1{\displaystyle 2^{L}-1} corresponds to the set of binary strings of length L{\displaystyle L}. For any non-negative integer y{\displaystyle y}, define bit(y,k){\displaystyle \mathrm {bit} (y,k)} to be the k{\displaystyle k}-th bit in the binary representation of y{\displaystyle y}, such that:

y=∑k≥0bit(y,k)2k.{\displaystyle y=\sum _{k\geq 0}\mathrm {bit} (y,k)2^{k}.}We then define a function ρ(y){\displaystyle \rho (y)} that outputs the position of the least-significant set bit in the binary representation of y{\displaystyle y}, and L{\displaystyle L} if no such set bit can be found as all bits are zero:
ρ(y)={min{k≥0∣bit(y,k)≠0}y>0Ly=0{\displaystyle \rho (y)={\begin{cases}\min\{k\geq 0\mid \mathrm {bit} (y,k)\neq 0\}&y>0\\L&y=0\end{cases}}}
Note that with the above definition we are using 0-indexing for the positions, starting from the least significant bit. For example, ρ(13)=ρ(11012)=0{\displaystyle \rho (13)=\rho (1101_{2})=0}, since the least significant bit is a 1 (0th position), and ρ(8)=ρ(10002)=3{\displaystyle \rho (8)=\rho (1000_{2})=3}, since the least significant set bit is at the 3rd position. At this point, note that under the assumption that the output of our hash function is uniformly distributed, then the probability of observing a hash output ending with 2k{\displaystyle 2^{k}} (a one, followed by k{\displaystyle k} zeroes) is 2−(k+1){\displaystyle 2^{-(k+1)}}, since this corresponds to flipping k{\displaystyle k} heads and then a tail with a fair coin.
Now the Flajolet–Martin algorithm for estimating the cardinality of a multiset M{\displaystyle M} is as follows:

Initialize a bit-vector BITMAP to be of length L{\displaystyle L} and contain all 0s.
For each element x{\displaystyle x} in M{\displaystyle M}:
Calculate the index i=ρ(hash(x)){\displaystyle i=\rho (\mathrm {hash} (x))}.
Set BITMAP[i]=1{\displaystyle \mathrm {BITMAP} [i]=1}.
Let R{\displaystyle R} denote the smallest index i{\displaystyle i} such that BITMAP[i]=0{\displaystyle \mathrm {BITMAP} [i]=0}.
Estimate the cardinality of M{\displaystyle M} as 2R/ϕ{\displaystyle 2^{R}/\phi }, where ϕ≈0.77351{\displaystyle \phi \approx 0.77351}.The idea is that if n{\displaystyle n} is the number of distinct elements in the multiset M{\displaystyle M}, then BITMAP[0]{\displaystyle \mathrm {BITMAP} [0]} is accessed approximately n/2{\displaystyle n/2} times, BITMAP[1]{\displaystyle \mathrm {BITMAP} [1]} is accessed approximately n/4{\displaystyle n/4} times and so on. Consequently, if i≫log2⁡n{\displaystyle i\gg \log _{2}n}, then BITMAP[i]{\displaystyle \mathrm {BITMAP} [i]} is almost certainly 0, and if i≪log2⁡n{\displaystyle i\ll \log _{2}n}, then BITMAP[i]{\displaystyle \mathrm {BITMAP} [i]} is almost certainly 1. If i≈log2⁡n{\displaystyle i\approx \log _{2}n}, then BITMAP[i]{\displaystyle \mathrm {BITMAP} [i]} can be expected to be either 1 or 0.
The correction factor ϕ≈0.77351{\displaystyle \phi \approx 0.77351} is found by calculations, which can be found in the original article.

Improving accuracy
A problem with the Flajolet–Martin algorithm in the above form is that the results vary significantly. A common solution has been to run the algorithm multiple times with k{\displaystyle k} different hash functions and combine the results from the different runs. One idea is to take the mean of the k{\displaystyle k} results together from each hash function, obtaining a single estimate of the cardinality. The problem with this is that averaging is very susceptible to outliers (which are likely here). A different idea is to use the median, which is less prone to be influences by outliers. The problem with this is that the results can only take form 2R/ϕ{\displaystyle 2^{R}/\phi }, where R{\displaystyle R} is integer. A common solution is to combine both the mean and the median: Create k⋅l{\displaystyle k\cdot l} hash functions and split them into k{\displaystyle k} distinct groups (each of size l{\displaystyle l}). Within each group use the mean for aggregating together the l{\displaystyle l} results, and finally take the median of the k{\displaystyle k} group estimates as the final estimate.The 2007 HyperLogLog algorithm splits the multiset into subsets and estimates their cardinalities, then it uses the harmonic mean to combine them into an estimate for the original cardinality.

See also
Streaming algorithm
HyperLogLog

References
Additional sources
Rajaraman, Anand; Ullman, Jeffrey David (2011-10-27). Mining of Massive Datasets. Cambridge University Press. p. 119. ISBN 9781139505345. Retrieved 2014-11-09.",44308703,https://en.wikipedia.org/wiki/Flajolet%E2%80%93Martin_algorithm
Generalized distributive law,"The generalized distributive law (GDL) is a generalization of the distributive property which gives rise to a general message passing algorithm. It is a synthesis of the work of many authors in the information theory, digital communications, signal processing, statistics, and artificial intelligence communities. The law and algorithm were introduced in a semi-tutorial by Srinivas M. Aji and Robert J. McEliece with the same title.","The generalized distributive law (GDL) is a generalization of the distributive property which gives rise to a general message passing algorithm. It is a synthesis of the work of many authors in the information theory, digital communications, signal processing, statistics, and artificial intelligence communities. The law and algorithm were introduced in a semi-tutorial by Srinivas M. Aji and Robert J. McEliece with the same title.

Introduction
""The distributive law in mathematics is the law relating the operations of multiplication and addition, stated symbolically, a∗(b+c)=a∗b+a∗c{\displaystyle a*(b+c)=a*b+a*c}; that is, the monomial factor a{\displaystyle a} is distributed, or separately applied, to each term of the binomial factor b+c{\displaystyle b+c}, resulting in the product a∗b+a∗c{\displaystyle a*b+a*c}"" -  BritannicaAs it can be observed from the definition, application of distributive law to an arithmetic expression reduces the number of operations in it. In the previous example the total number of operations reduced from three (two multiplications and an addition in a∗b+a∗c{\displaystyle a*b+a*c}) to two (one multiplication and one addition in a∗(b+c){\displaystyle a*(b+c)}). Generalization of distributive law leads to a large family of fast algorithms. This includes the FFT and Viterbi algorithm.
This is explained in a more formal way in the example below:
α(a,b)=def∑c,d,e∈Af(a,c,b)g(a,d,e){\displaystyle \alpha (a,\,b){\stackrel {\mathrm {def} }{=}}\displaystyle \sum \limits _{c,d,e\in A}f(a,\,c,\,b)\,g(a,\,d,\,e)} where f(⋅){\displaystyle f(\cdot )} and g(⋅){\displaystyle g(\cdot )} are real-valued functions, a,b,c,d,e∈A{\displaystyle a,b,c,d,e\in A} and |A|=q{\displaystyle |A|=q} (say)
Here we are ""marginalizing out"" the independent variables (c{\displaystyle c}, d{\displaystyle d}, and e{\displaystyle e}) to obtain the result. When we are calculating the computational complexity, we can see that for each q2{\displaystyle q^{2}} pairs of (a,b){\displaystyle (a,b)}, there are q3{\displaystyle q^{3}} terms due to the triplet (c,d,e){\displaystyle (c,d,e)} which needs to take part in the evaluation of α(a,b){\displaystyle \alpha (a,\,b)} with each step having one addition and one multiplication. Therefore, the total number of computations needed is 2⋅q2⋅q3=2q5{\displaystyle 2\cdot q^{2}\cdot q^{3}=2q^{5}}. Hence the asymptotic complexity of the above function is O(n5){\displaystyle O(n^{5})}.
If we apply the distributive law to the RHS of the equation, we get the following:

α(a,b)=def∑c∈Af(a,c,b)⋅∑d,e∈Ag(a,d,e){\displaystyle \alpha (a,\,b){\stackrel {\mathrm {def} }{=}}\displaystyle \sum \limits _{c\in A}f(a,\,c,\,b)\cdot \sum _{d,\,e\in A}g(a,\,d,\,e)}This implies that α(a,b){\displaystyle \alpha (a,\,b)} can be described as a product α1(a,b)⋅α2(a){\displaystyle \alpha _{1}(a,\,b)\cdot \alpha _{2}(a)} where α1(a,b)=def∑c∈Af(a,c,b){\displaystyle \alpha _{1}(a,b){\stackrel {\mathrm {def} }{=}}\displaystyle \sum \limits _{c\in A}f(a,\,c,\,b)} and α2(a)=def∑d,e∈Ag(a,d,e){\displaystyle \alpha _{2}(a){\stackrel {\mathrm {def} }{=}}\displaystyle \sum \limits _{d,\,e\in A}g(a,\,d,\,e)}
Now, when we are calculating the computational complexity, we can see that there are q3{\displaystyle q^{3}} additions in α1(a,b){\displaystyle \alpha _{1}(a,\,b)} and α2(a){\displaystyle \alpha _{2}(a)} each and there are q2{\displaystyle q^{2}} multiplications when we are using the product α1(a,b)⋅α2(a){\displaystyle \alpha _{1}(a,\,b)\cdot \alpha _{2}(a)} to evaluate α(a,b){\displaystyle \alpha (a,\,b)}. Therefore, the total number of computations needed is q3+q3+q2=2q3+q2{\displaystyle q^{3}+q^{3}+q^{2}=2q^{3}+q^{2}}. Hence the asymptotic complexity of calculating α(a,b){\displaystyle \alpha (a,b)} reduces to O(n3){\displaystyle O(n^{3})} from O(n5){\displaystyle O(n^{5})}.  This shows by an example that applying distributive law reduces the computational complexity which is one of the good features of a ""fast algorithm"".

History
Some of the problems that used distributive law to solve can be grouped as follows
1. Decoding algorithms
A GDL like algorithm was used by Gallager's for decoding low density parity-check codes. Based on Gallager's work Tanner introduced the Tanner graph and expressed Gallagers work in message passing form. The tanners graph also helped explain the  Viterbi algorithm.
It is observed by Forney that Viterbi's maximum likelihood decoding of convolutional codes also used algorithms of GDL-like generality.
2. Forward-backward algorithm
The forward backward algorithm helped as an algorithm for tracking the states in the markov chain. And this also was used the algorithm of GDL like generality
3. Artificial intelligence
The notion of junction trees has been used to solve many problems in AI. Also the concept of bucket elimination used many of the concepts.

The MPF problem
MPF or marginalize a product function is a general computational problem which as special case includes many classical problems such as computation of discrete Hadamard transform, maximum likelihood decoding of a linear code over a memory-less channel, and matrix chain multiplication. The power of the GDL lies in the fact that it applies to situations in which additions and multiplications are generalized.
A commutative semiring is a good framework for explaining this behavior. It is defined over a set K{\displaystyle K} with operators ""+{\displaystyle +}"" and "".{\displaystyle .}"" where (K,+){\displaystyle (K,\,+)} and (K,.){\displaystyle (K,\,.)} are a commutative monoids and the distributive law holds.
Let p1,…,pn{\displaystyle p_{1},\ldots ,p_{n}} be variables such that p1∈A1,…,pn∈An{\displaystyle p_{1}\in A_{1},\ldots ,p_{n}\in A_{n}} where A{\displaystyle A} is a finite set and |Ai|=qi{\displaystyle |A_{i}|=q_{i}}. Here i=1,…,n{\displaystyle i=1,\ldots ,n}. If S={i1,…,ir}{\displaystyle S=\{i_{1},\ldots ,i_{r}\}} and S⊂{1,…,n}{\displaystyle S\,\subset \{1,\ldots ,n\}}, let
AS=Ai1×⋯×Air{\displaystyle A_{S}=A_{i_{1}}\times \cdots \times A_{i_{r}}},
pS=(pi1,…,pir){\displaystyle p_{S}=(p_{i_{1}},\ldots ,p_{i_{r}})},  
qS=|AS|{\displaystyle q_{S}=|A_{S}|}, 
A=A1×⋯×An{\displaystyle \mathbf {A} =A_{1}\times \cdots \times A_{n}}, and
p={p1,…,pn}{\displaystyle \mathbf {p} =\{p_{1},\ldots ,p_{n}\}}
Let S={Sj}j=1M{\displaystyle S=\{S_{j}\}_{j=1}^{M}} where Sj⊂{1,...,n}{\displaystyle S_{j}\subset \{1,...\,,n\}}. Suppose a function is defined as αi:ASi→R{\displaystyle \alpha _{i}:A_{S_{i}}\rightarrow R}, where R{\displaystyle R} is a commutative semiring. Also, pSi{\displaystyle p_{S_{i}}} are named the local domains and αi{\displaystyle \alpha _{i}} as the local kernels.
Now the global kernel β:A→R{\displaystyle \beta :\mathbf {A} \rightarrow R} is defined as :
β(p1,...,pn)=∏i=1Mα(pSi){\displaystyle \beta (p_{1},...\,,p_{n})=\prod _{i=1}^{M}\alpha (p_{S_{i}})}
Definition of MPF problem: For one or more indices i=1,...,M{\displaystyle i=1,...\,,M}, compute a table of the values of Si{\displaystyle S_{i}}-marginalization of the global kernel β{\displaystyle \beta }, which is the function βi:ASi→R{\displaystyle \beta _{i}:A_{S_{i}}\rightarrow R} defined as βi(pSi)=∑pSic∈ASicβ(p){\displaystyle \beta _{i}(p_{S_{i}})\,=\displaystyle \sum \limits _{p_{S_{i}^{c}}\in A_{S_{i}^{c}}}\beta (p)}
Here Sic{\displaystyle S_{i}^{c}} is the complement of Si{\displaystyle S_{i}} with respect to {1,...,n}{\displaystyle \mathbf {\{} 1,...\,,n\}} and the βi(pSi){\displaystyle \beta _{i}(p_{S_{i}})} is called the ith{\displaystyle i^{th}} objective function, or the objective function at Si{\displaystyle S_{i}}. It can observed that the computation of the ith{\displaystyle i^{th}} objective function in the obvious way needs Mq1q2q3⋯qn{\displaystyle Mq_{1}q_{2}q_{3}\cdots q_{n}} operations. This is because there are q1q2⋯qn{\displaystyle q_{1}q_{2}\cdots q_{n}} additions and (M−1)q1q2...qn{\displaystyle (M-1)q_{1}q_{2}...q_{n}} multiplications needed in the computation of the ith{\displaystyle i^{\text{th}}} objective function. The GDL algorithm which is explained in the next section can reduce this computational complexity.
The following is an example of the MPF problem. 
Let p1,p2,p3,p4,{\displaystyle p_{1},\,p_{2},\,p_{3},\,p_{4},} and p5{\displaystyle p_{5}} be variables such that p1∈A1,p2∈A2,p3∈A3,p4∈A4,{\displaystyle p_{1}\in A_{1},p_{2}\in A_{2},p_{3}\in A_{3},p_{4}\in A_{4},} and p5∈A5{\displaystyle p_{5}\in A_{5}}. Here M=4{\displaystyle M=4} and S={{1,2,5},{2,4},{1,4},{2}}{\displaystyle S=\{\{1,2,5\},\{2,4\},\{1,4\},\{2\}\}}. The given functions using these variables are f(p1,p2,p5){\displaystyle f(p_{1},p_{2},p_{5})} and g(p3,p4){\displaystyle g(p_{3},p_{4})} and we need to calculate α(p1,p4){\displaystyle \alpha (p_{1},\,p_{4})} and β(p2){\displaystyle \beta (p_{2})} defined as:

α(p1,p4)=∑p2∈A2,p3∈A3,p5∈A5f(p1,p2,p5)⋅g(p2,p4){\displaystyle \alpha (p_{1},\,p_{4})=\displaystyle \sum \limits _{p_{2}\in A_{2},\,p_{3}\in A_{3},\,p_{5}\in A_{5}}f(p_{1},\,p_{2},\,p_{5})\cdot g(p_{2},\,p_{4})}β(p2)=∑p1∈A1,p3∈A3,p4∈A4,p5∈A5f(p1,p2,p5)⋅g(p2,p4){\displaystyle \beta (p_{2})=\sum \limits _{p_{1}\in A_{1},\,p_{3}\in A_{3},\,p_{4}\in A_{4},\,p_{5}\in A_{5}}f(p_{1},\,p_{2},\,p_{5})\cdot g(p_{2},\,p_{4})}Here local domains and local kernels are defined as follows: 

where α(p1,p4){\displaystyle \alpha (p_{1},p_{4})} is the 3rd{\displaystyle 3^{rd}} objective function and β(p2){\displaystyle \beta (p_{2})} is the 4th{\displaystyle 4^{th}} objective function.
Consider another example where p1,p2,p3,p4,r1,r2,r3,r4∈{0,1}{\displaystyle p_{1},p_{2},p_{3},p_{4},r_{1},r_{2},r_{3},r_{4}\in \{0,1\}} and f(r1,r2,r3,r4){\displaystyle f(r_{1},r_{2},r_{3},r_{4})} is a real valued function. Now, we shall consider the MPF problem where the commutative semiring is defined as the set of real numbers with ordinary addition and multiplication and the local domains and local kernels are defined as follows:

Now since the global kernel is defined as the product of the local kernels, it is

F(p1,p2,p3,p4,r1,r2,r3,r4)=f(p1,p2,p3,p4)⋅(−1)p1r1+p2r2+p3r3+p4r4{\displaystyle F(p_{1},p_{2},p_{3},p_{4},r_{1},r_{2},r_{3},r_{4})=f(p_{1},p_{2},p_{3},p_{4})\cdot (-1)^{p_{1}r_{1}+p_{2}r_{2}+p_{3}r_{3}+p_{4}r_{4}}}and the objective function at the local domain p1,p2,p3,p4{\displaystyle p_{1},p_{2},p_{3},p_{4}} is

F(p1,p2,p3,p4)=∑r1,r2,r3,r4f(r1,r2,r3,r4)⋅(−1)p1r1+p2r2+p3r3+p4r4.{\displaystyle F(p_{1},p_{2},p_{3},p_{4})=\displaystyle \sum \limits _{r_{1},r_{2},r_{3},r_{4}}f(r_{1},r_{2},r_{3},r_{4})\cdot (-1)^{p_{1}r_{1}+p_{2}r_{2}+p_{3}r_{3}+p_{4}r_{4}}.}This is the Hadamard transform of the function f(⋅){\displaystyle f(\cdot )}. Hence we can see that the computation of Hadamard transform is a special case of the MPF problem. More examples can be demonstrated to prove that the MPF problem forms special cases of many classical problem as explained above whose details can be found at

GDL: an algorithm for solving the MPF problem
If one can find a relationship among the elements of a given set S{\displaystyle S}, then one can solve the MPF problem basing on the notion of belief propagation which is a special use of ""message passing"" technique. The required relationship is that the given set of local domains can be organised into a junction tree. In other words, we create a graph theoretic tree with the elements of S{\displaystyle S} as the vertices of the tree T{\displaystyle T}, such that for any two arbitrary vertices say vi{\displaystyle v_{i}} and vj{\displaystyle v_{j}} where i≠j{\displaystyle i\neq j} and there exists an edge between these two vertices, then the intersection of corresponding labels, viz Si∩Sj{\displaystyle S_{i}\cap S_{j}}, is a subset of the label on each vertex on the unique path from vi{\displaystyle v_{i}} to vj{\displaystyle v_{j}}.
For example,
Example 1: Consider the following nine local domains:

{p2}{\displaystyle \{p_{2}\}}
{p3,p2}{\displaystyle \{p_{3},p_{2}\}}
{p2,p1}{\displaystyle \{p_{2},p_{1}\}}
{p3,p4}{\displaystyle \{p_{3},p_{4}\}}
{p3}{\displaystyle \{p_{3}\}}
{p1,p4}{\displaystyle \{p_{1},p_{4}\}}
{p1}{\displaystyle \{p_{1}\}}
{p4}{\displaystyle \{p_{4}\}}
{p2,p4}{\displaystyle \{p_{2},p_{4}\}}For the above given set of local domains, one can organize them into a junction tree as shown below:

Similarly If another set like the following is given
Example 2: Consider the following four local domains:

{p1,p2}{\displaystyle \{p_{1},p_{2}\}}
{p2,p3}{\displaystyle \{p_{2},p_{3}\}}
{p3,p4}{\displaystyle \{p_{3},p_{4}\}}
{p1,p4}{\displaystyle \{p_{1},p_{4}\}}Then constructing the tree only with these local domains is not possible since this set of values has no common domains which can be placed between any two values of the above set. But however, if add the two dummy domains as shown below then organizing the updated set into a junction tree would be possible and easy too.
5.{p1,p2{\displaystyle \{p_{1},p_{2}},p4}{\displaystyle p_{4}\}}
6.{p2,p3{\displaystyle \{p_{2},p_{3}},p4}{\displaystyle p_{4}\}}
Similarly for these set of domains, the junction tree looks like shown below:

Generalized distributive law (GDL) algorithm
Input: A set of local domains.
Output: For the given set of domains, possible minimum number of operations that is required to solve the problem is computed. 
So, if vi{\displaystyle v_{i}} and vj{\displaystyle v_{j}} are connected by an edge in the junction tree, then a message from vi{\displaystyle v_{i}} to vj{\displaystyle v_{j}} is a set/table of values given by a function: μi,j{\displaystyle \mu _{i,j}}:ASi∩Sj→R{\displaystyle A_{S_{i}\cap S_{j}}\rightarrow R}. To begin with all the functions i.e. for all combinations of i{\displaystyle i} and j{\displaystyle j} in the given tree, μi,j{\displaystyle \mu _{i,j}} is defined to be identically 1{\displaystyle 1} and when a particular message is update, it follows the equation given below.

μi,j(pSi∩Sj){\displaystyle \mu _{i,j}(p_{S_{i}\cap S_{j}})} = ∑pSi∖Sj∈ASi∖Sjαi(pSi)∏vkadj⁡vi,k≠jμk,j(pSk∩Si)(1){\displaystyle \sum _{p_{S_{i}\setminus S_{j}}\in A_{S_{i}\setminus S_{j}}}\alpha _{i}(p_{S_{i}})\prod _{{v_{k}\operatorname {adj} v_{i}},{k\neq j}}\mu _{k,j}(p_{S_{k}\cap S_{i}})(1)}where vkadj⁡vi{\displaystyle v_{k}\operatorname {adj} v_{i}} means that vk{\displaystyle v_{k}} is an adjacent vertex to vi{\displaystyle v_{i}} in tree.
Similarly each vertex has a state which is defined as a table containing the values from the function σi:ASi→R{\displaystyle \sigma _{i}:A_{S_{i}}\rightarrow R}, Just like how messages initialize to 1 identically, state of vi{\displaystyle v_{i}} is defined to be local kernel α(pSi){\displaystyle \alpha (p_{S_{i}})}, but whenever σi{\displaystyle \sigma _{i}} gets updated, it follows the following equation:

σ(pSi)=αi(pSi)∏vkadj⁡viμk,j(pSk∩Si)(2).{\displaystyle \sigma (p_{S_{i}})=\alpha _{i}(p_{S_{i}})\prod _{v_{k}\operatorname {adj} v_{i}}\mu _{k,j}(p_{S_{k}\cap S_{i}})(2).}

Basic working of the algorithm
For the given set of local domains as input, we find out if we can create a junction tree, either by using the set directly or by adding dummy domains to the set first and then creating the junction tree, if construction junction is not possible then algorithm output that there is no way to reduce the number of steps to compute the given equation problem, but once we have junction tree, algorithm will have to schedule messages and compute states, by doing these we can know where steps can be reduced, hence will be discusses this below.

Scheduling of the message passing and the state computation
There are two special cases we are going to talk about here namely Single Vertex Problem in which the objective function is computed at only one vertex v0{\displaystyle v_{0}}  and the second one is All Vertices Problem where the goal is to compute the objective function at all vertices.
Lets begin with the single-vertex problem, GDL will start by directing each edge towards the targeted vertex v0{\displaystyle v_{0}}. Here messages are sent only in the direction towards the targeted vertex. Note that all the directed messages are sent only once. The messages are started from the leaf nodes(where the degree is 1) go up towards the target vertex v0{\displaystyle v_{0}}. The message travels from the leaves to its parents and then from there to their parents and so on until it reaches the target vertex v0{\displaystyle v_{0}}. The target vertex v0{\displaystyle v_{0}} will compute its state only when it receives all messages from all its neighbors. Once we have the state, We have got the answer and hence the algorithm terminates.
For Example, let us consider a junction tree constructed from the set of local domains given above i.e. the set from example 1, Now the Scheduling table for these domains is (where the target vertex is p2{\displaystyle p_{2}}).
Round                      Message or State Computation{\displaystyle {\text{Round                      Message or State Computation}}}1.μ8,4(p4)=α8(p4){\displaystyle 1.\mu _{8,4}(p_{4})=\alpha _{8}(p_{4})}2.μ8,4(p4)=Σp2α9(p2,p4){\displaystyle 2.\mu _{8,4}(p_{4})=\Sigma _{p_{2}}\alpha _{9}(p_{2},p_{4})}3.μ5,2(p3)=α5(p3){\displaystyle 3.\mu _{5,2}(p_{3})=\alpha _{5}(p_{3})}4.μ6,3(p1)=Σp4α6(p1,p4){\displaystyle 4.\mu _{6,3}(p_{1})=\Sigma _{p_{4}}\alpha _{6}(p_{1},p_{4})}5.μ7,3(p1)=α7(p1){\displaystyle 5.\mu _{7,3}(p_{1})=\alpha _{7}(p_{1})}6.μ4,2(p3)=Σp4α4(p3,p4).μ8,4(p4).μ9,4(p4){\displaystyle 6.\mu _{4,2}(p_{3})=\Sigma _{p_{4}}\alpha _{4}(p_{3},p_{4}).\mu _{8,4}(p_{4}).\mu _{9,4}(p_{4})}7.μ3,1(p2)=Σp1α3(p2,p1).μ6,3(p1).μ7,3(p1){\displaystyle 7.\mu _{3,1}(p_{2})=\Sigma _{p_{1}}\alpha _{3}(p_{2},p_{1}).\mu _{6,3}(p_{1}).\mu _{7,3}(p_{1})}8.μ2,1(p2)=Σp3α2(p3,p2).μ4,2(p3).μ5,2(p3){\displaystyle 8.\mu _{2,1}(p_{2})=\Sigma _{p_{3}}\alpha _{2}(p_{3},p_{2}).\mu _{4,2}(p_{3}).\mu _{5,2}(p_{3})}9.σ1(p2)=α1(p2).μ2,1(p2).μ3,1(p2){\displaystyle 9.\sigma _{1}(p_{2})=\alpha _{1}(p_{2}).\mu _{2,1}(p_{2}).\mu _{3,1}(p_{2})}
Thus the complexity for Single Vertex GDL can be shown as
Σvd(v)|AS(v)|{\displaystyle \Sigma _{v}d(v)|A_{S_{(v)}}|}  arithmetic operations
Where (Note: The explanation for the above equation is explained later in the article )S(v){\displaystyle S(v)} is the label of v{\displaystyle v}.d(v){\displaystyle d(v)} is the degree of v{\displaystyle v} (i.e. number of vertices adjacent to v).
To solve the All-Vertices problem, we can schedule GDL in several ways, some of them are parallel implementation where in each round, every state is updated and every message is computed and transmitted at the same time. In this type of implementation the states and messages will stabilizes after number of rounds that is at most equal to the diameter of the tree. At this point all the all states of the vertices will be equal to the desired objective function.
Another way to schedule GDL for this problem is serial implementation where its similar to the  Single vertex problem except that we don't stop the algorithm until all the vertices of a required set have not got all the messages from all their neighbors and have compute their state. 
Thus the number of arithmetic this implementation requires is at most Σv∈Vd(v)|AS(v)|{\displaystyle \Sigma _{v\in V}d(v)|A_{S_{(v)}}|} arithmetic operations.

Constructing a junction tree
The key to constructing a junction tree lies in the local domain graph GLD{\displaystyle G_{LD}}, which is a weighted complete graph with M{\displaystyle M} vertices v1,v2,v3,…,vM{\displaystyle v_{1},v_{2},v_{3},\ldots ,v_{M}} i.e. one for each local domain, having the weight of the edge  ei,j:vi↔vj{\displaystyle e_{i,j}:v_{i}\leftrightarrow v_{j}} defined byωi,j=|Si∩Sj|{\displaystyle \omega _{i,j}=|S_{i}\cap S_{j}|}.
if xk∈Si∩Sj{\displaystyle x_{k}\in S_{i}\cap S_{j}}, then we say xk{\displaystyle x_{k}} is contained inei,j{\displaystyle e_{i,j}}. Denoted by ωmax{\displaystyle \omega _{max}} (the weight of a maximal-weight spanning tree of GLD{\displaystyle G_{LD}}), which is defined by

ω∗=Σi=1M|Si|−n{\displaystyle \omega ^{*}=\Sigma _{i=1}^{M}|S_{i}|-n}where n is the number of elements in that set. For more clarity and details, please refer to these.

Scheduling theorem
Let ′T′{\displaystyle 'T'} be a junction tree with vertex set ′V′{\displaystyle 'V'} and edge set ′E′{\displaystyle 'E'}. In this algorithm, the messages are sent in both the direction on any edge, so we can say/regard the edge set E as set of ordered pairs of vertices. For example, from Figure 1 ′E′{\displaystyle 'E'} can be defined as follows

E={(1,2),(2,1),(1,3),(3,1),(4,2),(2,4),(5,2),(2,5),(6,3),(3,6),(7,3),(3,7),(8,4),(4,8),(9,4),(4,9)}{\displaystyle E=\{(1,2),(2,1),(1,3),(3,1),(4,2),(2,4),(5,2),(2,5),(6,3),(3,6),(7,3),(3,7),(8,4),(4,8),(9,4),(4,9)\}}NOTE:E{\displaystyle E} above gives you all the possible directions that a message can travel in the tree.
The schedule for the GDL is defined as a finite sequence of subsets ofE{\displaystyle E}. Which is generally represented by 
E={\displaystyle {\mathcal {E}}=}{E1,E2,E3,…,EN{\displaystyle E_{1},E_{2},E_{3},\ldots ,E_{N}}}, Where EN{\displaystyle E_{N}} is the set of messages updated during the Nth{\displaystyle N^{th}} round of running the algorithm.
Having defined/seen some notations, we will see want the theorem says,
When we are given a schedule E={E1,E2,E3,…,EN}{\displaystyle {\mathcal {E}}=\{E_{1},E_{2},E_{3},\ldots ,E_{N}\}}, the corresponding message trellis as a finite directed graph with Vertex set of  V×{0,1,2,3,…,N}{\displaystyle V\times \{0,1,2,3,\ldots ,N\}}, in which a typical element is denoted by vi(t){\displaystyle v_{i}(t)} for  t∈{0,1,2,3,…,N}{\displaystyle t\in \{0,1,2,3,\ldots ,N\}}, Then after completion of the message passing, state at  vertex vj{\displaystyle v_{j}} will be the jth{\displaystyle j^{\text{th}}} objective defined in

σ(pSi)=αi(pSi)∏vkadj⁡viμk,j(pSk∩Si){\displaystyle \sigma (p_{S_{i}})=\alpha _{i}(p_{S_{i}})\prod _{v_{k}\operatorname {adj} v_{i}}\mu _{k,j}(p_{S_{k}\cap S_{i}})}and iff there is a path from vi(0){\displaystyle v_{i}(0)} to vj(N){\displaystyle v_{j}(N)}

Computational complexity
Here we try to explain the complexity of solving the MPF problem in terms of the number of mathematical operations required for the calculation. i.e. We compare the number of operations required when calculated using the normal method (Here by normal method we mean by methods that do not use message passing or junction trees in short methods that do not use the concepts of GDL)and the number of operations using the generalized distributive law.
Example: Consider the simplest case where we need to compute the following expression ab+ac{\displaystyle ab+ac}.
To evaluate this expression naively requires two multiplications and one addition. The expression when expressed using the distributive law can be written as a(b+c){\displaystyle a(b+c)} a simple optimization that reduces the number of operations to one addition and one multiplication.
Similar to the above explained example we will be expressing the equations in different forms to perform as few operation as possible by applying the GDL.
As explained in the previous sections we solve the problem by using the concept of the junction trees. The optimization obtained by the use of these trees is comparable to the optimization obtained by solving a semi group problem on trees. For example, to find the minimum of a group of numbers we can observe that if we have a tree and the elements are all at the bottom of the tree, then we can compare the minimum of two items in parallel and the resultant minimum will be written to the parent. When this process is propagated up the tree the minimum of the group of elements will be found at the root.
The following is the complexity for solving the junction tree using message passing
We rewrite the formula used earlier to the following form. This is the eqn for a message to be sent from vertex v to w

μv,w(pv∩w)=∑pv∖w∈AS(v)∖S(w)αv(pv)∏uadjvu≠vμu,v(pu∩v){\displaystyle \mu _{v,w}(p_{v\cap w})=\sum _{p_{v\setminus w}\in A_{S(v)\setminus S(w)}}\alpha _{v}(p_{v})\prod _{uadjv_{u\neq v}}\mu _{u,v}(p_{u\cap v})}            ----message equationSimilarly we rewrite the equation for calculating the state of vertex v as follows

σv(pv)=αv(pv)∏uadj⁡vμv,w(pv∩w){\displaystyle \sigma _{v}(p_{v})=\alpha _{v}(p_{v})\prod _{u\operatorname {adj} v}\mu _{v,w}(p_{v\cap w})}We first will analyze for the single-vertex problem and assume the target vertex is v0{\displaystyle v_{0}} and hence we have one edge from v{\displaystyle v} to v0{\displaystyle v_{0}}. 
Suppose we have an edge (v,w){\displaystyle (v,w)} we calculate the message using the message equation. To calculate pu∩v{\displaystyle p_{u\cap v}} requires

qv∖w−1{\displaystyle q_{v\setminus w}-1}additions and

qv∖w(d(v)−1){\displaystyle q_{v\setminus w}(d(v)-1)}multiplications.
(We represent the |AS(v) S(w)|{\displaystyle |A_{S(v)\ S(w)}|} as qv∖w{\displaystyle q_{v\setminus w}}.)
But there will be many possibilities for xv∩w{\displaystyle x_{v\cap w}} hence qv∩w=def|AS(v)∩S(w)|{\displaystyle q_{v\cap w}{\stackrel {\mathrm {def} }{=}}|A_{S(v)\cap S(w)}|} possibilities for pv∩w{\displaystyle p_{v\cap w}}.
Thus the entire message will need

(qv∩w)(qv∖w−1)=qv−qv∩w{\displaystyle (q_{v\cap w})(q_{v\setminus w}-1)=q_{v}-q_{v\cap w}}additions and

(qv∩w)qv∖w.(d(v)−1)=(d(v)−1)qv{\displaystyle (q_{v\cap w})q_{v\setminus w}.(d(v)-1)=(d(v)-1)q_{v}}multiplications
The total number of arithmetic operations required to send a message towards v0{\displaystyle v_{0}}along the edges of tree will be

∑v≠v0(qv−qv∩w){\displaystyle \sum _{v\neq v0}(q_{v}-q_{v\cap w})}additions and

∑v≠v0(d(v)−1)qv{\displaystyle \sum _{v\neq v0}(d(v)-1)q_{v}}multiplications.
Once all the messages have been transmitted the algorithm terminates with the computation of state at v0{\displaystyle v_{0}}  The state computation requires d(v0)q0{\displaystyle d(v_{0})q_{0}} more multiplications.
Thus number of calculations required to calculate the state is given as below

∑v≠v0(qv−qv∩w){\displaystyle \sum _{v\neq v_{0}}(q_{v}-q_{v\cap w})}additions and

∑v≠v0(d(v)−1)qv+d(v0)qv0{\displaystyle \sum _{v\neq v_{0}}(d(v)-1)q_{v}+d(v_{0})q_{v_{0}}}multiplications
Thus the grand total of the number of calculations is

χ(T)=∑v∈Vd(v)qv−∑e∈Eqe{\displaystyle \chi (T)=\sum _{v\in V}d(v)q_{v}-\sum _{e\in E}q_{e}} ----(1){\displaystyle (1)}where e=(v,w){\displaystyle e=(v,w)} is an edge and its size is defined by qv∩w{\displaystyle q_{v\cap w}}
The formula above gives us the upper bound.
If we define the complexity of the edge e=(v,w){\displaystyle e=(v,w)} as

χ(e)=qv+qw−qv∩w{\displaystyle \chi (e)=q_{v}+q_{w}-q_{v\cap w}}Therefore, (1){\displaystyle (1)} can be written as

χ(T)=∑e∈Eχ(e){\displaystyle \chi (T)=\sum _{e\in E}\chi (e)}We now calculate the edge complexity for the problem defined in Figure 1 as follows

χ(1,2)=q2+q2q3−q2{\displaystyle \chi (1,2)=q_{2}+q_{2}q_{3}-q_{2}}
χ(2,4)=q3q4+q2q3−q3{\displaystyle \chi (2,4)=q_{3}q_{4}+q_{2}q_{3}-q_{3}}
χ(2,5)=q3+q2q3−q3{\displaystyle \chi (2,5)=q_{3}+q_{2}q_{3}-q_{3}}
χ(4,8)=q4+q3q4−q4{\displaystyle \chi (4,8)=q_{4}+q_{3}q_{4}-q_{4}}
χ(4,9)=q2q4+q3q4−q4{\displaystyle \chi (4,9)=q_{2}q_{4}+q_{3}q_{4}-q_{4}}
χ(1,3)=q2+q2q1−q2{\displaystyle \chi (1,3)=q_{2}+q_{2}q_{1}-q_{2}}
χ(3,7)=q1+q1q2−q1{\displaystyle \chi (3,7)=q_{1}+q_{1}q_{2}-q_{1}}
χ(3,6)=q1q4+q1q2−q1{\displaystyle \chi (3,6)=q_{1}q_{4}+q_{1}q_{2}-q_{1}}The total complexity will be 3q2q3+3q3q4+3q1q2+q2q4+q1q4−q1−q3−q4{\displaystyle 3q_{2}q_{3}+3q_{3}q_{4}+3q_{1}q_{2}+q_{2}q_{4}+q_{1}q_{4}-q_{1}-q_{3}-q_{4}} which is considerably low compared to the direct method. (Here by direct method we mean by methods that do not use message passing. The time taken using the direct method will be the equivalent to calculating message at each node and time to calculate the state of each of the nodes.)
Now we consider the all-vertex problem where the message will have to be sent in both the directions and state must be computed at both the vertexes. This would take O(∑vd(v)d(v)qv){\displaystyle O(\sum _{v}d(v)d(v)q_{v})} but by precomputing we can reduce the number of multiplications to 3(d−2){\displaystyle 3(d-2)}. Here d{\displaystyle d} is the degree of the vertex. Ex : If there is a set (a1,…,ad){\displaystyle (a_{1},\ldots ,a_{d})} with d{\displaystyle d} numbers. It is possible to compute all the d products of d−1{\displaystyle d-1} of the ai{\displaystyle a_{i}} with at most 3(d−2){\displaystyle 3(d-2)} multiplications rather than the obvious d(d−2){\displaystyle d(d-2)}. 
We do this by precomputing the quantities 
b1=a1,b2=b1⋅a2=a1⋅a2,bd−1=bd−2⋅ad−1=a1a2⋯ad−1{\displaystyle b_{1}=a_{1},b_{2}=b_{1}\cdot a_{2}=a_{1}\cdot a_{2},b_{d-1}=b_{d-2}\cdot a_{d-1}=a_{1}a_{2}\cdots a_{d-1}} and cd=ad,cd−1=ad−1cd=ad−1⋅ad,…,c2=a2⋅c3=a2a3⋯ad{\displaystyle c_{d}=a_{d},c_{d-1}=a_{d-1}c_{d}=a_{d-1}\cdot a_{d},\ldots ,c_{2}=a_{2}\cdot c_{3}=a_{2}a_{3}\cdots a_{d}} this takes 2(d−2){\displaystyle 2(d-2)} multiplications. Then if mj{\displaystyle m_{j}} denotes the product of all ai{\displaystyle a_{i}} except for aj{\displaystyle a_{j}} we have m1=c2,m2=b1⋅c3{\displaystyle m_{1}=c_{2},m_{2}=b_{1}\cdot c_{3}} and so on will need another d−2{\displaystyle d-2} multiplications making the total 3(d−2){\displaystyle 3(d-2)}
There is not much we can do when it comes to the construction of the junction tree except that we may have many maximal weight spanning tree and we should choose the spanning tree with the least χ(T){\displaystyle \chi (T)} and sometimes this might mean adding a local domain to lower the junction tree complexity.
It may seem that GDL is correct only when the local domains can be expressed as a junction tree. But even in cases where there are cycles and a number of iterations the messages will approximately be equal to the objective function. The experiments on Gallager–Tanner–Wiberg algorithm for low density parity-check codes were supportive of this claim.


== References ==",35685954,https://en.wikipedia.org/wiki/Generalized_distributive_law
Gutmann method,"The Gutmann method is an algorithm for securely erasing the contents of computer hard disk drives, such as files. Devised by Peter Gutmann and Colin Plumb and presented in the paper Secure Deletion of Data from Magnetic and Solid-State Memory in July 1996, it involved writing a series of 35 patterns over the region to be erased.
The selection of patterns assumes that the user does not know the encoding mechanism used by the drive, so it includes patterns designed specifically for three types of drives. A user who knows which type of encoding the drive uses can choose only those patterns intended for their drive. A drive with a different encoding mechanism would need different patterns.
Most of the patterns in the Gutmann method were designed for older MFM/RLL encoded disks. Gutmann himself has noted that more modern drives no longer use these older encoding techniques, making parts of the method irrelevant. He said ""In the time since this paper was published, some people have treated the 35-pass overwrite technique described in it more as a kind of voodoo incantation to banish evil spirits than the result of a technical analysis of drive encoding techniques"".Since about 2001, some ATA IDE and SATA hard drive manufacturer designs include support for the ATA Secure Erase standard, obviating the need to apply the Gutmann method when erasing an entire drive. The Gutmann method does not apply to USB sticks: an 2011 study reports that 71.7% of data remained available. On solid state drives it resulted in 0.8 - 4.3% recovery.","The Gutmann method is an algorithm for securely erasing the contents of computer hard disk drives, such as files. Devised by Peter Gutmann and Colin Plumb and presented in the paper Secure Deletion of Data from Magnetic and Solid-State Memory in July 1996, it involved writing a series of 35 patterns over the region to be erased.
The selection of patterns assumes that the user does not know the encoding mechanism used by the drive, so it includes patterns designed specifically for three types of drives. A user who knows which type of encoding the drive uses can choose only those patterns intended for their drive. A drive with a different encoding mechanism would need different patterns.
Most of the patterns in the Gutmann method were designed for older MFM/RLL encoded disks. Gutmann himself has noted that more modern drives no longer use these older encoding techniques, making parts of the method irrelevant. He said ""In the time since this paper was published, some people have treated the 35-pass overwrite technique described in it more as a kind of voodoo incantation to banish evil spirits than the result of a technical analysis of drive encoding techniques"".Since about 2001, some ATA IDE and SATA hard drive manufacturer designs include support for the ATA Secure Erase standard, obviating the need to apply the Gutmann method when erasing an entire drive. The Gutmann method does not apply to USB sticks: an 2011 study reports that 71.7% of data remained available. On solid state drives it resulted in 0.8 - 4.3% recovery.

Background
The delete function in most operating systems simply marks the space occupied by the file as reusable (removes the pointer to the file) without immediately removing any of its contents. At this point the file can be fairly easily recovered by numerous recovery applications. However, once the space is overwritten with other data, there is no known way to use software to recover it. It cannot be done with software alone since the storage device only returns its current contents via its normal interface.  Gutmann claims that intelligence agencies have sophisticated tools, including magnetic force microscopes, which together with image analysis, can detect the previous values of bits on the affected area of the media (for example hard disk). This claim however seems to be invalid based on following thesis - Data Reconstruction from a Hard Disk Drive using Magnetic Force Microscopy

Method
An overwrite session consists of a lead-in of four random write patterns, followed by patterns 5 to 31 (see rows of table below), executed in a random order, and a lead-out of four more random patterns.
Each of patterns 5 to 31 was designed with a specific magnetic media encoding scheme in mind, which each pattern targets. The drive is written to for all the passes even though the table below only shows the bit patterns for the passes that are specifically targeted at each encoding scheme. The end result should obscure any data on the drive so that only the most advanced physical scanning (e.g., using a magnetic force microscope) of the drive is likely to be able to recover any data.
The series of patterns is as follows:

Encoded bits shown in bold are what should be present in the ideal pattern, although due to the encoding the complementary bit is actually present at the start of the track.

Criticism
Daniel Feenberg of the National Bureau of Economic Research, an American private nonprofit research organization, criticized Gutmann's claim that intelligence agencies are likely to be able to read overwritten data, citing a lack of evidence for such claims. He finds that Gutmann cites one non-existent source and sources that do not actually demonstrate recovery, only partially-successful observations. The definition of ""random"" is also quite different from the usual one used: Gutmann expects the use of pseudorandom data with sequences known to the recovering side, not an unpredictable one such as a cryptographically secure pseudorandom number generator.Nevertheless, some published government security procedures consider a disk overwritten once to still be sensitive.Gutmann himself has responded to some of these criticisms and also criticized how his algorithm has been abused in an epilogue to his original paper, in which he states:
In the time since this paper was published, some people have treated the 35-pass overwrite technique described in it more as a kind of voodoo incantation to banish evil spirits than the result of a technical analysis of drive encoding techniques. As a result, they advocate applying the voodoo to PRML and EPRML drives even though it will have no more effect than a simple scrubbing with random data. In fact performing the full 35-pass overwrite is pointless for any drive since it targets a blend of scenarios involving all types of (normally-used) encoding technology, which covers everything back to 30+-year-old MFM methods (if you don't understand that statement, re-read the paper). If you're using a drive which uses encoding technology X, you only need to perform the passes specific to X, and you never need to perform all 35 passes. For any modern PRML/EPRML drive, a few passes of random scrubbing is the best you can do. As the paper says, ""A good scrubbing with random data will do about as well as can be expected"". This was true in 1996, and is still true now.

See also
Data remanence
Data recovery
Computer forensics

Notes
External links
Secure Deletion of Data from Magnetic and Solid-State Memory, Gutmann's original paper",1773852,https://en.wikipedia.org/wiki/Gutmann_method
HAKMEM,"HAKMEM, alternatively known as AI Memo 239, is a February 1972 ""memo"" (technical report) of the MIT AI Lab containing a wide variety of hacks, including useful and clever algorithms for mathematical computation, some number theory and schematic diagrams for hardware – in Guy L. Steele's words, ""a bizarre and eclectic potpourri of technical trivia"".
Contributors included about two dozen members and associates of the AI Lab. The title of the report is short for ""hacks memo"", abbreviated to six upper case characters that would fit in a single PDP-10 machine word (using a six-bit character set).","HAKMEM, alternatively known as AI Memo 239, is a February 1972 ""memo"" (technical report) of the MIT AI Lab containing a wide variety of hacks, including useful and clever algorithms for mathematical computation, some number theory and schematic diagrams for hardware – in Guy L. Steele's words, ""a bizarre and eclectic potpourri of technical trivia"".
Contributors included about two dozen members and associates of the AI Lab. The title of the report is short for ""hacks memo"", abbreviated to six upper case characters that would fit in a single PDP-10 machine word (using a six-bit character set).

History
HAKMEM is notable as an early compendium of algorithmic technique, particularly for its practical bent, and as an illustration of the wide-ranging interests of AI Lab people of the time, which included almost anything other than AI research.
HAKMEM contains original work in some fields, notably continued fractions.

Introduction
Compiled with the hope that a record of the random things people do around here can save some duplication of effort -- except for fun.Here is some little known data which may be of interest to computer hackers. The items and examples are so sketchy that to decipher them may require more sincerity and curiosity than a non-hacker can muster. Doubtless, little of this is new, but nowadays it's hard to tell. So we must be content to give you an insight, or save you some cycles, and to welcome further contributions of items, new or used.

See also
Hacker's Delight
AI Memo

References
External links
Schroeppel, Richard C.; Orman, Hilarie K. (1972-02-29), ""compilation"", HAKMEM, by Beeler, Michael; Gosper, Ralph William; Schroeppel, Richard C., Baker, Henry (ed.),  (report) (retyped & converted (April 1995) ed.), Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, Massachusetts, USA, MIT AI Memo 239, archived from the original on 2019-10-08, retrieved 2016-01-02
HAKMEM facsimile (PDF) (searchable version)",505526,https://en.wikipedia.org/wiki/HAKMEM
Hall circles,Hall circles (also known as M-circles and N-circles) are a graphical tool in control theory used to obtain values of a closed-loop transfer function from the Nyquist plot (or the Nichols plot) of the associated open-loop transfer function. Hall circles have been introduced in control theory by Albert C. Hall in his thesis.,"Hall circles (also known as M-circles and N-circles) are a graphical tool in control theory used to obtain values of a closed-loop transfer function from the Nyquist plot (or the Nichols plot) of the associated open-loop transfer function. Hall circles have been introduced in control theory by Albert C. Hall in his thesis.

Construction
Consider a closed-loop linear control system with open-loop transfer function given by transfer function G(s){\displaystyle G(s)} and with a unit gain in the feedback loop. The closed-loop transfer function is given by T(s)=G(s)1+G(s){\textstyle T(s)={\frac {G(s)}{1+G(s)}}}.
To check the stability of T(s), it is possible to use the Nyquist stability criterion with the Nyquist plot of the open-loop transfer function G(s). Note, however, that only the Nyquist plot of G(s) does not give the actual values of T(s). To get this information from the G(s)-plane, Hall proposed to construct the locus of points in the G(s)-plane such that T(s) has constant magnitude and the also the locus of points in the G(s)-plane such that T(s) has constant phase angle.
Given a positive real value M representing a fixed magnitude, and denoting G(s) by z, the points satisfying  are given by the points z in the G(s)-plane such that the ratio of the distance between z and 0 and the distance between z and -1 is equal to M. The points z satisfying this locus condition are circles of Apollonius, and this locus is known in the context of control systems as M-circles.
Given a positive real value N representing a phase angle, the points satisfying are given by the points z in the G(s)-plane such that the angle between -1 and z and the angle between 0 and z is constant. In other words, the angle opposed to the line segment between -1 and 0 must be constant. This implies that the points z satisfying this locus condition are arcs of circles, and this locus is known in the context of control systems as N-circles.

Usage
To use the Hall circles, a plot of M and N circles is done over the Nyquist plot of the open-loop transfer function. The points of the intersection between these graphics give the corresponding value of the closed-loop transfer function.
Hall circles are also used with the Nichols plot and in this setting, are also known as Nichols chart. Rather than overlaying directly the Hall circles over the Nichols plot, the points of the circles are transferred to a new coordinate system where the ordinate is given by 20log10⁡(|G(s)|){\displaystyle 20\log _{10}(|G(s)|)} and the abscissa is given by arg⁡(G(s)){\displaystyle \arg(G(s))}. The advantage of using Nichols chart is that adjusting the gain of the open loop transfer function directly reflects in up and down translation of the Nichols plot in the chart.

See also
Nyquist-plot
Nichols plot

Notes
References
Katsuhiko, Ogata (2002). Modern control engineering (4th ed.). Upper Saddle River, NJ: Prentice Hall. ISBN 0130609072. OCLC 46619221.
S., Nise, Norman (2008). Control systems engineering (5th ed.). Hoboken, NJ: Wiley. ISBN 9780471794752. OCLC 154798791.{{cite book}}:  CS1 maint: multiple names: authors list (link)",57506816,https://en.wikipedia.org/wiki/Hall_circles
Higuchi dimension,"In fractal geometry, the Higuchi dimension (or Higuchi fractal dimension (HFD)) is an approximate value for the box-counting dimension of the graph of a real-valued function or time series. This value is obtained via an algorithmic approximation so one also talks about the Higuchi method. It has many applications in science and engineering and has been applied to subjects like characterizing primary waves in seismograms, clinical neurophysiology and analyzing changes in the electroencephalogram in Alzheimer's disease.","In fractal geometry, the Higuchi dimension (or Higuchi fractal dimension (HFD)) is an approximate value for the box-counting dimension of the graph of a real-valued function or time series. This value is obtained via an algorithmic approximation so one also talks about the Higuchi method. It has many applications in science and engineering and has been applied to subjects like characterizing primary waves in seismograms, clinical neurophysiology and analyzing changes in the electroencephalogram in Alzheimer's disease.

Formulation of the method
The original formulation of the method is due to T. Higuchi. Given a time series X:{1,…,N}→R{\displaystyle X:\{1,\dots ,N\}\to \mathbb {R} } consisting of N{\displaystyle N} data points and a parameter kmax≥2{\displaystyle k_{\mathrm {max} }\geq 2} the Higuchi Fractal dimension (HFD) of X{\displaystyle X} is calculated in the following way: For each k∈{1,…,kmax}{\displaystyle k\in \{1,\dots ,k_{\mathrm {max} }}\} and m∈{1,…,k}{\displaystyle m\in \{1,\dots ,k}\} define the length Lm(k){\displaystyle L_{m}(k)} by

Lm(k)=N−1⌊N−mk⌋k2∑i=1⌊N−mk⌋|XN(m+ik)−XN(m+(i−1)k)|.{\displaystyle L_{m}(k)={\frac {N-1}{\lfloor {\frac {N-m}{k}}\rfloor k^{2}}}\sum _{i=1}^{\lfloor {\frac {N-m}{k}}\rfloor }|X_{N}(m+ik)-X_{N}(m+(i-1)k)|.}The length L(k){\displaystyle L(k)} is defined by the average value of the k{\displaystyle k} lengths L1(k),…,Lk(k){\displaystyle L_{1}(k),\dots ,L_{k}(k)},

L(k)=1k∑m=1kLm(k).{\displaystyle L(k)={\frac {1}{k}}\sum _{m=1}^{k}L_{m}(k).}The slope of the best-fitting linear function through the data points {(log⁡1k,log⁡L(k))}{\displaystyle \left\{\left(\log {\frac {1}{k}},\log L(k)\right)\right\}} is defined to be the Higuchi fractal dimension of the time-series X{\displaystyle X}.

Application to functions
For a real-valued function f:[0,1]→R{\displaystyle f:[0,1]\to \mathbb {R} } one can partition the unit interval [0,1]{\displaystyle [0,1]} into N{\displaystyle N} equidistantly intervals [tj,tj+1){\displaystyle [t_{j},t_{j+1})} and apply the Higuchi algorithm to the times series X(j)=f(tj){\displaystyle X(j)=f(t_{j})}. This results into the Higuchi fractal dimension of the function f{\displaystyle f}. It was shown that in this case the Higuchi method yields an approximation for the box-counting dimension of the graph of f{\displaystyle f} as it follows a geometrical approach (see Liehr & Massopust 2020).

Robustness and stability
Applications to fractional Brownian functions and the Weierstrass function reveal that the Higuchi fractal dimension can be close to the box-dimension. On the other hand, the method can be unstable in the case where the data X(1),…,X(N){\displaystyle X(1),\dots ,X(N)} are periodic or if subsets of it lie on a horizontal line (see Liehr & Massopust 2020).


== References ==",64202283,https://en.wikipedia.org/wiki/Higuchi_dimension
Hindley–Milner type system,"A Hindley–Milner (HM) type system is a classical type system for the lambda calculus with parametric polymorphism. It is also known as Damas–Milner or Damas–Hindley–Milner. It was first described by J. Roger Hindley and later rediscovered by Robin Milner. Luis Damas contributed a close formal analysis and proof of the method in his PhD thesis.Among HM's more notable properties are its completeness and its ability to infer the most general type of a given program without programmer-supplied type annotations or other hints. Algorithm W is an efficient type inference method in practice and has been successfully applied on large code bases, although it has a high theoretical complexity. HM is preferably used for functional languages. It was first implemented as part of the type system of the programming language ML. Since then, HM has been extended in various ways, most notably with type class constraints like those in Haskell.","A Hindley–Milner (HM) type system is a classical type system for the lambda calculus with parametric polymorphism. It is also known as Damas–Milner or Damas–Hindley–Milner. It was first described by J. Roger Hindley and later rediscovered by Robin Milner. Luis Damas contributed a close formal analysis and proof of the method in his PhD thesis.Among HM's more notable properties are its completeness and its ability to infer the most general type of a given program without programmer-supplied type annotations or other hints. Algorithm W is an efficient type inference method in practice and has been successfully applied on large code bases, although it has a high theoretical complexity. HM is preferably used for functional languages. It was first implemented as part of the type system of the programming language ML. Since then, HM has been extended in various ways, most notably with type class constraints like those in Haskell.

Introduction
As a type inference method, Hindley–Milner is able to deduce the types of variables, expressions and functions from programs written in an entirely untyped style. Being scope sensitive, it is not limited to deriving the types only from a small portion of source code, but rather from complete programs or modules. Being able to cope with parametric types, too, it is core to the type systems of many functional programming languages. It was first applied in this manner in the ML programming language.
The origin is the type inference algorithm for the simply typed lambda calculus that was devised by Haskell Curry and Robert Feys in 1958.
In 1969, J. Roger Hindley extended this work and proved that their algorithm always inferred the most general type.
In 1978, Robin Milner, independently of Hindley's work, provided an equivalent algorithm, Algorithm W.
In 1982, Luis Damas finally proved that Milner's algorithm is complete and extended it to support systems with polymorphic references.

Monomorphism vs. polymorphism
In the simply typed lambda calculus, types T are either atomic type constants or function types of form T→T{\displaystyle T\rightarrow T}.  Such types are monomorphic. Typical examples are the types used in arithmetic values:

 3       : Number
 add 3 4 : Number
 add     : Number -> Number -> Number

Contrary to this, the untyped lambda calculus is neutral to typing at all, and many of its functions can be meaningfully applied to all type of arguments. The trivial example is the identity function

id ≡ λ x . xwhich simply returns whatever value it is applied to. Less trivial examples include parametric types like lists.
While polymorphism in general means that operations accept values of more than one type, the polymorphism used here is parametric. One finds the notation of type schemes in the literature, too, emphasizing the parametric nature of the polymorphism. Additionally, constants may be typed with (quantified) type variables. E.g.:

 cons : forall a . a -> List a -> List a
 nil  : forall a . List a
 id   : forall a . a -> a

Polymorphic types can become monomorphic by consistent substitution of their variables. Examples of monomorphic instances are:

id'  : String -> String
nil' : List Number

More generally, types are polymorphic when they contain type variables, while types without them are monomorphic.
Contrary to the type systems used for example in Pascal (1970) or C (1972), which only support monomorphic types, HM is designed with emphasis on parametric polymorphism. The successors of the languages mentioned, like C++ (1985), focused on different types of polymorphism, namely subtyping in connection with object-oriented programming and overloading. While subtyping is incompatible with HM, a variant of systematic overloading is available in the HM-based type system of Haskell.

Let-polymorphism
When extending the type inference for the simply-typed lambda calculus towards polymorphism, one has to define when deriving an instance of a value is admissible. Ideally, this would be allowed with any use of a bound variable, as in:

 (λ id .  ... (id 3) ... (id ""text"") ... ) (λ x . x)

Unfortunately, type inference in polymorphic lambda calculus is not decidable. Instead, HM provides a let-polymorphism of the form

 let id = λ x . x
  in ... (id 3) ... (id ""text"") ...

restricting the binding mechanism in an extension of the expression syntax. Only values bound in a let construct are subject to instantiation, i.e. are polymorphic, while the parameters in lambda-abstractions are treated as being monomorphic.

Overview
The remainder of this article proceeds as follows:

The HM type system is defined. This is done by describing a deduction system that makes precise what expressions have what type, if any.
From there, it works towards an implementation of the type inference method. After introducing a syntax-driven variant of the above deductive system, it sketches an efficient implementation (algorithm J), appealing mostly to the reader's metalogical intuition.
Because it remains open whether algorithm J indeed realises the initial deduction system, a less efficient implementation (algorithm W), is introduced and its use in a proof is hinted.
Finally, further topics related to the algorithm are discussed.The same description of the deduction system is used throughout, even for the two algorithms, to make the various forms in which the HM method is presented directly comparable.

The Hindley–Milner type system
The type system can be formally described by syntax rules that fix a language for the expressions, types, etc. The presentation here of such a syntax is not too formal, in that it is written down not to study the surface grammar, but rather the depth grammar, and leaves some syntactical details open. This form of presentation is usual. Building on this, typing rules are used to define how expressions and types are related. As before, the form used is a bit liberal.

Syntax
The expressions to be typed are exactly those of the lambda calculus extended with a let-expression as shown in the adjacent table. Parentheses can be used to disambiguate an expression. The application is left-binding and binds stronger than abstraction or the let-in construct.
Types are syntactically split into two groups, monotypes and polytypes.

Monotypes
Monotypes always designate a particular type. Monotypes τ{\displaystyle \tau } are syntactically represented as terms.
Examples of monotypes include type constants like int{\displaystyle {\mathtt {int}}} or string{\displaystyle {\mathtt {string}}}, and parametric types like Map (Set string) int{\displaystyle {\mathtt {Map\ (Set\ string)\ int}}}.   The latter types are examples of applications of type functions, for example, from the set
{Map2, Set1, string0, int0, →2}{\displaystyle \{{\mathtt {Map^{2},\ Set^{1},\ string^{0},\ int^{0}}},\ \rightarrow ^{2}\}}, 
where the superscript indicates the number of type parameters.  The complete set of type functions C{\displaystyle C} is arbitrary in HM, except that it must contain at least →2{\displaystyle \rightarrow ^{2}}, the type of functions.  It is often written in infix notation for convenience.  For example, a function mapping integers to strings has type int→string{\displaystyle {\mathtt {int}}\rightarrow {\mathtt {string}}}. Again, parentheses can be used to disambiguate a type expression. The application binds stronger than the infix arrow, which is right-binding.
Type variables are admitted as monotypes. Monotypes are not to be confused with monomorphic types, which exclude variables and allow only ground terms.
Two monotypes are equal if they have identical terms.

Polytypes
Polytypes (or type schemes) are types containing variables bound by zero or more for-all quantifiers, e.g. ∀α.α→α{\displaystyle \forall \alpha .\alpha \rightarrow \alpha }.
A function with polytype ∀α.α→α{\displaystyle \forall \alpha .\alpha \rightarrow \alpha } can map any value of the same type to itself,
and the identity function is a value for this type.
As another example, ∀α.(Set α)→int{\displaystyle \forall \alpha .({\mathtt {Set}}\ \alpha )\rightarrow {\mathtt {int}}} is the type of a function mapping all finite sets to integers. A function which returns the cardinality of a set would be a value of this type.
Quantifiers can only appear top level. For instance, a type ∀α.α→∀α.α{\displaystyle \forall \alpha .\alpha \rightarrow \forall \alpha .\alpha } is excluded by the syntax of types. Also monotypes are included in the polytypes, thus a type has the general form ∀α1…∀αn.τ,n≥0{\displaystyle \forall \alpha _{1}\dots \forall \alpha _{n}.\tau ,n\geq 0}, where τ{\displaystyle \tau } is a monotype.
Equality of polytypes is up to reordering the quantification and renaming the quantified variables (α{\displaystyle \alpha }-conversion). Further, quantified variables not occurring in the monotype can be dropped.

Context and typing
To meaningfully bring together the still disjoint parts (syntax expressions and types) a third part is needed: context. Syntactically, a context is a list of pairs x:σ{\displaystyle x:\sigma }, called assignments, assumptions or bindings, each pair stating that value variable xi{\displaystyle x_{i}}has type σi.{\displaystyle \sigma _{i}.} All three parts combined give a typing judgment of the form Γ ⊢ e:σ{\displaystyle \Gamma \ \vdash \ e:\sigma }, stating that under assumptions Γ{\displaystyle \Gamma }, the expression e{\displaystyle e} has type σ{\displaystyle \sigma }.

Free type variables
In a type ∀α1…∀αn.τ{\displaystyle \forall \alpha _{1}\dots \forall \alpha _{n}.\tau }, the symbol ∀{\displaystyle \forall } is the quantifier binding the type variables αi{\displaystyle \alpha _{i}} in the monotype τ{\displaystyle \tau }. The variables αi{\displaystyle \alpha _{i}} are called quantified and any occurrence of a quantified type variable in τ{\displaystyle \tau } is called bound and all unbound type variables in τ{\displaystyle \tau } are called free. Additionally to the quantification ∀{\displaystyle \forall } in polytypes, type variables can also be bound by occurring in the context, but with the inverse effect on the right hand side of the ⊢{\displaystyle \vdash }. Such variables then behave like type constants there. Finally, a type variable may legally occur unbound in a typing, in which case they are implicitly all-quantified.
The presence of both bound and unbound type variables is a bit uncommon in programming languages. Often, all type variables are implicitly treated all-quantified. For instance, one does not have clauses with free variables in Prolog. Likewise in Haskell,  where all type variables implicitly occur quantified, i.e. a Haskell type a -> a means ∀α.α→α{\displaystyle \forall \alpha .\alpha \rightarrow \alpha } here. Related and also very uncommon is the binding effect of the right hand side σ{\displaystyle \sigma } of the assignments.
Typically, the mixture of both bound and unbound type variables originate from the use of free variables in an expression. The constant function K = λx.λy.x{\displaystyle \lambda x.\lambda y.x} provides an example. It has the monotype α→β→α{\displaystyle \alpha \rightarrow \beta \rightarrow \alpha }. One can force polymorphism by let k=λx.(let f=λy.x in f) in k{\displaystyle \mathbf {let} \ k=\lambda x.(\mathbf {let} \ f=\lambda y.x\ \mathbf {in} \ f)\ \mathbf {in} \ k}. Herein, f{\displaystyle f} has the type ∀γ.γ→α{\displaystyle \forall \gamma .\gamma \rightarrow \alpha }. The free monotype variable α{\displaystyle \alpha } originates from the type of the variable x{\displaystyle x} bound in the surrounding scope. k{\displaystyle k} has the type ∀α∀β.α→β→α{\displaystyle \forall \alpha \forall \beta .\alpha \rightarrow \beta \rightarrow \alpha }. One could imagine the free type variable α{\displaystyle \alpha } in the type of f{\displaystyle f} be bound by the ∀α{\displaystyle \forall \alpha } in the type of k{\displaystyle k}. But such a scoping cannot be expressed in HM. Rather, the binding is realized by the context.

Type order
Polymorphism means that one and the same expression can have (perhaps infinitely) many types. But in this type system, these types are not completely unrelated, but rather orchestrated by the parametric polymorphism.
As an example, the identity λx.x{\displaystyle \lambda x.x} can have ∀α.α→α{\displaystyle \forall \alpha .\alpha \rightarrow \alpha } as its type as well as
string→string{\displaystyle {\texttt {string}}\rightarrow {\texttt {string}}} or int→int{\displaystyle {\texttt {int}}\rightarrow {\texttt {int}}} and many others, but not int→string{\displaystyle {\texttt {int}}\rightarrow {\texttt {string}}}. The most general type for this function is
∀α.α→α{\displaystyle \forall \alpha .\alpha \rightarrow \alpha }, while the
others are more specific and can be derived from the general one by consistently
replacing another type for the type parameter, i.e. the quantified
variable α{\displaystyle \alpha }.  The counter-example fails because the
replacement is not consistent.
The consistent replacement can be made formal by applying a substitution S={ ai↦τi, … }{\displaystyle S=\left\{\ a_{i}\mapsto \tau _{i},\ \dots \ \right\}} to the term of a type τ{\displaystyle \tau }, written Sτ{\displaystyle S\tau }. As the example suggests, substitution is not only strongly related to an order, that expresses that a type is more or less special, but also with the all-quantification which allows the substitution to be applied.

Formally, in HM, a type σ′{\displaystyle \sigma '} is more general than σ{\displaystyle \sigma }, formally σ′⊑σ{\displaystyle \sigma '\sqsubseteq \sigma }, if some quantified variable in σ′{\displaystyle \sigma '} is consistently substituted such that one gains σ{\displaystyle \sigma } as shown in the side bar. This order is part of the type definition of the type system.
In our previous example, applying the substitution S={α↦string}{\displaystyle S=\left\{\alpha \mapsto {\texttt {string}}\right\}} would result in ∀α.α→α⊑string→string{\displaystyle \forall \alpha .\alpha \rightarrow \alpha \sqsubseteq {\texttt {string}}\rightarrow {\texttt {string}}}.
While substituting a monomorphic (ground) type for a quantified variable is
straight forward, substituting a polytype has some pitfalls caused by the
presence of free variables. Most particularly, unbound variables must not be
replaced. They are treated as constants here. Additionally, quantifications can only occur top-level. Substituting a parametric type,
one has to lift its quantifiers. The table on the right makes the rule precise.
Alternatively, consider an equivalent notation for the polytypes without
quantifiers in which quantified variables are represented by a different set of
symbols. In such a notation, the specialization reduces to plain consistent
replacement of such variables.
The relation ⊑{\displaystyle \sqsubseteq } is a partial order
and  ∀α.α{\displaystyle \forall \alpha .\alpha } is its smallest element.

Principal type
While specialization of a type scheme is one use of the order, it plays a
crucial second role in the type system. Type inference with polymorphism
faces the challenge of summarizing all possible types an expression may have.
The order guarantees that such a summary exists as the most general type
of the expression.

Substitution in typings
The type order defined above can be extended to typings because the implied all-quantification of typings enables consistent replacement:

Γ⊢e:σ⟹SΓ⊢e:Sσ{\displaystyle \Gamma \vdash e:\sigma \quad \Longrightarrow \quad S\Gamma \vdash e:S\sigma }Contrary to the specialisation rule, this is not part of the definition, but like the implicit all-quantification rather a consequence of the type rules defined next.
Free type variables in a typing serve as placeholders for possible refinement. The binding effect of the environment to free type
variables on the right hand side of ⊢{\displaystyle \vdash } that prohibits their substitution in the specialisation rule is again
that a replacement has to be consistent and would need to include the whole typing.
This article will discuss four different rule sets:

⊢D{\displaystyle \vdash _{D}} declarative system
⊢S{\displaystyle \vdash _{S}} syntactical system
⊢J{\displaystyle \vdash _{J}} algorithm J
⊢W{\displaystyle \vdash _{W}} algorithm W

Deductive system
The syntax of HM is carried forward to the syntax of the inference rules that form the body of the formal system, by using the typings as judgments. Each of the rules define what conclusion could be drawn from what premises. Additionally to the judgments, some extra conditions introduced above might be used as premises, too.
A proof using the rules is a sequence of judgments such that all premises are listed before a conclusion. The examples below show a possible format of proofs. From left to right, each line shows the conclusion, the [Name]{\displaystyle [{\mathtt {Name}}]} of the rule applied and the premises, either by referring to an earlier line (number) if the premise is a judgment or by making the predicate explicit.

Typing rules
See also Typing rulesThe side box shows the deduction rules of the HM type system. One can roughly divide the rules into two groups:
The first four rules [Var]{\displaystyle [{\mathtt {Var}}]} (variable or function access), [App]{\displaystyle [{\mathtt {App}}]} (application, i.e. function call with one parameter), [Abs]{\displaystyle [{\mathtt {Abs}}]} (abstraction, i.e. function declaration) and [Let]{\displaystyle [{\mathtt {Let}}]} (variable declaration) are centered around the syntax, presenting one rule for each of the expression forms. Their meaning is obvious at the first glance, as they decompose each expression, prove their sub-expressions and finally combine the individual types found in the premises to the type in the conclusion.
The second group is formed by the  remaining two rules [Inst]{\displaystyle [{\mathtt {Inst}}]} and [Gen]{\displaystyle [{\mathtt {Gen}}]}.
They handle specialization and generalization of types. While the rule [Inst]{\displaystyle [{\mathtt {Inst}}]} should be clear from the section on specialization above, [Gen]{\displaystyle [{\mathtt {Gen}}]} complements the former, working in the opposite direction. It allows generalization, i.e. to quantify monotype variables not bound in the context.
The following two examples exercise the rule system in action. Since both the expression and the type are given, they are a type-checking use of the rules.
Example: A proof for Γ⊢Did(n):int{\displaystyle \Gamma \vdash _{D}id(n):int} where Γ=id:∀α.α→α, n:int{\displaystyle \Gamma =id:\forall \alpha .\alpha \rightarrow \alpha ,\ n:int},
could be written

1:Γ⊢Did:∀α.α→α[Var](id:∀α.α→α∈Γ)2:Γ⊢Did:int→int[Inst](1), (∀α.α→α⊑int→int)3:Γ⊢Dn:int[Var](n:int∈Γ)4:Γ⊢Did(n):int[App](2), (3){\displaystyle {\begin{array}{llll}1:&\Gamma \vdash _{D}id:\forall \alpha .\alpha \rightarrow \alpha &[{\mathtt {Var}}]&(id:\forall \alpha .\alpha \rightarrow \alpha \in \Gamma )\\2:&\Gamma \vdash _{D}id:int\rightarrow int&[{\mathtt {Inst}}]&(1),\ (\forall \alpha .\alpha \rightarrow \alpha \sqsubseteq int\rightarrow int)\\3:&\Gamma \vdash _{D}n:int&[{\mathtt {Var}}]&(n:int\in \Gamma )\\4:&\Gamma \vdash _{D}id(n):int&[{\mathtt {App}}]&(2),\ (3)\\\end{array}}}Example: To demonstrate generalization,
⊢D letid=λx.x in id:∀α.α→α{\displaystyle \vdash _{D}\ {\textbf {let}}\,id=\lambda x.x\ {\textbf {in}}\ id\,:\,\forall \alpha .\alpha \rightarrow \alpha }
is shown below:

1:x:α⊢Dx:α[Var](x:α∈{x:α})2:⊢Dλx.x:α→α[Abs](1)3:⊢Dλx.x:∀α.α→α[Gen](2), (α∉free(ϵ))4:id:∀α.α→α⊢Did:∀α.α→α[Var](id:∀α.α→α∈{id:∀α.α→α})5:⊢Dletid=λx.x in id:∀α.α→α[Let](3), (4){\displaystyle {\begin{array}{llll}1:&x:\alpha \vdash _{D}x:\alpha &[{\mathtt {Var}}]&(x:\alpha \in \left\{x:\alpha \right\})\\2:&\vdash _{D}\lambda x.x:\alpha \rightarrow \alpha &[{\mathtt {Abs}}]&(1)\\3:&\vdash _{D}\lambda x.x:\forall \alpha .\alpha \rightarrow \alpha &[{\mathtt {Gen}}]&(2),\ (\alpha \not \in free(\epsilon ))\\4:&id:\forall \alpha .\alpha \rightarrow \alpha \vdash _{D}id:\forall \alpha .\alpha \rightarrow \alpha &[{\mathtt {Var}}]&(id:\forall \alpha .\alpha \rightarrow \alpha \in \left\{id:\forall \alpha .\alpha \rightarrow \alpha \right\})\\5:&\vdash _{D}{\textbf {let}}\,id=\lambda x.x\ {\textbf {in}}\ id\,:\,\forall \alpha .\alpha \rightarrow \alpha &[{\mathtt {Let}}]&(3),\ (4)\\\end{array}}}

Let-polymorphism
Not visible immediately, the rule set encodes a regulation under which circumstances a type might be generalized or not by a slightly varying use of mono- and polytypes in the rules [Abs]{\displaystyle [{\mathtt {Abs}}]} and [Let]{\displaystyle [{\mathtt {Let}}]}. Remember that σ{\displaystyle \sigma } and τ{\displaystyle \tau } denote poly- and monotypes respectively.
In rule [Abs]{\displaystyle [{\mathtt {Abs}}]}, the value variable of the parameter of the function λx.e{\displaystyle \lambda x.e} is added to the context with a monomorphic type through the premise Γ, x:τ⊢De:τ′{\displaystyle \Gamma ,\ x:\tau \vdash _{D}e:\tau '}, while in the rule  [Let]{\displaystyle [{\mathtt {Let}}]}, the variable enters the environment in polymorphic form Γ, x:σ⊢De1:τ{\displaystyle \Gamma ,\ x:\sigma \vdash _{D}e_{1}:\tau }. Though in both cases the presence of x{\displaystyle x} in the context prevents the use of the generalisation rule for any free variable in the assignment, this regulation forces the type of parameter x{\displaystyle x} in a λ{\displaystyle \lambda }-expression to remain monomorphic, while in a let-expression, the variable could be introduced polymorphic, making specializations possible.
As a consequence of this regulation, λf.(ftrue,f0){\displaystyle \lambda f.(f\,{\textrm {true}},f\,{\textrm {0}})} cannot be typed,
since the parameter f{\displaystyle f} is in a monomorphic position, while let f=λx.xin(ftrue,f0){\displaystyle {\textbf {let}}\ f=\lambda x.x\,{\textbf {in}}\,(f\,{\textrm {true}},f\,{\textrm {0}})} has type (bool,int){\displaystyle (bool,int)}, because f{\displaystyle f} has been introduced in a let-expression and is treated polymorphic therefore.

Generalization rule
The generalisation rule is also worth for closer look. Here, the all-quantification implicit in the premise Γ⊢De:σ{\displaystyle \Gamma \vdash _{D}e:\sigma } is simply moved to the right hand side of ⊢D{\displaystyle \vdash _{D}} in the conclusion, bound by an explicit universal quantifier. This is possible, since α{\displaystyle \alpha } does not occur free in the context. Again, while this makes the generalization rule plausible, it is not really a consequence. On the contrary, the generalization rule is part of the definition of HM's type system and the implicit all-quantification a consequence.

An inference algorithm
Now that the deduction system of HM is at hand, one could present an algorithm and validate it with respect to the rules.
Alternatively, it might be possible to derive it by taking a closer look on how the rules interact and proof are
formed. This is done in the remainder of this article focusing on the possible decisions one can make while proving a typing.

Degrees of freedom choosing the rules
Isolating the points in a proof, where no decision is possible at all,
the first group of rules centered around the syntax leaves no choice since
to each syntactical rule corresponds a unique typing rule, which determines
a part of the proof, while between the conclusion and the premises of these
fixed parts chains of [Inst]{\displaystyle [{\mathtt {Inst}}]} and [Gen]{\displaystyle [{\mathtt {Gen}}]}
could occur. Such a chain could also exist between the conclusion of the
proof and the rule for topmost expression. All proofs must have
the so sketched shape.
Because the only choice in a proof with respect of rule selection are the
[Inst]{\displaystyle [{\mathtt {Inst}}]} and [Gen]{\displaystyle [{\mathtt {Gen}}]} chains, the
form of the proof suggests the question whether it can be made more precise,
where these chains might not be needed. This is in fact possible and leads to a
variant of the rules system with no such rules.

Syntax-directed rule system
A contemporary treatment of HM uses a purely syntax-directed rule system due to
Clement
as an intermediate step. In this system, the specialization is located directly after the original [Var]{\displaystyle [{\mathtt {Var}}]} rule
and merged into it, while the generalization becomes part of the [Let]{\displaystyle [{\mathtt {Let}}]} rule. There the generalization is
also determined to always produce the most general type by introducing the function Γ¯(τ){\displaystyle {\bar {\Gamma }}(\tau )}, which quantifies
all monotype variables not bound in Γ{\displaystyle \Gamma }.
Formally, to validate that this new rule system ⊢S{\displaystyle \vdash _{S}} is equivalent to the original ⊢D{\displaystyle \vdash _{D}}, one has
to show that Γ⊢D e:σ⇔Γ⊢S e:σ{\displaystyle \Gamma \vdash _{D}\ e:\sigma \Leftrightarrow \Gamma \vdash _{S}\ e:\sigma }, which decomposes into two sub-proofs:

Γ⊢D e:σ⇐Γ⊢S e:σ{\displaystyle \Gamma \vdash _{D}\ e:\sigma \Leftarrow \Gamma \vdash _{S}\ e:\sigma } (Consistency)
Γ⊢D e:σ⇒Γ⊢S e:σ{\displaystyle \Gamma \vdash _{D}\ e:\sigma \Rightarrow \Gamma \vdash _{S}\ e:\sigma } (Completeness)While consistency can be seen by decomposing the rules [Let]{\displaystyle [{\mathtt {Let}}]} and [Var]{\displaystyle [{\mathtt {Var}}]}
of ⊢S{\displaystyle \vdash _{S}} into proofs in ⊢D{\displaystyle \vdash _{D}}, it is likely visible that ⊢S{\displaystyle \vdash _{S}} is incomplete, as
one cannot show λ x.x:∀α.α→α{\displaystyle \lambda \ x.x:\forall \alpha .\alpha \rightarrow \alpha } in ⊢S{\displaystyle \vdash _{S}}, for instance, but only
λ x.x:α→α{\displaystyle \lambda \ x.x:\alpha \rightarrow \alpha }.  An only slightly weaker version of completeness is provable
 though, namely

Γ⊢D e:σ⇒Γ⊢S e:τ∧Γ¯(τ)⊑σ{\displaystyle \Gamma \vdash _{D}\ e:\sigma \Rightarrow \Gamma \vdash _{S}\ e:\tau \wedge {\bar {\Gamma }}(\tau )\sqsubseteq \sigma }implying, one can derive the principal type for an expression in ⊢S{\displaystyle \vdash _{S}} allowing us to generalize the proof in the end.
Comparing ⊢D{\displaystyle \vdash _{D}} and ⊢S{\displaystyle \vdash _{S}}, now only monotypes appear in the judgments of all rules. Additionally, the shape of any possible proof with the deduction system is now identical to the shape of the expression (both seen as trees). Thus the expression fully determines the shape of the proof. In ⊢D{\displaystyle \vdash _{D}} the shape would likely be determined with respect to all rules except [Inst]{\displaystyle [{\mathtt {Inst}}]} and [Gen]{\displaystyle [{\mathtt {Gen}}]}, which allow building arbitrarily long branches (chains) between the other nodes.

Degrees of freedom instantiating the rules
Now that the shape of the proof is known, one is already close to formulating a type inference algorithm.
Because any proof for a given expression must have the same shape, one can assume the monotypes in the
proof's judgements to be undetermined and consider how to determine them.
Here, the substitution (specialisation) order comes into play. Although at the first glance one cannot determine the types locally, the hope is that it is possible to refine them with the help of the order while traversing the proof tree, additionally assuming, because the resulting algorithm is to become an inference method, that the type in any premise will be determined as the best possible. And in fact, one can, as looking at the rules of ⊢S{\displaystyle \vdash _{S}} suggests:

[Abs]: The critical choice is τ. At this point, nothing is known about τ, so one can only assume the most general type, which is ∀α.α{\displaystyle \forall \alpha .\alpha }. The plan is to specialize the type if it should become necessary. Unfortunately, a polytype is not permitted in this place, so some α has to do for the moment. To avoid unwanted captures, a type variable not yet in the proof is a safe choice. Additionally, one has to keep in mind that this monotype is not yet fixed, but might be further refined.
[Var]: The choice is how to refine σ. Because any choice of a type τ here depends on the usage of the variable, which is not locally known, the safest bet is the most general one. Using the same method as above one can instantiate all quantified variables in σ with fresh monotype variables, again keeping them open to further refinement.
[Let]: The rule does not leave any choice. Done.
[App]: Only the application rule might force a refinement to the variables ""opened"" so far, as required by both premises.
The first premise forces the outcome of the inference to be of the form τ→τ′{\displaystyle \tau \rightarrow \tau '}.
If it is, then fine. One can later pick its τ' for the result.
If not, it might be an open variable. Then this can be refined to the required form with two new variables as before.
Otherwise, the type checking fails because the first premise inferred a type which is not and cannot be made into a function type.
The second premise requires that the inferred type is equal to τ of the first premise. Now there are two possibly different types, perhaps with open type variables, at hand to compare and to make equal if it is possible. If it is, a refinement is found, and if not, a type error is detected again. An effective method is known to ""make two terms equal"" by substitution, Robinson's Unification in combination with the so-called Union-Find algorithm.To briefly summarize the union-find algorithm, given the set of all types in a proof, it allows one to group them together into equivalence classes by means of a union
procedure and to pick a representative for each such class using a find procedure. Emphasizing the word procedure in the sense of side effect, we're clearly leaving the realm of logic in order to prepare an effective algorithm. The representative of a union(a,b){\displaystyle {\mathtt {union}}(a,b)} is determined such that, if both a and b are type variables then the representative is arbitrarily one of them, but while uniting a variable and a term, the term becomes the representative. Assuming an implementation of union-find at hand, one can formulate the unification of two monotypes as follows:

unify(ta, tb):
    ta = find(ta)
    tb = find(tb)
    if both ta,tb are terms of the form D p1..pn with identical D,n then
        unify(ta[i], tb[i]) for each corresponding ith parameter
    else
    if at least one of ta,tb is a type variable then
        union(ta, tb)
    else
        error 'types do not match'

Now having a sketch of an inference algorithm at hand, a more formal presentation is given in the next section. It is described in Milner P. 370 ff. as algorithm J.

Algorithm J
The presentation of Algorithm J is a misuse of the notation of logical rules, since it includes side effects but allows a direct comparison with ⊢S{\displaystyle \vdash _{S}} while expressing an efficient implementation at the same time. The rules now specify a procedure with parameters Γ,e{\displaystyle \Gamma ,e} yielding τ{\displaystyle \tau } in the conclusion where the execution of the premises proceeds from left to right.
The procedure inst(σ){\displaystyle inst(\sigma )} specializes the polytype σ{\displaystyle \sigma } by copying the term and replacing the bound type variables consistently by new monotype variables. 'newvar{\displaystyle newvar}' produces a new monotype variable. Likely, Γ¯(τ){\displaystyle {\bar {\Gamma }}(\tau )} has to copy the type introducing new variables for the quantification to avoid unwanted captures. Overall, the algorithm now proceeds by always making the most general choice leaving the specialization to the unification, which by itself produces the most general result. As noted above, the final result τ{\displaystyle \tau } has to be generalized to Γ¯(τ){\displaystyle {\bar {\Gamma }}(\tau )} in the end, to gain the most general type for a given expression.
Because the procedures used in the algorithm have nearly O(1) cost, the overall cost of the algorithm is close to linear in the size of the expression for which a type is to be inferred. This is in strong contrast to many other attempts to derive type inference algorithms, which often came out to be NP-hard, if not undecidable with respect to termination. Thus the HM performs as well as the best fully informed type-checking algorithms can. Type-checking here means that an algorithm does not have to find a proof, but only to validate a given one.
Efficiency is slightly reduced because the binding of type variables in the context has to be maintained to allow computation of Γ¯(τ){\displaystyle {\bar {\Gamma }}(\tau )} and enable an occurs check to prevent the building of recursive types during union(α,τ){\displaystyle union(\alpha ,\tau )}.
An example of such a case is λ x.(x x){\displaystyle \lambda \ x.(x\ x)}, for which no type can be derived using HM.  Practically, types are only small terms and do not build up expanding structures.  Thus, in complexity analysis, one can treat comparing them as a constant, retaining O(1) costs.

Proving the algorithm
In the previous section, while sketching the algorithm its proof was hinted at with metalogical argumentation.  While this leads to an efficient algorithm J, it is not clear whether the algorithm properly reflects the deduction systems D or S which serve as a semantic base line.
The most critical point in the above argumentation is the refinement of monotype
variables bound by the context. For instance, the algorithm boldly changes the
context while inferring e.g. λf.(f 1){\displaystyle \lambda f.(f\ 1)},
because the monotype variable added to the context for the parameter f{\displaystyle f} later needs to be refined
to int→β{\displaystyle int\rightarrow \beta } when handling application.
The problem is that the deduction rules do not allow such a refinement.
Arguing that the refined type could have been added earlier instead of the
monotype variable is an expedient at best.
The key to reaching a formally satisfying argument is to properly include
the context within the refinement. Formally,
typing is compatible with substitution of free type variables.

Γ⊢Se:τ⟹SΓ⊢Se:Sτ{\displaystyle \Gamma \vdash _{S}e:\tau \quad \Longrightarrow \quad S\Gamma \vdash _{S}e:S\tau }To refine the free variables thus means to refine the whole typing.

Algorithm W
From there, a proof of algorithm J leads to algorithm W, which only makes the
side effects imposed by the procedure union{\displaystyle {\textit {union}}} explicit by
expressing its serial composition by means of the substitutions
Si{\displaystyle S_{i}}. The presentation of algorithm W in the sidebar still makes use of side effects
in the operations set in italic, but these are now limited to generating
fresh symbols. The form of judgement is Γ⊢e:τ,S{\displaystyle \Gamma \vdash e:\tau ,S},
denoting a function with a context and expression as parameter producing a monotype together with
a substitution. mgu{\displaystyle {\textsf {mgu}}} is a side-effect free version
of union{\displaystyle {\textit {union}}} producing a substitution which is the most general unifier.
While algorithm W is normally considered to be the HM algorithm and is
often directly presented after the rule system in literature, its purpose is
described by Milner on P. 369 as follows:

As it stands, W is hardly an efficient algorithm; substitutions are applied too often. It was formulated to aid the proof of soundness. We now present a simpler algorithm J which simulates W in a precise sense.While he considered W more complicated and less efficient, he presented it 
in his publication before J. It has its merits when side effects are unavailable or unwanted.
W is also needed to prove completeness, which is factored by him into the soundness proof.

Proof obligations
Before formulating the proof obligations, a deviation between the rules systems D and S and the algorithms presented needs to be emphasized.
While the development above sort of misused the monotypes as ""open"" proof variables, the possibility that proper monotype variables might be harmed was sidestepped by introducing fresh variables and hoping for the best. But there's a catch: One of the promises made was that these fresh variables would be ""kept in mind"" as such. This promise is not fulfilled by the algorithm.
Having a context 1:int, f:α{\displaystyle 1:int,\ f:\alpha }, the expression f 1{\displaystyle f\ 1}
cannot be typed in either ⊢D{\displaystyle \vdash _{D}} or ⊢S{\displaystyle \vdash _{S}}, but the algorithms come up with
the type β{\displaystyle \beta }, where W additionally delivers the substitution {α↦int→β}{\displaystyle \left\{\alpha \mapsto int\rightarrow \beta \right\}},
meaning that the algorithm fails to detect all type errors. This omission can easily be fixed by more carefully distinguishing proof
variables and monotype variables.
The authors were well aware of the problem but decided not to fix it. One might assume a pragmatic reason behind this.
While more properly implementing the type inference would have enabled the algorithm to deal with abstract monotypes,
they were not needed for the intended application where none of the items in a preexisting context have free
variables. In this light, the unneeded complication was dropped in favor of a simpler algorithm.
The remaining downside is that the proof of the algorithm with respect to the rule system is less general and can only be made
for contexts with free(Γ)=∅{\displaystyle free(\Gamma )=\emptyset } as a side condition.
(Correctness)Γ⊢We:τ,S⟹Γ⊢Se:τ(Completeness)Γ⊢Se:τ⟹Γ⊢We:τ′,Sforall τ where ∅¯(τ′)⊑τ{\displaystyle {\begin{array}{lll}{\text{(Correctness)}}&\Gamma \vdash _{W}e:\tau ,S&\quad \Longrightarrow \quad \Gamma \vdash _{S}e:\tau \\{\text{(Completeness)}}&\Gamma \vdash _{S}e:\tau &\quad \Longrightarrow \quad \Gamma \vdash _{W}e:\tau ',S\quad \quad {\text{forall}}\ \tau \ {\text{where}}\ {\overline {\emptyset }}(\tau ')\sqsubseteq \tau \end{array}}}
The side condition in the completeness obligation addresses how the deduction may give many types, while the algorithm always produces one. At the same time, the side condition demands that the type inferred is actually the most general.
To properly prove the obligations one needs to strengthen them first to allow activating the substitution lemma threading the substitution S{\displaystyle S} through ⊢S{\displaystyle \vdash _{S}} and ⊢W{\displaystyle \vdash _{W}}. From there, the proofs are by induction over the expression.
Another proof obligation is the substitution lemma itself, i.e. the substitution of the typing, which finally establishes the all-quantification. The later cannot formally be proven, since no such syntax is at hand.

Extensions
Recursive definitions
To make programming practical recursive functions are needed.
A central property of the lambda calculus is that recursive definitions
are not directly available, but can instead be expressed with a fixed point combinator.
But unfortunately, the fixpoint combinator cannot be formulated in a typed version
of the lambda calculus without having a disastrous effect on the system as outlined
below.

Typing rule
The original paper shows recursion can be realized by a combinator
fix:∀α.(α→α)→α{\displaystyle {\mathit {fix}}:\forall \alpha .(\alpha \rightarrow \alpha )\rightarrow \alpha }. A possible recursive definition could thus be formulated as
rec v=e1 in e2 ::=let v=fix(λv.e1) in e2{\displaystyle {\mathtt {rec}}\ v=e_{1}\ {\mathtt {in}}\ e_{2}\ ::={\mathtt {let}}\ v={\mathit {fix}}(\lambda v.e_{1})\ {\mathtt {in}}\ e_{2}}.
Alternatively an extension of the expression syntax and an extra typing rule is possible:

Γ,Γ′⊢e1:τ1…Γ,Γ′⊢en:τnΓ,Γ″⊢e:τΓ ⊢ rec v1=e1 and … and vn=en in e:τ[Rec]{\displaystyle \displaystyle {\frac {\Gamma ,\Gamma '\vdash e_{1}:\tau _{1}\quad \dots \quad \Gamma ,\Gamma '\vdash e_{n}:\tau _{n}\quad \Gamma ,\Gamma ''\vdash e:\tau }{\Gamma \ \vdash \ {\mathtt {rec}}\ v_{1}=e_{1}\ {\mathtt {and}}\ \dots \ {\mathtt {and}}\ v_{n}=e_{n}\ {\mathtt {in}}\ e:\tau }}\quad [{\mathtt {Rec}}]}where

Γ′=v1:τ1, …, vn:τn{\displaystyle \Gamma '=v_{1}:\tau _{1},\ \dots ,\ v_{n}:\tau _{n}}
Γ″=v1:Γ¯( τ1 ), …, vn:Γ¯( τn ){\displaystyle \Gamma ''=v_{1}:{\bar {\Gamma }}(\ \tau _{1}\ ),\ \dots ,\ v_{n}:{\bar {\Gamma }}(\ \tau _{n}\ )}basically merging [Abs]{\displaystyle [{\mathtt {Abs}}]} and [Let]{\displaystyle [{\mathtt {Let}}]} while including the recursively defined
variables in monotype positions where they occur to the left of the in{\displaystyle {\mathtt {in}}} but as polytypes to the right of it.

Consequences
While the above is straightforward it does come at a price.
Type theory connects lambda calculus with computation and logic.
The easy modification above has effects on both:

The strong normalisation property is invalidated, because non-terminating terms can be formulated.
The logic collapses because the type ∀a.a{\displaystyle \forall a.a} becomes inhabited.

Overloading
Overloading means that different functions can be defined and used with the same name. Most programming languages at least provide overloading with the built-in arithmetic operations (+,<,etc.), to allow the programmer to write arithmetic expressions in the same form, even for different numerical types like int or real. Because a mixture of these different types within the same expression also demands for implicit conversion, overloading especially for these operations is often built into the programming language itself. In some languages, this feature is generalized and made available to the user, e.g. in C++.
While ad hoc overloading has been avoided in functional programming for the computation costs both in type checking and inference, a means to systematise overloading has been introduced that resembles both in form and naming to object oriented programming, but works one level upwards. ""Instances"" in this systematic are not objects (i.e. on value level), but rather types.
The quicksort example mentioned in the introduction uses the overloading in the orders, having the following type annotation in Haskell:

Herein, the type a is not only polymorphic, but also restricted to be an instance of some type class Ord, that provides the order predicates < and >= used in the functions body. The proper implementations of these predicates are then passed to quicksorts as additional parameters, as soon as quicksort is used on more concrete types providing a single implementation of the overloaded function quickSort.
Because the ""classes"" only allow a single type as their argument, the resulting type system can still provide inference. Additionally, the type classes can then be equipped with some kind of overloading order allowing one to arrange the classes as a lattice.

Higher-order types
Parametric polymorphism implies that types themselves are passed as parameters as if they were proper values. Passed as arguments to a proper functions, but also into ""type functions"" as in the ""parametric"" type constants, leads to the question how to more properly type types themselves. Higher-order types are used to create an even more expressive type system.
Unfortunately, unification is no longer decidable in the presence of meta types, rendering type inference impossible in this extend of generality. Additionally, assuming a type of all types that includes itself as type leads into a paradox, as in the set of all sets, so one must proceed in steps of levels of abstraction.
Research in second order lambda calculus, one step upwards, showed that type inference is undecidable in this generality.
Haskell introduces one higher level named kind. In standard Haskell, kinds are inferred and used for little more than to describe the arity of type constructors. e.g. a list type constructor is thought of as mapping a type (the type of its elements) to another type (the type of the list containing said elements); notationally this is expressed as ∗→∗{\displaystyle *\to *}. Language extensions are available which extend kinds to emulate features of a dependent type system.

Subtyping
Attempts to combine subtyping and type inference have caused quite some frustration.
It is straightforward to accumulate and propagate subtyping constraints (as opposed to type equality constraints), making the resulting constraints part of the inferred typing schemes,
for example ∀α. (α≤T)⇒α→α{\displaystyle \forall \alpha .\ (\alpha \leq T)\Rightarrow \alpha \rightarrow \alpha }, where α≤T{\displaystyle \alpha \leq T} is a constraint on the type variable α{\displaystyle \alpha }.
However, because type variables are no longer unified eagerly in this approach, it tends to generate large and unwieldy typing schemes containing many useless type variables and constraints, making them hard to read and understand.
Therefore, considerable effort was put into simplifying such typing schemes and their constraints,
using techniques similar to those of nondeterministic finite automaton (NFA) simplification (useful in the presence of inferred recursive types).
More recently, Dolan and Mycroft
formalized the relationship between typing scheme simplification and NFA simplification
and showed that an algebraic take on the formalization of subtyping allowed generating compact principal typing schemes for an ML-like language (called MLsub).
Notably, their proposed typing scheme used a restricted form of union and intersection types instead of explicit constraints.
Parreaux later claimed
that this algebraic formulation was equivalent to a relatively simple algorithm resembling Algorithm W,
and that the use of union and intersection types was not essential.
On the other hand, type inference has proven more difficult in the context of object-oriented programming languages,
because object methods tend to require first-class polymorphism in the style of System F (where type inference is undecidable)
and because of features like F-bounded polymorphism.
Consequently, type systems with subtyping enabling object-oriented programming, such as Cardelli's system F<:{\displaystyle F_{<:}}, do not support HM-style type inference.
Row polymorphism can be used as an alternative to subtyping for supporting language features like structural records.
While this style of polymorphism is less flexible than subtyping in some ways, notably requiring more polymorphism than strictly necessary to cope with the lack of directionality in type constraints,
it has the advantage that it can be integrated with the standard HM algorithms quite easily.

Notes
References
External links
A literate Haskell implementation of Algorithm W along with its source code on GitHub.
A simple implementation of Hindley-Milner algorithm in Python.",32612385,https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system
Holographic algorithm,"In computer science, a holographic algorithm is an algorithm that uses a holographic reduction. A holographic reduction is a constant-time reduction that maps solution fragments many-to-many such that the sum of the solution fragments remains unchanged. These concepts were introduced by Leslie Valiant, who called them holographic because ""their effect can be viewed as that of producing interference patterns among the solution fragments"". The algorithms are unrelated to laser holography, except metaphorically. Their power comes from the mutual cancellation of many contributions to a sum, analogous to the interference patterns in a hologram.Holographic algorithms have been used to find polynomial-time solutions to problems without such previously known solutions for special cases of satisfiability, vertex cover, and other graph problems. They have received notable coverage due to speculation that they are relevant to the P versus NP problem and their impact on computational complexity theory.  Although some of the general problems are #P-hard problems, the special cases solved are not themselves #P-hard, and thus do not prove FP = #P.
Holographic algorithms have some similarities with quantum computation, but are completely classical.","In computer science, a holographic algorithm is an algorithm that uses a holographic reduction. A holographic reduction is a constant-time reduction that maps solution fragments many-to-many such that the sum of the solution fragments remains unchanged. These concepts were introduced by Leslie Valiant, who called them holographic because ""their effect can be viewed as that of producing interference patterns among the solution fragments"". The algorithms are unrelated to laser holography, except metaphorically. Their power comes from the mutual cancellation of many contributions to a sum, analogous to the interference patterns in a hologram.Holographic algorithms have been used to find polynomial-time solutions to problems without such previously known solutions for special cases of satisfiability, vertex cover, and other graph problems. They have received notable coverage due to speculation that they are relevant to the P versus NP problem and their impact on computational complexity theory.  Although some of the general problems are #P-hard problems, the special cases solved are not themselves #P-hard, and thus do not prove FP = #P.
Holographic algorithms have some similarities with quantum computation, but are completely classical.

Holant problems
Holographic algorithms exist in the context of Holant problems, which generalize counting constraint satisfaction problems (#CSP). A #CSP instance is a hypergraph G=(V,E) called the constraint graph. Each hyperedge represents a variable and each vertex v{\displaystyle v} is assigned a constraint fv.{\displaystyle f_{v}.} A vertex is connected to an hyperedge if the constraint on the vertex involves the variable on the hyperedge. The counting problem is to compute

∑σ:E→{0,1}∏v∈Vfv(σ|E(v)),          (1){\displaystyle \sum _{\sigma :E\to \{0,1\}}\prod _{v\in V}f_{v}(\sigma |_{E(v)}),~~~~~~~~~~(1)}which is a sum over all variable assignments, the product of every constraint, where the inputs to the constrain fv{\displaystyle f_{v}} are the variables on the incident hyperedges of v{\displaystyle v}.
A Holant problem is like a #CSP except the input must be a graph, not a hypergraph. Restricting the class of input graphs in this way is indeed a generalization. Given a #CSP instance, replace each hyperedge e of size s with a vertex v of degree s with edges incident to the vertices contained in e. The constraint on v is the equality function of arity s.  This identifies all of the variables on the edges incident to v, which is the same effect as the single variable on the hyperedge e.
In the context of Holant problems, the expression in (1) is called the Holant after a related exponential sum introduced by Valiant.

Holographic reduction
A standard technique in complexity theory is a many-one reduction, where an instance of one problem is reduced to an instance of another (hopefully simpler) problem.
However, holographic reductions between two computational problems preserve the sum of solutions without necessarily preserving correspondences between solutions.  For instance, the total number of solutions in both sets can be preserved, even though individual problems do not have matching solutions. The sum can also be weighted, rather than simply counting the number of solutions, using linear basis vectors.

General example
It is convenient to consider holographic reductions on bipartite graphs. A general graph can always be transformed it into a bipartite graph while preserving the Holant value. This is done by replacing each edge in the graph by a path of length 2, which is also known as the 2-stretch of the graph. To keep the same Holant value, each new vertex is assigned the binary equality constraint.
Consider a bipartite graph G=(U,V,E) where the constraint assigned to every vertex u∈U{\displaystyle u\in U} is fu{\displaystyle f_{u}} and the constraint assigned to every vertex v∈V{\displaystyle v\in V} is fv{\displaystyle f_{v}}. Denote this counting problem by Holant(G,fu,fv).{\displaystyle {\text{Holant}}(G,f_{u},f_{v}).} If the vertices in U are viewed as one large vertex of degree |E|, then the constraint of this vertex is the tensor product of fu{\displaystyle f_{u}} with itself |U| times, which is denoted by fu⊗|U|.{\displaystyle f_{u}^{\otimes |U|}.} Likewise, if the vertices in V are viewed as one large vertex of degree |E|, then the constraint of this vertex is fv⊗|V|.{\displaystyle f_{v}^{\otimes |V|}.} Let the constraint fu{\displaystyle f_{u}} be represented by its weighted truth table as a row vector and the constraint fv{\displaystyle f_{v}} be represented by its weighted truth table as a column vector. Then the Holant of this constraint graph is simply fu⊗|U|fv⊗|V|.{\displaystyle f_{u}^{\otimes |U|}f_{v}^{\otimes |V|}.}
Now for any complex 2-by-2 invertible matrix T (the columns of which are the linear basis vectors mentioned above), there is a holographic reduction between Holant(G,fu,fv){\displaystyle {\text{Holant}}(G,f_{u},f_{v})} and Holant(G,fuT⊗(deg⁡u),(T−1)⊗(deg⁡v)fv).{\displaystyle {\text{Holant}}(G,f_{u}T^{\otimes (\deg u)},(T^{-1})^{\otimes (\deg v)}f_{v}).} To see this, insert the identity matrix T⊗|E|(T−1)⊗|E|{\displaystyle T^{\otimes |E|}(T^{-1})^{\otimes |E|}} in between fu⊗|U|fv⊗|V|{\displaystyle f_{u}^{\otimes |U|}f_{v}^{\otimes |V|}} to get

fu⊗|U|fv⊗|V|{\displaystyle f_{u}^{\otimes |U|}f_{v}^{\otimes |V|}}
=fu⊗|U|T⊗|E|(T−1)⊗|E|fv⊗|V|{\displaystyle =f_{u}^{\otimes |U|}T^{\otimes |E|}(T^{-1})^{\otimes |E|}f_{v}^{\otimes |V|}}
=(fuT⊗(deg⁡u))⊗|U|(fv(T−1)⊗(deg⁡v))⊗|V|.{\displaystyle =\left(f_{u}T^{\otimes (\deg u)}\right)^{\otimes |U|}\left(f_{v}(T^{-1})^{\otimes (\deg v)}\right)^{\otimes |V|}.}Thus, Holant(G,fu,fv){\displaystyle {\text{Holant}}(G,f_{u},f_{v})} and Holant(G,fuT⊗(deg⁡u),(T−1)⊗(deg⁡v)fv){\displaystyle {\text{Holant}}(G,f_{u}T^{\otimes (\deg u)},(T^{-1})^{\otimes (\deg v)}f_{v})} have exactly the same Holant value for every constraint graph. They essentially define the same counting problem.

Specific examples
Vertex covers and independent sets
Let G be a graph. There is a 1-to-1 correspondence between the vertex covers of G and the independent sets of G. For any set S of vertices of G, S is a vertex cover in G if and only if the complement of S is an independent set in G. Thus, the number of vertex covers in G is exactly the same as the number of independent sets in G.
The equivalence of these two counting problems can also be proved using a holographic reduction. For simplicity, let G be a 3-regular graph. The 2-stretch of G gives a bipartite graph H=(U,V,E), where U corresponds to the edges in G and V corresponds to the vertices in G. The Holant problem that naturally corresponds to counting the number of vertex covers in G is Holant(H,OR2,EQUAL3).{\displaystyle {\text{Holant}}(H,{\text{OR}}_{2},{\text{EQUAL}}_{3}).} The truth table of OR2 as a row vector is (0,1,1,1). The truth table of EQUAL3 as a column vector is (1,0,0,0,0,0,0,1)T=[10]⊗3+[01]⊗3{\displaystyle (1,0,0,0,0,0,0,1)^{T}={\begin{bmatrix}1\\0\end{bmatrix}}^{\otimes 3}+{\begin{bmatrix}0\\1\end{bmatrix}}^{\otimes 3}}. Then under a holographic transformation by [0110],{\displaystyle {\begin{bmatrix}0&1\\1&0\end{bmatrix}},}

OR2⊗|U|EQUAL3⊗|V|{\displaystyle {\text{OR}}_{2}^{\otimes |U|}{\text{EQUAL}}_{3}^{\otimes |V|}}
=(0,1,1,1)⊗|U|([10]⊗3+[01]⊗3)⊗|V|{\displaystyle =(0,1,1,1)^{\otimes |U|}\left({\begin{bmatrix}1\\0\end{bmatrix}}^{\otimes 3}+{\begin{bmatrix}0\\1\end{bmatrix}}^{\otimes 3}\right)^{\otimes |V|}}
=(0,1,1,1)⊗|U|[0110]⊗|E|[0110]⊗|E|([10]⊗3+[01]⊗3)⊗|V|{\displaystyle =(0,1,1,1)^{\otimes |U|}{\begin{bmatrix}0&1\\1&0\end{bmatrix}}^{\otimes |E|}{\begin{bmatrix}0&1\\1&0\end{bmatrix}}^{\otimes |E|}\left({\begin{bmatrix}1\\0\end{bmatrix}}^{\otimes 3}+{\begin{bmatrix}0\\1\end{bmatrix}}^{\otimes 3}\right)^{\otimes |V|}}
=((0,1,1,1)[0110]⊗2)⊗|U|(([0110][10])⊗3+([0110][01])⊗3)⊗|V|{\displaystyle =\left((0,1,1,1){\begin{bmatrix}0&1\\1&0\end{bmatrix}}^{\otimes 2}\right)^{\otimes |U|}\left(\left({\begin{bmatrix}0&1\\1&0\end{bmatrix}}{\begin{bmatrix}1\\0\end{bmatrix}}\right)^{\otimes 3}+\left({\begin{bmatrix}0&1\\1&0\end{bmatrix}}{\begin{bmatrix}0\\1\end{bmatrix}}\right)^{\otimes 3}\right)^{\otimes |V|}}
=(1,1,1,0)⊗|U|([01]⊗3+[10]⊗3)⊗|V|{\displaystyle =(1,1,1,0)^{\otimes |U|}\left({\begin{bmatrix}0\\1\end{bmatrix}}^{\otimes 3}+{\begin{bmatrix}1\\0\end{bmatrix}}^{\otimes 3}\right)^{\otimes |V|}}
=NAND2⊗|U|EQUAL3⊗|V|,{\displaystyle ={\text{NAND}}_{2}^{\otimes |U|}{\text{EQUAL}}_{3}^{\otimes |V|},}which is Holant(H,NAND2,EQUAL3),{\displaystyle {\text{Holant}}(H,{\text{NAND}}_{2},{\text{EQUAL}}_{3}),} the Holant problem that naturally corresponds to counting the number of independent sets in G.

History
As with any type of reduction, a holographic reduction does not, by itself, yield a polynomial time algorithm. In order to get a polynomial time algorithm, the problem being reduced to must also have a polynomial time algorithm. Valiant's original application of holographic algorithms used a holographic reduction to a problem where every constraint is realizable by matchgates, which he had just proved is tractable by a further reduction to counting the number of perfect matchings in a planar graph. The latter problem is tractable by the FKT algorithm, which dates to the 1960s.
Soon after, Valiant found holographic algorithms with reductions to matchgates for #7Pl-Rtw-Mon-3CNF and #7Pl-3/2Bip-VC. These problems may appear somewhat contrived, especially with respect to the modulus. Both problems were already known to be #P-hard when ignoring the modulus and Valiant supplied proofs of #P-hardness modulo 2, which also used holographic reductions. Valiant found these two problems by a computer search that looked for problems with holographic reductions to matchgates. He called their algorithms accidental algorithms, saying ""when applying the term accidental to an algorithm we intend to point out that the algorithm arises from satisfying an apparently onerous set of constraints."" The ""onerous"" set of constraints in question are polynomial equations that, if satisfied, imply the existence of a holographic reduction to matchgate realizable constraints.
After several years of developing (what is known as) matchgate signature theory, Jin-Yi Cai and Pinyan Lu were able to explain the existence of Valiant's two accidental algorithms.  These two problems are just special cases of two much larger families of problems: #2k-1Pl-Rtw-Mon-kCNF and #2k-1Pl-k/2Bip-VC for any positive integer k. The modulus 7 is just the third Mersenne number and Cai and Lu showed that these types of problems with parameter k can be solved in polynomial time exactly when the modulus is the kth Mersenne number by using holographic reductions to matchgates and the Chinese remainder theorem.
Around the same time, Jin-Yi Cai, Pinyan Lu and Mingji Xia gave the first holographic algorithm that did not reduce to a problem that is tractable by matchgates. Instead, they reduced to a problem that is tractable by Fibonacci gates, which are symmetric constraints whose truth tables satisfy a recurrence relation similar to one that defines the Fibonacci numbers. They also used holographic reductions to prove that certain counting problems are #P-hard. Since then, holographic reductions have been used extensively as ingredients in both polynomial time algorithms and proofs of #P-hardness.


== References ==",14609233,https://en.wikipedia.org/wiki/Holographic_algorithm
How to Solve it by Computer,"How to Solve it by Computer is a computer science book by R. G. Dromey, first published by Prentice-Hall in 1982.
It is occasionally used as a textbook, especially in India.It is an introduction to the whys of algorithms and data structures.
Features of the book:

The design factors associated with problems
The creative process behind coming up with innovative solutions for algorithms and data structures
The line of reasoning behind the constraints, factors and the design choices made.The very fundamental algorithms portrayed by this book are mostly presented in pseudocode and/or Pascal notation.","How to Solve it by Computer is a computer science book by R. G. Dromey, first published by Prentice-Hall in 1982.
It is occasionally used as a textbook, especially in India.It is an introduction to the whys of algorithms and data structures.
Features of the book:

The design factors associated with problems
The creative process behind coming up with innovative solutions for algorithms and data structures
The line of reasoning behind the constraints, factors and the design choices made.The very fundamental algorithms portrayed by this book are mostly presented in pseudocode and/or Pascal notation.

See also
How to Solve It, by George Pólya, the author's mentor and inspiration for writing the book.


== References ==",4104986,https://en.wikipedia.org/wiki/How_to_Solve_it_by_Computer
Hybrid algorithm,"A hybrid algorithm is an algorithm that combines two or more other algorithms that solve the same problem, either choosing one based on some characteristic of the data, or switching between them over the course of the algorithm. This is generally done to combine desired features of each, so that the overall algorithm is better than the individual components.
""Hybrid algorithm"" does not refer to simply combining multiple algorithms to solve a different problem – many algorithms can be considered as combinations of simpler pieces – but only to combining algorithms that solve the same problem, but differ in other characteristics, notably performance.","A hybrid algorithm is an algorithm that combines two or more other algorithms that solve the same problem, either choosing one based on some characteristic of the data, or switching between them over the course of the algorithm. This is generally done to combine desired features of each, so that the overall algorithm is better than the individual components.
""Hybrid algorithm"" does not refer to simply combining multiple algorithms to solve a different problem – many algorithms can be considered as combinations of simpler pieces – but only to combining algorithms that solve the same problem, but differ in other characteristics, notably performance.

Examples
In computer science, hybrid algorithms are very common in optimized real-world implementations of recursive algorithms, particularly implementations of 
divide-and-conquer or decrease-and-conquer algorithms, where the size of the data decreases as one moves deeper in the recursion. In this case, one algorithm is used for the overall approach (on large data), but deep in the recursion, it switches to a different algorithm, which is more efficient on small data. A common example is in sorting algorithms, where the insertion sort, which is inefficient on large data, but very efficient on small data (say, five to ten elements), is used as the final step, after primarily applying another algorithm, such as merge sort or quicksort. Merge sort and quicksort are asymptotically optimal on large data, but the overhead becomes significant if applying them to small data, hence the use of a different algorithm at the end of the recursion. A highly optimized hybrid sorting algorithm is Timsort, which combines merge sort, insertion sort, together with additional logic (including binary search) in the merging logic.
A general procedure for a simple hybrid recursive algorithm is short-circuiting the base case, also known as arm's-length recursion. In this case whether the next step will result in the base case is checked before the function call, avoiding an unnecessary function call. For example, in a tree, rather than recursing to a child node and then checking if it is null, checking null before recursing. This is useful for efficiency when the algorithm usually encounters the base case many times, as in many tree algorithms, but is otherwise considered poor style, particularly in academia, due to the added complexity.
Another example of hybrid algorithms for performance reasons are introsort and introselect, which combine one algorithm for fast average performance, falling back on another algorithm to ensure (asymptotically) optimal worst-case performance. Introsort begins with a quicksort, but switches to a heap sort if quicksort is not progressing well; analogously introselect begins with quickselect, but switches to median of medians if quickselect is not progressing well.
Centralized distributed algorithms can often be considered as hybrid algorithms, consisting of an individual algorithm (run on each distributed processor), and a combining algorithm (run on a centralized distributor) – these correspond respectively to running the entire algorithm on one processor, or running the entire computation on the distributor, combining trivial results (a one-element data set from each processor). A basic example of these algorithms are distribution sorts, particularly used for external sorting, which divide the data into separate subsets, sort the subsets, and then combine the subsets into totally sorted data; examples include bucket sort and flashsort.
However, in general distributed algorithms need not be hybrid algorithms, as individual algorithms or combining or communication algorithms may be solving different problems. For example, in models such as MapReduce, the Map and Reduce step solve different problems, and are combined to solve a different, third problem.

See also
Hybrid algorithm (constraint satisfaction)
Hybrid genetic algorithm
Hybrid input output (HIO) algorithm for phase retrieval",40338559,https://en.wikipedia.org/wiki/Hybrid_algorithm
Hyphenation algorithm,"Syllabification () or syllabication (), also known as hyphenation, is the separation of a word into syllables, whether spoken, written or signed.","Syllabification () or syllabication (), also known as hyphenation, is the separation of a word into syllables, whether spoken, written or signed.

Overview
The written separation into syllables is usually marked by a hyphen when using English orthography (e.g., syl-la-ble) and with a period when transcribing the actually spoken syllables in the International Phonetic Alphabet (e.g., [ˈsɪl.ə.bᵊɫ]). For presentation purposes, typographers may use an interpunct (Unicode character U+00B7, e.g., syl·la·ble), a special-purpose ""hyphenation point"" (U+2027, e.g., syl‧la‧ble), or a space (e.g., syl la ble).
At the end of a line, a word is separated in writing into parts, conventionally called ""syllables"", if it does not fit the line and if moving it to the next line would make the first line much shorter than the others. This can be a particular problem with very long words, and with narrow columns in newspapers. Word processing has automated the process of justification, making syllabification of shorter words often unnecessary.
In some languages, the spoken syllables are also the basis of syllabification in writing. However, possibly due to the weak correspondence between sounds and letters in the spelling of modern English, written syllabification in English is based mostly on etymological or morphological, instead of phonetic, principles. For example, it is not possible to syllabify ""learning"" as lear-ning according to the correct syllabification of the living language. Seeing only lear- at the end of a line might mislead the reader into pronouncing the word incorrectly, as the digraph ea can hold many different values. The history of English orthography accounts for such phenomena.
English written syllabification therefore deals with a concept of ""syllable"" that does not correspond to the linguistic concept of a phonological (as opposed to morphological) unit.
As a result, even most native English speakers are unable to syllabify words according to established rules without consulting a dictionary or using a word processor. Schools usually do not provide much more advice on the topic than to consult a dictionary. In addition, there are differences between British and US syllabification and even between dictionaries of the same English variety.
In Finnish, Italian, Portuguese, Japanese (Romaji), Korean (Romanized) and other nearly phonemically spelled languages, writers can in principle correctly syllabify any existing or newly created word using only general rules. In Finland, children are first taught to hyphenate every word until they produce the correct syllabification reliably, after which the hyphens can be omitted.

Algorithm
A hyphenation algorithm is a set of rules, especially one codified for implementation in a computer program, that decides at which points a word can be broken over two lines with a hyphen. For example, a hyphenation algorithm might decide that impeachment can be broken as impeach-ment or im-peachment but not impe-achment.
One of the reasons for the complexity of the rules of word-breaking is that different dialects of English tend to differ on hyphenation: American English tends to work on sound, but British English tends to look to the origins of the word and then to sound. There are also a large number of exceptions, which further complicates matters.Some rules of thumb can be found in the Major Keary's ""On Hyphenation – Anarchy of Pedantry.""  Among the algorithmic approaches to hyphenation, the one implemented in the TeX typesetting system is widely used. It is thoroughly documented in the first two volumes of Computers and Typesetting by Donald Knuth and in Franklin Mark Liang's dissertation. The aim of Liang's work was to get the algorithm as accurate as possible and to keep exceptions to a minimum.
In TeX's original hyphenation patterns for American English, the exception list contains only 14 words.

In TeX
Ports of the TeX hyphenation algorithm are available as libraries for several programming languages, including Haskell, JavaScript, Perl, PostScript, Python, Ruby, C#, and TeX can be made to show hyphens in the log by the command \showhyphens.
In LaTeX, hyphenation correction can be added by users by using:

\hyphenation{words}
The \hyphenation command declares allowed hyphenation points in which words is a list of words, separated by spaces, in which each hyphenation point is indicated by a - character. For example,

\hyphenation{fortran er-go-no-mic}
declares that in the current job ""fortran"" should not be hyphenated and that if ""ergonomic"" must be hyphenated, it will be at one of the indicated points.However, there are several limits. For example, the stock \hyphenation command accepts only ASCII letters by default and so it cannot be used to correct hyphenation for words with non-ASCII characters (like ä, é, ç), which are very common in many  languages. Simple workarounds exist, however.

See also
Phonotactics
Tautosyllabic, heterosyllabic and ambisyllabic phones
Syllable structure in English phonology

Notes
External links
Online Lyric Hyphenator: Hyphenates English text into syllables
Hyphenation tool for the French Language: Hyphenates French words with explanation",1393831,https://en.wikipedia.org/wiki/Syllabification
In-place algorithm,"In computer science, an in-place algorithm is an algorithm that operates directly on the input data structure without requiring extra space proportional to the input size. In other words, it modifies the input in place, without creating a separate copy of the data structure. An algorithm which is not in-place is sometimes called not-in-place or out-of-place.
In-place can have slightly different meanings. In its strictest form, the algorithm can only have a constant amount of extra space, counting everything including function calls and pointers. However, this form is very limited as simply having an index to a length n array requires O(log n) bits. More broadly, in-place means that the algorithm does not use extra space for manipulating the input but may require a small though nonconstant extra space for its operation. Usually, this space is O(log n), though sometimes anything in o(n) is allowed. Note that space complexity also has varied choices in whether or not to count the index lengths as part of the space used. Often, the space complexity is given in terms of the number of indices or pointers needed, ignoring their length. In this article, we refer to total space complexity (DSPACE), counting pointer lengths. Therefore, the space requirements here have an extra log n factor compared to an analysis that ignores the length of indices and pointers.  
An algorithm may or may not count the output as part of its space usage. Since in-place algorithms usually overwrite their input with output, no additional space is needed. When writing the output to write-only memory or a stream, it may be more appropriate to only consider the working space of the algorithm. In theoretical applications such as log-space reductions, it is more typical to always ignore output space (in these cases it is more essential that the output is write-only).","In computer science, an in-place algorithm is an algorithm that operates directly on the input data structure without requiring extra space proportional to the input size. In other words, it modifies the input in place, without creating a separate copy of the data structure. An algorithm which is not in-place is sometimes called not-in-place or out-of-place.
In-place can have slightly different meanings. In its strictest form, the algorithm can only have a constant amount of extra space, counting everything including function calls and pointers. However, this form is very limited as simply having an index to a length n array requires O(log n) bits. More broadly, in-place means that the algorithm does not use extra space for manipulating the input but may require a small though nonconstant extra space for its operation. Usually, this space is O(log n), though sometimes anything in o(n) is allowed. Note that space complexity also has varied choices in whether or not to count the index lengths as part of the space used. Often, the space complexity is given in terms of the number of indices or pointers needed, ignoring their length. In this article, we refer to total space complexity (DSPACE), counting pointer lengths. Therefore, the space requirements here have an extra log n factor compared to an analysis that ignores the length of indices and pointers.  
An algorithm may or may not count the output as part of its space usage. Since in-place algorithms usually overwrite their input with output, no additional space is needed. When writing the output to write-only memory or a stream, it may be more appropriate to only consider the working space of the algorithm. In theoretical applications such as log-space reductions, it is more typical to always ignore output space (in these cases it is more essential that the output is write-only).

Examples
Given an array a of n items, suppose we want an array that holds the same elements in reversed order and to dispose of the original. One seemingly simple way to do this is to create a new array of equal size, fill it with copies from a in the appropriate order and then delete a.

 function reverse(a[0..n - 1])
     allocate b[0..n - 1]
     for i from 0 to n - 1
         b[n − 1 − i] := a[i]
     return b

Unfortunately, this requires O(n) extra space for having the arrays a and b available simultaneously. Also, allocation and deallocation are often slow operations. Since we no longer need a, we can instead overwrite it with its own reversal using this in-place algorithm which will only need constant number (2) of integers for the auxiliary variables i and tmp, no matter how large the array is.

 function reverse_in_place(a[0..n-1])
     for i from 0 to floor((n-2)/2)
         tmp := a[i]
         a[i] := a[n − 1 − i]
         a[n − 1 − i] := tmp

As another example, many sorting algorithms rearrange arrays into sorted order in-place, including: bubble sort, comb sort, selection sort, insertion sort, heapsort, and Shell sort. These algorithms require only a few pointers, so their space complexity is O(log n).Quicksort operates in-place on the data to be sorted. However, quicksort requires O(log n) stack space pointers to keep track of the subarrays in its divide and conquer strategy. Consequently, quicksort needs O(log2 n) additional space. Although this non-constant space technically takes quicksort out of the in-place category, quicksort and other algorithms needing only O(log n) additional pointers are usually considered in-place algorithms.
Most selection algorithms are also in-place, although some considerably rearrange the input array in the process of finding the final, constant-sized result.
Some text manipulation algorithms such as trim and reverse may be done in-place.

In computational complexity
In computational complexity theory, the strict definition of in-place algorithms includes all algorithms with O(1) space complexity, the class DSPACE(1). This class is very limited; it equals the regular languages. In fact, it does not even include any of the examples listed above.
Algorithms are usually considered in L, the class of problems requiring O(log n) additional space, to be in-place. This class is more in line with the practical definition, as it allows numbers of size n as pointers or indices. This expanded definition still excludes quicksort, however, because of its recursive calls.  
Identifying the in-place algorithms with L has some interesting implications; for example, it means that there is a (rather complex) in-place algorithm to determine whether a path exists between two nodes in an undirected graph, a problem that requires O(n) extra space using typical algorithms such as depth-first search (a visited bit for each node). This in turn yields in-place algorithms for problems such as determining if a graph is bipartite or testing whether two graphs have the same number of connected components.

Role of randomness
In many cases, the space requirements of an algorithm can be drastically cut by using a randomized algorithm. For example, if one wishes to know if two vertices in a graph of n vertices are in the same connected component of the graph, there is no known simple, deterministic, in-place algorithm to determine this. However, if we simply start at one vertex and perform a random walk of about 20n3 steps, the chance that we will stumble across the other vertex provided that it is in the same component is very high. Similarly, there are simple randomized in-place algorithms for primality testing such as the Miller–Rabin primality test, and there are also simple in-place randomized factoring algorithms such as Pollard's rho algorithm.

In functional programming
Functional programming languages often discourage or do not support explicit in-place algorithms that overwrite data, since this is a type of side effect; instead, they only allow new data to be constructed. However, good functional language compilers will often recognize when an object very similar to an existing one is created and then the old one is thrown away, and will optimize this into a simple mutation ""under the hood"".
Note that it is possible in principle to carefully construct in-place algorithms that do not modify data (unless the data is no longer being used), but this is rarely done in practice.

See also
Table of in-place and not-in-place sorting algorithms


== References ==",219861,https://en.wikipedia.org/wiki/In-place_algorithm
Irish logarithm,"The Irish logarithm was a system of number manipulation invented by Percy Ludgate for machine multiplication. The system used a combination of mechanical cams as lookup tables and mechanical addition to sum pseudo-logarithmic indices to produce partial products, which were then added to produce results.The technique is similar to Zech logarithms (also known as Jacobi logarithms), but uses a system of indices original to Ludgate.","The Irish logarithm was a system of number manipulation invented by Percy Ludgate for machine multiplication. The system used a combination of mechanical cams as lookup tables and mechanical addition to sum pseudo-logarithmic indices to produce partial products, which were then added to produce results.The technique is similar to Zech logarithms (also known as Jacobi logarithms), but uses a system of indices original to Ludgate.

Concept
Ludgate's algorithm compresses the multiplication of two single decimal numbers into two table lookups (to convert the digits into indices), the addition of the two indices to create a new index which is input to a second lookup table that generates the output product. Because both lookup tables are one-dimensional, and the addition of linear movements is simple to implement mechanically, this allows a less complex mechanism than would be needed to implement a two-dimensional 10×10 multiplication lookup table.
Ludgate stated that he deliberately chose the values in his tables to be as small as he could make them; given this, Ludgate's tables can be simply constructed from first principles, either via pen-and-paper methods, or a systematic search using only a few tens of lines of program code. They do not correspond to either Zech logarithms, Remak indexes or Korn indexes.

Pseudocode
The following is an implementation of Ludgate's Irish logarithm algorithm in the Python programming language:

Table 1 is taken from Ludgate's original paper; given the first table, the contents of Table 2 can be trivially derived from Table 1 and the definition of the algorithm. Note since that the last third of the second table is entirely zeros, this could be exploited to further simplify a mechanical implementation of the algorithm.

See also
Faber-Castell Model 366 – Unusual slide rule using a system similar to discrete logarithmsPages displaying short descriptions of redirect targets
Canon arithmeticus – Book by Carl Jacobi

References
Further reading
Boys, C.V., ""A New Analytical Engine,"" Nature, Vol. 81, No. 2070, July 1, 1904, pp. 14–15.
Randell, B., ""Ludgate's analytical machine of 1909"", The Computer Journal, Volume 14, Issue 3, 1971, Pages 317–326, https://doi.org/10.1093/comjnl/14.3.317 Includes the text of Ludgate's original paper.

External links
A detailed treatment of Ludgate's Irish Logarithms, Brian Coghlan, 2019 (Archived from original link)
Transcript of ""On a Proposed Analytical Machine"" by Percy Ludgate (first published in Scientific Proceedings of the Royal Dublin Society 1909 vol 12 pages 77–91), containing Ludgate's own description of the Irish logarithm tables
A reproduction of Ludgate's original 1909 paper, from The origins of digital computers : selected papers. Randell, Brian, 1936-. Berlin: Springer-Verlag. 1973. p. 71. ISBN 978-3-642-96145-8. OCLC 858931618.{{cite book}}:  CS1 maint: others (link)
Method for deriving Ludgate's Irish Logarithms from first principles, Brian Coghlan, 2022)",31818344,https://en.wikipedia.org/wiki/Irish_logarithm
Iteration,"Iteration is the repetition of a process in order to generate a (possibly unbounded) sequence of outcomes. Each repetition of the process is a single iteration, and the outcome of each iteration is then the starting point of the next iteration. 
In mathematics and computer science, iteration (along with the related technique of recursion) is a standard element of algorithms.","Iteration is the repetition of a process in order to generate a (possibly unbounded) sequence of outcomes. Each repetition of the process is a single iteration, and the outcome of each iteration is then the starting point of the next iteration. 
In mathematics and computer science, iteration (along with the related technique of recursion) is a standard element of algorithms.

Mathematics
In mathematics, iteration may refer to the process of iterating a function, i.e. applying a function repeatedly, using the output from one iteration as the input to the next. Iteration of apparently simple functions can produce complex behaviors and difficult problems – for examples, see the Collatz conjecture and juggler sequences.
Another use of iteration in mathematics is in iterative methods which are used to produce approximate numerical solutions to certain mathematical problems. Newton's method is an example of an iterative method. Manual calculation of a number's square root is a common use and a well-known example.

Computing
In computing, iteration is the technique marking out of a block of statements within a computer program for a defined number of repetitions.  That block of statements is said to be iterated; a computer scientist might also refer to that block of statements as an ""iteration"".

Implementations
Loops constitute the most common language constructs for performing iterations. The following pseudocode ""iterates"" three times the line of code between begin & end through a for loop, and uses the values of i as increments.

It is permissible, and often necessary, to use values from other parts of the program outside the bracketed block of statements, to perform the desired function.
Iterators constitute alternative language constructs to loops, which ensure consistent iterations over specific data structures. They can eventually save time and effort in later coding attempts. In particular, an iterator allows one to repeat the same kind of operation at each node of such a data structure, often in some pre-defined order.
Iteratees are purely functional language constructs, which accept or reject data during the iterations.

Relation with recursion
Recursions and iterations have different algorithmic definitions, even though they can generate identical effects/results.  The primary difference is that recursion can be employed as a solution without prior knowledge as to how many times the action will have to repeat, while a successful iteration requires that foreknowledge. 
Some types of programming languages, known as functional programming languages, are designed such that they do not set up a block of statements for explicit repetition, as with the for loop.  Instead, those programming languages exclusively use recursion.  Rather than call out a block of code to be repeated a pre-defined number of times, the executing code block instead ""divides"" the work to be done into a number of separate pieces, after which the code block executes itself on each individual piece.  Each piece of work will be divided repeatedly until the ""amount"" of work is as small as it can possibly be, at which point the algorithm will do that work very quickly.  The algorithm then ""reverses"" and reassembles the pieces into a complete whole.
The classic example of recursion is in list-sorting algorithms, such as merge sort.  The merge sort recursive algorithm will first repeatedly divide the list into consecutive pairs; each pair is then ordered, then each consecutive pair of pairs, and so forth until the elements of the list are in the desired order.
The code below is an example of a recursive algorithm in the Scheme programming language that will output the same result as the pseudocode under the previous heading.

Education
In some schools of pedagogy, iterations are used to describe the process of teaching or guiding students to repeat experiments, assessments, or projects, until more accurate results are found, or the student has mastered the technical skill.  This idea is found in the old adage, ""Practice makes perfect."" In particular, ""iterative"" is defined as the ""process of learning and development that involves cyclical inquiry, enabling multiple opportunities for people to revisit ideas and critically reflect on their implication.""Unlike computing and math, educational iterations are not predetermined; instead, the task is repeated until success according to some external criteria (often a test) is achieved.

See also
Recursion
Fractal
Brute-force search
Iterated function
Infinite compositions of analytic functions


== References ==",68833,https://en.wikipedia.org/wiki/Iteration
Jumble algorithm,"Jumble is a word puzzle with a clue, a drawing illustrating the clue, and a set of words, each of which is “jumbled” by scrambling its letters. A solver reconstructs the words, and then arranges letters at marked positions in the words to spell the answer phrase to the clue.  The clue, and sometimes the illustration, provide hints about the answer phrase, which frequently uses a homophone or pun.
Jumble was created in 1954 by Martin Naydel, who was better known for his work on comic books. It originally appeared under the title ""Scramble."" Henri Arnold and Bob Lee took over the feature in 1962 and continued it for at least 30 years. As of 2013, Jumble was being maintained by David L. Hoyt and Jeff Knurek. Jumble is one of the most valuable properties of its distributor, US company Tribune Content Agency, which owns the JUMBLE trademarks and copyrights. Daily and Sunday Jumble puzzles appear in over 600 newspapers in the United States and internationally.
The current syndicated version found in most daily newspapers (under the official title Jumble--That Scrambled Word Game) has four base anagrams, two of five letters and two of six, followed by a clue and a series of blank spaces into which the answer to the clue fits. The answer to the clue is generally a pun of some sort. A weekly ""kids version"" of the puzzle features a three-letter word plus three four-letter words. In order to find the letters that are in the answer to the given clue, the player must unscramble all four of the scrambled words; the letters that are in the clue will be circled. The contestant then unscrambles the circled letters to form the answer to the clue. An alternate workaround is to solve some of the scrambled words, figure out the answer to the clue without all the letters, then use the ""extra"" letters as aids to solve the remaining scrambled words.There are many variations of puzzles from the Jumble brand including Jumble, Jumble for Kids, Jumble Crosswords, TV Jumble, Jumble BrainBusters, Jumble BrainBusters Junior, Hollywood Jumble, Jumble Jong, Jumble Word Vault, Jumpin' Jumble, Jumble Solitaire, and Jumble Word Web.","Jumble is a word puzzle with a clue, a drawing illustrating the clue, and a set of words, each of which is “jumbled” by scrambling its letters. A solver reconstructs the words, and then arranges letters at marked positions in the words to spell the answer phrase to the clue.  The clue, and sometimes the illustration, provide hints about the answer phrase, which frequently uses a homophone or pun.
Jumble was created in 1954 by Martin Naydel, who was better known for his work on comic books. It originally appeared under the title ""Scramble."" Henri Arnold and Bob Lee took over the feature in 1962 and continued it for at least 30 years. As of 2013, Jumble was being maintained by David L. Hoyt and Jeff Knurek. Jumble is one of the most valuable properties of its distributor, US company Tribune Content Agency, which owns the JUMBLE trademarks and copyrights. Daily and Sunday Jumble puzzles appear in over 600 newspapers in the United States and internationally.
The current syndicated version found in most daily newspapers (under the official title Jumble--That Scrambled Word Game) has four base anagrams, two of five letters and two of six, followed by a clue and a series of blank spaces into which the answer to the clue fits. The answer to the clue is generally a pun of some sort. A weekly ""kids version"" of the puzzle features a three-letter word plus three four-letter words. In order to find the letters that are in the answer to the given clue, the player must unscramble all four of the scrambled words; the letters that are in the clue will be circled. The contestant then unscrambles the circled letters to form the answer to the clue. An alternate workaround is to solve some of the scrambled words, figure out the answer to the clue without all the letters, then use the ""extra"" letters as aids to solve the remaining scrambled words.There are many variations of puzzles from the Jumble brand including Jumble, Jumble for Kids, Jumble Crosswords, TV Jumble, Jumble BrainBusters, Jumble BrainBusters Junior, Hollywood Jumble, Jumble Jong, Jumble Word Vault, Jumpin' Jumble, Jumble Solitaire, and Jumble Word Web.

Versions in other media
In addition to being playable online through various interactive online platforms such as on Tribune Content Agency's Web site in an HTML 5 implementation, Jumble is downloadable through several mobile game applications such as Apple's iTunes, AT&T and on the Amazon Kindle.
In 2010, Jumble Madness	was developed by Anino Entertainment and published by Destineer for the Nintendo DS.
As of 2012, Jumble books were published by Andrews McMeel Publishing, Triumph Books, and Tyndale House Publishers.Jumble is also available as a Bicycle playing card by United States Playing Card Company with an assortment of game titles such as ""3-4-5,"" ""Jumble Word Meld,"" and ""Jumble Solitaire.""
A TV game show based on Jumble aired in 1994. It was hosted by game show veteran Wink Martindale, and aired on The Family Channel (now called Freeform).

Computerized solutions
Algorithms have been designed to solve Jumbles, using a dictionary. Common algorithms work by printing all words that can be formed from a set of letters. The solver then chooses the right word. A dictionary of such anagrams may be used to solve puzzles or verify that a jumbled word is unique when creating puzzles.
First algorithm:

Begin
Input: J, all the jumbled letters that form an unknown W word(s)
Sort the letters of J in alphabetical order, preserving duplicates
Look up sorted letters in a hash table, initialised with a dictionary, that maps a sorted set of letters to unscrambled words
Print the set of words, which is W
EndSecond algorithm:

Begin
Input: J, all the jumbled letters that form an unknown W word(s)
Frame a word list Y with all permutations of J
For each word in Y check if the word is existing in the dictionary
If a match is found then collect it in word list W
Print the words in W
EndAlgorithm to find the permutations of J:

Begin
Initialize a string with first character of J denoted by J(1)
Add the second character of J denoted by J(2) on either side of J(1) to get two strings
J(1)J(2)
J(2)J(1)
Add the third character of J denoted by J(3) on either side and in between the above 2 strings to get 6 strings
J(1)J(2)J(3)
J(1)J(3)J(2)
J(3)J(1)J(2)
J(2)J(1)J(3)
J(2)J(3)J(1)
J(3)J(2)J(1)
In the same way add J(4) to each of the above strings in either sides and between two characters to get 24 strings
Continue this until all the characters are completedDouglas Hofstadter developed a program called Jumbo that tries to solve Jumble problems as a human mind would.
The program does not rely on a dictionary and does not try to find real English words, but rather words that could be English, exploiting a database of plausibilities for various combinations of letters.
Letters are combined non-deterministically, following a strategy inspired by chemical reactions and free associations.

See also
Metapuzzle


== References ==",1173921,https://en.wikipedia.org/wiki/Jumble
Jump-and-Walk algorithm,"Jump-and-Walk is an algorithm for point location in triangulations (though most of the theoretical analysis were performed in 2D and 3D random Delaunay triangulations). Surprisingly, the algorithm does not need any preprocessing or complex data structures except some simple representation of the triangulation itself. The predecessor of Jump-and-Walk was due to Lawson (1977) and Green and Sibson (1978), which picks a random starting point S and then walks from S toward the query point Q one triangle at a time. But no theoretical analysis was known for these predecessors until after mid-1990s.
Jump-and-Walk picks a small group of sample points and starts the walk from the sample point which is the closest to Q until the simplex containing Q is found. The algorithm was a folklore in practice for some time, and the formal presentation of the algorithm and the analysis of its performance on 2D random Delaunay triangulation was done by Devroye, Mucke and Zhu in mid-1990s (the paper appeared in Algorithmica, 1998). The analysis on 3D random Delaunay triangulation was done by Mucke, Saias and Zhu (ACM Symposium of Computational Geometry, 1996). In both cases, a boundary condition was assumed, namely, Q must be slightly away from the boundary of the convex domain where the vertices of the random Delaunay triangulation are drawn. In 2004, Devroye, Lemaire and Moreau showed that in 2D the boundary condition can be withdrawn (the paper appeared in Computational Geometry: Theory and Applications, 2004).
Jump-and-Walk has been used in many famous software packages, e.g., QHULL, Triangle and CGAL.","Jump-and-Walk is an algorithm for point location in triangulations (though most of the theoretical analysis were performed in 2D and 3D random Delaunay triangulations). Surprisingly, the algorithm does not need any preprocessing or complex data structures except some simple representation of the triangulation itself. The predecessor of Jump-and-Walk was due to Lawson (1977) and Green and Sibson (1978), which picks a random starting point S and then walks from S toward the query point Q one triangle at a time. But no theoretical analysis was known for these predecessors until after mid-1990s.
Jump-and-Walk picks a small group of sample points and starts the walk from the sample point which is the closest to Q until the simplex containing Q is found. The algorithm was a folklore in practice for some time, and the formal presentation of the algorithm and the analysis of its performance on 2D random Delaunay triangulation was done by Devroye, Mucke and Zhu in mid-1990s (the paper appeared in Algorithmica, 1998). The analysis on 3D random Delaunay triangulation was done by Mucke, Saias and Zhu (ACM Symposium of Computational Geometry, 1996). In both cases, a boundary condition was assumed, namely, Q must be slightly away from the boundary of the convex domain where the vertices of the random Delaunay triangulation are drawn. In 2004, Devroye, Lemaire and Moreau showed that in 2D the boundary condition can be withdrawn (the paper appeared in Computational Geometry: Theory and Applications, 2004).
Jump-and-Walk has been used in many famous software packages, e.g., QHULL, Triangle and CGAL.

References
Green, P. J.; Sibson, R. (1978), ""Computing Dirichlet tessellations in the plane"", The Computer Journal, 21 (2): 168–173, doi:10.1093/comjnl/21.2.168, MR 0485467.
Lawson, C. (1977), ""Software for C1 surface interpolation"", in Rice, J. R. (ed.), Mathematical Software III, NY: Academic Press, pp. 161–194.
Devroye, Luc; Lemaire, Christophe; Moreau, Jean-Michel (2004), ""Expected time analysis for Delaunay point location"", Computational Geometry: Theory and Applications, 29 (2): 61–89, doi:10.1016/j.comgeo.2004.02.002, MR 2082208.
Devroye, L.; Mücke, E. P.; Zhu, Binhai (1998), ""A note on point location in Delaunay triangulations of random points"", Algorithmica, 22 (4): 477–482, CiteSeerX 10.1.1.15.8612, doi:10.1007/PL00009234, MR 1701623, S2CID 3000041.
Mücke, Ernst P.; Saias, Isaac; Zhu, Binhai (1999), ""Fast randomized point location without preprocessing in two- and three-dimensional Delaunay triangulations"", Special issue for 12th ACM Symposium on Computational Geometry (Philadelphia, PA, 1996), Computational Geometry: Theory and Applications, 12 (1–2): 63–83, doi:10.1016/S0925-7721(98)00035-2, MR 1677599.",13830115,https://en.wikipedia.org/wiki/Jump-and-Walk_algorithm
Kinodynamic planning,"In robotics and motion planning, kinodynamic planning is a class of problems for which velocity,  acceleration, and force/torque bounds must be satisfied, together with kinematic constraints such as avoiding obstacles.  The term was coined by Bruce Donald, Pat Xavier, John Canny, and John Reif. Donald et al. developed the first polynomial-time approximation schemes (PTAS) for the problem. By providing a  provably polynomial-time ε-approximation algorithm, they resolved a long-standing open problem in optimal control. Their first paper considered time-optimal control  (""fastest path"") of a point mass under Newtonian dynamics, amidst polygonal (2D) or polyhedral  (3D) obstacles, subject to  state  bounds on position, velocity, and acceleration. Later they extended the technique to many other cases, for example, to 3D open-chain kinematic robots under full Lagrangian dynamics. More recently, many  practical heuristic algorithms  based on stochastic optimization and iterative sampling were developed, by a wide range of authors, to address the kinodynamic planning problem. These techniques for kinodynamic planning have been shown to work well in practice. However,  none of these heuristic techniques can guarantee the optimality of the computed solution (i.e., they have no performance guarantees), and  none can be mathematically proven to be faster than the original PTAS algorithms (i.e., none have a provably lower computational complexity).


== References ==","In robotics and motion planning, kinodynamic planning is a class of problems for which velocity,  acceleration, and force/torque bounds must be satisfied, together with kinematic constraints such as avoiding obstacles.  The term was coined by Bruce Donald, Pat Xavier, John Canny, and John Reif. Donald et al. developed the first polynomial-time approximation schemes (PTAS) for the problem. By providing a  provably polynomial-time ε-approximation algorithm, they resolved a long-standing open problem in optimal control. Their first paper considered time-optimal control  (""fastest path"") of a point mass under Newtonian dynamics, amidst polygonal (2D) or polyhedral  (3D) obstacles, subject to  state  bounds on position, velocity, and acceleration. Later they extended the technique to many other cases, for example, to 3D open-chain kinematic robots under full Lagrangian dynamics. More recently, many  practical heuristic algorithms  based on stochastic optimization and iterative sampling were developed, by a wide range of authors, to address the kinodynamic planning problem. These techniques for kinodynamic planning have been shown to work well in practice. However,  none of these heuristic techniques can guarantee the optimality of the computed solution (i.e., they have no performance guarantees), and  none can be mathematically proven to be faster than the original PTAS algorithms (i.e., none have a provably lower computational complexity).


== References ==",19759995,https://en.wikipedia.org/wiki/Kinodynamic_planning
KiSAO,"The Kinetic Simulation Algorithm Ontology (KiSAO) supplies information about existing algorithms available for the simulation of systems biology models, their characterization and interrelationships. KiSAO is part of the BioModels.net project and of the COMBINE initiative.","The Kinetic Simulation Algorithm Ontology (KiSAO) supplies information about existing algorithms available for the simulation of systems biology models, their characterization and interrelationships. KiSAO is part of the BioModels.net project and of the COMBINE initiative.

Structure
KiSAO consists of three main branches:

simulation algorithm
simulation algorithm characteristic
simulation algorithm parameterThe elements of each algorithm branch are linked to characteristic and parameter branches using has characteristic and has parameter relationships accordingly. The algorithm branch itself is hierarchically structured using relationships which denote that the descendant algorithms were derived from, or specify, more general ancestors.

See also
COMBINE
SED-ML
MIRIAM
SBO
TEDDY


== References ==",42563034,https://en.wikipedia.org/wiki/KiSAO
Kleene's algorithm,"In theoretical computer science, in particular in formal language theory, Kleene's algorithm transforms a given nondeterministic finite automaton (NFA) into a regular expression. 
Together with other conversion algorithms, it establishes the equivalence of several description formats for regular languages. Alternative presentations of the same method include the ""elimination method"" attributed to Brzozowski and McCluskey, the algorithm of McNaughton and Yamada, and the use of Arden's lemma.","In theoretical computer science, in particular in formal language theory, Kleene's algorithm transforms a given nondeterministic finite automaton (NFA) into a regular expression. 
Together with other conversion algorithms, it establishes the equivalence of several description formats for regular languages. Alternative presentations of the same method include the ""elimination method"" attributed to Brzozowski and McCluskey, the algorithm of McNaughton and Yamada, and the use of Arden's lemma.

Algorithm description
According to Gross and Yellen (2004), the algorithm can be traced back to Kleene (1956). A presentation of the algorithm in the case of deterministic finite automata (DFAs) is given in Hopcroft and Ullman (1979). The presentation of the algorithm for NFAs below follows Gross and Yellen (2004).Given a nondeterministic finite automaton M = (Q, Σ, δ, q0, F), with Q = { q0,...,qn } its set of states, the algorithm computes 

the sets Rkij of all strings that take M from state qi to qj without going through any state numbered higher than k.Here, ""going through a state"" means entering and leaving it, so both i and j may be higher than k, but no intermediate state may.
Each set Rkij is represented by a regular expression; the algorithm computes them step by step for k = -1, 0, ..., n. Since there is no state numbered higher than n, the regular expression Rn0j represents the set of all strings that take M from its start state q0 to qj. If F = { q1,...,qf } is the set of accept states, the regular expression Rn01 | ... | Rn0f represents the language accepted by M.
The initial regular expressions, for k = -1, are computed as follows for i≠j:

R−1ij = a1 | ... | am       where qj ∈ δ(qi,a1), ..., qj ∈ δ(qi,am)and as follows for i=j:

R−1ii = a1 | ... | am | ε       where qi ∈ δ(qi,a1), ..., qi ∈ δ(qi,am)In other words, R−1ij mentions all letters that label a transition from i to j, and we also include ε in the case where i=j.
After that, in each step the expressions Rkij are computed from the previous ones by

Rkij = Rk-1ik (Rk-1kk)* Rk-1kj | Rk-1ijAnother way to understand the operation of the algorithm is as an ""elimination method"", where the states from 0 to n are successively removed: when state k is removed, the regular expression Rk-1ij, which describes the words that label a path from state i>k to state j>k, is rewritten into Rkij so as to take into account the possibility of going via the ""eliminated"" state k.
By induction on k, it can be shown that the length of each expression Rkij is at most 1/3(4k+1(6s+7) - 4) symbols, where s denotes the number of characters in Σ.
Therefore, the length of the regular expression representing the language accepted by M is at most 1/3(4n+1(6s+7)f - f - 3) symbols, where f denotes the number of final states.
This exponential blowup is inevitable, because there exist families of DFAs for which any equivalent regular expression must be of exponential size.In practice, the size of the regular expression obtained by running the algorithm can be very different depending on the order in which the states are considered by the procedure, i.e., the order in which they are numbered from 0 to n.

Example
The automaton shown in the picture can be described as M = (Q, Σ, δ, q0, F) with

the set of states Q = { q0, q1, q2 },
the input alphabet Σ = { a, b },
the transition function δ with δ(q0,a)=q0,   δ(q0,b)=q1,   δ(q1,a)=q2,   δ(q1,b)=q1,   δ(q2,a)=q1, and δ(q2,b)=q1,
the start state q0, and
set of accept states F = { q1 }.Kleene's algorithm computes the initial regular expressions as

After that, the Rkij are computed from the Rk-1ij step by step for k = 0, 1, 2.
Kleene algebra equalities are used to simplify the regular expressions as much as possible.

Step 0Step 1Step 2Since q0 is the start state and q1 is the only accept state, the regular expression R201 denotes the set of all strings accepted by the automaton.

See also
Floyd–Warshall algorithm — an algorithm on weighted graphs that can be implemented by Kleene's algorithm using a particular Kleene algebra
Star height problem — what is the minimum stars' nesting depth of all regular expressions corresponding to a given DFA?
Generalized star height problem — if a complement operator is allowed additionally in regular expressions, can the stars' nesting depth of Kleene's algorithm's output be limited to a fixed bound?
Thompson's construction algorithm — transforms a regular expression to a finite automaton


== References ==",42923391,https://en.wikipedia.org/wiki/Kleene%27s_algorithm
Knuth–Plass line-breaking algorithm,"The Knuth–Plass algorithm is a line-breaking algorithm designed for use in Donald Knuth's typesetting program TeX. It integrates the problems of text justification and hyphenation into a single algorithm by using a discrete dynamic programming method to minimize a loss function that attempts to quantify the aesthetic qualities desired in the finished output.The algorithm works by dividing the text into a stream of three kinds of objects: boxes, which are non-resizable chunks of content, glue, which are flexible, resizeable elements, and penalties, which represent places where breaking is undesirable (or, if negative, desirable). The loss function, known as ""badness"", is defined in terms of the deformation of the glue elements, and any extra penalties incurred through line breaking.Making hyphenation decisions follows naturally from the algorithm, but the choice of possible hyphenation points within words, and optionally their preference weighting, must be performed first, and that information inserted into the text stream in advance. Knuth and Plass' original algorithm does not include page breaking, but may be modified to interface with a pagination algorithm, such as the algorithm designed by Plass in his PhD thesis.Typically, the cost function for this technique should be modified so that it does not count the space left on the final line of a paragraph; this modification allows a paragraph to end in the middle of a line without penalty. The same technique can also be extended to take into account other factors such as the number of lines or costs for hyphenating long words.","The Knuth–Plass algorithm is a line-breaking algorithm designed for use in Donald Knuth's typesetting program TeX. It integrates the problems of text justification and hyphenation into a single algorithm by using a discrete dynamic programming method to minimize a loss function that attempts to quantify the aesthetic qualities desired in the finished output.The algorithm works by dividing the text into a stream of three kinds of objects: boxes, which are non-resizable chunks of content, glue, which are flexible, resizeable elements, and penalties, which represent places where breaking is undesirable (or, if negative, desirable). The loss function, known as ""badness"", is defined in terms of the deformation of the glue elements, and any extra penalties incurred through line breaking.Making hyphenation decisions follows naturally from the algorithm, but the choice of possible hyphenation points within words, and optionally their preference weighting, must be performed first, and that information inserted into the text stream in advance. Knuth and Plass' original algorithm does not include page breaking, but may be modified to interface with a pagination algorithm, such as the algorithm designed by Plass in his PhD thesis.Typically, the cost function for this technique should be modified so that it does not count the space left on the final line of a paragraph; this modification allows a paragraph to end in the middle of a line without penalty. The same technique can also be extended to take into account other factors such as the number of lines or costs for hyphenating long words.

Computational complexity
A naive brute-force exhaustive search for the minimum badness by trying every possible combination of breakpoints would take an impractical  O(2n){\displaystyle O(2^{n})} time. The classic Knuth-Plass dynamic programming approach to solving the minimization problem is a worst-case O(n2){\displaystyle O(n^{2})} algorithm but usually runs much faster in close to linear time.Solving for the Knuth-Plass optimum can be shown to be a special case of the convex least-weight subsequence problem, which can be solved in O(n){\displaystyle O(n)} time. Methods to do this include the SMAWK algorithm.

Simple example of minimum raggedness metric
For the input text

AAA BB CC DDDDD

with line width 6, a greedy algorithm that puts as many words on a line as possible while preserving order before moving to the next line, would produce:

------    Line width: 6
AAA BB    Remaining space: 0
CC        Remaining space: 4
DDDDD     Remaining space: 1

The sum of squared space left over by this method is 02+42+12=17{\displaystyle 0^{2}+4^{2}+1^{2}=17}. However, the optimal solution achieves the smaller sum 32+12+12=11{\displaystyle 3^{2}+1^{2}+1^{2}=11}:

------    Line width: 6
AAA       Remaining space: 3
BB CC     Remaining space: 1
DDDDD     Remaining space: 1

The difference here is that the first line is broken before BB instead of after it, yielding a better right margin and a lower cost 11.

References
External links
Breaking Paragraphs into Lines, the original paper by Knuth and Plass",76478062,https://en.wikipedia.org/wiki/Knuth%E2%80%93Plass_line-breaking_algorithm
Krauss wildcard-matching algorithm,"In computer science, the Krauss wildcard-matching algorithm is a pattern matching algorithm. Based on the wildcard syntax in common use, e.g. in the Microsoft Windows command-line interface, the algorithm provides a non-recursive mechanism for matching patterns in software applications, based on syntax simpler than that typically offered by regular expressions.","In computer science, the Krauss wildcard-matching algorithm is a pattern matching algorithm. Based on the wildcard syntax in common use, e.g. in the Microsoft Windows command-line interface, the algorithm provides a non-recursive mechanism for matching patterns in software applications, based on syntax simpler than that typically offered by regular expressions.

History
The algorithm is based on a history of development, correctness and performance testing, and programmer feedback that began with an unsuccessful search for a reliable non-recursive algorithm for matching wildcards. An initial algorithm, implemented in a single while loop, quickly prompted comments from software developers, leading to improvements. Ongoing comments and suggestions culminated in a revised algorithm still implemented in a single while loop but refined based on a collection of test cases and a performance profiler. The experience tuning the single while loop using the profiler prompted development of a two-loop strategy that achieved further performance gains, particularly in situations involving empty input strings or input containing no wildcard characters. The two-loop algorithm is available for use by the open-source software development community, under the terms of the Apache License v. 2.0, and is accompanied by test case code.

Usage
The algorithm made available under the Apache license is implemented in both pointer-based C++ and portable C++ (implemented without pointers). The test case code, also available under the Apache license, can be applied to any algorithm that provides the pattern matching operations below. The implementation as coded is unable to handle multibyte character sets and poses problems when the text being searched may contain multiple incompatible character sets.

Pattern matching operations
The algorithm supports three pattern matching operations:

A one-to-one match is performed between the pattern and the source to be checked for a match, with the exception of asterisk (*) or question mark (?) characters in the pattern.
An asterisk (*) character matches any sequence of zero or more characters.
A question mark (?) character matches any single character.

Examples
*foo*  	  matches any string containing ""foo"".
mini*       matches any string that begins with ""mini"" (including the string ""mini"" itself).
???*        matches any string of three or more letters.

Applications
The original algorithm has been ported to the DataFlex programming language by Larry Heiges for use with Data Access Worldwide code library. It has been posted on GitHub in modified form as part of a log file reader. The 2014 algorithm is part of the Unreal Model Viewer built into the Epic Games Unreal Engine game engine.

See also
pattern matching
glob (programming)
wildmat


== References ==",57373227,https://en.wikipedia.org/wiki/Krauss_wildcard-matching_algorithm
Kunerth's algorithm,"Kunerth's algorithm is an algorithm for computing the modular square root of a given number.
The algorithm does not require the factorization of the modulus, and relies on modular operations that is often easy when the given number is prime.","Kunerth's algorithm is an algorithm for computing the modular square root of a given number.
The algorithm does not require the factorization of the modulus, and relies on modular operations that is often easy when the given number is prime.

Algorithm
To find y from a given value

B=y2modN,{\displaystyle B=y^{2}{\bmod {N}},}it takes the following steps:

find the modular square root of r≡±N(modB){\displaystyle r\equiv {\sqrt {\pm N}}{\pmod {B}}}. This step is quite easy, irrespectively of how big N when B{\displaystyle B} is a prime.
solve a quadratic equation associated with the modular square root of w2=A⋅z2+B⋅z+C{\displaystyle w^{2}=A\cdot z^{2}+B\cdot z+C}. Most of Kunerth's examples in his original paper solve this equation by having C be a integer square and thus setting z to zero.
Expand out the following equation to obtain the quadratic
((B⋅z+r)2±N)/B=w2.{\displaystyle ((B\cdot z+r)^{2}\pm N)/B=w^{2}.}
One can always make sure that the quadratic can be solved by adjusting the modulus N in the above equation. Thus
((B⋅z+r)2+(B⋅F+N))/B=w2{\displaystyle ((B\cdot z+r)^{2}+(B\cdot F+N))/B=w^{2}}
will ensure a quadratic of A⋅z2+D⋅z+C+F{\displaystyle A\cdot z^{2}+D\cdot z+C+F}.
One can then adjust F to make sure that C+F{\displaystyle C+F} is a square. For large moduli, such as 67mod67F+RSA260{\displaystyle {\sqrt {67}}{\bmod {67F+RSA260}}}, can have their square roots computed quickly via this method.
The parameters of the polynomial expansion are quite flexible, in that ((67z+r)2+X⋅RSA260)/(67y){\displaystyle ((67z+r)^{2}+X\cdot RSA260)/(67y)} can be done, for instance.  It is quite easy to choose X and Y such that (r2+X⋅RSA260)/(67y){\displaystyle (r^{2}+X\cdot RSA260)/(67y)} is a square. The modular square root of 67ymodRSA260{\displaystyle {\sqrt {67y}}{\bmod {RSA260}}} can be taken this way.
Having solved the associated quadratic equation we now have the variables w and set v = r (if C in the quadratic is a natural square).
Solve for variables α{\displaystyle \alpha } and β{\displaystyle \beta } the following equation:
α=w(v+wβ),{\displaystyle \alpha =w(v+w\beta ),}
Obtain a value for X via factorization of the following polynomial:
α2⋅x2+(2αβ−N)x+(β2−(y2modN)){\displaystyle \alpha ^{2}\cdot x^{2}+(2\alpha \beta -N)x+(\beta ^{2}-(y^{2}{\bmod {N}}))}
obtaining an answer like
(−37+9x)(1+25x){\displaystyle (-37+9x)(1+25x)}
Obtain the modular square root by the equation. Remember to set X such that the term above is zero.  Thus X would be 37/9 or -1/25.
y≡αX+β(modN).{\displaystyle y\equiv \alpha X+\beta {\pmod {N}}.}

Example
To obtain 41mod856,{\displaystyle {\sqrt {41}}{\bmod {856}},} first obtain −856≡13(mod41){\displaystyle {\sqrt {-856}}\equiv 13{\pmod {41}}}.
Then expand the polynomial:

((41z+13)2+856)/41=w2{\displaystyle ((41z+13)^{2}+856)/41=w^{2}}into

25+26z+41z2{\displaystyle 25+26z+41z^{2}}Since, in this case the C term is a square, we take w=5{\displaystyle w=5} and compute v=13{\displaystyle v=13} (in general, v=41⋅z+13{\displaystyle v=41\cdot z+13}).

Solve for α{\displaystyle \alpha } and β{\displaystyle \beta } the following equation
α==w(v+wβ){\displaystyle \alpha ==w(v+w\beta )}
getting the solution α=15{\displaystyle \alpha =15} and β=−2{\displaystyle \beta =-2}. (There may be other pairs of solutions to this equation.)Then factor the following polynomial:α2x2+(2αβ−856)x+(β2−41){\displaystyle \alpha ^{2}x^{2}+(2\alpha \beta -856)x+(\beta ^{2}-41)}obtaining(−37+9x)(1+25x){\displaystyle (-37+9x)(1+25x)}Then obtain the modular square root via15⋅(37⋅9−1)+(−2)≡345(mod856).{\displaystyle 15\cdot (37\cdot 9^{-1})+(-2)\equiv 345{\pmod {856}}.}Verify that 3452≡41(mod856).{\displaystyle 345^{2}\equiv 41{\pmod {856}}.}In the case that −856mod41{\displaystyle {\sqrt {-856}}{\bmod {41}}} has no answer, then r≡−856(modb⋅856+41){\displaystyle r\equiv {\sqrt {-856}}{\pmod {b\cdot 856+41}}} can be used instead.

See also
Methods of computing square roots

References

Adolf Kunerth, ""Sitzungsberichte. Academie Der Wissenschaften"" vol 75, II, 1877, pp. 7–58
Adolf Kunerth, ""Sitzungsberichte. Academie Der Wissenschaften"" vol 82, II, 1880, pp. 342–375",69299670,https://en.wikipedia.org/wiki/Kunerth%27s_algorithm
Kunstweg,"Bürgi's Kunstweg is a set of algorithms invented by Jost Bürgi at the end of the 16th century. They can be used for the calculation of sines to an arbitrary precision. Bürgi used these algorithms to calculate a Canon Sinuum, a table of sines in steps of 2 arc seconds. It is thought that this table had 8 sexagesimal places. Some authors have speculated that this table only covered the range from 0 to 45 degrees, but nothing seems to support this claim. Such tables were extremely important for navigation at sea. Johannes Kepler called the Canon Sinuum the most precise known table of sines. Bürgi explained his algorithms in his work Fundamentum Astronomiae which he presented to Emperor Rudolf II. in 1592.
The principles of iterative sine table calculation through the Kunstweg are as follows: cells in a column sum up the values of the two previous cells in the same column. The final cell's value is divided by two, and the next iteration starts. Finally, the values of the last column get normalized. Rather accurate approximations of sines are obtained after few iterations.
As recently as 2015, Folkerts et al. showed that this simple process converges indeed towards the true sines. According to Folkerts, this was the first step towards difference calculus.


== References ==","Bürgi's Kunstweg is a set of algorithms invented by Jost Bürgi at the end of the 16th century. They can be used for the calculation of sines to an arbitrary precision. Bürgi used these algorithms to calculate a Canon Sinuum, a table of sines in steps of 2 arc seconds. It is thought that this table had 8 sexagesimal places. Some authors have speculated that this table only covered the range from 0 to 45 degrees, but nothing seems to support this claim. Such tables were extremely important for navigation at sea. Johannes Kepler called the Canon Sinuum the most precise known table of sines. Bürgi explained his algorithms in his work Fundamentum Astronomiae which he presented to Emperor Rudolf II. in 1592.
The principles of iterative sine table calculation through the Kunstweg are as follows: cells in a column sum up the values of the two previous cells in the same column. The final cell's value is divided by two, and the next iteration starts. Finally, the values of the last column get normalized. Rather accurate approximations of sines are obtained after few iterations.
As recently as 2015, Folkerts et al. showed that this simple process converges indeed towards the true sines. According to Folkerts, this was the first step towards difference calculus.


== References ==",49589765,https://en.wikipedia.org/wiki/Kunstweg
Lamé's theorem,"Lamé's Theorem is the result of Gabriel Lamé's analysis of the complexity of the Euclidean algorithm. Using Fibonacci numbers, he proved in 1844 that when looking for the greatest common divisor (GCD) of two integers a and b, the algorithm finishes in at most 5k steps, where k is the number of digits (decimal) of b.","Lamé's Theorem is the result of Gabriel Lamé's analysis of the complexity of the Euclidean algorithm. Using Fibonacci numbers, he proved in 1844 that when looking for the greatest common divisor (GCD) of two integers a and b, the algorithm finishes in at most 5k steps, where k is the number of digits (decimal) of b.

Statement
The number of division steps in Euclidean algorithm with entries u{\displaystyle u\,\!} and v{\displaystyle v\,\!} is less than 5{\displaystyle 5} times the number of decimal digits of min(u,v){\displaystyle \min(u,v)\,\!}.

Proof
Let u>v{\displaystyle u>v} be two positive integers.      Applying to them the Euclidean algorithm provides two sequences (q1,…,qn){\displaystyle (q_{1},\ldots ,q_{n})} and (v2,…,vn){\displaystyle (v_{2},\ldots ,v_{n})} of positive integers such that, setting v0=u,{\displaystyle v_{0}=u,} v1=v{\displaystyle v_{1}=v} and vn+1=0,{\displaystyle v_{n+1}=0,} one has

vi−1=qivi+vi+1{\displaystyle v_{i-1}=q_{i}v_{i}+v_{i+1}}for i=1,…,n,{\displaystyle i=1,\ldots ,n,} and

u>v>v2>⋯>vn>0.{\displaystyle u>v>v_{2}>\cdots >v_{n}>0.}The number n is called the number of steps of the Euclidean algorithm, since it is the number of Euclidean divisions that are performed.
The Fibonacci numbers are defined by F0=0,{\displaystyle F_{0}=0,} F1=1,{\displaystyle F_{1}=1,} and 

Fn+1=Fn+Fn−1{\displaystyle F_{n+1}=F_{n}+F_{n-1}}for n>0.{\displaystyle n>0.}
The above relations show that vn≥1=F2,{\displaystyle v_{n}\geq 1=F_{2},} and vn−1≥2=F3.{\displaystyle v_{n-1}\geq 2=F_{3}.} By induction,

vn−i−1=qn−ivn−i+vn−i+1≥vn−i+vn−i+1≥Fi+2+Fi+1=Fi+3.{\displaystyle {\begin{aligned}v_{n-i-1}&=q_{n-i}v_{n-i}+v_{n-i+1}\\&\geq v_{n-i}+v_{n-i+1}\\&\geq F_{i+2}+F_{i+1}=F_{i+3}.\end{aligned}}}So, if the Euclidean algorithm requires n steps, one has v≥Fn+1.{\displaystyle v\geq F_{n+1}.}
One has Fk≥φk−2{\displaystyle F_{k}\geq \varphi ^{k-2}} for every integer k>2{\displaystyle k>2}, where φ=1+52{\textstyle \varphi ={\frac {1+{\sqrt {5}}}{2}}} is the Golden ratio. This can be proved by induction, starting with F2=φ0=1,{\displaystyle F_{2}=\varphi ^{0}=1,} F3=2>φ,{\displaystyle F_{3}=2>\varphi ,} and continuing by using that φ2=φ+1:{\displaystyle \varphi ^{2}=\varphi +1:}

Fk+1=Fk+Fk−1≥φk−2+φk−3=φk−3(1+φ)=φk−1.{\displaystyle {\begin{aligned}F_{k+1}&=F_{k}+F_{k-1}\\&\geq \varphi ^{k-2}+\varphi ^{k-3}\\&=\varphi ^{k-3}(1+\varphi )\\&=\varphi ^{k-1}.\end{aligned}}}So, if n is the number of steps of the Euclidean algorithm, one has 

v≥φn−1,{\displaystyle v\geq \varphi ^{n-1},}and thus

n−1≤log10⁡vlog10⁡φ<5log10⁡v,{\displaystyle n-1\leq {\frac {\log _{10}v}{\log _{10}\varphi }}<5\log _{10}v,}using 1log10⁡φ<5.{\textstyle {\frac {1}{\log _{10}\varphi }}<5.}
If k is the number of decimal digits of v{\displaystyle v}, one has v<10k{\displaystyle v<10^{k}} and log10⁡v<k.{\displaystyle \log _{10}v<k.}
So,

n−1<5k,{\displaystyle n-1<5k,}and, as both members of the inequality are integers,

n≤5k,{\displaystyle n\leq 5k,}which is exactly what Lamé's theorem asserts.
As a side result of this proof, one gets that the pairs of integers (u,v){\displaystyle (u,v)} that give the maximum number of steps of the Euclidean algorithm (for a given size of v{\displaystyle v}) are the pairs of consecutive Fibonacci numbers.

References
Bibliography
Bach, Eric (1996). Algorithmic number theory. Jeffrey Outlaw Shallit. Cambridge, Mass.: MIT Press. ISBN 0-262-02405-5. OCLC 33164327
Carvalho, João Bosco Pitombeira de (1993). Olhando mais de cima: Euclides, Fibonacci e Lamé. Revista do Professor de Matemática, São Paulo, n. 24, p. 32-40, 2 sem.",73761875,https://en.wikipedia.org/wiki/Lam%C3%A9%27s_theorem
Lancichinetti–Fortunato–Radicchi benchmark,Lancichinetti–Fortunato–Radicchi benchmark is an algorithm that generates benchmark networks (artificial networks that resemble real-world networks). They have a priori known communities and are used to compare different community detection methods.  The advantage of the benchmark over other methods is that it accounts for the heterogeneity in the distributions of node degrees and of community sizes.,"Lancichinetti–Fortunato–Radicchi benchmark is an algorithm that generates benchmark networks (artificial networks that resemble real-world networks). They have a priori known communities and are used to compare different community detection methods.  The advantage of the benchmark over other methods is that it accounts for the heterogeneity in the distributions of node degrees and of community sizes.

The algorithm
The node degrees and the community sizes are distributed according to a power law, with different exponents. The benchmark assumes that both the degree and the community size have power law distributions with different exponents, γ{\displaystyle \gamma } and β{\displaystyle \beta }, respectively. N{\displaystyle N} is the number of nodes and the average degree is ⟨k⟩{\displaystyle \langle k\rangle }. There is a mixing parameter μ{\displaystyle \mu }, which is the average fraction of neighboring nodes of a node that do not belong to any community that the benchmark node belongs to.  This parameter controls the fraction of edges that are between communities. Thus, it reflects the amount of noise in the network. At the extremes, when μ=0{\displaystyle \mu =0} all links are within community links, if μ=1{\displaystyle \mu =1} all links are between nodes belonging to different communities.One can generate the benchmark network using the following steps.
Step 1: Generate a network with nodes following a power law distribution with exponent γ{\displaystyle \gamma } and choose extremes of the distribution kmin{\displaystyle k_{\min }} and kmax{\displaystyle k_{\max }} to get desired average degree is ⟨k⟩{\displaystyle \langle k\rangle }.
Step 2: (1−μ){\displaystyle (1-\mu )} fraction of links of every node is with nodes of the same community, while fraction μ{\displaystyle \mu } is with the other nodes.
Step 3: Generate community sizes from a power law distribution with exponent β{\displaystyle \beta }. The sum of all sizes must be equal to N{\displaystyle N}. The minimal and maximal community sizes smin{\displaystyle s_{\min }} and smax{\displaystyle s_{\max }} must satisfy the definition of community so that every non-isolated node is in at least in one community:

smin>kmin{\displaystyle s_{\min }>k_{\min }}
smax>kmax{\displaystyle s_{\max }>k_{\max }}Step 4: Initially, no nodes are assigned to communities. Then, each node is randomly assigned to a community. As long as the number of neighboring nodes within the community does not exceed the community size a new node is added to the community, otherwise stays out. In the following iterations the “homeless” node is randomly assigned to some community. If that community is complete, i.e. the size is exhausted, a randomly selected node of that community must be unlinked. Stop the iteration when all the communities are complete and all the nodes belong to at least one community.
Step 5: Implement rewiring of nodes keeping the same node degrees but only affecting the fraction of internal and external links such that the number of links outside the community for each node is approximately equal to the mixing parameter μ{\displaystyle \mu }.

Testing
Consider a partition into communities that do not overlap. The communities of randomly chosen nodes in each iteration follow a p(C){\displaystyle p(C)} distribution that represents the probability that a randomly picked node is from the community C{\displaystyle C}. Consider a partition of the same network that was predicted by some community finding algorithm and has p(C2){\displaystyle p(C_{2})} distribution. The benchmark partition has p(C1){\displaystyle p(C_{1})} distribution.
The joint distribution is p(C1,C2){\displaystyle p(C_{1},C_{2})}. The similarity of these two partitions is captured by the normalized mutual information.

In=∑C1,C2p(C1,C2)log2⁡p(C1,C2)p(C1)p(C2)12H({p(C1)})+12H({p(C2)}){\displaystyle I_{n}={\frac {\sum _{C_{1},C_{2}}p(C_{1},C_{2})\log _{2}{\frac {p(C_{1},C_{2})}{p(C_{1})p(C_{2})}}}{{\frac {1}{2}}H(\{p(C_{1})\})+{\frac {1}{2}}H(\{p(C_{2})\})}}}If  In=1{\displaystyle I_{n}=1} the benchmark and the detected partitions are identical, and if In=0{\displaystyle I_{n}=0} then they are independent of each other.


== References ==",46902242,https://en.wikipedia.org/wiki/Lancichinetti%E2%80%93Fortunato%E2%80%93Radicchi_benchmark
Learning augmented algorithm,"A learning augmented algorithm is an algorithm that can make use of a prediction to improve its performance.
Whereas in regular algorithms just the problem instance is inputted, learning augmented algorithms accept an extra parameter.
This extra parameter often is a prediction of some property of the solution.
This prediction is then used by the algorithm to improve its running time or the quality of its output.","A learning augmented algorithm is an algorithm that can make use of a prediction to improve its performance.
Whereas in regular algorithms just the problem instance is inputted, learning augmented algorithms accept an extra parameter.
This extra parameter often is a prediction of some property of the solution.
This prediction is then used by the algorithm to improve its running time or the quality of its output.

Description
A learning augmented algorithm typically takes an input (I,A){\displaystyle ({\mathcal {I}},{\mathcal {A}})}. Here I{\displaystyle {\mathcal {I}}} is a problem instance and A{\displaystyle {\mathcal {A}}} is the advice: a prediction about a certain property of the optimal solution. The type of the problem instance and the prediction depend on the algorithm. Learning augmented algorithms usually satisfy the following two properties:

Consistency. A learning augmented algorithm is said to be consistent if the algorithm can be proven to have a good performance when it is provided with an accurate prediction. Usually, this is quantified by giving a bound on the performance that depends on the error in the prediction.
Robustnesss. An algorithm is called robust if its worst-case performance can be bounded even if the given prediction is inaccurate.Learning augmented algorithms generally do not prescribe how the prediction should be done. For this purpose machine learning can be used.

Examples
Binary search
The binary search algorithm is an algorithm for finding elements of a sorted list x1,…,xn{\displaystyle x_{1},\ldots ,x_{n}}. It needs O(log⁡(n)){\displaystyle O(\log(n))} steps to find an element with some known value x{\displaystyle x} in a list of length n{\displaystyle n}.
With a prediction i{\displaystyle i} for the position of x{\displaystyle x}, the following learning augmented algorithm can be used.
First, look at position i{\displaystyle i} in the list. If xi=y{\displaystyle x_{i}=y}, the element has been found.
If xi<y{\displaystyle x_{i}<y}, look at positions i+1,i+2,i+4,…{\displaystyle i+1,i+2,i+4,\ldots } until an index j{\displaystyle j} with xj≥y{\displaystyle x_{j}\geq y} is found.
Now perform a binary search on xi,…,xj{\displaystyle x_{i},\ldots ,x_{j}}.
If xi>y{\displaystyle x_{i}>y}, do the same as in the previous case, but instead consider i−1,i−2,i−4,…{\displaystyle i-1,i-2,i-4,\ldots }.The error is defined to be η=|i−i∗|{\displaystyle \eta =|i-i^{*}|}, where i∗{\displaystyle i^{*}} is the real index of y{\displaystyle y}.
In the learning augmented algorithm, probing the positions i+1,i+2,i+4,…{\displaystyle i+1,i+2,i+4,\ldots } takes log2⁡(η){\displaystyle \log _{2}(\eta )} steps.
Then a binary search is performed on a list of size at most 2η{\displaystyle 2\eta }, which takes log2⁡(η){\displaystyle \log _{2}(\eta )} steps. This makes the total running time of the algorithm 2log2⁡(η){\displaystyle 2\log _{2}(\eta )}.
So, when the error is small, the algorithm is faster than a normal binary search. This shows that the algorithm is consistent.
Even in the worst case, the error will be at most n{\displaystyle n}. Then the algorithm takes at most O(log⁡(n)){\displaystyle O(\log(n))} steps, so the algorithm is robust.

More examples
Learning augmented algorithms are known for:

The ski rental problem
The maximum weight matching problem
The weighted paging problem

See also
Machine learning

References
External links
An overview of publications about learning augmented algorithms",70856028,https://en.wikipedia.org/wiki/Learning_augmented_algorithm
Least-squares spectral analysis,"Least-squares spectral analysis (LSSA) is a method of estimating a frequency spectrum based on a least-squares fit of sinusoids to data samples, similar to Fourier analysis. Fourier analysis, the most used spectral method in science, generally boosts long-periodic noise in the long and gapped records; LSSA mitigates such problems. Unlike in Fourier analysis, data need not be equally spaced to use LSSA.
Developed in 1969 and 1971, LSSA is also known as the Vaníček method and the Gauss-Vaniček method after Petr Vaníček, and as the Lomb method or the Lomb–Scargle periodogram, based on the simplifications first by Nicholas R. Lomb and then by Jeffrey D. Scargle.","Least-squares spectral analysis (LSSA) is a method of estimating a frequency spectrum based on a least-squares fit of sinusoids to data samples, similar to Fourier analysis. Fourier analysis, the most used spectral method in science, generally boosts long-periodic noise in the long and gapped records; LSSA mitigates such problems. Unlike in Fourier analysis, data need not be equally spaced to use LSSA.
Developed in 1969 and 1971, LSSA is also known as the Vaníček method and the Gauss-Vaniček method after Petr Vaníček, and as the Lomb method or the Lomb–Scargle periodogram, based on the simplifications first by Nicholas R. Lomb and then by Jeffrey D. Scargle.

Historical background
The close connections between Fourier analysis, the periodogram, and the least-squares fitting of sinusoids have been known for a long time. 
However, most developments are restricted to complete data sets of equally spaced samples. In 1963, Freek J. M. Barning of Mathematisch Centrum, Amsterdam, handled unequally spaced data by similar techniques, including both a periodogram analysis equivalent to what nowadays is called the Lomb method and least-squares fitting of selected frequencies of sinusoids determined from such periodograms — and connected by a procedure known today as the matching pursuit with post-back fitting or the orthogonal matching pursuit.Petr Vaníček, a Canadian geophysicist and geodesist of the University of New Brunswick, proposed in 1969 also the matching-pursuit approach for equally and unequally spaced data, which he called ""successive spectral analysis"" and the result a ""least-squares periodogram"". He generalized this method to account for any systematic components beyond a simple mean, such as a ""predicted linear (quadratic, exponential, ...) secular trend of unknown magnitude"", and applied it to a variety of samples, in 1971.Vaníček's strictly least-squares method was then simplified in 1976 by Nicholas R. Lomb of the University of Sydney, who pointed out its close connection to periodogram analysis.  Subsequently, the definition of a periodogram of unequally spaced data was modified and analyzed by Jeffrey D. Scargle of NASA Ames Research Center, who showed that, with minor changes, it becomes identical to Lomb's least-squares formula for fitting individual sinusoid frequencies.
Scargle states that his paper ""does not introduce a new detection technique, but instead studies the reliability and efficiency of detection with the most commonly used technique, the periodogram, in the case where the observation times are unevenly spaced,"" and further points out regarding least-squares fitting of sinusoids compared to periodogram analysis, that his paper ""establishes, apparently for the first time, that (with the proposed modifications) these two methods are exactly equivalent.""Press summarizes the development this way:

A completely different method of spectral analysis for unevenly sampled data, one that mitigates these difficulties and has some other very desirable properties, was developed by Lomb, based in part on earlier work by Barning and Vanicek, and additionally elaborated by Scargle.
In 1989, Michael J. Korenberg of Queen's University in Kingston, Ontario, developed the ""fast orthogonal search"" method of more quickly finding a near-optimal decomposition of spectra or other problems, similar to the technique that later became known as the orthogonal matching pursuit.

Development of LSSA and variants
The Vaníček method
In the Vaníček method, a discrete data set is approximated by a weighted sum of sinusoids of progressively determined frequencies using a standard linear regression or least-squares fit.  The frequencies are chosen using a method similar to Barning's, but going further in optimizing the choice of each successive new frequency by picking the frequency that minimizes the residual after least-squares fitting (equivalent to the fitting technique now known as matching pursuit with pre-backfitting). The number of sinusoids must be less than or equal to the number of data samples (counting sines and cosines of the same frequency as separate sinusoids).
A data vector Φ is represented as a weighted sum of sinusoidal basis functions, tabulated in a matrix A by evaluating each function at the sample times, with weight vector x:

ϕ≈Ax{\displaystyle \phi \approx {\textbf {A}}x},where the weights vector x is chosen to minimize the sum of squared errors in approximating Φ.  The solution for x is closed-form, using standard linear regression:
x=(ATA)−1ATϕ.{\displaystyle x=({\textbf {A}}^{\mathrm {T} }{\textbf {A}})^{-1}{\textbf {A}}^{\mathrm {T} }\phi .}Here the matrix A can be based on any set of functions mutually independent (not necessarily orthogonal) when evaluated at the sample times; functions used for spectral analysis are typically sines and cosines evenly distributed over the frequency range of interest. If we choose too many frequencies in a too-narrow frequency range, the functions will be insufficiently independent, the matrix ill-conditioned, and the resulting spectrum meaningless.When the basis functions in A are orthogonal (that is, not correlated, meaning the columns have zero pair-wise dot products), the matrix ATA is diagonal; when the columns all have the same power (sum of squares of elements), then that matrix is an identity matrix times a constant, so the inversion is trivial. The latter is the case when the sample times are equally spaced and sinusoids chosen as sines and cosines equally spaced in pairs on the frequency interval 0 to a half cycle per sample (spaced by 1/N cycles per sample, omitting the sine phases at 0 and maximum frequency where they are identically zero). This case is known as the discrete Fourier transform, slightly rewritten in terms of measurements and coefficients.
x=ATϕ{\displaystyle x={\textbf {A}}^{\mathrm {T} }\phi } — DFT case for N equally spaced samples and frequencies, within a scalar factor.

The Lomb method
Trying to lower the computational burden of the Vaníček method in 1976  (no longer an issue), Lomb proposed using the above simplification in general, except for pair-wise correlations between sine and cosine bases of the same frequency, since the correlations between pairs of sinusoids are often small, at least when they are not tightly spaced. This formulation is essentially that of the traditional periodogram but adapted for use with unevenly spaced samples. The vector x is a reasonably good estimate of an underlying spectrum, but since we ignore any correlations, Ax is no longer a good approximation to the signal, and the method is no longer a least-squares method — yet in the literature continues to be referred to as such.
Rather than just taking dot products of the data with sine and cosine waveforms directly, Scargle modified the standard periodogram formula so to find a time delay τ{\displaystyle \tau } first, such that this pair of sinusoids would be mutually orthogonal at sample times tj{\displaystyle t_{j}} and also adjusted for the potentially unequal powers of these two basis functions, to obtain a better estimate of the power at a frequency. This procedure made his modified periodogram method exactly equivalent to Lomb's method. Time delay τ{\displaystyle \tau } by definition equals to

tan⁡2ωτ=∑jsin⁡2ωtj∑jcos⁡2ωtj.{\displaystyle \tan {2\omega \tau }={\frac {\sum _{j}\sin 2\omega t_{j}}{\sum _{j}\cos 2\omega t_{j}}}.}Then the periodogram at frequency ω{\displaystyle \omega } is estimated as:

Px(ω)=12([∑jXjcos⁡ω(tj−τ)]2∑jcos2⁡ω(tj−τ)+[∑jXjsin⁡ω(tj−τ)]2∑jsin2⁡ω(tj−τ)){\displaystyle P_{x}(\omega )={\frac {1}{2}}\left({\frac {\left[\sum _{j}X_{j}\cos \omega (t_{j}-\tau )\right]^{2}}{\sum _{j}\cos ^{2}\omega (t_{j}-\tau )}}+{\frac {\left[\sum _{j}X_{j}\sin \omega (t_{j}-\tau )\right]^{2}}{\sum _{j}\sin ^{2}\omega (t_{j}-\tau )}}\right)},which, as Scargle reports, has the same statistical distribution as the periodogram in the evenly sampled case.At any individual frequency ω{\displaystyle \omega }, this method gives the same power as does a least-squares fit to sinusoids of that frequency and of the form:

ϕ(t)=Asin⁡ωt+Bcos⁡ωt.{\displaystyle \phi (t)=A\sin \omega t+B\cos \omega t.}In practice, it is always difficult to judge if a given Lomb peak is significant or not, especially when the nature of the noise is unknown, so for example a false-alarm spectral peak in the Lomb periodogram analysis of noisy periodic signal may result from noise in turbulence data. Fourier methods can also report false spectral peaks when analyzing patched-up or data edited otherwise.

The generalized Lomb–Scargle periodogram
The standard Lomb–Scargle periodogram is only valid for a model with a zero mean. Commonly, this is approximated — by subtracting the mean of the data before calculating the periodogram. However, this is an inaccurate assumption when the mean of the model (the fitted sinusoids) is non-zero. The generalized Lomb–Scargle periodogram removes this assumption and explicitly solves for the mean. In this case, the function fitted is

ϕ(t)=Asin⁡ωt+Bcos⁡ωt+C.{\displaystyle \phi (t)=A\sin \omega t+B\cos \omega t+C.}The generalized Lomb–Scargle periodogram has also been referred to in the literature as a floating mean periodogram.

Korenberg's ""fast orthogonal search"" method
Michael Korenberg of Queen's University in Kingston, Ontario, developed a method for choosing a sparse set of components from an over-complete set — such as sinusoidal components for spectral analysis — called the fast orthogonal search (FOS).  Mathematically, FOS uses a slightly modified Cholesky decomposition in a mean-square error reduction (MSER) process, implemented as a sparse matrix inversion.  As with the other LSSA methods, FOS avoids the major shortcoming of discrete Fourier analysis, so it can accurately identify embedded periodicities and excel with unequally spaced data. The fast orthogonal search method was applied to also other problems, such as nonlinear system identification.

Palmer's Chi-squared method
Palmer has developed a method for finding the best-fit function to any chosen number of harmonics, allowing more freedom to find non-sinusoidal harmonic functions. 
His is a fast (FFT-based) technique for weighted least-squares analysis on arbitrarily spaced data with non-uniform standard errors.  Source code that implements this technique is available.
Because data are often not sampled at uniformly spaced discrete times, this method ""grids"" the data by sparsely filling a time series array at the sample times.  All intervening grid points receive zero statistical weight, equivalent to having infinite error bars at times between samples.

Applications
The most useful feature of LSSA is enabling incomplete records to be spectrally analyzed — without the need to manipulate data or to invent otherwise non-existent data.
Magnitudes in the LSSA spectrum depict the contribution of a frequency or period to the variance of the time series. Generally, spectral magnitudes thus defined enable the output's straightforward significance level regime.  Alternatively, spectral magnitudes in the Vaníček spectrum can also be expressed in dB. Note that spectral magnitudes in the Vaníček spectrum follow β-distribution.Inverse transformation of Vaníček's LSSA is possible, as is most easily seen by writing the forward transform as a matrix; the matrix inverse (when the matrix is not singular) or pseudo-inverse will then be an inverse transformation; the inverse will exactly match the original data if the chosen sinusoids are mutually independent at the sample points and their number is equal to the number of data points.  No such inverse procedure is known for the periodogram method.

Implementation
The LSSA can be implemented in less than a page of MATLAB code. In essence:

""to compute the least-squares spectrum we must compute m spectral values ... which involves performing the least-squares approximation m times, each time to get [the spectral power] for a different frequency""

I.e., for each frequency in a desired set of frequencies, sine and cosine functions are evaluated at the times corresponding to the data samples, and dot products of the data vector with the sinusoid vectors are taken and appropriately normalized; following the method known as Lomb/Scargle periodogram, a time shift is calculated for each frequency to orthogonalize the sine and cosine components before the dot product; finally, a power is computed from those two amplitude components.  This same process implements a discrete Fourier transform when the data are uniformly spaced in time and the frequencies chosen correspond to integer numbers of cycles over the finite data record.
This method treats each sinusoidal component independently, or out of context, even though they may not be orthogonal to data points; it is Vaníček's original method. In addition, it is possible to perform a full simultaneous or in-context least-squares fit by solving a matrix equation and partitioning the total data variance between the specified sinusoid frequencies. Such a matrix least-squares solution is natively available in MATLAB as the backslash operator.Furthermore, the simultaneous or in-context method, as opposed to the independent or out-of-context version (as well as the periodogram version due to Lomb), cannot fit more components (sines and cosines) than there are data samples, so that:
""...serious repercussions can also arise if the selected frequencies result in some of the Fourier components (trig functions) becoming nearly linearly dependent with each other, thereby producing an ill-conditioned or near singular N. To avoid such ill conditioning it becomes necessary to either select a different set of frequencies to be estimated (e.g., equally spaced frequencies) or simply neglect the correlations in N (i.e., the off-diagonal blocks) and estimate the inverse least squares transform separately for the individual frequencies...""
Lomb's periodogram method, on the other hand, can use an arbitrarily high number of, or density of, frequency components, as in a standard periodogram; that is, the frequency domain can be over-sampled by an arbitrary factor. However, as mentioned above, one should keep in mind that Lomb's simplification and diverging from the least squares criterion opened up his technique to grave sources of errors, resulting even in false spectral peaks.In Fourier analysis, such as the Fourier transform and discrete Fourier transform, the sinusoids fitted to data are all mutually orthogonal, so there is no distinction between the simple out-of-context dot-product-based projection onto basis functions versus an in-context simultaneous least-squares fit; that is, no matrix inversion is required to least-squares partition the variance between orthogonal sinusoids of different frequencies. In the past, Fourier's was for many a method of choice thanks to its processing-efficient fast Fourier transform implementation when complete data records with equally spaced samples are available, and they used the Fourier family of techniques to analyze gapped records as well, which, however, required manipulating and even inventing non-existent data just so to be able to run a Fourier-based algorithm.

See also
Non-uniform discrete Fourier transform
Orthogonal functions
SigSpec
Sinusoidal model
Spectral density
Spectral density estimation, for competing alternatives

References
External links
LSSA package freeware download, FORTRAN, Vaníček's least-squares spectral analysis method, from the University of New Brunswick.
LSWAVE package freeware download, MATLAB, includes the Vaníček's least-squares spectral analysis method, from the U.S. National Geodetic Survey.
LSSA software freeware download (via ftp), FORTRAN, Vaníček's method, from the Natural Resources Canada.",13609399,https://en.wikipedia.org/wiki/Least-squares_spectral_analysis
Leiden algorithm,"The Leiden algorithm is a community detection algorithm developed by Traag et al 
 at Leiden University. It was developed as a modification of the 
Louvain method to address the issues with disconnected communities.","The Leiden algorithm is a community detection algorithm developed by Traag et al 
 at Leiden University. It was developed as a modification of the 
Louvain method to address the issues with disconnected communities.

Quality
Similar to modularity, the quality function is used to assess how well the communities have been allocated. The Leiden algorithm uses the Constant Potts Model (CPM):H(G,P)=∑C∈P|E(C,C)|−γ(||C||2){\displaystyle {\begin{aligned}{\mathcal {H}}(G,{\mathcal {P}})&=\sum _{C\in {\mathcal {P}}}|E(C,C)|-\gamma {\binom {||C||}{2}}\end{aligned}}}

Algorithm
The Leiden algorithm is similar to that of the Louvain method, with some important modifications.
Step 1: First, each node in the network is assigned to its own community.
Step 2: Next, we decide which communities to move the nodes into and update the partition P{\displaystyle {\mathcal {P}}}.

queue = V(G) # create a queue from the nodes

while queue != empty:
  node = queue.next() # get the next node
  delta_H = 0
  for C in communities: # compute the change in quality for each community
    if delta_H(node, C) > delta_H:
      delta_H = delta_H(node, C)
      community = C
  if delta_H > 0:
    move node to community
    outside_nodes = { node_i | (node, node_i) are edges and node_i is not in community } # find the nodes which are connected to the node but not in the community
    queue.add(outside_nodes not already in queue)

Step 3: Assign each node in the graph to its own community in a new partition called Prefined{\displaystyle {\mathcal {P}}_{\text{refined}}}.
Step 4: The goal of this step is to separate poorly-connected communities:

for C in communities of P:
  # find the nodes in the community which have lots of edges within the community
  well_connected_nodes = { node | node is in C, |E(node, C\node)| >= gamma ||node||(||C|| - ||node||) }
  for node in well_connected_nodes:
    if node is singleton:
      well_connected_communities = { C_i | C_i is in P, C_i is a subset of C, |E(C_i, C\C_i)| >= gamma*||C_i||(||C|| - ||C_i||)
      for C_i in well_connected_communities:
        compute probability P(C_i = C)
      assign node to C_i by sampling P(C_i = C) distribution

Step 5: Use the refined partition Prefined{\displaystyle {\mathcal {P}}_{\text{refined}}} to aggregate the graph. Each community in Prefined{\displaystyle {\mathcal {P}}_{\text{refined}}} becomes a node in the new graph Gagg{\displaystyle G_{\text{agg}}}.
Example: Suppose that we have:
V={v1,v2,v3,v4,v5,v6,v7}C1={v1,v2,v3,v4}C2={v5,v6,v7}P={C1,C2}Prefined={C1a,C1b,C2}{\displaystyle {\begin{aligned}V&=\{v_{1},v_{2},v_{3},v_{4},v_{5},v_{6},v_{7}\}\\C_{1}&=\{v_{1},v_{2},v_{3},v_{4}\}\\C_{2}&=\{v_{5},v_{6},v_{7}\}\\{\mathcal {P}}&=\{C_{1},C_{2}\}\\{\mathcal {P}}_{\text{refined}}&=\{C_{1a},C_{1b},C_{2}\}\end{aligned}}}
Then our new set of nodes will be:
Vagg={C1a↦w1a,C1b↦w1b,C2↦w2}{\displaystyle {\begin{aligned}V_{agg}&=\{C_{1a}\mapsto w_{1a},C_{1b}\mapsto w_{1b},C_{2}\mapsto w_{2}\}\end{aligned}}}
Step 6: Update the partition P{\displaystyle {\mathcal {P}}} using the aggregated graph. We keep the communities from partition P{\displaystyle {\mathcal {P}}}, but the communities can be separated into multiple nodes from the refined partition Prefined{\displaystyle {\mathcal {P}}_{\text{refined}}}:
P={{v | v⊆C,v∈V(Gagg)} | C∈P}{\displaystyle {\begin{aligned}{\mathcal {P}}&=\{\{v~|~v\subseteq C,v\in V(G_{\text{agg}})\}~|~C\in {\mathcal {P}}\}\end{aligned}}}
Example: Suppose that C{\displaystyle C} is a poorly-connected community from the partition P{\displaystyle {\mathcal {P}}}:
C={v1,v2,v3,v4,v5}P={C}{\displaystyle {\begin{aligned}C&=\{v_{1},v_{2},v_{3},v_{4},v_{5}\}\\{\mathcal {P}}&=\{C\}\end{aligned}}}
Then suppose during the refinement step, it was separated into two communities, C1{\displaystyle C_{1}} and C2{\displaystyle C_{2}}:
C1={v1,v2,v3}C2={v4,v5}Prefined={C1,C2}{\displaystyle {\begin{aligned}C_{1}&=\{v_{1},v_{2},v_{3}\}\\C_{2}&=\{v_{4},v_{5}\}\\{\mathcal {P}}_{\text{refined}}&=\{C_{1},C_{2}\}\end{aligned}}}
When we aggregate the graph, the new nodes will be:
V(Gagg)={C1,C2}{\displaystyle {\begin{aligned}V(G_{\text{agg}})&=\{C_{1},C_{2}\}\end{aligned}}}
but we will keep the old partition:
P={{C1,C2}}{\displaystyle {\begin{aligned}{\mathcal {P}}&=\{\{C_{1},C_{2}\}\}\end{aligned}}}
7. Repeat Steps 2 - 6 until each community consists of only one node.


== References ==",76155381,https://en.wikipedia.org/wiki/Leiden_algorithm
Lion algorithm,"Lion algorithm (LA) is one among the bio-inspired (or) nature-inspired optimization algorithms (or) that are mainly based on meta-heuristic principles. It was first introduced by B. R. Rajakumar in 2012 in the name, Lion’s Algorithm.. It was further extended in 2014 to solve the system identification problem. This version was referred as LA, which has been applied by many researchers for their optimization problems.","Lion algorithm (LA) is one among the bio-inspired (or) nature-inspired optimization algorithms (or) that are mainly based on meta-heuristic principles. It was first introduced by B. R. Rajakumar in 2012 in the name, Lion’s Algorithm.. It was further extended in 2014 to solve the system identification problem. This version was referred as LA, which has been applied by many researchers for their optimization problems.

Inspiration from lion’s social behaviour
Lions form a social system called a ""pride"", which consists of 1–3 pair of lions. A pride of lions shares a common area known as territory in which a dominant lion is called as territorial lion. The territorial lion safeguards its territory from outside attackers, especially nomadic lions. This process is called territorial defense. It protects the cubs till they become sexually matured. The maturity period is about 2–4 years. The pride undergoes survival fights to protect its territory and the cubs from nomadic lions. Upon getting defeated by the nomadic lions, the dominating nomadic lion takes the role of territorial lion by killing or driving out the cubs of the pride. The lioness of the pride give birth to cubs though the new territorial lion. When the cubs of the pride mature and considered to be stronger than the territorial lion, they take over the pride. This process is called territorial take-over. If territorial take-over happens, either the old territorial lion, which is considered to be laggard, is driven out or it leaves the pride. The stronger lions and lioness form the new pride and give birth to their own cubs

Terminology
In the LA, the terms that are associated with lion’s social system are mapped to the terminology of optimization problems. Few of such notable terms are related here.
Lion: A potential solution to be generated or determined as optimal (or) near-optimal solution of the problem. The lion can be a territorial lion and lioness, cubs and nomadic lions that represent the solution based on the processing steps of the LA.
Territorial lion: The strongest solution of the pride that tends to meet the objective function.
Nomadic lion: A random solution, sometimes termed as nomad, to facilitate the exploration principle
Laggard lion: Poor solutions that are failed in the survival fight.
Pride: A pool of potential solutions i.e. a lion, lioness and their cubs, that are potential solutions of the search problem.
Fertility evaluation: A process of evaluating whether the territorial lion and lioness are able to provide potential solutions in the future generations i.e. It ensures that the lion or lioness converge at every generation.
Survival fight: It is a greedy selection process, which is often carried out between the pride and nomadic lion.

Algorithm
The steps involved in LA are given below:
Pride Generation: Generate Xmale{\displaystyle X^{male}}, Xfemale{\displaystyle X^{female}}and X1nomad{\displaystyle X_{1}^{nomad}}
Determine f(Xmale){\displaystyle f(X^{male})}, f(Xfemale){\displaystyle f(X^{female})}, f(X1nomad){\displaystyle f(X_{1}^{nomad})}
Initialize fref{\displaystyle f^{ref}} asf(Xmale){\displaystyle f(X^{male})} and Ng{\displaystyle N_{g}} as 0
Memorize Xmale{\displaystyle X^{male}} and Xfemale{\displaystyle X^{female}}
Apply Fertility evaluation Process
Generation of cubpool by mating
Gender clustering: Define Xcubmale{\displaystyle X_{cub}^{male}} and Xcubfemale{\displaystyle X_{cub}^{female}}
Initialize agecub{\displaystyle age_{cub}} as zero
Apply Cub growth function
Territorial defense: If Xmale{\displaystyle X^{male}} (or pride) fails in the survival fight i.e. X1nomad{\displaystyle X_{1}^{nomad}} defeats the pride, go to step 4, else continue
Increase agecub{\displaystyle age_{cub}} by 1 and check whether cub attains maturity i.e., if agecub>agemax{\displaystyle age_{cub}>age_{max}},  go to Step 9, else continue
Territorial takeover: If Xcubmale{\displaystyle X_{cub}^{male}} and Xcubfemale{\displaystyle X_{cub}^{female}} are found to be closer to optimal solution, update Xmale{\displaystyle X^{male}} and Xfemale{\displaystyle X^{female}}
Increment Ng{\displaystyle N_{g}} by 1
Repeat from Step 5, if termination criterion is not violated, else return Xmale{\displaystyle X^{male}} as the near-optimal solution

Variants
The LA has been further taken forward to adopt in different problem areas. According to the characteristics of the problem area, significant amendment has been done in the processes and the models used in the LA. Accordingly, diverse variants have been developed by the researchers. They can be broadly grouped as hybrid LAs and non-hybrid LAs. Hybrid LAs are the LAs that are amended by the principle of other meta-heuristics, whereas the Non-hybrid LAs  take any scientific amendment inside its operation that are felt to be essential to attend the respective problem area.

Applications
LA is applied in diverse engineering applications that range from network security, text mining, image processing, electrical systems, data mining and many more. Few of the notable applications are discussed here.

Networking applications: In WSN, LA is used to solve the cluster head selection problem by determining optimal cluster head. Route discovery problem in both the VANET and MANET are also addressed by the LA in the literature. It is also used to detect attacks in advanced networking scenarios such as Software-Defined Networks (SDN)
Power Systems: LA has attended generation rescheduling problem in a deregulated environment, optimal localization and sizing of FACTS devices for power quality enhancement and load-frequency controlling problem
Cloud computing: LA is used in optimal container-resource allocation problem in cloud environment and cloud security


== References ==",65467021,https://en.wikipedia.org/wiki/Lion_algorithm
List of cryptosystems,A cryptosystem is a set of cryptographic algorithms that map ciphertexts and plaintexts to each other.,"A cryptosystem is a set of cryptographic algorithms that map ciphertexts and plaintexts to each other.

Private-key cryptosystems
Private-key cryptosystems use the same key for encryption and decryption.

Caesar cipher
Substitution cipher
Enigma machine
Data Encryption Standard
Twofish
Serpent
Camellia
Salsa20
ChaCha20
Blowfish
CAST5
Kuznyechik
RC4
3DES
Skipjack
Safer
IDEA
Advanced Encryption Standard, also known as AES and Rijndael.

Public-key cryptosystems
Public-key cryptosystems use a public key for encryption and a private key for decryption.

Diffie–Hellman key exchange
RSA encryption
Rabin cryptosystem
Schnorr signature
ElGamal encryption
Elliptic-curve cryptography
Lattice-based cryptography
McEliece cryptosystem
Multivariate cryptography
Isogeny-based cryptography


== References ==",69167071,https://en.wikipedia.org/wiki/List_of_cryptosystems
Long division,"In arithmetic, long division is a standard division algorithm suitable for dividing multi-digit Hindu-Arabic numerals (Positional notation) that is simple enough to perform by hand. It breaks down a division problem into a series of easier steps.
As in all division problems, one number, called the dividend, is divided by another, called the divisor,  producing a result called the quotient. It enables computations involving arbitrarily large numbers to be performed by following a series of simple steps. The abbreviated form of long division is called short division, which is almost always used instead of long division when the divisor has only one digit. Chunking (also known as the partial quotients method or the hangman method) is a less mechanical form of long division prominent in the UK which contributes to a more holistic understanding of the division process.","In arithmetic, long division is a standard division algorithm suitable for dividing multi-digit Hindu-Arabic numerals (Positional notation) that is simple enough to perform by hand. It breaks down a division problem into a series of easier steps.
As in all division problems, one number, called the dividend, is divided by another, called the divisor,  producing a result called the quotient. It enables computations involving arbitrarily large numbers to be performed by following a series of simple steps. The abbreviated form of long division is called short division, which is almost always used instead of long division when the divisor has only one digit. Chunking (also known as the partial quotients method or the hangman method) is a less mechanical form of long division prominent in the UK which contributes to a more holistic understanding of the division process.

History
Related algorithms have existed since the 12th century.Al-Samawal al-Maghribi (1125–1174) performed calculations with decimal numbers that essentially require long division, leading to infinite decimal results, but without formalizing the algorithm.
Caldrini (1491) is the earliest printed example of long division, known as the Danda method in medieval Italy, and it became more practical with the introduction of decimal notation for fractions by Pitiscus (1608).
The specific algorithm in modern use was introduced by Henry Briggs c. 1600.

Education
Inexpensive calculators and computers have become the most common way to solve division problems, eliminating a traditional mathematical exercise and decreasing the educational opportunity to show how to do so by paper and pencil techniques. (Internally, those devices use one of a variety of division algorithms, the faster of which rely on approximations and multiplications to achieve the tasks.) In the United States, long division has been especially targeted for deemphasis or even elimination from the school curriculum by reform mathematics, though it has been traditionally introduced in the 4th or 5th grades.

Method
In English-speaking countries, long division does not use the division slash ⟨∕⟩ or division sign ⟨÷⟩ symbols but instead constructs a tableau. The divisor is separated from the dividend by a right parenthesis ⟨)⟩ or vertical bar ⟨|⟩; the dividend is separated from the quotient by a vinculum (i.e., an overbar). The combination of these two symbols is sometimes known as a long division symbol or division bracket. It developed in the 18th century from an earlier single-line notation separating the dividend from the quotient by a left parenthesis.The process is begun by dividing the left-most digit of the dividend by the divisor.  The quotient (rounded down to an integer) becomes the first digit of the result, and the remainder is calculated (this step is notated as a subtraction).  This remainder carries forward when the process is repeated on the following digit of the dividend (notated as 'bringing down' the next digit to the remainder).  When all digits have been processed and no remainder is left, the process is complete.
An example is shown below, representing the division of 500 by 4 (with a result of 125).

     125      (Explanations)
   4)500
     4        ( 4 ×  1 =  4)
     10       ( 5 -  4 =  1)
      8       ( 4 ×  2 =  8)
      20      (10 -  8 =  2)
      20      ( 4 ×  5 = 20)
       0      (20 - 20 =  0)

A more detailed breakdown of the steps goes as follows:

Find the shortest sequence of digits starting from the left end of the dividend, 500, that the divisor 4 goes into at least once. In this case, this is simply the first digit, 5. The largest number that the divisor 4 can be multiplied by without exceeding 5 is 1, so the digit 1 is put above the 5 to start constructing the quotient.
Next, the 1 is multiplied by the divisor 4, to obtain the largest whole number that is a multiple of the divisor 4 without exceeding the 5 (4 in this case). This 4 is then placed under and subtracted from the 5 to get the remainder, 1, which is placed under the 4 under the 5.
Afterwards, the first as-yet unused digit in the dividend, in this case the first digit 0 after the 5, is copied directly underneath itself and next to the remainder 1, to form the number 10.
At this point the process is repeated enough times to reach a stopping point: The largest number by which the divisor 4 can be multiplied without exceeding 10 is 2, so 2 is written above as the second leftmost quotient digit. This 2 is then multiplied by the divisor 4 to get 8, which is the largest multiple of 4 that does not exceed 10; so 8 is written below 10, and the subtraction 10 minus 8 is performed to get the remainder 2, which is placed below the 8.
The next digit of the dividend (the last 0 in 500) is copied directly below itself and next to the remainder 2 to form 20. Then the largest number by which the divisor 4 can be multiplied without exceeding 20, which is 5, is placed above as the third leftmost quotient digit. This 5 is multiplied by the divisor 4 to get 20, which is written below and subtracted from the existing 20 to yield the remainder 0, which is then written below the second 20.
At this point, since there are no more digits to bring down from the dividend and the last subtraction result was 0, we can be assured that the process finished.If the last remainder when we ran out of dividend digits had been something other than 0, there would have been two possible courses of action:

We could just stop there and say that the dividend divided by the divisor is the quotient written at the top with the remainder written at the bottom, and write the answer as the quotient followed by a fraction that is the remainder divided by the divisor.
We could extend the dividend by writing it as, say, 500.000... and continue the process (using a decimal point in the quotient directly above the decimal point in the dividend), in order to get a decimal answer, as in the following example.      31.75     
   4)127.00
     12         (12 ÷ 4 = 3)
      07        (0 remainder, bring down next figure)
       4        (7 ÷ 4 = 1 r 3)                                             
       3.0      (bring down 0 and the decimal point)
       2.8      (7 × 4 = 28, 30 ÷ 4 = 7 r 2)
         20     (an additional zero is brought down)
         20     (5 × 4 = 20)
          0

In this example, the decimal part of the result is calculated by continuing the process beyond the units digit, ""bringing down"" zeros as being the decimal part of the dividend.
This example also illustrates that, at the beginning of the process, a step that produces a zero can be omitted.  Since the first digit 1 is less than the divisor 4, the first step is instead performed on the first two digits 12.  Similarly, if the divisor were 13, one would perform the first step on 127 rather than 12 or 1.

Basic procedure for long division of n ÷ m
Find the location of all decimal points in the dividend n and divisor m.
If necessary, simplify the long division problem by moving the decimals of the divisor and dividend by the same number of decimal places, to the right (or to the left), so that the decimal of the divisor is to the right of the last digit.
When doing long division, keep the numbers lined up straight from top to bottom under the tableau.
After each step, be sure the remainder for that step is less than the divisor. If it is not, there are three possible problems: the multiplication is wrong, the subtraction is wrong, or a greater quotient is needed.
In the end, the remainder, r, is added to the growing quotient as a fraction, r/m.

Invariant property and correctness
The basic presentation of the steps of the process (above)
focus on the what steps are to be performed,
rather than the properties of those steps that ensure the result will be correct
(specifically, that q × m + r = n, where q is the final quotient and r the final remainder).
A slight variation of presentation requires more writing,
and requires that we change, rather than just update, digits of the quotient,
but can shed more light on why these steps actually produce the right answer
by allowing evaluation of q × m + r at intermediate points in the process.
This illustrates the key property used in the derivation of the algorithm 
(below).
Specifically, we amend the above basic procedure so that
we fill the space after the digits of the quotient under construction with 0's, to at least the 1's place,
and include those 0's in the numbers we write below the division bracket.
This lets us maintain an invariant relation at every step:
q × m + r = n, where q is the partially-constructed quotient (above the division bracket)
and r the partially-constructed remainder (bottom number below the division bracket).
Note that, initially q=0 and r=n, so this property holds initially;
the process reduces r and increases q with each step,
eventually stopping when r<m if we seek the answer in quotient + integer remainder form.
Revisiting the 500 ÷ 4 example above, we find

     125      (q, changes from 000 to 100 to 120 to 125 as per notes below)
   4)500
     400      (  4 × 100 = 400)
     100      (500 - 400 = 100; now q=100, r=100; note q×4+r = 500.)
      80      (  4 ×  20 =  80)
      20      (100 -  80 =  20; now q=120, r= 20; note q×4+r = 500.)
      20      (  4 ×   5 =  20)
       0      ( 20 -  20 =   0; now q=125, r=  0; note q×4+r = 500.)

Example with multi-digit divisor
A divisor of any number of digits can be used. In this example, 1260257 is to be divided by 37. First the problem is set up as follows:

              
    37)1260257

Digits of the number 1260257 are taken until a number greater than or equal to 37 occurs. So 1 and 12 are less than 37, but 126 is greater. Next, the greatest multiple of 37 less than or equal to 126 is computed. So 3 × 37 = 111 < 126, but 4 × 37 > 126. The multiple 111 is written underneath the 126 and the 3 is written on the top where the solution will appear:

         3    
    37)1260257
       111

Note carefully which place-value column these digits are written into. The 3 in the quotient goes in the same column (ten-thousands place) as the 6 in the dividend 1260257, which is the same column as the last digit of 111.
The 111 is then subtracted from the line above, ignoring all digits to the right:

         3    
    37)1260257
       111
        15

Now the digit from the next smaller place value of the dividend is copied down and appended to the result 15:

         3    
    37)1260257
       111
        150

The process repeats: the greatest multiple of 37 less than or equal to 150 is subtracted. This is 148 = 4 × 37, so a 4 is added to the top as the next quotient digit. Then the result of the subtraction is extended by another digit taken from the dividend:

         34   
    37)1260257
       111
        150
        148
          22

The greatest multiple of 37 less than or equal to 22 is 0 × 37 = 0. Subtracting 0 from 22 gives 22, we often don't write the subtraction step. Instead, we simply take another digit from the dividend:

         340  
    37)1260257
       111
        150
        148
          225

The process is repeated until 37 divides the last line exactly:

         34061
    37)1260257
       111
        150
        148
          225
          222
            37

Mixed mode long division
For non-decimal currencies (such as the British £sd system before 1971) and measures (such as avoirdupois) mixed mode division must be used.  Consider dividing 50 miles 600 yards into 37 pieces:

          mi -     yd -   ft -   in
           1 -    634      1      9 r. 15""
    37)   50 -    600 -    0 -    0
          37    22880     66    348
          13    23480     66    348
        1760    222       37    333
       22880     128      29     15
       =====     111     348     ==
                  170    ===
                  148
                   22
                   66
                   ==

Each of the four columns is worked in turn.  Starting with the miles: 50/37 = 1 remainder 13.  No further division is
possible, so perform a long multiplication by 1,760 to convert miles to yards, the result is 22,880 yards.  Carry this to the top of the yards column and add it to the 600 yards in the dividend giving 23,480.  Long division of 23,480 / 37 now proceeds as normal yielding 634 with remainder 22.  The remainder is multiplied by 3 to get feet and carried up to the feet column.  Long division of the feet gives 1 remainder 29 which is then multiplied by twelve to get 348 inches.  Long division continues with the final remainder of 15 inches being shown on the result line.

Interpretation of decimal results
When the quotient is not an integer and the division process is extended beyond the decimal point, one of two things can happen:

The process can terminate, which means that a remainder of 0 is reached; or
A remainder could be reached that is identical to a previous remainder that occurred after the decimal points were written. In the latter case, continuing the process would be pointless, because from that point onward the same sequence of digits would appear in the quotient over and over. So a bar is drawn over the repeating sequence to indicate that it repeats forever (i.e., every rational number is either a terminating or repeating decimal).

Notation in non-English-speaking countries
China, Japan, Korea use the same notation as English-speaking nations including India. Elsewhere, the same general principles are used, but the figures are often arranged differently.

Latin America
In Latin America (except Argentina, Bolivia, Mexico, Colombia, Paraguay, Venezuela, Uruguay and Brazil), the calculation is almost exactly the same, but is written down differently as shown below with the same two examples used above. Usually the quotient is written under a bar drawn under the divisor. A long vertical line is sometimes drawn to the right of the calculations.

     500 ÷ 4 =  125   (Explanations) 
     4                ( 4 ×  1 =  4)
     10               ( 5 -  4 =  1)
      8               ( 4 ×  2 =  8)
      20              (10 -  8 =  2)
      20              ( 4 ×  5 = 20)
       0              (20 - 20 =  0)

and

     127 ÷ 4 = 31.75
     124                             
       30      (bring down 0; decimal to quotient)
       28      (7 × 4 = 28)
        20     (an additional zero is added)
        20     (5 × 4 = 20)
          0

In Mexico, the English-speaking world notation is used, except that only the result of the subtraction is annotated and the calculation is done mentally, as shown below:

     125     (Explanations)
   4)500
     10      ( 5 -  4 = 1)
      20     (10 -  8 = 2)
       0     (20 - 20 = 0)

In Bolivia, Brazil, Paraguay, Venezuela, French-Speaking Canada, Colombia, and Peru, the European notation (see below) is used, except that the quotient is not separated by a vertical line, as shown below:

    127|4    
   −124 31,75
      30
     −28
       20
      −20
        0

Same procedure applies in Mexico, Uruguay and Argentina, only the result of the subtraction is annotated and the calculation is done mentally.

Eurasia
In Spain, Italy, France, Portugal, Lithuania, Romania, Turkey, Greece, Belgium, Belarus, Ukraine, and Russia, the divisor is to the right of the dividend, and separated by a vertical bar. The division also occurs in the column, but the quotient (result) is written below the divider, and separated by the horizontal line. The same method is used in Iran, Vietnam, and Mongolia.

    127|4    
   −124|31,75
      30
     −28
       20
      −20
        0

In Cyprus, as well as in France, a long vertical bar separates the dividend and subsequent subtractions from the quotient and divisor, as in the example below of 6359 divided by 17, which is 374 with a remainder of 1.

    6359|17    
   −51  |374
    125 |
   −119 |
      69|
     −68|
       1|

Decimal numbers are not divided directly, the dividend and divisor are multiplied by a power of ten so that the division involves two whole numbers. Therefore, if one were dividing 12,7 by 0,4 (commas being used instead of decimal points), the dividend and divisor would first be changed to 127 and 4, and then the division would proceed as above.
In Austria, Germany and Switzerland, the notational form of a normal equation is used. <dividend> : <divisor> = <quotient>, with the colon "":"" denoting a binary infix symbol for the division operator (analogous to ""/"" or ""÷""). In these regions the decimal separator is written as a comma. (cf. first section of Latin American countries above, where it's done virtually the same way):

    127 : 4 = 31,75
   −12
     07
     −4
      30
     −28
       20
      −20
        0

The same notation is adopted in Denmark, Norway, Bulgaria, North Macedonia, Poland, Croatia, Slovenia, Hungary, Czech Republic, Slovakia, Vietnam and in Serbia.
In the Netherlands, the following notation is used:

   12 / 135 \ 11,25
        12
         15
         12
          30
          24
           60
           60
            0

In Finland, the Italian method detailed above was replaced by the Anglo-American one in the 1970s. In the early 2000s, however, some textbooks have adopted the German method as it retains the order between the divisor and the dividend.

Algorithm for arbitrary base
Every natural number n{\displaystyle n} can be uniquely represented in an arbitrary number base b>1{\displaystyle b>1} as a sequence of digits n=α0α1α2...αk−1{\displaystyle n=\alpha _{0}\alpha _{1}\alpha _{2}...\alpha _{k-1}} where 0≤αi<b{\displaystyle 0\leq \alpha _{i}<b} for all 0≤i<k{\displaystyle 0\leq i<k}, where k{\displaystyle k} is the number of digits in n{\displaystyle n}. The value of n{\displaystyle n} in terms of its digits and the base is

n=∑i=0k−1αibk−i−1{\displaystyle n=\sum _{i=0}^{k-1}\alpha _{i}b^{k-i-1}}Let n{\displaystyle n} be the dividend and m{\displaystyle m} be the divisor, where l{\displaystyle l} is the number of digits in m{\displaystyle m}. If k<l{\displaystyle k<l}, then quotient q=0{\displaystyle q=0} and remainder r=n{\displaystyle r=n}. Otherwise, we iterate from 0≤i≤k−l{\displaystyle 0\leq i\leq k-l}, before stopping.
For each iteration i{\displaystyle i}, let qi{\displaystyle q_{i}} be the quotient extracted so far, di{\displaystyle d_{i}} be the intermediate dividend, ri{\displaystyle r_{i}} be the intermediate remainder, αi{\displaystyle \alpha _{i}} be the next digit of the original dividend, and βi{\displaystyle \beta _{i}} be the next digit of the quotient. By definition of digits in base b{\displaystyle b}, 0≤βi<b{\displaystyle 0\leq \beta _{i}<b}. By definition of remainder, 0≤ri<m{\displaystyle 0\leq r_{i}<m}. All values are natural numbers. We initiate 

q−1=0{\displaystyle q_{-1}=0}
r−1=∑i=0l−2αibl−2−i{\displaystyle r_{-1}=\sum _{i=0}^{l-2}\alpha _{i}b^{l-2-i}}the first l−1{\displaystyle l-1} digits of n{\displaystyle n}.
With every iteration, the three equations are true:

di=bri−1+αi+l−1{\displaystyle d_{i}=br_{i-1}+\alpha _{i+l-1}}
ri=di−mβi=bri−1+αi+l−1−mβi{\displaystyle r_{i}=d_{i}-m\beta _{i}=br_{i-1}+\alpha _{i+l-1}-m\beta _{i}}
qi=bqi−1+βi{\displaystyle q_{i}=bq_{i-1}+\beta _{i}}There only exists one such βi{\displaystyle \beta _{i}} such that 0≤ri<m{\displaystyle 0\leq r_{i}<m}.

The final quotient is q=qk−l{\displaystyle q=q_{k-l}} and the final remainder is r=rk−l{\displaystyle r=r_{k-l}}

Examples
In base 10, using the example above with n=1260257{\displaystyle n=1260257} and m=37{\displaystyle m=37}, the initial values q−1=0{\displaystyle q_{-1}=0} and r−1=1{\displaystyle r_{-1}=1}.

Thus, q=34061{\displaystyle q=34061} and r=0{\displaystyle r=0}.
In base 16, with n=f412df{\displaystyle n={\text{f412df}}} and m=12{\displaystyle m=12}, the initial values are q−1=0{\displaystyle q_{-1}=0} and r−1=f{\displaystyle r_{-1}={\text{f}}}.

Thus, q=d8f45{\displaystyle q={\text{d8f45}}} and r=5{\displaystyle r={\text{5}}}.
If one doesn't have the addition, subtraction, or multiplication tables for base b memorised, then this algorithm still works if the numbers are converted to decimal and at the end are converted back to base b. For example, with the above example, 

n=f412df16=15⋅165+4⋅164+1⋅163+2⋅162+13⋅161+15⋅160{\displaystyle n={\text{f412df}}_{16}=15\cdot 16^{5}+4\cdot 16^{4}+1\cdot 16^{3}+2\cdot 16^{2}+13\cdot 16^{1}+15\cdot 16^{0}}and 

m=1216=1⋅161+2⋅160=18{\displaystyle m={\text{12}}_{16}=1\cdot 16^{1}+2\cdot 16^{0}=18}with b=16{\displaystyle b=16}. The initial values are q−1=0{\displaystyle q_{-1}=0} and r−1=15{\displaystyle r_{-1}=15}.

Thus, q=164⋅13+163⋅8+162⋅15+161⋅4+5=d8f4516{\displaystyle q=16^{4}\cdot 13+16^{3}\cdot 8+16^{2}\cdot 15+16^{1}\cdot 4+5={\text{d8f45}}_{16}} and r=5=516{\displaystyle r=5={\text{5}}_{16}}.
This algorithm can be done using the same kind of pencil-and-paper notations as shown in above sections.

          d8f45 r. 5
    12 ) f412df
         ea
          a1
          90
          112
          10e
            4d
            48
             5f
             5a
              5

Rational quotients
If the quotient is not constrained to be an integer, then the algorithm does not terminate for i>k−l{\displaystyle i>k-l}. Instead, if i>k−l{\displaystyle i>k-l} then αi=0{\displaystyle \alpha _{i}=0} by definition. If the remainder ri{\displaystyle r_{i}} is equal to zero at any iteration, then the quotient is a b{\displaystyle b}-adic fraction, and is represented as a finite decimal expansion in base b{\displaystyle b} positional notation. Otherwise, it is still a rational number but not a b{\displaystyle b}-adic rational, and is instead represented as an infinite repeating decimal expansion in base b{\displaystyle b} positional notation.

Binary division
Performance
On each iteration, the most time-consuming task is to select βi{\displaystyle \beta _{i}}. We know that there are b{\displaystyle b} possible values, so we can find βi{\displaystyle \beta _{i}} using O(log⁡(b)){\displaystyle O(\log(b))} comparisons. Each comparison will require evaluating di−mβi{\displaystyle d_{i}-m\beta _{i}}. Let k{\displaystyle k} be the number of digits in the dividend n{\displaystyle n} and l{\displaystyle l} be the number of digits in the divisor m{\displaystyle m}. The number of digits in di≤l+1{\displaystyle d_{i}\leq l+1}. The multiplication of mβi{\displaystyle m\beta _{i}} is therefore O(l){\displaystyle O(l)}, and likewise the subtraction of di−mβi{\displaystyle d_{i}-m\beta _{i}}. Thus it takes O(llog⁡(b)){\displaystyle O(l\log(b))} to select βi{\displaystyle \beta _{i}}. The remainder of the algorithm are addition and the digit-shifting of qi{\displaystyle q_{i}} and ri{\displaystyle r_{i}} to the left one digit, and so takes time O(k){\displaystyle O(k)} and O(l){\displaystyle O(l)} in base b{\displaystyle b}, so each iteration takes O(llog⁡(b)+k+l){\displaystyle O(l\log(b)+k+l)}, or just O(llog⁡(b)+k){\displaystyle O(l\log(b)+k)}. For all k−l+1{\displaystyle k-l+1} digits, the algorithm takes time O((k−l+1)(llog⁡(b)+k)){\displaystyle O((k-l+1)(l\log(b)+k))}, or O(kllog⁡(b)+k2){\displaystyle O(kl\log(b)+k^{2})} in base b{\displaystyle b}.

Generalizations
Rational numbers
Long division of integers can easily be extended to include non-integer dividends, as long as they are rational. This is because every rational number has a recurring decimal expansion. The procedure can also be extended to include divisors which have a finite or terminating decimal expansion (i.e. decimal fractions). In this case the procedure involves multiplying the divisor and dividend by the appropriate power of ten so that the new divisor is an integer – taking advantage of the fact that a ÷ b = (ca) ÷ (cb) –  and then proceeding as above.

Polynomials
A generalised version of this method called polynomial long division is also used for dividing polynomials (sometimes using a shorthand version called synthetic division).

See also
Algorism
Arbitrary-precision arithmetic
Egyptian multiplication and division
Elementary arithmetic
Fourier division
Polynomial long division
Shifting nth root algorithm – for finding square root or any nth root of a number
Short division

References
External links
Long Division Algorithm
Long Division and Euclid's Lemma",313384,https://en.wikipedia.org/wiki/Long_division
Magic state distillation,"Magic state distillation is a method for creating more accurate quantum states from multiple noisy ones, which is important for building fault tolerant quantum computers. It has also been linked to quantum contextuality, a concept thought to contribute to quantum computers' power.The technique was first proposed by Emanuel Knill in 2004,
and further analyzed by Sergey Bravyi and Alexei Kitaev the same year.Thanks to the Gottesman–Knill theorem, it is known that some quantum operations (operations in the Clifford algebra) can be perfectly simulated in polynomial time on a classical computer. In order to achieve universal quantum computation, a quantum computer must be able to perform operations outside this set. Magic state distillation achieves this, in principle, by concentrating the usefulness of imperfect resources, represented by mixed states, into states that are conducive for performing operations that are difficult to simulate classically.
A variety of qubit magic state distillation routines and distillation routines for qubits with various advantages have been proposed.","Magic state distillation is a method for creating more accurate quantum states from multiple noisy ones, which is important for building fault tolerant quantum computers. It has also been linked to quantum contextuality, a concept thought to contribute to quantum computers' power.The technique was first proposed by Emanuel Knill in 2004,
and further analyzed by Sergey Bravyi and Alexei Kitaev the same year.Thanks to the Gottesman–Knill theorem, it is known that some quantum operations (operations in the Clifford algebra) can be perfectly simulated in polynomial time on a classical computer. In order to achieve universal quantum computation, a quantum computer must be able to perform operations outside this set. Magic state distillation achieves this, in principle, by concentrating the usefulness of imperfect resources, represented by mixed states, into states that are conducive for performing operations that are difficult to simulate classically.
A variety of qubit magic state distillation routines and distillation routines for qubits with various advantages have been proposed.

Stabilizer formalism
The Clifford group consists of a set of n{\displaystyle n}-qubit operations generated by the gates {H, S, CNOT}  (where H is Hadamard and S is [100i]{\displaystyle {\begin{bmatrix}1&0\\0&i\end{bmatrix}}}) called Clifford gates. The Clifford group generates stabilizer states which can be efficiently simulated classically, as shown by the Gottesman–Knill theorem. This set of gates with a non-Clifford operation is universal for quantum computation.

Magic states
Magic states are purified from n{\displaystyle n} copies of a mixed state ρ{\displaystyle \rho }. These states are typically provided via an ancilla to the circuit. A magic state for the T{\displaystyle T} gate is |M⟩=cos⁡(β/2)|0⟩+eiπ4sin⁡(β/2)|1⟩{\displaystyle |M\rangle =\cos(\beta /2)|0\rangle +e^{i{\frac {\pi }{4}}}\sin(\beta /2)|1\rangle }  where β=arccos⁡(13){\displaystyle \beta =\arccos \left({\frac {1}{\sqrt {3}}}\right)}. By combining (copies of) magic states with Clifford gates, can be used to make a non-Clifford gate. Since Clifford gates combined with a non-Clifford gate are universal for quantum computation, magic states combined with Clifford gates are also universal.

Purification algorithm for distilling |M〉
The first magic state distillation algorithm, invented by Sergey Bravyi and Alexei Kitaev, is a follows.
Input: Prepare 5 imperfect states.
Output: An almost pure state having a small error probability.
repeat
Apply the decoding operation of the five-qubit error correcting code and measure the syndrome.
If the measured syndrome is |0000⟩{\displaystyle |0000\rangle }, the distillation attempt is successful.
else Get rid of the resulting state and restart the algorithm.
until The states have been distilled to the desired purity.


== References ==",61982153,https://en.wikipedia.org/wiki/Magic_state_distillation
Plotting algorithms for the Mandelbrot set,"There are many programs and algorithms used to plot the Mandelbrot set and other fractals, some of which are described in fractal-generating software. These programs use a variety of algorithms to determine the color of individual pixels efficiently.","There are many programs and algorithms used to plot the Mandelbrot set and other fractals, some of which are described in fractal-generating software. These programs use a variety of algorithms to determine the color of individual pixels efficiently.

Escape time algorithm
The simplest algorithm for generating a representation of the Mandelbrot set is known as the ""escape time"" algorithm. A repeating calculation is performed for each x, y point in the plot area and based on the behavior of that calculation, a color is chosen for that pixel.

Unoptimized naïve escape time algorithm
In both the unoptimized and optimized escape time algorithms, the x and y locations of each point are used as starting values in a repeating, or iterating calculation (described in detail below). The result of each iteration is used as the starting values for the next. The values are checked during each iteration to see whether they have reached a critical ""escape"" condition, or ""bailout"". If that condition is reached, the calculation is stopped, the pixel is drawn, and the next x, y point is examined. For some starting values, escape occurs quickly, after only a small number of iterations. For starting values very close to but not in the set, it may take hundreds or thousands of iterations to escape. For values within the Mandelbrot set, escape will never occur. The programmer or user must choose how many iterations–or how much ""depth""–they wish to examine. The higher the maximal number of iterations, the more detail and subtlety emerge in the final image, but the longer time it will take to calculate the fractal image.
Escape conditions can be simple or complex. Because no complex number with a real or imaginary part greater than 2 can be part of the set, a common bailout is to escape when either coefficient exceeds 2. A more computationally complex method that detects escapes sooner, is to compute distance from the origin using the Pythagorean theorem, i.e., to determine the absolute value, or modulus, of the complex number. If this value exceeds 2, or equivalently, when the sum of the squares of the real and imaginary parts exceed 4, the point has reached escape. More computationally intensive rendering variations include the Buddhabrot method, which finds escaping points and plots their iterated coordinates.
The color of each point represents how quickly the values reached the escape point. Often black is used to show values that fail to escape before the iteration limit, and gradually brighter colors are used for points that escape. This gives a visual representation of how many cycles were required before reaching the escape condition.
To render such an image, the region of the complex plane we are considering is subdivided into a certain number of pixels. To color any such pixel, let c{\displaystyle c} be the midpoint of that pixel. We now iterate the critical point 0 under Pc{\displaystyle P_{c}}, checking at each step whether the orbit point has modulus larger than 2. When this is the case, we know that c{\displaystyle c} does not belong to the Mandelbrot set, and we color our pixel according to the number of iterations used to find out. Otherwise, we keep iterating up to a fixed number of steps, after which we decide that our parameter is ""probably"" in the Mandelbrot set, or at least very close to it, and color the pixel black.
In pseudocode, this algorithm would look as follows. The algorithm does not use complex numbers and manually simulates complex-number operations using two real numbers, for those who do not have a complex data type. The program may be simplified if the programming language includes complex-data-type operations.

for each pixel (Px, Py) on the screen do
    x0 := scaled x coordinate of pixel (scaled to lie in the Mandelbrot X scale (-2.00, 0.47))
    y0 := scaled y coordinate of pixel (scaled to lie in the Mandelbrot Y scale (-1.12, 1.12))
    x := 0.0
    y := 0.0
    iteration := 0
    max_iteration := 1000
    while (x*x + y*y ≤ 2*2 AND iteration < max_iteration) do
        xtemp := x*x - y*y + x0
        y := 2*x*y + y0
        x := xtemp
        iteration := iteration + 1
 
    color := palette[iteration]
    plot(Px, Py, color)

Here, relating the pseudocode to c{\displaystyle c}, z{\displaystyle z} and Pc{\displaystyle P_{c}}:

z=x+iy {\displaystyle z=x+iy\ }
z2=x2+2ixy{\displaystyle z^{2}=x^{2}+2ixy} - y2 {\displaystyle y^{2}\ }
c=x0+iy0 {\displaystyle c=x_{0}+iy_{0}\ }and so, as can be seen in the pseudocode in the computation of x and y:

x=Re⁡(z2+c)=x2−y2+x0{\displaystyle x=\mathop {\mathrm {Re} } (z^{2}+c)=x^{2}-y^{2}+x_{0}} and y=Im⁡(z2+c)=2xy+y0. {\displaystyle y=\mathop {\mathrm {Im} } (z^{2}+c)=2xy+y_{0}.\ }To get colorful images of the set, the assignment of a color to each value of the number of executed iterations can be made using one of a variety of functions (linear, exponential, etc.). One practical way, without slowing down calculations, is to use the number of executed iterations as an entry to a palette initialized at startup. If the color table has, for instance, 500 entries, then the color selection is n mod 500, where n is the number of iterations.

Optimized escape time algorithms
The code in the previous section uses an unoptimized inner while loop for clarity. In the unoptimized version, one must perform five multiplications per iteration. To reduce the number of multiplications the following code for the inner while loop may be used instead:

x2:= 0
y2:= 0
w:= 0

while (x2 + y2 ≤ 4 and iteration < max_iteration) do
    x:= x2 - y2 + x0
    y:= w - x2 - y2 + y0
    x2:= x * x
    y2:= y * y
    w:= (x + y) * (x + y)
    iteration:= iteration + 1

The above code works via some algebraic simplification of the complex multiplication:
(iy+x)2=−y2+2iyx+x2=x2−y2+2iyx{\displaystyle {\begin{aligned}(iy+x)^{2}&=-y^{2}+2iyx+x^{2}\\&=x^{2}-y^{2}+2iyx\end{aligned}}}
Using the above identity, the number of multiplications can be reduced to three instead of five.
The above inner while loop can be further optimized by expanding w to
w=x2+2xy+y2{\displaystyle w=x^{2}+2xy+y^{2}}
Substituting w into y=w−x2−y2+y0{\displaystyle y=w-x^{2}-y^{2}+y_{0}} yields
y=2xy+y0{\displaystyle y=2xy+y_{0}}
and hence calculating w is no longer needed.
The further optimized pseudocode for the above is:

x2:= 0
y2:= 0

while (x2 + y2 ≤ 4 and iteration < max_iteration) do
    y:= 2 * x * y + y0
    x:= x2 - y2 + x0
    x2:= x * x
    y2:= y * y
    iteration:= iteration + 1

Note that in the above pseudocode, 2xy{\displaystyle 2xy} seems to increase the number of multiplications by 1, but since 2 is the multiplier the code can be optimized via (x+x)y{\displaystyle (x+x)y}.

Derivative Bailout or ""derbail""
It is common to check the magnitude of z after every iteration, but there is another method we can use that can converge faster and reveal structure within julia sets. 
Instead of checking if the magnitude of z after every iteration is larger than a given value, we can instead check if the sum of each derivative of z up to the current iteration step is larger than a given bailout value:
zn′:=(2∗zn−1′∗zn−1)+1{\displaystyle z_{n}^{\prime }:=(2*z_{n-1}^{\prime }*z_{n-1})+1}
The size of the dbail value can enhance the detail in the structures revealed within the dbail method with very large values.
It is possible to find derivatives automatically by leveraging Automatic differentiation and computing the iterations using Dual numbers.

Rendering fractals with the derbail technique can often require a large number of samples per pixel, as there can be precision issues which lead to fine detail and can result in noisy images even with samples in the hundreds or thousands.
Python code:

Coloring algorithms
In addition to plotting the set, a variety of algorithms have been developed to 

efficiently color the set in an aesthetically pleasing way
show structures of the data (scientific visualisation)

Histogram coloring
A more complex coloring method involves using a histogram which pairs each pixel with said pixel's maximum iteration count before escape/bailout. This method will equally distribute colors to the same overall area, and, importantly, is independent of the maximum number of iterations chosen.This algorithm has four passes. The first pass involves calculating the iteration counts associated with each pixel (but without any pixels being plotted). These are stored in an array: IterationCounts[x][y], where x and y are the x and y coordinates of said pixel on the screen respectively.

The first step of the second pass is to create an array of size n, which is the maximum iteration count: NumIterationsPerPixel. Next, one must iterate over the array of pixel-iteration count pairs, IterationCounts[][], and retrieve each pixel's saved iteration count, i, via e.g. i = IterationCounts[x][y]. After each pixel's iteration count i is retrieved, it is necessary to index the NumIterationsPerPixel by i and increment the indexed value (which is initially zero) -- e.g. NumIterationsPerPixel[i] = NumIterationsPerPixel[i] + 1 .

for (x = 0; x < width; x++) do
    for (y = 0; y < height; y++) do
        i:= IterationCounts[x][y]
        NumIterationsPerPixel[i]++

The third pass iterates through the NumIterationsPerPixel array and adds up all the stored values, saving them in total. The array index represents the number of pixels that reached that iteration count before bailout. 

total: = 0
for (i = 0; i < max_iterations; i++) do
    total += NumIterationsPerPixel[i]

After this, the fourth pass begins and all the values in the IterationCounts array are indexed, and, for each iteration count i, associated with each pixel, the count is added to a global sum of all the iteration counts from 1 to i in the NumIterationsPerPixel array . This value is then normalized by dividing the sum by the total value computed earlier.

hue[][]:= 0.0
for (x = 0; x < width; x++) do
    for (y = 0; y < height; y++) do
        iteration:= IterationCounts[x][y]
        for (i = 0; i <= iteration; i++) do
            hue[x][y] += NumIterationsPerPixel[i] / total /* Must be floating-point division. */

...

color = palette[hue[m, n]]

...

Finally, the computed value is used, e.g. as an index to a color palette.
This method may be combined with the smooth coloring method below for more aesthetically pleasing images.

Continuous (smooth) coloring
The escape time algorithm is popular for its simplicity. However, it creates bands of color, which, as a type of aliasing, can detract from an image's aesthetic value. This can be improved using an algorithm known as ""normalized iteration count"", which provides a smooth transition of colors between iterations. The algorithm associates a real number ν{\displaystyle \nu } with each value of z by using the connection of the iteration number with the potential function. This function is given by

ϕ(z)=limn→∞(log⁡|zn|/Pn),{\displaystyle \phi (z)=\lim _{n\to \infty }(\log |z_{n}|/P^{n}),}where zn is the value after n iterations and P is the power for which z is raised to in the Mandelbrot set equation (zn+1 = znP + c, P is generally 2).
If we choose a large bailout radius N (e.g., 10100), we have that

log⁡|zn|/Pn=log⁡(N)/Pν(z){\displaystyle \log |z_{n}|/P^{n}=\log(N)/P^{\nu (z)}}for some real number ν(z){\displaystyle \nu (z)}, and this is

ν(z)=n−logP⁡(log⁡|zn|/log⁡(N)),{\displaystyle \nu (z)=n-\log _{P}(\log |z_{n}|/\log(N)),}and as n is the first iteration number such that |zn| > N, the number we subtract from n is in the interval [0, 1).
For the coloring we must have a cyclic scale of colors (constructed mathematically, for instance) and containing H colors numbered from 0 to H − 1 (H = 500, for instance). We multiply the real number ν(z){\displaystyle \nu (z)} by a fixed real number determining the density of the colors in the picture, take the integral part of this number modulo H, and use it to look up the corresponding color in the color table.
For example, modifying the above pseudocode and also using the concept of linear interpolation would yield

for each pixel (Px, Py) on the screen do
    x0:= scaled x coordinate of pixel (scaled to lie in the Mandelbrot X scale (-2.5, 1))
    y0:= scaled y coordinate of pixel (scaled to lie in the Mandelbrot Y scale (-1, 1))
    x:= 0.0
    y:= 0.0
    iteration:= 0
    max_iteration:= 1000
    // Here N = 2^8 is chosen as a reasonable bailout radius.

    while x*x + y*y ≤ (1 << 16) and iteration < max_iteration do
        xtemp:= x*x - y*y + x0
        y:= 2*x*y + y0
        x:= xtemp
        iteration:= iteration + 1

    // Used to avoid floating point issues with points inside the set.
    if iteration < max_iteration then
        // sqrt of inner term removed using log simplification rules.
        log_zn:= log(x*x + y*y) / 2
        nu:= log(log_zn / log(2)) / log(2)
        // Rearranging the potential function.
        // Dividing log_zn by log(2) instead of log(N = 1<<8)
        // because we want the entire palette to range from the
        // center to radius 2, NOT our bailout radius.
        iteration:= iteration + 1 - nu

    color1:= palette[floor(iteration)]
    color2:= palette[floor(iteration) + 1]
    // iteration % 1 = fractional part of iteration.
    color:= linear_interpolate(color1, color2, iteration % 1)
    plot(Px, Py, color)

Exponentially mapped and cyclic iterations
Typically when we render a fractal, the range of where colors from a given palette appear along the fractal is static. If we desire to offset the location from the border of the fractal, or adjust their palette to cycle in a specific way, there are a few simple changes we can make when taking the final iteration count before passing it along to choose an item from our palette.

When we have obtained the iteration count, we can make the range of colors non-linear. Raising a value normalized to the range [0,1] to a power n, maps a linear range to an exponential range, which in our case can nudge the appearance of colors along the outside of the fractal, and allow us to bring out other colors, or push in the entire palette closer to the border.
v=((i/maxi)SN)1.5modN{\displaystyle v=((\mathbf {i} /max_{i})^{\mathbf {S} }\mathbf {N} )^{1.5}{\bmod {\mathbf {N} }}}
where i is our iteration count after bailout, max_i is our iteration limit, S is the exponent we are raising iters to, and N is the number of items in our palette. This scales the iter count non-linearly and scales the palette to cycle approximately proportionally to the zoom. 
We can then plug v into whatever algorithm we desire for generating a color.

Passing iterations into a color directly
One thing we may want to consider is avoiding having to deal with a palette or color blending at all. There are actually a handful of methods we can leverage to generate smooth, consistent coloring by constructing the color on the spot.

v refers to a normalized exponentially mapped cyclic iter count
f(v) refers to the sRGB transfer function
A naive method for generating a color in this way is by directly scaling v to 255 and passing it into RGB as such

rgb = [v * 255, v * 255, v * 255]

One flaw with this is that RGB is non-linear due to gamma; consider linear sRGB instead. Going from RGB to sRGB uses an inverse companding function on the channels. This makes the gamma linear, and allows us to properly sum the colors for sampling.

srgb = [v * 255, v * 255, v * 255]

HSV coloring
HSV Coloring can be accomplished by mapping iter count from [0,max_iter) to [0,360), taking it to the power of 1.5, and then modulo 360.

We can then simply take the exponentially mapped iter count into the value and return

hsv = [powf((i / max) * 360, 1.5) % 360, 100, (i / max) * 100]

This method applies to HSL as well, except we pass a saturation of 50% instead.

hsl = [powf((i / max) * 360, 1.5) % 360, 50, (i / max) * 100]

LCH coloring
One of the most perceptually uniform coloring methods involves passing in the processed iter count into LCH. If we utilize the exponentially mapped and cyclic method above, we can take the result of that into the Luma and Chroma channels. We can also exponentially map the iter count and scale it to 360, and pass this modulo 360 into the hue.
x∈Q+si=(i/maxi)xv=1.0−cos2(πsi)L=75−(75v)C=28+(75−75v)H=(360si)1.5mod360{\textstyle {\begin{array}{lcl}x&\in &\mathbb {Q+} \\s_{i}&=&(i/max_{i})^{\mathbf {x} }\\v&=&1.0-cos^{2}(\pi s_{i})\\L&=&75-(75v)\\C&=&28+(75-75v)\\H&=&(360s_{i})^{1.5}{\bmod {3}}60\end{array}}}
One issue we wish to avoid here is out-of-gamut colors. This can be achieved with a little trick based on the change in in-gamut colors relative to luma and chroma. As we increase luma, we need to decrease chroma to stay within gamut.

s = iters/max_i;
v = 1.0 - powf(cos(pi * s), 2.0);
LCH = [75 - (75 * v), 28 + (75 - (75 * v)), powf(360 * s, 1.5) % 360];

Advanced plotting algorithms
In addition to the simple and slow escape time algorithms already discussed, there are many other more advanced algorithms that can be used to speed up the plotting process.

Distance estimates
One can compute the distance from point c (in exterior or interior) to nearest point on the boundary of the Mandelbrot set.

Exterior distance estimation
The proof of the connectedness of the Mandelbrot set in fact gives a formula for the uniformizing map of the complement of M{\displaystyle M} (and the derivative of this map). By the Koebe quarter theorem, one can then estimate the distance between the midpoint of our pixel and the Mandelbrot set up to a factor of 4.
In other words, provided that the maximal number of iterations is sufficiently high, one obtains a picture of the Mandelbrot set with the following properties:

Every pixel that contains a point of the Mandelbrot set is colored black.
Every pixel that is colored black is close to the Mandelbrot set.The upper bound b for the distance estimate of a pixel c (a complex number) from the Mandelbrot set is given by
b=limn→∞2⋅|Pcn(c)|⋅ln⁡|Pcn(c)||∂∂cPcn(c)|,{\displaystyle b=\lim _{n\to \infty }{\frac {2\cdot |{P_{c}^{n}(c)|\cdot \ln |{P_{c}^{n}(c)}}|}{|{\frac {\partial }{\partial {c}}}P_{c}^{n}(c)|}},}where 

Pc(z){\displaystyle P_{c}(z)\,} stands for complex quadratic polynomial
Pcn(c){\displaystyle P_{c}^{n}(c)} stands for n iterations of Pc(z)→z{\displaystyle P_{c}(z)\to z} or z2+c→z{\displaystyle z^{2}+c\to z}, starting with z=c{\displaystyle z=c}: Pc0(c)=c{\displaystyle P_{c}^{0}(c)=c}, Pcn+1(c)=Pcn(c)2+c{\displaystyle P_{c}^{n+1}(c)=P_{c}^{n}(c)^{2}+c};
∂∂cPcn(c){\displaystyle {\frac {\partial }{\partial {c}}}P_{c}^{n}(c)} is the derivative of Pcn(c){\displaystyle P_{c}^{n}(c)} with respect to c. This derivative can be found by starting with ∂∂cPc0(c)=1{\displaystyle {\frac {\partial }{\partial {c}}}P_{c}^{0}(c)=1} and then ∂∂cPcn+1(c)=2⋅Pcn(c)⋅∂∂cPcn(c)+1{\displaystyle {\frac {\partial }{\partial {c}}}P_{c}^{n+1}(c)=2\cdot {}P_{c}^{n}(c)\cdot {\frac {\partial }{\partial {c}}}P_{c}^{n}(c)+1}. This can easily be verified by using the chain rule for the derivative.The idea behind this formula is simple: When the equipotential lines for the potential function ϕ(z){\displaystyle \phi (z)} lie close, the number |ϕ′(z)|{\displaystyle |\phi '(z)|} is large, and conversely, therefore the equipotential lines for the function ϕ(z)/|ϕ′(z)|{\displaystyle \phi (z)/|\phi '(z)|} should lie approximately regularly.
From a mathematician's point of view, this formula only works in limit where n goes to infinity, but very reasonable estimates can be found with just a few additional iterations after the main loop exits.
Once b is found, by the Koebe 1/4-theorem, we know that there is no point of the Mandelbrot set with distance from c smaller than b/4.
The distance estimation can be used for drawing of the boundary of the Mandelbrot set, see the article Julia set. In this approach, pixels that are sufficiently close to M are drawn using a different color. This creates drawings where the thin ""filaments"" of the Mandelbrot set can be easily seen. This technique is used to good effect in the B&W images of Mandelbrot sets in the books ""The Beauty of Fractals"" and ""The Science of Fractal Images"".Here is a sample B&W image rendered using Distance Estimates:

Distance Estimation can also be used to render 3D images of Mandelbrot and Julia sets

Interior distance estimation
It is also possible to estimate the distance of a limitly periodic (i.e., hyperbolic) point to the boundary of the Mandelbrot set. The upper bound b for the distance estimate is given by
b=1−|∂∂zPcp(z0)|2|∂∂c∂∂zPcp(z0)+∂∂z∂∂zPcp(z0)∂∂cPcp(z0)1−∂∂zPcp(z0)|,{\displaystyle b={\frac {1-\left|{{\frac {\partial }{\partial {z}}}P_{c}^{p}(z_{0})}\right|^{2}}{\left|{{\frac {\partial }{\partial {c}}}{\frac {\partial }{\partial {z}}}P_{c}^{p}(z_{0})+{\frac {\partial }{\partial {z}}}{\frac {\partial }{\partial {z}}}P_{c}^{p}(z_{0}){\frac {{\frac {\partial }{\partial {c}}}P_{c}^{p}(z_{0})}{1-{\frac {\partial }{\partial {z}}}P_{c}^{p}(z_{0})}}}\right|}},}where

p{\displaystyle p} is the period,
c{\displaystyle c} is the point to be estimated,
Pc(z){\displaystyle P_{c}(z)} is the complex quadratic polynomial Pc(z)=z2+c{\displaystyle P_{c}(z)=z^{2}+c}
Pcp(z0){\displaystyle P_{c}^{p}(z_{0})} is the p{\displaystyle p}-fold iteration of Pc(z)→z{\displaystyle P_{c}(z)\to z}, starting with Pc0(z)=z0{\displaystyle P_{c}^{0}(z)=z_{0}}
z0{\displaystyle z_{0}} is any of the p{\displaystyle p} points that make the attractor of the iterations of Pc(z)→z{\displaystyle P_{c}(z)\to z} starting with Pc0(z)=c{\displaystyle P_{c}^{0}(z)=c}; z0{\displaystyle z_{0}} satisfies z0=Pcp(z0){\displaystyle z_{0}=P_{c}^{p}(z_{0})},
∂∂c∂∂zPcp(z0){\displaystyle {\frac {\partial }{\partial {c}}}{\frac {\partial }{\partial {z}}}P_{c}^{p}(z_{0})}, ∂∂z∂∂zPcp(z0){\displaystyle {\frac {\partial }{\partial {z}}}{\frac {\partial }{\partial {z}}}P_{c}^{p}(z_{0})}, ∂∂cPcp(z0){\displaystyle {\frac {\partial }{\partial {c}}}P_{c}^{p}(z_{0})} and ∂∂zPcp(z0){\displaystyle {\frac {\partial }{\partial {z}}}P_{c}^{p}(z_{0})} are various derivatives of Pcp(z){\displaystyle P_{c}^{p}(z)}, evaluated at z0{\displaystyle z_{0}}.Analogous to the exterior case, once b is found, we know that all points within the distance of b/4 from c are inside the Mandelbrot set.
There are two practical problems with the interior distance estimate: first, we need to find z0{\displaystyle z_{0}} precisely, and second, we need to find p{\displaystyle p} precisely.
The problem with z0{\displaystyle z_{0}} is that the convergence to z0{\displaystyle z_{0}} by iterating Pc(z){\displaystyle P_{c}(z)} requires, theoretically, an infinite number of operations.
The problem with any given p{\displaystyle p} is that, sometimes, due to rounding errors, a period is falsely identified to be an integer multiple of the real period (e.g., a period of 86 is detected, while the real period is only 43=86/2). In such case, the distance is overestimated, i.e., the reported radius could contain points outside the Mandelbrot set.

Cardioid / bulb checking
One way to improve calculations is to find out beforehand whether the given point lies within the cardioid or in the period-2 bulb. Before passing the complex value through the escape time algorithm, first check that:

p=(x−14)2+y2{\displaystyle p={\sqrt {\left(x-{\frac {1}{4}}\right)^{2}+y^{2}}}},
x≤p−2p2+14{\displaystyle x\leq p-2p^{2}+{\frac {1}{4}}},
(x+1)2+y2≤116{\displaystyle (x+1)^{2}+y^{2}\leq {\frac {1}{16}}},where x represents the real value of the point and y the imaginary value. The first two equations determine that the point is within the cardioid, the last the period-2 bulb.
The cardioid test can equivalently be performed without the square root:

q=(x−14)2+y2,{\displaystyle q=\left(x-{\frac {1}{4}}\right)^{2}+y^{2},}
q(q+(x−14))≤14y2.{\displaystyle q\left(q+\left(x-{\frac {1}{4}}\right)\right)\leq {\frac {1}{4}}y^{2}.}3rd- and higher-order buds do not have equivalent tests, because they are not perfectly circular. However, it is possible to find whether the points are within circles inscribed within these higher-order bulbs, preventing many, though not all, of the points in the bulb from being iterated.

Periodicity checking
To prevent having to do huge numbers of iterations for points inside the set, one can perform periodicity checking, which checks whether a point reached in iterating a pixel has been reached before. If so, the pixel cannot diverge and must be in the set. Periodicity checking is a trade-off, as the need to remember points costs data management instructions and memory, but saves computational instructions. However, checking against only one previous iteration can detect many periods with little performance overhead. For example, within the while loop of the pseudocode above, make the following modifications:

xold:= 0
yold:= 0
period:= 0
while (x*x + y*y ≤ 2*2 and iteration < max_iteration) do
    xtemp:= x*x - y*y + x0
    y:= 2*x*y + y0
    x:= xtemp
    iteration:= iteration + 1 
 
    if x ≈ xold and y ≈ yold then
        iteration:= max_iteration  /* Set to max for the color plotting */
        break        /* We are inside the Mandelbrot set, leave the while loop */
 
    period:= period + 1
    if period > 20 then
        period:= 0
        xold:= x
        yold:= y

The above code stores away a new x and y value on every 20th iteration, thus it can detect periods that are up to 20 points long.

Border tracing / edge checking
Because the Mandelbrot set is full, any point enclosed by a closed shape whose borders lie entirely within the Mandelbrot set must itself be in the Mandelbrot set. Border tracing works by following the lemniscates of the various iteration levels (colored bands) all around the set, and then filling the entire band at once. This also provides a speed increase because large numbers of points can be now skipped.In the animation shown, points outside the set are colored with a 1000-iteration escape time algorithm. Tracing the set border and filling it, rather than iterating the interior points, reduces the total number of iterations by 93.16%. With a higher iteration limit the benefit would be even greater.

Rectangle checking
An older and simpler to implement method than border tracing is to use rectangles. There are several variations of the rectangle method. All of them are slower than border tracing because they end up calculating more pixels.
The basic method is to calculate the border pixels of a box of say 8x8 pixels. If the entire box border has the same color, then just fill in the 36 pixels (6x6) inside the box with the same color, instead of calculating them. (Mariani's algorithm.)A faster and slightly more advanced variant is to first calculate a bigger box, say 25x25 pixels. If the entire box border has the same color, then just fill the box with the same color. If not, then split the box into four boxes of 13x13 pixels, reusing the already calculated pixels as outer border, and sharing the inner ""cross"" pixels between the inner boxes. Again, fill in those boxes that has only one border color. And split those boxes that don't, now into four 7x7 pixel boxes. And then those that ""fail"" into 4x4 boxes. (Mariani-Silver algorithm.)
Even faster is to split the boxes in half instead of into four boxes. Then it might be optimal to use boxes with a 1.4:1 aspect ratio, so they can be split like how A3 papers are folded into A4 and A5 papers. (The DIN approach.)
One variant just calculates the corner pixels of each box. However this causes damaged pictures more often than calculating all box border pixels. Thus it only works reasonably well if only small boxes of say 6x6 pixels are used, and no recursing in from bigger boxes. (Fractint method.)
As with border tracing, rectangle checking only works on areas with one discrete color. But even if the outer area uses smooth/continuous coloring then  rectangle checking will still speed up the costly inner area of the Mandelbrot set. Unless the inner area also uses some smooth coloring method, for instance interior distance estimation.

Symmetry utilization
The horizontal symmetry of the Mandelbrot set allows for portions of the rendering process to be skipped upon the presence of the real axis in the final image. However, regardless of the portion that gets mirrored, the same number of points will be rendered.
Julia sets have symmetry around the origin. This means that quadrant 1 and quadrant 3 are symmetric, and quadrants 2 and quadrant 4 are symmetric. Supporting symmetry for both Mandelbrot and Julia sets requires handling symmetry differently for the two different types of graphs.

Multithreading
Escape-time rendering of Mandelbrot and Julia sets lends itself extremely well to parallel processing. On multi-core machines the area to be plotted can be divided into a series of rectangular areas which can then be provided as a set of tasks to be rendered by a pool of rendering threads. This is an embarrassingly parallel computing problem. (Note that one gets the best speed-up by first excluding symmetric areas of the plot, and then dividing the remaining unique regions into rectangular areas.)Here is a short video showing the Mandelbrot set being rendered using multithreading and symmetry, but without boundary following:

Finally, here is a video showing the same Mandelbrot set image being rendered using multithreading, symmetry, and boundary following:

Perturbation theory and series approximation
Very highly magnified images require more than the standard 64–128 or so bits of precision that most hardware floating-point units provide, requiring renderers to use slow ""BigNum"" or ""arbitrary-precision"" math libraries to calculate. However, this can be sped up by the exploitation of perturbation theory. Given

zn+1=zn2+c{\displaystyle z_{n+1}=z_{n}^{2}+c}as the iteration, and a small epsilon and delta, it is the case that

(zn+ϵ)2+(c+δ)=zn2+2znϵ+ϵ2+c+δ,{\displaystyle (z_{n}+\epsilon )^{2}+(c+\delta )=z_{n}^{2}+2z_{n}\epsilon +\epsilon ^{2}+c+\delta ,}or

=zn+1+2znϵ+ϵ2+δ,{\displaystyle =z_{n+1}+2z_{n}\epsilon +\epsilon ^{2}+\delta ,}so if one defines

ϵn+1=2znϵn+ϵn2+δ,{\displaystyle \epsilon _{n+1}=2z_{n}\epsilon _{n}+\epsilon _{n}^{2}+\delta ,}one can calculate a single point (e.g. the center of an image) using high-precision arithmetic (z), giving a reference orbit, and then compute many points around it in terms of various initial offsets delta plus the above iteration for epsilon, where epsilon-zero is set to 0. For most iterations, epsilon does not need more than 16 significant figures, and consequently hardware floating-point may be used to get a mostly accurate image. There will often be some areas where the orbits of points diverge enough from the reference orbit that extra precision is needed on those points, or else additional local high-precision-calculated reference orbits are needed. By measuring the orbit distance between the reference point and the point calculated with low precision, it can be detected that it is not possible to calculate the point correctly, and the calculation can be stopped. These incorrect points can later be re-calculated e.g. from another closer reference point.
Further, it is possible to approximate the starting values for the low-precision points with a truncated Taylor series, which often enables a significant amount of iterations to be skipped.
Renderers implementing these techniques are publicly available and offer speedups for highly magnified images by around two orders of magnitude.An alternate explanation of the above:
For the central point in the disc c{\displaystyle c} and its iterations zn{\displaystyle z_{n}}, and an arbitrary point in the disc c+δ{\displaystyle c+\delta } and its iterations zn′{\displaystyle z'_{n}}, it is possible to define the following iterative relationship:

zn′=zn+ϵn{\displaystyle z'_{n}=z_{n}+\epsilon _{n}}With ϵ1=δ{\displaystyle \epsilon _{1}=\delta }. Successive iterations of ϵn{\displaystyle \epsilon _{n}} can be found using the following:

zn+1′=zn′2+(c+δ){\displaystyle z'_{n+1}={z'_{n}}^{2}+(c+\delta )}zn+1′=(zn+ϵn)2+c+δ{\displaystyle z'_{n+1}=(z_{n}+\epsilon _{n})^{2}+c+\delta }zn+1′=zn2+c+2znϵn+ϵn2+δ{\displaystyle z'_{n+1}={z_{n}}^{2}+c+2z_{n}\epsilon _{n}+{\epsilon _{n}}^{2}+\delta }zn+1′=zn+1+2znϵn+ϵn2+δ{\displaystyle z'_{n+1}=z_{n+1}+2z_{n}\epsilon _{n}+{\epsilon _{n}}^{2}+\delta }Now from the original definition:

zn+1′=zn+1+ϵn+1{\displaystyle z'_{n+1}=z_{n+1}+\epsilon _{n+1}},It follows that:

ϵn+1=2znϵn+ϵn2+δ{\displaystyle \epsilon _{n+1}=2z_{n}\epsilon _{n}+{\epsilon _{n}}^{2}+\delta }As the iterative relationship relates an arbitrary point to the central point by a very small change δ{\displaystyle \delta }, then most of the iterations of ϵn{\displaystyle \epsilon _{n}} are also small and can be calculated using floating point hardware.
However, for every arbitrary point in the disc it is possible to calculate a value for a given ϵn{\displaystyle \epsilon _{n}} without having to iterate through the sequence from ϵ0{\displaystyle \epsilon _{0}}, by expressing ϵn{\displaystyle \epsilon _{n}} as a power series of δ{\displaystyle \delta }.

ϵn=Anδ+Bnδ2+Cnδ3+…{\displaystyle \epsilon _{n}=A_{n}\delta +B_{n}\delta ^{2}+C_{n}\delta ^{3}+\dotsc }With A1=1,B1=0,C1=0,…{\displaystyle A_{1}=1,B_{1}=0,C_{1}=0,\dotsc }.
Now given the iteration equation of ϵ{\displaystyle \epsilon }, it is possible to calculate the coefficients of the power series for each ϵn{\displaystyle \epsilon _{n}}:

ϵn+1=2znϵn+ϵn2+δ{\displaystyle \epsilon _{n+1}=2z_{n}\epsilon _{n}+{\epsilon _{n}}^{2}+\delta }ϵn+1=2zn(Anδ+Bnδ2+Cnδ3+…)+(Anδ+Bnδ2+Cnδ3+…)2+δ{\displaystyle \epsilon _{n+1}=2z_{n}(A_{n}\delta +B_{n}\delta ^{2}+C_{n}\delta ^{3}+\dotsc )+(A_{n}\delta +B_{n}\delta ^{2}+C_{n}\delta ^{3}+\dotsc )^{2}+\delta }ϵn+1=(2znAn+1)δ+(2znBn+An2)δ2+(2znCn+2AnBn)δ3+…{\displaystyle \epsilon _{n+1}=(2z_{n}A_{n}+1)\delta +(2z_{n}B_{n}+{A_{n}}^{2})\delta ^{2}+(2z_{n}C_{n}+2A_{n}B_{n})\delta ^{3}+\dotsc }Therefore, it follows that:

An+1=2znAn+1{\displaystyle A_{n+1}=2z_{n}A_{n}+1}
Bn+1=2znBn+An2{\displaystyle B_{n+1}=2z_{n}B_{n}+{A_{n}}^{2}}
Cn+1=2znCn+2AnBn{\displaystyle C_{n+1}=2z_{n}C_{n}+2A_{n}B_{n}}
⋮{\displaystyle \vdots }The coefficients in the power series can be calculated as iterative series using only values from the central point's iterations z{\displaystyle z}, and do not change for any arbitrary point in the disc. If δ{\displaystyle \delta } is very small, ϵn{\displaystyle \epsilon _{n}} should be calculable to sufficient accuracy using only a few terms of the power series. As the Mandelbrot Escape Contours are 'continuous' over the complex plane, if a points escape time has been calculated, then the escape time of that points neighbours should be similar. Interpolation of the neighbouring points should provide a good estimation of where to start in the ϵn{\displaystyle \epsilon _{n}} series.
Further, separate interpolation of both real axis points and imaginary axis points should provide both an upper and lower bound for the point being calculated. If both results are the same (i.e. both escape or do not escape) then the difference Δn{\displaystyle \Delta n} can be used to recuse until both an upper and lower bound can be established. If floating point hardware can be used to iterate the ϵ{\displaystyle \epsilon } series, then there exists a relation between how many iterations can be achieved in the time it takes to use BigNum software to compute a given ϵn{\displaystyle \epsilon _{n}}. If the difference between the bounds is greater than the number of iterations, it is possible to perform binary search using BigNum software, successively halving the gap until it becomes more time efficient to find the escape value using floating point hardware.


== References ==",63087276,https://en.wikipedia.org/wiki/Plotting_algorithms_for_the_Mandelbrot_set
Manhattan address algorithm,The Manhattan address algorithm is a series of formulas used to estimate the closest east–west cross street for building numbers on north–south avenues in the New York City borough of Manhattan.,"The Manhattan address algorithm is a series of formulas used to estimate the closest east–west cross street for building numbers on north–south avenues in the New York City borough of Manhattan.

Algorithm
To find the approximate number of the closest cross street, divide the building number by a divisor (generally 20) and add (or subtract) the ""tricky number"" from the table below:

Examples
For example, if you are at 62 Avenue B, 62÷20≈3{\displaystyle 62\div 20\approx 3}, then add the ""tricky number"" 3{\displaystyle 3} to give 6{\displaystyle 6}. The nearest cross street to 62 Avenue B is East 6th Street. 
If you are at 78 Riverside Drive, 78÷10≈8{\displaystyle 78\div 10\approx 8}, then add the ""tricky number"" 72{\displaystyle 72} to give 80{\displaystyle 80}. The nearest cross street to 78 Riverside Drive is West 80th Street. 
If you are at 501 5th Avenue, 501÷20≈25{\displaystyle 501\div 20\approx 25}, then add the ""tricky number"" 18{\displaystyle 18} to give 43{\displaystyle 43}. The nearest cross street to 501 5th Avenue is actually 42nd Street, not 43rd Street, as the Manhattan address algorithm only gives approximate answers.

See also
List of numbered streets in Manhattan
Numbered street


== References ==",26784161,https://en.wikipedia.org/wiki/Manhattan_address_algorithm
The Master Algorithm,The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World is a book by Pedro Domingos released in 2015. Domingos wrote the book in order to generate interest from people outside the field.,"The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World is a book by Pedro Domingos released in 2015. Domingos wrote the book in order to generate interest from people outside the field.

Overview
The book outlines five approaches of machine learning: inductive reasoning, connectionism, evolutionary computation, Bayes' theorem and analogical modelling. The author explains these tribes to the reader by referring to more understandable processes of logic, connections made in the brain, natural selection, probability and similarity judgments. Throughout the book, it is suggested that each different tribe has the potential to contribute to a unifying ""master algorithm"".
Towards the end of the book the author pictures a ""master algorithm"" in the near future, where machine learning algorithms asymptotically grow to a perfect understanding of how the world and people in it work. Although the algorithm doesn't yet exist, he briefly reviews his own invention of the Markov logic network.

In the media
In 2016 Bill Gates recommended the book, alongside Nick Bostrom's Superintelligence, as one of two books everyone should read to understand AI. In 2018 the book was noted to be on Chinese Communist Party general secretary Xi Jinping's bookshelf.

Reception
A computer science educator stated in Times Higher Education that the examples are clear and accessible. In contrast, The Economist agreed Domingos ""does a good job"" but complained that he ""constantly invents metaphors that grate or confuse"". Kirkus Reviews praised the book, stating that ""Readers unfamiliar with logic and computer theory will have a difficult time, but those who persist will discover fascinating insights.""A New Scientist review called it ""compelling but rather unquestioning"".

References
Further reading
https://www.wsj.com/articles/the-sum-of-human-knowledge-1442610803
http://www.kdnuggets.com/2015/09/book-master-algorithm-pedro-domingos.html
http://www.kdnuggets.com/2014/08/interview-pedro-domingos-master-algorithm-new-deep-learning.html (interview)

External links
Official website",47937215,https://en.wikipedia.org/wiki/The_Master_Algorithm
Maze generation algorithm,Maze generation algorithms are automated methods for the creation of mazes.,"Maze generation algorithms are automated methods for the creation of mazes.

Graph theory based methods
A maze can be generated by starting with a predetermined arrangement of cells (most commonly a rectangular grid but other arrangements are possible) with wall sites between them. This predetermined arrangement can be considered as a connected graph with the edges representing possible wall sites and the nodes representing cells. The purpose of the maze generation algorithm can then be considered to be making a subgraph in which it is challenging to find a route between two particular nodes.
If the subgraph is not connected, then there are regions of the graph that are wasted because they do not contribute to the search space.  If the graph contains loops, then there may be multiple paths between the chosen nodes.  Because of this, maze generation is often approached as generating a random spanning tree.  Loops, which can confound naive maze solvers, may be introduced by adding random edges to the result during the course of the algorithm.
The animation shows the maze generation steps for a 
graph that is not on a rectangular grid.
First, the computer creates a random planar graph G
shown in blue, and its dual F
shown in yellow. Second, the computer traverses F using a chosen
algorithm, such as a depth-first search, coloring the path red.
During the traversal, whenever a red edge crosses over a blue edge,
the blue edge is removed.
Finally, when all vertices of F have been visited, F is erased
and two edges from G, one for the entrance and one for the exit, are removed.

Randomized depth-first search
This algorithm, also known as the ""recursive backtracker"" algorithm, is a randomized version of the depth-first search algorithm.
Frequently implemented with a stack, this approach is one of the simplest ways to generate a maze using a computer. Consider the space for a maze being a large grid of cells (like a large chess board), each cell starting with four walls. Starting from a random cell, the computer then selects a random neighbouring cell that has not yet been visited. The computer removes the wall between the two cells and marks the new cell as visited, and adds it to the stack to facilitate backtracking. The computer continues this process, with a cell that has no unvisited neighbours being considered a dead-end. When at a dead-end it backtracks through the path until it reaches a cell with an unvisited neighbour, continuing the path generation by visiting this new, unvisited cell (creating a new junction). This process continues until every cell has been visited, causing the computer to backtrack all the way back to the beginning cell. We can be sure every cell is visited.
As given above this algorithm involves deep recursion which may cause stack overflow issues on some computer architectures. The algorithm can be rearranged into a loop by storing backtracking information in the maze itself. This also provides a quick way to display a solution, by starting at any given point and backtracking to the beginning.

Mazes generated with a depth-first search have a low branching factor and contain many long corridors, because the algorithm explores as far as possible along each branch before backtracking.

Recursive implementation
The depth-first search algorithm of maze generation is frequently implemented using backtracking. This can be described with a following recursive routine:

Given a current cell as a parameter
Mark the current cell as visited
While the current cell has any unvisited neighbour cells
Choose one of the unvisited neighbours
Remove the wall between the current cell and the chosen cell
Invoke the routine recursively for the chosen cellwhich is invoked once for any initial cell in the area.

Iterative implementation (with stack)
A disadvantage of the first approach is a large depth of recursion – in the worst case, the routine may need to recur on every cell of the area being processed, which may exceed the maximum recursion stack depth in many environments. As a solution, the same backtracking method can be implemented with an explicit stack, which is usually allowed to grow much bigger with no harm.

Choose the initial cell, mark it as visited and push it to the stack
While the stack is not empty
Pop a cell from the stack and make it a current cell
If the current cell has any neighbours which have not been visited
Push the current cell to the stack
Choose one of the unvisited neighbours
Remove the wall between the current cell and the chosen cell
Mark the chosen cell as visited and push it to the stack

Iterative randomized Kruskal's algorithm (with sets)
This algorithm is a randomized version of Kruskal's algorithm.

Create a list of all walls, and create a set for each cell, each containing just that one cell.
For each wall, in some random order:
If the cells divided by this wall belong to distinct sets:
Remove the current wall.
Join the sets of the formerly divided cells.There are several data structures that can be used to model the sets of cells.  An efficient implementation using a disjoint-set data structure can perform each union and find operation on two sets in nearly constant amortized time (specifically, O(α(V)){\displaystyle O(\alpha (V))} time; α(x)<5{\displaystyle \alpha (x)<5} for any plausible value of x{\displaystyle x}), so the running time of this algorithm is essentially proportional to the number of walls available to the maze.
It matters little whether the list of walls is initially randomized or if a wall is randomly chosen from a nonrandom list, either way is just as easy to code.
Because the effect of this algorithm is to produce a minimal spanning tree from a graph with equally weighted edges, it tends to produce regular patterns which are fairly easy to solve.

Iterative randomized Prim's algorithm (without stack, without sets)
This algorithm is a randomized version of Prim's algorithm.

Start with a grid full of walls.
Pick a cell, mark it as part of the maze. Add the walls of the cell to the wall list.
While there are walls in the list:
Pick a random wall from the list. If only one of the cells that the wall divides is visited, then:
Make the wall a passage and mark the unvisited cell as part of the maze.
Add the neighboring walls of the cell to the wall list.
Remove the wall from the list.Note that simply running classical Prim's on a graph with random edge weights would create mazes stylistically identical to Kruskal's, because they are both minimal spanning tree algorithms.  Instead, this algorithm introduces stylistic variation because the edges closer to the starting point have a lower effective weight.

Modified version
Although the classical Prim's algorithm keeps a list of edges, for maze generation we could instead maintain a list of adjacent cells. If the randomly chosen cell has multiple edges that connect it to the existing maze, select one of these edges at random. This will tend to branch slightly more than the edge-based version above.

Simplified version
The algorithm can be simplified even further by randomly selecting cells that neighbour already-visited cells, rather than keeping track of the weights of all cells or edges.
It will usually be relatively easy to find the way to the starting cell, but hard to find the way anywhere else.

Wilson's algorithm
All the above algorithms have biases of various sorts: depth-first search is biased toward long corridors, while Kruskal's/Prim's algorithms are biased toward many short dead ends. Wilson's algorithm, on the other hand, generates an unbiased sample from the uniform distribution over all mazes, using loop-erased random walks.
We begin the algorithm by initializing the maze with one cell chosen arbitrarily. Then we start at a new cell chosen arbitrarily, and perform a random walk until we reach a cell already in the maze—however, if at any point the random walk reaches its own path, forming a loop, we erase the loop from the path before proceeding. When the path reaches the maze, we add it to the maze. Then we perform another loop-erased random walk from another arbitrary starting cell, repeating until all cells have been filled.
This procedure remains unbiased no matter which method we use to arbitrarily choose starting cells. So we could always choose the first unfilled cell in (say) left-to-right, top-to-bottom order for simplicity.

Aldous-Broder algorithm
The Aldous-Broder algorithm also produces uniform spanning trees. However, it is one of the least efficient maze algorithms.
Pick a random cell as the current cell and mark it as visited.
While there are unvisited cells:
Pick a random neighbour.
If the chosen neighbour has not been visited:
Remove the wall between the current cell and the chosen neighbour.
Mark the chosen neighbour as visited.
Make the chosen neighbour the current cell.

Recursive division method
Mazes can be created with recursive division, an algorithm which works as follows: Begin with the maze's space with no walls. Call this a chamber. Divide the chamber with a randomly positioned wall (or multiple walls) where each wall contains a randomly positioned passage opening within it. Then recursively repeat the process on the subchambers until all chambers are minimum sized. This method results in mazes with long straight walls crossing their space, making it easier to see which areas to avoid.
For example, in a rectangular maze, build at random points two walls that are perpendicular to each other. These two walls divide the large chamber into four smaller chambers separated by four walls. Choose three of the four walls at random, and open a one cell-wide hole at a random point in each of the three. Continue in this manner recursively, until every chamber has a width of one cell in either of the two directions.

Tessellation algorithm
This is a simple and fast way to generate a maze.On each iteration, this algorithm creates a maze twice the size by copying itself 3 times. At the end of each iteration, 3 paths are opened between the 4 smaller mazes.
The advantage of this method is that it is very fast. The downside is that it is not possible to get a maze of a chosen size - but various tricks can be used to get around this problem.

Simple algorithms
Other algorithms exist that require only enough memory to store one line of a 2D maze or one plane of a 3D maze. Eller's algorithm prevents loops by storing which cells in the current line are connected through cells in the previous lines, and never removes walls between any two cells already connected. The Sidewinder algorithm starts with an open passage along the entire top row, and subsequent rows consist of shorter horizontal passages with one connection to the passage above. The Sidewinder algorithm is trivial to solve from the bottom up because it has no upward dead ends. Given a starting width, both algorithms create perfect mazes of unlimited height.
Most maze generation algorithms require maintaining relationships between cells within it, to ensure the result will be solvable. Valid simply connected mazes can however be generated by focusing on each cell independently. A binary tree maze is a standard orthogonal maze where each cell always has a passage leading up or leading left, but never both. To create a binary tree maze, for each cell flip a coin to decide whether to add a passage leading up or left. Always pick the same direction for cells on the boundary, and the result will be a valid simply connected maze that looks like a binary tree, with the upper left corner its root. As with Sidewinder, the binary tree maze has no dead ends in the directions of bias.

A related form of flipping a coin for each cell is to create an image using a random mix of forward slash and backslash characters. This doesn't generate a valid simply connected maze, but rather a selection of closed loops and unicursal passages.  The manual for the Commodore 64 presents a BASIC program using this algorithm, using PETSCII diagonal line graphic characters instead for a smoother graphic appearance.

Cellular automaton algorithms
Certain types of cellular automata can be used to generate mazes. Two well-known such cellular automata, Maze and Mazectric, have rulestrings B3/S12345 and B3/S1234. In the former, this means that cells survive from one generation to the next if they have at least one and at most five neighbours. In the latter, this means that cells survive if they have one to four neighbours. If a cell has exactly three neighbours, it is born. It is similar to Conway's Game of Life in that patterns that do not have a living cell adjacent to 1, 4, or 5 other living cells in any generation will behave identically to it. However, for large patterns, it behaves very differently from Life.For a random starting pattern, these maze-generating cellular automata will evolve into complex mazes with well-defined walls outlining corridors. Mazecetric, which has the rule B3/S1234 has a tendency to generate longer and straighter corridors compared with Maze, with the rule B3/S12345. Since these cellular automaton rules are deterministic, each maze generated is uniquely determined by its random starting pattern. This is a significant drawback since the mazes tend to be relatively predictable.
Like some of the graph-theory based methods described above, these cellular automata typically generate mazes from a single starting pattern; hence it will usually be relatively easy to find the way to the starting cell, but harder to find the way anywhere else.

See also
Maze solving algorithm
Self-avoiding walk
Brute-force search

References
External links
Think Labyrinth: Maze algorithms (details on these and other maze generation algorithms)
Jamis Buck: HTML 5 Presentation with Demos of Maze generation Algorithms
Maze generation visualization
Java implementation of Prim's algorithm
Implementations of DFS maze creation algorithm in multiple languages at Rosetta Code
Armin Reichert: 34 maze algorithms in Java 8, with demo application
Coding Challenge #10.1: Maze Generator with p5.js - Part 1: Maze generation algorithm in JavaScript with p5
Maze Generator by Charles Bond, COMPUTE! Magazine, December 1981",200877,https://en.wikipedia.org/wiki/Maze_generation_algorithm
Maze-solving algorithm,"A maze-solving algorithm is an automated method for solving a maze. The random mouse, wall follower, Pledge, and Trémaux's algorithms are designed to be used inside the maze by a traveler with no prior knowledge of the maze, whereas the dead-end filling and shortest path algorithms are designed to be used by a person or computer program that can see the whole maze at once.
Mazes containing no loops are known as ""simply connected"", or ""perfect"" mazes, and are equivalent to a tree in graph theory.  Maze-solving algorithms are closely related to graph theory. Intuitively, if one pulled and stretched out the paths in the maze in the proper way, the result could be made to resemble a tree.","A maze-solving algorithm is an automated method for solving a maze. The random mouse, wall follower, Pledge, and Trémaux's algorithms are designed to be used inside the maze by a traveler with no prior knowledge of the maze, whereas the dead-end filling and shortest path algorithms are designed to be used by a person or computer program that can see the whole maze at once.
Mazes containing no loops are known as ""simply connected"", or ""perfect"" mazes, and are equivalent to a tree in graph theory.  Maze-solving algorithms are closely related to graph theory. Intuitively, if one pulled and stretched out the paths in the maze in the proper way, the result could be made to resemble a tree.

Random mouse algorithm
This is a trivial method that can be implemented by a very unintelligent robot or perhaps a mouse. It is simply to proceed following the current passage until a junction is reached, and then to make a random decision about the next direction to follow. Although such a method would always eventually find the right solution, this algorithm can be extremely slow.

Hand On Wall Rule
One effective rule for traversing mazes is the Hand On Wall Rule, also known as either the left-hand rule or the right-hand rule. If the maze is simply connected, that is, all its walls are connected together or to the maze's outer boundary, then by keeping one hand in contact with one wall of the maze the solver is guaranteed not to get lost and will reach a different exit if there is one; otherwise, the algorithm will return to the entrance having traversed every corridor next to that connected section of walls at least once. The algorithm is a depth-first in-order tree traversal.
Another perspective into why wall following works is topological. If the walls are connected, then they may be deformed into a loop or circle. Then wall following reduces to walking around a circle from start to finish. To further this idea, notice that by grouping together connected components of the maze walls, the boundaries between these are precisely the solutions, even if there is more than one solution (see figures on the right).
If the maze is not simply-connected (i.e. if the start or endpoints are in the center of the structure surrounded by passage loops, or the pathways cross over and under each other and such parts of the solution path are surrounded by passage loops), this method will not necessarily reach the goal.
Another concern is that care should be taken to begin wall-following at the entrance to the maze. If the maze is not simply-connected and one begins wall-following at an arbitrary point inside the maze, one could find themselves trapped along a separate wall that loops around on itself and containing no entrances or exits.  Should it be the case that wall-following begins late, attempt to mark the position in which wall-following began. Because wall-following will always lead you back to where you started, if you come across your starting point a second time, you can conclude the maze is not simply-connected, and you should switch to an alternative wall not yet followed. See the Pledge Algorithm, below, for an alternative methodology.
Wall-following can be done in 3D or higher-dimensional mazes if its higher-dimensional passages can be projected onto the 2D plane in a deterministic manner. For example, if in a 3D maze ""up"" passages can be assumed to lead Northwest, and ""down"" passages can be assumed to lead southeast, then standard wall following rules can apply. However, unlike in 2D, this requires that the current orientation is known, to determine which direction is the first on the left or right.

Pledge algorithm
Disjoint (where walls are not connected to the outer boundary/boundary is not closed) mazes can be solved with the wall follower method, so long as the entrance and exit to the maze are on the outer walls of the maze. If however, the solver starts inside the maze, it might be on a section disjoint from the exit, and wall followers will continually go around their ring. The Pledge algorithm (named after John Pledge of Exeter) can solve this problem.The Pledge algorithm, designed to circumvent obstacles, requires an arbitrarily chosen direction to go toward, which will be preferential. When an obstacle is met, one hand (say the right hand) is kept along the obstacle while the angles turned are counted (clockwise turn is positive, counter-clockwise turn is negative). When the solver is facing the original preferential direction again, and the angular sum of the turns made is 0, the solver leaves the obstacle and continues moving in its original direction.
The hand is removed from the wall only when both ""sum of turns made"" and ""current heading"" are at zero. This allows the algorithm to avoid traps shaped like an upper case letter ""G"". Assuming the algorithm turns left at the first wall, one gets turned around a full 360 degrees by the walls. An algorithm that only keeps track of ""current heading"" leads into an infinite loop as it leaves the lower rightmost wall heading left and runs into the curved section on the left hand side again. The Pledge algorithm does not leave the rightmost wall due to the ""sum of turns made"" not being zero at that point (note 360 degrees is not equal to 0 degrees). It follows the wall all the way around, finally leaving it heading left outside and just underneath the letter shape.
This algorithm allows a person with a compass to find their way from any point inside to an outer exit of any finite two-dimensional maze, regardless of the initial position of the solver. However, this algorithm will not work in doing the reverse, namely finding the way from an entrance on the outside of a maze to some end goal within it.

Trémaux's algorithm
Trémaux's algorithm, invented by Charles Pierre Trémaux, is an efficient method to find the way out of a maze that requires drawing lines on the floor to mark a path, and is guaranteed to work for all mazes that have well-defined passages, but it is not guaranteed to find the shortest route.
An entrance of a passage is either unvisited, marked once or marked twice. Note that marking an entrance is not the same as marking a junction or a passage, because a junction may have multiple entrances, and a passage has an entrance at both ends. Dead ends can be thought of as junctions with one entrance (imagine there being a room at each dead end).
The algorithm works according to the following rules:

Whenever you pass through an entrance of a passage, whether it is to enter or exit a junction, leave a mark at the entrance as you pass.
When you are at a junction, use the first applicable rule below to pick an entrance to exit through:
If only the entrance you just came from is marked, pick an arbitrary unmarked entrance, if any. This rule also applies if you're just starting in the middle of the maze and there are no marked entrances at all.
Pick the entrance you just came from, unless it is marked twice. This rule will apply whenever you reach a dead end.
Pick any entrance with the fewest marks (zero if possible, else one).The ""turn around and return"" rule effectively transforms any maze with loops into a simply connected one; whenever we find a path that would close a loop, we treat it as a dead end and return. Without this rule, it is possible to cut off one's access to still-unexplored parts of a maze if, instead of turning back, we arbitrarily pick another entrance.
When you finally reach the solution, entrances marked exactly once will indicate a way back to the start. If there is no exit, this method will take you back to the start where all entrances are marked twice.
In this case each passage is walked down exactly twice, once in each direction. The resulting walk is called a bidirectional double-tracing.Essentially, this algorithm, which was discovered in the 19th century, has been used about a hundred years later as depth-first search.

Dead-end filling
Dead-end filling is an algorithm for solving mazes that fills all dead ends, leaving only the correct ways unfilled. It can be used for solving mazes on paper or with a computer program, but it is not useful to a person inside an unknown maze since this method looks at the entire maze at once. The method is to

find all of the dead-ends in the maze, and then
""fill in"" the path from each dead-end until the first junction is met.Note that some passages won't become parts of dead end passages until other dead ends are removed first. A video of dead-end filling in action can be seen to the right.
Dead-end filling cannot accidentally ""cut off"" the start from the finish since each step of the process preserves the topology of the maze. Furthermore, the process won't stop ""too soon"" since the result cannot contain any dead-ends. Thus if dead-end filling is done on a perfect maze (maze with no loops), then only the solution will remain. If it is done on a partially braid maze (maze with some loops), then every possible solution will remain but nothing more. [1]

Recursive algorithm
If given an omniscient view of the maze, a simple recursive algorithm can tell one how to get to the end. The algorithm will be given a starting X and Y value. If the X and Y values are not on a wall, the method will call itself with all adjacent X and Y values, making sure that it did not already use those X and Y values before. If the X and Y values are those of the end location, it will save all the previous instances of the method as the correct path.
This is in effect a depth-first search expressed in term of grid points. The omniscient view prevents entering loops by memorization. Here is a sample code in Java:

Maze-routing algorithm
The maze-routing algorithm  is a low overhead method to find the way between any two locations of the maze. The algorithm is initially proposed for chip multiprocessors (CMPs) domain and guarantees to work for any grid-based maze. In addition to finding paths between two locations of the grid (maze), the algorithm can detect when there is no path between the source and destination. Also, the algorithm is to be used by an inside traveler with no prior knowledge of the maze with fixed memory complexity regardless of the maze size; requiring 4 variables in total for finding the path and detecting the unreachable locations. Nevertheless, the algorithm is not to find the shortest path.
Maze-routing algorithm uses the notion of Manhattan distance (MD) and relies on the property of grids that the MD increments/decrements exactly by 1 when moving from one location to any 4 neighboring locations. Here is the pseudocode without the capability to detect unreachable locations.

Shortest path algorithm
When a maze has multiple solutions, the solver may want to find the shortest path from start to finish. There are several algorithms to find shortest paths, most of them coming from graph theory. One such algorithm finds the shortest path by implementing a breadth-first search, while another, the A* algorithm, uses a heuristic technique. The breadth-first search algorithm uses a queue to visit cells in increasing distance order from the start until the finish is reached. Each visited cell needs to keep track of its distance from the start or which adjacent cell nearer to the start caused it to be added to the queue. When the finish location is found, follow the path of cells backwards to the start, which is the shortest path. The breadth-first search in its simplest form has its limitations, like finding the shortest path in weighted graphs.

See also
Mazes
Maze generation algorithm

References
External links
Think Labyrinth: Maze algorithms (details on these and other maze-solving algorithms)
MazeBlog: Solving mazes using image analysis
Video: Maze solving simulation
Simon Ayrinhac, Electric current solves mazes, © 2014 IOP Publishing Ltd.",22074859,https://en.wikipedia.org/wiki/Maze-solving_algorithm
Medical algorithm,"A medical algorithm is any computation, formula, statistical survey, nomogram, or look-up table, useful in healthcare.  Medical algorithms include decision tree approaches to healthcare treatment (e.g., if symptoms A, B, and C are evident, then use treatment X) and also less clear-cut tools aimed at reducing or defining uncertainty. A medical prescription is also a type of medical algorithm.","A medical algorithm is any computation, formula, statistical survey, nomogram, or look-up table, useful in healthcare.  Medical algorithms include decision tree approaches to healthcare treatment (e.g., if symptoms A, B, and C are evident, then use treatment X) and also less clear-cut tools aimed at reducing or defining uncertainty. A medical prescription is also a type of medical algorithm.

Scope
Medical algorithms are part of a broader field which is usually fit under the aims of medical informatics and medical decision-making. Medical decisions occur in several areas of medical activity including medical test selection, diagnosis, therapy and prognosis, and automatic control of medical equipment.
In relation to logic-based and artificial neural network-based clinical decision support systems, which are also computer applications used in the medical decision-making field, algorithms are less complex in architecture, data structure and user interface. Medical algorithms are not necessarily implemented using digital computers. In fact, many of them can be represented on paper, in the form of diagrams, nomographs, etc.

Examples
A wealth of medical information exists in the form of published medical algorithms.  These algorithms range from simple calculations to complex outcome predictions.  Most clinicians use only a small subset routinely.
Examples of medical algorithms are:

Calculators, e.g. an on-line or stand-alone calculator for body mass index (BMI) when stature and body weight are given;
Flowcharts and drakon-charts, e.g. a binary decision tree for deciding what is the etiology of chest pain
Look-up tables, e.g. for looking up food energy and nutritional contents of foodstuffs
Nomograms, e.g. a moving circular slide to calculate body surface area or drug dosages.A common class of algorithms are embedded in guidelines on the choice of treatments produced by many national, state, financial and local healthcare organisations and provided as knowledge resources for day to day use and for induction of new physicians. A field which has gained particular attention is the choice of medications for psychiatric conditions. In the United Kingdom, guidelines or algorithms for this have been produced by most of the circa 500 primary care trusts, substantially all of the circa 100 secondary care psychiatric units and many of the circa 10 000 general practices. In the US, there is a national (federal) initiative to provide them for all states, and by 2005 six states were adapting the approach of the Texas Medication Algorithm Project or otherwise working on their production.
A grammar—the Arden syntax—exists for describing algorithms in terms of medical logic modules. An approach such as this should allow exchange of MLMs between doctors and establishments, and enrichment of the common stock of tools.

Purpose
The intended purpose of medical algorithms is to improve and standardize decisions made in the delivery of medical care. Medical algorithms assist in standardizing selection and application of treatment regimens, with algorithm automation intended to reduce potential introduction of errors.  Some attempt to predict the outcome, for example critical care scoring systems.
Computerized health diagnostics algorithms can provide timely clinical decision support, improve adherence to evidence-based guidelines, and be a resource for education and research.
Medical algorithms based on best practice can assist everyone involved in delivery of standardized treatment via a wide range of clinical care providers. Many are presented as protocols and it is a key task in training to ensure people step outside the protocol when necessary.  In our present state of knowledge, generating hints and producing guidelines may be less satisfying to the authors, but more appropriate.

Cautions
In common with most science and medicine, algorithms whose contents are not wholly available for scrutiny and open to improvement should be regarded with suspicion.
Computations obtained from medical algorithms should be compared with, and tempered by, clinical knowledge and physician judgment.

See also
Artificial intelligence in healthcare
Medical guideline
Odds algorithm

Further reading
Johnson, Kathy A.; Svirbely, John R.; Sriram, M.G.; Smith, Jack W.; Kantor, Gareth; Rodriguez, Jorge Raul (November 2002). ""Automated Medical Algorithms: Issues for Medical Errors"". Journal of the American Medical Informatics Association. 9 (6 Suppl 1): s56–s57. doi:10.1197/jamia.M1228. PMC 419420.",1551981,https://en.wikipedia.org/wiki/Medical_algorithm
Miller's recurrence algorithm,"Miller's recurrence algorithm is a procedure for calculating a rapidly decreasing solution of a linear recurrence relation developed by J. C. P. Miller. It was originally developed to compute tables of the modified Bessel function but also applies to Bessel functions of the first kind and has other applications such as computation of the coefficients of  Chebyshev expansions of other special functions.Many families of special functions satisfy a recurrence relation that relates the values of the functions of different orders with common argument x{\displaystyle x}.
The modified Bessel functions of the first kind In(x){\displaystyle I_{n}(x)} satisfy the recurrence relation

In−1(x)=2nxIn(x)+In+1(x){\displaystyle I_{n-1}(x)={\frac {2n}{x}}I_{n}(x)+I_{n+1}(x)}.However, the modified Bessel functions of the second kind Kn(x){\displaystyle K_{n}(x)} also satisfy the same recurrence relation

Kn−1(x)=2nxKn(x)+Kn+1(x){\displaystyle K_{n-1}(x)={\frac {2n}{x}}K_{n}(x)+K_{n+1}(x)}.The first solution decreases rapidly with n{\displaystyle n}.  The second solution increases rapidly with n{\displaystyle n}.  Miller's algorithm provides a numerically stable procedure to obtain the decreasing solution.
To compute the terms of a recurrence a0{\displaystyle a_{0}} through aN{\displaystyle a_{N}} according to Miller's algorithm, one first chooses a value M{\displaystyle M} much larger than N{\displaystyle N} and computes a trial solution taking initial conditionaM{\displaystyle a_{M}} to an arbitrary non-zero value (such as 1) and taking aM+1{\displaystyle a_{M+1}} and later terms to be zero.  Then the recurrence relation is used to successively compute trial values for aM−1{\displaystyle a_{M-1}}, aM−2{\displaystyle a_{M-2}} down to a0{\displaystyle a_{0}}. Noting that a second sequence obtained from the trial sequence by multiplication by a constant normalizing factor will still satisfy the same recurrence relation, one can then apply a separate normalizing relationship to determine the normalizing factor that yields the actual solution.
In the example of the modified Bessel functions, a suitable normalizing relation is a summation involving the even terms of the recurrence: 

I0(x)+2∑m=1∞(−1)mI2m(x)=1{\displaystyle I_{0}(x)+2\sum _{m=1}^{\infty }(-1)^{m}I_{2m}(x)=1}where the infinite summation becomes finite due to the approximation that aM+1{\displaystyle a_{M+1}} and later terms are zero.
Finally, it is confirmed that the approximation error of the procedure is acceptable by repeating the procedure with a second choice of M{\displaystyle M} larger than the initial choice and confirming that the second set of results for a0{\displaystyle a_{0}} through aN{\displaystyle a_{N}} agree within the first set within the desired tolerance. Note that to obtain this agreement, the value of M{\displaystyle M} must be large enough such that the term aM{\displaystyle a_{M}} is small compared to the desired tolerance.
In contrast to Miller's algorithm, attempts to apply the recurrence relation in the forward direction starting from known values of I0(x){\displaystyle I_{0}(x)} and I1(x){\displaystyle I_{1}(x)} obtained by other methods will fail as rounding errors introduce components of the rapidly increasing solution.Olver and Gautschi analyses the error propagation of the algorithm in detail.
For Bessel functions of the first kind, the equivalent recurrence relation and normalizing relationship are:
Jn−1(x)=2nxJn(x)−Jn+1(x){\displaystyle J_{n-1}(x)={\frac {2n}{x}}J_{n}(x)-J_{n+1}(x)}
J0(x)+2∑m=1∞J2m(x)=1{\displaystyle J_{0}(x)+2\sum _{m=1}^{\infty }J_{2m}(x)=1}.The algorithm is particularly efficient in applications that require the values of the Bessel functions for all orders 0⋯N{\displaystyle 0\cdots N} for each value of x{\displaystyle x} compared to direct independent computations of N+1{\displaystyle N+1} separate functions.


== References ==","Miller's recurrence algorithm is a procedure for calculating a rapidly decreasing solution of a linear recurrence relation developed by J. C. P. Miller. It was originally developed to compute tables of the modified Bessel function but also applies to Bessel functions of the first kind and has other applications such as computation of the coefficients of  Chebyshev expansions of other special functions.Many families of special functions satisfy a recurrence relation that relates the values of the functions of different orders with common argument x{\displaystyle x}.
The modified Bessel functions of the first kind In(x){\displaystyle I_{n}(x)} satisfy the recurrence relation

In−1(x)=2nxIn(x)+In+1(x){\displaystyle I_{n-1}(x)={\frac {2n}{x}}I_{n}(x)+I_{n+1}(x)}.However, the modified Bessel functions of the second kind Kn(x){\displaystyle K_{n}(x)} also satisfy the same recurrence relation

Kn−1(x)=2nxKn(x)+Kn+1(x){\displaystyle K_{n-1}(x)={\frac {2n}{x}}K_{n}(x)+K_{n+1}(x)}.The first solution decreases rapidly with n{\displaystyle n}.  The second solution increases rapidly with n{\displaystyle n}.  Miller's algorithm provides a numerically stable procedure to obtain the decreasing solution.
To compute the terms of a recurrence a0{\displaystyle a_{0}} through aN{\displaystyle a_{N}} according to Miller's algorithm, one first chooses a value M{\displaystyle M} much larger than N{\displaystyle N} and computes a trial solution taking initial conditionaM{\displaystyle a_{M}} to an arbitrary non-zero value (such as 1) and taking aM+1{\displaystyle a_{M+1}} and later terms to be zero.  Then the recurrence relation is used to successively compute trial values for aM−1{\displaystyle a_{M-1}}, aM−2{\displaystyle a_{M-2}} down to a0{\displaystyle a_{0}}. Noting that a second sequence obtained from the trial sequence by multiplication by a constant normalizing factor will still satisfy the same recurrence relation, one can then apply a separate normalizing relationship to determine the normalizing factor that yields the actual solution.
In the example of the modified Bessel functions, a suitable normalizing relation is a summation involving the even terms of the recurrence: 

I0(x)+2∑m=1∞(−1)mI2m(x)=1{\displaystyle I_{0}(x)+2\sum _{m=1}^{\infty }(-1)^{m}I_{2m}(x)=1}where the infinite summation becomes finite due to the approximation that aM+1{\displaystyle a_{M+1}} and later terms are zero.
Finally, it is confirmed that the approximation error of the procedure is acceptable by repeating the procedure with a second choice of M{\displaystyle M} larger than the initial choice and confirming that the second set of results for a0{\displaystyle a_{0}} through aN{\displaystyle a_{N}} agree within the first set within the desired tolerance. Note that to obtain this agreement, the value of M{\displaystyle M} must be large enough such that the term aM{\displaystyle a_{M}} is small compared to the desired tolerance.
In contrast to Miller's algorithm, attempts to apply the recurrence relation in the forward direction starting from known values of I0(x){\displaystyle I_{0}(x)} and I1(x){\displaystyle I_{1}(x)} obtained by other methods will fail as rounding errors introduce components of the rapidly increasing solution.Olver and Gautschi analyses the error propagation of the algorithm in detail.
For Bessel functions of the first kind, the equivalent recurrence relation and normalizing relationship are:
Jn−1(x)=2nxJn(x)−Jn+1(x){\displaystyle J_{n-1}(x)={\frac {2n}{x}}J_{n}(x)-J_{n+1}(x)}
J0(x)+2∑m=1∞J2m(x)=1{\displaystyle J_{0}(x)+2\sum _{m=1}^{\infty }J_{2m}(x)=1}.The algorithm is particularly efficient in applications that require the values of the Bessel functions for all orders 0⋯N{\displaystyle 0\cdots N} for each value of x{\displaystyle x} compared to direct independent computations of N+1{\displaystyle N+1} separate functions.


== References ==",60034541,https://en.wikipedia.org/wiki/Miller%27s_recurrence_algorithm
Multiplicative weight update method,"The multiplicative weights update method is an algorithmic technique most commonly used for decision making and prediction, and also widely deployed in game theory and algorithm design. The simplest use case is the problem of prediction from expert advice, in which a decision maker needs to iteratively decide on an expert whose advice to follow. The method assigns initial weights to the experts (usually identical initial weights), and updates these weights multiplicatively and iteratively according to the feedback of how well an expert performed: reducing it in case of poor performance, and increasing it otherwise. It was discovered repeatedly in very diverse fields such as machine learning (AdaBoost, Winnow, Hedge), optimization (solving linear programs), theoretical computer science (devising fast algorithm for LPs and SDPs), and game theory.","The multiplicative weights update method is an algorithmic technique most commonly used for decision making and prediction, and also widely deployed in game theory and algorithm design. The simplest use case is the problem of prediction from expert advice, in which a decision maker needs to iteratively decide on an expert whose advice to follow. The method assigns initial weights to the experts (usually identical initial weights), and updates these weights multiplicatively and iteratively according to the feedback of how well an expert performed: reducing it in case of poor performance, and increasing it otherwise. It was discovered repeatedly in very diverse fields such as machine learning (AdaBoost, Winnow, Hedge), optimization (solving linear programs), theoretical computer science (devising fast algorithm for LPs and SDPs), and game theory.

Name
""Multiplicative weights"" implies the iterative rule used in algorithms derived from the multiplicative weight update method. It is given with different names in the different fields where it was discovered or rediscovered.

History and background
The earliest known version of this technique was in an algorithm named ""fictitious play"" which was proposed in game theory in the early 1950s. Grigoriadis and Khachiyan applied a randomized variant of ""fictitious play"" to solve two-player zero-sum games efficiently using the multiplicative weights algorithm. In this case, player allocates higher weight to the actions that had a better outcome and choose his strategy relying on these weights. In machine learning, Littlestone applied the earliest form of the multiplicative weights update rule in his famous winnow algorithm, which is similar to Minsky and Papert's earlier perceptron learning algorithm. Later, he generalized the winnow algorithm to weighted majority algorithm. Freund and Schapire followed his steps and generalized the winnow algorithm in the form of hedge algorithm.
The multiplicative weights algorithm is also widely applied in computational geometry such as Kenneth Clarkson's algorithm for linear programming (LP) with a bounded number of variables in linear time. Later, Bronnimann and Goodrich employed analogous methods to find set covers for hypergraphs with small VC dimension.In operation research and on-line statistical decision making problem field, the weighted majority algorithm and its more complicated versions have been found independently.
In computer science field, some researchers have previously observed the close relationships between multiplicative update algorithms used in different contexts. Young discovered the similarities between fast LP algorithms and Raghavan's method of pessimistic estimators for derandomization of randomized rounding algorithms; Klivans and Servedio linked boosting algorithms in learning theory to proofs of Yao's XOR Lemma; Garg and Khandekar defined a common framework for convex optimization problems that contains Garg-Konemann and Plotkin-Shmoys-Tardos as subcases.The Hedge algorithm is a special case of mirror descent.

General setup
A binary decision needs to be made based on n experts’ opinions to attain an associated payoff. In the first round, all experts’ opinions have the same weight. The decision maker will make the first decision based on the majority of the experts' prediction. Then, in each successive round, the decision maker will repeatedly update the weight of each expert's opinion depending on the correctness of his prior predictions. Real life examples includes predicting if it is rainy tomorrow or if the stock market will go up or go down.

Algorithm analysis
Halving algorithm
Given a sequential game played between an adversary and an aggregator who is advised by N experts, the goal is for the aggregator to make as few mistakes as possible. Assume there is an expert among the N experts who always gives the correct prediction. In the halving algorithm, only the consistent experts are retained. Experts who make mistakes will be dismissed. For every decision, the aggregator decides by taking a majority vote among the remaining experts. Therefore, every time the aggregator makes a mistake, at least half of the remaining experts are dismissed. The aggregator makes at most  log2(N) mistakes.

Weighted majority algorithm
Unlike halving algorithm which dismisses experts who have made mistakes, weighted majority algorithm discounts their advice. Given the same ""expert advice"" setup, suppose we have n decisions, and we need to select one decision for each loop. In each loop, every decision incurs a cost. All costs will be revealed after making the choice. The cost is 0 if the expert is correct, and 1 otherwise. this algorithm's goal is to limit its cumulative losses to roughly the same as the best of experts.
The very first algorithm that makes choice based on majority vote every iteration does not work since the majority of the experts can be wrong consistently every time. The weighted majority algorithm corrects above trivial algorithm by keeping a weight of experts instead of fixing the cost at either 1 or 0. This would make fewer mistakes compared to halving algorithm.

   Initialization: 
      Fix an η≤1/2{\displaystyle \eta \leq 1/2}. For each expert, associate the weight wi1{\displaystyle {w_{i}}^{1}}≔1.
   For t{\displaystyle t} = 1{\displaystyle {\mathit {1}}}, 2{\displaystyle {\mathit {2}}},...,T{\displaystyle T}
      1. Make the prediction given by the weighted majority of the experts' predictions based on their weightsw1t,...,wnt{\displaystyle \mathbb {w_{1}} ^{t},...,\mathbb {w_{n}} ^{t}}. That is, choose 0 or 1 depending on which prediction has a higher total weight of experts advising it (breaking ties arbitrarily). 
      2. For every expert i that predicted wrongly, decrease his weight for the next round by multiplying it by a factor of (1-η):
           wit+1{\displaystyle w_{i}^{t+1}}=(1−η)wit{\displaystyle (1-\eta )w_{i}^{t}} (update rule)

If η=0{\displaystyle \eta =0}, the weight of the expert's advice will remain the same. When η{\displaystyle \eta } increases, the weight of the expert's advice will decrease. Note that some researchers fix η=1/2{\displaystyle \eta =1/2} in weighted majority algorithm.
After T{\displaystyle T} steps, let miT{\displaystyle m_{i}^{T}} be the number of mistakes of expert i and MT{\displaystyle M^{T}} be the number of mistakes our algorithm has made. Then we have the following bound for every i{\displaystyle i}:

    MT≤2(1+η)miT+2ln⁡(n)η{\displaystyle M^{T}\leq 2(1+\eta )m_{i}^{T}+{\frac {2\ln(n)}{\eta }}}.

In particular, this holds for i which is the best expert. Since the best expert will have the least miT{\displaystyle m_{i}^{T}}, it will give the best bound on the number of mistakes made by the algorithm as a whole.

Randomized weighted majority algorithm
This algorithm can be understood as follows:Given the same setup with N experts. Consider the special situation where the proportions of experts predicting positive and negative, counting the weights, are both close to 50%. Then, there might be a tie. Following the weight update rule in weighted majority algorithm, the predictions made by the algorithm would be randomized. The algorithm calculates the probabilities of experts predicting positive or negatives, and then makes a random decision based on the computed fraction:predict  

f(x)={1with probabilityq1W0otherwise{\displaystyle f(x)={\begin{cases}1&{\text{with probability}}{\frac {q_{1}}{W}}\\0&{\text{otherwise}}\end{cases}}}where    

 W=∑iwi=q0+q1{\displaystyle W=\sum _{i}{w_{i}}=q_{0}+q_{1}}.

The number of mistakes made by the randomized weighted majority algorithm is bounded as: 

 E[#mistakes of the learner]≤αβ(# mistakes of the best expert)+cβln⁡(N){\displaystyle E\left[\#{\text{mistakes of the learner}}\right]\leq \alpha _{\beta }\left(\#{\text{ mistakes of the best expert}}\right)+c_{\beta }\ln(N)}

where     αβ=ln⁡(1β)1−β{\displaystyle \alpha _{\beta }={\frac {\ln({\frac {1}{\beta }})}{1-\beta }}} and          cβ=11−β{\displaystyle c_{\beta }={\frac {1}{1-\beta }}}.
Note that only the learning algorithm is randomized. The underlying assumption is that the examples and experts' predictions are not random. The only randomness is the randomness where the learner makes his own prediction.
In this randomized algorithm, αβ→1{\displaystyle \alpha _{\beta }\rightarrow 1} if β→1{\displaystyle \beta \rightarrow 1}. Compared to weighted algorithm, this randomness halved the number of mistakes the algorithm is going to make. However, it is important to note that in some research, people define η=1/2{\displaystyle \eta =1/2} in weighted majority algorithm and allow 0≤η≤1{\displaystyle 0\leq \eta \leq 1} in randomized weighted majority algorithm.

Applications
The multiplicative weights method is usually used to solve a constrained optimization problem. Let each expert be the constraint in the problem, and the events represent the points in the area of interest. The punishment of the expert corresponds to how well its corresponding constraint is satisfied on the point represented by an event.

Solving zero-sum games approximately (Oracle algorithm):
Suppose we were given the distribution P{\displaystyle P} on experts. Let A{\displaystyle A} = payoff matrix of a finite two-player zero-sum game, with n{\displaystyle n} rows.
When the row player pr{\displaystyle p_{r}} uses plan i{\displaystyle i} and the column player pc{\displaystyle p_{c}} uses plan j{\displaystyle j}, the payoff of player pc{\displaystyle p_{c}} is A(i,j){\displaystyle A\left(i,j\right)}≔Aij{\displaystyle A_{ij}}, assuming A(i,j)∈[0,1]{\displaystyle A\left(i,j\right)\in \left[0,1\right]}.
If player pr{\displaystyle p_{r}} chooses action i{\displaystyle i} from a distribution P{\displaystyle P} over the rows, then the expected result for player pc{\displaystyle p_{c}} selecting action j{\displaystyle j} is A(P,j)=Ei∈P[A(i,j)]{\displaystyle A\left(P,j\right)=E_{i\in P}\left[A\left(i,j\right)\right]}.
To maximize A(P,j){\displaystyle A\left(P,j\right)}, player pc{\displaystyle p_{c}} should choose plan j{\displaystyle j}. Similarly, the expected payoff for player pl{\displaystyle p_{l}} is A(i,P)=Ej∈P[A(i,j)]{\displaystyle A\left(i,P\right)=E_{j\in P}\left[A\left(i,j\right)\right]}. Choosing plan i{\displaystyle i} would minimize this payoff. By John Von Neumann's Min-Max Theorem, we obtain:

                                          minPmaxjA(P,j)=maxQminiA(i,Q){\displaystyle \min _{P}\max _{j}A\left(P,j\right)=\max _{Q}\min _{i}A\left(i,Q\right)}

where P and i changes over the distributions over rows, Q and j changes over the columns.
Then, let λ∗{\displaystyle \lambda ^{*}} denote the common value of above quantities, also named as the ""value of the game"". Let δ>0{\displaystyle \delta >0} be an error parameter. To solve the zero-sum game bounded by additive error of δ{\displaystyle \delta },

                                                 λ∗−δ≤miniA(i,q){\displaystyle \lambda ^{*}-\delta \leq \min _{i}A\left(i,q\right)}
                                                 maxjA(p,j)≤λ∗+δ{\displaystyle \max _{j}A\left(p,j\right)\leq \lambda ^{*}+\delta }

So there is an algorithm solving zero-sum game up to an additive factor of δ using O(log2(n)/δ2{\displaystyle \delta ^{2}}) calls to ORACLE, with an additional processing time of O(n) per callBailey and Piliouras showed that although the time average behavior of multiplicative weights update converges to Nash equilibria in zero-sum games the day-to-day (last iterate) behavior diverges away from it.

Machine learning
In machine learning, Littlestone and Warmuth generalized the winnow algorithm to the weighted majority algorithm. Later, Freund and Schapire generalized it in the form of hedge algorithm. AdaBoost Algorithm formulated by Yoav Freund and Robert Schapire also employed the Multiplicative Weight Update Method.

Winnow algorithm
Based on current knowledge in algorithms, the multiplicative weight update method was first used in Littlestone's winnow algorithm. It is used in machine learning to solve a linear program.
Given m{\displaystyle m} labeled examples (a1,l1),…,(am,lm){\displaystyle \left(a_{1},l_{1}\right),{\text{…}},\left(a_{m},l_{m}\right)} where aj∈Rn{\displaystyle a_{j}\in \mathbb {R} ^{n}} are feature vectors, and lj∈{−1,1}{\displaystyle l_{j}\in \left\{-1,1\right\}\quad } are their labels.
The aim is to find non-negative weights such that for all examples, the sign of the weighted combination of the features matches its labels. That is, require that ljajx≥0{\displaystyle l_{j}a_{j}x\geq 0} for all j{\displaystyle j}. Without loss of generality, assume the total weight is 1 so that they form a distribution. Thus, for notational convenience, redefine aj{\displaystyle a_{j}} to be ljaj{\displaystyle l_{j}a_{j}}, the problem reduces to finding a solution to the following LP:

                     ∀j=1,2,…,m:ajx≥0{\displaystyle \forall j=1,2,{\text{…}},m:a_{j}x\geq 0},
                     1∗x=1{\displaystyle 1*x=1},
                     ∀i:xi≥0{\displaystyle \forall i:x_{i}\geq 0}.

This is general form of LP.

Hedge algorithm
The hedge algorithm is similar to the weighted majority algorithm. However, their exponential update rules are different.
It is generally used to solve the problem of binary allocation in which we need to allocate different portion of resources into N different options. The loss with every option is available at the end of every iteration. The goal is to reduce the total loss suffered for a particular allocation. The allocation for the following iteration is then revised, based on the total loss suffered in the current iteration using multiplicative update.

Analysis
Assume the learning rate η>0{\displaystyle \eta >0} and for t∈[T]{\displaystyle t\in [T]}, pt{\displaystyle p^{t}} is picked by Hedge. Then for all experts i{\displaystyle i},

                                ∑t≤Tptmt≤∑t≤Tmit+ln⁡(N)η+ηT{\displaystyle \sum _{t\leq T}p^{t}m^{t}\leq \sum _{t\leq T}m_{i}^{t}+{\frac {\ln(N)}{\eta }}+\eta T}

Initialization: Fix an η>0{\displaystyle \eta >0}. For each expert, associate the weight wi1{\displaystyle w_{i}^{1}} ≔1
For t=1,2,...,T:

      1. Pick the distribution pit=witΦt{\displaystyle p_{i}^{t}={\frac {w_{i}^{t}}{\Phi t}}} where Φt=∑iwit{\displaystyle \Phi t=\sum _{i}w_{i}^{t}}.
      2. Observe the cost of the decision mt{\displaystyle m^{t}}. 
      3. Set 
                              wit+1=witexp⁡(−ηmit{\displaystyle w_{i}^{t+1}=w_{i}^{t}\exp(-\eta m_{i}^{t}}).

AdaBoost algorithm
This algorithm maintains a set of weights wt{\displaystyle w^{t}} over the training examples. On every iteration t{\displaystyle t}, a distribution pt{\displaystyle p^{t}} is computed by normalizing these weights. This distribution is fed to the weak learner WeakLearn which generates a hypothesis ht{\displaystyle h_{t}} that (hopefully) has small error with respect to the distribution. Using the new hypothesis ht{\displaystyle h_{t}}, AdaBoost generates the next weight vector wt+1{\displaystyle w^{t+1}}. The process repeats. After T such iterations, the final hypothesis hf{\displaystyle h_{f}} is the output. The hypothesis hf{\displaystyle h_{f}} combines the outputs of the T weak hypotheses using a weighted majority vote.
Input: 
      Sequence of N{\displaystyle N} labeled examples (x1{\displaystyle x_{1}},y1{\displaystyle y_{1}}),...,(xN{\displaystyle x_{N}}, yN{\displaystyle y_{N}})
      Distribution D{\displaystyle D} over the N{\displaystyle N} examples
      Weak learning algorithm ""'WeakLearn""'
      Integer T{\displaystyle T} specifying number of iterations
Initialize the weight vector: wi1=D(i){\displaystyle w_{i}^{1}=D(i)} for i=1,2,...,N{\displaystyle i=1,2,...,N}.
Do for t=1,2,...,T{\displaystyle t=1,2,...,T}
      1. Set pt=wt∑i=1Nwit{\displaystyle p^{t}={\frac {w^{t}}{\sum _{i=1}^{N}w_{i}^{t}}}}.
      2. Call WeakLearn, providing it with the distribution pt{\displaystyle p^{t}}; get back a hypothesis ht:X→{\displaystyle h_{t}:X\rightarrow } [0,1].
      3. Calculate the error of ht:ϵt=∑i=1Npit|ht(xi)−yi|{\displaystyle h_{t}:\epsilon _{t}=\sum _{i=1}^{N}p_{i}^{t}|h_{t}(x_{i})-y_{i}|}.
      4. Set βt=ϵt1−ϵt{\displaystyle \beta _{t}={\frac {\epsilon _{t}}{1-\epsilon _{t}}}}.                                     
      5. Set the new weight vector to be wit+1=witβt1−|ht(xi)−yi|{\displaystyle w_{i}^{t+1}=w_{i}^{t}\beta _{t}^{1-|h_{t}(x_{i})-y_{i}|}}.

Output the hypothesis:

      f(x)=hf(x)={1if∑t=1T(log⁡(1/βt))ht(x)≥12∑t=1Tlog⁡(1/βt)0otherwise{\displaystyle f(x)=h_{f}(x)={\begin{cases}1&{\text{if}}\sum _{t=1}^{T}(\log(1/\beta _{t}))h_{t}(x)\geq {\frac {1}{2}}\sum _{t=1}^{T}\log(1/\beta _{t})\\0&{\text{otherwise}}\end{cases}}}

Solving linear programs approximately
Problem
Given a m×n{\displaystyle m\times n} matrix A{\displaystyle A} and b∈Rn{\displaystyle b\in \mathbb {R} ^{n}}, is there a x{\displaystyle x} such that Ax≥b{\displaystyle Ax\geq b}?

                      ∃?x:Ax≥b{\displaystyle \exists ?x:Ax\geq b}              (1)

Assumption
Using the oracle algorithm in solving zero-sum problem, with an error parameter ϵ>0{\displaystyle \epsilon >0}, the output would either be a point x{\displaystyle x} such that Ax≥b−ϵ{\displaystyle Ax\geq b-\epsilon } or a proof that x{\displaystyle x} does not exist, i.e., there is no solution to this linear system of inequalities.

Solution
Given vector p∈Δn{\displaystyle p\in \Delta _{n}}, solves the following relaxed problem

                     ∃?x:pTAx≥pTb{\displaystyle \exists ?x:p^{\textsf {T}}\!\!Ax\geq p^{\textsf {T}}\!b}             (2)

If there exists a x satisfying (1), then x satisfies (2) for all p∈Δn{\displaystyle p\in \Delta _{n}}. The contrapositive of this statement is also true.
Suppose if oracle returns a feasible solution for a p{\displaystyle p}, the solution x{\displaystyle x} it returns has bounded width maxi|(Ax)i−bi|≤1{\displaystyle \max _{i}|{(Ax)}_{i}-b_{i}|\leq 1}.
So if there is a solution to (1), then there is an algorithm that its output x satisfies the system (2) up to an additive error of 2ϵ{\displaystyle 2\epsilon }. The algorithm makes at most ln⁡(m)ϵ2{\displaystyle {\frac {\ln(m)}{\epsilon ^{2}}}} calls to a width-bounded oracle for the problem (2). The contrapositive stands true as well. The multiplicative updates is applied in the algorithm in this case.

Other applications
Evolutionary game theory
Multiplicative weights update is the discrete-time variant of the replicator equation (replicator dynamics), which is a commonly used model in evolutionary game theory. It converges to Nash equilibrium when applied to a congestion game.Operations research and online statistical decision-making
In operations research and on-line statistical decision making problem field, the weighted majority algorithm and its more complicated versions have been found independently.Computational geometry
The multiplicative weights algorithm is also widely applied in computational geometry, such as Clarkson's algorithm for linear programming (LP) with a bounded number of variables in linear time. Later, Bronnimann and Goodrich employed analogous methods to find Set Covers for hypergraphs with small VC dimension.Gradient descent methodMatrix multiplicative weights updatePlotkin, Shmoys, Tardos framework for packing/covering LPsApproximating multi-commodity flow problemsO (logn)- approximation for many NP-hard problemsLearning theory and boostingHard-core sets and the XOR lemmaHannan's algorithm and multiplicative weightsOnline convex optimization

References
External links
The Game Theory of Life a Quanta Magazine article describing the use of the method to evolutionary biology in a paper by Erick Chastain, Adi Livnat, Christos Papadimitriou, and Umesh Vazirani",52242050,https://en.wikipedia.org/wiki/Multiplicative_weight_update_method
Neural style transfer,"Neural style transfer (NST) refers to a class of software algorithms that manipulate digital images, or videos, in order to adopt the appearance or visual style of another image. NST algorithms are characterized by their use of deep neural networks for the sake of image transformation. Common uses for NST are the creation of artificial artwork from photographs, for example by transferring the appearance of famous paintings to user-supplied photographs.  Several notable mobile apps use NST techniques for this purpose, including DeepArt and Prisma. This method has been used by artists and designers around the globe to develop new artwork based on existent style(s).","Neural style transfer (NST) refers to a class of software algorithms that manipulate digital images, or videos, in order to adopt the appearance or visual style of another image. NST algorithms are characterized by their use of deep neural networks for the sake of image transformation. Common uses for NST are the creation of artificial artwork from photographs, for example by transferring the appearance of famous paintings to user-supplied photographs.  Several notable mobile apps use NST techniques for this purpose, including DeepArt and Prisma. This method has been used by artists and designers around the globe to develop new artwork based on existent style(s).

Earlier style transfer algorithms
NST is an example of image stylization, a problem studied for over two decades within the field of non-photorealistic rendering.  The first two example-based style transfer algorithms were image analogies and image quilting. Both of these methods were based on patch-based texture synthesis algorithms.
Given a training pair of images–a photo and an artwork depicting that photo–a transformation could be learned and then applied to create new artwork from a new photo, by analogy. If no training photo was available, it would need to be produced by processing the input artwork; image quilting did not require this processing step, though it was demonstrated on only one style.

NST
NST was first published in the paper ""A Neural Algorithm of Artistic Style"" by Leon Gatys et al., originally released to ArXiv 2015, and subsequently accepted by the peer-reviewed CVPR conference in 2016. The original paper used a  VGG-19 architecture that has been pre-trained to perform object recognition using the ImageNet dataset.
In 2017, Google AI introduced a method that allows a single deep convolutional style transfer network to learn multiple styles at the same time. This algorithm permits style interpolation in real-time, even when done on video media.

Formulation
The process of NST assumes an input image p{\displaystyle p} and an example style image a{\displaystyle a}.
The image p{\displaystyle p} is fed through the CNN, and network activations are sampled at a late convolution layer of the VGG-19 architecture. Let C(p){\displaystyle C(p)} be the resulting output sample, called the 'content' of the input p{\displaystyle p}.
The style image a{\displaystyle a} is then fed through the same CNN, and network activations are sampled at the early to middle layers of the CNN.  These activations are encoded into a Gramian matrix representation, call it S(a){\displaystyle S(a)} to denote the 'style' of a{\displaystyle a}.
The goal of NST is to synthesize an output image x{\displaystyle x} that exhibits the content of p{\displaystyle p} applied with the style of a{\displaystyle a}, i.e.  C(x)=C(p){\displaystyle C(x)=C(p)} and S(x)=S(a){\displaystyle S(x)=S(a)}.
An iterative optimization (usually gradient descent) then gradually updates x{\displaystyle x} to minimize the loss function error:
L(x)=|C(x)−C(p)|+k|S(x)−S(a)|{\displaystyle {\mathcal {L(x)}}=|C(x)-C(p)|+k|S(x)-S(a)|},
where |.|{\displaystyle |.|} is the L2 distance.  The constant k{\displaystyle k} controls the level of the stylization effect.

Training
Image x{\displaystyle x} is initially approximated by adding a small amount of white noise to input image p{\displaystyle p} and feeding it through the CNN.  Then we successively backpropagate this loss through the network with the CNN weights fixed in order to update the pixels of x{\displaystyle x}.  After several thousand epochs of training, an x{\displaystyle x} (hopefully) emerges that matches the style of a{\displaystyle a} and the content of p{\displaystyle p}.
Algorithms are typically implemented for GPUs, so that training takes a few minutes.

Extensions
NST has also been extended to videos.Subsequent work improved the speed of NST for images.In a paper by Fei-Fei Li et al. adopted a different regularized loss metric and accelerated method for training to produce results in real-time (three orders of magnitude faster than Gatys). Their idea was to use not the pixel-based loss defined above but rather a 'perceptual loss' measuring the differences between higher-level layers within the CNN. They used a symmetric encoder-decoder CNN.  Training uses a similar loss function to the basic NST method but also regularizes the output for smoothness using a total variation (TV) loss. Once trained, the network may be used to transform an image into the style used during training, using a single feed-forward pass of the network. However the network is restricted to the single style in which it has been trained.In a work by Chen Dongdong et al. they explored the fusion of optical flow information into feedforward networks in order to improve the temporal coherence of the output.Most recently, feature transform based NST methods have been explored for fast stylization that are not coupled to single specific style and enable user-controllable blending of styles, for example the whitening and coloring transform (WCT).


== References ==",59892172,https://en.wikipedia.org/wiki/Neural_style_transfer
Newest vertex bisection,"Newest Vertex Bisection is an algorithmic method to locally refine triangulations. It is widely used in computational science, numerical simulation, and computer graphics. The advantage of newest vertex bisection is that it allows local refinement of triangulations without degenerating the shape of the triangles after repeated usage.In newest vertex bisection, whenever a triangle is to be split into smaller triangles, it will be bisected by drawing a line from the newest vertex to the midpoint of the edge opposite to that vertex. That midpoint becomes the newest vertex of the two newer triangles. One can show that repeating this procedure for a given triangulation leads to triangles that belong to only a finite number of similarity classes.
Generalizations of newest vertex bisection to dimension three and higher are known. Newest vertex bisection is used in local mesh refinement for adaptive finite element methods, where it is an alternative to red-green refinement and uniform mesh refinement.


== References ==","Newest Vertex Bisection is an algorithmic method to locally refine triangulations. It is widely used in computational science, numerical simulation, and computer graphics. The advantage of newest vertex bisection is that it allows local refinement of triangulations without degenerating the shape of the triangles after repeated usage.In newest vertex bisection, whenever a triangle is to be split into smaller triangles, it will be bisected by drawing a line from the newest vertex to the midpoint of the edge opposite to that vertex. That midpoint becomes the newest vertex of the two newer triangles. One can show that repeating this procedure for a given triangulation leads to triangles that belong to only a finite number of similarity classes.
Generalizations of newest vertex bisection to dimension three and higher are known. Newest vertex bisection is used in local mesh refinement for adaptive finite element methods, where it is an alternative to red-green refinement and uniform mesh refinement.


== References ==",59538271,https://en.wikipedia.org/wiki/Newest_vertex_bisection
Newman–Janis algorithm,"In general relativity, the Newman–Janis algorithm (NJA) is a complexification technique for finding exact solutions to the Einstein field equations.  In 1964, Newman and Janis showed that the Kerr metric could be obtained from the Schwarzschild metric by means of a coordinate transformation and allowing the radial coordinate to take on complex values.  Originally, no clear reason for why the algorithm works was known.In 1998, Drake and Szekeres gave a detailed explanation of the success of the algorithm and proved the uniqueness of certain solutions.  In particular, the only perfect fluid solution generated by NJA is the Kerr metric and the only Petrov type D solution is the Kerr–Newman metric.The algorithm works well on ƒ(R) and Einstein–Maxwell–Dilaton theories, but doesn't return expected results on Braneworld and Born–Infield theories.","In general relativity, the Newman–Janis algorithm (NJA) is a complexification technique for finding exact solutions to the Einstein field equations.  In 1964, Newman and Janis showed that the Kerr metric could be obtained from the Schwarzschild metric by means of a coordinate transformation and allowing the radial coordinate to take on complex values.  Originally, no clear reason for why the algorithm works was known.In 1998, Drake and Szekeres gave a detailed explanation of the success of the algorithm and proved the uniqueness of certain solutions.  In particular, the only perfect fluid solution generated by NJA is the Kerr metric and the only Petrov type D solution is the Kerr–Newman metric.The algorithm works well on ƒ(R) and Einstein–Maxwell–Dilaton theories, but doesn't return expected results on Braneworld and Born–Infield theories.

See also
Birkhoff's theorem (relativity)


== References ==",63151790,https://en.wikipedia.org/wiki/Newman%E2%80%93Janis_algorithm
Non-malleable code,"The notion of non-malleable codes was introduced in 2010 by Dziembowski, Pietrzak, and Wichs, for relaxing the notion of error-correction and error-detection. Informally, a code is non-malleable if the message contained in a modified code-word is either the original message, or a completely unrelated value. Non-malleable codes provide a useful and meaningful security guarantee in situations where traditional error-correction and error-detection is impossible; for example, when the attacker can completely overwrite the encoded message. Although such codes do not exist if the family of ""tampering functions"" F is completely unrestricted, they are known to exist for many broad tampering families F.","The notion of non-malleable codes was introduced in 2010 by Dziembowski, Pietrzak, and Wichs, for relaxing the notion of error-correction and error-detection. Informally, a code is non-malleable if the message contained in a modified code-word is either the original message, or a completely unrelated value. Non-malleable codes provide a useful and meaningful security guarantee in situations where traditional error-correction and error-detection is impossible; for example, when the attacker can completely overwrite the encoded message. Although such codes do not exist if the family of ""tampering functions"" F is completely unrestricted, they are known to exist for many broad tampering families F.

Background
Tampering experiment
To know the operation schema of non-malleable code, we have to have a knowledge of the basic experiment it based on. The following is the three step method of tampering experiment.

A source message s{\displaystyle s} is encoded via a (possibly randomized) procedure Enc{\displaystyle Enc}, yielding a code-word c{\displaystyle c} = Enc(s){\displaystyle Enc(s)}.
The code-word is modified under some tampering-function f∈F{\displaystyle f\in F} to an erroneous-code-word c∗{\displaystyle c^{*}}=f(c){\displaystyle f(c)}.
The erroneous-code-word c∗{\displaystyle c^{*}} is decoded using a procedure Dec{\displaystyle Dec}, resulting in a decoded-message  s∗{\displaystyle s^{*}}= Dec(c∗){\displaystyle Dec(c^{*})}.The tampering experiment can be used to model several interesting real-world settings, such as data transmitted over a noisy channel, or adversarial tampering of data stored in the memory of a physical device. Having this experimental base, we would like to build special encoding/decoding procedures (Enc,Dec){\displaystyle (Enc,Dec)}, which give us some meaningful guarantees about the results of the above tampering experiment, for large and interesting families F{\displaystyle F} of tampering functions. The following are several possibilities for the type of guarantees that we may hope for.

Error correction
One very natural guarantee, called error-correction, would be to require that for any tampering function and any source-message s, the tampering experiment always produces the correct decoded message  s∗=s{\displaystyle s^{*}=s}.

Error detection
A weaker guarantee, called error-detection, requires that the tampering-experiment always results in either the correct value s∗=s{\displaystyle s^{*}=s} or a special symbol s∗=⊥{\displaystyle s^{*}=\perp } indicating that tampering has been detected. This notion of error-detection is a weaker guarantee than error-correction, and achievable for larger F of tampering functions.

Algorithm description
A non-malleable code ensures that either the tampering experiment results in a correct decoded-message  s∗=s{\displaystyle s^{*}=s}, or the decoded-message s∗{\displaystyle s^{*}} is completely independent of and unrelated to the source-message s{\displaystyle s}. In other word, the notion of non-malleability for codes is similar, in spirit, to notions of non-malleability for cryptographic primitives (such as encryption2, commitments and zero-knowledge proofs), introduced by the seminal work of Dolev, Dwork and Naor.Compared to error correction or error detection, the ""right"" formalization of non-malleable codes is somewhat harder to define. Let Tampersf{\displaystyle Tamper_{s}^{f}} be a random variable for the value of the decoded-message, which results when we run the tampering experiment with source-message s{\displaystyle s} and tampering-function f{\displaystyle f}, over the randomness of the encoding procedure. Intuitively, we wish to say that the distribution of Tampersf{\displaystyle Tamper_{s}^{f}} is independent of the encoded message s{\displaystyle s}. Of course, we also want to allow for the case where the tampering experiment results in s∗=s{\displaystyle s^{*}=s} (for example, if the tampering function is identity), which clearly depends on s{\displaystyle s}.
Thus, we require that for every tampering-function f∈F{\displaystyle f\in F}, there exists a distribution Df{\displaystyle D_{f}} which outputs either concrete values s∗{\displaystyle s^{*}} or a special same ∗{\displaystyle *} symbol, and faithfully models the distribution of Tampersf{\displaystyle Tamper_{s}^{f}} for all s{\displaystyle s} in the following sense: for every source message s{\displaystyle s}, the distributions of Tampersf{\displaystyle Tamper_{s}^{f}} and Df{\displaystyle D_{f}} are statistically close when the ∗{\displaystyle *} symbol is interpreted as s{\displaystyle s}. That is, Df{\displaystyle D_{f}} correctly simulates the ""outcome"" of the tampering-experiment with a function f∈F{\displaystyle f\in F} without knowing the source-messages s{\displaystyle s}, but it is allowed some ambiguity by outputting a same ∗{\displaystyle *} symbol to indicate that the decoded-message should be the same as the source-message, without specifying what the exact value is. The fact that Df{\displaystyle D_{f}} depends on only f{\displaystyle f} and not on s{\displaystyle s}, shows that the outcome of Tampersf{\displaystyle Tamper_{s}^{f}} is independent of s{\displaystyle s}, exempting equality.

Relation to error correction/detection
Notice that non-malleability is a weaker guarantee than error correction/detection; the latter ensure that any change in the code-word can be corrected or at least detected by the decoding procedure, whereas the former does allow the message to be modified, but only to an unrelated value. However, when studying error correction/detection we usually restrict ourselves to limited forms of tampering which preserve some notion of distance (e.g., usually hamming distance) between the original and tampered code-word. 
For example, it is already impossible to achieve error correction/detection for the simple family of functions Fconst{\displaystyle F_{const}} which, for every constant c∗{\displaystyle c^{*}}, includes a ""constant"" function fc∗{\displaystyle f_{c^{*}}} that maps all inputs to c∗{\displaystyle c^{*}}. There is always some function in Fconst{\displaystyle F_{const}} that maps everything to a valid code-word c∗{\displaystyle c^{*}}. In contrast, it is trivial to construct codes that are non-malleable w.r.t Fconst{\displaystyle F_{const}}, as the output of a constant function is clearly independent of its input. The prior works on non-malleable codes show that one can construct non-malleable codes for highly complex tampering function families F{\displaystyle F} for which error correction/detection can not be achievable.

Application over tampering functions
Bit-wise independent tampering
As one very concrete example, we study non-malleability with respect to the family of functions f{\displaystyle f} which specify, for each bit of the code-word c{\displaystyle c}, whether to keep it as is, flip it, set it to 0, set it to 1. That is, each bit of the code-word is modified arbitrarily but independently of the value of the other bits of the code-word. We call this the “bit-wise independent tampering” family FBIT{\displaystyle F_{BIT}}. Note that this family contains constant functions Fconst{\displaystyle F_{const}} and constant-error functions Ferr{\displaystyle F_{err}} as subsets. Therefore, as we have mentioned, error-correction and error-detection cannot be achieved w.r.t. this family. Nevertheless, the following can show an efficient non-malleable code for this powerful family.
With FBIT{\displaystyle F_{BIT}} we denote the family which contains all tampering functions that tamper every bit independently. Formally, this family contains all functions fi:{0,1}n→{0,1}n{\displaystyle f_{i}:\left\{{0},{1}\right\}^{n}\to \left\{{0},{1}\right\}^{n}}  that are defined by n functionsfi:{0,1}→{0,1}{\displaystyle f_{i}:\left\{{0},{1}\right\}\to \left\{{0},{1}\right\}} (for i=1...n) as f(c1..cn)=f1(c1)..fn(cn){\displaystyle f(c_{1}..c_{n})=f_{1}(c_{1})..f_{n}(c_{n})}. Note that there are only 4 possible choices for each fi{\displaystyle f_{i}} (i.e. how to modify a particular bit) and we name these “set to 0”, “set to 1”, “flip”, “keep” where the meanings should be intuitive. We call the above family the bit-wise independent tampering family.

All families of bounded size
Probabilistic Method ApproachFor any ""small enough"" function family F{\displaystyle F}, there exists a (possibly inefficient) coding scheme which is non-malleable w.r.t. F. Moreover, for a fixed ""small enough"" function family F{\displaystyle F}, a random coding scheme is likely to be non-malleable w.r.t. F with overwhelming probability. Unfortunately, random coding schemes cannot be efficiently represented, nor is the encoding/decoding function likely to be efficient. Therefore, this result should merely be thought of as showing ""possibility"" and providing a target that we should then strive to match constructively. Moreover, this result also highlights the difference between ""error-correction/detection"" and ""non-malleability"" since a result of this form could not be true for the former notions.

Random Oracle Model ApproachIt is not clear what the bound from the theorem of this type actually implies. For example, it does tell us that non-malleable codes exist with respect to all efficient functions, but this is misleading as we know that efficient non-malleable codes (and ultimately we are only interested in such) cannot be non-malleable w.r.t. this class. Nevertheless, the result by the probabilistic method does give us codes which are non-malleable w.r.t. very general classes of functions in the random oracle model.

Model of tamper-resilient security
In this model, we consider two ways of interacting with the system:
Execute(x{\displaystyle x}): A user can provide the system with Execute(x) queries, for x∈{0,1}u{\displaystyle x\in \left\{{0},{1}\right\}^{u}}, in which case the system computes (y,s′)←G(x,s){\displaystyle (y,s^{'})\gets G(x,s)}, updates the state of the system to s:=s′{\displaystyle s:=s^{'}} and outputs y{\displaystyle y}.
Tamper(f{\displaystyle f}): We also consider tampering attacks against the system, modeled by Tamper(f{\displaystyle f}) commands, for functions f:{0,1}n→{0,1}n{\displaystyle f:\left\{{0},{1}\right\}^{n}\to \left\{{0},{1}\right\}^{n}}. Upon receiving such command, the system state is set to s:=f(s){\displaystyle s:=f(s)}.
An attacker that can also interact with the system via Tamper queries can potentially learn significantly more about the secret state, even recover it entirely. Therefore, we would like to have a general method for securing systems against tampering attacks, so that the ability to issue Tamper queries (at least for functions f in some large family F{\displaystyle F}) cannot provide the attacker with additional information. By using non-malleable code for this purpose we have the conclusion: Let (Enc,Dec){\displaystyle (Enc,Dec)} be any coding scheme which is non-malleable w.r.t F{\displaystyle F}, then (Enc,Dec){\displaystyle (Enc,Dec)} can also be tamper-simulate w.r.t. F{\displaystyle F}.

Capacity of non-malleable codes
For every family F{\displaystyle F} with |F|≤22αn{\displaystyle |F|\leq 2^{2^{\alpha n}}}, there exist non-malleable codes against F{\displaystyle F} with rate arbitrarily close to 1 − α{\displaystyle \alpha } (this is achieved w.h.p. by a randomized construction).
For families of size exp(nO(1)2αn){\displaystyle exp(n^{O(1)}2^{\alpha n})} against which there is no non-malleable code of rate 1 − α{\displaystyle \alpha } (in fact this is the case w.h.p for a random family of this size).
1 − α{\displaystyle \alpha } is the best achievable rate for the family of functions which are only allowed to tamper the first αn{\displaystyle \alpha n} bits of the code-word, which is of special interest.


== References ==",48768665,https://en.wikipedia.org/wiki/Non-malleable_code
Note G,"Note G is a computer algorithm written by Ada Lovelace that was designed to calculate Bernoulli numbers using the hypothetical analytical engine. Note G is generally agreed to be the first algorithm specifically for a computer, and Lovelace is considered as the first computer programmer as a result. The algorithm was the last note in a series labelled A to G, which she employed as visual aids to accompany her English translation of Luigi Menabrea's 1842 French transcription of Charles Babbage's lecture on the analytical engine at the University of Turin, ""Notions sur la machine analytique de Charles Babbage"" (""Elements of Charles Babbage’s Analytical Machine""). Lovelace's Note G was never tested, as the engine was never built. Her notes, along with her translation, were published in 1843.In the modern era, thanks to more readily available computing equipment and programming resources, Lovelace's algorithm has since been tested, after being ""translated"" into modern programming languages. These tests have independently concluded that there was a bug in the script, due to a minor typographical error, rendering the algorithm in its original state unusable.","Note G is a computer algorithm written by Ada Lovelace that was designed to calculate Bernoulli numbers using the hypothetical analytical engine. Note G is generally agreed to be the first algorithm specifically for a computer, and Lovelace is considered as the first computer programmer as a result. The algorithm was the last note in a series labelled A to G, which she employed as visual aids to accompany her English translation of Luigi Menabrea's 1842 French transcription of Charles Babbage's lecture on the analytical engine at the University of Turin, ""Notions sur la machine analytique de Charles Babbage"" (""Elements of Charles Babbage’s Analytical Machine""). Lovelace's Note G was never tested, as the engine was never built. Her notes, along with her translation, were published in 1843.In the modern era, thanks to more readily available computing equipment and programming resources, Lovelace's algorithm has since been tested, after being ""translated"" into modern programming languages. These tests have independently concluded that there was a bug in the script, due to a minor typographical error, rendering the algorithm in its original state unusable.

Origin
In 1840, Charles Babbage was invited to give a seminar in Turin on his analytical engine, the only public explanation he ever gave on the engine. During Babbage's lecture, mathematician Luigi Menabrea wrote an account of the engine in French. A friend of Babbage's, Charles Wheatstone, suggested that in order to contribute, Lovelace should translate Menabrea's account. Babbage suggested that she augment the account with appendices, which she compiled at the end of her translation as a series of seven ""notes"" labelled A-G. Her translation was published in August 1843, in Taylor's Scientific Memoirs, wherein Lovelace's name was signed ""A.A.L"". In these notes, Lovelace described the capabilities of Babbage's analytical engine if it were to be used for computing, laying out a more ambitious plan for the engine than even Babbage himself had.Lovelace's notes for the article were three times longer than the article itself. In the first notes, she explores beyond the numerical ambitions that Babbage had for the machine, and suggests the machine could take advantage of computation in order to deal with the realms of music, graphics, and language.
Again, it might act upon other things besides number, were objects found whose mutual fundamental relations could be expressed by those of the abstract science of operations, and which should be also susceptible of adaptations to the action of the operating notation and mechanism of the engine. Supposing, for instance, that the fundamental relations of pitched sounds in the science of harmony and of musical composition were susceptible of such expression and adaptations, the engine might compose elaborate and scientific pieces of music of any degree of complexity or extent.
She explains to readers how the analytical engine was separate from Babbage's earlier difference engine, and likens its function to the Jacquard machine, in that it used binary punch cards to denote machine language. In note C, this point is furthered by the fact that simultaneous and iterated actions can be made by the machine, ensuring that any card or collection of cards can be used several times in the solution of a single problem, essentially anticipating modern methods of control flow and looping. These ideas were brought to a head in the final note, G, where Lovelace sought to demonstrate an example of computation.
Note G only made use of only the four arithmetical operations: addition, subtraction, multiplication and division, the implementation of Babbage's vision:

Under the impossibility of my here explaining the process through which this end is attained, we must limit ourselves to admitting that the first four operations of arithmetic, that is addition, subtraction, multiplication and division, can be performed in a direct manner through the intervention of the machine. This granted, the machine is thence capable of performing every species of numerical calculation, for all such calculations ultimately resolve themselves into the four operations we have just named.It also uses Babbage's idea of storing information in columns of discs, each denoted by V{\displaystyle V} (for variable) and a subscript number denoting which column is being referred to.

Function
Lovelace used a recursive equation to calculate Bernoulli numbers, wherein she used the previous values in an equation to generate the next one. her method ran thus:
Bn=−∑k=0n−1n!(n+1−k)!⋅k!{\displaystyle B_{n}=-\sum _{k=0}^{n-1}{\frac {n!}{(n+1-k)!\cdot k!}}}Bk=−∑k=0n−1(nk)Bkn+1−k{\displaystyle B_{k}=-\sum _{k=0}^{n-1}{\binom {n}{k}}{\frac {B_{k}}{n+1-k}}}where (nk){\displaystyle {\binom {n}{k}}} is a binomial coefficient, 

(nk)=n!k!(n−k)!{\displaystyle \displaystyle {\binom {n}{k}}={\frac {n!}{k!(n-k)!}}}.Bernoulli numbers can be calculated in many ways, but Lovelace deliberately chose an elaborate method in order to demonstrate the power of the engine. In Note G, she states: ""We will terminate these Notes by following up in detail the steps through which the engine could compute the Numbers of Bernoulli, this being (in the form in which we shall deduce it) a rather complicated example of its powers."" The particular algorithm used by Lovelace in Note G generates the eighth Bernoulli number (labelled as B7{\displaystyle B_{7}}, as she started with B0{\displaystyle B_{0}}.)

Notation
The table of the algorithm organises each command in order. Each command denotes one operation being made on two terms. The second column states only the operator being used. Variables are notated as ""V{\displaystyle V}"", where the superscript before it represents the amount of different values the variable has been assigned to, and the subscript after it represents the ordinal assignment of the variable, that is which variable it is. (For example, 2V4{\displaystyle ^{2}V_{4}} refers to the second assignment of variable number 4. Any variables hitherto undefined have a superscript of 0.) The variables are numbered starting from V0{\displaystyle V_{0}}. The third column tells the computer exactly what command is taking place, (For example, on line 1, the command performed is ""1V2×1V3{\displaystyle ^{1}V_{2}\times ^{1}V_{3}}"" - the first iteration of variable 2 is multiplied by the first iteration of variable 3.) and only incorporates one operation between two terms per line. Column 4 - ""Variables receiving results"" takes note of where the result of the operation in column 3 should be stored. In this way, any variables in this column have their superscript number incremented by one each time. (e.g. on line 1, the result of 1V2×1V3{\displaystyle ^{1}V_{2}\times ^{1}V_{3}} is assigned to variables V4{\displaystyle V_{4}}, V5{\displaystyle V_{5}}, and V6{\displaystyle V_{6}}.)
Column 5 states whether either of the variables used in the operation of the command has been changed. Enclosed in curly braces, two rows per command put the original variable on the left side of an equals sign, and the new variable on the other side - that is, if the variable has been changed, its superscript is incremented by one, and if not, it remains the same. (e.g. line three assigns the result of 1V5+1V1{\displaystyle ^{1}V_{5}+^{1}V_{1}} to the second iteration of the variable V5{\displaystyle V_{5}}, and the fifth column reflects this by noting;

{1V5=2V51V1=1V1}{\displaystyle {\begin{Bmatrix}^{1}V_{5}=^{2}V_{5}\\^{1}V_{1}=^{1}V_{1}\end{Bmatrix}}}V5{\displaystyle V_{5}} has changed, but V1{\displaystyle V_{1}} hasn't.
In column 6, ""Statement of Results"", the result assigned to the variable in column 4 is shown in its exact value based on the values of the two terms previously assigned. (e.g. on line 1 - 1V2×1V3{\displaystyle ^{1}V_{2}\times ^{1}V_{3}} - V2{\displaystyle V_{2}} was set at the beginning to be 2{\displaystyle 2}, and V3{\displaystyle V_{3}} was set to be the variable n{\displaystyle n}. Therefore, 1V2×1V3=2n{\displaystyle ^{1}V_{2}\times ^{1}V_{3}=2n}, in mathematical notation.) This column is ostensibly not computed by the engine, and appears to be more to aid clarity and the reader's ability to follow the steps of the program. (For example, line 5 has a fraction being divided by two, which is notated as it being multiplied by a half, probably for coherence and the typographical complexity of a nested fraction.) It also makes use of separate variable notation outside of the program, the A{\displaystyle A} and B{\displaystyle B} variables, which are multiplied successively to find the final value, B7{\displaystyle B_{7}}, thus:
B7=−1(A0+B1A1+B3A3+B5A5){\displaystyle B_{7}=-1(A_{0}+B_{1}A_{1}+B_{3}A_{3}+B_{5}A_{5})}Beyond this, each successive column shows the values of a given variable over time. Each time a variable either changes, or has its value become relevant by token of its presence as one of the terms in the current command, its value is stated or restated in its respective column. Otherwise, it is marked with an ellipsis to denote its irrelevancy. This presumably mimics the computer's need for only relevant information, thereby tracking the value of a variable as the program parses.

Method
The program sought to calculate what is known by modern convention as the eighth Bernoulli number, listed as B7{\displaystyle B_{7}}, as Lovelace begins counting from B0{\displaystyle B_{0}}.

Error
In operation 4, the division supposedly taking place is ""2V5÷2V4{\displaystyle ^{2}V_{5}\div ^{2}V_{4}}"", to be stored in variable 1V11{\displaystyle ^{1}V_{11}}. However, the ""Statement of results"" says that the division should be:

2n−12n+1{\displaystyle {\frac {2n-1}{2n+1}}}As a matter of fact, the division is the wrong way round; 2n−1{\displaystyle 2n-1} is the second iteration of V4{\displaystyle V_{4}}, as can be seen in operation 2. Likewise, 2n+1{\displaystyle 2n+1} is the second iteration of V5{\displaystyle V_{5}}, as can be seen in operation 3. Thus, operation 4 should not be 2V5÷2V4{\displaystyle ^{2}V_{5}\div ^{2}V_{4}}, but rather 2V4÷2V5{\displaystyle ^{2}V_{4}\div ^{2}V_{5}}. This bug means that if the engine were ever to run this algorithm in this state, it would fail to generate Bernoulli numbers correctly, and would find its final goal value (the eighth Bernoulli number, −130{\displaystyle -{\tfrac {1}{30}}}) to be −25621630{\displaystyle -{\tfrac {25621}{630}}}.

Modern implementations
Lovelace's program can be implemented in a modern programming language, though due to the above stated error, if transcribed exactly it would return an incorrect final value for B7{\displaystyle B_{7}}. The original program generalised in pseudocode follows as thus:

V[1] = 1
V[2] = 2
V[3] = n (n = 4 in Lovelace's program.)

V[4] = V[4] - V[1]
V[5] = V[5] + V[1]
V[11] = V[5] / V[4]
V[11] = V[11] / V[2]
V[13] = V[13] - V[11]
V[10] = V[3] - V[1]
V[7] = V[2] + V[7]
V[11] = V[6] / V[7]
V[12] = V[21] * V[11]
V[13] = V[12] + V[13]
V[10] = V[10] - V[1]
V[6] = V[6] - V[1]
V[7]= V[1] + V[7]
//Finish Later

The implementation in pseudocode highlights the fact that computer languages define variables on a stack, which obviates the need for tracking and specifying the current iteration of a variable. In addition, Lovelace's program only allowed for variables to be defined by performing addition, subtraction, multiplication or division on two terms that were previously defined variables. Modern syntax would be capable of performing each calculation more concisely. This restriction becomes apparent in a few places, for example on command 6 (V13=V13−V11{\displaystyle V_{13}=V_{13}-V_{11}}). Here Lovelace defines a hitherto undefined variable (V13{\displaystyle V_{13}}) by itself, thereby assuming that all undefined variables are automatically equal to 0, where most modern programming languages would return an error or list the variable as null. What she intended was ""0−V11{\displaystyle 0-V_{11}}"", but had constrained herself to only using variables as terms. Likewise, in command 8 (V7=V2+V7{\displaystyle V_{7}=V_{2}+V_{7}}), the strict notation of two-term arithmetic becomes cumbersome, as in order to define V7{\displaystyle V_{7}} as 2, Lovelace assigns its value (0) to itself plus V2{\displaystyle V_{2}} (2). It is due to this restrictive notation that V7{\displaystyle V_{7}} is defined thus.

Notes
References


== Sources ==",70923477,https://en.wikipedia.org/wiki/Note_G
Online optimization,"Online optimization is a field of optimization theory, more popular in computer science and operations research, that deals with optimization problems having no or incomplete knowledge of the future (online). These kind of problems are denoted as online problems and are seen as opposed to the classical optimization problems where complete information is assumed (offline). The research on online optimization can be distinguished into online problems where multiple decisions are made sequentially based on a piece-by-piece input and those where a decision is made only once. A famous online problem where a decision is made only once is the Ski rental problem. In general, the output of an online algorithm is compared to the solution of a corresponding offline algorithm which is necessarily always optimal and knows the entire input in advance (competitive analysis).
In many situations, present decisions (for example, resources allocation) must be made with incomplete knowledge of the future or distributional assumptions on the future are not reliable. In such cases, online optimization  can be used, which is different from other approaches such as robust optimization, stochastic optimization and Markov decision processes.","Online optimization is a field of optimization theory, more popular in computer science and operations research, that deals with optimization problems having no or incomplete knowledge of the future (online). These kind of problems are denoted as online problems and are seen as opposed to the classical optimization problems where complete information is assumed (offline). The research on online optimization can be distinguished into online problems where multiple decisions are made sequentially based on a piece-by-piece input and those where a decision is made only once. A famous online problem where a decision is made only once is the Ski rental problem. In general, the output of an online algorithm is compared to the solution of a corresponding offline algorithm which is necessarily always optimal and knows the entire input in advance (competitive analysis).
In many situations, present decisions (for example, resources allocation) must be made with incomplete knowledge of the future or distributional assumptions on the future are not reliable. In such cases, online optimization  can be used, which is different from other approaches such as robust optimization, stochastic optimization and Markov decision processes.

Online problems
A problem exemplifying the concepts of online algorithms is the Canadian traveller problem. The goal of this problem is to minimize the cost of reaching a target in a weighted graph where some of the edges are unreliable and may have been removed from the graph. However, that an edge has been removed (failed) is only revealed to the traveller when they reach one of the edge's endpoints. The worst case for this problem is simply that all of the unreliable edges fail and the problem reduces to the usual shortest path problem. An alternative analysis of the problem can be made with the help of competitive analysis. For this method of analysis, the offline algorithm knows in advance which edges will fail and the goal is to minimize the ratio between the online and offline algorithms' performance. This problem is PSPACE-complete.
There are many formal problems that offer more than one online algorithm as solution:

k-server problem
Job shop scheduling problem
List update problem
Bandit problem
Secretary problem
Search games
Ski rental problem
Linear search problem
Portfolio selection problem
Online matching

See also
Online algorithm
Online mirror descent


== References ==",49914674,https://en.wikipedia.org/wiki/Online_optimization
Pan–Tompkins algorithm,"The Pan–Tompkins algorithm is commonly used to detect QRS complexes in electrocardiographic signals (ECG). The QRS complex represents the ventricular depolarization and the main spike visible in an ECG signal (see figure). This feature makes it particularly suitable for measuring heart rate, the first way to assess the heart health state. In the first derivation of Einthoven of a physiological heart, the QRS complex is composed by a downward deflection (Q wave), a high upward deflection (R wave) and a final downward deflection (S wave).
The Pan–Tompkins algorithm applies a series of filters to highlight the frequency content of this rapid heart depolarization and removes the background noise. Then, it squares the signal to amplify the QRS contribution, which makes identifying the QRS complex more straightforward. Finally, it applies adaptive thresholds to detect the peaks of the filtered signal. The algorithm was proposed by Jiapu Pan and Willis J. Tompkins in 1985, in the journal IEEE Transactions on Biomedical Engineering. The performance of the method was tested on an annotated arrhythmia database (MIT/BIH) and evaluated also in presence of noise. Pan and Tompkins reported that the 99.3 percent of QRS complexes was correctly detected.","The Pan–Tompkins algorithm is commonly used to detect QRS complexes in electrocardiographic signals (ECG). The QRS complex represents the ventricular depolarization and the main spike visible in an ECG signal (see figure). This feature makes it particularly suitable for measuring heart rate, the first way to assess the heart health state. In the first derivation of Einthoven of a physiological heart, the QRS complex is composed by a downward deflection (Q wave), a high upward deflection (R wave) and a final downward deflection (S wave).
The Pan–Tompkins algorithm applies a series of filters to highlight the frequency content of this rapid heart depolarization and removes the background noise. Then, it squares the signal to amplify the QRS contribution, which makes identifying the QRS complex more straightforward. Finally, it applies adaptive thresholds to detect the peaks of the filtered signal. The algorithm was proposed by Jiapu Pan and Willis J. Tompkins in 1985, in the journal IEEE Transactions on Biomedical Engineering. The performance of the method was tested on an annotated arrhythmia database (MIT/BIH) and evaluated also in presence of noise. Pan and Tompkins reported that the 99.3 percent of QRS complexes was correctly detected.

Pre-processing
Noise cancellation
As a first step, a band-pass filter is applied to increase the signal-to-noise ratio. A filter bandwidth of 5-15 Hz is suggested to maximize the QRS contribute and reduce muscle noise, baseline wander, powerline interference and the P wave/T wave frequency content. In the original algorithm proposed in 1985, the band-pass filter was obtained with a low-pass filter and a high-pass filter in cascade to reduce the computational cost and allow a real-time detection, while ensuring a 3 dB passband in the 5–12 Hz frequency range, reasonably close to the design goal.
For a signal sampled at a frequency of 200 Hz, Pan and Tompkins suggested the filters with the following transfer functions H(z){\displaystyle H(z)} in an updated version of their article:
H(z)=(1−z−5)2(1−z−1)2{\displaystyle H(z)={(1-z^{-5})^{2} \over (1-z^{-1})^{2}}} for a second-order low-pass filter with a gain of 36 and a processing delay of 5 samples;
H(z)=(−1/32+z−16−z−17+z−32/32)(1−z−1){\displaystyle H(z)={(-1/32+z^{-16}-z^{-17}+z^{-32}/32) \over (1-z^{-1})}}for a high-pass filter with a unity gain and a processing delay of 16 samples.

Derivative step
As a third step, a derivative filter is applied to provide information about the slope of the QRS. For a signal sampled at 200 Hz, Pan and Tompkins suggested the following transfer function:H(z)=0.1(−z−2−2z−1+2z1+z2){\displaystyle H(z)=0.1(-z^{-2}-2z^{-1}+2z^{1}+z^{2})}for a 5-point derivative filter with gain of 0.1 and a processing delay of 2 samples.

Squaring and integration
The filtered signal is squared to enhance the dominant peaks (QRSs) and reduce the possibility of erroneously recognizing a T wave as an R peak. Then, a moving average filter is applied to provide information about the duration of the QRS complex. The number of samples to average is chosen in order to average on windows of 150 ms. The signal so obtained is called integrated signal.

Decision rules
Fiducial mark
In order to detect a QRS complex, the local peaks of the integrated signal are found. A peak is defined as the point in which the signal changes direction (from an increasing direction to a decreasing direction). After each peak, no peak can be detected in the next 200 ms (i.e. the lockout time). This is a physiological constraint due to the refractory period during which ventricular depolarization cannot occur even in the presence of a stimulus.

Thresholds
Each fiducial mark is considered as a potential QRS. To reduce the possibility of wrongly selecting a noise peak as a QRS, each peak amplitude is compared to a threshold  (ThresholdI) that takes into account the available information about already detected QRS and the noise level:
ThresholdI=NoiseLevelI+0.25(SignalLevelI−NoiseLevelI){\displaystyle Threshold_{I}=NoiseLevel_{I}+0.25(SignalLevel_{I}-NoiseLevel_{I})}
where NoiseLevelI is the running estimate of the noise level in the integrated signal and SignalLevelI is the running estimate of the signal level in the integrated signal.
The threshold is automatically updated after detecting a new peak, based on its classification as signal or noise peak:
SignalLevelI=0.125PEAKI+0.875SignalLevelI{\displaystyle SignalLevel_{I}=0.125PEAK_{I}+0.875SignalLevel_{I}}(if PEAKI is a signal peak)
NoiseLevelI=0.125PEAKI+0.875NoiseLevelI{\displaystyle NoiseLevel_{I}=0.125PEAK_{I}+0.875NoiseLevel_{I}}(if PEAKI is a noise peak)
where PEAKI is the new peak found in the integrated signal.
At the beginning of the QRS detection, a 2 seconds learning phase is needed to initialize SignalLevelI and NoiseLevelI as a percentage of the maximum and average amplitude of the integrated signal, respectively.
If a new PEAKI is under the ThresholdI, the noise level is updated. If PEAKI is above the ThresholdI, the algorithm implements a further check before confirming the peak as a true QRS, taking into consideration the information provided by the bandpass filtered signal.
In the filtered signal the peak corresponding to the one evaluated on the integrated signal is searched and compared with a threshold, calculated in a similar way to the previous step:
ThresholdF=NoiseLevelF+0.25(SignalLevelF−NoiseLevelF){\displaystyle Threshold_{F}=NoiseLevel_{F}+0.25(SignalLevel_{F}-NoiseLevel_{F})}
SignalLevelF=0.125PEAKF+0.875SignalLevelF{\displaystyle SignalLevel_{F}=0.125PEAK_{F}+0.875SignalLevel_{F}}(if PEAKF is a signal peak)
NoiseLevelF=0.125PEAKF+0.875NoiseLevelF{\displaystyle NoiseLevel_{F}=0.125PEAK_{F}+0.875NoiseLevel_{F}}(if PEAKF is a noise peak)
where the final F stands for filtered signal.

Search back for missed QRS complexes
The algorithm takes into account the possibility of setting too high values of ThresholdII and ThresholdIF. A check is performed to continuously assess the RR intervals (namely the temporal interval between two consecutively QRS peaks) to overcome this issue. The average RR is computed in two ways to consider both regular and irregular heart rhythm. In the first method RRaverage1 is computed as the mean of the last RR intervals. In the second method RRaverage2 is computed as the mean of the last RR intervals that fell between the limits specified as:
RRlow=92%RRaverage2{\displaystyle RRlow=92\%RRaverage2}
RRhigh=116%RRaverage2{\displaystyle RRhigh=116\%RRaverage2}
If no QRS is detected in a window of 166% of the average RR (RRaverage1 or RRaverage2, if the heart rhythm is regular or irregular, respectively), the algorithm adds the maximal peak in the window as a potential QRS and classify it considering half the values of the thresholds (both ThresholdII and ThresholdIF). This check is implemented because the temporal distance between two consecutive beats cannot physiologically change more quickly than this.

T wave discrimination
The algorithm takes particularly into consideration the possibility of a false detection of T waves. If a potential QRS falls up to a 160 ms window after the refractory period from the last correctly detected QRS complex, the algorithm evaluates if it could be a T wave with particular high amplitude. In this case, its slope is compared to the one of the precedent QRS complex. If the slope is less than half the previous one, the current QRS is recognized as a T wave and discarded, and it also updates the NoiseLevel (both in the filtered signal and the integrated signal).

Application
Once the QRS complex is successfully recognized, the heart rate is computed as a function of the distance in seconds between two consecutive QRS complexes (or R peaks):
HR (bpm)=60RR (s){\displaystyle {\mathit {HR}}\ ({\text{bpm}})={60 \over {\mathit {RR}}\ ({\text{s}})}}
where bpm stands for beats per minute. The HR is often used to compute the heart rate variability (HRV) a measure of the variability of the time interval between heartbeats. HRV is often used in the clinical field to diagnose and monitor pathological conditions and their treatment, but also in the affective computing research to study new methods to assess the emotional state of people.

See also
Electrophysiology
QRS
Heart rate
Heart rate variability
Affective computing


== References ==",61186810,https://en.wikipedia.org/wiki/Pan%E2%80%93Tompkins_algorithm
Parallel external memory,"In computer science, a parallel external memory (PEM) model is a cache-aware, external-memory abstract machine. It is the parallel-computing analogy to the single-processor external memory (EM) model. In a similar way, it is the cache-aware analogy to the parallel random-access machine (PRAM). The PEM model consists of a number of processors, together with their respective private caches and a shared main memory.","In computer science, a parallel external memory (PEM) model is a cache-aware, external-memory abstract machine. It is the parallel-computing analogy to the single-processor external memory (EM) model. In a similar way, it is the cache-aware analogy to the parallel random-access machine (PRAM). The PEM model consists of a number of processors, together with their respective private caches and a shared main memory.

Model
Definition
The PEM model is a combination of the EM model and the PRAM model. The PEM model is a computation model which consists of P{\displaystyle P} processors and a two-level memory hierarchy. This memory hierarchy consists of a large  external memory (main memory) of size N{\displaystyle N} and P{\displaystyle P} small  internal memories (caches). The processors share the main memory. Each cache is exclusive to a single processor. A processor can't access another’s cache. The caches have a size M{\displaystyle M} which is partitioned in blocks of size B{\displaystyle B}. The processors can only perform operations on data which are in their cache. The data can be transferred between the main memory and the cache in blocks of size B{\displaystyle B}.

I/O complexity
The  complexity measure of the PEM model is the I/O complexity, which determines the number of parallel blocks transfers between the main memory and the cache. During a parallel block transfer each processor can transfer a block. So if P{\displaystyle P} processors load parallelly a data block of size B{\displaystyle B} form the main memory into their caches, it is considered as an I/O complexity of O(1){\displaystyle O(1)} not O(P){\displaystyle O(P)}. A program in the PEM model should minimize the data transfer between main memory and caches and operate as much as possible on the data in the caches.

Read/write conflicts
In the PEM model, there is no  direct communication network between the P processors. The processors have to communicate indirectly over the main memory. If multiple processors try to access the same block in main memory concurrently read/write conflicts occur. Like in the PRAM model, three different variations of this problem are considered:

Concurrent Read Concurrent Write (CRCW): The same block in main memory can be read and written by multiple processors concurrently.
Concurrent Read Exclusive Write (CREW): The same block in main memory can be read by multiple processors concurrently. Only one processor can write to a block at a time.
Exclusive Read Exclusive Write (EREW): The same block in main memory cannot be read or written by multiple processors concurrently. Only one processor can access a block at a time.The following two algorithms solve the CREW and EREW problem if P≤B{\displaystyle P\leq B} processors write to the same block simultaneously.
A first approach is to serialize the write operations. Only one processor after the other writes to the block. This results in a total of P{\displaystyle P} parallel block transfers. A second approach needs O(log⁡(P)){\displaystyle O(\log(P))} parallel block transfers and an additional block for each processor. The main idea is to schedule the write operations in a  binary tree fashion and gradually combine the data into a single block. In the first round P{\displaystyle P} processors combine their blocks into P/2{\displaystyle P/2} blocks. Then P/2{\displaystyle P/2} processors combine the P/2{\displaystyle P/2} blocks into P/4{\displaystyle P/4}. This procedure is continued until all the data is combined in one block.

Comparison to other models
Examples
Multiway partitioning
Let M={m1,...,md−1}{\displaystyle M=\{m_{1},...,m_{d-1}\}} be a vector of d-1 pivots sorted in increasing order. Let A be an unordered set of N elements. A d-way partition of A is a set Π={A1,...,Ad}{\displaystyle \Pi =\{A_{1},...,A_{d}\}} , where ∪i=1dAi=A{\displaystyle \cup _{i=1}^{d}A_{i}=A} and Ai∩Aj=∅{\displaystyle A_{i}\cap A_{j}=\emptyset } for 1≤i<j≤d{\displaystyle 1\leq i<j\leq d}. Ai{\displaystyle A_{i}} is called the i-th bucket. The number of elements in Ai{\displaystyle A_{i}} is greater than mi−1{\displaystyle m_{i-1}} and smaller than mi2{\displaystyle m_{i}^{2}}. In the following algorithm the input is partitioned into N/P-sized contiguous segments S1,...,SP{\displaystyle S_{1},...,S_{P}} in main memory. The processor i primarily works on the segment Si{\displaystyle S_{i}}. The multiway partitioning algorithm (PEM_DIST_SORT) uses a PEM prefix sum algorithm to calculate the prefix sum with the optimal O(NPB+log⁡P){\displaystyle O\left({\frac {N}{PB}}+\log P\right)} I/O complexity. This algorithm simulates an optimal PRAM prefix sum algorithm.

// Compute parallelly a d-way partition on the data segments Si{\displaystyle S_{i}}
for each processor i in parallel do
    Read the vector of pivots M into the cache.
    Partition Si{\displaystyle S_{i}} into d buckets and let vector Mi={j1i,...,jdi}{\displaystyle M_{i}=\{j_{1}^{i},...,j_{d}^{i}\}} be the number of items in each bucket.
end for

Run PEM prefix sum on the set of vectors {M1,...,MP}{\displaystyle \{M_{1},...,M_{P}\}} simultaneously.

// Use the prefix sum vector to compute the final partition
for each processor i in parallel do
    Write elements Si{\displaystyle S_{i}} into memory locations offset appropriately by Mi−1{\displaystyle M_{i-1}} and Mi{\displaystyle M_{i}}.
end for

Using the prefix sums stored in MP{\displaystyle M_{P}} the last processor P calculates the vector B of bucket sizes and returns it.

If the vector of d=O(MB){\displaystyle d=O\left({\frac {M}{B}}\right)} pivots M and the input set A are located in contiguous memory, then the d-way partitioning problem can be solved in the PEM model with O(NPB+⌈dB⌉>log⁡(P)+dlog⁡(B)){\displaystyle O\left({\frac {N}{PB}}+\left\lceil {\frac {d}{B}}\right\rceil >\log(P)+d\log(B)\right)} I/O complexity. The content of the final buckets have to be located in contiguous memory.

Selection
The selection problem is about finding the k-th smallest item in an unordered list A of size N.
The following code makes use of PRAMSORT which is a PRAM optimal sorting algorithm which runs in O(log⁡N){\displaystyle O(\log N)}, and SELECT, which is a cache optimal single-processor selection algorithm.

if N≤P{\displaystyle N\leq P} then 
    PRAMSORT(A,P){\displaystyle {\texttt {PRAMSORT}}(A,P)}
    return A[k]{\displaystyle A[k]}
end if 

//Find median of each Si{\displaystyle S_{i}}
for each processor i in parallel do 
    mi=SELECT(Si,N2P){\displaystyle m_{i}={\texttt {SELECT}}(S_{i},{\frac {N}{2P}})}
end for 

// Sort medians
PRAMSORT({m1,…,m2},P){\displaystyle {\texttt {PRAMSORT}}(\lbrace m_{1},\dots ,m_{2}\rbrace ,P)}

// Partition around median of medians
t=PEMPARTITION(A,mP/2,P){\displaystyle t={\texttt {PEMPARTITION}}(A,m_{P/2},P)}

if k≤t{\displaystyle k\leq t} then 
    return PEMSELECT(A[1:t],P,k){\displaystyle {\texttt {PEMSELECT}}(A[1:t],P,k)}
else 
    return PEMSELECT(A[t+1:N],P,k−t){\displaystyle {\texttt {PEMSELECT}}(A[t+1:N],P,k-t)}
end if

Under the assumption that the input is stored in contiguous memory, PEMSELECT has an I/O complexity of:

O(NPB+log⁡(PB)⋅log⁡(NP)){\displaystyle O\left({\frac {N}{PB}}+\log(PB)\cdot \log({\frac {N}{P}})\right)}

Distribution sort
Distribution sort partitions an input list A of size N into d disjoint buckets of similar size. Every bucket is then sorted recursively and the results are combined into a fully sorted list.
If P=1{\displaystyle P=1} the task is delegated to a cache-optimal single-processor sorting algorithm.
Otherwise the following algorithm is used:

// Sample 4Nd{\displaystyle {\tfrac {4N}{\sqrt {d}}}} elements from A
for each processor i in parallel do
    if M<|Si|{\displaystyle M<|S_{i}|} then
        d=M/B{\displaystyle d=M/B}
        Load Si{\displaystyle S_{i}} in M-sized pages and sort pages individually
    else
        d=|Si|{\displaystyle d=|S_{i}|}
        Load and sort Si{\displaystyle S_{i}} as single page
    end if
    Pick every d/4{\displaystyle {\sqrt {d}}/4}'th element from each sorted memory page into contiguous vector Ri{\displaystyle R^{i}} of samples
end for 

in parallel do
    Combine vectors R1…RP{\displaystyle R^{1}\dots R^{P}} into a single contiguous vector R{\displaystyle {\mathcal {R}}}
    Make d{\displaystyle {\sqrt {d}}} copies of R{\displaystyle {\mathcal {R}}}: R1…Rd{\displaystyle {\mathcal {R}}_{1}\dots {\mathcal {R}}_{\sqrt {d}}}
end do

// Find d{\displaystyle {\sqrt {d}}} pivots M[j]{\displaystyle {\mathcal {M}}[j]}
for j=1{\displaystyle j=1} to d{\displaystyle {\sqrt {d}}} in parallel do
    M[j]=PEMSELECT(Ri,Pd,j⋅4Nd){\displaystyle {\mathcal {M}}[j]={\texttt {PEMSELECT}}({\mathcal {R}}_{i},{\tfrac {P}{\sqrt {d}}},{\tfrac {j\cdot 4N}{d}})}
end for

Pack pivots in contiguous array M{\displaystyle {\mathcal {M}}}

// Partition Aaround pivots into buckets B{\displaystyle {\mathcal {B}}}
B=PEMMULTIPARTITION(A[1:N],M,d,P){\displaystyle {\mathcal {B}}={\texttt {PEMMULTIPARTITION}}(A[1:N],{\mathcal {M}},{\sqrt {d}},P)}

// Recursively sort buckets
for j=1{\displaystyle j=1} to d+1{\displaystyle {\sqrt {d}}+1} in parallel do
    recursively call PEMDISTSORT{\displaystyle {\texttt {PEMDISTSORT}}} on bucket jof size B[j]{\displaystyle {\mathcal {B}}[j]}
    using O(⌈B[j]N/P⌉){\displaystyle O\left(\left\lceil {\tfrac {{\mathcal {B}}[j]}{N/P}}\right\rceil \right)} processors responsible for elements in bucket j
end for

The I/O complexity of PEMDISTSORT is:

O(⌈NPB⌉(logd⁡P+logM/B⁡NPB)+f(N,P,d)⋅logd⁡P){\displaystyle O\left(\left\lceil {\frac {N}{PB}}\right\rceil \left(\log _{d}P+\log _{M/B}{\frac {N}{PB}}\right)+f(N,P,d)\cdot \log _{d}P\right)}where

f(N,P,d)=O(log⁡PBdlog⁡NP+⌈dBlog⁡P+dlog⁡B⌉){\displaystyle f(N,P,d)=O\left(\log {\frac {PB}{\sqrt {d}}}\log {\frac {N}{P}}+\left\lceil {\frac {\sqrt {d}}{B}}\log P+{\sqrt {d}}\log B\right\rceil \right)}If the number of processors is chosen that f(N,P,d)=O(⌈NPB⌉){\displaystyle f(N,P,d)=O\left(\left\lceil {\tfrac {N}{PB}}\right\rceil \right)}and M<BO(1){\displaystyle M<B^{O(1)}} the I/O complexity is then:
O(NPBlogM/B⁡NB){\displaystyle O\left({\frac {N}{PB}}\log _{M/B}{\frac {N}{B}}\right)}

Other PEM algorithms
Where sortP(N){\displaystyle {\textrm {sort}}_{P}(N)} is the time it takes to sort N items with P processors in the PEM model.

See also
Parallel random-access machine (PRAM)
Random-access machine (RAM)
External memory (EM)


== References ==",59730114,https://en.wikipedia.org/wiki/Parallel_external_memory
Parameterized approximation algorithm,"A parameterized approximation algorithm is a type of algorithm that aims to find approximate solutions to NP-hard optimization problems in polynomial time in the input size and a function of a specific parameter. These algorithms are designed to combine the best aspects of both traditional approximation algorithms and fixed-parameter tractability.
In traditional approximation algorithms, the goal is to find solutions that are at most a certain factor α{\displaystyle \alpha } away from the optimal solution, known as an α{\displaystyle \alpha }-approximation, in polynomial time. On the other hand, parameterized algorithms are designed to find exact solutions to problems, but with the constraint that the running time of the algorithm is polynomial in the input size and a function of a specific parameter k{\displaystyle k}. The parameter describes some property of the input and is small in typical applications. The problem is said to be fixed-parameter tractable (FPT) if there is an algorithm that can find the optimum solution in f(k)nO(1){\displaystyle f(k)n^{O(1)}} time, where f(k){\displaystyle f(k)} is a function independent of the input size n{\displaystyle n}.
A parameterized approximation algorithm aims to find a balance between these two approaches by finding approximate solutions in FPT time: the algorithm computes an α{\displaystyle \alpha }-approximation in f(k)nO(1){\displaystyle f(k)n^{O(1)}} time, where f(k){\displaystyle f(k)} is a function independent of the input size n{\displaystyle n}. This approach aims to overcome the limitations of both traditional approaches by having stronger guarantees on the solution quality compared to traditional approximations while still having efficient running times as in FPT algorithms. An overview of the research area studying parameterized approximation algorithms can be found in the survey of Marx and the more recent survey by Feldmann et al.","A parameterized approximation algorithm is a type of algorithm that aims to find approximate solutions to NP-hard optimization problems in polynomial time in the input size and a function of a specific parameter. These algorithms are designed to combine the best aspects of both traditional approximation algorithms and fixed-parameter tractability.
In traditional approximation algorithms, the goal is to find solutions that are at most a certain factor α{\displaystyle \alpha } away from the optimal solution, known as an α{\displaystyle \alpha }-approximation, in polynomial time. On the other hand, parameterized algorithms are designed to find exact solutions to problems, but with the constraint that the running time of the algorithm is polynomial in the input size and a function of a specific parameter k{\displaystyle k}. The parameter describes some property of the input and is small in typical applications. The problem is said to be fixed-parameter tractable (FPT) if there is an algorithm that can find the optimum solution in f(k)nO(1){\displaystyle f(k)n^{O(1)}} time, where f(k){\displaystyle f(k)} is a function independent of the input size n{\displaystyle n}.
A parameterized approximation algorithm aims to find a balance between these two approaches by finding approximate solutions in FPT time: the algorithm computes an α{\displaystyle \alpha }-approximation in f(k)nO(1){\displaystyle f(k)n^{O(1)}} time, where f(k){\displaystyle f(k)} is a function independent of the input size n{\displaystyle n}. This approach aims to overcome the limitations of both traditional approaches by having stronger guarantees on the solution quality compared to traditional approximations while still having efficient running times as in FPT algorithms. An overview of the research area studying parameterized approximation algorithms can be found in the survey of Marx and the more recent survey by Feldmann et al.

Obtainable approximation ratios
The full potential of parameterized approximation algorithms is utilized when a given optimization problem is shown to admit an α{\displaystyle \alpha }-approximation algorithm running in f(k)nO(1){\displaystyle f(k)n^{O(1)}} time, while in contrast the problem neither has a polynomial-time α{\displaystyle \alpha }-approximation algorithm (under some complexity assumption, e.g., P≠NP{\displaystyle P\neq NP}), nor an FPT algorithm for the given parameter k{\displaystyle k} (i.e., it is at least W[1]-hard).
For example, some problems that are APX-hard and W[1]-hard admit a parameterized approximation scheme (PAS), i.e., for any ε>0{\displaystyle \varepsilon >0} a (1+ε){\displaystyle (1+\varepsilon )}-approximation can be computed in f(k,ε)ng(ε){\displaystyle f(k,\varepsilon )n^{g(\varepsilon )}} time for some functions f{\displaystyle f} and g{\displaystyle g}. This then circumvents the lower bounds in terms of polynomial-time approximation and fixed-parameter tractability. A PAS is similar in spirit to a polynomial-time approximation scheme (PTAS) but additionally exploits a given parameter k{\displaystyle k}. Since the degree of the polynomial in the runtime of a PAS depends on a function g(ε){\displaystyle g(\varepsilon )}, the value of ε{\displaystyle \varepsilon } is assumed to be arbitrary but constant in order for the PAS to run in FPT time. If this assumption is unsatisfying, ε{\displaystyle \varepsilon } is treated as a parameter as well to obtain an efficient parameterized approximation scheme (EPAS), which for any ε>0{\displaystyle \varepsilon >0} computes a (1+ε){\displaystyle (1+\varepsilon )}-approximation in f(k,ε)nO(1){\displaystyle f(k,\varepsilon )n^{O(1)}} time for some function f{\displaystyle f}. This is similar in spirit to an efficient polynomial-time approximation scheme (EPTAS).

k-cut
The k-cut problem has no polynomial-time (2−ε){\displaystyle (2-\varepsilon )}-approximation algorithm for any ε>0{\displaystyle \varepsilon >0}, assuming P≠NP{\displaystyle P\neq NP} and the small set expansion hypothesis. It is also W[1]-hard parameterized by the number k{\displaystyle k} of required components. However an EPAS exists, which computes a (1+ε){\displaystyle (1+\varepsilon )}-approximation in (k/ε)O(k)nO(1){\displaystyle (k/\varepsilon )^{O(k)}n^{O(1)}} time.

Steiner Tree
The Steiner tree problem is FPT parameterized by the number of terminals. However, for the ""dual"" parameter consisting of the number k{\displaystyle k} of non-terminals contained in the optimum solution, the problem is W[2]-hard (due to a folklore reduction from the Dominating Set problem). Steiner Tree is also known to be APX-hard. However, there is an EPAS computing a (1+ε){\displaystyle (1+\varepsilon )}-approximation in 2O(k2/ε4)nO(1){\displaystyle 2^{O(k^{2}/\varepsilon ^{4})}n^{O(1)}} time.

Strongly-connected Steiner subgraph
It is known that the Strongly Connected Steiner Subgraph problem is W[1]-hard parameterized by the number k{\displaystyle k} of terminals, and also does not admit an O(log2−ε⁡n){\displaystyle O(\log ^{2-\varepsilon }n)}-approximation in polynomial time (under standard complexity assumptions). However a 2-approximation can be computed in 3knO(1){\displaystyle 3^{k}n^{O(1)}} time. Furthermore, this is best possible, since no (2−ε){\displaystyle (2-\varepsilon )}-approximation can be computed in f(k)nO(1){\displaystyle f(k)n^{O(1)}} time for any function f{\displaystyle f}, under Gap-ETH.

k-median and k-means
For the well-studied metric clustering problems of k-median and k-means parameterized by the number k{\displaystyle k} of centers, it is known that no (1+2/e−ε){\displaystyle (1+2/e-\varepsilon )}-approximation for k-Median and no (1+8/e−ε){\displaystyle (1+8/e-\varepsilon )}-approximation for k-Means can be computed in f(k)nO(1){\displaystyle f(k)n^{O(1)}} time for any function f{\displaystyle f}, under Gap-ETH. Matching parameterized approximation algorithms exist, but it is not known whether matching approximations can be computed in polynomial time.
Clustering is often considered in settings of low dimensional data, and thus a practically relevant parameterization is by the dimension of the underlying metric. In the Euclidean space, the k-Median and k-Means problems admit an EPAS parameterized by the dimension d{\displaystyle d}, and also an EPAS parameterized by k{\displaystyle k}. The former was generalized to an EPAS for the parameterization by the doubling dimension. For the loosely related highway dimension parameter, only an approximation scheme with XP runtime is known to date.

k-center
For the metric k-center problem a 2-approximation can be computed in polynomial time. However, when parameterizing by either the number k{\displaystyle k} of centers, the doubling dimension (in fact the dimension of a Manhattan metric), or the highway dimension, no parameterized (2−ε){\displaystyle (2-\varepsilon )}-approximation algorithm exists, under standard complexity assumptions. Furthermore, the k-Center problem is W[1]-hard even on planar graphs when simultaneously parameterizing it by the number k{\displaystyle k} of centers, the doubling dimension, the highway dimension, and the pathwidth. However, when combining k{\displaystyle k} with the doubling dimension an EPAS exists, and the same is true when combining k{\displaystyle k} with the highway dimension. For the more general version with vertex capacities, an EPAS exists for the parameterization by k and the doubling dimension, but not when using k and the highway dimension as the parameter. Regarding the pathwidth, k-Center admits an EPAS even for the more general treewidth parameter, and also for cliquewidth.

Densest subgraph
An optimization variant of the k-Clique problem is the Densest k-Subgraph problem (which is a 2-ary Constraint Satisfaction problem), where the task is to find a subgraph on k{\displaystyle k} vertices with maximum number of edges. It is not hard to obtain a (k−1){\displaystyle (k-1)}-approximation by just picking a matching of size k/2{\displaystyle k/2} in the given input graph, since the maximum number of edges on k{\displaystyle k} vertices is always at most (k2)=k(k−1)/2{\displaystyle {k \choose 2}=k(k-1)/2}. This is also asymptotically optimal, since under Gap-ETH no k1−o(1){\displaystyle k^{1-o(1)}}-approximation can be computed in FPT time parameterized by k{\displaystyle k}.

Dominating set
For the Dominating set problem it is W[1]-hard to compute any g(k){\displaystyle g(k)}-approximation in f(k)nO(1){\displaystyle f(k)n^{O(1)}} time for any functions g{\displaystyle g} and f{\displaystyle f}.

Approximate kernelization
Kernelization is a technique used in fixed-parameter tractability to pre-process an instance of an NP-hard problem in order to remove ""easy parts"" and reveal the NP-hard core of the instance. A kernelization algorithm takes an instance I{\displaystyle I} and a parameter k{\displaystyle k}, and returns a new instance I′{\displaystyle I'} with parameter k′{\displaystyle k'} such that the size of I′{\displaystyle I'} and k′{\displaystyle k'} is bounded as a function of the input parameter k{\displaystyle k}, and the algorithm runs in polynomial time. An α{\displaystyle \alpha }-approximate kernelization algorithm is a variation of this technique that is used in parameterized approximation algorithms. It returns a kernel I′{\displaystyle I'} such that any β{\displaystyle \beta }-approximation in I′{\displaystyle I'} can be converted into an αβ{\displaystyle \alpha \beta }-approximation to the input instance I{\displaystyle I} in polynomial time. This notion was introduced by Lokshtanov et al., but there are other related notions in the literature such as Turing kernels and α{\displaystyle \alpha }-fidelity kernelization.As for regular (non-approximate) kernels, a problem admits an α-approximate kernelization algorithm if and only if  it has a parameterized α-approximation algorithm. The proof of this fact is very similar to the one for regular kernels. However the guaranteed approximate kernel might be of exponential size (or worse) in the input parameter. Hence it becomes interesting to find problems that admit polynomial sized approximate kernels. Furthermore, a polynomial-sized approximate kernelization scheme (PSAKS) is an α{\displaystyle \alpha }-approximate kernelization algorithm that computes a polynomial-sized kernel and for which α{\displaystyle \alpha } can be set to 1+ε{\displaystyle 1+\varepsilon } for any ε>0{\displaystyle \varepsilon >0}.
For example, while the Connected Vertex Cover problem is FPT parameterized by the solution size, it does not admit a (regular) polynomial sized kernel (unless NP⊆coNP/poly{\displaystyle NP\subseteq coNP/poly}), but a PSAKS exists. Similarly, the Steiner Tree problem is FPT parameterized by the number of terminals, does not admit a polynomial sized kernel (unless NP⊆coNP/poly{\displaystyle NP\subseteq coNP/poly}), but a PSAKS exists. When parameterizing Steiner Tree by the number of non-terminals in the optimum solution, the problem is W[2]-hard (and thus admits no exact kernel at all, unless FPT=W[2]), but still admits a PSAKS.

Talks on parameterized approximations
Daniel Lokshtanov: A Parameterized Approximation Scheme for k-Min Cut
Tuukka Korhonen: Single-Exponential Time 2-Approximation Algorithm for Treewidth
Karthik C. S.: Recent Hardness of Approximation results in Parameterized Complexity
Ariel Kulik. Two-variable Recurrence Relations with Application to Parameterized Approximations
Meirav Zehavi. FPT Approximation
Vincent Cohen-Added: On the Parameterized Complexity of Various Clustering Problems
Fahad Panolan. Parameterized Approximation for Independent Set of Rectangles
Andreas Emil Feldmann. Approximate Kernelization Schemes for Steiner Networks


== References ==",72808068,https://en.wikipedia.org/wiki/Parameterized_approximation_algorithm
PHY-Level Collision Avoidance,"PHY-Level Collision Avoidance (PLCA) is a component of the Ethernet reconciliation sublayer (between the PHY and the MAC) defined within IEEE 802.3 clause 148. The purpose of PLCA is to avoid the shared medium collisions and associated retransmission overhead. PLCA is used in 802.3cg (10BASE-T1), which focuses on bringing ethernet connectivity to short-haul embedded internet of things and low throughput, noise-tolerant, industrial deployment use cases.In order for a multidrop 10BASE-T1S standard to successfully compete with CAN XL, some kind of arbitration was necessary. The linear arbitration scheme of PLCA somewhat resembles the one of the Byteflight, but PLCA was designed from scratch to accommodate the existing shared medium Ethernet MACs with their busy sensing mechanisms.","PHY-Level Collision Avoidance (PLCA) is a component of the Ethernet reconciliation sublayer (between the PHY and the MAC) defined within IEEE 802.3 clause 148. The purpose of PLCA is to avoid the shared medium collisions and associated retransmission overhead. PLCA is used in 802.3cg (10BASE-T1), which focuses on bringing ethernet connectivity to short-haul embedded internet of things and low throughput, noise-tolerant, industrial deployment use cases.In order for a multidrop 10BASE-T1S standard to successfully compete with CAN XL, some kind of arbitration was necessary. The linear arbitration scheme of PLCA somewhat resembles the one of the Byteflight, but PLCA was designed from scratch to accommodate the existing shared medium Ethernet MACs with their busy sensing mechanisms.

Operation
Under a PLCA scheme all nodes are assigned unique sequential numbers (IDs) in the range from 0 to N. Zero ID corresponds to a special ""master"" node that during the idle intervals transmits the synchronization beacon (a special heartbeat frame). After the beacon (within PLCA cycle) each node gets its transmission opportunity (TO). Each opportunity interval is very short (typically 20 bits), so overhead for the nodes that do not have anything to transmit is low. If the PLCA circuitry discovers that the node's TO cannot be used (the other node with a lower ID have started its transmission and the media is busy at the beginning of the TO for this node), it asserts the ""local collision"" input of the MAC thus delaying the transmission. The condition is cleared once the node gets its TO. A standard MAC reacts to the local collision with a backoff, however, since this is the first and only backoff for this frame, the backoff interval is equal to the smallest possible frame - and the backoff timer will definitely expire by the time the TO is granted, so there is no additional loss of performance.

See also
Internet of things (IOT)

References
Sources
Cena, Gianluca; Scanzio, Stefano; Valenzano, Adriano (2023-04-26). Composite CAN XL-Ethernet Networks for Next-Gen Automotive and Automation Systems. 2023 IEEE 19th International Conference on Factory Communication Systems (WFCS). IEEE. arXiv:2306.09498. doi:10.1109/wfcs57264.2023.10144116.
Beruto, Piergiorgio; Orzelli, Antonio (2018). 802.3cg draft 2.0 PLCA (Clause 148) Overview (PDF). San Diego, CA: IEEE 802.3 Plenary Meeting.",71578738,https://en.wikipedia.org/wiki/PHY-Level_Collision_Avoidance
Ping-pong scheme,"Algorithms said to employ a ping-pong scheme exist in different fields of software engineering. They are characterized by an alternation between two entities. In the examples described below, these entities are communication partners, network paths or file blocks.","Algorithms said to employ a ping-pong scheme exist in different fields of software engineering. They are characterized by an alternation between two entities. In the examples described below, these entities are communication partners, network paths or file blocks.

Databases
In most database management systems durable database transactions are supported through a log file. However, multiple writes to the same page of that file can produce a slim chance of data loss. Assuming for simplicity that the log file is organized in pages whose size matches the block size of its underlying medium, the following problem can occur:
If the very last page of the log file is only partially filled with data and has to be written to permanent storage in this state, the very same page will have to be overwritten during the next write operation. If a crash happens during that later write operation, previously stored log data may be lost.
The ping-pong scheme described in Transaction Processing eliminates this problem by alternately writing the contents of said (logical) last page to two different physical pages inside the log file (the actual last page i and its empty successor i+1). Once said logical log page is no longer the last page (i.e. it is completely filled with log data), it is written one last time to the regular physical position (i) inside the log file.
This scheme requires the usage of time stamps for each page in order to distinguish the most recent version of the logical last page one from its predecessor.

Networking
Internet
A functionality which lets a computer A find out whether a computer B is reachable and responding is built into the Internet Control Message Protocol (ICMP). Through an ""Echo Request"" Computer A asks B to send back an ""Echo Reply"". These two messages are also sometimes erroneously called ""ping"" and ""pong"".

Routing
In routing, a Ping-Pong scheme is a simple algorithm for distributing data packets across two paths. If you had two paths A and B, then the algorithm would randomly start with one of the paths and then switch back and forth between the two.If you were to get the next path from a function call, it would look like this in Python:


== References ==",12242679,https://en.wikipedia.org/wiki/Ping-pong_scheme
Data structure,"In computer science, a data structure is a data organization, management, and storage format that is usually chosen for efficient access to data. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data, i.e., it is an algebraic structure about data.","In computer science, a data structure is a data organization, management, and storage format that is usually chosen for efficient access to data. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data, i.e., it is an algebraic structure about data.

Usage
Data structures serve as the basis for abstract data types (ADT). The ADT defines the logical form of the data type. The data structure implements the physical form of the data type.Different types of data structures are suited to different kinds of applications, and some are highly specialized to specific tasks. For example, relational databases commonly use B-tree indexes for data retrieval, while compiler implementations usually use hash tables to look up identifiers.Data structures provide a means to manage large amounts of data efficiently for uses such as large databases and internet indexing services. Usually, efficient data structures are key to designing efficient algorithms. Some formal design methods and programming languages emphasize data structures, rather than algorithms, as the key organizing factor in software design. Data structures can be used to organize the storage and retrieval of information stored in both main memory and secondary memory.

Implementation
Data structures can be implemented using a variety of programming languages and techniques, but they all share the common goal of efficiently organizing and storing data. Data structures are generally based on the ability of a computer to fetch and store data at any place in its memory, specified by a pointer—a bit string, representing a memory address, that can be itself stored in memory and manipulated by the program. Thus, the array and record data structures are based on computing the addresses of data items with arithmetic operations, while the linked data structures are based on storing addresses of data items within the structure itself. This approach to data structuring has profound implications for the efficiency and scalability of algorithms. For instance, the contiguous memory allocation in arrays facilitates rapid access and modification operations, leading to optimized performance in sequential data processing scenarios.The implementation of a data structure usually requires writing a set of procedures that create and manipulate instances of that structure. The efficiency of a data structure cannot be analyzed separately from those operations. This observation motivates the theoretical concept of an abstract data type, a data structure that is defined indirectly by the operations that may be performed on it, and the mathematical properties of those operations (including their space and time cost).

Examples
There are numerous types of data structures, generally built upon simpler primitive data types. Well known examples are:
An array is a number of elements in a specific order, typically all of the same type (depending on the language, individual elements may either all be forced to be the same type, or may be of almost any type). Elements are accessed using an integer index to specify which element is required. Typical implementations allocate contiguous memory words for the elements of arrays (but this is not always a necessity). Arrays may be fixed-length or resizable.
A linked list (also just called list) is a linear collection of data elements of any type, called nodes, where each node has itself a value, and points to the next node in the linked list. The principal advantage of a linked list over an array is that values can always be efficiently inserted and removed without relocating the rest of the list. Certain other operations, such as random access to a certain element, are however slower on lists than on arrays.
A record (also called tuple or struct) is an aggregate data structure. A record is a value that contains other values, typically in fixed number and sequence and typically indexed by names. The elements of records are usually called fields or members. In the context of object-oriented programming, records are known as plain old data structures to distinguish them from objects.
Hash tables, also known as hash maps, are data structures that provide fast retrieval of values based on keys. They use a hashing function to map keys to indexes in an array, allowing for constant-time access in the average case. Hash tables are commonly used in dictionaries, caches, and database indexing. However, hash collisions can occur, which can impact their performance. Techniques like chaining and open addressing are employed to handle collisions.
Graphs are collections of nodes connected by edges, representing relationships between entities. Graphs can be used to model social networks, computer networks, and transportation networks, among other things. They consist of vertices (nodes) and edges (connections between nodes). Graphs can be directed or undirected, and they can have cycles or be acyclic. Graph traversal algorithms include breadth-first search and depth-first search.
Stacks and queues are abstract data types that can be implemented using arrays or linked lists. A stack has two primary operations: push (adds an element to the top of the stack) and pop (removes the topmost element from the stack), that follow the Last In, First Out (LIFO) principle. Queues have two main operations: enqueue (adds an element to the rear of the queue) and dequeue (removes an element from the front of the queue) that follow the First In, First Out (FIFO) principle.
Trees represent a hierarchical organization of elements. A tree consists of nodes connected by edges, with one node being the root and all other nodes forming subtrees. Trees are widely used in various algorithms and data storage scenarios. Binary trees (particularly heaps), AVL trees, and B-trees are some popular types of trees. They enable efficient and optimal searching, sorting, and hierarchical representation of data.
A trie, also known as a prefix tree, is a specialized tree data structure used for the efficient retrieval of strings. Tries store characters of a string as nodes, with each edge representing a character. They are particularly useful in text processing scenarios like autocomplete, spell-checking, and dictionary implementations. Tries enable fast searching and prefix-based operations on strings.

Language support
Most assembly languages and some low-level languages, such as BCPL (Basic Combined Programming Language), lack built-in support for data structures. On the other hand, many high-level programming languages and some higher-level assembly languages, such as MASM, have special syntax or other built-in support for certain data structures, such as records and arrays. For example, the C (a direct descendant of BCPL) and Pascal languages support structs and records, respectively, in addition to vectors (one-dimensional arrays) and multi-dimensional arrays.Most programming languages feature some sort of library mechanism that allows data structure implementations to be reused by different programs. Modern languages usually come with standard libraries that implement the most common data structures. Examples are the C++ Standard Template Library, the Java Collections Framework, and the Microsoft .NET Framework.
Modern languages also generally support modular programming, the separation between the interface of a library module and its implementation. Some provide opaque data types that allow clients to hide implementation details. Object-oriented programming languages, such as C++, Java, and Smalltalk, typically use classes for this purpose.
Many known data structures have concurrent versions which allow multiple computing threads to access a single concrete instance of a data structure simultaneously.

See also
References
Bibliography
Peter Brass, Advanced Data Structures, Cambridge University Press, 2008, ISBN 978-0521880374
Donald Knuth, The Art of Computer Programming, vol. 1. Addison-Wesley, 3rd edition, 1997, ISBN 978-0201896831
Dinesh Mehta and Sartaj Sahni, Handbook of Data Structures and Applications, Chapman and Hall/CRC Press, 2004, ISBN 1584884355
Niklaus Wirth, Algorithms and Data Structures, Prentice Hall, 1985, ISBN 978-0130220059

Further reading
Alfred Aho, John Hopcroft, and Jeffrey Ullman, Data Structures and Algorithms, Addison-Wesley, 1983, ISBN 0-201-00023-7
G. H. Gonnet and R. Baeza-Yates, Handbook of Algorithms and Data Structures - in Pascal and C, second edition, Addison-Wesley, 1991, ISBN 0-201-41607-7
Ellis Horowitz and Sartaj Sahni, Fundamentals of Data Structures in Pascal, Computer Science Press, 1984, ISBN 0-914894-94-3

External links

Descriptions from the Dictionary of Algorithms and Data Structures
Data structures course
An Examination of Data Structures from .NET perspective
Schaffer, C. Data Structures and Algorithm Analysis",8519,https://en.wikipedia.org/wiki/Data_structure
Region (model checking),"In model checking, a field of computer science, a region is a convex polytope in Rd{\displaystyle \mathbb {R} ^{d}} for some dimension d{\displaystyle d}, and more precisely a zone, satisfying some minimality property. The regions partition Rd{\displaystyle \mathbb {R} ^{d}}.
The set of zones depends on a set K{\displaystyle K} of constraints of the form x≤c{\displaystyle x\leq c}, x≥c{\displaystyle x\geq c}, x1≤x2+c{\displaystyle x_{1}\leq x_{2}+c} and x1≥x2+c{\displaystyle x_{1}\geq x_{2}+c}, with x1{\displaystyle x_{1}} and x2{\displaystyle x_{2}} some variables, and c{\displaystyle c} a constant. The regions are defined such that if two vectors x→{\displaystyle {\vec {x}}} and x→′{\displaystyle {\vec {x}}'} belong to the same region, then they satisfy the same constraints of K{\displaystyle K}. Furthermore, when those vectors are considered as a tuple of clocks, both vectors have the same  set of possible futures. Intuitively, it means that any timed propositional temporal logic-formula, or timed automaton or signal automaton using only the constraints of K{\displaystyle K} can not distinguish both vectors.
The set of region allows to create the region automaton, which is a directed graph in which each node is a region, and each edge r→r′{\displaystyle r\to r'} ensure that r′{\displaystyle r'} is a possible future of r{\displaystyle r}. Taking a product of this region automaton and of a timed automaton A{\displaystyle {\mathcal {A}}} which accepts a language L{\displaystyle L} creates a finite automaton or a Büchi automaton which accepts untimed L{\displaystyle L}. In particular, it allows to reduce the emptiness problem for A{\displaystyle {\mathcal {A}}} to the emptiness problem for a finite or Büchi automaton. This technique is used for example by the software UPPAAL.","In model checking, a field of computer science, a region is a convex polytope in Rd{\displaystyle \mathbb {R} ^{d}} for some dimension d{\displaystyle d}, and more precisely a zone, satisfying some minimality property. The regions partition Rd{\displaystyle \mathbb {R} ^{d}}.
The set of zones depends on a set K{\displaystyle K} of constraints of the form x≤c{\displaystyle x\leq c}, x≥c{\displaystyle x\geq c}, x1≤x2+c{\displaystyle x_{1}\leq x_{2}+c} and x1≥x2+c{\displaystyle x_{1}\geq x_{2}+c}, with x1{\displaystyle x_{1}} and x2{\displaystyle x_{2}} some variables, and c{\displaystyle c} a constant. The regions are defined such that if two vectors x→{\displaystyle {\vec {x}}} and x→′{\displaystyle {\vec {x}}'} belong to the same region, then they satisfy the same constraints of K{\displaystyle K}. Furthermore, when those vectors are considered as a tuple of clocks, both vectors have the same  set of possible futures. Intuitively, it means that any timed propositional temporal logic-formula, or timed automaton or signal automaton using only the constraints of K{\displaystyle K} can not distinguish both vectors.
The set of region allows to create the region automaton, which is a directed graph in which each node is a region, and each edge r→r′{\displaystyle r\to r'} ensure that r′{\displaystyle r'} is a possible future of r{\displaystyle r}. Taking a product of this region automaton and of a timed automaton A{\displaystyle {\mathcal {A}}} which accepts a language L{\displaystyle L} creates a finite automaton or a Büchi automaton which accepts untimed L{\displaystyle L}. In particular, it allows to reduce the emptiness problem for A{\displaystyle {\mathcal {A}}} to the emptiness problem for a finite or Büchi automaton. This technique is used for example by the software UPPAAL.

Definition
Let C={x1,…,xd}{\displaystyle C=\{x_{1},\dots ,x_{d}\}} a set of clocks. For each x∈N{\displaystyle x\in \mathbb {N} } let cx∈N{\displaystyle c_{x}\in \mathbb {N} }. Intuitively, this number represents an upper bound on the values to which the clock x{\displaystyle x} can be compared. The definition of a region over the clocks of C{\displaystyle C} uses those numbers cx{\displaystyle c_{x}}'s.  Three equivalent definitions are now given.
Given a clock assignment ν{\displaystyle \nu },  [ν]{\displaystyle [\nu ]} denotes the region in which  ν{\displaystyle \nu } belongs. The set of regions is denoted by R{\displaystyle {\mathcal {R}}}.

Equivalence of clocks assignment
The first definition allow to easily test whether two assignments belong to the same region.
A region may be defined as an equivalence class for some equivalence relation. Two clocks assignments ν1{\displaystyle \nu _{1}} and ν2{\displaystyle \nu _{2}} are equivalent if they satisfy the following constraints:: 202 
ν1(x)∼c{\displaystyle \nu _{1}(x)\sim c} iff ν2(x)∼c{\displaystyle \nu _{2}(x)\sim c}, for each x∈C{\displaystyle x\in C} and 0≤c≤cx{\displaystyle 0\leq c\leq c_{x}} an integer, and ~ being one of the following relation =, < or ≤.
{ν1(x)}∼{ν1(y)}{\displaystyle \{\nu _{1}(x)\}\sim \{\nu _{1}(y)\}} iff {ν2(x)}∼{ν2(y)}{\displaystyle \{\nu _{2}(x)\}\sim \{\nu _{2}(y)\}}, for each x,y∈C{\displaystyle x,y\in C}, ν1(x)≤cx{\displaystyle \nu _{1}(x)\leq c_{x}}, ν1(y)≤cy{\displaystyle \nu _{1}(y)\leq c_{y}}, {r}{\displaystyle \{r\}} being the fractional part of  the real r{\displaystyle r},  and ~ being one of the following relation =, < or ≤.The first kind of constraints ensures that ν1{\displaystyle \nu _{1}} and ν2{\displaystyle \nu _{2}} satisfies the same constraints. Indeed, if ν1(x)=0.5{\displaystyle \nu _{1}(x)=0.5} and ν2(x)=1{\displaystyle \nu _{2}(x)=1}, then only the second assignment satisfies x=1{\displaystyle x=1}. On the other hand, if ν1(x)=0.5{\displaystyle \nu _{1}(x)=0.5} and ν2(x)=0.6{\displaystyle \nu _{2}(x)=0.6}, both assignment satisfies exactly the same set of constraint, since the constraints use only integral constants.
The second kind of constraints ensures that the future of two assignments satisfy  the  same constraints. For example, let ν1={x↦0.5,y↦0.6}{\displaystyle \nu _{1}=\{x\mapsto 0.5,y\mapsto 0.6\}} and ν2={x↦0.5,y↦0.4}{\displaystyle \nu _{2}=\{x\mapsto 0.5,y\mapsto 0.4\}}. Then, the constraint y=1∧x<1{\displaystyle y=1\land x<1} is eventually satisfied by the future of ν1{\displaystyle \nu _{1}} without clock reset, but not by the future of ν2{\displaystyle \nu _{2}} without clock reset.

Explicit definition of a region
While the previous definition allow to test whether two assignments belong to the same region, it does not allow to easily represents a region as a data structure. The third definition given below allow to give a canonical encoding of a region.
A region can be explicitly defined as a zone, using a set S{\displaystyle S} of equations and inequations satisfying the following constraints:

for each x∈C{\displaystyle x\in C}, S{\displaystyle S} contains either:
x=c{\displaystyle x=c} for some integer 0≤c≤cx{\displaystyle 0\leq c\leq c_{x}}
x∈(c,c+1){\displaystyle x\in (c,c+1)} for some integer 0≤c<cx{\displaystyle 0\leq c<c_{x}},
x>cx{\displaystyle x>c_{x}},
furthermore, for each pair of clocks x,y∈C{\displaystyle x,y\in C}, where S{\displaystyle S} contains constraints of the form x∈(c,c+1){\displaystyle x\in (c,c+1)} and y∈(c′,c′+1){\displaystyle y\in (c',c'+1)}, then S{\displaystyle S} contains an (in) equality of the form  {x}∼{y}{\displaystyle \{x\}\sim \{y\}} with ∼{\displaystyle \sim } being either =, < or ≤.Since, when c{\displaystyle c} and c′{\displaystyle c'} are fixed, the last constraint is equivalent to x∼y+c−c′{\displaystyle x\sim y+c-c'}.
This definition allow to encode a region as a data structure. It suffices, for each clock, to state to which interval it belongs and to recall the order of the fractional part of the  clocks which belong in an open interval of length 1. It follows that the size of this structure is O(∑log⁡(ck)+|C|log⁡(|C|)){\displaystyle O\left(\sum \log(c_{k})+|C|\log(|C|)\right)} with |C|{\displaystyle |C|} the number of clocks.

Timed bisimulation
Let us now give a third definition of regions. While this definition is more abstract, it is also the reason why regions are used in model checking. Intuitively, this definition states that two clock assignments belong to the same region if the differences between  them  are  such that no timed automaton can notice them.  Given any run r{\displaystyle r} starting with a clock assignment ν{\displaystyle \nu }, for any other assignment ν′{\displaystyle \nu '} in the same region, there is a run r′{\displaystyle r'}, going through the same locations, reading the same letters, where the only difference is that the time waited between two successive transition may be different, and thus the successive clock variations are different.
The formal definition is now given. Given a set of clock C{\displaystyle C}, two assignments two clocks assignments ν1{\displaystyle \nu _{1}} and ν2{\displaystyle \nu _{2}} belongs to the same region if for each timed automaton A{\displaystyle {\mathcal {A}}} in which the guards never compare a clock x{\displaystyle x} to a number greater than cx{\displaystyle c_{x}}, given any location ℓ{\displaystyle \ell } of A{\displaystyle {\mathcal {A}}}, there is a timed bisimulation between the extended states (ℓ,ν1){\displaystyle (\ell ,\nu _{1})} and (ℓ,ν2){\displaystyle (\ell ,\nu _{2})}. More precisely, this bisimulation preserves letters and locations but not the exact clock assignments.: 7

Operation on regions
Some operations are now defined over regions: Resetting some of its clock, and letting time pass.

Resetting clocks
Given a region α{\displaystyle \alpha } defined by a set of (in)equations S{\displaystyle S}, and a set of clocks C′⊆C{\displaystyle C'\subseteq C}, the region similar to α{\displaystyle \alpha } in which the clocks of C′{\displaystyle C'} are restarted is now defined. This region is denoted by α[C′↦0]{\displaystyle \alpha [C'\mapsto 0]}, it is defined by the following constraints:

each constraints of S{\displaystyle S} not containing the clock x{\displaystyle x},
the constraints x=0{\displaystyle x=0} for x∈C′{\displaystyle x\in C'}.The set of assignments defined by α[C′↦0]{\displaystyle \alpha [C'\mapsto 0]} is exactly the set of assignments ν[C′↦0]{\displaystyle \nu [C'\mapsto 0]} for ν∈α{\displaystyle \nu \in \alpha }.

Time-successor
Given a region α{\displaystyle \alpha }, the regions which can be attained without resetting a clock are called the time-successors of α{\displaystyle \alpha }. Two equivalent definitions are now given.

Definition
A clock region α′{\displaystyle \alpha '} is a time-successor of another clock region α{\displaystyle \alpha } if for each assignment ν∈α{\displaystyle \nu \in \alpha }, there exists some positive real tν,α′>0{\displaystyle t_{\nu ,\alpha '}>0} such that ν+tν,α′∈α′{\displaystyle \nu +t_{\nu ,\alpha '}\in \alpha '}.
Note that it does not mean that α+tν,α′=α′{\displaystyle \alpha +t_{\nu ,\alpha '}=\alpha '}. For example, the region α{\displaystyle \alpha } defined by the set of constraint {0<x<1,0<y<1,x<y}{\displaystyle \{0<x<1,0<y<1,x<y\}} has the time-successor α′{\displaystyle \alpha '} defined by the set of constraint {0<x<1,y=1}{\displaystyle \{0<x<1,y=1\}}. Indeed, for each ν∈α{\displaystyle \nu \in \alpha }, it suffices to take tν,α′=1−ν(y){\displaystyle t_{\nu ,\alpha '}=1-\nu (y)}.  However, there exists no real t{\displaystyle t} such that α+t=α′{\displaystyle \alpha +t=\alpha '} or even such that α+t⊆α′{\displaystyle \alpha +t\subseteq \alpha '}; indeed, α{\displaystyle \alpha } defines a triangle while α′{\displaystyle \alpha '} defines a segment.

Computable definition
The second definition now given allow to explicitly compute the set of time-successor of a region, given by its set of constraints.
Given a region α{\displaystyle \alpha } defined as a set of constraints S{\displaystyle S}, let us define its set of time-successors. In order to do so, the following variables are required. Let  T⊆S{\displaystyle T\subseteq S} the set of constraints of S{\displaystyle S} of the form xi=ci{\displaystyle x_{i}=c_{i}}. Let Y⊆C{\displaystyle Y\subseteq C} the set of clocks y{\displaystyle y} such that S{\displaystyle S} contains the constraint y>cy{\displaystyle y>c_{y}}. Let Z⊆C∖Y{\displaystyle Z\subseteq C\setminus Y} the set of clocks {z}{\displaystyle \{z\}} such that there are no constraints  of the form {x}<{z}{\displaystyle \{x\}<\{z\}} in S{\displaystyle S}.
If T{\displaystyle T} is empty, α{\displaystyle \alpha } is its own time successor. If Y=C{\displaystyle Y=C}, then α{\displaystyle \alpha } is the only time-successor of α{\displaystyle \alpha }. Otherwise, there is a least time-successor of α{\displaystyle \alpha } not equal to α{\displaystyle \alpha }. The least time-successor, if T{\displaystyle T} is non-empty, contains:

the constraints of S∖T{\displaystyle S\setminus T}
xi>ci{\displaystyle x_{i}>c_{i}},
{xi}={xj}{\displaystyle \{x_{i}\}=\{x_{j}\}}, and
for each y{\displaystyle y} such that y>cy{\displaystyle y>c_{y}} does not belong to S{\displaystyle S}, the constraint xi<y{\displaystyle x_{i}<y}.If T{\displaystyle T} is empty,  the least time-successor is defined by the following constraints:

the constraints of S{\displaystyle S} not using the clocks of Z{\displaystyle Z},
the constraint z=c+1{\displaystyle z=c+1}, for each constraint c<z<c+1{\displaystyle c<z<c+1} in S{\displaystyle S}, with z∈Z{\displaystyle z\in Z}.

Properties
There are at most |C|!2|C|∏x∈C(2cx+2){\displaystyle |C|!2^{|C|}\prod _{x\in C}(2c_{x}+2)} regions, where |C|{\displaystyle |C|} is the number of clocks.: 203

Region automaton
Given a timed automaton A{\displaystyle {\mathcal {A}}}, its region automaton is a finite automaton or a Büchi automaton which accepts untimed L{\displaystyle L}. This automaton is similar to A{\displaystyle {\mathcal {A}}}, where clocks are replaced by region. Intuitively, the region automaton is contructude as a product of A{\displaystyle {\mathcal {A}}} and of the region graph. This region graph is defined first.

Region graph
The region graph is a rooted directed graph which models the set of possible clock valuations during a run of a timed-autoamton. It is defined as follows:

its nodes are regions,
its root is the initial region α0{\displaystyle \alpha _{0}}, defined by the set of constraints {x=0∣x∈C}{\displaystyle \{x=0\mid x\in C\}},
the set of edges are (α,α′[C′↦0]){\displaystyle (\alpha ,\alpha '[C'\mapsto 0])}, for α′{\displaystyle \alpha '} a time-successor of α{\displaystyle \alpha }.

Region automaton
Let A=⟨Σ,L,L0,C,F,E⟩{\displaystyle {\mathcal {A}}=\langle \Sigma ,L,L_{0},C,F,E\rangle } a timed automaton. For each clock x∈C{\displaystyle x\in C}, let cx{\displaystyle c_{x}} the greatest number c{\displaystyle c} such that there exists a guard of the form x∼c{\displaystyle x\sim c} in A{\displaystyle {\mathcal {A}}}. The region automaton of A{\displaystyle {\mathcal {A}}}, denoted by R(A){\displaystyle R({\mathcal {A}})} is a finite or Büchi automaton which is essentially a product of A{\displaystyle {\mathcal {A}}} and of the region graph defined above.  That is, each state of the region automaton is a pair containing a location of A{\displaystyle {\mathcal {A}}} and a region. Since two clocks assignment belonging to the same region satisfies the same guard, each region contains enough information to decide which transitions can be taken.
Formally, the region automaton is defined as follows:

its alphabet is Σ{\displaystyle \Sigma },
its set of states is L×R{\displaystyle L\times {\mathcal {R}}},
its set of states is L0×{α0}{\displaystyle L_{0}\times \{\alpha _{0}\}} with α0{\displaystyle \alpha _{0}} the initial region,
its set of accepting states is F×R{\displaystyle F\times {\mathcal {R}}},
its transition relation δ{\displaystyle \delta } contains  ((ℓ,α),a,(ℓ′,α′[C′↦0])){\displaystyle ((\ell ,\alpha ),a,(\ell ',\alpha '[C'\mapsto 0]))}, for (ℓ,a,g,C′,ℓ′)∈E{\displaystyle (\ell ,a,g,C',\ell ')\in E}, such that γ⊨α′{\displaystyle \gamma \models \alpha '} and α′{\displaystyle \alpha '} is a time-successor of α{\displaystyle \alpha }.Given any run r=(ℓ0,ν0)→t1σ1(ℓ1,ν1)…{\displaystyle r=(\ell _{0},\nu _{0}){\xrightarrow[{t_{1}}]{\sigma _{1}}}(\ell _{1},\nu _{1})\dots } of A{\displaystyle {\mathcal {A}}}, the sequence (ℓ0,[ν0])→σ1(ℓ1,[ν1])…{\displaystyle (\ell _{0},[\nu _{0}]){\xrightarrow {\sigma _{1}}}(\ell _{1},[\nu _{1}])\dots } is denoted [r]{\displaystyle [r]}, it is a run of R(A){\displaystyle R({\mathcal {A}})} and is accepting if and only if r{\displaystyle r} is accepting: 207 . It follows that L(R(A))=Untime⁡(L(A)){\displaystyle L(R({\mathcal {A}}))=\operatorname {Untime} (L({\mathcal {A}}))}. In particular, A{\displaystyle {\mathcal {A}}} accepts a timed-word if and only if R(A){\displaystyle R({\mathcal {A}})} accepts a word. Furthermore, an accepting run of A{\displaystyle {\mathcal {A}}} can be computed from an accepting run of R(A){\displaystyle R({\mathcal {A}})}.


== References ==",60442605,https://en.wikipedia.org/wiki/Region_(model_checking)
List of data structures,"This is a list of well-known data structures. For a wider list of terms, see list of terms relating to algorithms and data structures. For a comparison of running times for a subset of this list see comparison of data structures.","This is a list of well-known data structures. For a wider list of terms, see list of terms relating to algorithms and data structures. For a comparison of running times for a subset of this list see comparison of data structures.

Data types
Primitive types
Boolean, true or false.
Character
Floating-point representation of a finite subset of the rationals.
Including single-precision and double-precision IEEE 754 floats, among others
Fixed-point representation of the rationals
Integer, a direct representation of either the integers or the non-negative integers
Reference, sometimes erroneously referred to as a pointer or handle, is a value that refers to another value, possibly including itself
Symbol, a unique identifier
Enumerated type, a set of symbols
Complex, representation of complex numbers

Composite types or non-primitive type
Array, a sequence of elements of the same type stored contiguously in memory
Record (also called a structure or struct), a collection of fields
Product type (also called a tuple), a record in which the fields are not named
String, a sequence of characters representing text
Union, a datum which may be one of a set of types
Tagged union (also called a variant, discriminated union or sum type), a union with a tag specifying which type the data is

Abstract data types
Container
List
Tuple
Associative array, Map
Multimap
Set
Multiset (bag)
Stack
Queue (example Priority queue)
Double-ended queue
Graph (example Tree, Heap)
Some properties of abstract data types:""Ordered"" means that the elements of the data type have some kind of explicit order to them, where an element can be considered ""before"" or ""after"" another element. This order is usually determined by the order in which the elements are added to the structure, but the elements can be rearranged in some contexts, such as sorting a list. For a structure that isn't ordered, on the other hand, no assumptions can be made about the ordering of the elements (although a physical implementation of these data types will often apply some kind of arbitrary ordering). ""Uniqueness"" means that duplicate elements are not allowed. Depending on the implementation of the data type, attempting to add a duplicate element may either be ignored, overwrite the existing element, or raise an error. The detection for duplicates is based on some inbuilt (or alternatively, user-defined) rule for comparing elements.

Linear data structures
A data structure is said to be linear if its elements form a sequence.

Arrays
Array
Bit array
Bit field
Bitboard
Bitmap
Circular buffer
Control table
Image
Dope vector
Dynamic array
Gap buffer
Hashed array tree
Lookup table
Matrix
Parallel array
Sorted array
Sparse matrix
Iliffe vector
Variable-length array

Lists
Doubly linked list
Array list
Linked list also known as a Singly linked list
Association list
Self-organizing list
Skip list
Unrolled linked list
VList
Conc-tree list
Xor linked list
Zipper
Doubly connected edge list also known as half-edge
Difference list
Free list

Trees
Trees are a subset of directed acyclic graphs.

Binary trees
AA tree
AVL tree
Binary search tree
Binary tree
Cartesian tree
Conc-tree list
Left-child right-sibling binary tree
Order statistic tree
Pagoda
Randomized binary search tree
Red–black tree
Rope
Scapegoat tree
Self-balancing binary search tree
Splay tree
T-tree
Tango tree
Threaded binary tree
Top tree
Treap
WAVL tree
Weight-balanced tree
Zip tree

B-trees
B-tree
B+ tree
B*-tree
Dancing tree
2–3 tree
2–3–4 tree
Queap
Fusion tree
Bx-tree

Heaps
Heap
Min-max heap
Binary heap
B-heap
Weak heap
Binomial heap
Fibonacci heap
AF-heap
Leonardo heap
2–3 heap
Soft heap
Pairing heap
Leftist heap
Treap
Beap
Skew heap
Ternary heap
D-ary heap
Brodal queue

Bit-slice trees
In these data structures each tree node compares a bit slice of key values.

Radix tree
Suffix tree
Suffix array
Compressed suffix array
FM-index
Generalised suffix tree
B-tree
Judy array
Trie
X-fast trie
Y-fast trie
Merkle tree

Multi-way trees
Ternary search tree
Ternary tree
K-ary tree
And–or tree
(a,b)-tree
Link/cut tree
SPQR-tree
Spaghetti stack
Disjoint-set data structure (Union-find data structure)
Fusion tree
Enfilade
Exponential tree
Fenwick tree
Van Emde Boas tree
Rose tree

Space-partitioning trees
These are data structures used for space partitioning or binary space partitioning.

Segment tree
Interval tree
Range tree
Bin
K-d tree
Implicit k-d tree
Min/max k-d tree
Relaxed k-d tree
Adaptive k-d tree
Quadtree
Octree
Linear octree
Z-order
UB-tree
R-tree
R+ tree
R* tree
Hilbert R-tree
X-tree
Metric tree
Cover tree
M-tree
VP-tree
BK-tree
Bounding interval hierarchy
Bounding volume hierarchy
BSP tree
Rapidly exploring random tree

Application-specific trees
Abstract syntax tree
Parse tree
Decision tree
Alternating decision tree
Minimax tree
Expectiminimax tree
Finger tree
Expression tree
Log-structured merge-tree

Hash-based structures
Bloom filter
Binary fuse filter
Cuckoo filter
Xor filter
Count–min sketch
Distributed hash table
Double hashing
Dynamic perfect hash table
Hash array mapped trie
Hash list
Hash table
Hash tree
Hash trie
Koorde
Prefix hash tree
Rolling hash
MinHash
Quotient filter
Ctrie

Graphs
Many graph-based data structures are used in computer science and related fields:

Graph
Adjacency list
Adjacency matrix
Graph-structured stack
Scene graph
Decision tree
Binary decision diagram
Zero-suppressed decision diagram
And-inverter graph
Directed graph
Directed acyclic graph
Propositional directed acyclic graph
Multigraph
Hypergraph

Other
Lightmap
Winged edge
Quad-edge
Routing table
Symbol table
Piece table
E-graph

See also
List of algorithms
Purely functional data structure
Blockchain, a hash-based chained data structure that can persist state history over time

External links
Tommy Benchmarks Comparison of several data structures.",177318,https://en.wikipedia.org/wiki/List_of_data_structures
Active data structure,"An active data structure is a data structure with an associated thread or process that performs internal operations. More specifically, an active data structure is associated with a computing resource, which contains one or more concurrently executing processes, and data associated with those processes. Communication is modeled using remote procedure calls, as opposed to shared memory or message passing. The active data structure's internals are hidden behind its RPC interface, and may be accessed concurrently. Common examples include databases and file systems. Active data structures can perform maintenance when resources would otherwise be idle, and present multiple views of the data.","An active data structure is a data structure with an associated thread or process that performs internal operations. More specifically, an active data structure is associated with a computing resource, which contains one or more concurrently executing processes, and data associated with those processes. Communication is modeled using remote procedure calls, as opposed to shared memory or message passing. The active data structure's internals are hidden behind its RPC interface, and may be accessed concurrently. Common examples include databases and file systems. Active data structures can perform maintenance when resources would otherwise be idle, and present multiple views of the data.

Example
A queue provided by the hardware or operating system is generally not unbounded, but rather has finite capacity. Suppose that the application has a strong requirement to never lose queue items. Then, the writing process must be modified to save items to a high-capacity storage medium if the queue is full, and the reading process must read the items back. Using the concept of active data structures, one can instead consider an ""active queue"" which manages saving and retrieving items from the high-capacity storage. Although there are now three running processes instead of two, potentially making synchronization more complex, the high level reader-writer abstraction for using an active queue is still simple and clear.

Formalization
Self-adjusting computation is a technique for creating incremental computing programs that maintain internal state and can adjust to new inputs more efficiently than recomputing from scratch. This suggests that active data structures can be formalized by introducing the notion of time to the typical algebraic characterization of data structures. Specifically, Kanat Tangwongsan proposes that an active data structure is an algebra with these three meta-operations:
perform(""operationi(·)"", t) will perform the operation operationi at the time t. If operationi(·) returns a value ri, then the meta-operation returns the value ri.
The meta-operation undo(t) causes an undo of the operation at the time t. This is used for modeling incremental computation.
The meta-operation update(t) informs the data structure to ""synchronize"" up to time t. This incorporates information about other processes.

See also
passive data structure

References

 This article incorporates public domain material from Paul E. Black. ""Active Data Structure"". Dictionary of Algorithms and Data Structures. NIST.",4436168,https://en.wikipedia.org/wiki/Active_data_structure
Block availability map,"In computer file systems, a block availability map (BAM)   is a data structure used to track disk blocks that are considered free (available for new data). It is used along with a directory to manage files on a disk (originally only a floppy disk, and later also a hard disk).
In terms of Commodore DOS (CBM DOS) compatible disk drives, the BAM was a data structure stored in a reserved area of the disk (its size and location varied based on the physical characteristics of the disk).  For each track, the BAM consisted of a bitmap of available blocks and (usually) a count of the available blocks.  The count was held in a single byte, as all formats had 256 or fewer blocks per track. The count byte was simply the sum of all 1-bits in the bitmap of bytes for the current track.
The following table illustrates the layout of Commodore 1541 BAM.  The table would be larger for higher-capacity disks (described below).

The bitmap was contained in 3 bytes for Commodore 1541 format (single-sided) disks because it had 17 to 20 sectors per track (note 3 bytes can hold at least 20 bits).  Similarly, the Commodore 1571 used 3 bytes for the bitmap of each track, but the BAM was twice the size because there were twice as many tracks when formatted as double-sided.  In contrast, the Commodore 1581 disk drive used 5 bytes for the bitmap because the disk format had 40 blocks per track (note 5 bytes can hold 40 bits).In the bitmap of any format, a 1 bit indicated the block was available (free), while a 0 bit indicated the block was not available (used), and the bitmap data was stored low-byte first.  So the first byte held a map for blocks 0 to 7, the second byte held a map for blocks 8 to 15, and so on.  Within a byte, the bitmap was ordered low-bit first.  For example, the first byte would represent block 0 with the least significant bit and block 7 with the most significant bit.
Storage devices by Creative Micro Designs, intended for use with CBM computers, also used a Block Availability Map which served the same purpose.  However, these devices (FD-2000, FD-4000, and CMD-HD) did not include a count byte, and the bits in each byte were reversed (high-bit first).  Although the bits were reversed (compared to CBM formats), the bytes were still stored in the same order (low-byte first).","In computer file systems, a block availability map (BAM)   is a data structure used to track disk blocks that are considered free (available for new data). It is used along with a directory to manage files on a disk (originally only a floppy disk, and later also a hard disk).
In terms of Commodore DOS (CBM DOS) compatible disk drives, the BAM was a data structure stored in a reserved area of the disk (its size and location varied based on the physical characteristics of the disk).  For each track, the BAM consisted of a bitmap of available blocks and (usually) a count of the available blocks.  The count was held in a single byte, as all formats had 256 or fewer blocks per track. The count byte was simply the sum of all 1-bits in the bitmap of bytes for the current track.
The following table illustrates the layout of Commodore 1541 BAM.  The table would be larger for higher-capacity disks (described below).

The bitmap was contained in 3 bytes for Commodore 1541 format (single-sided) disks because it had 17 to 20 sectors per track (note 3 bytes can hold at least 20 bits).  Similarly, the Commodore 1571 used 3 bytes for the bitmap of each track, but the BAM was twice the size because there were twice as many tracks when formatted as double-sided.  In contrast, the Commodore 1581 disk drive used 5 bytes for the bitmap because the disk format had 40 blocks per track (note 5 bytes can hold 40 bits).In the bitmap of any format, a 1 bit indicated the block was available (free), while a 0 bit indicated the block was not available (used), and the bitmap data was stored low-byte first.  So the first byte held a map for blocks 0 to 7, the second byte held a map for blocks 8 to 15, and so on.  Within a byte, the bitmap was ordered low-bit first.  For example, the first byte would represent block 0 with the least significant bit and block 7 with the most significant bit.
Storage devices by Creative Micro Designs, intended for use with CBM computers, also used a Block Availability Map which served the same purpose.  However, these devices (FD-2000, FD-4000, and CMD-HD) did not include a count byte, and the bits in each byte were reversed (high-bit first).  Although the bits were reversed (compared to CBM formats), the bytes were still stored in the same order (low-byte first).

See also
File Allocation Table (FAT)
Design of the FAT file system
Free space bitmap


== References ==",38426261,https://en.wikipedia.org/wiki/Block_availability_map
Comparison of data structures,"This is a comparison of the performance of notable data structures, as measured by the complexity of their logical operations. For a more comprehensive listing of data structures, see List of data structures.
The comparisons in this article are organized by abstract data type. As a single concrete data structure may be used to implement many abstract data types, some data structures may appear in multiple comparisons (for example, a hash map can be used to implement an associative array or a set).","This is a comparison of the performance of notable data structures, as measured by the complexity of their logical operations. For a more comprehensive listing of data structures, see List of data structures.
The comparisons in this article are organized by abstract data type. As a single concrete data structure may be used to implement many abstract data types, some data structures may appear in multiple comparisons (for example, a hash map can be used to implement an associative array or a set).

Lists
A list or sequence is an abstract data type that represents a finite number of ordered values, where the same value may occur more than once. Lists generally support the following operations:

peek: access the element at a given index.
insert: insert a new element at a given index. When the index is zero, this is called prepending; when the index is the last index in the list it is called appending.
delete: remove the element at a given index.

Maps
Maps store a collection of (key, value) pairs, such that each possible key appears at most once in the collection. They generally support three operations:
Insert: add a new (key, value) pair to the collection, mapping the key to its new value. Any existing mapping is overwritten. The arguments to this operation are the key and the value.
Remove: remove a (key, value) pair from the collection, unmapping a given key from its value. The argument to this operation is the key.
Lookup: find the value (if any) that is bound to a given key. The argument to this operation is the key, and the value is returned from the operation.Unless otherwise noted, all data structures in this table require O(n) space.

Integer keys
Some map data structures offer superior performance in the case of integer keys. In the following table, let m be the number of bits in the keys.

Priority queues
A priority queue is an  abstract data-type similar to a regular queue or stack. Each element in a priority queue has an associated priority. In a priority queue, elements with high priority are served before elements with low priority. Priority queues support the following operations:

insert: add an element to the queue with an associated priority.
find-max: return the element from the queue that has the highest priority.
delete-max: remove the element from the queue that has the highest priority.Priority queues are frequently implemented using heaps.

Heaps
A (max) heap is a tree-based data structure which satisfies the heap property: for any given node C, if P is a parent node of C, then the key (the value) of P is greater than or equal to the key of C.
In addition to the operations of an abstract priority queue, the following table lists the complexity of two additional logical operations:

increase-key: updating a key.
meld: joining two heaps to form a valid new heap containing all the elements of both, destroying the original heaps.Here are time complexities of various heap data structures. Function names assume a max-heap.  For the meaning of ""O(f)"" and ""Θ(f)"" see Big O notation.

Notes
References
Cormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L.; Stein, Clifford (2022-04-05). Introduction to Algorithms, fourth edition. MIT Press. ISBN 978-0-262-36750-9.",73255051,https://en.wikipedia.org/wiki/Comparison_of_data_structures
Compressed data structure,"The term compressed data structure arises in the computer science subfields of algorithms, data structures, and theoretical computer science.  It refers to a data structure whose operations are roughly as fast as those of a conventional data structure for the problem, but whose size can be substantially smaller.  The size of the compressed data structure is typically highly dependent upon the information entropy of the data being represented.  
Important examples of compressed data structures include the compressed suffix array and the FM-index,both of which can represent an arbitrary text of characters T for pattern matching.  Given any input pattern P, they support the operation of finding if and where P appears in T.  The search time is proportional to the sum of the length of pattern P, a very slow-growing function of the length of the text T, and the number of reported matches.  The space they occupy is roughly equal to the size of the text T in entropy-compressed form, such as that obtained by Prediction by Partial Matching or gzip.  Moreover, both data structures are self-indexing, in that they can reconstruct the text T in a random access manner, and thus the underlying text T can be discarded.  In other words, they simultaneously provide a compressed and quickly searchable representation of the text T.  They represent a substantial space improvement over the conventional suffix tree and suffix array, which occupy many times more space than the size of T.  They also support searching for arbitrary patterns, as opposed to the inverted index, which can support only word-based searches.  In addition, inverted indexes do not have the self-indexing feature. 
An important related notion is that of a succinct data structure, which uses space roughly equal to the information-theoretic minimum, which is a worst-case notion of the space needed to represent the data.  In contrast, the size of a compressed data structure depends upon the particular data being represented.  When the data are compressible, as is often the case in practice for natural language text, the compressed data structure can occupy space very close to the information-theoretic minimum, and significantly less space than most compression schemes.


== References ==","The term compressed data structure arises in the computer science subfields of algorithms, data structures, and theoretical computer science.  It refers to a data structure whose operations are roughly as fast as those of a conventional data structure for the problem, but whose size can be substantially smaller.  The size of the compressed data structure is typically highly dependent upon the information entropy of the data being represented.  
Important examples of compressed data structures include the compressed suffix array and the FM-index,both of which can represent an arbitrary text of characters T for pattern matching.  Given any input pattern P, they support the operation of finding if and where P appears in T.  The search time is proportional to the sum of the length of pattern P, a very slow-growing function of the length of the text T, and the number of reported matches.  The space they occupy is roughly equal to the size of the text T in entropy-compressed form, such as that obtained by Prediction by Partial Matching or gzip.  Moreover, both data structures are self-indexing, in that they can reconstruct the text T in a random access manner, and thus the underlying text T can be discarded.  In other words, they simultaneously provide a compressed and quickly searchable representation of the text T.  They represent a substantial space improvement over the conventional suffix tree and suffix array, which occupy many times more space than the size of T.  They also support searching for arbitrary patterns, as opposed to the inverted index, which can support only word-based searches.  In addition, inverted indexes do not have the self-indexing feature. 
An important related notion is that of a succinct data structure, which uses space roughly equal to the information-theoretic minimum, which is a worst-case notion of the space needed to represent the data.  In contrast, the size of a compressed data structure depends upon the particular data being represented.  When the data are compressible, as is often the case in practice for natural language text, the compressed data structure can occupy space very close to the information-theoretic minimum, and significantly less space than most compression schemes.


== References ==",24757213,https://en.wikipedia.org/wiki/Compressed_data_structure
Dynamization,"In computer science, dynamization is the process of transforming a static data structure into a dynamic one. Although static data structures may provide very good functionality and fast queries, their utility is limited because of their inability to grow/shrink quickly, thus making them inapplicable for the solution of dynamic problems, where the input data changes. Dynamization techniques provide uniform ways of creating dynamic data structures.","In computer science, dynamization is the process of transforming a static data structure into a dynamic one. Although static data structures may provide very good functionality and fast queries, their utility is limited because of their inability to grow/shrink quickly, thus making them inapplicable for the solution of dynamic problems, where the input data changes. Dynamization techniques provide uniform ways of creating dynamic data structures.

Decomposable search problems
We define problem P{\displaystyle P} of searching for the predicate M{\displaystyle M} match in the set S{\displaystyle S} as P(M,S){\displaystyle P(M,S)}. Problem P{\displaystyle P} is decomposable if the set S{\displaystyle S} can be decomposed into subsets Si{\displaystyle S_{i}} and there exists an operation +{\displaystyle +} of result unification such that P(M,S)=P(M,S0)+P(M,S1)+⋯+P(M,Sn){\displaystyle P(M,S)=P(M,S_{0})+P(M,S_{1})+\dots +P(M,S_{n})}.

Decomposition
Decomposition is a term used in computer science to break static data structures into smaller units of unequal size. The basic principle is the idea that any decimal number can be translated into a representation in any other base. For more details about the topic see Decomposition (computer science). For simplicity, binary system will be used in this article but any other base (as well as other possibilities such as Fibonacci numbers) can also be utilized.
If using the binary system, a set of n{\displaystyle n} elements is broken down into subsets of sizes with 

2i∗ni{\displaystyle 2^{i}*n_{i}}elements where ni{\displaystyle n_{i}} is the  i{\displaystyle i}-th bit of n{\displaystyle n} in binary. This means that if n{\displaystyle n} has i{\displaystyle i}-th bit equal to 0, the corresponding set does not contain any elements. Each of the subset has the same property as the original static data structure. Operations performed on the new dynamic data structure may involve traversing log2⁡(n){\displaystyle \log _{2}\left(n\right)} sets formed by decomposition. As a result, this will add O(log⁡(n)){\displaystyle O(\log \left(n\right))}  factor as opposed to the static data structure operations but will allow insert/delete operation to be added. 
Kurt Mehlhorn proved several equations for time complexity of operations on the data structures dynamized according to this idea. Some of these equalities are listed. 
If 

PS(n){\displaystyle P_{S}\left(n\right)} is the time to build the static data structure
QS(n){\displaystyle Q_{S}\left(n\right)} is the time to query the static data structure
QD(n){\displaystyle Q_{D}\left(n\right)} is the time to query the dynamic data structure formed by decomposition
I¯{\displaystyle {\overline {I}}} is the amortized insertion timethen

QD(n)=O(QS(n)⋅log⁡(n)){\displaystyle Q_{D}\left(n\right)=O\left(Q_{S}\left(n\right)\cdot \log \left(n\right)\right)}
I¯=O((PS(n)/n)⋅log⁡(n)).{\displaystyle {\overline {I}}=O\left(\left(P_{S}\left(n\right)/n\right)\cdot \log \left(n\right)\right).}If QS(n){\displaystyle Q_{S}\left(n\right)} is at least polynomial, then QD(n)=O(QS(n)){\displaystyle Q_{D}\left(n\right)=O\left(Q_{S}\left(n\right)\right)}.

Further reading
Kurt Mehlhorn, Data structures and algorithms 3, . An EATCS Series, vol. 3, Springer, 1984.",3641207,https://en.wikipedia.org/wiki/Dynamization
Implicit data structure,"In computer science, an implicit data structure or space-efficient data structure is a data structure that stores very little information other than the main or required data: a data structure that requires low overhead. They are called ""implicit"" because the position of the elements carries meaning and relationship between elements; this is contrasted with the use of pointers to give an explicit relationship between elements. Definitions of ""low overhead"" vary, but generally means constant overhead; in big O notation, O(1) overhead. A less restrictive definition is a succinct data structure, which allows greater overhead.","In computer science, an implicit data structure or space-efficient data structure is a data structure that stores very little information other than the main or required data: a data structure that requires low overhead. They are called ""implicit"" because the position of the elements carries meaning and relationship between elements; this is contrasted with the use of pointers to give an explicit relationship between elements. Definitions of ""low overhead"" vary, but generally means constant overhead; in big O notation, O(1) overhead. A less restrictive definition is a succinct data structure, which allows greater overhead.

Definition
An implicit data structure is one with constant O(1) space overhead (above the information-theoretic lower bound).
Historically, Munro & Suwanda (1980) defined an implicit data structure (and algorithms acting on one) as one ""in which structural information is implicit in the way data are stored, rather than explicit in pointers."" They are somewhat vague in the definition, defining it most strictly as a single array, with only the size retained (a single number of overhead), or more loosely as a data structure with constant overhead (O(1)). This latter definition is today more standard, and the still-looser notion of a data structure with non-constant but small o(n) overhead is today known as a succinct data structure, as defined by Jacobson (1988); it was referred to as semi-implicit by Munro & Suwanda (1980).A fundamental distinction is between static data structures (read-only) and dynamic data structures (which can be modified). Simple implicit data structures, such as representing a sorted list as an array, may be very efficient as a static data structure, but inefficient as a dynamic data structure, due to modification operations (such as insertion in the case of a sorted list) being inefficient.

Examples
A trivial example of an implicit data structure is an array data structure, which is an implicit data structure for a list, and requires only the constant overhead of the length; unlike a linked list, which has a pointer associated with each data element, which explicitly gives the relationship from one element to the next. Similarly, a null-terminated string is an implicit data structure for a string (list of characters). These are considered very simple because they are static data structures (read-only), and only admit the simple operation of iteration over the elements.
Similarly simple is representing a multi-dimensional array as a single 1-dimensional array, together with its dimensions. For example, representing an m × n array as a single list of length m·n, together with the numbers m and n (instead of as a 1-dimensional array of pointers to each 1-dimensional subarray). The elements need not be of the same type, and a table of data (a list of records) may similarly be represented implicitly as a flat (1-dimensional) list, together with the length of each field, so long as each field has uniform size (so a single size can be used per field, not per record).
A less trivial example is representing a sorted list by a sorted array, which allows search in logarithmic time by binary search. Contrast with a search tree, specifically a binary search tree, which also allows logarithmic-time search, but requires pointers. A sorted array is only efficient as a static data structure, as modifying the list is slow – unlike a binary search tree – but does not require the space overhead of a tree.
An important example of an implicit data structure is representing a perfect binary tree as a list, in increasing order of depth, so root, first left child, first right child, first left child of first left child, etc. Such a tree occurs notably for an ancestry chart to a given depth, and the implicit representation is known as an Ahnentafel (ancestor table).
This can be generalized to a complete binary tree (where the last level may be incomplete), which yields the best-known example of an implicit data structure, namely the binary heap, which is an implicit data structure for a priority queue. This is more sophisticated than earlier examples because it allows multiple operations, and is an efficient dynamic data structure (it allows efficient modification of the data): not only top, but also insert and pop.
More sophisticated implicit data structures include the beap (bi-parental heap).

History
The trivial examples of lists or tables of values date to prehistory, while historically non-trivial implicit data structures date at least to the Ahnentafel, which was introduced by Michaël Eytzinger in 1590 for use in genealogy. In formal computer science, the first implicit data structure is generally considered to be the sorted list, used for binary search, which was introduced by John Mauchly in 1946, in the Moore School Lectures, the first ever set of lectures regarding any computer-related topic. The binary heap was introduced in Williams (1964) to implement the heapsort. The notion of an implicit data structure was formalized in Munro & Suwanda (1980), as part of introducing and analyzing the beap.

References
Further reading
See publications of Hervé Brönnimann, J. Ian Munro, and Greg Frederickson.",3669635,https://en.wikipedia.org/wiki/Implicit_data_structure
Monoque,"A monoque is a linear data structure which provides dynamic array semantics. A monoque is similar in structure to a deque but is limited to operations on one end. Hence the name, mono-que. A monoque offers O(1) random access and O(1) push_back/pop_back. Unlike a C++ vector, the push_back/pop_back functions are not amortized and are strictly O(1) in time complexity.  Because the block list is never reallocated or resized, it maintains strictly O(1) non-amortized worst case performance. Unlike C++'s deque, the O(1) performance guarantee includes the time complexity of working with the block list, whereas the C++ standard only guarantees the deque to be O(1) in terms of operations on the underlying value type.
The monoque consists of a size variable and a fixed-size block list of blocks with exponentially increasing sizes. Thus, the size of the monoque in bits is roughly proportional to the square of the system pointer size. Though arguably O(lg N) in size, because lg(pointer_size) is constant on any particular machine the block list is O(1) in size and is an upper bound to O(lg(N)), it bounds the space complexity of the structure by a constant.","A monoque is a linear data structure which provides dynamic array semantics. A monoque is similar in structure to a deque but is limited to operations on one end. Hence the name, mono-que. A monoque offers O(1) random access and O(1) push_back/pop_back. Unlike a C++ vector, the push_back/pop_back functions are not amortized and are strictly O(1) in time complexity.  Because the block list is never reallocated or resized, it maintains strictly O(1) non-amortized worst case performance. Unlike C++'s deque, the O(1) performance guarantee includes the time complexity of working with the block list, whereas the C++ standard only guarantees the deque to be O(1) in terms of operations on the underlying value type.
The monoque consists of a size variable and a fixed-size block list of blocks with exponentially increasing sizes. Thus, the size of the monoque in bits is roughly proportional to the square of the system pointer size. Though arguably O(lg N) in size, because lg(pointer_size) is constant on any particular machine the block list is O(1) in size and is an upper bound to O(lg(N)), it bounds the space complexity of the structure by a constant.",54593071,https://en.wikipedia.org/wiki/Monoque
Oblivious data structure,"In computer science, an oblivious data structure is a data structure that gives no information about the sequence or pattern of the operations that have been applied except for the final result of the operations.In most conditions, even if the data is encrypted, the access pattern can be achieved, and this pattern can leak some important information such as encryption keys. And in the outsourcing of cloud data, this leakage of access pattern is still very serious.  An access pattern is a specification of an access mode for every attribute of a relation schema. For example, the sequences of user read or write the data in the cloud are access patterns.
We say a machine is oblivious if the sequence in which it accesses is equivalent for any two inputs with the same running time. So the data access pattern is independent from the input.
Applications:

Cloud data outsourcing: When writing or reading data from a cloud server, oblivious data structures are useful. And modern databases rely on data structures heavily, so oblivious data structures come in handy.
Secure processor: Tamper-resilient secure processors are used for defense against physical attacks or the malicious intruders access the users’ computer platforms. The existing secure processors designed in academia and industry include AEGIS and Intel SGX. But the memory addresses are still transferred in the clear on the memory bus. So the research finds that this memory buses can give out the information about encryption keys. With the Oblivious data structure comes in practical, the secure processor can obfuscate memory access pattern in a provably secure manner.
Secure computation: Traditionally people used circuit-model to do the secure computation, but the model is not enough for the security when the amount of data is getting big. RAM-model secure computation was proposed as an alternative to the traditional circuit model, and oblivious data structure is used to prevent information access behavioral being stolen.","In computer science, an oblivious data structure is a data structure that gives no information about the sequence or pattern of the operations that have been applied except for the final result of the operations.In most conditions, even if the data is encrypted, the access pattern can be achieved, and this pattern can leak some important information such as encryption keys. And in the outsourcing of cloud data, this leakage of access pattern is still very serious.  An access pattern is a specification of an access mode for every attribute of a relation schema. For example, the sequences of user read or write the data in the cloud are access patterns.
We say a machine is oblivious if the sequence in which it accesses is equivalent for any two inputs with the same running time. So the data access pattern is independent from the input.
Applications:

Cloud data outsourcing: When writing or reading data from a cloud server, oblivious data structures are useful. And modern databases rely on data structures heavily, so oblivious data structures come in handy.
Secure processor: Tamper-resilient secure processors are used for defense against physical attacks or the malicious intruders access the users’ computer platforms. The existing secure processors designed in academia and industry include AEGIS and Intel SGX. But the memory addresses are still transferred in the clear on the memory bus. So the research finds that this memory buses can give out the information about encryption keys. With the Oblivious data structure comes in practical, the secure processor can obfuscate memory access pattern in a provably secure manner.
Secure computation: Traditionally people used circuit-model to do the secure computation, but the model is not enough for the security when the amount of data is getting big. RAM-model secure computation was proposed as an alternative to the traditional circuit model, and oblivious data structure is used to prevent information access behavioral being stolen.

Oblivious data structures
Oblivious RAM
Goldreich and Ostrovsky proposed this term on software protection.
The memory access of oblivious RAM is probabilistic and the probabilistic distribution is independent of the input. In the paper composed by Goldreich and Ostrovsky have theorem to oblivious RAM: Let RAM(m) denote a RAM with m memory locations and access to a random oracle machine. Then t steps of an arbitrary RAM(m) program can be simulated by less than O(t(log2⁡t)3){\displaystyle O(t(\log _{2}t)^{3})} steps of an oblivious RAM(m(log2⁡m)2){\displaystyle \mathrm {RAM} (m(\log _{2}m)^{2})}. Every oblivious simulation of RAM(m) must make at least max{m,(t−1)log2⁡m}{\displaystyle \max\{m,(t-1)\log _{2}m\}} accesses in order to simulate t steps.
Now we have the square-root algorithm to simulate the oblivious ram working.

For each m{\displaystyle {\sqrt {m}}} accesses, randomly permute first m+m{\displaystyle m+{\sqrt {m}}} memory.
Check the shelter words first if we want to access a word.
If the word is there, access one of the dummy words. And if the word is not there, find the permuted location.To access original RAM in t steps we need to simulate it with t+m{\displaystyle t+{\sqrt {m}}}  steps for the oblivious RAM. For each access, the cost would be O(m⋅log⁡m{\displaystyle {\sqrt {m}}\cdot \log m}).
Another way to simulate is hierarchical algorithm. The basic idea is to consider the shelter memory as a buffer, and extend it to the multiple levels of buffers. For level I, there are 4i{\displaystyle 4^{i}} buckets and for each bucket has log t items. For each level there is a random selected hash function.
The operation is like the following: At first load program to the last level, which can be say has 4t{\displaystyle 4^{t}} buckets. For reading, check the bucket hi(V){\displaystyle h_{i}(V)} from each level, If (V,X) is already found, pick a bucket randomly to access, and if it is not found, check the bucket hi(V){\displaystyle h_{i}(V)}, there is only one real match and remaining are dummy entries . For writing, put (V,X) to the first level, and if the first I levels are full, move all I levels to I+1{\displaystyle I+1} levels and empty the first I levels.
The time cost for each level cost O(log t); cost for every access is O((log⁡t)2){\displaystyle O((\log t)^{2})}; The cost of Hashing is O(t(log⁡t)3){\displaystyle O(t(\log t)^{3})}.

Oblivious tree
An Oblivious Tree is a rooted tree with the following property:

All the leaves are in the same level.
All the internal nodes have degree at most 3.
Only the nodes along the rightmost path in the tree may have degree of one.The oblivious tree is a data structure similar to 2–3 tree, but with the additional property of being oblivious. The rightmost path may have degree one and this can help to describe the update algorithms. Oblivious tree requires randomization to achieve a O(log⁡(n)){\displaystyle O(\log(n))} running time for the update operations. And for two sequences of operations M and N acting to the tree, the output of the tree has the same output probability distributions. For the tree, there are three operations:

CREATE (L)
build a new tree storing the sequence of values L at its leaves.
INSERT (b, i,T)
insert a new leaf node storing the value b as the ith leaf of the tree T.
DELETE (i, T)
remove the ith leaf from T.Step of Create: The list of nodes at the ithlevel is obtained traversing the list of nodes at level i+1 from left to right and repeatedly doing the following:

Choose d {2, 3} uniformly at random.
If there are less than d nodes left at level i+1, set d equal to the number of nodes left.
Create a new node n at level I with the next d nodes at level i+1 as children and compute the size of n as the sum of the sizes of its children.For example, if the coin tosses of d {2, 3} has an outcome of: 2, 3, 2, 2, 2, 2, 3 stores the string “OBLIVION” as follow oblivious tree.
Both the INSERT (b, I, T) and DELETE(I, T) have the O(log n) expected running time. And for INSERT and DELETE
we have:

INSERT (b, I, CREATE (L)) = CREATE (L [1] + …….., L[ i], b, L[i+1]………..)
DELETE (I, CREATE (L)) = CREATE (L[1]+ ………L[I - 1], L[i+1], ………..)

For example, if the CREATE (ABCDEFG) or INSERT (C, 2, CREATE (ABDEFG)) is run, it yields the same probabilities of out come between these two operations.


== References ==",48730466,https://en.wikipedia.org/wiki/Oblivious_data_structure
Partition refinement,"In the design of algorithms, partition refinement is a technique for representing a partition of a set as a data structure that allows the partition to be refined by splitting its sets into a larger number of smaller sets. In that sense it is dual to the union-find data structure, which also maintains a partition into disjoint sets but in which the operations merge pairs of sets. In some applications of partition refinement, such as lexicographic breadth-first search, the data structure maintains as well an ordering on the sets in the partition.
Partition refinement forms a key component of several efficient algorithms on graphs and finite automata, including DFA minimization, the Coffman–Graham algorithm for parallel scheduling, and lexicographic breadth-first search of graphs.","In the design of algorithms, partition refinement is a technique for representing a partition of a set as a data structure that allows the partition to be refined by splitting its sets into a larger number of smaller sets. In that sense it is dual to the union-find data structure, which also maintains a partition into disjoint sets but in which the operations merge pairs of sets. In some applications of partition refinement, such as lexicographic breadth-first search, the data structure maintains as well an ordering on the sets in the partition.
Partition refinement forms a key component of several efficient algorithms on graphs and finite automata, including DFA minimization, the Coffman–Graham algorithm for parallel scheduling, and lexicographic breadth-first search of graphs.

Data structure
A partition refinement algorithm maintains a family of disjoint sets Si. At the start of the algorithm, this family contains a single set of all the elements in the data structure. At each step of the algorithm, a set X is presented to the algorithm, and each set Si in the family that contains members of X is split into two sets, the intersection Si ∩ X and the difference Si \ X.
Such an algorithm may be implemented efficiently by maintaining data structures representing the following information:
The ordered sequence of the sets Si in the family, in a form such as a doubly linked list that allows new sets to be inserted into the middle of the sequence
Associated with each set Si, a collection of its elements of Si, in a form such as a doubly linked list or array data structure that allows for rapid deletion of individual elements from the collection. Alternatively, this component of the data structure may be represented by storing all of the elements of all of the sets in a single array, sorted by the identity of the set they belong to, and by representing the collection of elements in any set Si by its starting and ending positions in this array.
Associated with each element, the set it belongs to.To perform a refinement operation, the algorithm loops through the elements of the given set X. For each such element x, it finds the set Si that contains x, and checks whether a second set for Si ∩ X has already been started. If not, it creates the second set and adds Si to a list L of the sets that are split by the operation.
Then, regardless of whether a new set was formed, the algorithm removes x from Si and adds it to Si ∩ X. In the representation in which all elements are stored in a single array, moving x from one set to another may be performed by swapping x with the final element of Si and then decrementing the end index of Si and the start index of the new set. Finally, after all elements of X have been processed in this way, the algorithm loops through L, separating each current set Si from the second set that has been split from it, and reports both of these sets as being newly formed by the refinement operation.
The time to perform a single refinement operation in this way is O(|X|), independent of the number of elements in the family of sets and also independent of the total number of sets in the data structure. Thus, the time for a sequence of refinements is proportional to the total size of the sets given to the algorithm in each refinement step.

Applications
An early application of partition refinement was in an algorithm by Hopcroft (1971) for DFA minimization. In this problem, one is given as input a deterministic finite automaton, and must find an equivalent automaton with as few states as possible. Hopcroft's algorithm maintains a partition of the states of the input automaton into subsets, with the property that any two states in different subsets must be mapped to different states of the output automaton. Initially, there are two subsets, one containing all the accepting states of the automaton and one containing the remaining states. At each step one of the subsets Si and one of the input symbols x of the automaton are chosen, and the subsets of states are refined into states for which a transition labeled x would lead to Si, and states for which an x-transition would lead somewhere else. When a set Si that has already been chosen is split by a refinement, only one of the two resulting sets (the smaller of the two) needs to be chosen again; in this way, each state participates in the sets X for O(s log n) refinement steps and the overall algorithm takes time O(ns log n), where n is the number of initial states and s is the size of the alphabet.Partition refinement was applied  by Sethi (1976) in an efficient implementation of the Coffman–Graham algorithm for parallel scheduling. Sethi showed that it could be used to construct a lexicographically ordered topological sort of a given directed acyclic graph in linear time; this lexicographic topological ordering is one of the key steps of the Coffman–Graham algorithm. In this application, the elements of the disjoint sets are vertices of the input graph and the sets X used to refine the partition are sets of neighbors of vertices. Since the total number of neighbors of all vertices is just the number of edges in the graph, the algorithm takes time linear in the number of edges, its input size.Partition refinement also forms a key step in lexicographic breadth-first search, a graph search algorithm with applications in the recognition of chordal graphs and several other important classes of graphs. Again, the disjoint set elements are vertices and the set X represents sets of neighbors, so the algorithm takes linear time.


== References ==",31595644,https://en.wikipedia.org/wiki/Partition_refinement
Persistent data structure,"In computing, a persistent data structure or not ephemeral data structure is a data structure that always preserves the previous version of itself when it is modified. Such data structures are effectively immutable, as their operations do not (visibly) update the structure in-place, but instead always yield a new updated structure. The term was introduced in Driscoll, Sarnak, Sleator, and Tarjan's 1986 article.A data structure is partially persistent if all versions can be accessed but only the newest version can be modified. The data structure is fully persistent if every version can be both accessed and modified. If there is also a meld or merge operation that can create a new version from two previous versions, the data structure is called confluently persistent. Structures that are not persistent are called ephemeral.These types of data structures are particularly common in logical and functional programming, as languages in those paradigms discourage (or fully forbid) the use of mutable data.","In computing, a persistent data structure or not ephemeral data structure is a data structure that always preserves the previous version of itself when it is modified. Such data structures are effectively immutable, as their operations do not (visibly) update the structure in-place, but instead always yield a new updated structure. The term was introduced in Driscoll, Sarnak, Sleator, and Tarjan's 1986 article.A data structure is partially persistent if all versions can be accessed but only the newest version can be modified. The data structure is fully persistent if every version can be both accessed and modified. If there is also a meld or merge operation that can create a new version from two previous versions, the data structure is called confluently persistent. Structures that are not persistent are called ephemeral.These types of data structures are particularly common in logical and functional programming, as languages in those paradigms discourage (or fully forbid) the use of mutable data.

Partial versus full persistence
In the partial persistence model, a programmer may query any previous version of a data structure, but may only update the latest version. This implies a linear ordering among each version of the data structure. In the fully persistent model, both updates and queries are allowed on any version of the data structure. In some cases the performance characteristics of querying or updating older versions of a data structure may be allowed to degrade, as is true with the rope data structure. In addition, a data structure can be referred to as confluently persistent if, in addition to being fully persistent, two versions of the same data structure can be combined to form a new version which is still fully persistent.

Techniques for preserving previous versions
Copy-on-write
One method for creating a persistent data structure is to use a platform provided ephemeral data structure such as an array to store the data in the data structure and copy the entirety of that data structure using copy-on-write semantics for any updates to the data structure. This is an inefficient technique because the entire backing data structure must be copied for each write, leading to worst case O(n·m) performance characteristics for m modifications of an array of size n.

Fat node
The fat node method is to record all changes made to node fields in the nodes themselves, without erasing old values of the fields. This requires that nodes be allowed to become arbitrarily “fat”. In other words, each fat node contains the same information and pointer fields as an ephemeral node, along with space for an arbitrary number of extra field values. Each extra field value has an associated field name and a version stamp which indicates the version in which the named field was changed to have the specified value. Besides, each fat node has its own version stamp, indicating the version in which the node was created. The only purpose of nodes having version stamps is to make sure that each node only contains one value per field name per version. In order to navigate through the structure, each original field value in a node has a version stamp of zero.

Complexity of fat node
With using fat node method, it requires O(1) space for every modification: just store the new data. Each modification takes O(1) additional time to store the modification at the end of the modification history. This is an amortized time bound, assuming modification history is stored in a growable array. At access time, the right version at each node must be found as the structure is traversed. If ""m"" modifications were to be made, then each access operation would have O(log m) slowdown resulting from the cost of finding the nearest modification in the array.

Path copying
With the path copying method a copy of all nodes is made on the path to any node which is about to be modified. These changes must then be cascaded back through the data structure: all nodes that pointed to the old node must be modified to point to the new node instead. These modifications cause more cascading changes, and so on, until the root node is reached.

Complexity of path copying
With m modifications, this costs O(log m) additive lookup time. Modification time and space are bounded by the size of the longest path in the data structure and the cost of the update in the ephemeral data structure.  In a Balanced Binary Search Tree without parent pointers the worst case modification time complexity is O(log n + update cost). However, in a linked list the worst case modification time complexity is O(n + update cost).

A combination
Driscoll, Sarnak, Sleator, Tarjan came up with a way to combine the techniques of fat nodes and path copying, achieving O(1) access slowdown and O(1) modification space and time complexity.
In each node, one modification box is stored. This box can hold one modification to the node—either a modification to one of the pointers, or to the node's key, or to some other piece of node-specific data—and a timestamp for when that modification was applied. Initially, every node's modification box is empty.
Whenever a node is accessed, the modification box is checked, and its timestamp is compared against the access time. (The access time specifies the version of the data structure being considered.) If the modification box is empty, or the access time is before the modification time, then the modification box is ignored and only the normal part of the node is considered. On the other hand, if the access time is after the modification time, then the value in the modification box is used, overriding that value in the node.
Modifying a node works like this. (It is assumed that each modification touches one pointer or similar field.) If the node's modification box is empty, then it is filled with the modification. Otherwise, the modification box is full. A copy of the node is made, but using only the latest values. The modification is performed directly on the new node, without using the modification box. (One of the new node's fields is overwritten and its modification box stays empty.) Finally, this change is cascaded to the node's parent, just like path copying. (This may involve filling the parent's modification box, or making a copy of the parent recursively. If the node has no parent—it's the root—it is added the new root to a sorted array of roots.)
With this algorithm, given any time t, at most one modification box exists in the data structure with time t. Thus, a modification at time t splits the tree into three parts: one part contains the data from before time t, one part contains the data from after time t, and one part was unaffected by the modification.

Complexity of the combination
Time and space for modifications require amortized analysis. A modification takes O(1) amortized space, and O(1) amortized time. To see why, use a potential function ϕ, where ϕ(T) is the number of full live nodes in T . The live nodes of T are just the nodes that are reachable from the current root at the current time (that is, after the last modification). The full live nodes are the live nodes whose modification boxes are full.
Each modification involves some number of copies, say k, followed by 1 change to a modification box. Consider each of the k copies. Each costs O(1) space and time, but decreases the potential function by one. (First, the node to be copied must be full and live, so it contributes to the potential function. The potential function will only drop, however, if the old node isn't reachable in the new tree. But it is known that it isn't reachable in the new tree—the next step in the algorithm will be to modify the node's parent to point at the copy. Finally, it is known that the copy's modification box is empty. Thus, replaced a full live node has been replaced with an empty live node, and ϕ goes down by one.) The final step fills a modification box, which costs O(1) time and increases ϕ by one.
Putting it  all together, the change in ϕ is Δϕ =1− k. Thus, the algorithm takes O(k +Δϕ)= O(1) space and O(k +Δϕ +1) = O(1) time

Generalized form of persistence
Path copying is one of the simple methods to achieve persistency in a certain data structure such as binary search trees. It is nice to have a general strategy for implementing persistence that works with any given data structure. In order to achieve that, we consider a directed graph G. We assume that each vertex v in G has a constant number c of outgoing edges that are represented by pointers. Each vertex has a label representing the data. We consider that a vertex has a bounded number d of edges leading into it which we define as inedges(v). We allow the following different operations on G. 

CREATE-NODE(): Creates a new vertex with no incoming or outgoing edges.
CHANGE-EDGE(v, i, u): Changes the ith edge of v to point to u
CHANGE-LABEL(v, x): Changes the value of the data stored at v to xAny of the above operations is performed at a specific time and the purpose of the persistent graph representation is to be able to access any version of G at any given time. For this purpose we define a table for each vertex v in G. The table contains c columns and d+1{\displaystyle d+1} rows. Each row contains in addition to the pointers for the outgoing edges, a label which represents the data at the vertex and a time t at which the operation was performed. In addition to that there is an array inedges(v) that keeps track of all the incoming edges to v. When a table is full, a new table with d+1{\displaystyle d+1} rows can be created. The old table becomes inactive and the new table becomes the active table.

CREATE-NODE
A call to CREATE-NODE creates a new table and set all the references to null

CHANGE-EDGE
If we assume that CHANGE-EDGE(v, i, u) is called, then there are two cases to consider. 

There is an empty row in the table of the vertex v: In this case we copy the last row in the table and we change the ith edge of vertex v to point to the new vertex u
Table of the vertex v is full: In this case we need to create a new table. We copy the last row of the old table into the new table. We need to loop in the array inedges(v) in order to let each vertex in the array point to the new table created. In addition to that, we need to change the entry v in the inedges(w) for every vertex w such that edge v,w exists in the graph G.

CHANGE-LABEL
It works exactly the same as CHANGE-EDGE except that instead of changing the ith edge of the vertex, we change the ith label.

Efficiency of the generalized persistent data structure
In order to find the efficiency of the scheme proposed above, we use an argument defined as a credit scheme. The credit represents a currency. For example, the credit can be used to pay for a table. The argument states the following:

The creation of one table requires one credit
Each call to CREATE-NODE comes with two credits
Each call to CHANGE-EDGE comes with one creditThe credit scheme should always satisfy the following invariant: Each row of each active table stores one credit and the table has the same number of credits as the number of rows. Let us confirm that the invariant applies to all the three operations CREATE-NODE, CHANGE-EDGE and CHANGE-LABEL.

CREATE-NODE: It acquires two credits, one is used to create the table and the other is given to the one row that is added to the table. Thus the invariant is maintained.
CHANGE-EDGE: There are two cases to consider. The first case occurs when there is still at least one empty row in the table. In this case one credit is used to the newly inserted row. The second case occurs when the table is full. In this case the old table becomes inactive and the d+1{\displaystyle d+1} credits are transformed to the new table in addition to the one credit acquired from calling the CHANGE-EDGE. So in total we have d+2{\displaystyle d+2} credits. One credit will be used for the creation of the new table. Another credit will be used for the new row added to the table and the d credits left are used for updating the tables of the other vertices that need to point to the new table. We conclude that the invariant is maintained.
CHANGE-LABEL: It works exactly the same as CHANGE-EDGE.As a summary, we conclude that having n1{\displaystyle n_{1}} calls to CREATE_NODE and n2{\displaystyle n_{2}} calls to CHANGE_EDGE will result in the creation of 2⋅n1+n2{\displaystyle 2\cdot n_{1}+n_{2}} tables. Since each table has size O(d){\displaystyle O(d)} without taking into account the recursive calls, then filling in a table requires O(d2){\displaystyle O(d^{2})} where the additional d factor comes from updating the inedges at other nodes. Therefore, the amount of work required to complete a sequence of operations is bounded by the number of tables created multiplied by O(d2){\displaystyle O(d^{2})}. Each access operation can be done in O(Log(d)){\displaystyle O(Log(d))} and there are m{\displaystyle m} edge and label operations, thus it requires m⋅O(Log(d)){\displaystyle m\cdot O(Log(d))}. We conclude that There exists a data structure that can complete any n{\displaystyle n} sequence of CREATE-NODE, CHANGE-EDGE and CHANGE-LABEL in O(n⋅d2)+m⋅O(Log(d)){\displaystyle O(n\cdot d^{2})+m\cdot O(Log(d))}.

Applications of persistent data structures
Next element search or point location
One of the useful applications that can be solved efficiently using persistence is the Next Element Search. Assume that there are n{\displaystyle n} non intersecting line segments that don't cross each other that are parallel to the x-axis. We want to build a data structure that can query a point p{\displaystyle p} and return the segment above p{\displaystyle p} (if any). We will start by solving the Next Element Search using the naïve method then we will show how to solve it using the persistent data structure method.

Naïve method
We start with a vertical line segment that starts off at infinity and we sweep the line segments from the left to the right. We take a pause every time we encounter an end point of these segments. The vertical lines split the plane into vertical strips. If there are n{\displaystyle n} line segments then we can get 2⋅n+1{\displaystyle 2\cdot n+1} vertical strips since each segment has 2{\displaystyle 2} end points. No segment begins and ends in the strip. Every segment either it doesn't touch the strip or it completely crosses it. We can think of the segments as some objects that are in some sorted order from top to bottom. What we care about is where the point that we are looking at fits in this order. We sort the endpoints of the segments by their x{\displaystyle x} coordinate. For each strip si{\displaystyle s_{i}}, we store the subset segments that cross si{\displaystyle s_{i}} in a dictionary. When the vertical line sweeps the line segments, whenever it passes over the left endpoint of a segment then we add it to the dictionary. When it passes through the right endpoint of the segment, we remove it from the dictionary. At every endpoint, we save a copy of the dictionary and we store all the copies sorted by the x{\displaystyle x} coordinates. Thus we have a data structure that can answer any query. In order to find the segment above a point p{\displaystyle p}, we can look at the x{\displaystyle x} coordinate of p{\displaystyle p} to know which copy or strip it belongs to. Then we can look at the y{\displaystyle y} coordinate to find the segment above it. Thus we need two binary searches, one for the x{\displaystyle x} coordinate to find the strip or the copy, and another for the y{\displaystyle y} coordinate to find the segment above it. Thus the query time takes O(Log(n)){\displaystyle O(Log(n))}. In this data structure, the space is the issue since if we assume that we have the segments structured in a way such that every segment starts before the end of any other segment, then the space required for the structure to be built using the naïve method would be O(n2){\displaystyle O(n^{2})}. Let us see how we can build another persistent data structure with the same query time but with a better space.

Persistent data structure method
We can notice that what really takes time in the data structure used in the naïve method is that whenever we move from a strip to the next, we need to take a snap shot of whatever data structure we are using to keep things in sorted order. We can notice that once we get the segments that intersect si{\displaystyle s_{i}}, when we move to si+1{\displaystyle s_{i+1}} either one thing leaves or one thing enters. If the difference between what is in si{\displaystyle s_{i}} and what is in si+1{\displaystyle s_{i+1}} is only one insertion or deletion then it is not a good idea to copy everything from si{\displaystyle s_{i}} to si+1{\displaystyle s_{i+1}}. The trick is that since each copy differs from the previous one by only one insertion or deletion, then we need to copy only the parts that change. Let us assume that we have a tree rooted at T{\displaystyle T}. When we insert a key k{\displaystyle k} into the tree, we create a new leaf containing k{\displaystyle k}. Performing rotations to rebalance the tree will only modify the nodes of the path from k{\displaystyle k} to T{\displaystyle T}. Before inserting the key k{\displaystyle k} into the tree, we copy all the nodes on the path from k{\displaystyle k} to T{\displaystyle T}. Now we have 2 versions of the tree, the original one which doesn't contain k{\displaystyle k} and the new tree that contains k{\displaystyle k} and whose root is a copy of the root of T{\displaystyle T}. Since copying the path from k{\displaystyle k} to T{\displaystyle T} doesn't increase the insertion time by more than a constant factor then the insertion in the persistent data structure takes O(Log(n)){\displaystyle O(Log(n))} time. For the deletion, we need to find which nodes will be affected by the deletion. For each node v{\displaystyle v} affected by the deletion, we copy the path from the root to v{\displaystyle v}. This will provide a new tree whose root is a copy of the root of the original tree. Then we perform the deletion on the new tree. We will end up with 2 versions of the tree. The original one which contains k{\displaystyle k} and the new one which doesn't contain k{\displaystyle k}. Since any deletion only modifies the path from the root to v{\displaystyle v} and any appropriate deletion algorithm runs in O(Log(n)){\displaystyle O(Log(n))}, thus the deletion in the persistent data structure takes O(Log(n)){\displaystyle O(Log(n))}.  Every sequence of insertion and deletion will cause the creation of a sequence of dictionaries or versions or trees S1,S2,…Si{\displaystyle S_{1},S_{2},\dots S_{i}} where each Si{\displaystyle S_{i}} is the result of operations S1,S2,…Si{\displaystyle S_{1},S_{2},\dots S_{i}}. If each Si{\displaystyle S_{i}} contains m{\displaystyle m} elements, then the search in each Si{\displaystyle S_{i}} takes O(Log(m)){\displaystyle O(Log(m))}. Using this persistent data structure we can solve the next element search problem in O(Log(n)){\displaystyle O(Log(n))} query time and O(n⋅Log(n)){\displaystyle O(n\cdot Log(n))} space instead of O(n2){\displaystyle O(n^{2})}. Please find below the source code for an example related to the next search problem.

Examples of persistent data structures
Perhaps the simplest persistent data structure is the singly linked list or cons-based list, a simple list of objects formed by each carrying a reference to the next in the list. This is persistent because the tail of the list can be taken, meaning the last k items for some k, and new nodes can be added in front of it. The tail will not be duplicated, instead becoming shared between both the old list and the new list.  So long as the contents of the tail are immutable, this sharing will be invisible to the program.
Many common reference-based data structures, such as red–black trees, stacks, and treaps, can easily be adapted to create a persistent version. Some others need slightly more effort, for example: queues, dequeues, and extensions including min-deques (which have an additional O(1) operation min returning the minimal element) and random access deques (which have an additional operation of random access with sub-linear, most often logarithmic, complexity).
There also exist persistent data structures which use destructive operations, making them impossible to implement efficiently in purely functional languages (like Haskell outside specialized monads like state or IO), but possible in languages like C or Java. These types of data structures can often be avoided with a different design. One primary advantage to using purely persistent data structures is that they often behave better in multi-threaded environments.

Linked lists
Singly linked lists are the bread-and-butter data structure in functional languages. Some ML-derived languages, like Haskell, are purely functional because once a node in the list has been allocated, it cannot be modified, only copied,  referenced or destroyed by the garbage collector when nothing refers to it.  (Note that ML itself is not purely functional, but supports non-destructive list operations subset, that is also true in the Lisp (LISt Processing) functional language dialects like Scheme and Racket.)
Consider the two lists:

xs = [0, 1, 2]
ys = [3, 4, 5]

These would be represented in memory by:

where a circle indicates a node in the list (the arrow out representing the second element of the node which is a pointer to another node).
Now concatenating the two lists:

zs = xs ++ ys

results in the following memory structure:

Notice that the nodes in list xs have been copied, but the nodes in ys are shared.  As a result, the original lists (xs and ys) persist and have not been modified.
The reason for the copy is that the last node in xs (the node containing the original value 2) cannot be modified to point to the start of ys, because that would change the value of xs.

Trees
Consider a binary search tree, where every node in the tree has the recursive invariant that all subnodes contained in the left subtree have a value that is less than or equal to the value stored in the node, and subnodes contained in the right subtree have a value that is greater than the value stored in the node.
For instance, the set of data

xs = [a, b, c, d, f, g, h]

might be represented by the following binary search tree:

A function which inserts data into the binary tree and maintains the invariant is:After executing
ys = insert (""e"", xs)

The following configuration is produced:

Notice two points: first, the original tree (xs) persists.  Second, many common nodes are shared between the old tree and the new tree. Such persistence and sharing is difficult to manage without some form of garbage collection (GC) to automatically free up nodes which have no live references, and this is why GC is a feature commonly found in functional programming languages.

Persistent hash array mapped trie
A persistent hash array mapped trie is a specialized variant of a hash array mapped trie that will preserve previous versions of itself on any updates. It is often used to implement a general purpose persistent map data structure.Hash array mapped tries were originally described in a 2001 paper by Phil Bagwell entitled ""Ideal Hash Trees"". This paper presented a mutable Hash table where ""Insert, search and delete times are small and constant, independent of key set size, operations are O(1). Small worst-case times for insert, search and removal operations can be guaranteed and misses cost less than successful searches"". This data structure was then modified by Rich Hickey to be fully persistent for use in the Clojure programming language.Conceptually, hash array mapped tries work similar to any generic tree in that they store nodes hierarchically and retrieve them by following a path down to a particular element. The key difference is that Hash Array Mapped Tries first use a hash function to transform their lookup key into a (usually 32 or 64 bit) integer. The path down the tree is then determined by using slices of the binary representation of that integer to index into a sparse array at each level of the tree. The leaf nodes of the tree behave similar to the buckets used to construct hash tables and may or may not contain multiple candidates depending on hash collisions.Most implementations of persistent hash array mapped tries use a branching factor of 32 in their implementation. This means that in practice while insertions, deletions, and lookups into a persistent hash array mapped trie have a computational complexity of O(log n), for most applications they are effectively constant time, as it would require an extremely large number of entries to make any operation take more than a dozen steps.

Usage in programming languages
Haskell
Haskell is a pure functional language and therefore does not allow for mutation. Therefore, all data structures in the language are persistent, as it is impossible to not preserve the previous state of a data structure with functional semantics. This is because any change to a data structure that would render previous versions of a data structure invalid would violate referential transparency.
In its standard library Haskell has efficient persistent implementations for linked lists, Maps (implemented as size balanced trees), and Sets among others.

Clojure
Like many programming languages in the Lisp family, Clojure contains an implementation of a linked list, but unlike other dialects its implementation of a linked list has enforced persistence instead of being persistent by convention. Clojure also has efficient implementations of persistent vectors, maps, and sets based on persistent hash array mapped tries. These data structures implement the mandatory read-only parts of the Java collections framework.The designers of the Clojure language advocate the use of persistent data structures over mutable data structures because they have value semantics which gives the benefit of making them freely shareable between threads with cheap aliases, easy to fabricate, and language independent.These data structures form the basis of Clojure's support for parallel computing since they allow for easy retries of operations to sidestep data races and atomic compare and swap semantics.

Elm
The Elm programming language is purely functional like Haskell, which makes all of its data structures persistent by necessity. It contains persistent implementations of linked lists as well as persistent arrays, dictionaries, and sets.Elm uses a custom virtual DOM implementation that takes advantage of the persistent nature of Elm data. As of 2016 it was reported by the developers of Elm that this virtual DOM allows the Elm language to render HTML faster than the popular JavaScript frameworks React, Ember, and Angular.

Java
The Java programming language is not particularly functional. Despite this, the core JDK package java.util.concurrent includes CopyOnWriteArrayList and CopyOnWriteArraySet which are persistent structures, implemented using copy-on-write techniques. The usual concurrent map implementation in Java, ConcurrentHashMap, is not persistent, however. Fully persistent collections are available in third-party libraries, or other JVM languages.

JavaScript
The popular JavaScript frontend framework React is frequently used along with a state management system that implements the Flux architecture, a popular implementation of which is the JavaScript library Redux. The Redux library is inspired by the state management pattern used in the Elm programming language, meaning that it mandates that users treat all data as persistent. As a result, the Redux project recommends that in certain cases users make use of libraries for enforced and efficient persistent data structures. This reportedly allows for greater performance than when comparing or making copies of regular JavaScript objects.One such library of persistent data structures Immutable.js is based on the data structures made available and popularized by Clojure and Scala. It is mentioned by the documentation of Redux as being one of the possible libraries that can provide enforced immutability. Mori.js brings data structures similar to those in Clojure to JavaScript. Immer.js brings an interesting approach where one ""creates the next immutable state by mutating the current one"".
 Immer.js uses native JavaScript objects and not efficient persistent data structures and it might cause performance issues when data size is big.

Prolog
Prolog terms are naturally immutable and therefore data structures are typically persistent data structures. Their performance depends on sharing and garbage collection offered by the Prolog system. Extensions to non-ground Prolog terms are not always feasible because of search space explosion. Delayed goals might mitigate the problem.
Some Prolog systems nevertheless do provide destructive operations like setarg/3, which might come in different flavors, with/without copying and with/without backtracking of the state change. There are cases where setarg/3 is used to the good of providing a new declarative layer, like a constraint solver.

Scala
The Scala programming language promotes the use of persistent data structures for implementing programs using ""Object-Functional Style"". Scala contains implementations of many persistent data structures including linked lists, red–black trees, as well as persistent hash array mapped tries as introduced in Clojure.

Garbage collection
Because persistent data structures are often implemented in such a way that successive versions of a data structure share underlying memory ergonomic use of such data structures generally requires some form of automatic garbage collection system such as reference counting or mark and sweep. In some platforms where persistent data structures are used it is an option to not use garbage collection which, while doing so can lead to memory leaks, can in some cases have a positive impact on the overall performance of an application.

See also
Copy-on-write
Navigational database
Persistent data
Retroactive data structures
Purely functional data structure

References
External links
Lightweight Java implementation of Persistent Red-Black Trees
Efficient persistent structures in C#",662889,https://en.wikipedia.org/wiki/Persistent_data_structure
Postings list,"The postings list is a data structure commonly used in information retrieval (IR) systems to store indexing information about a corpus. It is central to the design and efficiency of search engines and database management systems that need to retrieve information rapidly.
At the bare minimum, a postings list is associated with a term from a document and records the places where that term appears. Each term found in documents within a corpus is mapped to a corresponding postings list containing information such as the documents the term appears in and often the positions within those documents.","The postings list is a data structure commonly used in information retrieval (IR) systems to store indexing information about a corpus. It is central to the design and efficiency of search engines and database management systems that need to retrieve information rapidly.
At the bare minimum, a postings list is associated with a term from a document and records the places where that term appears. Each term found in documents within a corpus is mapped to a corresponding postings list containing information such as the documents the term appears in and often the positions within those documents.

Structure
A postings list consists of posting elements, sometimes referred to as postings. Each posting typically contains:

A document identifier (DocID), which uniquely identifies a document in the corpus.
Frequency information (Term Frequency), indicating how often the term appears within the document.
Position information, indicating where in the text the term appears.
Additional metadata may include fields such as document titles, headings, or other relevant document-specific information.The exact structure of a postings list can vary based on its application, with some using linked lists, arrays, or more complex data structures like skip lists to optimize for different types of searches.
During a search query, the IR system retrieves postings lists for each term in the query to determine which documents contain the terms and how relevant those documents could be based on the frequency and positions of the terms.

Variants
Some variants of postings lists include:

Inverted index: A form of postings list that points from terms to documents.
Impact-ordered postings: Lists where postings are ordered by the weight or ""impact"" of the term in the document.
Positional postings lists: Enhanced postings lists that include position information for phrase queries and proximity searches.


== References ==",75521167,https://en.wikipedia.org/wiki/Postings_list
Predecessor problem,"In computer science, the predecessor problem involves maintaining a set of items to, given an element, efficiently query which element precedes or succeeds that element in an order. Data structures used to solve the problem include balanced binary search trees, van Emde Boas trees, and fusion trees. In the static predecessor problem, the set of elements does not change, but in the dynamic predecessor problem, insertions into and deletions from the set are allowed.The predecessor problem is a simple case of the nearest neighbor problem, and data structures that solve it have applications in problems like integer sorting.","In computer science, the predecessor problem involves maintaining a set of items to, given an element, efficiently query which element precedes or succeeds that element in an order. Data structures used to solve the problem include balanced binary search trees, van Emde Boas trees, and fusion trees. In the static predecessor problem, the set of elements does not change, but in the dynamic predecessor problem, insertions into and deletions from the set are allowed.The predecessor problem is a simple case of the nearest neighbor problem, and data structures that solve it have applications in problems like integer sorting.

Definition
The problem consists of maintaining a set S, which contains a subset of U integers. Each of these integers can be stored with a word size of w, implying that U≤2w{\displaystyle U\leq 2^{w}}. Data structures that solve the problem support these operations:
predecessor(x), which returns the largest element in S less than or equal to x
successor(x), which returns the smallest element in S greater than or equal to xIn addition, data structures which solve the dynamic version of the problem also support these operations:

insert(x), which adds x to the set S
delete(x), which removes x from the set SThe problem is typically analyzed in a transdichotomous model of computation such as word RAM.

Data structures
One simple solution to this problem is to use a balanced binary search tree, which achieves (in Big O notation) a running time of O(log⁡n){\displaystyle O(\log n)} for predecessor queries. The Van Emde Boas tree achieves a query time of O(log⁡log⁡U){\displaystyle O(\log \log U)}, but requires O(U){\displaystyle O(U)} space. Dan Willard proposed an improvement on this space usage with the x-fast trie, which requires O(nlog⁡U){\displaystyle O(n\log U)} space and the same query time, and the more complicated y-fast trie, which only requires O(n){\displaystyle O(n)} space. Fusion trees, introduced by Michael Fredman and Willard, achieve O(logw⁡n){\displaystyle O(\log _{w}n)} query time and O(n){\displaystyle O(n)} for predecessor queries for the static problem. The dynamic problem has been solved using exponential trees with O(logw⁡n+log⁡log⁡n){\displaystyle O(\log _{w}n+\log \log n)} query time, and with expected time O(logw⁡n){\displaystyle O(\log _{w}n)} using hashing.

Mathematical properties
There have been a number of papers proving lower bounds on the predecessor problem, or identifying what the running time of asymptotically optimal solutions would be. For example, Michael Beame and Faith Ellen proved that for all values of w, there exists a value of n with query time (in Big Theta notation) Ω(log⁡wlog⁡log⁡w){\displaystyle \Omega \left({\tfrac {\log w}{\log \log w}}\right)}, and similarly, for all values of n, there exists a value of n such that the query time is Ω(log⁡nlog⁡log⁡n){\displaystyle \Omega \left({\sqrt {\tfrac {\log n}{\log \log n}}}\right)}. Other proofs of lower bounds include the notion of communication complexity.
For the static predecessor problem, Mihai Pătrașcu and Mikkel Thorup showed the following lower bound for the optimal search time, in the cell-probe model:
where the RAM has word length w{\displaystyle w}, the set contains n{\displaystyle n} integers of ℓ{\displaystyle \ell } bits each and is represented in the RAM using S{\displaystyle S} words of space, and defining a=lg⁡Sn+lg⁡w{\displaystyle a=\lg {\frac {S}{n}}+\lg w}.
In the case where w=ℓ=γlg⁡n{\displaystyle w=\ell =\gamma \lg n} for γ>1{\displaystyle \gamma >1} and S=n⋅lgO(1)⁡n{\displaystyle S=n\cdot \lg ^{O(1)}n}, the optimal search time is
Θ(lg⁡ℓ){\displaystyle \Theta (\lg \ell )} and the van Emde Boas tree achieves this bound.

See also
Integer sorting
y-fast trie
Fusion tree


== References ==",56037139,https://en.wikipedia.org/wiki/Predecessor_problem
Retroactive data structure,"In computer science a retroactive data structure is a data structure which supports efficient modifications to a sequence of operations that have been performed on the structure. These modifications can take the form of retroactive insertion, deletion or updating an operation that was performed at some time in the past.","In computer science a retroactive data structure is a data structure which supports efficient modifications to a sequence of operations that have been performed on the structure. These modifications can take the form of retroactive insertion, deletion or updating an operation that was performed at some time in the past.

Some applications of retroactive data structures
In the real world there are many cases where one would like to modify a past operation from a sequence of operations. Listed below are some of the possible applications:

Error correction: Incorrect input of data. The data should be corrected and all the secondary effects of the incorrect data be removed.
Bad data: When dealing with large systems, particularly those involving a large amount of automated data transfer, it is not uncommon. For example, suppose one of the sensors for a weather network malfunctions and starts to report garbage data or incorrect data. The ideal solution would be to remove all the data that the sensor produced since it malfunctioned along with all the effects the bad data had on the overall system.
Recovery: Suppose that a hardware sensor was damaged but is now repaired and data is able to be read from the sensor. We would like to be able to insert the data back into the system as if the sensor was never damaged in the first place.
Manipulation of the past: Changing the past can be helpful in the cases of damage control and retroactive data structures are designed for intentional manipulation of the past.

Time as a spatial dimension
It is not possible to consider time as an additional spatial dimension. To illustrate this suppose we map the dimension of time onto an axis of space. The data structure we will use to add the spatial time dimension is a min-heap. Let the y axis represent the key values of the items within the heap and the x axis is the spatial time dimension. After several insertions and delete-min operations (all done non-retroactively) our min-heap would appear like in figure 1. Now suppose we retroactively insert zero to the beginning of the operation list. Our min-heap would appear like in figure 2. Notice how the single operation produces a cascading effect which affects the entire data structure. Thus we can see that while time can be drawn as a spatial dimension, operations with time involved produces dependence which have a ripple when modifications are made with respect to time.

Comparison to persistence
At first glance the notion of a retroactive data structures seems very similar to persistent data structures since they both take into account the dimension of time. The key difference between persistent data structures and retroactive data structures is how they handle the element of time. A persistent data structure maintains several versions of a data structure and operations can be performed on one version to produce another version of the data structure. Since each operation produces a new version, each version thus becomes an archive that cannot be changed (only new versions can be spawned from it). Since each version does not change, the dependence between each version also does not change. In retroactive data structures we allow changes to be made directly to previous versions. Since each version is now interdependent, a single change can cause a ripple of changes of all later versions. Figures 1 and 2 show an example of this rippling effect.

Definition
Any data structure can be reformulated in a retroactive setting. In general the data structure involves a series of updates and queries made over some period of time. Let U = [ut1, ut2, ut3, ..., utm] be the sequence of update operations from t1 to tm such that t1 < t2 < ... < tm. The assumption here is that at most one operation can be performed for a given time t.

Partially retroactive
We define the data structure to be partially retroactive if it can perform update and query operations at the current time and support insertion and deletion operations in the past. Thus for partially retroactive we are interested in the following operations:

Insert(t, u): Insert a new operation u into the list U at time t.
Delete(t): Delete the operation at time t from the list U.Given the above retroactive operations, a standard insertion operation would now the form of Insert(t, ""insert(x)""). All retroactive changes on the operational history of the data structure can potentially affect all the operations at the time of the operation to the present. For example, if we have ti-1 < t < ti+1, then Insert(t, insert(x)) would place a new operation, op, between the operations opi-1 and opi+1. The current state of the data structure (i.e.: the data structure at the present time) would then be in a state such the operations opi-1, op and opi+1 all happened in a sequence, as if the
operation op was always there. See figure 1 and 2 for a visual example.

Fully retroactive
We define the data structure to be fully retroactive if in addition to the partially retroactive operations we also allow for one to perform queries about the past. Similar to how the standard operation insert(x) becomes Insert(t, ""insert(x)"") in the partially retroactive model, the operation query(x) in the fully retroactive model now has the form Query(t, ""query(x)"").

Retroactive running times
The running time of retroactive data structures are based on the number of operations, m, performed on the structure, the number of operations r that were performed before the retroactive operation is performed, and the maximum number of elements n in the structure at any single time.

Automatic retro-activity
The main question regarding automatic retro-activity with respect to data structures is whether or not there is a general technique which can convert any data structure into an efficient retroactive counterpart. A simple approach is to perform a roll-back on all the changes made to the structure prior to the retroactive operation that is to be applied. Once we have rolled back the data structure to the appropriate state we can then apply the retroactive operation to make the change we wanted. Once the change is made we must then reapply all the changes we rolled back before to put the data structure into its new state. While this can work for any data structure, it is often inefficient and wasteful especially once the number of changes we need to roll-back is large. To create an efficient retroactive data structure we must take a look at the properties of the structure itself to determine where speed ups can be realized. Thus there is no general way to convert any data structure into an efficient retroactive counterpart. Erik D. Demaine, John Iacono and Stefan Langerman prove this.

See also
Persistent data structure


== References ==",35579271,https://en.wikipedia.org/wiki/Retroactive_data_structure
Routing table,"In computer networking, a routing table, or routing information base (RIB), is a data table stored in a router or a network host that lists the routes to particular network destinations, and in some cases, metrics (distances) associated with those routes. The routing table contains information about the topology of the network immediately around it.
The construction of routing tables is the primary goal of routing protocols. Static routes are entries that are fixed, rather than resulting from routing protocols and network topology discovery procedures.","In computer networking, a routing table, or routing information base (RIB), is a data table stored in a router or a network host that lists the routes to particular network destinations, and in some cases, metrics (distances) associated with those routes. The routing table contains information about the topology of the network immediately around it.
The construction of routing tables is the primary goal of routing protocols. Static routes are entries that are fixed, rather than resulting from routing protocols and network topology discovery procedures.

Overview
A routing table is analogous to a distribution map in package delivery. Whenever a node needs to send data to another node on a network, it must first know where to send it. If the node cannot directly connect to the destination node, it has to send it via other nodes along a route to the destination node. Each node needs to keep track of which way to deliver various packages of data, and for this it uses a routing table. A routing table is a database that keeps track of paths, like a map, and uses these to determine which way to forward traffic. A routing table is a data file in RAM that is used to store route information about directly connected and remote networks. Nodes can also share the contents of their routing table with other nodes.
The primary function of a router is to forward a packet toward its destination network, which is the destination IP address of the packet. To do this, a router needs to search the routing information stored in its routing table. The routing table contains network/next hop associations. These associations tell a router that a particular destination can be optimally reached by sending the packet to a specific router that represents the next hop on the way to the final destination. The next hop association can also be the outgoing or exit interface to the final destination.
With hop-by-hop routing, each routing table lists, for all reachable destinations, the address of the next device along the path to that destination: the next hop.  Assuming that the routing tables are consistent, the simple algorithm of relaying packets to their destination's next hop thus suffices to deliver data anywhere in a network.  Hop-by-hop is the fundamental characteristic of the IP Internet layer and the OSI Network Layer.
When a router interface is configured with an IP address and subnet mask, the interface becomes a host on that attached network. A directly connected network is a network that is directly attached to one of the router interfaces. The network address and subnet mask of the interface, along with the interface type and number, are entered into the routing table as a directly connected network.
A remote network is a network that can only be reached by sending the packet to another router. Routing table entries to remote networks may be either dynamic or static. Dynamic routes are routes to remote networks that were learned automatically by the router through a dynamic routing protocol. Static routes are routes that a network administrator manually configured.
Routing tables are also a key aspect of certain security operations, such as unicast reverse path forwarding (uRPF). In this technique, which has several variants, the router also looks up, in the routing table, the source address of the packet.  If there exists no route back to the source address, the packet is assumed to be malformed or involved in a network attack and is dropped.

Difficulties
The need to record routes to large numbers of devices using limited storage space represents a major challenge in routing table construction. In the Internet, the currently dominant address aggregation technology is a bitwise prefix matching scheme called Classless Inter-Domain Routing (CIDR). Supernetworks can also be used to help control routing table size.

Contents
The routing table consists of at least three information fields:

network identifier: The destination subnet and netmask
metric: The routing metric of the path through which the packet is to be sent. The route will go in the direction of the gateway with the lowest metric.
next hop: The next hop, or gateway, is the address of the next station to which the packet is to be sent on the way to its final destinationDepending on the application and implementation, it can also contain additional values that refine path selection: 

quality of service associated with the route. For example, the U flag indicates that an IP route is up.
filtering criteria: Access-control lists associated with the route
interface: Such as eth0 for the first Ethernet card, eth1 for the second Ethernet card, etc.Shown below is an example of what the table above could look like on a computer connected to the internet via a home router:

The columns Network destination and Netmask together describe the Network identifier as mentioned earlier. For example, destination 192.168.0.0 and netmask 255.255.255.0 can be written as 192.168.0.0/24.
The Gateway column contains the same information as the Next hop, i.e. it points to the gateway through which the network can be reached.
The Interface indicates what locally available interface is responsible for reaching the gateway. In this example, gateway 192.168.0.1 (the internet router) can be reached through the local network card with address 192.168.0.100.
Finally, the Metric indicates the associated cost of using the indicated route. This is useful for determining the efficiency of a certain route from two points in a network. In this example, it is more efficient to communicate with the computer itself through the use of address 127.0.0.1 (called localhost) than it would be through 192.168.0.100 (the IP address of the local network card).

Forwarding table
Routing tables are generally not used directly for packet forwarding in modern router architectures; instead, they are used to generate the information for a simpler forwarding table. This forwarding table contains only the routes which are chosen by the routing algorithm as preferred routes for packet forwarding. It is often in a compressed or pre-compiled format that is optimized for hardware storage and lookup.
This router architecture separates the control plane function of the routing table from the forwarding plane function of the forwarding table. This separation of control and forwarding provides uninterrupted high-performance forwarding.

See also
Luleå algorithm
Internet protocol suite

References
External links
IP Routing from the Linux Network Administrators Guide",48043,https://en.wikipedia.org/wiki/Routing_table
Search data structure,"In computer science, a search data structure is any data structure that allows the efficient retrieval of specific items from a set of items, such as a specific record from a database.
The simplest, most general, and least efficient search structure is merely an unordered sequential list of all the items. Locating the desired item in such a list, by the linear search method, inevitably requires a number of operations proportional to the number n of items, in the worst case as well as in the average case.  Useful search data structures allow faster retrieval; however, they are limited to queries of some specific kind.  Moreover, since the cost of building such structures is at least proportional to n, they only pay off if several queries are to be performed on the same database (or on a database that changes little between queries).
Static search structures are designed for answering many queries on a fixed database; dynamic structures also allow insertion, deletion, or modification of items between successive queries. In the dynamic case, one must also consider the cost of fixing the search structure to account for the changes in the database.","In computer science, a search data structure is any data structure that allows the efficient retrieval of specific items from a set of items, such as a specific record from a database.
The simplest, most general, and least efficient search structure is merely an unordered sequential list of all the items. Locating the desired item in such a list, by the linear search method, inevitably requires a number of operations proportional to the number n of items, in the worst case as well as in the average case.  Useful search data structures allow faster retrieval; however, they are limited to queries of some specific kind.  Moreover, since the cost of building such structures is at least proportional to n, they only pay off if several queries are to be performed on the same database (or on a database that changes little between queries).
Static search structures are designed for answering many queries on a fixed database; dynamic structures also allow insertion, deletion, or modification of items between successive queries. In the dynamic case, one must also consider the cost of fixing the search structure to account for the changes in the database.

Classification
The simplest kind of query is to locate a record that has a specific field (the key) equal to a specified value v.  Other common kinds of query are ""find the item with smallest (or largest) key value"", ""find the item with largest key value not exceeding v"", ""find all items with key values between specified bounds vmin and vmax"".
In certain databases the key values may be points in some multi-dimensional space.  For example, the key may be a geographic position (latitude and longitude) on the Earth.  In that case, common kinds of queries are ""find the record with a key closest to a given point v"", or ""find all items whose key lies at a given distance from v"", or ""find all items within a specified region R of the space"".
A common special case of the latter are simultaneous range queries on two or more simple keys, such as ""find all employee records with salary between 50,000 and 100,000 and hired between 1995 and 2007"".

Single ordered keys
Array if the key values span a moderately compact interval.
Priority-sorted list; see linear search
Key-sorted array; see binary search
Self-balancing binary search tree
Hash table

Finding the smallest element
Heap

Asymptotic worst-case analysis
In this table, the asymptotic notation O(f(n)) means ""not exceeding some fixed multiple of f(n) in the worst case.""

Note: Insert on an unsorted array is sometimes quoted as being O(n) due to the assumption that the element to be inserted must be inserted at one particular location of the array, which would require shifting all the subsequent elements by one position. However, in a classic array, the array is used to store arbitrary unsorted elements, and hence the exact position of any given element is of no consequence, and insert is carried out by increasing the array size by 1 and storing the element at the end of the array, which is a O(1) operation. Likewise, the deletion operation is sometimes quoted as being O(n) due to the assumption that subsequent elements must be shifted, but in a classic unsorted array the order is unimportant (though elements are implicitly ordered by insert-time), so deletion can be carried out by swapping the element to be deleted with the last element in the array and then decrementing the array size by 1, which is a O(1) operation.This table is only an approximate summary; for each data structure there are special situations and variants that may lead to different costs. Also two or more data structures can be combined to obtain lower costs.

Footnotes
See also
List of data structures
Skip list",24019691,https://en.wikipedia.org/wiki/Search_data_structure
Set intersection oracle,"A set intersection oracle (SIO) is a data structure which represents a collection of sets and can quickly answer queries about whether the set intersection of two given sets is non-empty.
The input to the problem is n finite sets. The sum of the sizes of all sets is N (which also means that there are at most N distinct elements). The SIO should quickly answer any query of the form:

""Does the set Si intersect the set Sk""?","A set intersection oracle (SIO) is a data structure which represents a collection of sets and can quickly answer queries about whether the set intersection of two given sets is non-empty.
The input to the problem is n finite sets. The sum of the sizes of all sets is N (which also means that there are at most N distinct elements). The SIO should quickly answer any query of the form:

""Does the set Si intersect the set Sk""?

Minimum memory, maximum query time
Without any pre-processing, a query can be answered by inserting the elements of Si into a temporary hash table and then checking for each element of Sk whether it is in the hash table. The query time is O(|Si|+|Sj|)=O(N){\displaystyle O(|S_{i}|+|S_{j}|)=O(N)}.

Maximum memory, minimum query time
Alternatively, we can pre-process the sets and create an n-by-n table where the intersection information is already entered. Then the query time is O(1){\displaystyle O(1)}, but the memory required is O(n2){\displaystyle O(n^{2})}.

A compromise
Define a ""large set"" as a set with at least N{\displaystyle {\sqrt {N}}} elements. Obviously there are at most N{\displaystyle {\sqrt {N}}} such sets. Create a table of intersection data between every large set to every other large set. This requires O(N){\displaystyle O(N)} memory. Additionally, for each large set, keep a hash table of all its elements. This requires additional O(N3/2){\displaystyle O(N^{3/2})} memory.
Given two sets, there are three possible cases:

Both sets are large. Then just read the answer to the intersection query from the table, in time O(1){\displaystyle O(1)}.
Both sets are small. Then insert the elements of one of them into a hash table and check the elements of the other one; because the sets are small, the required time is O(N){\displaystyle O({\sqrt {N}})}.
One set is large and one set is small. Loop over all elements in the small set and check them against the hash table of the large set. The required time is again O(N){\displaystyle O({\sqrt {N}})}.In general, if we define a ""large set"" as a set with at least Nc{\displaystyle N^{c}} elements, then the number of large set is at most N1−c{\displaystyle N^{1-c}} so the memory required is O(N2−c){\displaystyle O(N^{2-c})}, and the query time is O(Nc){\displaystyle O(N^{c})}.

Reduction to approximate distance oracle
The SIO problem can be reduced to the approximate distance oracle (DO) problem, in the following way.
Build an undirected bipartite graph where one part contains a node for each of the n sets, and the other part contains a node for each of the (at most) N elements contained in the sets.
There is an edge between a set and an element, iff the set contains the element.This graph has the following properties:

If two sets intersect, the distance between them is 2 (from one set, to an element in the intersection, to the other set).
If two sets do not intersect, the distance between them is at least 4.So, with a DO whose approximation factor of less than 2, we can solve the SIO problem.
It is believed that the SIO problem does not have a non-trivial solution. I.e., it requires Ω(n2){\displaystyle \Omega (n^{2})} space to answer queries in time O(1){\displaystyle O(1)}. If this conjecture is true, this implies that there is no DO with an approximation factor of less than 2 and a constant query time.


== References ==",45378348,https://en.wikipedia.org/wiki/Set_intersection_oracle
Term indexing,"In computer science, a term index is a data structure to facilitate fast lookup of terms and clauses in a logic program, deductive database, or automated theorem prover.","In computer science, a term index is a data structure to facilitate fast lookup of terms and clauses in a logic program, deductive database, or automated theorem prover.

Overview
Many operations in automatic theorem provers require search in huge collections of terms and clauses. Such operations typically fall into the following scheme. Given a collection S{\displaystyle S} of terms (clauses) and a query term (clause) q{\displaystyle q}, find in S{\displaystyle S} some/all terms t{\displaystyle t} related to q{\displaystyle q} according to a certain retrieval condition. Most interesting retrieval conditions are formulated as existence of a substitution that relates in a special way the query and the retrieved objects t{\displaystyle t}. Here is a list of retrieval conditions frequently used in provers:

term q{\displaystyle q} is unifiable with term t{\displaystyle t}, i.e., there exists a substitution θ{\displaystyle \theta }, such that qθ{\displaystyle q\theta } = tθ{\displaystyle t\theta }
term t{\displaystyle t} is an instance of q{\displaystyle q}, i.e., there exists a substitution θ{\displaystyle \theta }, such that qθ{\displaystyle q\theta } = t{\displaystyle t}
term t{\displaystyle t} is a generalisation of q{\displaystyle q}, i.e., there exists a substitution θ{\displaystyle \theta }, such that q{\displaystyle q} = tθ{\displaystyle t\theta }
clause q{\displaystyle q} θ-subsumes clause t{\displaystyle t}, i.e., there exists a substitution θ{\displaystyle \theta }, such that qθ{\displaystyle q\theta } is a subset/submultiset of t{\displaystyle t}
clause q{\displaystyle q} is θ-subsumed by t{\displaystyle t}, i.e., there exists a substitution θ{\displaystyle \theta }, such that tθ{\displaystyle t\theta } is a subset/submultiset of q{\displaystyle q}More often than not, we are actually interested in finding the appropriate 
substitutions explicitly, together with the retrieved terms t{\displaystyle t},
rather than just in establishing existence of such substitutions. 
Very often the sizes of term sets to be searched are large, 
the retrieval calls are frequent and the retrieval condition test
is rather complex. In such situations linear search in S{\displaystyle S}, when the retrieval
condition is tested on every term from S{\displaystyle S}, becomes prohibitively costly. 
To overcome this problem, special data structures, called indexes, are 
designed in order to support fast retrieval. Such data structures, 
together with the accompanying algorithms for index maintenance
and retrieval, are called term indexing techniques.

Classic indexing techniques
discrimination trees
substitution trees
path indexingSubstitution trees outperform path indexing, discrimination tree indexing, and abstraction trees.A discrimination tree term index stores its information in a trie data structure.

Indexing techniques used in logic programming
First-argument indexing is the most common strategy where the first argument is used as index. It distinguishes atomic values and the principal functor of compound terms.
Nonfirst argument indexing is a variation of first-argument indexing that uses the same or similar techniques as first-argument indexing on one or more alternative arguments. For instance, if a predicate call uses variables for the first argument, the system may choose to use the second argument as the index instead.
Multiargument indexing creates a combined index over multiple instantiated arguments if there is not a sufficiently selective single argument index.
Deep indexing is used when multiple clauses use the same principal functor for some argument. It recursively uses the same or similar indexing techniques on the arguments of the compound terms.
Trie indexing uses a prefix tree to find applicable clauses.

References
Further reading
P. Graf, Term Indexing, Lecture Notes in Computer Science 1053, 1996 (slightly outdated overview)
R. Sekar and I.V. Ramakrishnan and A. Voronkov, Term Indexing, in A. Robinson and A. Voronkov, editors, Handbook of Automated Reasoning, volume 2, 2001 (recent overview)
W. W. McCune, Experiments with Discrimination-Tree Indexing and Path Indexing for Term Retrieval, Journal of Automated Reasoning, 9(2), 1992
P. Graf, Substitution Tree Indexing, Proc. of RTA, Lecture Notes in Computer Science 914, 1995
M. Stickel, The Path Indexing Method for Indexing Terms, Tech. Rep. 473, Artificial Intelligence Center, SRI International, 1989
S. Schulz, Simple and Efficient Clause Subsumption with Feature Vector Indexing, Proc. of IJCAR-2004 workshop ESFOR, 2004
A. Riazanov and A. Voronkov, Partially Adaptive Code Trees, Proc. JELIA, Lecture Notes in Artificial Intelligence 1919, 2000
H. Ganzinger and R. Nieuwenhuis and P. Nivela, Fast Term Indexing with Coded Context Trees, Journal of Automated Reasoning, 32(2), 2004
A. Riazanov and A. Voronkov, Efficient Instance Retrieval with Standard and Relational Path Indexing, Information and Computation, 199(1–2), 2005",2930391,https://en.wikipedia.org/wiki/Term_indexing
Amortized analysis,"In computer science, amortized analysis is a method for analyzing a given algorithm's complexity, or how much of a resource, especially time or memory, it takes to execute.  The motivation for amortized analysis is that looking at the worst-case run time can be too pessimistic.  Instead, amortized analysis averages the running times of operations in a sequence over that sequence.: 306 
As a conclusion: ""Amortized analysis is a useful tool that complements other techniques such as worst-case and average-case analysis."": 14 For a given operation of an algorithm, certain situations (e.g., input parametrizations or data structure contents) may imply a significant cost in resources, whereas other situations may not be as costly.  The amortized analysis considers both the costly and less costly operations together over the whole sequence of operations.  This may include accounting for different types of input, length of the input, and other factors that affect its performance.","In computer science, amortized analysis is a method for analyzing a given algorithm's complexity, or how much of a resource, especially time or memory, it takes to execute.  The motivation for amortized analysis is that looking at the worst-case run time can be too pessimistic.  Instead, amortized analysis averages the running times of operations in a sequence over that sequence.: 306 
As a conclusion: ""Amortized analysis is a useful tool that complements other techniques such as worst-case and average-case analysis."": 14 For a given operation of an algorithm, certain situations (e.g., input parametrizations or data structure contents) may imply a significant cost in resources, whereas other situations may not be as costly.  The amortized analysis considers both the costly and less costly operations together over the whole sequence of operations.  This may include accounting for different types of input, length of the input, and other factors that affect its performance.

History
Amortized analysis initially emerged from a method called aggregate analysis, which is now subsumed by amortized analysis. The technique was first formally introduced by Robert Tarjan in his 1985 paper Amortized Computational Complexity, which addressed the need for a more useful form of analysis than the common probabilistic methods used. Amortization was initially used for very specific types of algorithms, particularly those involving binary trees and union operations. However, it is now ubiquitous and comes into play when analyzing many other algorithms as well.

Method
Amortized analysis requires knowledge of which series of operations are possible. This is most commonly the case with data structures, which have state that persists between operations. The basic idea is that a worst-case operation can alter the state in such a way that the worst case cannot occur again for a long time, thus ""amortizing"" its cost.
There are generally three methods for performing amortized analysis: the aggregate method, the accounting method, and the potential method. All of these give correct answers; the choice of which to use depends on which is most convenient for a particular situation.
Aggregate analysis determines the upper bound T(n) on the total cost of a sequence of n operations, then calculates the amortized cost to be T(n) / n.
The accounting method is a form of aggregate analysis which assigns to each operation an amortized cost which may differ from its actual cost.  Early operations have an amortized cost higher than their actual cost, which accumulates a saved ""credit"" that pays for later operations having an amortized cost lower than their actual cost.  Because the credit begins at zero, the actual cost of a sequence of operations equals the amortized cost minus the accumulated credit.  Because the credit is required to be non-negative, the amortized cost is an upper bound on the actual cost.  Usually, many short-running operations accumulate such credit in small increments, while rare long-running operations decrease it drastically.
The potential method is a form of the accounting method where the saved credit is computed as a function (the ""potential"") of the state of the data structure.  The amortized cost is the immediate cost plus the change in potential.

Examples
Dynamic array
Consider a dynamic array that grows in size as more elements are added to it, such as ArrayList in Java or std::vector in C++.  If we started out with a dynamic array of size 4, we could push 4 elements onto it, and each operation would take constant time.  Yet pushing a fifth element onto that array would take longer as the array would have to create a new array of double the current size (8), copy the old elements onto the new array, and then add the new element.  The next three push operations would similarly take constant time, and then the subsequent addition would require another slow doubling of the array size.
In general if we consider an arbitrary number of pushes n + 1 to an array of size n, we notice that push operations take constant time except for the last one which takes Θ(n){\displaystyle \Theta (n)} time to perform the size doubling operation.  Since there were n + 1 operations total we can take the average of this and find that pushing elements onto the dynamic array takes: nΘ(1)+Θ(n)n+1=Θ(1){\displaystyle {\tfrac {n\Theta (1)+\Theta (n)}{n+1}}=\Theta (1)}, constant time.

Queue
Shown is a Python3 implementation of a Queue, a FIFO data structure:

The enqueue operation just pushes an element onto the input array; this operation does not depend on the lengths of either input or output and therefore runs in constant time.
However the dequeue operation is more complicated.  If the output array already has some elements in it, then dequeue runs in constant time; otherwise, dequeue takes O(n){\displaystyle O(n)} time to add all the elements onto the output array from the input array, where n is the current length of the input array.  After copying n elements from input, we can perform n dequeue operations, each taking constant time, before the output array is empty again. Thus, we can perform a sequence of n dequeue operations in only O(n){\displaystyle O(n)} time, which implies that the amortized time of each dequeue operation is 
.Alternatively, we can charge the cost of copying any item from the input array to the output array to the earlier enqueue operation for that item.  This charging scheme doubles the amortized time for enqueue but reduces the amortized time for dequeue to O(1){\displaystyle O(1)}.

Common use
In common usage, an ""amortized algorithm"" is one that an amortized analysis has shown to perform well.
Online algorithms commonly use amortized analysis.

References
Literature
""Lecture 7: Amortized Analysis"" (PDF). Carnegie Mellon University. Retrieved 14 March 2015.
Allan Borodin and Ran El-Yaniv (1998). Online Computation and Competitive Analysis. pp. 20, 141.",236683,https://en.wikipedia.org/wiki/Amortized_analysis
2–3 tree,"In computer science, a 2–3 tree is a tree data structure, where every node with children (internal node) has either two children (2-node) and one data element or three children (3-node) and two data elements. A 2–3 tree is a B-tree of order 3. Nodes on the outside of the tree (leaf nodes) have no children and one or two data elements. 2–3 trees were invented by John Hopcroft in 1970.2–3 trees are required to be balanced, meaning that each leaf is at the same level. It follows that each right, center, and left subtree of a node contains the same or close to the same amount of data.","In computer science, a 2–3 tree is a tree data structure, where every node with children (internal node) has either two children (2-node) and one data element or three children (3-node) and two data elements. A 2–3 tree is a B-tree of order 3. Nodes on the outside of the tree (leaf nodes) have no children and one or two data elements. 2–3 trees were invented by John Hopcroft in 1970.2–3 trees are required to be balanced, meaning that each leaf is at the same level. It follows that each right, center, and left subtree of a node contains the same or close to the same amount of data.

Definitions
We say that an internal node is a 2-node if it has one data element and two children.
We say that an internal node is a 3-node if it has two data elements and three children.
A 4-node, with three data elements, may be temporarily created during manipulation of the tree but is never persistently stored in the tree.

			
			
		
		
			
			
		
We say that T is a 2–3 tree if and only if one of the following statements hold:
T is empty. In other words, T does not have any nodes.
T is a 2-node with data element a. If T has left child p and right child q, then
p and q are 2–3 trees of the same height;
a is greater than each element in p; and
a is less than each data element in q.
T is a 3-node with data elements a and b, where a  < b. If T has left child p, middle child q, and right child r, then
p, q, and r are 2–3 trees of equal height;
a is greater than each data element in p and less than each data element in q; and
b is greater than each data element in q and less than each data element in r.

Properties
Every internal node is a 2-node or a 3-node.
All leaves are at the same level.
All data is kept in sorted order.

Operations
Searching
Searching for an item in a 2–3 tree is similar to searching for an item in a binary search tree. Since the data elements in each node are ordered, a search function will be directed to the correct subtree and eventually to the correct node which contains the item.

Let T be a 2–3 tree and d be the data element we want to find. If T is empty, then d is not in T and we're done.
Let t be the root of T.
Suppose t is a leaf.
If d is not in t, then d is not in T. Otherwise, d is in T. We need no further steps and we're done.
Suppose t is a 2-node with left child p and right child q. Let a be the data element in t. There are three cases:
If d is equal to a, then we've found d in T and we're done.
If d<a{\displaystyle d<a}, then set T to p, which by definition is a 2–3 tree, and go back to step 2.
If d>a{\displaystyle d>a}, then set T to q and go back to step 2.
Suppose t is a 3-node with left child p, middle child q, and right child r. Let a and b be the two data elements of t, where a<b{\displaystyle a<b}. There are four cases:
If d is equal to a or b, then d is in T and we're done.
If d<a{\displaystyle d<a}, then set T to p and go back to step 2.
If a<d<b{\displaystyle a<d<b}, then set T to q and go back to step 2.
If d>b{\displaystyle d>b}, then set T to r and go back to step 2.

Insertion
Insertion maintains the balanced property of the tree.To insert into a 2-node, the new key is added to the 2-node in the appropriate order.
To insert into a 3-node, more work may be required depending on the location of the 3-node. If the tree consists only of a 3-node, the node is split into three 2-nodes with the appropriate keys and children.

If the target node is a 3-node whose parent is a 2-node, the key is inserted into the 3-node to create a temporary 4-node. In the illustration, the key 10 is inserted into the 2-node with 6 and 9. The middle key is 9, and is promoted to the parent 2-node. This leaves a 3-node of 6 and 10, which is split to be two 2-nodes held as children of the parent 3-node.
If the target node is a 3-node and the parent is a 3-node, a temporary 4-node is created then split as above. This process continues up the tree to the root. If the root must be split, then the process of a single 3-node is followed: a temporary 4-node root is split into three 2-nodes, one of which is considered to be the root. This operation grows the height of the tree by one.

Deletion
Deleting a key from a non-leaf node can be done by replacing it by its immediate predecessor or successor, and then deleting the predecessor or successor from a leaf node.  Deleting a key from a leaf node is easy if the leaf is a 3-node.  Otherwise, it may require creating a temporary 1-node which may be absorbed by reorganizing the tree, or it may repeatedly travel upwards before it can be absorbed, as a temporary 4-node may in the case of insertion.  Alternatively, it's possible to use an algorithm which is both top-down and bottom-up, creating temporary 4-nodes on the way down that are then destroyed as you travel back up.  Deletion methods are explained in more detail in the references.

Parallel operations
Since 2–3 trees are similar in structure to red–black trees, parallel algorithms for red–black trees can be applied to 2–3 trees as well.

See also
2–3–4 tree
2–3 heap
AA tree
B-tree
(a,b)-tree
Finger tree

References
External links
2–3 Tree In-depth description",647196,https://en.wikipedia.org/wiki/2%E2%80%933_tree
AVL tree,"In computer science, an AVL tree (named after inventors Adelson-Velsky and Landis) is a self-balancing binary search tree. In an AVL tree, the heights of the two child subtrees of any node differ by at most one; if at any time they differ by more than one, rebalancing is done to restore this property. Lookup, insertion, and deletion all take O(log n) time in both the average and worst cases, where n{\displaystyle n} is the number of nodes in the tree prior to the operation. Insertions and deletions may require the tree to be rebalanced by one or more tree rotations.
The AVL tree is named after its two Soviet inventors, Georgy Adelson-Velsky and Evgenii Landis, who published it in their 1962 paper ""An algorithm for the organization of information"".  It is the oldest self-balancing binary search tree data structure to be invented.AVL trees are often compared with red–black trees because both support the same set of operations and take O(log⁡n){\displaystyle {\text{O}}(\log n)} time for the basic operations. For lookup-intensive applications, AVL trees are faster than red–black trees because they are more strictly balanced. Similar to red–black trees, AVL trees are height-balanced. Both are, in general, neither weight-balanced nor μ{\displaystyle \mu }-balanced for any μ≤12{\displaystyle \mu \leq {\tfrac {1}{2}}}; that is, sibling nodes can have hugely differing numbers of descendants.","In computer science, an AVL tree (named after inventors Adelson-Velsky and Landis) is a self-balancing binary search tree. In an AVL tree, the heights of the two child subtrees of any node differ by at most one; if at any time they differ by more than one, rebalancing is done to restore this property. Lookup, insertion, and deletion all take O(log n) time in both the average and worst cases, where n{\displaystyle n} is the number of nodes in the tree prior to the operation. Insertions and deletions may require the tree to be rebalanced by one or more tree rotations.
The AVL tree is named after its two Soviet inventors, Georgy Adelson-Velsky and Evgenii Landis, who published it in their 1962 paper ""An algorithm for the organization of information"".  It is the oldest self-balancing binary search tree data structure to be invented.AVL trees are often compared with red–black trees because both support the same set of operations and take O(log⁡n){\displaystyle {\text{O}}(\log n)} time for the basic operations. For lookup-intensive applications, AVL trees are faster than red–black trees because they are more strictly balanced. Similar to red–black trees, AVL trees are height-balanced. Both are, in general, neither weight-balanced nor μ{\displaystyle \mu }-balanced for any μ≤12{\displaystyle \mu \leq {\tfrac {1}{2}}}; that is, sibling nodes can have hugely differing numbers of descendants.

Definition
Balance factor
In a binary tree the balance factor of a node X is defined to be the height difference

BF(X):=Height(RightSubtree(X))−Height(LeftSubtree(X)){\displaystyle {\text{BF}}(X):={\text{Height}}({\text{RightSubtree}}(X))-{\text{Height}}({\text{LeftSubtree}}(X))}: 459 of its two child sub-trees rooted by node X. A binary tree is defined to be an AVL tree if the invariant

BF(X)∈{−1,0,1}{\displaystyle {\text{BF}}(X)\in {\{-1,0,1\}}}holds for every node X in the tree.
A node X with BF(X)<0{\displaystyle {\text{BF}}(X)<0} is called ""left-heavy"", one with BF(X)>0{\displaystyle {\text{BF}}(X)>0} is called ""right-heavy"", and one with BF(X)=0{\displaystyle {\text{BF}}(X)=0} is sometimes simply called ""balanced"".

Properties
Balance factors can be kept up-to-date by knowing the previous balance factors and the change in height – it is not necessary to know the absolute height. For holding the AVL balance information, two bits per node are sufficient.The height h{\displaystyle h} (counted as the maximal number of levels) of an AVL tree with n{\displaystyle n} nodes lies in the interval:: 460 
log2⁡(n+1)≤h<logφ⁡(n+2)+b{\displaystyle \log _{2}(n+1)\leq h<\log _{\varphi }(n+2)+b}where φ:=1+52≈1.618{\displaystyle \varphi :={\tfrac {1+{\sqrt {5}}}{2}}\approx 1.618}  is the golden ratio and b:=log2⁡52log2⁡φ−2≈−0.3277.{\displaystyle b:={\frac {\log _{2}5}{2\log _{2}\varphi }}-2\approx \;-0.3277.}
This is because an AVL tree of height h{\displaystyle h} contains at least Fh+2−1{\displaystyle F_{h+2}-1} nodes where {Fn}n∈N{\displaystyle \{F_{n}\}_{n\in \mathbb {N} }} is the Fibonacci sequence with the seed values F1=F2=1.{\displaystyle F_{1}=F_{2}=1.}

Operations
Read-only operations of an AVL tree involve carrying out the same actions as would be carried out on an unbalanced binary search tree, but modifications have to observe and restore the height balance of the sub-trees.

Searching
Searching for a specific key in an AVL tree can be done the same way as that of any balanced or unbalanced binary search tree.: ch. 8  In order for search to work effectively it has to employ a comparison function which establishes a total order (or at least a total preorder) on the set of keys.: 23  The number of comparisons required for successful search is limited by the height h and for unsuccessful search is very close to h, so both are in O(log n).: 216

Traversal
As a read-only operation the traversal of an AVL tree functions the same way as on any other binary tree. Exploring all n nodes of the tree visits each link exactly twice: one downward visit to enter the subtree rooted by that node, another visit upward to leave that node's subtree after having explored it.
Once a node has been found in an AVL tree, the next or previous node can be accessed in amortized constant time.: 58  Some instances of exploring these ""nearby"" nodes require traversing up to h ∝ log(n) links (particularly when navigating from the rightmost leaf of the root's left subtree to the root or from the root to the leftmost leaf of the root's right subtree; in the AVL tree of figure 1, navigating from node P to the next-to-the-right node Q takes 3 steps). Since there are n−1 links in any tree, the amortized cost is 2×(n−1)/n, or approximately 2.

Insert
When inserting a node into an AVL tree, you initially follow the same process as inserting into a Binary Search Tree. If the tree is empty, then the node is inserted as the root of the tree. If the tree is not empty, then we go down the root, and recursively go down the tree searching for the location to insert the new node. This traversal is guided by the comparison function. In this case, the node always replaces a NULL reference (left or right) of an external node in the tree i.e., the node is either made a left-child or a right-child of the external node.
After this insertion, if a tree becomes unbalanced, only ancestors of the newly inserted node are unbalanced. This is because only those nodes have their sub-trees altered. So it is necessary to check each of the node's ancestors for consistency with the invariants of AVL trees: this is called ""retracing"". This is achieved by considering the balance factor of each node.: 458–481  : 108 Since with a single insertion the height of an AVL subtree cannot increase by more than one, the temporary balance factor of a node after an insertion will be in the range [–2,+2]. For each node checked, if the temporary balance factor remains in the range from –1 to +1 then only an update of the balance factor and no rotation is necessary. However, if the temporary balance factor is ±2, the subtree rooted at this node is AVL unbalanced, and a rotation is needed.: 52  With insertion as the code below shows, the adequate rotation immediately perfectly rebalances the tree.
In figure 1, by inserting the new node Z as a child of node X the height of that subtree Z increases from 0 to 1.

Invariant of the retracing loop for an insertionThe height of the subtree rooted by Z has increased by 1. It is already in AVL shape.

In order to update the balance factors of all nodes, first observe that all nodes requiring correction lie from child to parent along the path of the inserted leaf. If the above procedure is applied to nodes along this path, starting from the leaf, then every node in the tree will again have a balance factor of −1, 0, or 1.
The retracing can stop if the balance factor becomes 0 implying that the height of that subtree remains unchanged.
If the balance factor becomes ±1 then the height of the subtree increases by one and the retracing needs to continue.
If the balance factor temporarily becomes ±2, this has to be repaired by an appropriate rotation after which the subtree has the same height as before (and its root the balance factor 0).
The time required is O(log n) for lookup, plus a maximum of O(log n) retracing levels (O(1) on average) on the way back to the root, so the operation can be completed in O(log n) time.: 53

Delete
The preliminary steps for deleting a node are described in section Binary search tree#Deletion.
There, the effective deletion of the subject node or the replacement node decreases the height of the corresponding child tree either from 1 to 0 or from 2 to 1, if that node had a child.
Starting at this subtree, it is necessary to check each of the ancestors for consistency with the invariants of AVL trees. This is called ""retracing"".
Since with a single deletion the height of an AVL subtree cannot decrease by more than one, the temporary balance factor of a node will be in the range from −2 to +2.
If the balance factor remains in the range from −1 to +1 it can be adjusted in accord with the AVL rules. If it becomes ±2 then the subtree is unbalanced and needs to be rotated. (Unlike insertion where a rotation always balances the tree, after delete, there may be BF(Z) ≠ 0 (see figures 2 and 3), so that after the appropriate single or double rotation the height of the rebalanced subtree decreases by one meaning that the tree has to be rebalanced again on the next higher level.) The various cases of rotations are described in section Rebalancing.

Invariant of the retracing loop for a deletionThe height of the subtree rooted by N has decreased by 1. It is already in AVL shape.

The retracing can stop if the balance factor becomes ±1 (it must have been 0) meaning that the height of that subtree remains unchanged.
If the balance factor becomes 0 (it must have been ±1) then the height of the subtree decreases by one and the retracing needs to continue.
If the balance factor temporarily becomes ±2, this has to be repaired by an appropriate rotation. It depends on the balance factor of the sibling Z (the higher child tree in figure 2) whether the height of the subtree decreases by one –and the retracing needs to continue– or does not change (if Z has the balance factor 0) and the whole tree is in AVL-shape.
The time required is O(log n) for lookup, plus a maximum of O(log n) retracing levels (O(1) on average) on the way back to the root, so the operation can be completed in O(log n) time.

Set operations and bulk operations
In addition to the single-element insert, delete and lookup operations, several set operations have been defined on AVL trees: union, intersection and set difference. Then fast bulk operations on insertions or deletions can be implemented based on these set functions. These set operations rely on two helper operations, Split and Join. With the new operations, the implementation of AVL trees can be more efficient and highly-parallelizable.The function Join on two AVL trees t1 and t2 and a key k will return a tree containing all elements in t1, t2 as well as k. It requires k to be greater than all keys in t1 and smaller than all keys in t2. If the two trees differ by height at most one, Join simply create a new node with left subtree t1, root k and right subtree t2. Otherwise, suppose that t1 is higher than t2 for more than one (the other case is symmetric). Join follows the right spine of t1 until a node c which is balanced with t2. At this point a new node with left child c, root k and right child t2 is created to replace c. The new node satisfies the AVL invariant, and its height is one greater than c. The increase in height can increase the height of its ancestors, possibly invalidating the AVL invariant of those nodes. This can be fixed either with a double rotation if invalid at the parent or a single left rotation if invalid higher in the tree, in both cases restoring the height for any further ancestor nodes. Join will therefore require at most two rotations. The cost of this function is the difference of the heights between the two input trees.

To split an AVL tree into two smaller trees, those smaller than key k, and those greater than key k, first draw a path from the root by inserting k into the AVL. After this insertion, all values less than k will be found on the left of the path, and all values greater than k will be found on the right. By applying Join, all the subtrees on the left side are merged bottom-up using keys on the path as intermediate nodes from bottom to top to form the left tree, and the right part is asymmetric. The cost of Split is O(log n), order of the height of the tree.

The union of two AVL trees t1 and t2 representing sets A and B, is an AVL t that represents A ∪ B.

The algorithm for intersection or difference is similar, but requires the Join2 helper routine that is the same as Join but without the middle key. Based on the new functions for union, intersection or difference, either one key or multiple keys can be inserted to or deleted from the AVL tree. Since Split calls Join but does not deal with the balancing criteria of AVL trees directly, such an implementation is usually called the ""join-based"" implementation.
The complexity of each of union, intersection and difference is O(mlog⁡(nm+1)){\displaystyle {\text{O}}\left(m\log \left({n \over m}+1\right)\right)} for AVL trees of sizes m{\displaystyle m} and n(≥m){\displaystyle n\;(\geq m)}. More importantly, since the recursive calls to union, intersection or difference are independent of each other, they can be executed in parallel with a parallel depth O(log⁡mlog⁡n){\displaystyle {\text{O}}(\log m\log n)}. When m=1{\displaystyle m=1}, the join-based implementation has the same computational DAG as single-element insertion and deletion.

Rebalancing
If during a modifying operation the height difference between two child subtrees changes, this may, as long as it is < 2, be reflected by an adaption of the balance information at the parent. During insert and delete operations a (temporary) height difference of 2 may arise, which means that the parent subtree has to be ""rebalanced"". The given repair tools are the so-called tree rotations, because they move the keys only ""vertically"", so that the (""horizontal"") in-order sequence of the keys is fully preserved (which is essential for a binary-search tree).: 458–481  : 33 Let X be the node that has a (temporary) balance factor of −2 or +2. Its left or right subtree was modified. Let Z be the child with the higher subtree (see figures 2 and 3). Note that both children are in AVL shape by induction hypothesis.
In case of insertion this insertion has happened to one of Z's children in a way that Z's height has increased.
In case of deletion this deletion has happened to the sibling t1 of Z in a way so that t1's height being already lower has decreased. (This is the only case where Z's balance factor may also be 0.)
There are four possible variants of the violation:

And the rebalancing is performed differently:

Thereby, the situations are denoted as C B, where C (= child direction) and B (= balance) come from the set { Left, Right } with Right := −Left. The balance violation of case C == B is repaired by a simple rotation rotate_(−C), whereas the case C != B is repaired by a double rotation rotate_CB.
The cost of a rotation, either simple or double, is constant.

Simple rotation
Figure 2 shows a Right Right situation. In its upper half, node X has two child trees with a balance factor of +2. Moreover, the inner child t23 of Z (i.e., left child when Z is right child, or right child when Z is left child) is not higher than its sibling t4. This can happen by a height increase of subtree t4 or by a height decrease of subtree t1. In the latter case, also the pale situation where t23 has the same height as t4 may occur.
The result of the left rotation is shown in the lower half of the figure. Three links (thick edges in figure 2) and two balance factors are to be updated.
As the figure shows, before an insertion, the leaf layer was at level h+1, temporarily at level h+2 and after the rotation again at level h+1. In case of a deletion, the leaf layer was at level h+2, where it is again, when t23 and t4 were of same height. Otherwise the leaf layer reaches level h+1, so that the height of the rotated tree decreases.

Code snippet of a simple left rotation

Double rotation
Figure 3 shows a Right Left situation. In its upper third, node X has two child trees with a balance factor of +2. But unlike figure 2, the inner child Y of Z is higher than its sibling t4. This can happen by the insertion of Y itself or a height increase of one of its subtrees t2 or t3 (with the consequence that they are of different height) or by a height decrease of subtree t1. In the latter case, it may also occur that t2 and t3 are of the same height.
The result of the first, the right, rotation is shown in the middle third of the figure. (With respect to the balance factors, this rotation is not of the same kind as the other AVL single rotations, because the height difference between Y and t4 is only 1.) The result of the final left rotation is shown in the lower third of the figure. Five links (thick edges in figure 3) and three balance factors are to be updated.
As the figure shows, before an insertion, the leaf layer was at level h+1, temporarily at level h+2 and after the double rotation again at level h+1. In case of a deletion, the leaf layer was at level h+2 and after the double rotation it is at level h+1, so that the height of the rotated tree decreases.

Code snippet of a right-left double rotation

Comparison to other structures
Both AVL trees and red–black (RB) trees are self-balancing binary search trees and they are related mathematically. Indeed, every AVL tree can be colored red–black, but there are RB trees which are not AVL balanced. For maintaining the AVL (or RB) tree's invariants, rotations play an important role. In the worst case, even without rotations, AVL or RB insertions or deletions require O(log n) inspections and/or updates to AVL balance factors (or RB colors). RB insertions and deletions and AVL insertions require from zero to three tail-recursive rotations and run in amortized O(1) time,: pp.165, 158   thus equally constant on average. AVL deletions requiring O(log n) rotations in the worst case are also O(1) on average. RB trees require storing one bit of information (the color) in each node, while AVL trees mostly use two bits for the balance factor, although, when stored at the children, one bit with meaning «lower than sibling» suffices. The bigger difference between the two data structures is their height limit.
For a tree of size n ≥ 1

an AVL tree's height is at most
h≦clog2⁡(n+d)+b<clog2⁡(n+2)+b{\displaystyle {\begin{array}{ll}h&\leqq \;c\log _{2}(n+d)+b\\&<\;c\log _{2}(n+2)+b\end{array}}}where φ:=1+52≈1.618{\displaystyle \varphi :={\tfrac {1+{\sqrt {5}}}{2}}\approx 1.618}  the golden ratio, c:=1log2⁡φ≈1.440,{\displaystyle c:={\tfrac {1}{\log _{2}\varphi }}\approx 1.440,}   b:=c2log2⁡5−2≈−0.328,{\displaystyle b:={\tfrac {c}{2}}\log _{2}5-2\approx \;-0.328,} and  d:=1+1φ45≈1.065{\displaystyle d:=1+{\tfrac {1}{\varphi ^{4}{\sqrt {5}}}}\approx 1.065}.a RB tree's height is at most
h≦2log2⁡(n+1){\displaystyle {\begin{array}{ll}h&\leqq \;2\log _{2}(n+1)\end{array}}} .AVL trees are more rigidly balanced than RB trees with an asymptotic relation AVL/RB ≈0.720 of the maximal heights. For insertions and deletions, Ben Pfaff shows in 79 measurements a relation of AVL/RB between 0.677 and 1.077 with median ≈0.947 and geometric mean ≈0.910.

See also
WAVL tree
Weight-balanced tree
Splay tree
Scapegoat tree
B-tree
T-tree
List of data structures

References
Further reading
Donald Knuth. The Art of Computer Programming, Volume 3: Sorting and Searching, Third Edition. Addison-Wesley, 1997. ISBN 0-201-89685-0. Pages 458–475 of section 6.2.3: Balanced Trees.
Haeupler, Bernhard; Sen, Siddhartha; Tarjan, Robert E. (2015), ""Rank-balanced trees"" (PDF), ACM Transactions on Algorithms, 11 (4): Art. 30, 26, doi:10.1145/2689412, MR 3361215, S2CID 1407290.

External links

 This article incorporates public domain material from Paul E. Black. ""AVL Tree"". Dictionary of Algorithms and Data Structures. NIST.",2118,https://en.wikipedia.org/wiki/AVL_tree
Day–Stout–Warren algorithm,"The Day–Stout–Warren (DSW) algorithm is a method for efficiently balancing binary search trees –  that is, decreasing their height to O(log n) nodes, where n is the total number of nodes. Unlike a self-balancing binary search tree, it does not do this incrementally during each operation, but periodically, so that its cost can be amortized over many operations. The algorithm was designed by Quentin F. Stout and Bette Warren in a 1986 CACM paper, based on work done by Colin Day in 1976.The algorithm requires linear (O(n)) time and is in-place. The original algorithm by Day generates as compact a tree as possible: all levels of the tree are completely full except possibly the bottom-most. It operates in two phases. First, the tree is turned into a linked list by means of an in-order traversal, reusing the pointers in the (threaded) tree's nodes. A series of left-rotations forms the second phase.
The Stout–Warren modification generates a complete binary tree, namely one in which the bottom-most level is filled strictly from left to right.  This is a useful transformation to perform if it is known that no more inserts will be done. It does not require the tree to be threaded, nor does it require more than constant space to operate. Like the original algorithm, Day–Stout–Warren operates in two phases, the first entirely new, the second a modification of Day's rotation phase.A 2002 article by Timothy J. Rolfe brought attention back to the DSW algorithm; the naming is from the section title ""6.7.1:  The DSW Algorithm"" in Adam Drozdek's textbook. Rolfe cites two main advantages: ""in circumstances in which one generates an entire binary search tree at the beginning of processing, followed by item look-up access for the rest of processing"" and ""pedagogically within a course on data structures where one progresses from the binary search tree into self-adjusting trees, since it gives a first exposure to doing rotations within a binary search tree.""","The Day–Stout–Warren (DSW) algorithm is a method for efficiently balancing binary search trees –  that is, decreasing their height to O(log n) nodes, where n is the total number of nodes. Unlike a self-balancing binary search tree, it does not do this incrementally during each operation, but periodically, so that its cost can be amortized over many operations. The algorithm was designed by Quentin F. Stout and Bette Warren in a 1986 CACM paper, based on work done by Colin Day in 1976.The algorithm requires linear (O(n)) time and is in-place. The original algorithm by Day generates as compact a tree as possible: all levels of the tree are completely full except possibly the bottom-most. It operates in two phases. First, the tree is turned into a linked list by means of an in-order traversal, reusing the pointers in the (threaded) tree's nodes. A series of left-rotations forms the second phase.
The Stout–Warren modification generates a complete binary tree, namely one in which the bottom-most level is filled strictly from left to right.  This is a useful transformation to perform if it is known that no more inserts will be done. It does not require the tree to be threaded, nor does it require more than constant space to operate. Like the original algorithm, Day–Stout–Warren operates in two phases, the first entirely new, the second a modification of Day's rotation phase.A 2002 article by Timothy J. Rolfe brought attention back to the DSW algorithm; the naming is from the section title ""6.7.1:  The DSW Algorithm"" in Adam Drozdek's textbook. Rolfe cites two main advantages: ""in circumstances in which one generates an entire binary search tree at the beginning of processing, followed by item look-up access for the rest of processing"" and ""pedagogically within a course on data structures where one progresses from the binary search tree into self-adjusting trees, since it gives a first exposure to doing rotations within a binary search tree.""

Pseudocode
The following is a presentation of the basic DSW algorithm in pseudocode, after the Stout–Warren paper. It consists of a main routine with three subroutines. The main routine is given by

Allocate a node, the ""pseudo-root"", and make the tree's actual root the right child of the pseudo-root.
Call tree-to-vine with the pseudo-root as its argument.
Call vine-to-tree on the pseudo-root and the size (number of elements) of the tree.
Make the tree's actual root equal to the pseudo-root's right child.
Dispose of the pseudo-root.The subroutines are defined as follows:
routine tree-to-vine(root)
    // Convert tree to a ""vine"", i.e., a sorted linked list,
    // using the right pointers to point to the next node in the list
    tail ← root
    rest ← tail.right
    while rest ≠ nil
        if rest.left = nil
            tail ← rest
            rest ← rest.right
        else
            temp ← rest.left
            rest.left ← temp.right
            temp.right ← rest
            rest ← temp
            tail.right ← temp

routine vine-to-tree(root, size)
    leaves ← size + 1 − 2⌊log2(size + 1))⌋
    compress(root, leaves)
    size ← size − leaves
    while size > 1
        compress(root, ⌊size / 2⌋)
        size ← ⌊size / 2⌋

routine compress(root, count)
    scanner ← root
    for i ← 1 to count
        child ← scanner.right
        scanner.right ← child.right
        scanner ← scanner.right
        child.right ← scanner.left
        scanner.left ← child

Notes


== References ==",1699060,https://en.wikipedia.org/wiki/Day%E2%80%93Stout%E2%80%93Warren_algorithm
Disjoint-set data structure,"In computer science, a disjoint-set data structure, also called a union–find data structure or merge–find set, is a data structure that stores a collection of disjoint (non-overlapping) sets.  Equivalently, it stores a partition of a set into disjoint subsets.  It provides operations for adding new sets, merging sets (replacing them by their union), and finding a representative member of a set. The last operation makes it possible to find out efficiently if any two elements are in the same or different sets.
While there are several ways of implementing disjoint-set data structures, in practice they are often identified with a particular implementation called a disjoint-set forest.  This is a specialized type of forest which performs unions and finds in near-constant amortized time.  To perform a sequence of m addition, union, or find operations on a disjoint-set forest with n nodes requires total time O(mα(n)), where α(n) is the extremely slow-growing inverse Ackermann function.  Disjoint-set forests do not guarantee this performance on a per-operation basis.  Individual union and find operations can take longer than a constant times α(n) time, but each operation causes the disjoint-set forest to adjust itself so that successive operations are faster.  Disjoint-set forests are both asymptotically optimal and practically efficient.
Disjoint-set data structures play a key role in Kruskal's algorithm for finding the minimum spanning tree of a graph.  The importance of minimum spanning trees means that disjoint-set data structures underlie a wide variety of algorithms.  In addition, disjoint-set data structures also have applications to symbolic computation, as well as in compilers, especially for register allocation problems.","In computer science, a disjoint-set data structure, also called a union–find data structure or merge–find set, is a data structure that stores a collection of disjoint (non-overlapping) sets.  Equivalently, it stores a partition of a set into disjoint subsets.  It provides operations for adding new sets, merging sets (replacing them by their union), and finding a representative member of a set. The last operation makes it possible to find out efficiently if any two elements are in the same or different sets.
While there are several ways of implementing disjoint-set data structures, in practice they are often identified with a particular implementation called a disjoint-set forest.  This is a specialized type of forest which performs unions and finds in near-constant amortized time.  To perform a sequence of m addition, union, or find operations on a disjoint-set forest with n nodes requires total time O(mα(n)), where α(n) is the extremely slow-growing inverse Ackermann function.  Disjoint-set forests do not guarantee this performance on a per-operation basis.  Individual union and find operations can take longer than a constant times α(n) time, but each operation causes the disjoint-set forest to adjust itself so that successive operations are faster.  Disjoint-set forests are both asymptotically optimal and practically efficient.
Disjoint-set data structures play a key role in Kruskal's algorithm for finding the minimum spanning tree of a graph.  The importance of minimum spanning trees means that disjoint-set data structures underlie a wide variety of algorithms.  In addition, disjoint-set data structures also have applications to symbolic computation, as well as in compilers, especially for register allocation problems.

History
Disjoint-set forests were first described by Bernard A. Galler and Michael J. Fischer in 1964. In 1973, their time complexity was bounded to O(log∗⁡(n)){\displaystyle O(\log ^{*}(n))}, the iterated logarithm of n{\displaystyle n}, by Hopcroft and Ullman. In 1975, Robert Tarjan was the first to prove the O(mα(n)){\displaystyle O(m\alpha (n))} (inverse Ackermann function) upper bound on the algorithm's time complexity,. He also proved it to be tight. In 1979, he showed that this was the lower bound for a certain class of algorithms, that include the Galler-Fischer structure. In 1989, Fredman and Saks showed that Ω(α(n)){\displaystyle \Omega (\alpha (n))} (amortized) words of O(log⁡n){\displaystyle O(\log n)} bits must be accessed by any disjoint-set data structure per operation, thereby proving the optimality of the data structure in this model.
In 1991, Galil and Italiano published a survey of data structures for disjoint-sets.In 1994, Richard J. Anderson and Heather Woll described a parallelized version of Union–Find that never needs to block.In 2007, Sylvain Conchon and Jean-Christophe Filliâtre developed a semi-persistent version of the disjoint-set forest data structure and formalized its correctness using the proof assistant Coq. ""Semi-persistent"" means that previous versions of the structure are efficiently retained, but accessing previous versions of the data structure invalidates later ones. Their fastest implementation achieves performance almost as efficient as the non-persistent algorithm. They do not perform a complexity analysis.
Variants of disjoint-set data structures with better performance on a restricted class of problems have also been considered.  Gabow and Tarjan showed that if the possible unions are restricted in certain ways, then a truly linear time algorithm is possible.

Representation
Each node in a disjoint-set forest consists of a pointer and some auxiliary information, either a size or a rank (but not both).  The pointers are used to make parent pointer trees, where each node that is not the root of a tree points to its parent.  To distinguish root nodes from others, their parent pointers have invalid values, such as a circular reference to the node or a sentinel value.  Each tree represents a set stored in the forest, with the members of the set being the nodes in the tree.  Root nodes provide set representatives: Two nodes are in the same set if and only if the roots of the trees containing the nodes are equal.
Nodes in the forest can be stored in any way convenient to the application, but a common technique is to store them in an array.  In this case, parents can be indicated by their array index.  Every array entry requires Θ(log n) bits of storage for the parent pointer.  A comparable or lesser amount of storage is required for the rest of the entry, so the number of bits required to store the forest is Θ(n log n).  If an implementation uses fixed size nodes (thereby limiting the maximum size of the forest that can be stored), then the necessary storage is linear in n.

Operations
Disjoint-set data structures support three operations: Making a new set containing a new element; Finding the representative of the set containing a given element; and Merging two sets.

Making new sets
The MakeSet operation adds a new element into a new set containing only the new element, and the new set is added to the data structure.  If the data structure is instead viewed as a partition of a set, then the MakeSet operation enlarges the set by adding the new element, and it extends the existing partition by putting the new element into a new subset containing only the new element.
In a disjoint-set forest, MakeSet initializes the node's parent pointer and the node's size or rank.  If a root is represented by a node that points to itself, then adding an element can be described using the following pseudocode:

function MakeSet(x) is
    if x is not already in the forest then
        x.parent := x
        x.size := 1     // if nodes store size
        x.rank := 0     // if nodes store rank
    end if
end function

This operation has constant time complexity.  In particular, initializing a
disjoint-set forest with n nodes requires O(n)
time.
Lack of a parent assigned to the node implies that the node is not present in the forest.
In practice, MakeSet must be preceded by an operation that allocates memory to hold x.  As long as memory allocation is an amortized constant-time operation, as it is for a good dynamic array implementation, it does not change the asymptotic performance of the random-set forest.

Finding set representatives
The Find operation follows the chain of parent pointers from a specified query node x until it reaches a root element.  This root element represents the set to which x belongs and may be x itself.  Find returns the root element it reaches.
Performing a Find operation presents an important opportunity for improving the forest.  The time in a Find operation is spent chasing parent pointers, so a flatter tree leads to faster Find operations.  When a Find is executed, there is no faster way to reach the root than by following each parent pointer in succession.  However, the parent pointers visited during this search can be updated to point closer to the root.  Because every element visited on the way to a root is part of the same set, this does not change the sets stored in the forest.  But it makes future Find operations faster, not only for the nodes between the query node and the root, but also for their descendants.  This updating is an important part of the disjoint-set forest's amortized performance guarantee.
There are several algorithms for Find that achieve the asymptotically optimal time complexity.  One family of algorithms, known as path compression, makes every node between the query node and the root point to the root.  Path compression can be implemented using a simple recursion as follows:

function Find(x) is
    if x.parent ≠ x then
        x.parent := Find(x.parent)
        return x.parent
    else
        return x
    end if
end function

This implementation makes two passes, one up the tree and one back down.  It requires enough scratch memory to store the path from the query node to the root (in the above pseudocode, the path is implicitly represented using the call stack).  This can be decreased to a constant amount of memory by performing both passes in the same direction.  The constant memory implementation walks from the query node to the root twice, once to find the root and once to update pointers:

function Find(x) is
    root := x
    while root.parent ≠ root do
        root := root.parent
    end while

    while x.parent ≠ root do
        parent := x.parent
        x.parent := root
        x := parent
    end while

    return root
end function

Tarjan and Van Leeuwen also developed one-pass Find algorithms that retain the same worst-case complexity but are more efficient in practice.  These are called path splitting and path halving.  Both of these update the parent pointers of nodes on the path between the query node and the root.  Path splitting replaces every parent pointer on that path by a pointer to the node's grandparent:

function Find(x) is
    while x.parent ≠ x do
        (x, x.parent) := (x.parent, x.parent.parent)
    end while
    return x
end function

Path halving works similarly but replaces only every other parent pointer:

function Find(x) is
    while x.parent ≠ x do
        x.parent := x.parent.parent
        x := x.parent
    end while
    return x
end function

Merging two sets
The operation Union(x, y) replaces the set containing x and the set containing y with their union.  Union first uses Find to determine the roots of the trees containing x and y.  If the roots are the same, there is nothing more to do.  Otherwise, the two trees must be merged.  This is done by either setting the parent pointer of x's root to y's, or setting the parent pointer of y's root to x's.
The choice of which node becomes the parent has consequences for the complexity of future operations on the tree. If it is done carelessly, trees can become excessively tall.  For example, suppose that Union always made the tree containing x a subtree of the tree containing y.  Begin with a forest that has just been initialized with elements 1,2,3,…,n,{\displaystyle 1,2,3,\ldots ,n,} and execute Union(1, 2), Union(2, 3), ..., Union(n - 1, n).  The resulting forest contains a single tree whose root is n, and the path from 1 to n passes through every node in the tree.  For this forest, the time to run Find(1) is O(n).
In an efficient implementation, tree height is controlled using union by size or union by rank.  Both of these require a node to store information besides just its parent pointer.  This information is used to decide which root becomes the new parent.  Both strategies ensure that trees do not become too deep.

Union by size
In the case of union by size, a node stores its size, which is simply its number of descendants (including the node itself).  When the trees with roots x and y are merged, the node with more descendants becomes the parent.  If the two nodes have the same number of descendants, then either one can become the parent.  In both cases, the size of the new parent node is set to its new total number of descendants.

function Union(x, y) is
    // Replace nodes by roots
    x := Find(x)
    y := Find(y)

    if x = y then
        return  // x and y are already in the same set
    end if

    // If necessary, swap variables to ensure that
    // x has at least as many descendants as y
    if x.size < y.size then
        (x, y) := (y, x)
    end if

    // Make x the new root
    y.parent := x
    // Update the size of x
    x.size := x.size + y.size
end function

The number of bits necessary to store the size is clearly the number of bits necessary to store n.  This adds a constant factor to the forest's required storage.

Union by rank
For union by rank, a node stores its rank, which is an upper bound for its height.  When a node is initialized, its rank is set to zero.  To merge trees with roots x and y, first compare their ranks.  If the ranks are different, then the larger rank tree becomes the parent, and the ranks of x and y do not change.  If the ranks are the same, then either one can become the parent, but the new parent's rank is incremented by one.  While the rank of a node is clearly related to its height, storing ranks is more efficient than storing heights.  The height of a node can change during a Find operation, so storing ranks avoids the extra effort of keeping the height correct.  In pseudocode, union by rank is:

function Union(x, y) is
    // Replace nodes by roots
    x := Find(x)
    y := Find(y)

    if x = y then
        return  // x and y are already in the same set
    end if

    // If necessary, rename variables to ensure that
    // x has rank at least as large as that of y
    if x.rank < y.rank then
        (x, y) := (y, x)
    end if

    // Make x the new root
    y.parent := x
    // If necessary, increment the rank of x
    if x.rank = y.rank then
        x.rank := x.rank + 1
    end if
end function

It can be shown that every node has rank ⌊log⁡n⌋{\displaystyle \lfloor \log n\rfloor } or less.  Consequently each rank can be stored in O(log log n) bits and all the ranks can be stored in O(n log log n) bits. This makes the ranks an asymptotically negligible portion of the forest's size.
It is clear from the above implementations that the size and rank of a node do not matter unless a node is the root of a tree.  Once a node becomes a child, its size and rank are never accessed again.

Time complexity
A disjoint-set forest implementation in which Find does not update parent pointers, and in which Union does not attempt to control tree heights, can have trees with height O(n).  In such a situation, the Find and Union operations require O(n) time.
If an implementation uses path compression alone, then a sequence of n MakeSet operations, followed by up to n − 1 Union operations and f Find operations, has a worst-case running time of Θ(n+f⋅(1+log2+f/n⁡n)){\displaystyle \Theta (n+f\cdot \left(1+\log _{2+f/n}n\right))}.Using union by rank, but without updating parent pointers during Find, gives a running time of Θ(mlog⁡n){\displaystyle \Theta (m\log n)} for m operations of any type, up to n of which are MakeSet operations.The combination of path compression, splitting, or halving, with union by size or by rank, reduces the running time for m operations of any type, up to n of which are MakeSet operations, to Θ(mα(n)){\displaystyle \Theta (m\alpha (n))}.  This makes the amortized running time of each operation Θ(α(n)){\displaystyle \Theta (\alpha (n))}.  This is asymptotically optimal, meaning that every disjoint set data structure must use Ω(α(n)){\displaystyle \Omega (\alpha (n))} amortized time per operation.  Here, the function α(n){\displaystyle \alpha (n)} is the inverse Ackermann function.  The inverse Ackermann function grows extraordinarily slowly, so this factor is 4 or less for any n that can actually be written in the physical universe.  This makes disjoint-set operations practically amortized constant time.

Proof of O(m log* n) time complexity of Union-Find
The precise analysis of the performance of a disjoint-set forest is somewhat intricate.  However, there is a much simpler analysis that proves that the amortized time for any m Find or Union operations on a disjoint-set forest containing n objects is O(m log* n), where log* denotes the iterated logarithm.Lemma 1: As the find function follows the path along to the root, the rank of node it encounters is increasing.

Lemma 2: A node u which is root of a subtree with rank r has at least 2r{\displaystyle 2^{r}} nodes.

Lemma 3: The maximum number of nodes of rank r is at most n2r.{\displaystyle {\frac {n}{2^{r}}}.}

For convenience, we define ""bucket"" here: a bucket is a set that contains vertices with particular ranks.
We create some buckets and put vertices into the buckets according to their ranks inductively. That is, vertices with rank 0 go into the zeroth bucket, vertices with rank 1 go into the first bucket, vertices with ranks 2 and 3 go into the second bucket. If the B-th bucket contains vertices with ranks from interval [r,2r−1]=[r,R−1]{\displaystyle \left[r,2^{r}-1\right]=[r,R-1]} then the (B+1)st bucket will contain vertices with ranks from interval [R,2R−1].{\displaystyle \left[R,2^{R}-1\right].}

We can make two observations about the buckets.

The total number of buckets is at most log*n
Proof: When we go from one bucket to the next, we add one more two to the power, that is, the next bucket to [B,2B−1]{\displaystyle \left[B,2^{B}-1\right]} will be [2B,22B−1]{\displaystyle \left[2^{B},2^{2^{B}}-1\right]}
The maximum number of elements in bucket [B,2B−1]{\displaystyle \left[B,2^{B}-1\right]} is at most 2n2B{\displaystyle {\frac {2n}{2^{B}}}}
Proof: The maximum number of elements in bucket [B,2B−1]{\displaystyle \left[B,2^{B}-1\right]} is at most n2B+n2B+1+n2B+2+⋯+n22B−1≤2n2B.{\displaystyle {\frac {n}{2^{B}}}+{\frac {n}{2^{B+1}}}+{\frac {n}{2^{B+2}}}+\cdots +{\frac {n}{2^{2^{B}-1}}}\leq {\frac {2n}{2^{B}}}.}Let F represent the list of ""find"" operations performed, and let

Then the total cost of m finds is T=T1+T2+T3.{\displaystyle T=T_{1}+T_{2}+T_{3}.}
Since each find operation makes exactly one traversal that leads to a root, we have T1 = O(m).
Also, from the bound above on the number of buckets, we have T2 = O(mlog*n).
For T3, suppose we are traversing an edge from u to v, where u and v have rank in the bucket [B, 2B − 1] and v is not the root (at the time of this traversing, otherwise the traversal would be accounted for in T1). Fix u and consider the sequence v1,v2,…,vk{\displaystyle v_{1},v_{2},\ldots ,v_{k}} that take the role of v in different find operations. Because of path compression and not accounting for the edge to a root, this sequence contains only different nodes and because of Lemma 1 we know that the ranks of the nodes in this sequence are strictly increasing. By both of the nodes being in the bucket we can conclude that the length k of the sequence (the number of times node u is attached to a different root in the same bucket) is at most the number of ranks in the buckets B, that is, at most 2B−1−B<2B.{\displaystyle 2^{B}-1-B<2^{B}.}
Therefore, T3≤∑[B,2B−1]∑u2B.{\displaystyle T_{3}\leq \sum _{[B,2^{B}-1]}\sum _{u}2^{B}.}
From Observations 1 and 2, we can conclude that T3≤∑B2B2n2B≤2nlog∗⁡n.{\textstyle T_{3}\leq \sum _{B}2^{B}{\frac {2n}{2^{B}}}\leq 2n\log ^{*}n.}
Therefore, T=T1+T2+T3=O(mlog∗⁡n).{\displaystyle T=T_{1}+T_{2}+T_{3}=O(m\log ^{*}n).}

Other structures
Better worst-case time per operation
The worst-case time of the Find operation in trees with Union by rank or Union by weight is Θ(log⁡n){\displaystyle \Theta (\log n)} (i.e., it is O(log⁡n){\displaystyle O(\log n)} and this bound is tight). 
In 1985, N. Blum gave an implementation of the operations that does not use path compression, but compresses trees during union{\displaystyle union}. His implementation runs in O(log⁡n/log⁡log⁡n){\displaystyle O(\log n/\log \log n)} time per operation, and thus in comparison with Galler and Fischer's structure it has a better worst-case time per operation, but inferior amortized time. In 1999, Alstrup et al. gave a structure that has optimal worst-case
time O(log⁡n/log⁡log⁡n){\displaystyle O(\log n/\log \log n)} together with inverse-Ackermann amortized time.

Deletion
The regular implementation as disjoint-set forests does not react favorably to the deletion of elements,
in the sense that the time for Find will not improve as a result of the decrease in the number of elements. However, there exist modern implementations that allow for constant-time deletion and where the time-bound for Find depends on the current number of elements

Applications
Disjoint-set data structures model the partitioning of a set, for example to keep track of the connected components of an undirected graph. This model can then be used to determine whether two vertices belong to the same component, or whether adding an edge between them would result in a cycle.  The Union–Find algorithm is used in high-performance implementations of unification.This data structure is used by the Boost Graph Library to implement its Incremental Connected Components functionality. It is also a key component in implementing Kruskal's algorithm to find the minimum spanning tree of a graph.
The  Hoshen-Kopelman algorithm uses a Union-Find in the algorithm.

See also
Partition refinement, a different data structure for maintaining disjoint sets, with updates that split sets apart rather than merging them together
Dynamic connectivity

References
External links
C++ implementation, part of the Boost C++ libraries
Java implementation, part of JGraphT library
Javascript implementation
Python implementation",1037551,https://en.wikipedia.org/wiki/Disjoint-set_data_structure
Dynamic array,"In computer science, a dynamic array, growable array, resizable array, dynamic table, mutable array, or array list is a random access, variable-size list data structure that allows elements to be added or removed. It is supplied with standard libraries in many modern mainstream programming languages. Dynamic arrays overcome a limit of static arrays, which have a fixed capacity that needs to be specified at allocation.
A dynamic array is not the same thing as a dynamically allocated array or variable-length array, either of which is an array whose size is fixed when the array is allocated, although a dynamic array may use such a fixed-size array as a back end.","In computer science, a dynamic array, growable array, resizable array, dynamic table, mutable array, or array list is a random access, variable-size list data structure that allows elements to be added or removed. It is supplied with standard libraries in many modern mainstream programming languages. Dynamic arrays overcome a limit of static arrays, which have a fixed capacity that needs to be specified at allocation.
A dynamic array is not the same thing as a dynamically allocated array or variable-length array, either of which is an array whose size is fixed when the array is allocated, although a dynamic array may use such a fixed-size array as a back end.

Bounded-size dynamic arrays and capacity
A simple dynamic array can be constructed by allocating an array of fixed-size, typically larger than the number of elements immediately required. The elements of the dynamic array are stored contiguously at the start of the underlying array, and the remaining positions towards the end of the underlying array are reserved, or unused. Elements can be added at the end of a dynamic array in constant time by using the reserved space, until this space is completely consumed. When all space is consumed, and an additional element is to be added, then the underlying fixed-size array needs to be increased in size. Typically resizing is expensive because it involves allocating a new underlying array and copying each element from the original array. Elements can be removed from the end of a dynamic array in constant time, as no resizing is required. The number of elements used by the dynamic array contents is its logical size or size, while the size of the underlying array is called the dynamic array's capacity or physical size, which is the maximum possible size without relocating data.A fixed-size array will suffice in applications where the maximum logical size is fixed (e.g. by specification), or can be calculated before the array is allocated. A dynamic array might be preferred if:

the maximum logical size is unknown, or difficult to calculate, before the array is allocated
it is considered that a maximum logical size given by a specification is likely to change
the amortized cost of resizing a dynamic array does not significantly affect performance or responsiveness

Geometric expansion and amortized cost
To avoid incurring the cost of resizing many times, dynamic arrays resize by a large amount, such as doubling in size, and use the reserved space for future expansion. The operation of adding an element to the end might work as follows:

As n elements are inserted, the capacities form a geometric progression. Expanding the array by any constant proportion a ensures that inserting n elements takes O(n) time overall, meaning that each insertion takes amortized constant time. Many dynamic arrays also deallocate some of the underlying storage if its size drops below a certain threshold, such as 30% of the capacity. This threshold must be strictly smaller than 1/a in order to provide hysteresis (provide a stable band to avoid repeatedly growing and shrinking) and support mixed sequences of insertions and removals with amortized constant cost.
Dynamic arrays are a common example when teaching amortized analysis.

Growth factor
The growth factor for the dynamic array depends on several factors including a space-time trade-off and algorithms used in the memory allocator itself. For growth factor a, the average time per insertion operation is about a/(a−1), while the number of wasted cells is bounded above by (a−1)n. If memory allocator uses a first-fit allocation algorithm, then growth factor values such as a=2 can cause dynamic array expansion to run out of memory even though a significant amount of memory may still be available. There have been various discussions on ideal growth factor values, including proposals for the golden ratio as well as the value 1.5. Many textbooks, however, use a = 2 for simplicity and analysis purposes.Below are growth factors used by several popular implementations:

Performance
The dynamic array has performance similar to an array, with the addition of new operations to add and remove elements:

Getting or setting the value at a particular index (constant time)
Iterating over the elements in order (linear time, good cache performance)
Inserting or deleting an element in the middle of the array (linear time)
Inserting or deleting an element at the end of the array (constant amortized time)Dynamic arrays benefit from many of the advantages of arrays, including good locality of reference and data cache utilization, compactness (low memory use), and random access. They usually have only a small fixed additional overhead for storing information about the size and capacity. This makes dynamic arrays an attractive tool for building cache-friendly data structures. However, in languages like Python or Java that enforce reference semantics, the dynamic array generally will not store the actual data, but rather it will store references to the data that resides in other areas of memory. In this case, accessing items in the array sequentially will actually involve accessing multiple non-contiguous areas of memory, so the many advantages of the cache-friendliness of this data structure are lost.
Compared to linked lists, dynamic arrays have faster indexing (constant time versus linear time) and typically faster iteration due to improved locality of reference; however, dynamic arrays require linear time to insert or delete at an arbitrary location, since all following elements must be moved, while linked lists can do this in constant time. This disadvantage is mitigated by the gap buffer and tiered vector variants discussed under Variants below. Also, in a highly fragmented memory region, it may be expensive or impossible to find contiguous space for a large dynamic array, whereas linked lists do not require the whole data structure to be stored contiguously.
A balanced tree can store a list while providing all operations of both dynamic arrays and linked lists reasonably efficiently, but both insertion at the end and iteration over the list are slower than for a dynamic array, in theory and in practice, due to non-contiguous storage and tree traversal/manipulation overhead.

Variants
Gap buffers are similar to dynamic arrays but allow efficient insertion and deletion operations clustered near the same arbitrary location. Some deque implementations use array deques, which allow amortized constant time insertion/removal at both ends, instead of just one end.
Goodrich presented a dynamic array algorithm called tiered vectors that provides O(n1/k) performance for insertions and deletions from anywhere in the array, and O(k) get and set, where k ≥ 2 is a constant parameter.
Hashed array tree (HAT) is a dynamic array algorithm published by Sitarski in 1996. Hashed array tree wastes order n1/2 amount of storage space, where n is the number of elements in the array. The algorithm has O(1) amortized performance when appending a series of objects to the end of a hashed array tree.
In a 1999 paper, Brodnik et al. describe a tiered dynamic array data structure, which wastes only n1/2 space for n elements at any point in time, and they prove a lower bound showing that any dynamic array must waste this much space if the operations are to remain amortized constant time. Additionally, they present a variant where growing and shrinking the buffer has not only amortized but worst-case constant time.
Bagwell (2002) presented the VList algorithm, which can be adapted to implement a dynamic array.
Naïve resizable arrays -- also called  ""the worst implementation"" of resizable arrays -- keep the allocated size of the array exactly big enough for all the data it contains, perhaps by calling realloc for each and every item added to the array. Naïve resizable arrays are the simplest way of implementing a resizeable array in C. They don't waste any memory, but appending to the end of the array always takes Θ(n) time.
Linearly growing arrays pre-allocate (""waste"") Θ(1) space every time they re-size the array, making them many times faster than naïve resizable arrays -- appending to the end of the array still takes Θ(n) time but with a much smaller constant.
Naïve resizable arrays and linearly growing arrays may be useful when a space-constrained application needs lots of small resizable arrays;
they are also commonly used as an educational example leading to exponentially growing dynamic arrays.

Language support
C++'s std::vector and Rust's std::vec::Vec are implementations of dynamic arrays, as are the ArrayList classes supplied with the Java API: 236  and the .NET Framework.: 22 The generic List<> class supplied with version 2.0 of the .NET Framework is also implemented with dynamic arrays. Smalltalk's OrderedCollection is a dynamic array with dynamic start and end-index, making the removal of the first element also O(1). 
Python's list datatype implementation is a dynamic array the growth pattern of which is:  0, 4, 8, 16, 24, 32, 40, 52, 64, 76, ...Delphi and D implement dynamic arrays at the language's core. 
Ada's Ada.Containers.Vectors generic package provides dynamic array implementation for a given subtype. 
Many scripting languages such as Perl and Ruby offer dynamic arrays as a built-in primitive data type. 
Several cross-platform frameworks provide dynamic array implementations for C, including CFArray and CFMutableArray in Core Foundation, and GArray and GPtrArray in GLib.
Common Lisp provides a rudimentary support for resizable vectors by allowing to configure the built-in array type as adjustable and the location of insertion by the fill-pointer.

References
External links
NIST Dictionary of Algorithms and Data Structures: Dynamic array
VPOOL - C language implementation of dynamic array.
CollectionSpy — A Java profiler with explicit support for debugging ArrayList- and Vector-related issues.
Open Data Structures - Chapter 2 - Array-Based Lists, Pat Morin",1456434,https://en.wikipedia.org/wiki/Dynamic_array
Fibonacci heap,"In computer science, a Fibonacci heap is a data structure for priority queue operations, consisting of a collection of  heap-ordered trees. It has a better amortized running time than many other priority queue data structures including the binary heap and binomial heap. Michael L. Fredman and Robert E. Tarjan developed Fibonacci heaps in 1984 and published them in a scientific journal in 1987. Fibonacci heaps are named after the Fibonacci numbers, which are used in their running time analysis.
For the Fibonacci heap, the find-minimum operation takes constant (O(1)) amortized time. The insert and decrease key operations also work in constant amortized time. Deleting an element (most often used in the special case of deleting the minimum element) works in O(log n) amortized time, where n is the size of the heap. This means that starting from an empty data structure, any sequence of a insert and decrease key operations and b delete operations would take O(a + b log n) worst case time, where n is the maximum heap size. In a binary or binomial heap, such a sequence of operations would take O((a + b) log n) time. A Fibonacci heap is thus better than a binary or binomial heap when b is smaller than a by a non-constant factor. It is also possible to merge two Fibonacci heaps in constant amortized time, improving on the logarithmic merge time of a binomial heap, and improving on binary heaps which cannot handle merges efficiently.
Using Fibonacci heaps for priority queues improves the asymptotic running time of important algorithms, such as Dijkstra's algorithm for computing the shortest path between two nodes in a graph, compared to the same algorithm using other slower priority queue data structures.","In computer science, a Fibonacci heap is a data structure for priority queue operations, consisting of a collection of  heap-ordered trees. It has a better amortized running time than many other priority queue data structures including the binary heap and binomial heap. Michael L. Fredman and Robert E. Tarjan developed Fibonacci heaps in 1984 and published them in a scientific journal in 1987. Fibonacci heaps are named after the Fibonacci numbers, which are used in their running time analysis.
For the Fibonacci heap, the find-minimum operation takes constant (O(1)) amortized time. The insert and decrease key operations also work in constant amortized time. Deleting an element (most often used in the special case of deleting the minimum element) works in O(log n) amortized time, where n is the size of the heap. This means that starting from an empty data structure, any sequence of a insert and decrease key operations and b delete operations would take O(a + b log n) worst case time, where n is the maximum heap size. In a binary or binomial heap, such a sequence of operations would take O((a + b) log n) time. A Fibonacci heap is thus better than a binary or binomial heap when b is smaller than a by a non-constant factor. It is also possible to merge two Fibonacci heaps in constant amortized time, improving on the logarithmic merge time of a binomial heap, and improving on binary heaps which cannot handle merges efficiently.
Using Fibonacci heaps for priority queues improves the asymptotic running time of important algorithms, such as Dijkstra's algorithm for computing the shortest path between two nodes in a graph, compared to the same algorithm using other slower priority queue data structures.

Structure
A Fibonacci heap is a collection of trees satisfying the minimum-heap property, that is, the key of a child is always greater than or equal to the key of the parent. This implies that the minimum key is always at the root of one of the trees. Compared with binomial heaps, the structure of a Fibonacci heap is more flexible. The trees do not have a prescribed shape and in the extreme case the heap can have every element in a separate tree. This flexibility allows some operations to be executed in a lazy manner, postponing the work for later operations. For example, merging heaps is done simply by concatenating the two lists of trees, and operation decrease key sometimes cuts a node from its parent and forms a new tree.
However, at some point order needs to be introduced to the heap to achieve the desired running time. In particular, degrees of nodes (here degree means the number of direct children) are kept quite low: every node has degree at most log n and the size of a subtree rooted in a node of degree k is at least Fk+2, where Fk is the kth Fibonacci number. This is achieved by the rule that we can cut at most one child of each non-root node. When a second child is cut, the node itself needs to be cut from its parent and becomes the root of a new tree (see Proof of degree bounds, below). The number of trees is decreased in the operation delete minimum, where trees are linked together.
As a result of a relaxed structure, some operations can take a long time while others are done very quickly. For the amortized running time analysis, we use the potential method, in that we pretend that very fast operations take a little bit longer than they actually do. This additional time is then later combined and subtracted from the actual running time of slow operations. The amount of time saved for later use is measured at any given moment by a potential function. The potential of a Fibonacci heap is given by

Potential = t + 2mwhere t is the number of trees in the Fibonacci heap, and m is the number of marked nodes. A node is marked if at least one of its children was cut since this node was made a child of another node (all roots are unmarked).
The amortized time for an operation is given by the sum of the actual time and c times the difference in potential, where c is a constant (chosen to match the constant factors in the O notation for the actual time).
Thus, the root of each tree in a heap has one unit of time stored. This unit of time can be used later to link this tree with another tree at amortized time 0. Also, each marked node has two units of time stored. One can be used to cut the node from its parent. If this happens, the node becomes a root and the second unit of time will remain stored in it as in any other root.

Implementation of operations
To allow fast deletion and concatenation, the roots of all trees are linked using a circular doubly linked list. The children of each node are also linked using such a list. For each node, we maintain its number of children and whether the node is marked. Moreover, we maintain a pointer to the root containing the minimum key.
Operation find minimum is now trivial because we keep the pointer to the node containing it. It does not change the potential of the heap, therefore both actual and amortized cost are constant.
As mentioned above, merge is implemented simply by concatenating the lists of tree roots of the two heaps. This can be done in constant time and the potential does not change, leading again to constant amortized time.
Operation insert works by creating a new heap with one element and doing merge. This takes constant time, and the potential increases by one, because the number of trees increases. The amortized cost is thus still constant.
Operation extract minimum (same as delete minimum) operates in three phases. First we take the root containing the minimum element and remove it. Its children will become roots of new trees. If the number of children was d, it takes time O(d) to process all new roots and the potential increases by d−1. Therefore, the amortized running time of this phase is O(d) = O(log n).
However to complete the extract minimum operation, we need to update the pointer to the root with minimum key. Unfortunately there may be up to n roots we need to check. In the second phase we therefore decrease the number of roots by successively linking together roots of the same degree. When two roots u and v have the same degree, we make one of them a child of the other so that the one with the smaller key remains the root. Its degree will increase by one. This is repeated until every root has a different degree. To find trees of the same degree efficiently we use an array of length O(log n) in which we keep a pointer to one root of each degree. When a second root is found of the same degree, the two are linked and the array is updated. The actual running time is O(log n + m) where m is the number of roots at the beginning of the second phase. At the end we will have at most O(log n) roots (because each has a different degree). Therefore, the difference in the potential function from before this phase to after it is: O(log n) − m, and the amortized running time is then at most O(log n + m) + c(O(log n) − m). With a sufficiently large choice of c, this simplifies to O(log n).

In the third phase we check each of the remaining roots and find the minimum. This takes O(log n) time and the potential does not change. The overall amortized running time of extract minimum is therefore O(log n).
Operation decrease key will take the node, decrease the key and if the heap property becomes violated (the new key is smaller than the key of the parent), the node is cut from its parent. If the parent is not a root, it is marked. If it has been marked already, it is cut as well and its parent is marked. We continue upwards until we reach either the root or an unmarked node. Now we set the minimum pointer to the decreased value if it is the new minimum. In the process we create some number, say k, of new trees. Each of these new trees except possibly the first one was marked originally but as a root it will become unmarked. One node can become marked. Therefore, the number of marked nodes changes by −(k − 1) + 1 = − k + 2. Combining these 2 changes, the potential changes by 2(−k + 2) + k = −k + 4. The actual time to perform the cutting was O(k), therefore (again with a sufficiently large choice of c) the amortized running time is constant.
Finally, operation delete can be implemented simply by decreasing the key of the element to be deleted to minus infinity, thus turning it into the minimum of the whole heap. Then we call extract minimum to remove it. The amortized running time of this operation is O(log n).

Proof of degree bounds
The amortized performance of a Fibonacci heap depends on the degree (number of children) of any tree root being O(log n), where n is the size of the heap.  Here we show that the size of the (sub)tree rooted at any node x of degree d in the heap must have size at least Fd+2, where Fk is the kth Fibonacci number.  The degree bound follows from this and the fact (easily proved by induction) that Fd+2≥φd{\displaystyle F_{d+2}\geq \varphi ^{d}} for all integers d≥0{\displaystyle d\geq 0}, where φ=(1+5)/2≐1.618{\displaystyle \varphi =(1+{\sqrt {5}})/2\doteq 1.618}.  (We then have n≥Fd+2≥φd{\displaystyle n\geq F_{d+2}\geq \varphi ^{d}}, and taking the log to base φ{\displaystyle \varphi } of both sides gives d≤logφ⁡n{\displaystyle d\leq \log _{\varphi }n} as required.)
Consider any node x somewhere in the heap (x need not be the root of one of the main trees).  Define size(x) to be the size of the tree rooted at x (the number of descendants of x, including x itself).  We prove by induction on the height of x (the length of a longest simple path from x to a descendant leaf), that size(x) ≥ Fd+2, where d is the degree of x.
Base case: If x has height 0, then d = 0, and size(x) = 1 = F2.
Inductive case:  Suppose x has positive height and degree d > 0.  Let y1, y2, ..., yd be the children of x, indexed in order of the times they were most recently made children of x (y1 being the earliest and yd the latest), and let c1, c2, ..., cd be their respective degrees.  We claim that ci ≥ i-2 for each i with 2 ≤ i ≤ d: Just before yi was made a child of x, y1,...,yi−1 were already children of x, and so x had degree at least i−1 at that time.  Since trees are combined only when the degrees of their roots are equal, it must have been that yi also had degree at least i-1 at the time it became a child of x.  From that time to the present, yi can only have lost at most one child (as guaranteed by the marking process), and so its current degree ci is at least i−2.  This proves the claim.
Since the heights of all the yi are strictly less than that of x, we can apply the inductive hypothesis to them to get size(yi) ≥ Fci+2 ≥ F(i−2)+2 = Fi.  The nodes x and y1 each contribute at least 1 to size(x), and so we have
size(x)≥2+∑i=2dsize(yi)≥2+∑i=2dFi=1+∑i=0dFi.{\displaystyle {\textbf {size}}(x)\geq 2+\sum _{i=2}^{d}{\textbf {size}}(y_{i})\geq 2+\sum _{i=2}^{d}F_{i}=1+\sum _{i=0}^{d}F_{i}.}
A routine induction proves that 1+∑i=0dFi=Fd+2{\displaystyle 1+\sum _{i=0}^{d}F_{i}=F_{d+2}} for any d≥0{\displaystyle d\geq 0}, which gives the desired lower bound on size(x).

Worst case
Although Fibonacci heaps look very efficient, they have the following two drawbacks:
They are complicated to implement.
They are not as efficient in practice when compared with theoretically less efficient forms of heaps. In their simplest version they require storage and manipulation of four pointers per node, whereas only two or three pointers per node are needed in other structures, such as the binary heap, binomial heap, pairing heap, Brodal queue and rank-pairing heap.Although the total running time of a sequence of operations starting with an empty structure is bounded by the bounds given above, some (very few) operations in the sequence can take very long to complete (in particular delete and delete minimum have linear running time in the worst case). For this reason Fibonacci heaps and other amortized data structures may not be appropriate for real-time systems. It is possible to create a data structure which has the same worst-case performance as the Fibonacci heap has amortized performance. One such structure, the Brodal queue, is, in the words of the creator, ""quite complicated"" and ""[not] applicable in practice."" Created in 2012, the strict Fibonacci heap is a simpler (compared to Brodal's) structure with the same worst-case bounds. Despite having simpler structure, experiments show that in practice the strict Fibonacci heap performs slower than more complicated Brodal queue and also slower than basic Fibonacci heap. The run-relaxed heaps of Driscoll et al. give good worst-case performance for all Fibonacci heap operations except merge.

Summary of running times
Here are time complexities of various heap data structures. Function names assume a min-heap.  For the meaning of ""O(f)"" and ""Θ(f)"" see Big O notation.

Practical considerations
Fibonacci heaps have a reputation for being slow in practice due to large memory consumption per node and high constant factors on all operations.  Recent experimental results suggest that Fibonacci heaps are more efficient in practice than most of its later derivatives, including quake heaps, violation heaps, strict Fibonacci heaps, rank pairing heaps, but less efficient than either pairing heaps or array-based heaps.

References
External links
Java applet simulation of a Fibonacci heap
MATLAB implementation of Fibonacci heap
De-recursived and memory efficient C implementation of Fibonacci heap (free/libre software, CeCILL-B license)
Ruby implementation of the Fibonacci heap (with tests)
Pseudocode of the Fibonacci heap algorithm",254142,https://en.wikipedia.org/wiki/Fibonacci_heap
Finger tree,"In computer science, a finger tree is a purely functional data structure that can be used to efficiently implement other functional data structures.  A finger tree gives amortized constant time access to the ""fingers"" (leaves) of the tree, which is where data is stored, and concatenation and splitting logarithmic time in the size of the smaller piece. It also stores in each internal node the result of applying some associative operation to its descendants.  This ""summary"" data stored in the internal nodes can be used to provide the functionality of data structures other than trees.","In computer science, a finger tree is a purely functional data structure that can be used to efficiently implement other functional data structures.  A finger tree gives amortized constant time access to the ""fingers"" (leaves) of the tree, which is where data is stored, and concatenation and splitting logarithmic time in the size of the smaller piece. It also stores in each internal node the result of applying some associative operation to its descendants.  This ""summary"" data stored in the internal nodes can be used to provide the functionality of data structures other than trees.

Overview
Ralf Hinze and Ross Paterson state a finger tree is a functional representation of persistent sequences that can access the ends in amortized constant time. Concatenation and splitting can be done in logarithmic time in the size of the smaller piece. The structure can also be made into a general purpose data structure by defining the split operation in a general form, allowing it to act as a sequence, priority queue, search tree, or priority search queue, among other varieties of abstract data types.A finger is a point where one can access part of a data structure; in imperative languages, this is called a pointer. In a finger tree, the fingers are structures that point to the ends of a sequence, or the leaf nodes. The fingers are added on to the original tree to allow for constant time access to fingers. In the images shown below, the fingers are the lines reaching out of the spine to the nodes.
A finger tree is composed of different layers which can be identified by the nodes along its spine. The spine of a tree can be thought of as the trunk in the same way trees have leaves and a root. Though finger trees are often shown with the spine and branches coming off the sides, there are actually two nodes on the spine at each level that have been paired to make this central spine. The prefix is on the left of the spine, while the suffix is on the right. Each of those nodes has a link to the next level of the spine until they reach the root.
The first level of the tree contains only values, the leaf nodes of the tree, and is of depth 0. The second level is of depth 1. The third is of depth 2 and so on. The closer to the root, the deeper the subtrees of the original tree (the tree before it was a finger tree) the nodes points to. In this way, working down the tree is going from the leaves to the root of the tree, which is the opposite of the typical tree data structure. To get this nice and unusual structure, we have to make sure the original tree has a uniform depth. To ensure that the depth is uniform, when declaring the node object, it must be parameterized by the type of the child. The nodes on the spine of depth 1 and above point to trees, and with this parameterization they can be represented by the nested nodes.

Transforming a tree into a finger tree
We will start this process with a balanced 2–3 tree. For the finger tree to work, all the leaf nodes need to also be level.
A finger is ""a structure providing efficient access to nodes of a tree near a distinguished location."" To make a finger tree we need to put fingers to the right and left ends of the tree and transform it like a zipper. This gives us that constant amortized time access to the ends of a sequence.
To transform, start with the balanced 2–3 tree.
Take the leftmost and rightmost internal nodes of the tree and pull them up so the rest of the tree dangles between them as shown in the image to the right. 
Combines the spines to make a standard 2–3 finger tree.
This can be described as:

The digits in the examples shown are the nodes with letters. Each list is divided by the prefix or suffix of each node on the spine. In a transformed 2–3 tree it seems that the digit lists at the top level can have a length of two or three with the lower levels only having length of one or two. In order for some application of finger trees to run so efficiently, finger trees allow between one and four subtrees on each level.

The digits of the finger tree can be transformed into a list like so:And so on the image, the top level has elements of type a, the next has elements of type Node a because the node in between the spine and leaves, and this would go on meaning in general that the nth level of the tree has elements of type Noden{\displaystyle Node^{n}} a, or 2–3 trees of depth n. This means a sequence of n elements is represented by a tree of depth Θ(log n). Even better, an element d places from the nearest end is stored at a depth of Θ(log d) in the tree.

Reductions
instance Reduce Node wherereducer (≺) (Node2 a b) z= a ≺(b ≺ z)reducer (≺) (Node3 a b c) z= a ≺( b≺(c ≺ z))reducel (≻) z (Node2 b a) = (z ≻ b) ≻ areducel (≻) z (Node3 c b a) = ((z ≻ c)≻ b)≻ a{\displaystyle {\begin{aligned}\mathrm {instance} &\ Reduce\ Node\ \mathrm {where} &&\\&reducer\ (\prec )\ (Node2\ a\ b)\ z&=&\ a\ \prec (b\ \prec \ z)\\&reducer\ (\prec )\ (Node3\ a\ b\ c)\ z&=&\ a\ \prec (\ b\prec (c\ \prec \ z))\\\\&reducel\ (\succ )\ z\ (Node2\ b\ a)\ &=&\ (z\ \succ \ b)\ \succ \ a\\&reducel\ (\succ )\ z\ (Node3\ c\ b\ a)\ &=&\ ((z\ \succ \ c)\succ \ b)\succ \ a\\\end{aligned}}}
instance Reduce FingerTree wherereducer (≺) (Empty) z = zreducer (≺) (Single x) z= x ≺ zreducer (≺) (Deep pr m sf) z= pr ≺′ (m ≺″ (sf ≺′ z))    where        (≺′) =reducer (≺)        (≺″) =reducer (reducer (≺))reducel (≻) z (Empty) = zreducel (≻) z (Single  x) = z ≻ xreducel (≻) z (Deep  pr m sf) = ((z ≻′ pr) ≻″ m) ≻′ sf)    where        (≻′) =reducel (≻)        (≻″) =reducel (reducel (≻)){\displaystyle {\begin{aligned}\mathrm {instance} &\ Reduce\ FingerTree\ \mathrm {where} &&\\&reducer\ (\prec )\ (Empty)\ z\ &=&\ z\\&reducer\ (\prec )\ (Single\ x)\ z&=&\ x\ \prec \ z\\&reducer\ (\prec )\ (Deep\ pr\ m\ sf)\ z&=&\ pr\ \prec '\ (m\ \prec ''\ (sf\ \prec '\ z))\\&\ \ \ \ where\\&\ \ \ \ \ \ \ \ (\prec ')\ =reducer\ (\prec )\\&\ \ \ \ \ \ \ \ (\prec '')\ =reducer\ (reducer\ (\prec ))\\\\&reducel\ (\succ )\ z\ (Empty)\ &=&\ z\\&reducel\ (\succ )\ z\ (Single\ \ x)\ &=&\ z\ \succ \ x\\&reducel\ (\succ )\ z\ (Deep\ \ pr\ m\ sf)\ &=&\ ((z\ \succ '\ pr)\ \succ ''\ m)\ \succ '\ sf)\\&\ \ \ \ where\\&\ \ \ \ \ \ \ \ (\succ ')\ =reducel\ (\succ )\\&\ \ \ \ \ \ \ \ (\succ '')\ =reducel\ (reducel\ (\succ ))\\\end{aligned}}}

Deque operations
Finger trees also make efficient deques. Whether the structure is persistent or not, all operations take Θ(1) amortized time. The analysis can be compared to Okasaki's implicit deques, the only difference being that the FingerTree type stores Nodes instead of pairs.

Application
Finger trees can be used to build other trees. For example, a priority queue can be implemented by labeling the internal nodes by the minimum priority of its children in the tree, or an indexed list/array can be implemented with a labeling of nodes by the count of the leaves in their children. Other applications are random-access sequences, described below, ordered sequences, and interval trees.Finger trees can provide amortized O(1) pushing, reversing, popping, O(log n) append and split; and can be adapted to be indexed or ordered sequences. And like all functional data structures, it is inherently persistent; that is, older versions of the tree are always preserved.

Random-access sequences
Finger trees can efficiently implement random-access sequences. This should support fast positional operations including accessing the nth element and splitting a sequence at a certain position. To do this, we annotate the finger tree with sizes.The N is for natural numbers. The new type is needed because the type is the carrier of different monoids. Another new type is still needed for the elements in the sequence, shown below. 
These lines of code show that instance works a base case for measuring the sizes and the elements are of size one. The use of newtypes doesn't cause a run-time penalty in Haskell because in a library, the Size and Elem types would be hidden from the user with wrapper functions.
With these changes, the length of a sequence can now be computed in constant time.

First publication
Finger trees were first published in 1977 by Leonidas J. Guibas, and periodically refined since (e.g. a version using AVL trees, non-lazy finger trees, simpler 2–3 finger trees shown here, B-Trees and so on)

Implementations
Finger trees have since been used in the Haskell core libraries (in the implementation of Data.Sequence), and an implementation in OCaml exists which was derived from a proven-correct Coq implementation. There is also a verified implementation in Isabelle (proof assistant) from which programs in Haskell and other (functional) languages can be generated. Finger trees can be implemented with or without lazy evaluation, but laziness allows for simpler implementations.

See also
Monoid
Finger search tree
Zippers

References
External links
http://www.soi.city.ac.uk/~ross/papers/FingerTree.html
http://hackage.haskell.org/packages/archive/EdisonCore/1.2.1.1/doc/html/Data-Edison-Concrete-FingerTree.html
Example of 2–3 trees in C#
Example of Hinze/Paterson Finger Trees in Java
Example of Hinze/Paterson Finger Trees in C#
Monoids and Finger Trees in Haskell
Finger tree library for Clojure
Finger tree in Scalaz",15262012,https://en.wikipedia.org/wiki/Finger_tree
Link/cut tree,"A link/cut tree is a data structure for representing a forest, a set of rooted trees, and offers the following operations:

Add a tree consisting of a single node to the forest.
Given a node in one of the trees, disconnect it (and its subtree) from the tree of which it is part.
Attach a node to another node as its child.
Given a node, find the root of the tree to which it belongs. By doing this operation on two distinct nodes, one can check whether they belong to the same tree.The represented forest may consist of very deep trees, so if we represent the forest as a plain collection of parent pointer trees, it might take us a long time to find the root of a given node. However, if we represent each tree in the forest as a link/cut tree, we can find which tree an element belongs to in O(log(n)) amortized time. Moreover, we can quickly adjust the collection of link/cut trees to changes in the represented forest. In particular, we can adjust it to merge (link) and split (cut) in O(log(n)) amortized time.
Link/cut trees divide each tree in the represented forest into vertex-disjoint paths, where each path is represented by an auxiliary data structure (often splay trees, though the original paper predates splay trees and thus uses biased binary search trees). The nodes in the auxiliary data structure are ordered by their depth in the corresponding represented tree. In one variation, Naive Partitioning, the paths are determined by the most recently accessed paths and nodes, similar to Tango Trees. In Partitioning by Size paths are determined by the heaviest child (child with the most children) of the given node. This gives a more complicated structure, but reduces the cost of the operations from amortized O(log n) to worst case O(log n). It has uses in solving a variety of network flow problems and to jive data sets.
In the original publication, Sleator and Tarjan referred to link/cut trees as ""dynamic trees"", or ""dynamic dyno trees"".","A link/cut tree is a data structure for representing a forest, a set of rooted trees, and offers the following operations:

Add a tree consisting of a single node to the forest.
Given a node in one of the trees, disconnect it (and its subtree) from the tree of which it is part.
Attach a node to another node as its child.
Given a node, find the root of the tree to which it belongs. By doing this operation on two distinct nodes, one can check whether they belong to the same tree.The represented forest may consist of very deep trees, so if we represent the forest as a plain collection of parent pointer trees, it might take us a long time to find the root of a given node. However, if we represent each tree in the forest as a link/cut tree, we can find which tree an element belongs to in O(log(n)) amortized time. Moreover, we can quickly adjust the collection of link/cut trees to changes in the represented forest. In particular, we can adjust it to merge (link) and split (cut) in O(log(n)) amortized time.
Link/cut trees divide each tree in the represented forest into vertex-disjoint paths, where each path is represented by an auxiliary data structure (often splay trees, though the original paper predates splay trees and thus uses biased binary search trees). The nodes in the auxiliary data structure are ordered by their depth in the corresponding represented tree. In one variation, Naive Partitioning, the paths are determined by the most recently accessed paths and nodes, similar to Tango Trees. In Partitioning by Size paths are determined by the heaviest child (child with the most children) of the given node. This gives a more complicated structure, but reduces the cost of the operations from amortized O(log n) to worst case O(log n). It has uses in solving a variety of network flow problems and to jive data sets.
In the original publication, Sleator and Tarjan referred to link/cut trees as ""dynamic trees"", or ""dynamic dyno trees"".

Structure
We take a tree where each node has an arbitrary degree of unordered nodes and split it into paths. We call this the represented tree. These paths are represented internally by auxiliary trees (here we will use splay trees), where the nodes from left to right represent the path from root to the last node on the path. Nodes that are connected in the represented tree that are not on the same preferred path (and therefore not in the same auxiliary tree) are connected via a path-parent pointer. This pointer is stored in the root of the auxiliary tree representing the path.

Preferred paths
When an access to a node v is made on the represented tree, the path that is taken becomes the preferred path. The preferred child of a node is the last child that was on the access path, or null if the last access was to v or if no accesses were made to this particular branch of the tree. A preferred edge is the edge that connects the preferred child to v.
In an alternate version, preferred paths are determined by the heaviest child.

Operations
The operations we are interested in are FindRoot(Node v), Cut(Node v), Link(Node v, Node w), and Path(Node v). 
Every operation is implemented using the Access(Node v) subroutine. When we access a vertex v, the preferred path of the represented tree is changed to a path from the root R of the represented tree to the node v. If a node on
the access path previously had a preferred child u, and the path now goes to child w, the old preferred edge
is deleted (changed to a path-parent pointer), and the new path now goes through w.

Access
After performing an access to node v, it will no longer have any preferred children, and will be at the end of the path. Since nodes in the auxiliary tree are keyed by depth, this means that any nodes to the right of v in the auxiliary tree must be disconnected. In a splay tree this is a relatively simple procedure; we splay at v, which brings v to the root of the auxiliary tree. We then disconnect the right subtree of v, which is every node that came below it on the previous preferred path. The root of the disconnected tree will have a path-parent pointer, which we point to v.
We now walk up the represented tree to the root R, breaking and resetting the preferred path where necessary. To do this we follow the path-parent pointer from v (since v is now the root, we have direct access to the path-parent pointer). If the path that v is on already contains the root R (since the nodes are keyed by depth, it would be the left most node in the auxiliary tree), the path-parent pointer will be null, and we are done the access. Otherwise we follow the pointer to some node on another path w. We want to break the old preferred path of w and reconnect it to the path v is on. To do this we splay at w, and disconnect its right subtree, setting its path-parent pointer to w. Since all nodes are keyed by depth, and every node in the path of v is deeper than every node in the path of w (since they are children of w in the represented tree), we simply connect the tree of v as the right child of w. We splay at v again, which, since v is a child of the root w, simply rotates v to root. We repeat this entire process until the path-parent pointer of v is null, at which point it is on the same preferred path as the root of the represented tree R.

FindRoot
FindRoot refers to finding the root of the represented tree that contains the node v. Since the access subroutine puts v on the preferred path, we first execute an access. Now the node v is on the same preferred path, and thus the same auxiliary tree as the root R. Since the auxiliary trees are keyed by depth, the root R will be the leftmost node of the auxiliary tree. So we simply choose the left child of v recursively until we can go no further, and this node is the
root R. The root may be linearly deep (which is worst case for a splay tree), we therefore splay it so that the next access will be quick.

Cut
Here we would like to cut the represented tree at node v. First we access v. This puts all the elements lower than v in the represented tree as the right child of v in the auxiliary tree. All the elements now in the left subtree of v are the nodes higher than v in the represented tree. We therefore disconnect the left child of v (which still maintains an attachment to the original represented tree through its path-parent pointer). Now v is the root of a represented tree. Accessing v breaks the preferred path below v as well, but that subtree maintains its connection to v through its path-parent pointer.

Link
If v is a tree root and w is a vertex in another tree, link the trees
containing v and w by adding the edge(v, w), making w the parent of v.
To do this we access both v and w in their respective trees, and make w the left
child of v. Since v is the root, and nodes are keyed by depth in the auxiliary tree, accessing v means
that v will have no left child in the auxiliary tree (since as root it is the minimum depth). Adding w as a left
child effectively makes it the parent of v in the represented tree.

Path
For this operation we wish to do some aggregate function over all the nodes (or edges) on the path from root R to node v (such as ""sum"" or ""min"" or ""max"" or ""increase"", etc.). To do this we access v, which gives us an auxiliary tree with all the nodes on the path from root R to node v. The data structure can be augmented with data we wish to retrieve, such as min or max values, or the sum of the costs in the subtree, which can then be returned from a given path in constant time.

Pseudocode of operations
Analysis
Cut and link have O(1) cost, plus that of the access. FindRoot has an O(log n) amortized upper bound, plus the cost of the access. The data structure can be augmented with additional information (such as the min or max valued node in its subtrees, or the sum), depending on the implementation. Thus Path can return this information in constant time plus the access bound.
So it remains to bound the access to find our running time.
Access makes use of splaying, which we know has an O(log n) amortized upper bound. So the remaining analysis deals with the number of times we need to splay.  This is equal to the number of preferred child changes (the number of edges changed in the preferred path) as we traverse up the tree.
We bound access by using a technique called Heavy-Light Decomposition.

Heavy-light decomposition
This technique calls an edge heavy or light depending on the number of nodes in the subtree. Size(v){\displaystyle Size(v)} represents the number of nodes in the subtree of v in the represented tree. An edge is called heavy if size(v) > 1⁄2 size(parent(v)).  Thus we can see that each node can have at most 1 heavy edge. An edge that is not a heavy edge is referred to as a light edge.
The light-depth refers to the number of light edges on a given path from root to vertex v. Light-depth ≤ lg n because each time we traverse a light-edge we decrease the number of nodes by at least a factor of 2 (since it can have at most half the nodes of the parent).
So a given edge in the represented tree can be any of four possibilities: heavy-preferred, heavy-unpreferred, light-preferred or light-unpreferred.
First we prove an O(log2⁡n){\displaystyle O(\log ^{2}n)} upper bound.

O(log 2 n) upper bound
The splay operation of the access gives us log n, so we need to bound the number of accesses to log n to prove the O(log 2 n) upper bound.
Every change of preferred edge results in a new preferred edge being formed. So we count the number of preferred edges formed. Since there are at most log n edges that are light on any given path, there are at most log n light edges changing to preferred.
The number of heavy edges becoming preferred can be O(n){\displaystyle O(n)} for any given operation, but it is O(log⁡n){\displaystyle O(\log n)} amortized. Over a series of executions we can have n-1 heavy edges become preferred (as there are at most n-1 heavy edges total in the represented tree), but from then on the number of heavy edges that become preferred is equal to the number of heavy edges that became unpreferred on a previous step. For every heavy edge that becomes unpreferred a light edge must become preferred. We have seen already that the number of light edges that can become preferred is at most log n. So the number of heavy edges that become preferred for m operations is m(log⁡n)+(n−1){\displaystyle m(\log n)+(n-1)}. Over enough operations (m>n−1{\displaystyle m>n-1}) this averages to O(log⁡n){\displaystyle O(\log n)}.

Improving to O(log n) upper bound
We have bound the number of preferred child changes at O(log⁡n){\displaystyle O(\log n)}, so if we can show that each preferred child change has cost O(1) amortized we can bound the access operation at O(log⁡n){\displaystyle O(\log n)}. This is done using the potential method.
Let s(v) be the number of nodes under v in the tree of auxiliary trees. Then the potential function Φ=∑vlog⁡s(v){\displaystyle \Phi =\sum _{v}\log {s(v)}}. We know that the amortized cost of splaying is bounded by:

cost(splay(v))≤3(log⁡s(root(v))−log⁡s(v))+1{\displaystyle cost(splay(v))\leq 3\left(\log {s(root(v))}-\log {s(v)}\right)+1}We know that after splaying, v is the child of its path-parent node w. So we know that:

s(v)≤s(w){\displaystyle s(v)\leq s(w)}We use this inequality and the amortized cost of access to achieve a telescoping sum that is bounded by:

3(log⁡s(R)−log⁡s(v))+O(number of preferred child changes){\displaystyle 3\left(\log {s(R)}-\log {s(v)}\right)+O({\text{number of preferred child changes}})}where R is the root of the represented tree, and we know the number of preferred child changes is O(log⁡n){\displaystyle O(\log n)}. s(R) = n, so we have O(log⁡n){\displaystyle O(\log n)} amortized.

Application
Link/cut trees can be used to solve the dynamic connectivity problem for acyclic graphs. Given two nodes x and y, they are connected if and only if FindRoot(x) = FindRoot(y). Another data structure that can be used for the same purpose is Euler tour tree.
In solving the maximum flow problem, link/cut trees can be used to improve the running time of Dinic's algorithm from O(V2E){\displaystyle O(V^{2}E)} to O(VElog⁡V){\displaystyle O(VE\log V)}.

See also
Splay tree
Potential method
Top tree


== Further reading ==",9328337,https://en.wikipedia.org/wiki/Link/cut_tree
List-labeling problem,"In computer science, the list-labeling problem involves maintaining a totally ordered set S supporting the following operations:

insert(X), which inserts X into set S;
delete(X), which removes X from set S;
label(X), which returns a label assigned to X subject to:
label(X) ∈{0,1,…,m−1}{\displaystyle \in \{0,1,\ldots ,m-1\}}
∀{\displaystyle \forall } X,Y ∈{\displaystyle \in } S, X < Y implies label(X) < label(Y)The cost of a  list labeling algorithm is the number of label (re-)assignments per insertion or deletion.  List labeling algorithms have applications in many areas, including the order-maintenance problem, cache-oblivious data structures, data structure persistence, graph algorithms and fault-tolerant data structures.Sometimes the list labeling problem is presented where S is not a set of values but rather a set of objects subject to a total order.  In this setting, when an item is inserted into S, it is specified to be the successor of some other item already in S.  For example, this is the way that list labeling is used in the order-maintenance problem.  The solutions presented below apply to both formulations.","In computer science, the list-labeling problem involves maintaining a totally ordered set S supporting the following operations:

insert(X), which inserts X into set S;
delete(X), which removes X from set S;
label(X), which returns a label assigned to X subject to:
label(X) ∈{0,1,…,m−1}{\displaystyle \in \{0,1,\ldots ,m-1\}}
∀{\displaystyle \forall } X,Y ∈{\displaystyle \in } S, X < Y implies label(X) < label(Y)The cost of a  list labeling algorithm is the number of label (re-)assignments per insertion or deletion.  List labeling algorithms have applications in many areas, including the order-maintenance problem, cache-oblivious data structures, data structure persistence, graph algorithms and fault-tolerant data structures.Sometimes the list labeling problem is presented where S is not a set of values but rather a set of objects subject to a total order.  In this setting, when an item is inserted into S, it is specified to be the successor of some other item already in S.  For example, this is the way that list labeling is used in the order-maintenance problem.  The solutions presented below apply to both formulations.

Upper bounds
The cost of list labeling is related to m{\displaystyle m}, the range of the labels assigned.  Suppose that no more than n{\displaystyle n} items are stored in the list-labeling structure at any time.  Four cases have been studied:

m=2Ω(n){\displaystyle m=2^{\Omega (n)}}
m=nΩ(1){\displaystyle m=n^{\Omega (1)}}
m=O(n){\displaystyle m=O(n)}
m=(1+ε)n{\displaystyle m=(1+\varepsilon )n}

Exponential Labels
In the exponential label case, each item that is inserted can be given a label that is the average of its neighboring labels.  It takes Ω(n){\displaystyle \Omega (n)} insertions before two items are at adjacent labels and there are no labels available for items in between them.  When this happens, all items are relabelled evenly from the space of all labels.  This incurs O(n){\displaystyle O(n)} relabeling cost.  Thus, the amortized relabeling cost in this case is O(1){\displaystyle O(1)}.

Polynomial Labels
The other cases of list labeling can be solved via balanced binary search trees.  Consider T{\displaystyle T}, a binary search tree on S of height h{\displaystyle h}.  We can label every node in the tree via a path label as follows:  
Let σ(X){\displaystyle \sigma (X)} be the sequence of left and right edges on the root-to-X{\displaystyle X} path, encoded as bits.  So if X{\displaystyle X} is in the left subtree of the root, the high-order bit of σ(X){\displaystyle \sigma (X)} is 0{\displaystyle 0}, and if it is in the right subtree of the root, the high-order bit of σ(X){\displaystyle \sigma (X)} is 1{\displaystyle 1}.  Once we reach X{\displaystyle X}, we complete σ(X){\displaystyle \sigma (X)} to a length of h+1{\displaystyle h+1} as follows.  If X{\displaystyle X} is a leaf, we append 0{\displaystyle 0}s as the low order bits until σ(X){\displaystyle \sigma (X)} has h+1{\displaystyle h+1} bits.  If 
X{\displaystyle X} is an internal node, we append one 0{\displaystyle 0} and then 1{\displaystyle 1}s as the low order bits until σ(X){\displaystyle \sigma (X)} has h+1{\displaystyle h+1} bits.
The important properties of σ(){\displaystyle \sigma ()} are that: these labels are in the range {0,1,…,2h+1−1}{\displaystyle \{0,1,\ldots ,2^{h+1}-1\}}; and for two nodes with keys X{\displaystyle X} and Y{\displaystyle Y} in T,{\displaystyle T,} if X<Y,{\displaystyle X<Y,} then σ(X)<σ(Y){\displaystyle \sigma (X)<\sigma (Y)}.  To see this latter property, notice that the property is true if the least common ancestor of X{\displaystyle X} and Y{\displaystyle Y} is neither X{\displaystyle X} nor Y{\displaystyle Y}, because σ(X){\displaystyle \sigma (X)} and  σ(Y){\displaystyle \sigma (Y)} will share bits until their least common ancestor.  If  X<Y{\displaystyle X<Y}, then because T{\displaystyle T} is a search tree, X{\displaystyle X} will be in the left subtree and will 
have a next bit of 0{\displaystyle 0}, whereas Y{\displaystyle Y} will be in the right subtree and will have a next bit of 1{\displaystyle 1}.
Suppose instead that, without loss of generality, the least common ancestor of X{\displaystyle X} and Y{\displaystyle Y} is X{\displaystyle X}, and that X{\displaystyle X} has depth d{\displaystyle d}.  If Y{\displaystyle Y} is in the left subtree of X{\displaystyle X}, then σ(X){\displaystyle \sigma (X)} and σ(Y){\displaystyle \sigma (Y)} share the first d+1{\displaystyle d+1} bits.  The remaining bits of σ(X){\displaystyle \sigma (X)} are all 1s, whereas the remaining bits of σ(Y){\displaystyle \sigma (Y)} must have a 0{\displaystyle 0}, so σ(Y)<σ(X){\displaystyle \sigma (Y)<\sigma (X)}.    If instead Y{\displaystyle Y} is in the right subtree of X{\displaystyle X}, then 
σ(X){\displaystyle \sigma (X)} and σ(Y){\displaystyle \sigma (Y)} share the first d{\displaystyle d} bits and the d+1{\displaystyle d+1}st bit of σ(X){\displaystyle \sigma (X)} is 0{\displaystyle 0}, whereas 
the d+1{\displaystyle d+1}st bit of σ(Y){\displaystyle \sigma (Y)} is 1{\displaystyle 1}.  Hence σ(X)<σ(Y){\displaystyle \sigma (X)<\sigma (Y)}.
We conclude that the σ(){\displaystyle \sigma ()} function fulfills the monotonicity property of the label() function.  Thus if we can balance the binary tree to a depth of (log⁡m)−1{\displaystyle (\log m)-1}, we will have a solution to the list labeling problem for labels in the range {0,…,m−1}{\displaystyle \{0,\ldots ,m-1\}}.

Weight-balanced trees
In order to use a self-balancing binary search tree to solve the list labeling problem, we need to first define the cost function of a balancing operation on insertion or deletion to equal the number of labels that are changed, since every rebalancing operation
of the tree would have to also update all path labels in the subtree rooted at the site of the rebalance.  So, 
for example, rotating a node with a subtree of size
k{\displaystyle k}, which can be done in constant time under usual
circumstances, requires Ω(k){\displaystyle \Omega (k)} path label updates. In
particular, if the node being rotated is the root then the rotation
would take time linear in the size of the whole tree. With that much
time the entire tree could be rebuilt. We will see below that there
are self-balancing binary search tree data structures that cause an
appropriate number of label updates during rebalancing.
A weight-balanced tree BB[α{\displaystyle \alpha }] is defined as follows.  For every X{\displaystyle X} in a root tree T{\displaystyle T}, define size(X){\displaystyle size(X)} to be the number of nodes in the subtree rooted at X{\displaystyle X}.  Let the left and right children of X{\displaystyle X} be X.left{\displaystyle X.left} and X.right{\displaystyle X.right}, respectively.  A tree T{\displaystyle T} is α{\displaystyle \alpha }-weight balanced if for every internal node X{\displaystyle X} in T{\displaystyle T}, size(X.left)≥⌊α⋅size(X.right)⌋{\displaystyle size(X.left)\geq \lfloor \alpha \cdot size(X.right)\rfloor } and size(X.right)≥⌊α⋅size(X.left)⌋.{\displaystyle size(X.right)\geq \lfloor \alpha \cdot size(X.left)\rfloor .}
The height of a BB[α{\displaystyle \alpha }] tree with n{\displaystyle n} nodes is at most log1/(1−α)⁡n=−log⁡(n)/log⁡(1−α).{\displaystyle \log _{1/(1-\alpha )}n=-\log(n)/\log(1-\alpha ).}  Therefore, in order to solve the list-labeling problem, we need α=1−1/(1−n−1/(log⁡(m)−1)){\displaystyle \alpha =1-1/(1-n^{-1/(\log(m)-1)})} to achieve a depth of log⁡(m)−1.{\displaystyle \log(m)-1.}
A scapegoat tree is a weight-balanced tree where whenever a node no longer satisfies the weight-balance condition the entire subtree rooted at that node is rebuilt.  This rebalancing scheme is ideal for list labeling, since the cost of rebalancing now equals the cost of relabeling.    The amortized cost of an insertion or deletion is (1+1/(1−2α))log1/1−α⁡n+O(1).{\displaystyle (1+1/(1-2\alpha ))\log _{1/1-\alpha }n+O(1).}  For the list labeling problem, the cost becomes:

m=nΩ(1){\displaystyle m=n^{\Omega (1)}}: α=O(1){\displaystyle \alpha =O(1)}, the cost of list labeling is amortized O(log⁡n).{\displaystyle O(\log n).} (Folklore, modification of Itai, Konheim and Rodeh.)
m=O(n){\displaystyle m=O(n)}: α=1+Θ(1/log⁡n){\displaystyle \alpha =1+\Theta (1/\log n)}, the cost of list labeling is amortized O(log2⁡n).{\displaystyle O(\log ^{2}n).} This bound was first achieved by Itai, Konheim, and Rodeh and deamortized by Willard.
m=(1+ε)n{\displaystyle m=(1+\varepsilon )n}: If m{\displaystyle m} is a power of two, then we can set α=1+Θ(ε/log⁡n){\displaystyle \alpha =1+\Theta (\varepsilon /\log n)}, and the cost of list labeling is O(ε−1log2⁡n){\displaystyle O(\varepsilon ^{-1}\log ^{2}n)}.  A more careful algorithm can achieve this bound even in the case where m{\displaystyle m} is not a power of two.

Lower bounds and open problems
In the case where m=n1+Θ(1){\displaystyle m=n^{1+\Theta (1)}}, a lower bound of Ω(log⁡n){\displaystyle \Omega (\log n)} has been established for list labeling.  This lower bound applies to randomized algorithms, and so the known bounds for this case are tight.
In the case where m=(1+Θ(1))n{\displaystyle m={(1+\Theta (1))}n}, there is a lower bound of Ω(log2⁡n){\displaystyle \Omega (\log ^{2}n)} list labeling cost for deterministic algorithms.  Furthermore, the same lower bound holds for smooth algorithms, which are those whose only relabeling operation assigns labels evenly in a range of items  This lower bound is surprisingly strong in that it applies in the offline cases where all insertions and deletions are known ahead of time.
However, the best lower bound known for the linear case of algorithms that are allowed to be non-smooth and randomized is Ω(log⁡n){\displaystyle \Omega (\log n)}.  Indeed, it has been an open problem since 1981 to close the gap between the O(log2⁡n){\displaystyle O(\log ^{2}n)} upper bound and the Ω(log⁡n){\displaystyle \Omega (\log n)} in the linear case. Some progress on this problem has been made by Bender et al. who give a randomized upper bound of O(log1.5⁡n){\displaystyle O(\log ^{1.5}n)}.

Applications
The best known applications of list labeling are the order-maintenance problem and packed-memory arrays for cache-oblivious data structures.  The order-maintenance problem is that of maintaining a data structure on a linked list to answer order queries: given two items in the linked list, which is closer to the front of the list?  This problem can be solved directly by polynomial list labeling in O(log⁡n){\displaystyle O(\log n)} per insertion and deletion and O(1){\displaystyle O(1)} time per query, by assigning labels that are monotone with the rank in the list.  The time for insertions and deletions can be improved to constant time by combining exponential polynomial list labeling with exponential list labeling on small lists.
The packed-memory array is an array of size (1+ε)n{\displaystyle (1+\varepsilon )n} to hold n{\displaystyle n} items so that any subarray of size k{\displaystyle k} holds Θ(k){\displaystyle \Theta (k)} items.  This can be solved directly by the m=(1+ε)n{\displaystyle m=(1+\varepsilon )n} case of list labeling, by using the labels as addresses in the array, as long as the solution guarantees that the space between items is O(1){\displaystyle O(1)}.  Packed-memory arrays are used in cache-oblivious data structures to store data that must be indexed and scanned.  The density bounds guarantee that a scan through the data is asymptotically optimal in the external-memory model for any block transfer size.


== References ==",56041424,https://en.wikipedia.org/wiki/List-labeling_problem
Order-maintenance problem,"In computer science, the order-maintenance problem involves maintaining a totally ordered set supporting the following operations:

insert(X, Y), which inserts X immediately after Y in the total order;
order(X, Y), which determines if X precedes Y in the total order; and
delete(X), which removes X from the set.Paul Dietz first introduced a data structure to solve this problem in
1982. This data
structure supports insert(X, Y) in O(log⁡n){\displaystyle O(\log n)} (in Big O notation)
amortized time and order(X, Y) in constant time but does
not support deletion. Athanasios Tsakalidis used BB[α] trees with the same performance bounds that supports
deletion in O(log⁡n){\displaystyle O(\log n)} and improved insertion and deletion performance to
O(1){\displaystyle O(1)} amortized time with indirection. Dietz and Daniel Sleator published an improvement to worst-case constant time in 1987. Michael Bender, Richard Cole and Jack Zito published significantly simplified alternatives in 2002. Bender, Fineman, Gilbert, Kopelowitz and Montes also published a deamortized solution in 2017.Efficient data structures for order-maintenance have applications in
many areas, including data structure persistence, graph algorithms and fault-tolerant data structures.","In computer science, the order-maintenance problem involves maintaining a totally ordered set supporting the following operations:

insert(X, Y), which inserts X immediately after Y in the total order;
order(X, Y), which determines if X precedes Y in the total order; and
delete(X), which removes X from the set.Paul Dietz first introduced a data structure to solve this problem in
1982. This data
structure supports insert(X, Y) in O(log⁡n){\displaystyle O(\log n)} (in Big O notation)
amortized time and order(X, Y) in constant time but does
not support deletion. Athanasios Tsakalidis used BB[α] trees with the same performance bounds that supports
deletion in O(log⁡n){\displaystyle O(\log n)} and improved insertion and deletion performance to
O(1){\displaystyle O(1)} amortized time with indirection. Dietz and Daniel Sleator published an improvement to worst-case constant time in 1987. Michael Bender, Richard Cole and Jack Zito published significantly simplified alternatives in 2002. Bender, Fineman, Gilbert, Kopelowitz and Montes also published a deamortized solution in 2017.Efficient data structures for order-maintenance have applications in
many areas, including data structure persistence, graph algorithms and fault-tolerant data structures.

List labeling
A problem related to the order-maintenance problem is the
list-labeling problem in which instead of the order(X,
Y) operation the solution must maintain an assignment of labels
from a universe of integers {1,2,…,m}{\displaystyle \{1,2,\ldots ,m\}} to the
elements of the set such that X precedes Y in the total order if and
only if X is assigned a lesser label than Y. It must also support an
operation label(X) returning the label of any node X.
Note that order(X, Y) can be implemented simply by
comparing label(X) and label(Y) so that any
solution to the list-labeling problem immediately gives one to the
order-maintenance problem. In fact, most solutions to the
order-maintenance problem are solutions to the list-labeling problem
augmented with a level of data structure indirection to improve
performance. We will see an example of this below.
For a list-labeling problem on sets of size up to n{\displaystyle n}, the cost of list labeling depends on how large m{\displaystyle m} is a function of n{\displaystyle n}.  The relevant parameter range for order maintenance are for m=n1+Θ(1){\displaystyle m=n^{1+\Theta (1)}}, for which an O(log⁡n){\displaystyle O(\log n)} amortized cost solution is known, and 2Ω(n){\displaystyle 2^{\Omega (n)}} for which a constant time amortized solution is known

O(1) amortized insertion via indirection
Indirection is a technique used in data structures in which a problem
is split into multiple levels of a data structure in order to improve
efficiency. Typically, a problem of size n{\displaystyle n} is split into
n/log⁡n{\displaystyle n/\log n} problems of size log⁡n{\displaystyle \log n}. For
example, this technique is used in y-fast tries. This
strategy also works to improve the insertion and deletion performance
of the data structure described above to constant amortized time. In
fact, this strategy works for any solution of the list-labeling
problem with O(log⁡n){\displaystyle O(\log n)} amortized insertion and deletion
time.

The new data structure is completely rebuilt whenever it grows too
large or too small. Let N{\displaystyle N} be the number of elements of
the total order when it was last rebuilt. The data structure is
rebuilt whenever the invariant N3≤n≤2N{\displaystyle {\tfrac {N}{3}}\leq n\leq 2N} is
violated by an insertion or deletion. Since rebuilding can be done in
linear time this does not affect the amortized performance of
insertions and deletions.
During the rebuilding operation, the N{\displaystyle N} elements of the
total order are split into O(N/log⁡N){\displaystyle O(N/\log N)} contiguous
sublists, each of size Ω(log⁡N){\displaystyle \Omega (\log N)}. The list labeling problem is solved on the set 
set of nodes representing each of
the sublists in their original list order. The labels for this subproblem are taken to be polynomial --- say m=N2{\displaystyle m=N^{2}}, so that they can be compared in constant time and updated in amortized O(log⁡N){\displaystyle O(\log N)} time.  
For each sublist a
doubly-linked list of its elements is built storing with each element a
pointer to its representative in the tree as well as a local integer
label. The local integer labels are also taken from a range m=N2{\displaystyle m=N^{2}}, so that the can be compared in constant time, but because each local problem involves only Θ(log⁡N){\displaystyle \Theta (\log N)} items, the labels range m{\displaystyle m} is exponential in the number of items being labeled.  Thus, they can be updated in O(1){\displaystyle O(1)} amortized time.
See the list-labeling problem for details of both solutions.

Order
Given the sublist nodes X and Y, order(X, Y) can be
answered by first checking if the two nodes are in the same
sublist. If so, their order can be determined by comparing their local
labels. Otherwise the labels of their representatives in the first list-labeling problem are compared.  
These comparisons take constant time.

Insert
Given a new sublist node for X and a pointer to the sublist node Y,
insert(X, Y) inserts X immediately after Y in the sublist
of Y, if there is room for X in the list, that is if the length of the list is no greater than 2log⁡N{\displaystyle 2\log N} after the insertion.  It's local label is given by the local list labeling algorithm for exponential labels.   This case takes O(1){\displaystyle O(1)} amortized time.
If the local list overflows, it is split evenly into two lists of size log⁡N{\displaystyle \log N}, and the items in each list are given new labels from their (independent) ranges.  This creates a new sublist, which is inserted into the list of sublists, and the new sublist node is given a label in the list of sublists by the list-labeling algorithm.  Finally X is inserted into the appropriate list. 
This sequence of operations take O(log⁡N){\displaystyle O(\log N)} time, but there have been Ω(log⁡N){\displaystyle \Omega (\log N)} insertions since the list was created or last split.  Thus the amortized time per insertion is O(1){\displaystyle O(1)}.

Delete
Given a sublist node X to be deleted, delete(X) simply
removes X from its sublist in constant time. If this leaves the
sublist empty, then we need to remove the representative of the
list of sublists. Since at least Ω(log⁡N){\displaystyle \Omega (\log N)}
elements were deleted from the sublist since it was first built we can afford to spend the O(log⁡N){\displaystyle O(\log N)} time, the amortized cost of a deletion is O(1){\displaystyle O(1)}.

References
External links
Two simplified algorithms for maintaining order in a list. - This paper (Michael A. Bender, Richard Cole, Erik D. Demaine, Martin Farach-Colton, and Jack Zito, 2002) presents a list-labeling data structure with amortized performance that does not explicitly store a tree.  The analysis given is simpler than the one given by (Dietz and Sleator, 1987) for a similar data structure.",39047079,https://en.wikipedia.org/wiki/Order-maintenance_problem
Pairing heap,"A pairing heap is a type of heap data structure with relatively simple implementation and excellent practical amortized performance, introduced by Michael Fredman, Robert Sedgewick, Daniel Sleator, and Robert Tarjan in 1986.
Pairing heaps are heap-ordered multiway tree structures, and can be considered simplified Fibonacci heaps. They are considered a ""robust choice"" for implementing such algorithms as Prim's MST algorithm, and support the following operations (assuming a min-heap):

find-min: simply return the top element of the heap.
meld: compare the two root elements, the smaller remains the root of the result, the larger element and its subtree is appended as a child of this root.
insert: create a new heap for the inserted element and meld into the original heap.
decrease-key (optional): remove the subtree rooted at the key to be decreased, replace the key with a smaller key, then meld the result back into the heap.
delete-min: remove the root and do repeated melds of its subtrees until one tree remains.  Various merging strategies are employed.The analysis of pairing heaps' time complexity was initially inspired by that of splay trees.
The amortized time per delete-min is O(log n), and the operations find-min, meld, and insert run in O(1) time.When a decrease-key operation is added as well, determining the precise asymptotic running time of pairing heaps has turned out to be difficult. Initially, the time complexity of this operation was conjectured on empirical grounds to be O(1), but Fredman proved that the amortized time per decrease-key is at least Ω(log⁡log⁡n){\displaystyle \Omega (\log \log n)} for some sequences of operations.
Using a different amortization argument, Pettie then proved that insert, meld, and decrease-key all run in O(22log⁡log⁡n){\displaystyle O(2^{2{\sqrt {\log \log n}}})} amortized time, which is o(log⁡n){\displaystyle o(\log n)}.
Elmasry later introduced elaborations of pairing heaps (lazy, consolidate) for which decrease-key runs in O(log⁡log⁡n){\displaystyle O(\log \log n)} amortized time and other operations have optimal amortized bounds, but no tight Θ(log⁡log⁡n){\displaystyle \Theta (\log \log n)} bound is known for the original data structure.Although the asymptotic performance of pairing heaps is worse than other priority queue algorithms such as Fibonacci heaps, which perform decrease-key in O(1){\displaystyle O(1)} amortized time, the performance in practice is excellent. Jones
and Larkin, Sen, and Tarjan
conducted experiments on pairing heaps and other heap data structures.  They concluded that d-ary heaps such as binary heaps are faster than all other heap implementations when the decrease-key operation is not needed (and hence there is no need to externally track the location of nodes in the heap), but that when decrease-key is needed pairing heaps are often faster than d-ary heaps and almost always faster than other pointer-based heaps, including data structures like Fibonacci heaps that are theoretically more efficient. Chen et al. examined priority queues specifically for use with Dijkstra's algorithm and concluded that in normal cases using a d-ary heap without decrease-key (instead duplicating nodes on the heap and ignoring redundant instances) resulted in better performance, despite the inferior theoretical performance guarantees.","A pairing heap is a type of heap data structure with relatively simple implementation and excellent practical amortized performance, introduced by Michael Fredman, Robert Sedgewick, Daniel Sleator, and Robert Tarjan in 1986.
Pairing heaps are heap-ordered multiway tree structures, and can be considered simplified Fibonacci heaps. They are considered a ""robust choice"" for implementing such algorithms as Prim's MST algorithm, and support the following operations (assuming a min-heap):

find-min: simply return the top element of the heap.
meld: compare the two root elements, the smaller remains the root of the result, the larger element and its subtree is appended as a child of this root.
insert: create a new heap for the inserted element and meld into the original heap.
decrease-key (optional): remove the subtree rooted at the key to be decreased, replace the key with a smaller key, then meld the result back into the heap.
delete-min: remove the root and do repeated melds of its subtrees until one tree remains.  Various merging strategies are employed.The analysis of pairing heaps' time complexity was initially inspired by that of splay trees.
The amortized time per delete-min is O(log n), and the operations find-min, meld, and insert run in O(1) time.When a decrease-key operation is added as well, determining the precise asymptotic running time of pairing heaps has turned out to be difficult. Initially, the time complexity of this operation was conjectured on empirical grounds to be O(1), but Fredman proved that the amortized time per decrease-key is at least Ω(log⁡log⁡n){\displaystyle \Omega (\log \log n)} for some sequences of operations.
Using a different amortization argument, Pettie then proved that insert, meld, and decrease-key all run in O(22log⁡log⁡n){\displaystyle O(2^{2{\sqrt {\log \log n}}})} amortized time, which is o(log⁡n){\displaystyle o(\log n)}.
Elmasry later introduced elaborations of pairing heaps (lazy, consolidate) for which decrease-key runs in O(log⁡log⁡n){\displaystyle O(\log \log n)} amortized time and other operations have optimal amortized bounds, but no tight Θ(log⁡log⁡n){\displaystyle \Theta (\log \log n)} bound is known for the original data structure.Although the asymptotic performance of pairing heaps is worse than other priority queue algorithms such as Fibonacci heaps, which perform decrease-key in O(1){\displaystyle O(1)} amortized time, the performance in practice is excellent. Jones
and Larkin, Sen, and Tarjan
conducted experiments on pairing heaps and other heap data structures.  They concluded that d-ary heaps such as binary heaps are faster than all other heap implementations when the decrease-key operation is not needed (and hence there is no need to externally track the location of nodes in the heap), but that when decrease-key is needed pairing heaps are often faster than d-ary heaps and almost always faster than other pointer-based heaps, including data structures like Fibonacci heaps that are theoretically more efficient. Chen et al. examined priority queues specifically for use with Dijkstra's algorithm and concluded that in normal cases using a d-ary heap without decrease-key (instead duplicating nodes on the heap and ignoring redundant instances) resulted in better performance, despite the inferior theoretical performance guarantees.

Structure
A pairing heap is either an empty heap, or a pairing tree consisting of a root element and a possibly empty list of pairing trees. The heap ordering property requires that parent of any node is no greater than the node itself. The following description assumes a purely functional heap that does not support the decrease-key operation.

type PairingTree[Elem] = Heap(elem: Elem, subheaps: List[PairingTree[Elem]])
type PairingHeap[Elem] = Empty | PairingTree[Elem]

A pointer-based implementation for RAM machines, supporting decrease-key, can be achieved using three pointers per node, by representing the children of a node by a doubly-linked list: a pointer to the node's first child, one to its next sibling, and one to its previous sibling (or, for the leftmost sibling, to its parent). It can also be viewed as a variant of a Left-child right-sibling binary tree with an additional pointer to a node's parent (which represents its previous sibling or actual parent for the leftmost sibling). Alternatively, the previous-pointer can be omitted by letting the last child point back to the parent, if a single boolean flag is added to indicate ""end of list"". This achieves a more compact structure at the expense of a constant overhead factor per operation.

Operations
find-min
The function find-min simply returns the root element of the heap:

function find-min(heap: PairingHeap[Elem]) -> Elem
    if heap is Empty
        error
    else
        return heap.elem

meld
Melding with an empty heap returns the other heap, otherwise a new heap is returned that has the minimum of the two root elements as its root element and just adds the heap with the larger root to the list of subheaps:

function meld(heap1, heap2: PairingHeap[Elem]) -> PairingHeap[Elem]
    if heap1 is Empty
        return heap2
    elsif heap2 is Empty
        return heap1
    elsif heap1.elem < heap2.elem
        return Heap(heap1.elem, heap2 :: heap1.subheaps)
    else
        return Heap(heap2.elem, heap1 :: heap2.subheaps)

insert
The easiest way to insert an element into a heap is to meld the heap with a new heap containing just this element and an empty list of subheaps:

function insert(elem: Elem, heap: PairingHeap[Elem]) -> PairingHeap[Elem]
    return meld(Heap(elem, []), heap)

delete-min
The only non-trivial fundamental operation is the deletion of the minimum element from the heap. This requires performing repeated melds of its children until only one tree remains.    The standard strategy first melds the subheaps in pairs (this is the step that gave this data structure its name) from left to right and then melds the resulting list of heaps from right to left:

function delete-min(heap: PairingHeap[Elem]) -> PairingHeap[Elem]
    if heap is Empty
        error
    else
        return merge-pairs(heap.subheaps)

This uses the auxiliary function merge-pairs:

function merge-pairs(list: List[PairingTree[Elem]]) -> PairingHeap[Elem]
    if length(list) == 0
        return Empty
    elsif length(list) == 1
        return list[0]
    else
        return meld(meld(list[0], list[1]), merge-pairs(list[2..]))

That this does indeed implement the described two-pass left-to-right then right-to-left merging strategy can be seen from this reduction:

   merge-pairs([H1, H2, H3, H4, H5, H6, H7])
=> meld(meld(H1, H2), merge-pairs([H3, H4, H5, H6, H7]))
     # meld H1 and H2 to H12, then the rest of the list
=> meld(H12, meld(meld(H3, H4), merge-pairs([H5, H6, H7])))
     # meld H3 and H4 to H34, then the rest of the list
=> meld(H12, meld(H34, meld(meld(H5, H6), merge-pairs([H7]))))
     # meld H5 and H6 to H56, then the rest of the list
=> meld(H12, meld(H34, meld(H56, H7)))
     # switch direction, meld the last two resulting heaps, giving H567
=> meld(H12, meld(H34, H567))
     # meld the last two resulting heaps, giving H34567
=> meld(H12, H34567) 
     # finally, meld the first pair with the result of merging the rest
=> H1234567

Summary of running times
Here are time complexities of various heap data structures. Function names assume a min-heap.  For the meaning of ""O(f)"" and ""Θ(f)"" see Big O notation.

References
External links
Louis Wasserman discusses pairing heaps and their implementation in Haskell in The Monad Reader, Issue 16 (pp. 37–52).
pairing heaps, Sartaj Sahni",3402053,https://en.wikipedia.org/wiki/Pairing_heap
Queap,"In computer science, a queap is a priority queue data structure. The data structure allows insertions and deletions of arbitrary elements, as well as retrieval of the highest-priority element. Each deletion takes amortized time logarithmic in the number of items that have been in the structure for a longer time than the removed item. Insertions take constant amortized time.
The data structure consists of a doubly linked list and a 2–4 tree data structure, each modified to keep track of its minimum-priority element. The basic operation of the structure is to keep newly inserted elements in the doubly linked list, until a deletion would remove one of the list items, at which point they are all moved into the 2–4 tree. The 2–4 tree stores its elements in insertion order, rather than the more conventional priority-sorted order.
Both the data structure and its name were devised by John Iacono and Stefan Langerman.","In computer science, a queap is a priority queue data structure. The data structure allows insertions and deletions of arbitrary elements, as well as retrieval of the highest-priority element. Each deletion takes amortized time logarithmic in the number of items that have been in the structure for a longer time than the removed item. Insertions take constant amortized time.
The data structure consists of a doubly linked list and a 2–4 tree data structure, each modified to keep track of its minimum-priority element. The basic operation of the structure is to keep newly inserted elements in the doubly linked list, until a deletion would remove one of the list items, at which point they are all moved into the 2–4 tree. The 2–4 tree stores its elements in insertion order, rather than the more conventional priority-sorted order.
Both the data structure and its name were devised by John Iacono and Stefan Langerman.

Description
A queap is a priority queue that inserts elements in O(1) amortized time, and removes the minimum element in O(log(k + 2)) if there are k items that have been in the heap for a longer time than the element to be extracted. The queap has a property called the queueish property: the time to search for element x is O(lg q(x)) where q(x) is equal to n − 1 − w(x) and w(x) is the number of distinct items that has been accessed by operations such as searching, inserting, or deleting. q(x) is defined as how many elements have not been accessed since x's last access. Indeed, the queueish property is the complement of the splay tree working set property: the time to search for element x is O(lg w(x)).
A queap can be represented by two data structures: a doubly linked list and a modified version of 2–4 tree. The doubly linked list, L, is used for a series of insert and locate-min operations. The queap keeps a pointer to the minimum element stored in the list. To add element x to list l, the element x is added to the end of the list and a bit variable in element x is set to one. This operation is done to determine if the element is either in the list or in a 2–4 tree. 
A 2–4 tree is used when a delete operation occurs. If the item x is already in tree T, the item is removed using the 2–4 tree delete operation. Otherwise, the item x is in list L (done by checking if the bit variable is set). All the elements stored in list L are then added to the 2–4 tree, setting the bit variable of each element to zero. x is then removed from T. 
A queap uses only the 2–4 tree structure properties, not a search tree. The modified 2–4 tree structure is as follows. Suppose list L has the following set of elements: x1,x2,x3,…,xk{\displaystyle x_{1},x_{2},x_{3},\dots ,x_{k}}. When the deletion operation is invoked, the set of elements stored in L is then added to the leaves of the 2–4 tree in that order, proceeded by a dummy leaf containing an infinite key. Each internal node of T has a pointer hv{\displaystyle h_{v}}, which points to the smallest item in subtree v. Each internal node on path P from the root to x0{\displaystyle x_{0}} has a pointer cv{\displaystyle c_{v}}, which points to the smallest key in T−Tv−{r}{\displaystyle T-T_{v}-\{r\}}. The hv{\displaystyle h_{v}} pointers of each internal node on path P are ignored. The queap has a pointer to cx0{\displaystyle c_{x_{0}}}, which points to the smallest element in T.
An application of queaps includes a unique set of high priority events and extraction of the highest priority event for processing.

Operations
Let minL be a pointer that points to the minimum element in the doubly linked list L, cx0{\displaystyle c_{x_{0}}} be the minimum element stored in the 2–4 tree, T, k be the number of elements stored in T, and n be the total number of elements stored in queap Q. The operations are as follows:
New(Q): Initializes a new empty queap.

Initialize an empty doubly linked list L and 2–4 tree T. Set k and n to zero.Insert(Q, x): Add the element x to queap Q.

Insert the element x in list L. Set the bit in element x to one to demonstrate that the element is in the list L. Update the minL pointer if x is the smallest element in the list. Increment n by 1.Minimum(Q): Retrieve a pointer to the smallest element from queap Q.

If key(minL) < key(cx0{\displaystyle c_{x_{0}}}), return minL. Otherwise return cx0{\displaystyle c_{x_{0}}}.Delete(Q, x): Remove element x from queap Q.

If the bit of the element x is set to one, the element is stored in list L. Add all the elements from L to T, setting the bit of each element to zero. Each element is added to the parent of the right most child of T using the insert operation of the 2–4 tree. L becomes empty. Update hv{\displaystyle h_{v}} pointers for all the nodes v whose children are new/modified, and repeat the process with the next parent until the parent is equal to the root. Walk from the root to node  x0{\displaystyle x_{0}}, and update the cv{\displaystyle c_{v}} values. Set k equal to n.If the bit of the element x is set to zero, x is a leaf of T. Delete x using the 2–4 tree delete operation. Starting from node x, walk in T to node x0{\displaystyle x_{0}}, updating hv{\displaystyle h_{v}} and cv{\displaystyle c_{v}} pointers. Decrement n and k by 1.DeleteMin(Q): Delete and return the smallest element from queap Q.

Invoke the Minimum(Q) operation. The operation returns min. Invoke the Delete(Q, min) operation. Return min.CleanUp(Q): Delete all the elements in list L and tree T.

Starting from the first element in list L, traverse the list, deleting each node.Starting from the root of the tree T, traverse the tree using the post-order traversal algorithm, deleting each node in the tree.

Analysis
The running time is analyzed using the amortized analysis. The potential function for queap Q will be ϕ(Q)=c|L|{\displaystyle \phi (Q)=c|L|} where Q=(T,L){\displaystyle Q=(T,L)}.
Insert(Q, x): The cost of the operation is O(1). The size of list L grows by one, the potential increases by some constant c.
Minimum(Q): The operation does not alter the data structure so the amortized cost is equal to its actual cost, O(1).
Delete(Q, x): There are two cases.

Case 1
If x is in tree T, then the amortized cost is not modified. The delete operation is O(1) amortized 2–4 tree. Since x was removed from the tree, hv{\displaystyle h_{v}} and cv{\displaystyle c_{v}} pointers may need updating. At most, there will be O(lgq(x)){\displaystyle O(lgq(x))} updates.

Case 2
If x is in list L, then all the elements from L are inserted in T. This has a cost of a|L|{\displaystyle a|L|} of some constant a, amortized over the 2–4 tree. After inserting and updating the hv{\displaystyle h_{v}} and cv{\displaystyle c_{v}} pointers, the total time spent is bounded by 2a|L|{\displaystyle 2a|L|}. The second operation is to delete x from T, and to walk on the path from x to x0{\displaystyle x_{0}}, correcting hv{\displaystyle h_{v}} and cv{\displaystyle c_{v}} values. The time is spent at most  2a|L|+O(lgq(x)){\displaystyle 2a|L|+O(lgq(x))}.  If c>2a{\displaystyle c>2a}, then the amortized cost will be O(lgq(x)){\displaystyle O(lgq(x))}.
Delete(Q, x): is the addition of the amortized cost of Minimum(Q) and Delete(Q, x), which is O(lgq(x)){\displaystyle O(lgq(x))}.

Code example
A small Java implementation of a queap:

See also
Queue (data structure)
Priority queue
Splay tree
2–4 tree
Doubly linked list
Amortized analysis


== References ==",31075298,https://en.wikipedia.org/wiki/Queap
Red–black tree,"In computer science, a red–black tree is a specialised binary search tree data structure noted for fast storage and retrieval of ordered information, and a guarantee that operations will complete within a known time. Compared to other self-balancing binary search trees, the nodes in a red-black tree hold an extra bit called ""color"" representing ""red"" and ""black"" which is used when re-organising the tree to ensure that it is always approximately balanced. When the tree is modified, the new tree is rearranged and ""repainted"" to restore the coloring properties that constrain how unbalanced the tree can become in the worst case. The properties are designed such that this rearranging and recoloring can be performed efficiently.
The (re-)balancing is not perfect, but guarantees searching in Big O time of O(log⁡n){\displaystyle O(\log n)}, where n{\displaystyle n} is the number of entries (or keys) in the tree. The insert and delete operations, along with the tree rearrangement and recoloring, are also performed in O(log⁡n){\displaystyle O(\log n)} time.Tracking the color of each node requires only one bit of information per node because there are only two colors. The tree does not contain any other data specific to it being a red–black tree, so its memory footprint is almost identical to that of a classic (uncolored) binary search tree. In some cases, the added bit of information can be stored at no added memory cost.","In computer science, a red–black tree is a specialised binary search tree data structure noted for fast storage and retrieval of ordered information, and a guarantee that operations will complete within a known time. Compared to other self-balancing binary search trees, the nodes in a red-black tree hold an extra bit called ""color"" representing ""red"" and ""black"" which is used when re-organising the tree to ensure that it is always approximately balanced. When the tree is modified, the new tree is rearranged and ""repainted"" to restore the coloring properties that constrain how unbalanced the tree can become in the worst case. The properties are designed such that this rearranging and recoloring can be performed efficiently.
The (re-)balancing is not perfect, but guarantees searching in Big O time of O(log⁡n){\displaystyle O(\log n)}, where n{\displaystyle n} is the number of entries (or keys) in the tree. The insert and delete operations, along with the tree rearrangement and recoloring, are also performed in O(log⁡n){\displaystyle O(\log n)} time.Tracking the color of each node requires only one bit of information per node because there are only two colors. The tree does not contain any other data specific to it being a red–black tree, so its memory footprint is almost identical to that of a classic (uncolored) binary search tree. In some cases, the added bit of information can be stored at no added memory cost.

History
In 1972, Rudolf Bayer invented a data structure that was a special order-4 case of a B-tree. These trees maintained all paths from root to leaf with the same number of nodes, creating perfectly balanced trees. However, they were not binary search trees. Bayer called them a ""symmetric binary B-tree"" in his paper and later they became popular as 2–3–4 trees or even 2–4 trees.In a 1978 paper, ""A Dichromatic Framework for Balanced Trees"", Leonidas J. Guibas and Robert Sedgewick derived the red–black tree from the symmetric binary B-tree. The color ""red"" was chosen because it was the best-looking color produced by the color laser printer available to the authors while working at Xerox PARC. Another response from Guibas states that it was because of the red and black pens available to them to draw the trees.In 1993, Arne Andersson introduced the idea of a right leaning tree to simplify insert and delete operations.In 1999, Chris Okasaki showed how to make the insert operation purely functional. Its balance function needed to take care of only 4 unbalanced cases and one default balanced case.The original algorithm used 8 unbalanced cases, but Cormen et al. (2001) reduced that to 6 unbalanced cases. Sedgewick showed that the insert operation can be implemented in just 46 lines of Java code.
In 2008, Sedgewick proposed the left-leaning red–black tree, leveraging Andersson’s idea that simplified the insert and delete operations. Sedgewick originally allowed nodes whose two children are red, making his trees more like 2–3–4 trees, but later this restriction was added, making new trees more like 2–3 trees. Sedgewick implemented the insert algorithm in just 33 lines, significantly shortening his original 46 lines of code.

Terminology
A red–black tree is a special type of binary search tree, used in computer science to organize pieces of comparable data, such as text fragments or numbers (as e.g. the numbers in figures 1 and 2). The nodes carrying keys and/or data are frequently called ""internal nodes"", but to make this very specific they are also called non-NIL nodes in this article.
The leaf nodes of red–black trees ( NIL  in figure 1) do not contain keys or data. These ""leaves"" need not be explicit individuals in computer memory: a NULL pointer can—as in all binary tree data structures— encode the fact that there is no child node at this position in the (parent) node. Nevertheless, by their position in the tree, these objects are in relation to other nodes that is relevant to the RB-structure, it may have parent, sibling (i.e., the other child of the parent), uncle, even nephew node; and may be child—but never parent—of another node.
It is not really necessary to attribute a ""color"" to these end-of-path objects, because the condition ""is NIL or BLACK"" is implied by the condition ""is NIL"" (see also this remark).
Figure 2 shows the conceptually same red–black tree without these NIL leaves. To arrive at the same notion of a path, one must notice that e.g., 3 paths run through the node 1, namely a path through 1left plus 2 added paths through 1right, namely the paths through 6left and 6right. This way, these ends of the paths are also docking points for new nodes to be inserted, fully equivalent to the NIL leaves of figure 1.
Instead, to save a marginal amount of execution time, these (possibly many) NIL leaves may be implemented as pointers to one unique (and black) sentinel node (instead of pointers of value NULL).
As a conclusion, the fact that a child does not exist (is not a true node, does not contain data) can in all occurrences be specified by the very same NULL pointer or as the very same pointer to a sentinel node. Throughout this article, either choice is called NIL node and has the constant value NIL.
The black depth of a node is defined as the number of black nodes from the root to that node (i.e. the number of black ancestors). The black height of a red–black tree is the number of black nodes in any path from the root to the leaves, which, by requirement 4, is constant (alternatively, it could be defined as the black depth of any leaf node).: 154–165 
The black height of a node is the black height of the subtree rooted by it. In this article, the black height of a NIL node shall be set to 0, because its subtree is empty as suggested by figure 2, and its tree height is also 0.

Properties
In addition to the requirements imposed on a binary search tree the following must be satisfied by a red–black tree:

Every node is either red or black.
All NIL nodes (figure 1) are considered black.
A red node does not have a red child.
Every path from a given node to any of its descendant NIL nodes goes through the same number of black nodes.
(Conclusion) If a node N has exactly one child, it must be a red child, because if it were black, its NIL descendants would sit at a different black depth than N's NIL child, violating requirement 4.Some authors, e.g. Cormen & al., claim ""the root is black"" as fifth requirement; but not Mehlhorn & Sanders or Sedgewick & Wayne.: 432–447  Since the root can always be changed from red to black, this rule has little effect on analysis.
This article also omits it, because it slightly disturbs the recursive algorithms and proofs.
As an example, every perfect binary tree that consists only of black nodes is a red–black tree.
The read-only operations, such as search or tree traversal, do not affect any of the requirements. In contrast, the modifying operations insert and delete easily maintain requirements 1 and 2, but with respect to the other requirements some extra effort must be made, to avoid introducing a violation of requirement 3, called a red-violation, or of requirement 4, called a black-violation.
The requirements enforce a critical property of red–black trees: the path from the root to the farthest leaf is no more than twice as long as the path from the root to the nearest leaf. The result is that the tree is height-balanced. Since operations such as inserting, deleting, and finding values require worst-case time proportional to the height h{\displaystyle h} of the tree, this upper bound on the height allows red–black trees to be efficient in the worst case, namely logarithmic in the number n{\displaystyle n} of entries, i.e. h∈O(log⁡n){\displaystyle h\in O(\log n)}, which is not the case for ordinary binary search trees. For a mathematical proof see section Proof of bounds.
Red–black trees, like all binary search trees, allow quite efficient sequential access (e.g. in-order traversal, that is: in the order Left–Root–Right) of their elements. But they support also asymptotically optimal direct access via a traversal from root to leaf, resulting in O(log⁡n){\displaystyle O(\log n)} search time.

Analogy to B-trees of order 4
A red–black tree is similar in structure to a B-tree of order 4, where each node can contain between 1 and 3 values and (accordingly) between 2 and 4 child pointers. In such a B-tree, each node will contain only one value matching the value in a black node of the red–black tree, with an optional value before and/or after it in the same node, both matching an equivalent red node of the red–black tree.
One way to see this equivalence is to ""move up"" the red nodes in a graphical representation of the red–black tree, so that they align horizontally with their parent black node, by creating together a horizontal cluster. In the B-tree, or in the modified graphical representation of the red–black tree, all leaf nodes are at the same depth.
The red–black tree is then structurally equivalent to a B-tree of order 4, with a minimum fill factor of 33% of values per cluster with a maximum capacity of 3 values.
This B-tree type is still more general than a red–black tree though, as it allows ambiguity in a red–black tree conversion—multiple red–black trees can be produced from an equivalent B-tree of order 4 (see figure 3). If a B-tree cluster contains only 1 value, it is the minimum, black, and has two child pointers. If a cluster contains 3 values, then the central value will be black and each value stored on its sides will be red. If the cluster contains two values, however, either one can become the black node in the red–black tree (and the other one will be red).
So the order-4 B-tree does not maintain which of the values contained in each cluster is the root black tree for the whole cluster and the parent of the other values in the same cluster. Despite this, the operations on red–black trees are more economical in time because you don't have to maintain the vector of values. It may be costly if values are stored directly in each node rather than being stored by reference. B-tree nodes, however, are more economical in space because you don't need to store the color attribute for each node. Instead, you have to know which slot in the cluster vector is used. If values are stored by reference, e.g. objects, null references can be used and so the cluster can be represented by a vector containing 3 slots for value pointers plus 4 slots for child references in the tree. In that case, the B-tree can be more compact in memory, improving data locality.
The same analogy can be made with B-trees with larger orders that can be structurally equivalent to a colored binary tree: you just need more colors. Suppose that you add blue, then the blue–red–black tree defined like red–black trees but with the additional constraint that no two successive nodes in the hierarchy will be blue and all blue nodes will be children of a red node, then it becomes equivalent to a B-tree whose clusters will have at most 7 values in the following colors: blue, red, blue, black, blue, red, blue (For each cluster, there will be at most 1 black node, 2 red nodes, and 4 blue nodes).
For moderate volumes of values, insertions and deletions in a colored binary tree are faster compared to B-trees because colored trees don't attempt to maximise the fill factor of each horizontal cluster of nodes (only the minimum fill factor is guaranteed in colored binary trees, limiting the number of splits or junctions of clusters). B-trees will be faster for performing rotations (because rotations will frequently occur within the same cluster rather than with multiple separate nodes in a colored binary tree). For storing large volumes, however, B-trees will be much faster as they will be more compact by grouping several children in the same cluster where they can be accessed locally.
All optimizations possible in B-trees to increase the average fill factors of clusters are possible in the equivalent multicolored binary tree. Notably, maximizing the average fill factor in a structurally equivalent B-tree is the same as reducing the total height of the multicolored tree, by increasing the number of non-black nodes. The worst case occurs when all nodes in a colored binary tree are black, the best case occurs when only a third of them are black (and the other two thirds are red nodes).

Applications and related data structures
Red–black trees offer worst-case guarantees for insertion time, deletion time, and search time. Not only does this make them valuable in time-sensitive applications such as real-time applications, but it makes them valuable building blocks in other data structures that provide worst-case guarantees; for example, many data structures used in computational geometry can be based on red–black trees, and the Completely Fair Scheduler used in current Linux kernels and epoll system call implementation uses red–black trees.
The AVL tree is another structure supporting O(log⁡n){\displaystyle O(\log n)} search, insertion, and removal. AVL trees can be colored red–black, thus are a subset of RB trees. Worst-case height is 0.720 times the worst-case height of RB trees, so AVL trees are more rigidly balanced. The performance measurements of Ben Pfaff with realistic test cases in 79 runs find AVL to RB ratios between 0.677 and 1.077, median at 0.947, and geometric mean 0.910. WAVL trees have a performance in between those two.
Red–black trees are also particularly valuable in functional programming, where they are one of the most common persistent data structures, used to construct associative arrays and sets that can retain previous versions after mutations. The persistent version of red–black trees requires O(log⁡n){\displaystyle O(\log n)} space for each insertion or deletion, in addition to time.
For every 2–4 tree, there are corresponding red–black trees with data elements in the same order. The insertion and deletion operations on 2–4 trees are also equivalent to color-flipping and rotations in red–black trees. This makes 2–4 trees an important tool for understanding the logic behind red–black trees, and this is why many introductory algorithm texts introduce 2–4 trees just before red–black trees, even though 2–4 trees are not often used in practice.
In 2008, Sedgewick introduced a simpler version of the red–black tree called the left-leaning red–black tree by eliminating a previously unspecified degree of freedom in the implementation. The LLRB maintains an additional invariant that all red links must lean left except during inserts and deletes. Red–black trees can be made isometric to either 2–3 trees, or 2–4 trees, for any sequence of operations. The 2–4 tree isometry was described in 1978 by Sedgewick. With 2–4 trees, the isometry is resolved by a ""color flip,"" corresponding to a split, in which the red color of two children nodes leaves the children and moves to the parent node.
The original description of the tango tree, a type of tree optimised for fast searches, specifically uses red–black trees as part of its data structure.As of Java 8, the HashMap has been modified such that instead of using a LinkedList to store different elements with colliding hashcodes, a red–black tree is used. This results in the improvement of time complexity of searching such an element from O(m){\displaystyle O(m)} to O(log⁡m){\displaystyle O(\log m)} where m{\displaystyle m} is the number of elements with colliding hashcodes.

Operations
The read-only operations, such as search or tree traversal, on a red–black tree require no modification from those used for binary search trees, because every red–black tree is a special case of a simple binary search tree. However, the immediate result of an insertion or removal may violate the properties of a red–black tree, the restoration of which is called rebalancing so that red–black trees become self-balancing.
It requires in the worst case a small number, O(log⁡n){\displaystyle O(\log n)} in Big O notation, where n{\displaystyle n} is the number of objects in the tree, on average or amortized O(1){\displaystyle O(1)}, a constant number,: 310  : 158  of color changes (which are very quick in practice); and no more than three tree rotations (two for insertion).
If the example implementation below is not suitable, other implementations with explanations may be found in Ben Pfaff’s annotated C library GNU libavl (v2.0.3 as of June 2019).
The details of the insert and removal operations will be demonstrated with example C++ code, which uses the type definitions, macros below, and the helper function for rotations:

Notes to the sample code and diagrams of insertion and removal
The proposal breaks down both, insertion and removal (not mentioning some very simple cases), into six constellations of nodes, edges and colors, which are called cases. The proposal contains for both, insertion and removal, exactly one case that advances one black level closer to the root and loops, the other five cases rebalance the tree of their own. The more complicated cases are pictured in a diagram.

 symbolises a red node and  a (non-NIL) black node (of black height ≥ 1),  symbolises the color red or black of a non-NIL node, but the same color throughout the same diagram. NIL nodes are not represented in the diagrams.
The variable N denotes the current node, which is labeled  N  or  N  in the diagrams.
A diagram contains three columns and two to four actions. The left column shows the first iteration, the right column the higher iterations, the middle column shows the segmentation of a case into its different actions.The action ""entry"" shows the constellation of nodes with their colors which defines a case and mostly violates some of the requirements.A blue border rings the current node N and the other nodes are labeled according to their relation to N.
If a rotation is considered useful, this is pictured in the next action, which is labeled ""rotation"".
If some recoloring is considered useful, this is pictured in the next action, which is labeled ""color"".
If there is still some need to repair, the cases make use of code of other cases and this after a reassignment of the current node N, which then again carries a blue ring and relative to which other nodes may have to be reassigned also. This action is labeled ""reassign"".For both, insert and delete, there is (exactly) one case which iterates one black level closer to the root; then the reassigned constellation satisfies the respective loop invariant.A possibly numbered triangle with a black circle atop  represents a red–black subtree (connected to its parent according to requirement 3) with a black height equal to the iteration level minus one, i.e. zero in the first iteration. Its root may be red or black.A possibly numbered triangle  represents a red–black subtree with a black height one less, i.e. its parent has black height zero in the second iteration.

Remark
For simplicity, the sample code uses the disjunction:
U == NIL || U->color == BLACK // considered black
and the conjunction:
U != NIL && U->color == RED   // not considered black
Thereby, it must be kept in mind that both statements are not evaluated in total, if U == NIL. Then in both cases U->color is not touched (see Short-circuit evaluation).(The comment considered black is in accordance with requirement 2.)
The related if-statements have to occur far less frequently if the proposal is realised.

Insertion
Insertion begins by placing the new (non-NIL) node, say N, at the position in the binary search tree of a NIL node whose in-order predecessor’s key compares less than the new node’s key, which in turn compares less than the key of its in-order successor.
(Frequently, this positioning is the result of a search within the tree immediately preceding the insert operation and consists of a node P together with a direction dir with P->child[dir] == NIL.)
The newly inserted node is temporarily colored red so that all paths contain the same number of black nodes as before.
But if its parent, say P, is also red then this action introduces a red-violation.

The rebalancing loop of the insert operation has the following invariant:

The variable N, representing the current node N and initially the insertion node, is made the variable running through the loop.
N is  (red) at the beginning of each iteration.
Requirement 3 is satisfied for all pairs node←parent with the possible exception N←P when P is also red (a red-violation at N).
All other properties (including requirement 4) are satisfied throughout the tree.

Notes to the insert diagrams
In the diagrams, P is used for N’s parent, G for its grandparent, and U for its uncle. In the table a — sign indicates root.
The diagrams show the parent node P as the left child of its parent G even though it is possible for P to be on either side. The sample code covers both possibilities by means of the side variable dir.
The diagrams show the cases where P is red also, the red-violation.
The column x indicates the change in child direction, i.e. o (for ""outer"") means that P and N are both left or both right children, whereas i (for ""inner"") means that the child direction changes from P’s to N’s.
The column group before defines the case, whose name is given in the column case. Thereby possible values in cells left empty are ignored. So in case I2 the sample code covers both possibilities of child directions of N, although the corresponding diagram shows only one.
The rows in the synopsis are ordered such that the coverage of all possible RB cases is easily comprehensible.
The column rotation indicates whether a rotation contributes to the rebalancing.
The column assignment shows an assignment of N before entering a subsequent step. This possibly induces a reassignment of the other nodes P, G, U also.
If something has been changed by the case, this is shown in the column group after.
A ✓ sign in column next signifies that the rebalancing is complete with this step. If the column after determines exactly one case, this case is given as the subsequent one, otherwise there are question marks.
The loop is contained in the sections ""Insert case I1"" and ""Insert case I2"", where in case I2 the problem of rebalancing is escalated Δh=2{\displaystyle \Delta h=2} tree levels or 1 black level higher in the tree, in that the grandfather G becomes the new current node N. So it takes maximally h2{\displaystyle {\tfrac {h}{2}}} steps of iteration to repair the tree (where h{\displaystyle h} is the height of the tree). Because the probability of escalation decreases exponentially with each step the total rebalancing cost is constant on average, indeed amortized constant.
From the body of the loop, case I1 exits by itself and there are exiting branches to cases I4, I6, I5 + I6, and I3.
Rotations occur in cases I6 and I5 + I6 – outside the loop. Therefore, at most two rotations occur in total.

Insert case I1
The current node’s parent P is black, so requirement 3 holds. Requirement 4 holds also according to the loop invariant.

Insert case I2
If both the parent P and the uncle U are red, then both of them can be repainted black and the grandparent G becomes red for maintaining requirement 4. Since any path through the parent or uncle must pass through the grandparent, the number of black nodes on these paths has not changed. However, the grandparent G may now violate requirement 3, if it has a red parent. After relabeling G to N the loop invariant is fulfilled so that the rebalancing can be iterated on one black level (= 2 tree levels) higher.

Insert case I3
Insert case I2 has been executed for h−12{\displaystyle {\tfrac {h-1}{2}}} times and the total height of the tree has increased by 1, now being h .{\displaystyle h~.}
The current node N is the (red) root of the tree, and all RB-properties are satisfied.

Insert case I4
The parent P is red and the root.
Because N is also red, requirement 3 is violated. But after switching P’s color the tree is in RB-shape.
The black height of the tree increases by 1.

Insert case I5
The parent P is red but the uncle U is black. The ultimate goal is to rotate the parent node P to the grandparent position, but this will not work if N is an ""inner"" grandchild of G (i.e., if N is the left child of the right child of G or the right child of the left child of G). A dir-rotation at P switches the roles of the current node N and its parent P. The rotation adds paths through N (those in the subtree labeled 2, see diagram) and removes paths through P (those in the subtree labeled 4). But both P and N are red, so requirement 4 is preserved. Requirement 3 is restored in case 6.

Insert case I6
The current node N is now certain to be an ""outer"" grandchild of G (left of left child or right of right child). Now (1-dir)-rotate at G, putting P in place of G and making P the parent of N and G. G is black and its former child P is red, since requirement 3 was violated. After switching the colors of P and G the resulting tree satisfies requirement 3. Requirement 4 also remains satisfied, since all paths that went through the black G now go through the black P.

Because the algorithm transforms the input without using an auxiliary data structure and using only a small amount of extra storage space for auxiliary variables it is in-place.

Removal
Simple cases
- When the deleted node has 2 children (non-NIL), then we can swap its value with its in-order successor (the leftmost child of the right subtree), and then delete the successor instead. Since the successor is leftmost, it can only have a right child (non-NIL) or no child at all.
- When the deleted node has only 1 child (non-NIL). In this case, just replace the node with its child, and color it black.
The single child (non-NIL) must be red according to conclusion 5, and the deleted node must be black according to requirement 3.
- When the deleted node has no children (both NIL) and is the root, replace it with NIL. The tree is empty.
- When the deleted node has no children (both NIL), and is red, simply remove the leaf node.
- When the deleted node has no children (both NIL), and is black, deleting it will create an imbalance, and requires a fixup, as covered in the next section.

Removal of a black non-root leaf
The complex case is when N is not the root, colored black and has no proper child (⇔ only NIL children).
In the first iteration, N is replaced by NIL.

The rebalancing loop of the delete operation has the following invariant:

At the beginning of each iteration the black height of N equals the iteration number minus one, which means that in the first iteration it is zero and that N is a true black node  in higher iterations.
The number of black nodes on the paths through N is one less than before the deletion, whereas it is unchanged on all other paths, so that there is a black-violation at P if other paths exist.
All other properties (including requirement 3) are satisfied throughout the tree.

Notes to the delete diagrams
In the diagrams below, P is used for N’s parent, S for the sibling of N, C (meaning close nephew) for S’s child in the same direction as N, and D (meaning distant nephew) for S’s other child (S cannot be a NIL node in the first iteration, because it must have black height one, which was the black height of N before its deletion, but C and D may be NIL nodes).
The diagrams show the current node N as the left child of its parent P even though it is possible for N to be on either side. The code samples cover both possibilities by means of the side variable dir.
At the beginning (in the first iteration) of removal, N is the NIL node replacing the node to be deleted. Because its location in parent’s node is the only thing of importance, it is symbolised by  (meaning: the current node N is a NIL node and left child) in the left column of the delete diagrams. As the operation proceeds also proper nodes (of black height ≥ 1) may become current (see e.g. case D2).
By counting the black bullets ( and ) in a delete diagram it can be observed that the paths through N have one bullet less than the other paths. This means a black-violation at P—if it exists.
The color constellation in column group before defines the case, whose name is given in the column case. Thereby possible values in cells left empty are ignored.
The rows in the synopsis are ordered such that the coverage of all possible RB cases is easily comprehensible.
The column rotation indicates whether a rotation contributes to the rebalancing.
The column assignment shows an assignment of N before entering a subsequent iteration step. This possibly induces a reassignment of the other nodes P, C, S, D also.
If something has been changed by the case, this is shown in the column group after.
A ✓ sign in column next signifies that the rebalancing is complete with this step. If the column after determines exactly one case, this case is given as the subsequent one, otherwise there are question marks.
The loop is contained in the sections from Start_D through ""Delete case D2"", where the problem of rebalancing is escalated Δh=1{\displaystyle \Delta h=1} level higher in the tree in that the parent P becomes the new current node N. So it takes maximally h{\displaystyle h} iterations to repair the tree (where h{\displaystyle h} is the height of the tree). Because the probability of escalation decreases exponentially with each iteration the total rebalancing cost is constant on average, indeed amortized constant. (Just as an aside: Mehlhorn & Sanders point out: ""AVL trees do not support constant amortized update costs."": 165, 158  This is true for the rebalancing after a deletion, but not AVL insertion.)
Out of the body of the loop there are exiting branches to the cases D3, D6, D5 + D6, D4, and D1; section ""Delete case D3"" of its own has three different exiting branches to the cases D6, D5 and D4.
Rotations occur in cases D6 and D5 + D6 and D3 + D5 + D6 – all outside the loop. Therefore, at most three rotations occur in total.

Delete case D1
The current node N is the new root. One black node has been removed from every path, so the RB-properties are preserved.
The black height of the tree decreases by 1.

Delete case D2
P, S, and S’s children are black. After painting S red all paths passing through S, which are precisely those paths not passing through N, have one less black node. Now all paths in the subtree rooted by P have the same number of black nodes, but one fewer than the paths that do not pass through P, so requirement 4 may still be violated. After relabeling P to N the loop invariant is fulfilled so that the rebalancing can be iterated on one black level (= 1 tree level) higher.

Delete case D3
The sibling S is red, so P and the nephews C and D have to be black. A dir-rotation at P turns S into N’s grandparent.
Then after reversing the colors of P and S, the path through N is still short one black node. But N now has a red parent P and after the reassignment a black sibling S, so the transformations in cases D4, D5, or D6 are able to restore the RB-shape.

Delete case D4
The sibling S and S’s children are black, but P is red. Exchanging the colors of S and P does not affect the number of black nodes on paths going through S, but it does add one to the number of black nodes on paths going through N, making up for the deleted black node on those paths.

Delete case D5
The sibling S is black, S’s close child C is red, and S’s distant child D is black. After a (1-dir)-rotation at S the nephew C becomes S’s parent and N’s new sibling. The colors of S and C are exchanged.
All paths still have the same number of black nodes, but now N has a black sibling whose distant child is red, so the constellation is fit for case D6. Neither N nor its parent P are affected by this transformation, and P may be red or black ( in the diagram).

Delete case D6
The sibling S is black, S’s distant child D is red. After a dir-rotation at P the sibling S becomes the parent of P and S’s distant child D. The colors of P and S are exchanged, and D is made black. The whole subtree still has the same color at its root S, namely either red or black ( in the diagram), which refers to the same color both before and after the transformation. This way requirement 3 is preserved. The paths in the subtree not passing through N (i.o.w. passing through D and node 3 in the diagram) pass through the same number of black nodes as before, but N now has one additional black ancestor: either P has become black, or it was black and S was added as a black grandparent. Thus, the paths passing through N pass through one additional black node, so that requirement 4 is restored and the total tree is in RB-shape.

Because the algorithm transforms the input without using an auxiliary data structure and using only a small amount of extra storage space for auxiliary variables it is in-place.

Proof of bounds
For h∈N{\displaystyle h\in \mathbb {N} } there is a red–black tree of height h{\displaystyle h} with

nodes (⌊⌋{\displaystyle \lfloor \,\rfloor } is the floor function) and there is no red–black tree of this tree height with fewer nodes—therefore it is minimal.Its black height is   ⌈h/2⌉{\displaystyle \lceil h/2\rceil }   (with black root) or for odd h{\displaystyle h} (then with a red root) also   (h−1)/2 .{\displaystyle (h-1)/2~.}

ProofFor a red–black tree of a certain height to have minimal number of nodes, it must have exactly one longest path with maximal number of red nodes, to achieve a maximal tree height with a minimal black height. Besides this path all other nodes have to be black.: 444 Proof sketch  If a node is taken off this tree it either loses height or some RB property.
The RB tree of height h=1{\displaystyle h=1} with red root is minimal. This is in agreement with

m1=2⌊(1+1)/2⌋+2⌊1/2⌋−2=21+20−2=1 .{\displaystyle m_{1}=2^{\lfloor (1+1)/2\rfloor }\!+\!2^{\lfloor 1/2\rfloor }\!\!-\!\!2=2^{1}\!+\!2^{0}\!\!-\!\!2=1~.}A minimal RB tree (RBh in figure 4) of height h>1{\displaystyle h>1} has a root whose two child subtrees are of different height. The higher child subtree is also a minimal RB tree, RBh–1, containing also a longest path that defines its height h−1{\displaystyle h\!\!-\!\!1}; it has mh−1{\displaystyle m_{h-1}} nodes and the black height ⌊(h−1)/2⌋=:s.{\displaystyle \lfloor (h\!\!-\!\!1)/2\rfloor =:s.} The other subtree is a perfect binary tree of (black) height s{\displaystyle s} having 2s−1=2⌊(h−1)/2⌋−1{\displaystyle 2^{s}\!\!-\!\!1=2^{\lfloor (h-1)/2\rfloor }\!\!-\!\!1} black nodes—and no red node. Then the number of nodes is by induction

The graph of the function mh{\displaystyle m_{h}} is convex and piecewise linear with breakpoints at (h=2k|m2k=2⋅2k−2){\displaystyle (h=2k\;|\;m_{2k}=2\cdot 2^{k}\!-\!2)} where k∈N.{\displaystyle k\in \mathbb {N} .} The function has been tabulated as mh={\displaystyle m_{h}=} A027383(h–1) for h≥1{\displaystyle h\geq 1} (sequence A027383 in the OEIS).

Solving the function for h{\displaystyle h}The inequality 9>8=23{\displaystyle 9>8=2^{3}} leads to 3>23/2{\displaystyle 3>2^{3/2}}, which for odd h{\displaystyle h} leads to

mh=3⋅2(h−1)/2−2=(3⋅2−3/2)⋅2(h+2)/2−2>2⋅2h/2−2{\displaystyle m_{h}=3\cdot 2^{(h-1)/2}-2={\bigl (}3\cdot 2^{-3/2}{\bigr )}\cdot 2^{(h+2)/2}-2>2\cdot 2^{h/2}-2}.So in both, the even and the odd case, h{\displaystyle h} is in the interval

with n{\displaystyle n} being the number of nodes.
ConclusionA red–black tree with n{\displaystyle n} nodes (keys) has tree height h∈O(log⁡n).{\displaystyle h\in O(\log n).}

Set operations and bulk operations
In addition to the single-element insert, delete and lookup operations, several set operations have been defined on red–black trees: union, intersection and set difference. Then fast bulk operations on insertions or deletions can be implemented based on these set functions. These set operations rely on two helper operations, Split and Join. With the new operations, the implementation of red–black trees can be more efficient and highly-parallelizable. In order to achieve its time complexities this implementation requires that the root is allowed to be either red or black, and that every node stores its own black height.

Join: The function Join is on two red–black trees t1 and t2 and a key k, where t1 < k < t2, i.e. all keys in t1 are less than k, and all keys in t2 are greater than k. It returns a tree containing all elements in t1, t2 also as k.If the two trees have the same black height, Join simply creates a new node with left subtree t1, root k and right subtree t2. If both t1 and t2 have black root, set k to be red. Otherwise k is set black.
If the black heights are unequal, suppose that t1 has larger black height than t2 (the other case is symmetric). Join follows the right spine of t1 until a black node c, which is balanced with t2. At this point a new node with left child c, root k (set to be red) and right child t2 is created to replace c. The new node may invalidate the red–black invariant because at most three red nodes can appear in a row. This can be fixed with a double rotation. If double red issue propagates to the root, the root is then set to be black, restoring the properties. The cost of this function is the difference of the black heights between the two input trees.Split: To split a red–black tree into two smaller trees, those smaller than key x, and those larger than key x, first draw a path from the root by inserting x into the red–black tree. After this insertion, all values less than x will be found on the left of the path, and all values greater than x will be found on the right. By applying Join, all the subtrees on the left side are merged bottom-up using keys on the path as intermediate nodes from bottom to top to form the left tree, and the right part is symmetric.For some applications, Split also returns a boolean value denoting if x appears in the tree. The cost of Split is O(log⁡n),{\displaystyle O(\log n),} order of the height of the tree. This algorithm actually has nothing to do with any special properties of a red–black tree, and may be used on any tree with a join operation, such as an AVL tree.The join algorithm is as follows:

function joinRightRB(TL, k, TR):
    if (TL.color=black) and (TL.blackHeight=TR.blackHeight):
        return Node(TL,⟨k,red⟩,TR)
    T'=Node(TL.left,⟨TL.key,TL.color⟩,joinRightRB(TL.right,k,TR))
    if (TL.color=black) and (T'.right.color=T'.right.right.color=red):
        T'.right.right.color=black;
        return rotateLeft(T')
    return T' /* T''[recte T'] */

function joinLeftRB(TL, k, TR):
  /* symmetric to joinRightRB */

function join(TL, k, TR):
    if TL.blackHeight>TR.blackHeight:
        T'=joinRightRB(TL,k,TR)
        if (T'.color=red) and (T'.right.color=red):
            T'.color=black
        return T'
    if TR.blackHeight>TL.blackHeight:
        /* symmetric */
    if (TL.color=black) and (TR.color=black):
        return Node(TL,⟨k,red⟩,TR)
    return Node(TL,⟨k,black⟩,TR)

The split algorithm is as follows:

function split(T, k):
    if (T = nil) return (nil, false, nil)
    if (k = T.key) return (T.left, true, T.right)
    if (k < T.key):
        (L',b,R') = split(T.left, k)
        return (L',b,join(R',T.key,T.right))
    (L',b,R') = split(T.right, k)
    return (join(T.left,T.key,L'),b,T.right)

The union of two red–black trees t1 and t2 representing sets A and B, is a red–black tree t that represents A ∪ B. The following recursive function computes this union:

function union(t1, t2):
    if t1 = nil return t2if t2 = nil return t1
    (L1,b,R1)=split(t1,t2.key)
    proc1=start:
        TL=union(L1,t2.left)
    proc2=start:
        TR=union(R1,t2.right)
    wait all proc1,proc2
    return join(TL, t2.key, TR)

Here, split is presumed to return two trees: one holding the keys less its input key, one holding the greater keys. (The algorithm is non-destructive, but an in-place destructive version exists also.)
The algorithm for intersection or difference is similar, but requires the Join2 helper routine that is the same as Join but without the middle key. Based on the new functions for union, intersection or difference, either one key or multiple keys can be inserted to or deleted from the red–black tree. Since Split calls Join but does not deal with the balancing criteria of red–black trees directly, such an implementation is usually called the ""join-based"" implementation.
The complexity of each of union, intersection and difference is O(mlog⁡(nm+1)){\displaystyle O\left(m\log \left({n \over m}+1\right)\right)} for two red–black trees of sizes m{\displaystyle m} and n(≥m){\displaystyle n(\geq m)}. This complexity is optimal in terms of the number of comparisons. More importantly, since the recursive calls to union, intersection or difference are independent of each other, they can be executed in parallel with a parallel depth O(log⁡mlog⁡n){\displaystyle O(\log m\log n)}. When m=1{\displaystyle m=1}, the join-based implementation has the same computational directed acyclic graph (DAG) as single-element insertion and deletion if the root of the larger tree is used to split the smaller tree.

Parallel algorithms
Parallel algorithms for constructing red–black trees from sorted lists of items can run in constant time or O(log⁡log⁡n){\displaystyle O(\log \log n)} time, depending on the computer model, if the number of processors available is asymptotically proportional to the number n{\displaystyle n} of items where n→∞{\displaystyle n\to \infty }. Fast search, insertion, and deletion parallel algorithms are also known.The join-based algorithms for red–black trees are parallel for bulk operations, including union, intersection, construction, filter, map-reduce, and so on.

Parallel bulk operations
Basic operations like insertion, removal or update can be parallelised by defining operations that process bulks of multiple elements. It is also possible to process bulks with several basic operations, for example bulks may contain elements to insert and also elements to remove from the tree.
The algorithms for bulk operations aren't just applicable to the red–black tree, but can be adapted to other sorted sequence data structures also, like the 2–3 tree, 2–3–4 tree and (a,b)-tree. In the following different algorithms for bulk insert will be explained, but the same algorithms can also be applied to removal and update. Bulk insert is an operation that inserts each element of a sequence I{\displaystyle I} into a tree T{\displaystyle T}.

Join-based
This approach can be applied to every sorted sequence data structure that supports efficient join- and split-operations.
The general idea is to split I{\displaystyle I} and T{\displaystyle T} in multiple parts and perform the insertions on these parts in parallel.

First the bulk I{\displaystyle I} of elements to insert must be sorted.
After that, the algorithm splits I{\displaystyle I} into k∈N+{\displaystyle k\in \mathbb {N} ^{+}} parts ⟨I1,⋯,Ik⟩{\displaystyle \langle I_{1},\cdots ,I_{k}\rangle } of about equal sizes.
Next the tree T{\displaystyle T} must be split into k{\displaystyle k} parts ⟨T1,⋯,Tk⟩{\displaystyle \langle T_{1},\cdots ,T_{k}\rangle } in a way, so that for every j∈N+|1≤j<k{\displaystyle j\in \mathbb {N} ^{+}|\,1\leq j<k} following constraints hold:
last(Ij)<first(Tj+1){\displaystyle {\text{last}}(I_{j})<{\text{first}}(T_{j+1})}
last(Tj)<first(Ij+1){\displaystyle {\text{last}}(T_{j})<{\text{first}}(I_{j+1})}
Now the algorithm inserts each element of Ij{\displaystyle I_{j}} into Tj{\displaystyle T_{j}} sequentially. This step must be performed for every j{\displaystyle j}, which can be done by up to k{\displaystyle k} processors in parallel.
Finally, the resulting trees will be joined to form the final result of the entire operation.Note that in Step 3 the constraints for splitting I{\displaystyle I} assure that in Step 5 the trees can be joined again and the resulting sequence is sorted.

			
			
		
		
			
			
		
		
			
			
		
		
			
			
		
The pseudo code shows a simple divide-and-conquer implementation of the join-based algorithm for bulk-insert.
Both recursive calls can be executed in parallel.
The join operation used here differs from the version explained in this article, instead join2 is used, which misses the second parameter k.

bulkInsert(T, I, k):
    I.sort()
    bulklInsertRec(T, I, k)

bulkInsertRec(T, I, k):
    if k = 1:
        forall e in I: T.insert(e)
    else
        m := ⌊size(I) / 2⌋
        (T1, _, T2) := split(T, I[m])
        bulkInsertRec(T1, I[0 .. m], ⌈k / 2⌉)
            || bulkInsertRec(T2, I[m + 1 .. size(I) - 1], ⌊k / 2⌋)
        T ← join2(T1, T2)

Execution time
Sorting I{\displaystyle I} is not considered in this analysis.

This can be improved by using parallel algorithms for splitting and joining.
In this case the execution time is ∈O(log⁡|T|+|I|klog⁡|T|){\displaystyle \in O\left(\log |T|+{\frac {|I|}{k}}\log |T|\right)}.

Work
Pipelining
Another method of parallelizing bulk operations is to use a pipelining approach.
This can be done by breaking the task of processing a basic operation up into a sequence of subtasks.
For multiple basic operations the subtasks can be processed in parallel by assigning each subtask to a separate processor.

First the bulk I{\displaystyle I} of elements to insert must be sorted.
For each element in I{\displaystyle I} the algorithm locates the according insertion position in T{\displaystyle T}. This can be done in parallel for each element ∈I{\displaystyle \in I} since T{\displaystyle T} won't be mutated in this process. Now I{\displaystyle I} must be divided into subsequences S{\displaystyle S} according to the insertion position of each element. For example sn,left{\displaystyle s_{n,{\mathit {left}}}} is the subsequence of I{\displaystyle I} that contains the elements whose insertion position would be to the left of node n{\displaystyle n}.
The middle element mn,dir{\displaystyle m_{n,{\mathit {dir}}}} of every subsequence sn,dir{\displaystyle s_{n,{\mathit {dir}}}} will be inserted into T{\displaystyle T} as a new node n′{\displaystyle n'}. This can be done in parallel for each mn,dir{\displaystyle m_{n,{\mathit {dir}}}} since by definition the insertion position of each mn,dir{\displaystyle m_{n,{\mathit {dir}}}} is unique. If sn,dir{\displaystyle s_{n,{\mathit {dir}}}} contains elements to the left or to the right of mn,dir{\displaystyle m_{n,{\mathit {dir}}}}, those will be contained in a new set of subsequences S{\displaystyle S} as sn′,left{\displaystyle s_{n',{\mathit {left}}}} or sn′,right{\displaystyle s_{n',{\mathit {right}}}}.
Now T{\displaystyle T} possibly contains up to two consecutive red nodes at the end of the paths form the root to the leaves, which needs to be repaired. Note that, while repairing, the insertion position of elements ∈S{\displaystyle \in S} have to be updated, if the corresponding nodes are affected by rotations.If two nodes have different nearest black ancestors, they can be repaired in parallel. Since at most four nodes can have the same nearest black ancestor, the nodes at the lowest level can be repaired in a constant number of parallel steps.This step will be applied successively to the black levels above until T{\displaystyle T} is fully repaired.
The steps 3 to 5 will be repeated on the new subsequences until S{\displaystyle S} is empty. At this point every element ∈I{\displaystyle \in I} has been inserted. Each application of these steps is called a stage. Since the length of the subsequences in S{\displaystyle S} is ∈O(|I|){\displaystyle \in O(|I|)} and in every stage the subsequences are being cut in half, the number of stages is ∈O(log⁡|I|){\displaystyle \in O(\log |I|)}.Since all stages move up the black levels of the tree, they can be parallelised in a pipeline. Once a stage has finished processing one black level, the next stage is able to move up and continue at that level.

Execution time
Sorting I{\displaystyle I} is not considered in this analysis.
Also, |I|{\displaystyle |I|} is assumed to be smaller than |T|{\displaystyle |T|}, otherwise it would be more efficient to construct the resulting tree from scratch.

Work
Popular culture
A red–black tree was referenced correctly in an episode of Missing as noted by Robert Sedgewick in one of his lectures:
Jess: It was the red door again.Pollock: I thought the red door was the storage container.Jess: But it wasn't red anymore, it was black.Antonio: So red turning to black means what?Pollock: Budget deficits, red ink, black ink.Antonio: It could be from a binary search tree. The red–black tree tracks every simple path from a node to a descendant leaf that has the same number of black nodes.Jess: Does that help you with the ladies?

See also
List of data structures
Tree data structure
Tree rotation
AA tree, a variation of the red–black tree
Left-leaning red–black tree
AVL tree
B-tree (2–3 tree, 2–3–4 tree, B+ tree, B*-tree, UB-tree)
Scapegoat tree
Splay tree
T-tree
WAVL tree

References and notes
Further reading
Mathworld: Red–Black Tree
San Diego State University: CS 660: Red–Black tree notes, by Roger Whitney
 Pfaff, Ben (June 2004). ""Performance Analysis of BSTs in System Software"" (PDF). Stanford University.

External links
Ben Pfaff: An Introduction to Binary Search Trees and Balanced Trees. Free Software Foundation, Boston 2004, ftp.gnu.org (PDF gzip; 1662 kB)
A complete and working implementation in C
OCW MIT Lecture on Red-black Trees by Erik Demaine
Binary Search Tree Insertion Visualization on YouTube – Visualization of random and pre-sorted data insertions, in elementary binary search trees, and left-leaning red–black trees
An intrusive red–black tree written in C++
Red–black BSTs in 3.3 Balanced Search Trees
Red–black BST Demo",26397,https://en.wikipedia.org/wiki/Red%E2%80%93black_tree
Scapegoat tree,"In computer science, a scapegoat tree is a self-balancing binary search tree, invented by Arne Andersson in 1989 and again by Igal Galperin and Ronald L. Rivest in 1993.  It provides worst-case O(log⁡n){\displaystyle {\color {Blue}O(\log n)}} lookup time (with n{\displaystyle n} as the number of entries) and O(log⁡n){\displaystyle O(\log n)} amortized insertion and deletion time.
Unlike most other self-balancing binary search trees which also provide worst case O(log⁡n){\displaystyle O(\log n)} lookup time, scapegoat trees have no additional per-node memory overhead compared to a regular binary search tree: besides key and value, a node stores only two pointers to the child nodes. This makes scapegoat trees easier to implement and, due to data structure alignment, can reduce node overhead by up to one-third.
Instead of the small incremental rebalancing operations used by most balanced tree algorithms, scapegoat trees rarely but expensively choose a ""scapegoat"" and completely rebuild the subtree rooted at the scapegoat into a complete binary tree.  Thus, scapegoat trees have O(n){\displaystyle O(n)} worst-case update performance.","In computer science, a scapegoat tree is a self-balancing binary search tree, invented by Arne Andersson in 1989 and again by Igal Galperin and Ronald L. Rivest in 1993.  It provides worst-case O(log⁡n){\displaystyle {\color {Blue}O(\log n)}} lookup time (with n{\displaystyle n} as the number of entries) and O(log⁡n){\displaystyle O(\log n)} amortized insertion and deletion time.
Unlike most other self-balancing binary search trees which also provide worst case O(log⁡n){\displaystyle O(\log n)} lookup time, scapegoat trees have no additional per-node memory overhead compared to a regular binary search tree: besides key and value, a node stores only two pointers to the child nodes. This makes scapegoat trees easier to implement and, due to data structure alignment, can reduce node overhead by up to one-third.
Instead of the small incremental rebalancing operations used by most balanced tree algorithms, scapegoat trees rarely but expensively choose a ""scapegoat"" and completely rebuild the subtree rooted at the scapegoat into a complete binary tree.  Thus, scapegoat trees have O(n){\displaystyle O(n)} worst-case update performance.

Theory
A binary search tree is said to be weight-balanced if half the nodes are on the left of the root, and half on the right.
An α-weight-balanced node is defined as meeting a relaxed weight balance criterion:

size(left) ≤ α*size(node)
size(right) ≤ α*size(node)

Where size can be defined recursively as:

function size(node) is
    if node = nil then
        return 0
    else
        return size(node->left) + size(node->right) + 1
    end if
end function

Even a degenerate tree (linked list) satisfies this condition if α=1, whereas an α=0.5 would only match almost complete binary trees.
A binary search tree that is α-weight-balanced must also be α-height-balanced, that is 

height(tree) ≤ floor(log1/α(size(tree)))

By contraposition, a tree that is not α-height-balanced is not α-weight-balanced.
Scapegoat trees are not guaranteed to keep α-weight-balance at all times, but are always loosely α-height-balanced in that

height(scapegoat tree) ≤ floor(log1/α(size(tree))) + 1.

Violations of this height balance condition can be detected at insertion time, and imply that a violation of the weight balance condition must exist.  
This makes scapegoat trees similar to red–black trees in that they both have restrictions on their height. They differ greatly though in their implementations of determining where the rotations (or in the case of scapegoat trees, rebalances) take place. Whereas red–black trees store additional 'color' information in each node to determine the location, scapegoat trees find a scapegoat which isn't α-weight-balanced to perform the rebalance operation on. This is loosely similar to AVL trees, in that the actual rotations depend on 'balances' of nodes, but the means of determining the balance differs greatly. Since AVL trees check the balance value on every insertion/deletion, it is typically stored in each node; scapegoat trees are able to calculate it only as needed, which is only when a scapegoat needs to be found.
Unlike most other self-balancing search trees, scapegoat trees are entirely flexible as to their balancing. They support any α such that 0.5 < α < 1. A high α value results in fewer balances, making insertion quicker but lookups and deletions slower, and vice versa for a low α. Therefore in practical applications, an α can be chosen depending on how frequently these actions should be performed.

Operations
Lookup
Lookup is not modified from a standard binary search tree, and has a worst-case time of O(log⁡n){\displaystyle O(\log n)}. This is in contrast to splay trees which have a worst-case time of O(n){\displaystyle O(n)}. The reduced node memory overhead compared to other self-balancing binary search trees can further improve locality of reference and caching.

Insertion
Insertion is implemented with the same basic ideas as an unbalanced binary search tree, however with a few significant changes.
When finding the insertion point, the depth of the new node must also be recorded. This is implemented via a simple counter that gets incremented during each iteration of the lookup, effectively counting the number of edges between the root and the inserted node. If this node violates the α-height-balance property (defined above), a rebalance is required.
To rebalance, an entire subtree rooted at a scapegoat undergoes a balancing operation. The scapegoat is defined as being an ancestor of the inserted node which isn't α-weight-balanced. There will always be at least one such ancestor. Rebalancing any of them will restore the α-height-balanced property.
One way of finding a scapegoat, is to climb from the new node back up to the root and select the first node that isn't α-weight-balanced.
Climbing back up to the root requires O(log⁡n){\displaystyle O(\log n)} storage space, usually allocated on the stack, or parent pointers. This can actually be avoided by pointing each child at its parent as you go down, and repairing on the walk back up.
To determine whether a potential node is a viable scapegoat, we need to check its α-weight-balanced property. To do this we can go back to the definition:

size(left) ≤ α*size(node)
size(right) ≤ α*size(node)

However a large optimisation can be made by realising that we already know two of the three sizes, leaving only the third to be calculated.
Consider the following example to demonstrate this. Assuming that we're climbing back up to the root:

size(parent) = size(node) + size(sibling) + 1

But as:

size(inserted node) = 1.

The case is trivialized down to:

size[x+1] = size[x] + size(sibling) + 1

Where x = this node, x + 1 = parent and size(sibling) is the only function call actually required.
Once the scapegoat is found, the subtree rooted at the scapegoat is completely rebuilt to be perfectly balanced.  This can be done in O(n){\displaystyle O(n)} time by traversing the nodes of the subtree to find their values in sorted order and recursively choosing the median as the root of the subtree.
As rebalance operations take O(n){\displaystyle O(n)} time (dependent on the number of nodes of the subtree), insertion has a worst-case performance of O(n){\displaystyle O(n)} time.  However, because these worst-case scenarios are spread out, insertion takes O(log⁡n){\displaystyle O(\log n)} amortized time.

Sketch of proof for cost of insertion
Define the Imbalance of a node v to be the absolute value of the difference in size between its left node and right node minus 1, or 0, whichever is greater.  In other words:
I(v)=max⁡(|left⁡(v)−right⁡(v)|−1,0){\displaystyle I(v)=\operatorname {max} (|\operatorname {left} (v)-\operatorname {right} (v)|-1,0)}
Immediately after rebuilding a subtree rooted at v, I(v) = 0.
Lemma: Immediately before rebuilding the subtree rooted at v, I(v)∈Ω(|v|){\displaystyle I(v)\in \Omega (|v|)}
(Ω{\displaystyle \Omega } is Big Omega notation.)
Proof of lemma:
Let v0{\displaystyle v_{0}} be the root of a subtree immediately after rebuilding.  h(v0)=log⁡(|v0|+1){\displaystyle h(v_{0})=\log(|v_{0}|+1)}.  If there are Ω(|v0|){\displaystyle \Omega (|v_{0}|)} degenerate insertions (that is, where each inserted node increases the height by 1), then I(v)∈Ω(|v0|){\displaystyle I(v)\in \Omega (|v_{0}|)},h(v)=h(v0)+Ω(|v0|){\displaystyle h(v)=h(v_{0})+\Omega (|v_{0}|)} andlog⁡(|v|)≤log⁡(|v0|+1)+1{\displaystyle \log(|v|)\leq \log(|v_{0}|+1)+1}.
Since I(v)∈Ω(|v|){\displaystyle I(v)\in \Omega (|v|)} before rebuilding, there were Ω(|v|){\displaystyle \Omega (|v|)} insertions into the subtree rooted at v{\displaystyle v} that did not result in rebuilding.  Each of these insertions can be performed in O(log⁡n){\displaystyle O(\log n)} time.  The final insertion that causes rebuilding costs O(|v|){\displaystyle O(|v|)}.  Using aggregate analysis it becomes clear that the amortized cost of an insertion is O(log⁡n){\displaystyle O(\log n)}:
Ω(|v|)O(log⁡n)+O(|v|)Ω(|v|)=O(log⁡n){\displaystyle {\Omega (|v|)O(\log n)+O(|v|) \over \Omega (|v|)}=O(\log n)}

Deletion
Scapegoat trees are unusual in that deletion is easier than insertion. To enable deletion, scapegoat trees need to store an additional value with the tree data structure. This property, which we will call MaxNodeCount simply represents the highest achieved NodeCount. It is set to NodeCount whenever the entire tree is rebalanced, and after insertion is set to max(MaxNodeCount, NodeCount).
To perform a deletion, we simply remove the node as you would in a simple binary search tree, but if

NodeCount ≤ α*MaxNodeCount

then we rebalance the entire tree about the root, remembering to set MaxNodeCount to NodeCount.
This gives deletion a worst-case performance of O(n){\displaystyle O(n)} time, whereas the amortized time is O(log⁡n){\displaystyle O(\log n)}.

Sketch of proof for cost of deletion
Suppose the scapegoat tree has n{\displaystyle n} elements and has just been rebuilt (in other words, it is a complete binary tree).  At most n/2−1{\displaystyle n/2-1} deletions can be performed before the tree must be rebuilt.  Each of these deletions take O(log⁡n){\displaystyle O(\log n)} time (the amount of time to search for the element and flag it as deleted).  The n/2{\displaystyle n/2} deletion causes the tree to be rebuilt and takes O(log⁡n)+O(n){\displaystyle O(\log n)+O(n)} (or just O(n){\displaystyle O(n)}) time.  Using aggregate analysis it becomes clear that the amortized cost of a deletion is O(log⁡n){\displaystyle O(\log n)}:
∑1n/2O(log⁡n)+O(n)n/2=n2O(log⁡n)+O(n)n/2=O(log⁡n) {\displaystyle {\sum _{1}^{n/2}O(\log n)+O(n) \over n/2}={{n \over 2}O(\log n)+O(n) \over n/2}=O(\log n)\ }

Etymology
The name Scapegoat tree ""[...] is based on the common wisdom that, when something goes wrong, the first thing people tend to do is find someone to blame (the scapegoat)."" In the Bible, a scapegoat is an animal that is ritually burdened with the sins of others, and then driven away.

See also
Splay tree
Trees
Tree rotation
AVL tree
B-tree
T-tree

References
External links
Galpern, Igal (September 1996). On Consulting a Set of Experts and Searching (PDF) (Ph.D. thesis). MIT.
Morin, Pat. ""Chapter 8 - Scapegoat Trees"". Open Data Structures (in pseudocode) (0.1G β ed.). Retrieved 2017-09-16.",1377178,https://en.wikipedia.org/wiki/Scapegoat_tree
Shadow heap,"In computer science, a shadow heap is a mergeable heap data structure which supports efficient heap merging in the amortized sense. More specifically, shadow heaps make use of the shadow merge algorithm to achieve insertion in O(f(n)) amortized time and deletion in O((log n log log n)/f(n)) amortized time, for any choice of 1 ≤ f(n) ≤ log log n.Throughout this article, it is assumed that A and B are binary heaps with |A| ≤ |B|.","In computer science, a shadow heap is a mergeable heap data structure which supports efficient heap merging in the amortized sense. More specifically, shadow heaps make use of the shadow merge algorithm to achieve insertion in O(f(n)) amortized time and deletion in O((log n log log n)/f(n)) amortized time, for any choice of 1 ≤ f(n) ≤ log log n.Throughout this article, it is assumed that A and B are binary heaps with |A| ≤ |B|.

Shadow merge
Shadow merge is an algorithm for merging two binary heaps efficiently if these heaps are implemented as arrays. Specifically, the running time of shadow merge on two heaps A{\displaystyle A} and B{\displaystyle B} is O(|A|+min{log⁡|B|log⁡log⁡|B|,log⁡|A|log⁡|B|}){\displaystyle O(|A|+\min\{\log |B|\log \log |B|,\log |A|\log |B|\})}.

Algorithm
We wish to merge the two binary min-heaps A{\displaystyle A} and B{\displaystyle B}. The algorithm is as follows:

Concatenate the array A{\displaystyle A} at the end of the array B{\displaystyle B} to obtain an array C{\displaystyle C}.
Identify the shadow of A{\displaystyle A} in C{\displaystyle C}; that is, the ancestors of the last |A|{\displaystyle |A|} nodes in C{\displaystyle C} which destroy the heap property.
Identify the following two parts of the shadow from C{\displaystyle C}:
The path P{\displaystyle P}: the set of nodes in the shadow for which there are at most 2 at any depth of C{\displaystyle C};
The subtree T{\displaystyle T}: the remainder of the shadow.
Extract and sort the smallest |P|{\displaystyle |P|} nodes from the shadow into an array S{\displaystyle S}.
Transform S{\displaystyle S} as follows:
If |S|>|C|{\displaystyle |S|>|C|}, then starting from the smallest element in the sorted array, sequentially insert each element of S{\displaystyle S} into C{\displaystyle C}, replacing them with C{\displaystyle C}'s smallest elements.
If |S|≤|C|{\displaystyle |S|\leq |C|}, then extract and sort the |P|{\displaystyle |P|} smallest elements from C{\displaystyle C}, and merge this sorted list with S{\displaystyle S}.
Replace the elements of S{\displaystyle S} into their original positions in C{\displaystyle C}.
Make a heap out of T{\displaystyle T}.

Running time
Again, let P{\displaystyle P} denote the path, and T{\displaystyle T} denote the subtree of the concatenated heap C{\displaystyle C}. The number of nodes in P{\displaystyle P} is at most twice the depth of C{\displaystyle C}, which is O(log⁡|B|){\displaystyle O(\log |B|)}. Moreover, the number of nodes in T{\displaystyle T} at depth d{\displaystyle d} is at most 3/4 the number of nodes at depth d+1{\displaystyle d+1}, so the subtree has size O(|A|){\displaystyle O(|A|)}. Since there are at most 2 nodes at each level on P{\displaystyle P}, then reading the smallest |P|{\displaystyle |P|} elements of the shadow into the sorted array S{\displaystyle S} takes O(log⁡|B|){\displaystyle O(\log |B|)} time.
If |S|>|C|{\displaystyle |S|>|C|}, then combining P{\displaystyle P} and C{\displaystyle C} as in step 5 above takes time O(log⁡|A|log⁡|B|){\displaystyle O(\log |A|\log |B|)}. Otherwise, the time taken in this step is O(|A|+log⁡|B|log⁡log⁡|B|){\displaystyle O(|A|+\log |B|\log \log |B|)}. Finally, making a heap of the subtree T{\displaystyle T} takes O(|A|){\displaystyle O(|A|)} time. This amounts to a total running time for shadow merging of O(|A|+min{log⁡|A|log⁡|B|,log⁡|B|log⁡log⁡|B|}){\displaystyle O(|A|+\min\{\log |A|\log |B|,\log |B|\log \log |B|\})}.

Structure
A shadow heap H{\displaystyle H} consists of threshold function f(H){\displaystyle f(H)}, and an array for which the usual array-implemented binary heap property is upheld in its first entries, and for which the heap property is not necessarily upheld in the other entries. Thus, the shadow heap is essentially a binary heap B{\displaystyle B} adjacent to an array A{\displaystyle A}. To add an element to the shadow heap, place it in the array A{\displaystyle A}. If the array becomes too large according to the specified threshold, we first build a heap out of A{\displaystyle A} using Floyd's algorithm for heap construction, and then merge this heap with B{\displaystyle B} using shadow merge. Finally, the merging of shadow heaps is simply done through sequential insertion of one heap into the other using the above insertion procedure.

Analysis
We are given a shadow heap H=(B,A){\displaystyle H=(B,A)}, with threshold function log⁡|H|≤f(H)≤log⁡|H|log⁡log⁡|H|{\displaystyle \log |H|\leq f(H)\leq \log |H|\log \log |H|} as above. Suppose that the threshold function is such that any change in |B|{\displaystyle |B|} induces no larger a change than in f(H){\displaystyle f(H)}. We derive the desired running time bounds for the mergeable heap operations using the potential method for amortized analysis. The potential Ψ(H){\displaystyle \Psi (H)} of the heap is chosen to be:

Ψ(H)=|A|(1+min{log⁡|B|log⁡log⁡|B|,log⁡|B|log⁡|A|}/f(H)){\displaystyle \Psi (H)=|A|(1+\min\{\log |B|\log \log |B|,\log |B|\log |A|\}/f(H))}Using this potential, we can obtain the desired amortized running times:
create(H): initializes a new empty shadow heap H{\displaystyle H}

Here, the potential Ψ{\displaystyle \Psi } is unchanged, so the amortized cost of creation is O(1){\displaystyle O(1)}, the actual cost.insert(x, H): inserts x{\displaystyle x} into the shadow heap H{\displaystyle H}

There are two cases:
If the merge is employed, then the drop in the potential function is exactly the actual cost of merging B{\displaystyle B} and A{\displaystyle A}, so the amortized cost is O(1){\displaystyle O(1)}.
If the merge is not done, then the amortized cost is O(1+min{log⁡|B|log⁡log⁡|B|,log⁡|B|log⁡|A|}/f(H)){\displaystyle O(1+\min\{\log |B|\log \log |B|,\log |B|\log |A|\}/f(H))}
By choice of the threshold function, we thus obtain that the amortized cost of insertion is:
O(log⁡|H|log⁡log⁡|H|/f(H)){\displaystyle O(\log |H|\log \log |H|/f(H))}delete_min(H): deletes the minimum priority element from H{\displaystyle H}

Finding and deleting the minimum takes actual time O(|A|+log⁡|B|){\displaystyle O(|A|+\log |B|)}. Moreover, the potential function can only increase after this deletion if the value of f(H){\displaystyle f(H)} decreases. By choice of f{\displaystyle f}, we have that the amortized cost of this operation is the same as the actual cost.

Related algorithms & data structures
A naive binary heap merging algorithm will merge the two heaps A{\displaystyle A} and B{\displaystyle B} in time O(|B|){\displaystyle O(|B|)} by simply concatenating both heaps and making a heap out of the resulting array using Floyd's algorithm for heap construction. Alternatively, the heaps can simply be merged by sequentially inserting each element of A{\displaystyle A} into B{\displaystyle B}, taking time O(|A|log⁡|B|){\displaystyle O(|A|\log |B|)}.
Sack and Strothotte proposed an algorithm for merging the binary heaps in O(|A|+log⁡|A|log⁡|B|){\displaystyle O(|A|+\log |A|\log |B|)} time. Their algorithm is known to be more efficient than the second naive solution described above roughly when |A|>log⁡|B|{\displaystyle |A|>\log |B|}. Shadow merge performs asymptotically better than their algorithm, even in the worst case.
There are several other heaps which support faster merge times. For instance, Fibonacci heaps can be merged in O(1){\displaystyle O(1)} time. Since binary heaps require Ω(|A|){\displaystyle \Omega (|A|)} time to merge, shadow merge remains efficient.


== References ==",42442221,https://en.wikipedia.org/wiki/Shadow_heap
Soft heap,"In computer science, a soft heap is a variant on the simple heap data structure that has constant amortized time complexity for 5 types of operations. This is achieved by carefully ""corrupting"" (increasing) the keys of at most a constant number of values in the heap.","In computer science, a soft heap is a variant on the simple heap data structure that has constant amortized time complexity for 5 types of operations. This is achieved by carefully ""corrupting"" (increasing) the keys of at most a constant number of values in the heap.

Definition and performance
The constant time operations are:
create(S): Create a new soft heap
insert(S, x): Insert an element into a soft heap
meld(S,  S' ): Combine the contents of two soft heaps into one, destroying both
delete(S, x): Delete an element from a soft heap
findmin(S): Get the element with minimum key in the soft heapOther heaps such as Fibonacci heaps achieve most of these bounds without any corruption, but cannot provide a constant-time bound on the critical delete operation. The amount of corruption can be controlled by the choice of a parameter ε{\displaystyle \varepsilon }, but the lower this is set, the more time insertions require: expressed using Big-O notation, the amortized time will be O(log⁡1/ε){\displaystyle O(\log 1/\varepsilon )} for an error rate of ε{\displaystyle \varepsilon }. Some versions of soft heaps allow the create, insert, and meld operations to take constant time in the worst case, producing amortized rather than worst-case performance only for findmin and delete. As with comparison sort, these algorithms access the keys only by comparisons; if arithmetic operations on integer keys are allowed, the time dependence on ε{\displaystyle \varepsilon } can be reduced to O(log⁡log⁡1/ε){\displaystyle O(\log \log 1/\varepsilon )} or (with randomization) O(log⁡log⁡1/ε){\textstyle O({\sqrt {\log \log 1/\varepsilon }})}.More precisely, the error guarantee offered by the soft heap is the following: each soft heap is initialized with a parameter ε{\displaystyle \varepsilon }, chosen between 0 and 1/2. Then at any point in time it will contain at most ε⋅n{\displaystyle \varepsilon \cdot n} corrupted keys, where n{\displaystyle n} is the number of elements inserted so far. Note that this does not guarantee that only a fixed percentage of the keys currently in the heap are corrupted: in an unlucky sequence of insertions and deletions, it can happen that all elements in the heap will have corrupted keys. Similarly, there is no guarantee that in a sequence of elements extracted from the heap with findmin and delete, only a fixed percentage will have corrupted keys: in an unlucky scenario only corrupted elements are extracted from the heap. When a key is corrupted, the value stored for it in the soft key is higher than its initially-given value; corruption can never decrease the value of any key. The findmin operation finds the minimum value among the currently stored keys, including the corrupted ones.The soft heap was designed by Bernard Chazelle in 2000. The term ""corruption"" in the structure is the result of what Chazelle called ""carpooling"" in a soft heap. Each node in the soft heap contains a linked list of keys and one common key. The common key is an upper bound on the values of the keys in the linked list. Once a key is added to the linked list, it is considered corrupted because its value is never again relevant in any of the soft heap operations: only the common keys are compared. This is what makes soft heaps ""soft""; one cannot be sure whether any particular value put into it will be corrupted. The purpose of these corruptions is effectively to lower the information entropy of the data, enabling the data structure to break through information-theoretic barriers regarding heaps.

Applications
Despite their limitations and unpredictable nature, soft heaps are useful in the design of deterministic algorithms. For instance, they have been used to achieve the best complexity to date for finding a minimum spanning tree. Other problems whose efficient solution has been simplified using soft heaps include finding the k{\displaystyle k}th smallest element in several classes of structured sets of values, including heap-ordered trees, sorted matrices, and sumsets.Another simple example is a selection algorithm, to find the k{\displaystyle k}th smallest of a group of n{\displaystyle n} numbers:
Initialize a soft heap with error rate 1/3{\displaystyle 1/3}, allowing at most 33% of its inserted keys to be corrupted.
Insert all n{\displaystyle n} elements into the heap.
Repeat n/3{\displaystyle n/3} times: perform a findmin operation and delete the key that it returns.
Let L{\displaystyle L} be the deleted element whose correct key is largest.
Compare L{\displaystyle L} to all of the given elements, partition them into the subset less than L{\displaystyle L} and the subset greater than L{\displaystyle L}, placing elements that are equal to L{\displaystyle L} into the first subset when they were deleted and into the second subset otherwise.
Recursively call the same selection algorithm in the subset that contains the k{\displaystyle k}th smallest.After the comparison step of the algorithm, the first of the two subsets contains all of the deleted keys, so it includes at least n/3{\displaystyle n/3} elements.
Among the 2n/3{\displaystyle 2n/3} elements that were not deleted, at most n/3{\displaystyle n/3} are corrupted, so at least n/3{\displaystyle n/3} are uncorrupted. These uncorrupted and undeleted elements must all belong to the second subset, because they are greater than or equal to the soft heap's (possibly corrupted) value of L{\displaystyle L}, which is in turn greater than the true value of L{\displaystyle L}. Thus, both subsets have between 33% and 66% of the elements. Because each level of recursion reduces the problem size by a constant factor, the total time of the algorithm can be bounded by a geometric series, showing that it is O(n){\displaystyle O(n)}.


== References ==",546678,https://en.wikipedia.org/wiki/Soft_heap
Splay tree,"A splay tree is a binary search tree with the additional property that recently accessed elements are quick to access again.  Like self-balancing binary search trees, a splay tree performs basic operations such as insertion, look-up and removal in O(log n) amortized time. For random access patterns drawn from a non-uniform random distribution, their amortized time can be faster than logarithmic, proportional to the entropy of the access pattern. For many patterns of non-random operations, also, splay trees can take better than logarithmic time, without requiring advance knowledge of the pattern. According to the unproven dynamic optimality conjecture, their performance on all access patterns is within a constant factor of the best possible performance that could be achieved by any other self-adjusting binary search tree, even one selected to fit that pattern. The splay tree was invented by Daniel Sleator and Robert Tarjan in 1985.All normal operations on a binary search tree are combined with one basic operation, called splaying. Splaying the tree for a certain element rearranges the tree so that the element is placed at the root of the tree.  One way to do this with the basic search operation is to first perform a standard binary tree search for the element in question, and then use tree rotations in a specific fashion to bring the element to the top. Alternatively, a top-down algorithm can combine the search and the tree reorganization into a single phase.","A splay tree is a binary search tree with the additional property that recently accessed elements are quick to access again.  Like self-balancing binary search trees, a splay tree performs basic operations such as insertion, look-up and removal in O(log n) amortized time. For random access patterns drawn from a non-uniform random distribution, their amortized time can be faster than logarithmic, proportional to the entropy of the access pattern. For many patterns of non-random operations, also, splay trees can take better than logarithmic time, without requiring advance knowledge of the pattern. According to the unproven dynamic optimality conjecture, their performance on all access patterns is within a constant factor of the best possible performance that could be achieved by any other self-adjusting binary search tree, even one selected to fit that pattern. The splay tree was invented by Daniel Sleator and Robert Tarjan in 1985.All normal operations on a binary search tree are combined with one basic operation, called splaying. Splaying the tree for a certain element rearranges the tree so that the element is placed at the root of the tree.  One way to do this with the basic search operation is to first perform a standard binary tree search for the element in question, and then use tree rotations in a specific fashion to bring the element to the top. Alternatively, a top-down algorithm can combine the search and the tree reorganization into a single phase.

Advantages
Good performance for a splay tree depends on the fact that it is self-optimizing, in that frequently accessed nodes will move nearer to the root where they can be accessed more quickly. The worst-case height—though unlikely—is O(n), with the average being O(log n).
Having frequently-used nodes near the root is an advantage for many practical applications (also see locality of reference), and is particularly useful for implementing caches and garbage collection algorithms.
Advantages include:

Comparable performance: Average-case performance is as efficient as other trees.
Small memory footprint: Splay trees do not need to store any bookkeeping data.

Disadvantages
The most significant disadvantage of splay trees is that the height of a splay tree can be linear.: 1   For example, this will be the case after accessing all n elements in non-decreasing order.  Since the height of a tree corresponds to the worst-case access time, this means that the actual cost of a single operation can be high. However the amortized access cost of this worst case is logarithmic, O(log n).  Also, the expected access cost can be reduced to O(log n) by using a randomized variant.The representation of splay trees can change even when they are accessed in a 'read-only' manner (i.e. by find operations).  This complicates the use of such splay trees in a multi-threaded environment.  Specifically, extra management is needed if multiple threads are allowed to perform find operations concurrently. This also makes them unsuitable for general use in purely functional programming, although even there they can be used in limited ways to implement priority queues.
Finally, when the access pattern is random, the additional splaying overhead adds a significant constant factor to the cost compared to less-dynamic alternatives.

Operations
Splaying
When a node x is accessed, a splay operation is performed on x to move it to the root. A splay operation is a sequence of splay steps, each of which moves x closer to the root. By performing a splay operation on the node of interest after every access, the recently accessed nodes are kept near the root and the tree remains roughly balanced, so it provides the desired amortized time bounds.
Each particular step depends on three factors:

Whether x is the left or right child of its parent node, p,
whether p is the root or not, and if not
whether p is the left or right child of its parent, g (the grandparent of x).There are three types of splay steps, each of which has two symmetric variants: left- and right-handed. For the sake of brevity, only one of these two is shown for each type. (In the following diagrams, circles indicate nodes of interest and triangles indicate sub-trees of arbitrary size.) The three types of splay steps are:
Zig step: this step is done when p is the root. The tree is rotated on the edge between x and p. Zig steps exist to deal with the parity issue, will be done only as the last step in a splay operation, and only when x has odd depth at the beginning of the operation.

Zig-zig step: this step is done when p is not the root and x and p are either both right children or are both left children. The picture below shows the case where x and p are both left children. The tree is rotated on the edge joining p with its parent g, then rotated on the edge joining x with p. Zig-zig steps are the only thing that differentiate splay trees from the rotate to root method introduced by Allen and Munro prior to the introduction of splay trees.

Zig-zag step: this step is done when p is not the root and x is a right child and p is a left child or vice versa (x is left, p is right). The tree is rotated on the edge between p and x, and then rotated on the resulting edge between x and g.

Join
Given two trees S and T such that all elements of S are smaller than the elements of T, the following steps can be used to join them to a single tree:

Splay the largest item in S. Now this item is in the root of S and has a null right child.
Set the right child of the new root to T.

Split
Given a tree and an element x, return two new trees: one containing all elements less than or equal to x and the other containing all elements greater than x. This can be done in the following way:

Splay x. Now it is in the root so the tree to its left contains all elements smaller than x and the tree to its right contains all element larger than x.
Split the right subtree from the rest of the tree.

Insertion
To insert a value x into a splay tree:

Insert x as with a normal binary search tree.
Perform a splay on x.As a result, the newly inserted node x becomes the root of the tree.
Alternatively:

Use the split operation to split the tree at the value of x to two sub-trees: S and T.
Create a new tree in which x is the root, S is its left sub-tree and T its right sub-tree.

Deletion
To delete a node x, use the same method as with a binary search tree:

If x has two children:
Swap its value with that of either the rightmost node of its left sub tree (its in-order predecessor) or the leftmost node of its right subtree (its in-order successor).
Remove that node instead.In this way, deletion is reduced to the problem of removing a node with 0 or 1 children. Unlike a binary search tree, in a splay tree after deletion, we splay the parent of the removed node to the top of the tree.
Alternatively:

The node to be deleted is first splayed, i.e. brought to the root of the tree and then deleted.  leaves the tree with two sub trees.
The two sub-trees are then joined using a ""join"" operation.

Implementation and variants
Splaying, as mentioned above, is performed during a second, bottom-up pass over the access path of a node. It is possible to record the access path during the first pass for use during the second, but that requires extra space during the access operation.  Another alternative is to keep a parent pointer in every node, which avoids the need for extra space during access operations but may reduce overall time efficiency because of the need to update those pointers.Another method which can be used is based on the argument that the tree can be restructured during the way down the access path instead of making a second pass. This top-down splaying routine uses three sets of nodes – left tree, right tree and middle tree. The first two contain all items of original tree known to be less than or greater than current item respectively. The middle tree consists of the sub-tree rooted at the current node. These three sets are updated down the access path while keeping the splay operations in check. Another method, semisplaying, modifies the zig-zig case to reduce the amount of restructuring done in all operations.Below there is an implementation of splay trees in C++, which uses pointers to represent each node on the tree. This implementation is based on bottom-up splaying version and uses the second method of deletion on a splay tree.  Also, unlike the above definition, this C++ version does not splay the tree on finds – it only splays on insertions and deletions, and the find operation, therefore, has linear time complexity.

Analysis
A simple amortized analysis of static splay trees can be carried out using the potential method. Define:

size(r) = the number of nodes in the sub-tree rooted at node r (including r).
rank(r) = log2(size(r)).
Φ = the sum of the ranks of all the nodes in the tree.Φ will tend to be high for poorly balanced trees and low for well-balanced trees.
To apply the potential method, we first calculate ΔΦ: the change in the potential caused by a splay operation. We check each case separately. Denote by rank' the rank function after the operation. x, p and g are the nodes affected by the rotation operation (see figures above).

Zig step
Zig-zig step
Zig-zag step
The amortized cost of any operation is ΔΦ plus the actual cost. The actual cost of any zig-zig or zig-zag operation is 2 since there are two rotations to make. Hence:

When summed over the entire splay operation, this telescopes to 1 + 3(rank(root)−rank(x)) which is O(log n), since we use The Zig operation at most once and the amortized cost of zig is at most 1+3(rank'(x)−rank(x)).
So now we know that the total amortized time for a sequence of m operations is:

Tamortized(m)=O(mlog⁡n){\displaystyle T_{\mathrm {amortized} }(m)=O(m\log n)}To go from the amortized time to the actual time, we must add the decrease in potential from the initial state before any operation is done (Φi) to the final state after all operations are completed (Φf).

Φi−Φf=∑xranki(x)−rankf(x)=O(nlog⁡n){\displaystyle \Phi _{i}-\Phi _{f}=\sum _{x}{\mathrm {rank} _{i}(x)-\mathrm {rank} _{f}(x)}=O(n\log n)}where the big O notation can be justified by the fact that for every node x, the minimum rank is 0 and the maximum rank is log(n).
Now we can finally bound the actual time:

Tactual(m)=O(mlog⁡n+nlog⁡n){\displaystyle T_{\mathrm {actual} }(m)=O(m\log n+n\log n)}

Weighted analysis
The above analysis can be generalized in the following way.

Assign to each node r a weight w(r).
Define size(r) = the sum of weights of nodes in the sub-tree rooted at node r (including r).
Define rank(r) and Φ exactly as above.The same analysis applies and the amortized cost of a splaying operation is again:

1+3(rank(root)−rank(x)){\displaystyle 1+3(\mathrm {rank} (root)-\mathrm {rank} (x))}where W is the sum of all weights.
The decrease from the initial to the final potential is bounded by:

Φi−Φf≤∑x∈treelog⁡Ww(x){\displaystyle \Phi _{i}-\Phi _{f}\leq \sum _{x\in tree}{\log {\frac {W}{w(x)}}}}since the maximum size of any single node is W and the minimum is w(x).
Hence the actual time is bounded by:

O(∑x∈sequence(1+3log⁡Ww(x))+∑x∈treelog⁡Ww(x))=O(m+∑x∈sequencelog⁡Ww(x)+∑x∈treelog⁡Ww(x)){\displaystyle O\left(\sum _{x\in sequence}{\left(1+3\log {\frac {W}{w(x)}}\right)}+\sum _{x\in tree}{\log {\frac {W}{w(x)}}}\right)=O\left(m+\sum _{x\in sequence}{\log {\frac {W}{w(x)}}}+\sum _{x\in tree}{\log {\frac {W}{w(x)}}}\right)}

Performance theorems
There are several theorems and conjectures regarding the worst-case runtime for performing a sequence S of m accesses in a splay tree containing n elements.

Dynamic optimality conjecture
In addition to the proven performance guarantees for splay trees there is an unproven conjecture of great interest from the original Sleator and Tarjan paper.  This conjecture is known as the dynamic optimality conjecture and it basically claims that splay trees perform as well as any other binary search tree algorithm up to a constant factor.

Dynamic Optimality Conjecture: Let A{\displaystyle A} be any binary search tree algorithm that accesses an element x{\displaystyle x} by traversing the path from the root to x{\displaystyle x} at a cost of d(x)+1{\displaystyle d(x)+1}, and that between accesses can make any rotations in the tree at a cost of 1 per rotation.  Let A(S){\displaystyle A(S)} be the cost for A{\displaystyle A} to perform the sequence S{\displaystyle S} of accesses.  Then the cost for a splay tree to perform the same accesses is O[n+A(S)]{\displaystyle O[n+A(S)]}.There are several corollaries of the dynamic optimality conjecture that remain unproven:

Traversal Conjecture: Let T1{\displaystyle T_{1}} and T2{\displaystyle T_{2}} be two splay trees containing the same elements.  Let S{\displaystyle S} be the sequence obtained by visiting the elements in T2{\displaystyle T_{2}} in preorder (i.e., depth first search order).  The total cost of performing the sequence S{\displaystyle S} of accesses on T1{\displaystyle T_{1}} is O(n){\displaystyle O(n)}.Deque Conjecture: Let S{\displaystyle S} be a sequence of m{\displaystyle m} double-ended queue operations (push, pop, inject, eject).  Then the cost of performing S{\displaystyle S} on a splay tree is O(m+n){\displaystyle O(m+n)}.Split Conjecture: Let S{\displaystyle S} be any permutation of the elements of the splay tree.  Then the cost of deleting the elements in the order S{\displaystyle S} is O(n){\displaystyle O(n)}.

Variants
In order to reduce the number of restructuring operations, it is possible to replace the splaying with semi-splaying, in which an element is splayed only halfway towards the root.Another way to reduce restructuring is to do full splaying, but only in some of the access operations – only when the access path is longer than a threshold, or only in the first m access operations.Using pointer-compression techniques, it is possible to construct a succinct splay tree.

See also
AVL tree
B-tree
Finger tree
Geometry of binary search trees
Iacono's working set structure
Link/cut tree
List of data structures
Scapegoat tree
Splaysort, a sorting algorithm using splay trees
T-tree
Treap
Tree rotation
Trees
Zipper (data structure)

Notes
References
Albers, Susanne; Karpinski, Marek (28 February 2002). ""Randomized Splay Trees: Theoretical and Experimental Results"" (PDF). Information Processing Letters. 81 (4): 213–221. doi:10.1016/s0020-0190(01)00230-7.
Allen, Brian; Munro, Ian (October 1978). ""Self-organizing binary search trees"". Journal of the ACM. 25 (4): 526–535. doi:10.1145/322092.322094. S2CID 15967344.
Brinkmann, Gunnar; Degraer, Jan; De Loof, Karel (January 2009). ""Rehabilitation of an unloved child: semi-splaying"" (PDF). Software: Practice and Experience. 39 (1): 33–45. CiteSeerX 10.1.1.84.790. doi:10.1002/spe.v39:1. hdl:11382/102133. The results show that semi-splaying, which was introduced in the same paper as splaying, performs better than splaying under almost all possible conditions. This makes semi-splaying a good alternative for all applications where normally splaying would be applied. The reason why splaying became so prominent while semi-splaying is relatively unknown and much less studied is hard to understand.
Cole, Richard; Mishra, Bud; Schmidt, Jeanette; Siegel, Alan (January 2000). ""On the Dynamic Finger Conjecture for Splay Trees. Part I: Splay Sorting log n-Block Sequences"". SIAM Journal on Computing. 30 (1): 1–43. CiteSeerX 10.1.1.36.4558. doi:10.1137/s0097539797326988.
Cole, Richard (January 2000). ""On the Dynamic Finger Conjecture for Splay Trees. Part II: The Proof"". SIAM Journal on Computing. 30 (1): 44–85. CiteSeerX 10.1.1.36.2713. doi:10.1137/S009753979732699X.
Elmasry, Amr (April 2004). ""On the sequential access theorem and Deque conjecture for splay trees"". Theoretical Computer Science. 314 (3): 459–466. doi:10.1016/j.tcs.2004.01.019.
Goodrich, Michael; Tamassia, Roberto; Goldwasser, Michael (2014). Data Structures and Algorithms in Java (6 ed.). Wiley. p. 506. ISBN 978-1-118-77133-4.
Grinberg, Dennis; Rajagopalan, Sivaramakrishnan; Venkatesan, Ramarathnam; Wei, Victor K. (1995). ""Splay trees for data compression"". In Clarkson, Kenneth L. (ed.). Proceedings of the Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, 22–24 January 1995. San Francisco, California, USA. ACM/SIAM. pp. 522–530. Average depth of access in a splay tree is proportional to the entropy.
Knuth, Donald (1997). The Art of Computer Programming. Vol. 3: Sorting and Searching (3rd ed.). Addison-Wesley. p. 478. ISBN 0-201-89685-0. The time needed to access data in a splay tree is known to be at most a small constant multiple of the access time of a statically optimum tree, when amortized over any series of operations.
Lucas, Joan M. (1991). ""On the Competitiveness of Splay Trees: Relations to the Union-Find Problem"". On-line Algorithms: Proceedings of a DIMACS Workshop, February 11–13, 1991. Series in Discrete Mathematics and Theoretical Computer Science. Vol. 7. Center for Discrete Mathematics and Theoretical Computer Science. pp. 95–124. ISBN 0-8218-7111-0.
Pettie, Seth (2008). Splay Trees, Davenport-Schinzel Sequences, and the Deque Conjecture (PDF). Proc. 19th ACM-SIAM Symposium on Discrete Algorithms. Vol. 0707. pp. 1115–1124. arXiv:0707.2160. Bibcode:2007arXiv0707.2160P.
Sleator, Daniel D.; Tarjan, Robert E. (1985). ""Self-Adjusting Binary Search Trees"" (PDF). Journal of the ACM. 32 (3): 652–686. doi:10.1145/3828.3835. S2CID 1165848.
Sundar, Rajamani (1992). ""On the Deque conjecture for the splay algorithm"". Combinatorica. 12 (1): 95–124. doi:10.1007/BF01191208. S2CID 27422556.
Tarjan, Robert E. (1985). ""Sequential access in splay trees takes linear time"". Combinatorica. 5 (4): 367–378. doi:10.1007/BF02579253. S2CID 34757821.
Bender, Michael A.; Conway, Alex; Farach-Colton, Martin; Kuszmaul, William; Tagliavini, Guido (2023). ""Tiny Pointers"". Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA): 477–508. doi:10.1137/1.9781611977554.ch21. ISBN 978-1-61197-755-4. S2CID 244709005.

External links
NIST's Dictionary of Algorithms and Data Structures: Splay Tree
Implementations in C and Java (by Daniel Sleator)
Pointers to splay tree visualizations
Fast and efficient implementation of Splay trees
Top-Down Splay Tree Java implementation
Zipper Trees",28382,https://en.wikipedia.org/wiki/Splay_tree
Array,"An array is a systematic arrangement of similar objects, usually in rows and columns.

Things called an array include:","An array is a systematic arrangement of similar objects, usually in rows and columns.

Things called an array include:

Music
In twelve-tone and serial composition, the presentation of simultaneous twelve-tone sets such that the sums of their horizontal segments form a succession of twelve-tone aggregates
Array mbira, a musical instrument
Spiral array model, a music pitch space

Science
Astronomy
A telescope array, also called astronomical interferometer.

Biology
Various kinds of multiple biological arrays called microarrays
Visual feature array, a model for the visual cortex

Computer science
Generally, a collection of same type data items that can be selected by indices computed at run-time, including:

Array (data structure), an arrangement of items at equally spaced addresses in computer memory
Array (data type), used in a programming language to specify a variable that can be indexed
Associative array, an abstract data structure model composed of key-value pairs, often implemented as a hash table or search treeor various kinds of the above, such as:

Bit array or bit vector
Dynamic array, allocated at run time
Jagged array, an array of arrays of which the member arrays can be of different lengths
Parallel array of records, with each field stored as a separate array
Sparse array, with most elements omitted, to store a sparse matrix
Variable-length arrayor various related concepts:

Array programming, using matrix algebra notation in programs (not the same as array processing)
Array slicing, the extraction of sub-arrays of an arrayor also:

Global Arrays, a library for parallel processing
Intel Array Visualizer, a piece of scientific graphics software

Mathematics and statistics
A standard array in coding theory
An array or matrix (mathematics)
a Costas array
a Monge array
A holor
In statistics, arrays are a name for some kinds of Category:Experimental design
Intersection array a concept of category theory

Technology
Computing
Array data structure, an arrangement of data in computer memory
Asynchronous array of simple processors
Disk array, such as the RAID
Gate array, including a field-programmable gate array (FPGA)
ICL Distributed Array Processor, an array processor for the ICL
Integrated circuit packages:
Ball grid array
pin grid array
land grid array
Processor array
Programmable Array Logic (PAL), a systematic way to implement boolean functions
Reconfigurable datapath array, a flexible data processing architecture
Systolic array, a hardware architecture
Transistor array, an integrated circuit
Video Graphics Array (VGA), a display adapter and many variants thereof
Wi-Fi array, a wireless networking device

Other technologies
Antenna array
Array gain, a telecommunications parameter
Array processing of multichannel signals (not to be confused with array programming)
Color filter array, placed over an imaging array
Field emitter array, an electron source
Halbach array, an arrangement of magnets
Linear diode array used in image scanners
Microphone array
Parametric array of transducers
Phased-array optics
Photovoltaic array
Staring array, an imaging sensor
Towed array sonar

Other
A Commission of Array, a commission for mustering a militia
ARRAY, an independent film distribution company
Array Networks, a computer networking company
Array Collective, a Belfast-based artist-activist collaborative project",21565793,https://en.wikipedia.org/wiki/Array
Array (data structure),"In computer science, an array is a data structure consisting of a collection of elements (values or variables), of same memory size, each identified by at least one array index or key. An array is stored such that the position of each element can be computed from its index tuple by a mathematical formula. The simplest type of data structure is a linear array, also called one-dimensional array.
For example, an array of ten 32-bit (4-byte) integer variables, with indices 0 through 9, may be stored as ten words at memory addresses 2000, 2004, 2008, ..., 2036, (in hexadecimal: 0x7D0, 0x7D4, 0x7D8, ..., 0x7F4) so that the element with index i has the address 2000 + (i × 4).
The memory address of the first element of an array is called first address, foundation address, or base address.
Because the mathematical concept of a matrix can be represented as a two-dimensional grid, two-dimensional arrays are also sometimes called ""matrices"". In some cases the term ""vector"" is used in computing to refer to an array, although tuples rather than vectors are the more mathematically correct equivalent. Tables are often implemented in the form of arrays, especially lookup tables; the word ""table"" is sometimes used as a synonym of array.
Arrays are among the oldest and most important data structures, and are used by almost every program. They are also used to implement many other data structures, such as lists and strings. They effectively exploit the addressing logic of computers. In most modern computers and many external storage devices, the memory is a one-dimensional array of words, whose indices are their addresses. Processors, especially vector processors, are often optimized for array operations.
Arrays are useful mostly because the element indices can be computed at run time. Among other things, this feature allows a single iterative statement to process arbitrarily many elements of an array. For that reason, the elements of an array data structure are required to have the same size and should use the same data representation. The set of valid index tuples and the addresses of the elements (and hence the element addressing formula) are usually, but not always, fixed while the array is in use.
The term ""array"" may also refer to an array data type, a kind of data type provided by most high-level programming languages that consists of a collection of values or variables that can be selected by one or more indices computed at run-time. Array types are often implemented by array structures; however, in some languages they may be implemented by hash tables, linked lists, search trees, or other data structures.
The term is also used, especially in the description of algorithms, to mean associative array or ""abstract array"", a theoretical computer science model (an abstract data type or ADT) intended to capture the essential properties of arrays.","In computer science, an array is a data structure consisting of a collection of elements (values or variables), of same memory size, each identified by at least one array index or key. An array is stored such that the position of each element can be computed from its index tuple by a mathematical formula. The simplest type of data structure is a linear array, also called one-dimensional array.
For example, an array of ten 32-bit (4-byte) integer variables, with indices 0 through 9, may be stored as ten words at memory addresses 2000, 2004, 2008, ..., 2036, (in hexadecimal: 0x7D0, 0x7D4, 0x7D8, ..., 0x7F4) so that the element with index i has the address 2000 + (i × 4).
The memory address of the first element of an array is called first address, foundation address, or base address.
Because the mathematical concept of a matrix can be represented as a two-dimensional grid, two-dimensional arrays are also sometimes called ""matrices"". In some cases the term ""vector"" is used in computing to refer to an array, although tuples rather than vectors are the more mathematically correct equivalent. Tables are often implemented in the form of arrays, especially lookup tables; the word ""table"" is sometimes used as a synonym of array.
Arrays are among the oldest and most important data structures, and are used by almost every program. They are also used to implement many other data structures, such as lists and strings. They effectively exploit the addressing logic of computers. In most modern computers and many external storage devices, the memory is a one-dimensional array of words, whose indices are their addresses. Processors, especially vector processors, are often optimized for array operations.
Arrays are useful mostly because the element indices can be computed at run time. Among other things, this feature allows a single iterative statement to process arbitrarily many elements of an array. For that reason, the elements of an array data structure are required to have the same size and should use the same data representation. The set of valid index tuples and the addresses of the elements (and hence the element addressing formula) are usually, but not always, fixed while the array is in use.
The term ""array"" may also refer to an array data type, a kind of data type provided by most high-level programming languages that consists of a collection of values or variables that can be selected by one or more indices computed at run-time. Array types are often implemented by array structures; however, in some languages they may be implemented by hash tables, linked lists, search trees, or other data structures.
The term is also used, especially in the description of algorithms, to mean associative array or ""abstract array"", a theoretical computer science model (an abstract data type or ADT) intended to capture the essential properties of arrays.

History
The first digital computers used machine-language programming to set up and access array structures for data tables, vector and matrix computations, and for many other purposes. John von Neumann wrote the first array-sorting program (merge sort) in 1945, during the building of the first stored-program computer. Array indexing was originally done by self-modifying code, and later using index registers and indirect addressing. Some mainframes designed in the 1960s, such as the Burroughs B5000 and its successors, used memory segmentation to perform index-bounds checking in hardware.Assembly languages generally have no special support for arrays, other than what the machine itself provides. The earliest high-level programming languages, including FORTRAN (1957), Lisp (1958), COBOL (1960), and ALGOL 60 (1960), had support for multi-dimensional arrays, and so has C (1972). In C++ (1983), class templates exist for multi-dimensional arrays whose dimension is fixed at runtime as well as for runtime-flexible arrays.

Applications
Arrays are used to implement mathematical vectors and matrices, as well as other kinds of rectangular tables. Many databases, small and large, consist of (or include) one-dimensional arrays whose elements are records.
Arrays are used to implement other data structures, such as lists, heaps, hash tables, deques, queues, stacks, strings, and VLists. Array-based implementations of other data structures are frequently simple and space-efficient (implicit data structures), requiring little space overhead, but may have poor space complexity, particularly when modified, compared to tree-based data structures (compare a sorted array to a search tree).
One or more large arrays are sometimes used to emulate in-program dynamic memory allocation, particularly memory pool allocation. Historically, this has sometimes been the only way to allocate ""dynamic memory"" portably.
Arrays can be used to determine partial or complete control flow in programs, as a compact alternative to (otherwise repetitive) multiple IF statements. They are known in this context as control tables and are used in conjunction with a purpose built interpreter whose control flow is altered according to values contained in the array. The array may contain subroutine pointers (or relative subroutine numbers that can be acted upon by SWITCH statements) that direct the path of the execution.

Element identifier and addressing formulas
When data objects are stored in an array, individual objects are selected by an index that is usually a non-negative scalar integer. Indexes are also called subscripts. An index maps the array value to a stored object.
There are three ways in which the elements of an array can be indexed:

0 (zero-based indexing)
The first element of the array is indexed by subscript of 0.
1 (one-based indexing)
The first element of the array is indexed by subscript of 1.
n (n-based indexing)
The base index of an array can be freely chosen. Usually programming languages allowing n-based indexing also allow negative index values and other scalar data types like enumerations, or characters may be used as an array index.Using zero based indexing is the design choice of many influential programming languages, including C, Java and Lisp. This leads to simpler implementation where the subscript refers to an offset from the starting position of an array, so the first element has an offset of zero.
Arrays can have multiple dimensions, thus it is not uncommon to access an array using multiple indices. For example, a two-dimensional array A with three rows and four columns might provide access to the element at the 2nd row and 4th column by the expression A[1][3] in the case of a zero-based indexing system. Thus two indices are used for a two-dimensional array, three for a three-dimensional array, and n for an n-dimensional array.
The number of indices needed to specify an element is called the dimension, dimensionality, or rank of the array.
In standard arrays, each index is restricted to a certain range of consecutive integers (or consecutive values of some enumerated type), and the address of an element is computed by a ""linear"" formula on the indices.

One-dimensional arrays
A one-dimensional array (or single dimension array) is a type of linear array. Accessing its elements involves a single subscript which can either represent a row or column index.
As an example consider the C declaration int anArrayName[10]; which declares a one-dimensional array of ten integers. Here, the array can store ten elements of type int . This array has indices starting from zero through nine. For example, the expressions anArrayName[0] and anArrayName[9] are the first and last elements respectively.
For a vector with linear addressing, the element with index i is located at the address B + c · i, where B is a fixed base address and c a fixed constant, sometimes called the address increment or stride.
If the valid element indices begin at 0, the constant B is simply the address of the first element of the array. For this reason, the C programming language specifies that array indices always begin at 0; and many programmers will call that element ""zeroth"" rather than ""first"".
However, one can choose the index of the first element by an appropriate choice of the base address B. For example, if the array has five elements, indexed 1 through 5, and the base address B is replaced by B + 30c, then the indices of those same elements will be 31 to 35. If the numbering does not start at 0, the constant B may not be the address of any element.

Multidimensional arrays
For a multidimensional array, the element with indices i,j would have address B + c · i + d · j, where the coefficients c and d are the row and column address increments, respectively.
More generally, in a k-dimensional array, the address of an element with indices i1, i2, ..., ik is

B + c1 · i1 + c2 · i2 + … + ck · ik.For example: int a[2][3];
This means that array a has 2 rows and 3 columns, and the array is of integer type. Here we can store 6 elements they will be stored linearly but starting from first row linear then continuing with second row. The above array will be stored as a11, a12, a13, a21, a22, a23.
This formula requires only k multiplications and k additions, for any array that can fit in memory. Moreover, if any coefficient is a fixed power of 2, the multiplication can be replaced by bit shifting.
The coefficients ck must be chosen so that every valid index tuple maps to the address of a distinct element.
If the minimum legal value for every index is 0, then B is the address of the element whose indices are all zero. As in the one-dimensional case, the element indices may be changed by changing the base address B. Thus, if a two-dimensional array has rows and columns indexed from 1 to 10 and 1 to 20, respectively, then replacing B by B + c1 − 3c2 will cause them to be renumbered from 0 through 9 and 4 through 23, respectively. Taking advantage of this feature, some languages (like FORTRAN 77) specify that array indices begin at 1, as in mathematical tradition while other languages (like Fortran 90, Pascal and Algol) let the user choose the minimum value for each index.

Dope vectors
The addressing formula is completely defined by the dimension d, the base address B, and the increments c1, c2, ..., ck. It is often useful to pack these parameters into a record called the array's descriptor or stride vector or dope vector. The size of each element, and the minimum and maximum values allowed for each index may also be included in the dope vector. The dope vector is a complete handle for the array, and is a convenient way to pass arrays as arguments to procedures. Many useful array slicing operations (such as selecting a sub-array, swapping indices, or reversing the direction of the indices) can be performed very efficiently by manipulating the dope vector.

Compact layouts
Often the coefficients are chosen so that the elements occupy a contiguous area of memory. However, that is not necessary. Even if arrays are always created with contiguous elements, some array slicing operations may create non-contiguous sub-arrays from them.

There are two systematic compact layouts for a two-dimensional array. For example, consider the matrix

A=[123456789].{\displaystyle A={\begin{bmatrix}1&2&3\\4&5&6\\7&8&9\end{bmatrix}}.}In the row-major order layout (adopted by C for statically declared arrays), the elements in each row are stored in consecutive positions and all of the elements of a row have a lower address than any of the elements of a consecutive row:

In column-major order (traditionally used by Fortran), the elements in each column are consecutive in memory and all of the elements of a column have a lower address than any of the elements of a consecutive column:

For arrays with three or more indices, ""row major order"" puts in consecutive positions any two elements whose index tuples differ only by one in the last index. ""Column major order"" is analogous with respect to the first index.
In systems which use processor cache or virtual memory, scanning an array is much faster if successive elements are stored in consecutive positions in memory, rather than sparsely scattered. This is known as spatial locality, which is a type of locality of reference. Many algorithms that use multidimensional arrays will scan them in a predictable order. A programmer (or a sophisticated compiler) may use this information to choose between row- or column-major layout for each array. For example, when computing the product A·B of two matrices, it would be best to have A stored in row-major order, and B in column-major order.

Resizing
Static arrays have a size that is fixed when they are created and consequently do not allow elements to be inserted or removed. However, by allocating a new array and copying the contents of the old array to it, it is possible to effectively implement a dynamic version of an array; see dynamic array. If this operation is done infrequently, insertions at the end of the array require only amortized constant time.
Some array data structures do not reallocate storage, but do store a count of the number of elements of the array in use, called the count or size. This effectively makes the array a dynamic array with a fixed maximum size or capacity; Pascal strings are examples of this.

Non-linear formulas
More complicated (non-linear) formulas are occasionally used. For a compact two-dimensional triangular array, for instance, the addressing formula is a polynomial of degree 2.

Efficiency
Both store and select take (deterministic worst case) constant time. Arrays take linear (O(n)) space in the number of elements n that they hold.
In an array with element size k and on a machine with a cache line size of B bytes, iterating through an array of n elements requires the minimum of ceiling(nk/B) cache misses, because its elements occupy contiguous memory locations. This is roughly a factor of B/k better than the number of cache misses needed to access n elements at random memory locations. As a consequence, sequential iteration over an array is noticeably faster in practice than iteration over many other data structures, a property called locality of reference (this does not mean however, that using a perfect hash or trivial hash within the same (local) array, will not be even faster - and achievable in constant time). Libraries provide low-level optimized facilities for copying ranges of memory (such as memcpy) which can be used to move contiguous blocks of array elements significantly faster than can be achieved through individual element access. The speedup of such optimized routines varies by array element size, architecture, and implementation.
Memory-wise, arrays are compact data structures with no per-element overhead. There may be a per-array overhead (e.g., to store index bounds) but this is language-dependent. It can also happen that elements stored in an array require less memory than the same elements stored in individual variables, because several array elements can be stored in a single word; such arrays are often called packed arrays. An extreme (but commonly used) case is the bit array, where every bit represents a single element. A single octet can thus hold up to 256 different combinations of up to 8 different conditions, in the most compact form.
Array accesses with statically predictable access patterns are a major source of data parallelism.

Comparison with other data structures
Dynamic arrays or growable arrays are similar to arrays but add the ability to insert and delete elements; adding and deleting at the end is particularly efficient. However, they reserve linear (Θ(n)) additional storage, whereas arrays do not reserve additional storage.
Associative arrays provide a mechanism for array-like functionality without huge storage overheads when the index values are sparse. For example, an array that contains values only at indexes 1 and 2 billion may benefit from using such a structure. Specialized associative arrays with integer keys include Patricia tries, Judy arrays, and van Emde Boas trees.
Balanced trees require O(log n) time for indexed access, but also permit inserting or deleting elements in O(log n) time, whereas growable arrays require linear (Θ(n)) time to insert or delete elements at an arbitrary position.
Linked lists allow constant time removal and insertion in the middle but take linear time for indexed access. Their memory use is typically worse than arrays, but is still linear.

An Iliffe vector is an alternative to a multidimensional array structure. It uses a one-dimensional array of references to arrays of one dimension less. For two dimensions, in particular, this alternative structure would be a vector of pointers to vectors, one for each row(pointer on c or c++). Thus an element in row i and column j of an array A would be accessed by double indexing (A[i][j] in typical notation). This alternative structure allows jagged arrays, where each row may have a different size—or, in general, where the valid range of each index depends on the values of all preceding indices. It also saves one multiplication (by the column address increment) replacing it by a bit shift (to index the vector of row pointers) and one extra memory access (fetching the row address), which may be worthwhile in some architectures.

Dimension
The dimension of an array is the number of indices needed to select an element. Thus, if the array is seen as a function on a set of possible index combinations, it is the dimension of the space of which its domain is a discrete subset. Thus a one-dimensional array is a list of data, a two-dimensional array is a rectangle of data, a three-dimensional array a block of data, etc.
This should not be confused with the dimension of the set of all matrices with a given domain, that is, the number of elements in the array. For example, an array with 5 rows and 4 columns is two-dimensional, but such matrices form a 20-dimensional space. Similarly, a three-dimensional vector can be represented by a one-dimensional array of size three.

See also
References
External links

 Data Structures/Arrays at Wikibooks",2052,https://en.wikipedia.org/wiki/Array_(data_structure)
Array (data type),"In computer science, array is a data type that represents a collection of elements (values or variables), each selected by one or more indices (identifying keys) that can be computed at run time during program execution.  Such a collection is usually called an array variable or array value.  By analogy with the mathematical concepts vector and matrix, array types with one and two indices are often called vector type and matrix type, respectively. More generally, a multidimensional array type can be called a tensor type, by analogy with the physical concept, tensor.Language support for array types may include certain built-in array data types, some syntactic constructions (array type constructors) that the programmer may use to define such types and declare array variables, and special notation for indexing array elements.  For example, in the Pascal programming language, the declaration type MyTable = array [1..4,1..2] of integer, defines a new array data type called MyTable. The declaration var A: MyTable then defines a variable A of that type, which is an aggregate of eight elements, each being an integer variable identified by two indices. In the Pascal program, those elements are denoted A[1,1], A[1,2], A[2,1], …, A[4,2].  Special array types are often defined by the language's standard libraries.
Dynamic lists are also more common and easier to implement than dynamic arrays. Array types are distinguished from record types mainly because they allow the element indices to be computed at run time, as in the Pascal assignment A[I,J] := A[N-I,2*J].  Among other things, this feature allows a single iterative statement to process arbitrarily many elements of an array variable.
In more theoretical contexts, especially in type theory and in the description of abstract algorithms, the terms ""array"" and ""array type"" sometimes refer to an abstract data type (ADT) also called abstract array or may refer to an associative array, a mathematical model with the basic operations and behavior of a typical array type in most languages –  basically, a collection of elements that are selected by indices computed at run-time.
Depending on the language, array types may overlap (or be identified with) other data types that describe aggregates of values, such as lists and strings.  Array types are often implemented by array data structures, but sometimes by other means, such as hash tables, linked lists, or search trees.","In computer science, array is a data type that represents a collection of elements (values or variables), each selected by one or more indices (identifying keys) that can be computed at run time during program execution.  Such a collection is usually called an array variable or array value.  By analogy with the mathematical concepts vector and matrix, array types with one and two indices are often called vector type and matrix type, respectively. More generally, a multidimensional array type can be called a tensor type, by analogy with the physical concept, tensor.Language support for array types may include certain built-in array data types, some syntactic constructions (array type constructors) that the programmer may use to define such types and declare array variables, and special notation for indexing array elements.  For example, in the Pascal programming language, the declaration type MyTable = array [1..4,1..2] of integer, defines a new array data type called MyTable. The declaration var A: MyTable then defines a variable A of that type, which is an aggregate of eight elements, each being an integer variable identified by two indices. In the Pascal program, those elements are denoted A[1,1], A[1,2], A[2,1], …, A[4,2].  Special array types are often defined by the language's standard libraries.
Dynamic lists are also more common and easier to implement than dynamic arrays. Array types are distinguished from record types mainly because they allow the element indices to be computed at run time, as in the Pascal assignment A[I,J] := A[N-I,2*J].  Among other things, this feature allows a single iterative statement to process arbitrarily many elements of an array variable.
In more theoretical contexts, especially in type theory and in the description of abstract algorithms, the terms ""array"" and ""array type"" sometimes refer to an abstract data type (ADT) also called abstract array or may refer to an associative array, a mathematical model with the basic operations and behavior of a typical array type in most languages –  basically, a collection of elements that are selected by indices computed at run-time.
Depending on the language, array types may overlap (or be identified with) other data types that describe aggregates of values, such as lists and strings.  Array types are often implemented by array data structures, but sometimes by other means, such as hash tables, linked lists, or search trees.

History
Heinz Rutishauser's programming language Superplan (1949–1951) included multi-dimensional arrays. Rutishauser however although describing how a compiler for his language should be built, did not implement one.
Assembly languages and low-level languages like BCPL generally have no syntactic support for arrays.
Because of the importance of array structures for efficient computation, the earliest high-level programming languages, including FORTRAN (1957), COBOL (1960), and Algol 60 (1960), provided support for multi-dimensional arrays.

Abstract arrays
An array data structure can be mathematically modeled as an abstract data structure (an abstract array) with two operations

get(A, I): the data stored in the element of the array A whose indices are the integer tuple I.
set(A,I,V): the array that results by setting the value of that element to V.These  operations are required to satisfy the axioms
get(set(A,I, V), I) = V
get(set(A,I, V), J) = get(A, J) if I ≠ Jfor any array state A, any value V, and any tuples I, J for which the operations are defined.
The first axiom means that each element behaves like a variable.  The second axiom means that elements with distinct indices behave as disjoint variables, so that storing a value in one element does not affect the value of any other element.
These axioms do not place any constraints on the set of valid index tuples I, therefore this abstract model can be used for triangular matrices and other oddly-shaped arrays.

Implementations
In order to effectively implement variables of such types as array structures (with indexing done by pointer arithmetic), many languages restrict the indices to integer data types (or other types that can be interpreted as integers, such as bytes and enumerated types), and require that all elements have the same data type and storage size.  Most of those languages also restrict each index to a finite interval of integers, that remains fixed throughout the lifetime of the array variable.  In some compiled languages, in fact, the index ranges may have to be known at compile time.
On the other hand, some programming languages provide more liberal array types, that allow indexing by arbitrary values, such as floating-point numbers, strings, objects, references, etc.. Such index values cannot be restricted to an interval, much less a fixed interval.  So, these languages usually allow arbitrary new elements to be created at any time.  This choice precludes the implementation of array types as array data structures.  That is, those languages use array-like syntax to implement a more general associative array semantics, and must therefore be implemented by a hash table or some other search data structure.

Language support
Multi-dimensional arrays
The number of indices needed to specify an element is called the dimension, dimensionality, or rank of the array type.  (This nomenclature conflicts with the concept of dimension in linear algebra, which expresses the shape of a matrix. Thus, an array of numbers with 5 rows and 4 columns, hence 20 elements, is said to have dimension 2 in computing contexts, but represents a matrix that is said to be 4×5-dimensional. Also, the computer science meaning of ""rank"" conflicts with the notion of tensor rank, which is a generalization of the linear algebra concept of rank of a matrix.)

Many languages support only one-dimensional arrays. In those languages, a multi-dimensional array is typically represented by an Iliffe vector, a one-dimensional array of references to arrays of one dimension less. A two-dimensional array, in particular, would be implemented as a vector of pointers to its rows.  Thus an element in row i and column j of an array A would be accessed by double indexing (A[i][j] in typical notation).  This way of emulating multi-dimensional arrays allows the creation of jagged arrays, where each row may have a different size –  or, in general, where the valid range of each index depends on the values of all preceding indices.
This representation for multi-dimensional arrays is quite prevalent in C and C++ software.  However, C and C++ will use a linear indexing formula for multi-dimensional arrays that are declared with compile time constant size, e.g. by int A[10][20] or int A[m][n], instead of the traditional int **A.

Indexing notation
Most programming languages that support arrays support the store and select operations, and have special syntax for indexing.  Early languages used parentheses, e.g. A(i,j), as in FORTRAN; others choose square brackets, e.g. A[i,j] or A[i][j], as in Algol 60 and Pascal (to distinguish from the use of parentheses for function calls).

Index types
Array data types are most often implemented as array structures: with the indices restricted to integer (or totally ordered) values, index ranges fixed at array creation time, and multilinear element addressing. This was the case in most ""third generation"" languages, and is still the case of most systems programming languages such as Ada, C, and C++. In some languages, however, array data types have the semantics of associative arrays, with indices of arbitrary type and dynamic element creation. This is the case in some scripting languages such as Awk and Lua, and of some array types provided by standard C++ libraries.

Bounds checking
Some languages (like Pascal and Modula) perform bounds checking on every access, raising an exception or aborting the program when any index is out of its valid range. Compilers may allow these checks to be turned off to trade safety for speed. Other languages (like FORTRAN and C) trust the programmer and perform no checks.  Good compilers may also analyze the program to determine the range of possible values that the index may have, and this analysis may lead to bounds-checking elimination.

Index origin
Some languages, such as C, provide only zero-based array types, for which the minimum valid value for any index is 0.  This choice is convenient for array implementation and address computations.  With a language such as C, a pointer to the interior of any array can be defined that will symbolically act as a pseudo-array that accommodates negative indices.  This works only because C does not check an index against bounds when used.
Other languages provide only one-based array types, where each index starts at 1; this is the traditional convention in mathematics for matrices and mathematical sequences.  A few languages, such as Pascal and Lua, support n-based array types,  whose minimum legal indices are chosen by the programmer.  The relative merits of each choice have been the subject of heated debate.  Zero-based indexing can avoid off-by-one or fencepost errors, specifically a 0-based for (i = 0; i < 5; i += 1) iterates (5-0) times, whereas in the equivalent 1-based half-open range for (i = 1; i < 6; i += 1) the 6 is itself a potential such error, typically requiring length() + 1, and the 1-based inclusive range for (i = 1; i <= 5; i+= 1) iterates (5-1)+1 times.

Highest index
The relation between numbers appearing in an array declaration and the index of that array's last element also varies by language. In many languages (such as C), one should specify the number of elements contained in the array; whereas in others (such as Pascal and Visual Basic .NET) one should specify the numeric value of the index of the last element. Needless to say, this distinction is immaterial in languages where the indices start at 1, such as Lua.

Array algebra
Some programming languages support array programming, where operations and functions defined for certain data types are implicitly extended to arrays of elements of those types. Thus one can write A+B to add corresponding elements of two arrays A and B.  Usually these languages provide both the element-by-element multiplication and the standard matrix product of linear algebra, and which of these is represented by the * operator varies by language.
Languages providing array programming capabilities have proliferated since the innovations in this area of  APL.  These are core capabilities of domain-specific languages such as
GAUSS, IDL, Matlab, and Mathematica. They are a core facility in newer languages, such as Julia and recent versions of Fortran. These capabilities are also provided via standard extension libraries for other general purpose programming languages (such as the widely used NumPy library for Python).

String types and arrays
Many languages provide a built-in string data type, with specialized notation (""string literals"") to build values of that type. In some languages (such as C), a string is just an array of characters, or is handled in much the same way.  Other languages, like Pascal, may provide vastly different operations for strings and arrays.

Array index range queries
Some programming languages provide operations that return the size (number of elements) of a vector, or, more generally, range of each index of an array.  In C and C++ arrays do not support the size function, so programmers often have to declare separate variable to hold the size, and pass it to procedures as a separate parameter.
Elements of a newly created array may have undefined values (as in C), or may be defined to have a specific ""default"" value such as 0 or a null pointer (as in Java).
In C++ a std::vector object supports the store, select, and append operations with the performance characteristics discussed above. Vectors can be queried for their size and can be resized. Slower operations like inserting an element in the middle are also supported.

Slicing
An array slicing operation takes a subset of the elements of an array-typed entity (value or variable) and then assembles them as another array-typed entity, possibly with other indices. If array types are implemented as array structures, many useful slicing operations (such as selecting a sub-array, swapping indices, or reversing the direction of the indices) can be performed very efficiently by manipulating the dope vector of the structure.  The possible slicings depend on the implementation details: for example, FORTRAN allows slicing off one column of a matrix variable, but not a row, and treat it as a vector; whereas C allow slicing off a row from a matrix, but not a column.
On the other hand, other slicing operations are possible when array types are implemented in other ways.

Resizing
Some languages allow dynamic arrays (also called resizable, growable, or extensible): array variables whose index ranges may be expanded at any time after creation,  without changing the values of its current elements.
For one-dimensional arrays, this facility may be provided as an operation ""append(A,x)"" that increases the size of the array A by one and then sets the value of the last element to x.  Other array types (such as Pascal strings) provide a concatenation operator, which can be used together with slicing to achieve that effect and more. In some languages, assigning a value to an element of an array automatically extends the array, if necessary, to include that element. In other array types, a slice can be replaced by an array of different size, with subsequent elements being renumbered accordingly –  as in Python's list assignment ""A[5:5] = [10,20,30]"", that inserts three new elements (10,20, and 30) before element ""A[5]"".  Resizable arrays are conceptually similar to lists, and the two concepts are synonymous in some languages.
An extensible array can be implemented as a fixed-size array, with a counter that records how many elements are actually in use.  The append operation merely increments the counter; until the whole array is used, when the append operation may be defined to fail. This is an implementation of a dynamic array with a fixed capacity, as in the string type of Pascal. Alternatively, the append operation may re-allocate the underlying array with a larger size, and copy the old elements to the new area.

See also
Array access analysis
Array database management system
Bounds-checking elimination
Delimiter-separated values
Index checking
Parallel array
Sparse array
Variable-length array

References
External links

NIST's Dictionary of Algorithms and Data Structures: Array",22817874,https://en.wikipedia.org/wiki/Array_(data_type)
Tensor (machine learning),"Tensor informally refers in machine learning to two different concepts that organize and represent data. Data may be organized in a multidimensional array (M-way array) that is informally referred to as a ""data tensor"";  however in the strict mathematical sense, a tensor is a multilinear mapping over a set of domain vector spaces to a range vector space.  Observations, such as images, movies, volumes, sounds, and relationships among words and concepts, stored in an M-way array (""data tensor"") may be analyzed either by artificial neural networks or tensor methods.Tensor decomposition can factorize data tensors into smaller tensors. Operations on data tensors can be expressed in terms of matrix multiplication and the Kronecker product.  The computation of gradients, an important aspect of the backpropagation algorithm, can be performed using PyTorch and TensorFlow.Computations are often performed on graphics processing units (GPUs) using CUDA and on dedicated hardware such as Google's Tensor Processing Unit or Nvidia's Tensor core. These developments have greatly accelerated neural network architectures and increased the size and complexity of models that can be trained.","Tensor informally refers in machine learning to two different concepts that organize and represent data. Data may be organized in a multidimensional array (M-way array) that is informally referred to as a ""data tensor"";  however in the strict mathematical sense, a tensor is a multilinear mapping over a set of domain vector spaces to a range vector space.  Observations, such as images, movies, volumes, sounds, and relationships among words and concepts, stored in an M-way array (""data tensor"") may be analyzed either by artificial neural networks or tensor methods.Tensor decomposition can factorize data tensors into smaller tensors. Operations on data tensors can be expressed in terms of matrix multiplication and the Kronecker product.  The computation of gradients, an important aspect of the backpropagation algorithm, can be performed using PyTorch and TensorFlow.Computations are often performed on graphics processing units (GPUs) using CUDA and on dedicated hardware such as Google's Tensor Processing Unit or Nvidia's Tensor core. These developments have greatly accelerated neural network architectures and increased the size and complexity of models that can be trained.

History
A tensor is by definition a multilinear map. In mathematics, this may express a multilinear relationship between sets of algebraic objects. In physics, tensor fields, considered as tensors at each point in space, are useful in expressing mechanics such as stress or elasticity. In machine learning, the exact use of tensors depends on the statistical approach being used.
In 2001, the field of signal processing and statistics were making use of tensor methods. Pierre Comon surveys the early adoption of tensor methods in the fields of telecommunications, radio surveillance, chemometrics and sensor processing. Linear tensor rank methods (such as, Parafac/CANDECOMP) analyzed M-way arrays (""data tensors"") composed of higher order statistics that were employed in blind source separation problems to compute a linear model of the data. He noted several early limitations in determining the tensor rank and efficient tensor rank decomposition.In the early 2000s, multilinear tensor methods crossed over into computer vision, computer graphics and machine learning with papers by Vasilescu  or in collaboration with Terzopoulos, such as Human Motion Signatures, TensorFaces  TensorTexures and Multilinear Projection.  Multilinear algebra, the algebra of higher-order tensors, is a suitable and transparent framework for analyzing the multifactor structure of an ensemble of observations and for addressing the difficult problem of disentangling the causal factors based on second order or higher order statistics associated with each causal factor.Tensor (multilinear) factor analysis disentangles and reduces the influence of different causal factors with multilinear subspace learning.  
When treating an image or a video as a 2- or 3-way array, i.e., ""data matrix/tensor"",  tensor methods reduce spatial or time redundancies as demonstrated by Wang and Ahuja.Yoshua Bengio,
Geoff Hinton
 and their collaborators briefly discuss the relationship between deep neural networks 
and tensor factor analysis beyond the use of M-way arrays (""data tensors"") as inputs.   One of the early uses of tensors for neural networks appeared in natural language processing. A single word can be expressed as a vector via Word2vec. Thus a relationship between two words can be encoded in a matrix. However, for more complex relationships such as subject-object-verb, it is necessary to build higher-dimensional networks. In 2009, the work of Sutsekver introduced Bayesian Clustered Tensor Factorization to model relational concepts while reducing the parameter space. From 2014 to 2015, tensor methods become more common in convolutional neural networks (CNNs). Tensor methods organize neural network weights in a ""data tensor"", analyze and reduce the number of neural network weights.  Lebedev et al. accelerated CNN networks for character classification (the recognition of letters and digits in images) by using 4D kernel tensors.

Definition
Let F{\displaystyle \mathbb {F} } be a field such as the real numbers R{\displaystyle \mathbb {R} } or the complex numbers C{\displaystyle \mathbb {C} }. A tensor A{\displaystyle {\mathcal {A}}} is an I0×I1×⋯×IC{\displaystyle I_{0}\times I_{1}\times \cdots \times I_{C}} array over F{\displaystyle \mathbb {F} }:

A∈FI0×I1×…×IC.{\displaystyle {\mathcal {A}}\in {\mathbb {F} }^{I_{0}\times I_{1}\times \ldots \times I_{C}}.}Here, C{\displaystyle C} and I1,I2,…,IC{\displaystyle I_{1},I_{2},\ldots ,I_{C}} are positive integers, and C{\displaystyle C} is the number of dimensions, number of ways, or mode of the tensor.One basic approach (not the only way) to using tensors in machine learning is to embed various data types directly. For example, a grayscale image, commonly represented as a discrete 2D function f(x,y){\displaystyle f(x,y)} with resolution N×M{\displaystyle N\times M} may be embedded in a mode-2 tensor as

f(x,y)↦A∈RN×M.{\displaystyle f(x,y)\mapsto {\mathcal {A}}\in \mathbb {R} ^{N\times M}.}A color image with 3 channels for RGB might be embedded in a mode-3 tensor with three elements in an additional dimension:

fRGB(x,y)↦A∈RN×M×3.{\displaystyle f_{RGB}(x,y)\mapsto {\mathcal {A}}\in \mathbb {R} ^{N\times M\times 3}.}In natural language processing, a word might be expressed as a vector v{\displaystyle v} via the Word2vec algorithm. Thus v{\displaystyle v} becomes a mode-1 tensor

v↦A∈RN.{\displaystyle v\mapsto {\mathcal {A}}\in \mathbb {R} ^{N}.}The embedding of subject-object-verb semantics requires embedding relationships among three words. Because a word is itself a vector, subject-object-verb semantics could be expressed using mode-3 tensors

va×vb×vc↦A∈RN×N×N.{\displaystyle v_{a}\times v_{b}\times v_{c}\mapsto {\mathcal {A}}\in \mathbb {R} ^{N\times N\times N}.}In practice the neural network designer is primarily concerned with the specification of embeddings, the connection of tensor layers, and the operations performed on them in a network. Modern machine learning frameworks manage the optimization, tensor factorization and backpropagation automatically.

As unit values
Tensors may be used as the unit values of neural networks which extend the concept of scalar, vector and matrix values to multiple dimensions.
The output value of single layer unit ym{\displaystyle y_{m}} is the sum-product of its input units and the connection weights filtered through the activation function f{\displaystyle f}:

ym=f(∑nxnum,n),{\displaystyle y_{m}=f\left(\sum _{n}x_{n}u_{m,n}\right),}where

ym∈R.{\displaystyle y_{m}\in \mathbb {R} .}If each output element of ym{\displaystyle y_{m}} is a scalar, then we have the classical definition of an artificial neural network. By replacing each unit component with a tensor, the network is able to express higher dimensional data such as images or videos:

ym∈RI0×I1×..×IC.{\displaystyle y_{m}\in \mathbb {R} ^{I_{0}\times I_{1}\times ..\times I_{C}}.}This use of tensors to replace unit values is common in convolutional neural networks where each unit might be an image processed through multiple layers. By embedding the data in tensors such network structures enable learning of complex data types.

In fully connected layers
Tensors may also be used to compute the layers of a fully connected neural network, where the tensor is applied to the entire layer instead of individual unit values.
The output value of single layer unit ym{\displaystyle y_{m}} is the sum-product of its input units and the connection weights filtered through the activation function f{\displaystyle f}:

ym=f(∑nxnum,n).{\displaystyle y_{m}=f\left(\sum _{n}x_{n}u_{m,n}\right).}The vectors x{\displaystyle x} and y{\displaystyle y} of output values can be expressed as a mode-1 tensors, while the hidden weights can be expressed as a mode-2 tensor. In this example the unit values are scalars while the tensor takes on the dimensions of the network layers:

xn↦X∈R1×N,{\displaystyle x_{n}\mapsto {\mathcal {X}}\in \mathbb {R} ^{1\times N},}
yn↦Y∈RM×1,{\displaystyle y_{n}\mapsto {\mathcal {Y}}\in \mathbb {R} ^{M\times 1},}
un↦U∈RN×M.{\displaystyle u_{n}\mapsto {\mathcal {U}}\in \mathbb {R} ^{N\times M}.}In this notation, the output values can be computed as a tensor product of the input and weight tensors:

Y=f(XU).{\displaystyle {\mathcal {Y}}=f({\mathcal {X}}{\mathcal {U}}).}which computes the sum-product as a tensor multiplication (similar to matrix multiplication).
This formulation of tensors enables the entire layer of a fully connected network to be efficiently computed by mapping the units and weights to tensors.

In convolutional layers
A different reformulation of neural networks allows tensors to express the convolution layers of a neural network. A convolutional layer has multiple inputs, each of which is a spatial structure such as an image or volume. The inputs are convolved by filtering before being passed to the next layer. A typical use is to perform feature detection or isolation in image recognition.
Convolution is often computed as the multiplication of an input signal g{\displaystyle g} with a filter kernel f{\displaystyle f}. In two dimensions the discrete, finite form is:

(f∗g)x,y=∑j=−ww∑k=−wwfj,kgx+j,y+k,{\displaystyle (f*g)_{x,y}=\sum _{j=-w}^{w}\sum _{k=-w}^{w}f_{j,k}g_{x+j,y+k},}where w{\displaystyle w} is the width of the kernel. 
This definition can be rephrased as a matrix-vector product in terms of tensors that express the kernel, data and inverse transform of the kernel.
Y=A[(Cg)⊙(Bd)],{\displaystyle {\mathcal {Y}}={\mathcal {A}}[(Cg)\odot (Bd)],}where A,B{\displaystyle {\mathcal {A}},{\mathcal {B}}} and C{\displaystyle {\mathcal {C}}} are the inverse transform, data and kernel. The derivation is more complex when the filtering kernel also includes a non-linear activation function such as sigmoid or ReLU.
The hidden weights of the convolution layer are the parameters to the filter. These can be reduced with a pooling layer which reduces the resolution (size) of the data, and can also be expressed as a tensor operation.

Tensor factorization
An important contribution of tensors in machine learning is the ability to factorize tensors to decompose data into constituent factors or reduce the learned parameters. Data tensor modeling techniques stem from the linear tensor decomposition (CANDECOMP/Parafac decomposition) and the multilinear tensor decompositions (Tucker).

Tucker decomposition
Tucker decomposition, for example, takes a 3-way array X∈RI×J×K{\displaystyle {\mathcal {X}}\in \mathbb {R} ^{I\times J\times K}} 
and decomposes the tensor into three matrices A,B,C{\displaystyle {\mathcal {A,B,C}}} and a smaller tensor G{\displaystyle {\mathcal {G}}}. The shape of the matrices and new tensor are such that the total number of elements is reduced. The new tensors have shapes

A∈RI×P,{\displaystyle {\mathcal {A}}\in \mathbb {R} ^{I\times P},}
B∈RJ×Q,{\displaystyle {\mathcal {B}}\in \mathbb {R} ^{J\times Q},}
C∈RK×R,{\displaystyle {\mathcal {C}}\in \mathbb {R} ^{K\times R},}
G∈RP×Q×R.{\displaystyle {\mathcal {G}}\in \mathbb {R} ^{P\times Q\times R}.}Then the original tensor can be expressed as the tensor product of these four tensors:

X=G×A×B×C.{\displaystyle {\mathcal {X}}={\mathcal {G}}\times {\mathcal {A}}\times {\mathcal {B}}\times {\mathcal {C}}.}In the example shown in the figure, the dimensions of the tensors are

X{\displaystyle {\mathcal {X}}}: I=8, J=6, K=3, A{\displaystyle {\mathcal {A}}}: I=8, P=5, B{\displaystyle {\mathcal {B}}}: J=6, Q=4, C{\displaystyle {\mathcal {C}}}: K=3, R=2, G{\displaystyle {\mathcal {G}}}: P=5, Q=4, R=2.The total number of elements in the Tucker factorization is

|A|+|B|+|C|+|G|={\displaystyle |{\mathcal {A}}|+|{\mathcal {B}}|+|{\mathcal {C}}|+|{\mathcal {G}}|=}
(I×P)+(J×Q)+(K×R)+(P×Q×R)=8×5+6×4+3×2+5×4×2=110.{\displaystyle (I\times P)+(J\times Q)+(K\times R)+(P\times Q\times R)=8\times 5+6\times 4+3\times 2+5\times 4\times 2=110.}The number of elements in the original X{\displaystyle {\mathcal {X}}} is 144, resulting in a data reduction from 144 down to 110 elements, a reduction of 23% in parameters or data size. For much larger initial tensors, and depending on the rank (redundancy) of the tensor, the gains can be more significant.
The work of Rabanser et al. provides an introduction to tensors with more details on the extension of Tucker decomposition to N-dimensions beyond the mode-3 example given here.

Tensor trains
Another technique for decomposing tensors rewrites the initial tensor as a sequence (train) of smaller sized tensors. A tensor-train (TT) is a sequence of tensors of reduced rank, called canonical factors. The original tensor can be expressed as the sum-product of the sequence.

X=G1G2G3..Gd{\displaystyle {\mathcal {X}}={\mathcal {G_{1}}}{\mathcal {G_{2}}}{\mathcal {G_{3}}}..{\mathcal {G_{d}}}}Developed in 2011 by Ivan Oseledts, the author observes that Tucker decomposition is ""suitable for small dimensions, especially for the three-dimensional case. For large d it is not suitable."" Thus tensor-trains can be used to factorize larger tensors in higher dimensions.

Tensor graphs
The unified data architecture and automatic differentiation of tensors has enabled higher-level designs of machine learning in the form of tensor graphs. This leads to new architectures, such as tensor-graph convolutional networks (TGCN), which identify highly non-linear associations in data, combine multiple relations, and scale gracefully, while remaining robust and performant.These developments are impacting all areas of machine learning, such as text mining and clustering, time varying data, and neural networks wherein the input data is a social graph and the data changes dynamically.

Hardware
Tensors provide a unified way to train neural networks for more complex data sets. However, training is expensive to compute on classical CPU hardware.
In 2014, Nvidia developed cuDNN, CUDA Deep Neural Network, a library for a set of optimized primitives written in the parallel CUDA language. CUDA and thus cuDNN run on dedicated GPUs that implement unified massive parallelism in hardware. These GPUs were not yet dedicated chips for tensors, but rather existing hardware adapted for parallel computation in machine learning.
In the period 2015–2017 Google invented the Tensor Processing Unit (TPU). TPUs are dedicated, fixed function hardware units that specialize in the matrix multiplications needed for tensor products. Specifically, they implement an array of 65,536 multiply units that can perform a 256x256 matrix sum-product in just one global instruction cycle.Later in 2017, Nvidia released its own Tensor Core with the Volta GPU architecture. Each Tensor Core is a microunit that can perform a 4x4 matrix sum-product. There are eight tensor cores for each shared memory (SM) block. The first GV100 GPU card has 108 SMs resulting in 672 tensor cores. This device accelerated machine learning by 12x over the previous Tesla GPUs. The number of tensor cores scales as the number of cores and SM units continue to grow in each new generation of cards.
The development of GPU hardware, combined with the unified architecture of tensor cores, has enabled the training of much larger neural networks. In 2022, the largest neural network was Google's PaLM with 540 billion learned parameters (network weights) (the older GPT-3 language model has over 175 billion learned parameters that produces human-like text; size isn't everything, Stanford's much smaller 2023 Alpaca model claims to be better, having learned from Meta/Facebook's 2023 model LLaMA, the smaller 7 billion parameter variant). The widely popular chatbot ChatGPT is built on top of GPT-3.5 (and after an update GPT-4) using supervised and reinforcement learning.


== References ==",73050688,https://en.wikipedia.org/wiki/Tensor_(machine_learning)
Array slicing,"In computer programming, array slicing is an operation that extracts a subset of elements from an array and packages them as another array, possibly in a different dimension from the original. 
Common examples of array slicing are extracting a substring from a string of characters, the ""ell"" in ""hello"", extracting a row or column from a two-dimensional array, or extracting a vector from a matrix.
Depending on the programming language, an array slice can be made out of non-consecutive elements.  Also depending on the language, the elements of the new array may be aliased to (i.e., share memory with) those of the original array.","In computer programming, array slicing is an operation that extracts a subset of elements from an array and packages them as another array, possibly in a different dimension from the original. 
Common examples of array slicing are extracting a substring from a string of characters, the ""ell"" in ""hello"", extracting a row or column from a two-dimensional array, or extracting a vector from a matrix.
Depending on the programming language, an array slice can be made out of non-consecutive elements.  Also depending on the language, the elements of the new array may be aliased to (i.e., share memory with) those of the original array.

Details
For ""one-dimensional"" (single-indexed) arrays –  vectors, sequence, strings etc. –  the most common slicing operation is extraction of zero or more consecutive elements. Thus, if we have a vector containing elements (2, 5, 7, 3, 8, 6, 4, 1), and we want to create an array slice from the 3rd to the 6th items, we get (7, 3, 8, 6). In programming languages that use a 0-based indexing scheme, the slice would be from index 2 to 5.
Reducing the range of any index to a single value effectively eliminates that index. This feature can be used, for example, to extract one-dimensional slices (vectors: in 3D, rows, columns, and tubes) or two-dimensional slices (rectangular matrices) from a  three-dimensional array. However, since the range can be specified at run-time, type-checked languages may require an explicit (compile-time) notation to actually eliminate the trivial indices.
General array slicing can be implemented (whether or not built into the language) by referencing every array through a dope vector or descriptor –  a record that contains the address of the first array element, and then the range of each index and the corresponding coefficient in the indexing formula. This technique also allows immediate array transposition, index reversal, subsampling, etc. For languages like C, where the indices always start at zero, the dope vector of an array with d indices has at least 1 + 2d parameters. For languages that allow arbitrary lower bounds for indices, like Pascal, the dope vector needs 1 + 3d entries.
If the array abstraction does not support true negative indices (as for example the arrays of Ada and Pascal do), then negative indices for the bounds of the slice for a given dimension are sometimes used to specify an offset from the end of the array in that dimension. In 1-based schemes, -1 generally would indicate the second-to-last item, while in a 0-based system, it would mean the very last item.

History
The concept of slicing was surely known even before the invention of compilers. Slicing as a language feature probably started with FORTRAN (1957), more as a consequence of non-existent type and range checking than by design. The concept was also alluded to in the preliminary report for the IAL (ALGOL 58) in that the syntax allowed one or more indices of an array element (or, for that matter, of a procedure call) to be omitted when used as an actual parameter.
Kenneth Iverson's APL (1957) had very flexible multi-dimensional array slicing, which contributed much to the language's expressive power and popularity.
ALGOL 68 (1968) introduced comprehensive multi-dimension array slicing and trimming features.
Array slicing facilities have been incorporated in several modern languages, such as Ada 2005, Cobra, D, Fortran 90, Go, Rust, Julia, MATLAB, Perl, Python, S-Lang, Windows PowerShell and the mathematical/statistical languages GNU Octave, S and R.

Timeline of slicing in various programming languages
1964: PL/I
PL/I provides two facilities for array slicing.

Using iSub DEFINING, an array slice can be declared using iSUB variables to map specific elements in a ""base array"" onto elements of the ""defined array"". iSUBs can define rows, columns, diagonals, or many-to-one mappings.: pp.212–213  The following example defines Y as a one-dimensional slice consisting of the diagonal elements of the two-dimensional array X.DECLARE X(5,5);
DECLARE Y(5) DEFINED(X(1SUB,1SUB));
A reference to Y(2) is a reference to X(2,2), and so on.

A slice, called a cross-section, of an array can be referred to by using asterisk as the subscript for one or more dimensions. The following code sets all the elements in the first column of X to zero. One or more subscripts can be specified by asterisks in an expression.: p.43 DECLARE X(5,5);
X(*,1)=0;

1966: Fortran 66
The Fortran 66 programmers were only able to take advantage of slicing matrices by row, and then only when passing that row to a subroutine:

Result:

   2.000000       4.000000       8.000000

Note that there is no dope vector in FORTRAN 66 hence the length of the slice must also be passed as an argument - or some other means - to the SUBROUTINE. 1970s Pascal and C had similar restrictions.

1968: Algol 68
Algol68 final report contains an early example of slicing, slices are specified in the form:

[lower bound:upper bound] ¢ for computers with extended character sets ¢

or:

(LOWER BOUND..UPPER BOUND) # FOR COMPUTERS WITH ONLY 6 BIT CHARACTERS. #

Both bounds are inclusive and can be omitted, in which case they default to the declared array bounds. Neither the stride facility, nor diagonal slice aliases are part of the revised report.
Examples:

[3, 3]real a := ((1, 1, 1), (2, 4, 8), (3, 9, 27)); # declaration of a variable matrix #
[,]  real c = ((1, 1, 1), (2, 4, 8), (3, 9, 27));   # constant matrix, the size is implied #

ref[]real row := a[2,];                    # alias/ref to a row slice #
ref[]real col2 = a[, 2];                   # permanent alias/ref to second column #

print ((a[:, 2], newline));                # second column slice #
print ((a[1⌈a, :], newline));              # last row slice #
print ((a[:, 2⌈a], newline));              # last column slice #
print ((a[:2, :2], newline));              # leading 2-by-2 submatrix ""slice"" #

+1.000010+0 +4.000010+0 +9.000010+0
+3.000010+0 +9.000010+0 +2.700010+1
+1.000010+0 +8.000010+0 +2.700010+1
+1.000010+0 +1.000010+0 +2.000010+0 +4.000010+0

1968: BASIC
HP's HP 2000 systems, introduced in November 1968, used HP Time-Shared BASIC as their primary interface and programming language. This version of BASIC used slicing for most string manipulation operations. One oddity of the language was that it allowed round or square braces interchangeably, and which was used in practice was typically a function of the computer terminal being used.
Example:

Will produce:

HELLO
WORLD

The HP systems were widely used in the early 1970s, especially in technical high schools and many small industrial and scientific settings. As the first microcomputers emerged in the mid-1970s, HP was often used as the pattern for their BASIC dialects as well. Notable examples include 1977's Apple BASIC, 1978's Atari BASIC, and 1979's Sinclair BASIC. This style of manipulation generally offers advantages in terms of memory use, and was often chosen on systems that shipped with small amounts of memory. Only Sinclair's dialect differed in any meaningful way, using the TO keyword instead of a comma-separated list:

Slicing was also selected as the basis for the ANSI Full BASIC standard, using the colon as the separator and thus differentiating between slicing and array access:

While this style of access offered a number of advantages, especially for the small machines of the era, sometime after 1970 Digital Equipment Corporation introduced their own variation of BASIC that used the LEFT$, RIGHT$ and MID$ string functions. Microsoft BASIC was written on the PDP-10 and its BASIC was used as the pattern. Through the late 1970s the two styles were both widely used, but by the early 1980s the DEC-style functions were the de facto standard.

1970s: MATLAB
1976: S/R
Arrays in S and GNU R are always one-based, thus the indices of a new slice will begin with one for each dimension, regardless of the previous indices. Dimensions with length of one will be dropped (unless drop = FALSE). Dimension names (where present) will be preserved.

1977: Fortran 77
The Fortran 77 standard introduced the ability to slice and concatenate strings:

Produces:

BCD

Such strings could be passed by reference to another subroutine, the length would also be passed transparently to the subroutine as a kind of short dope vector.

Again produces:

BCD

1983: Ada 83 and above
Ada 83 supports slices for all array types. Like Fortran 77 such arrays could be passed by reference to another subroutine, the length would also be passed transparently to the subroutine as a kind of short dope vector.

Produces:

BCD

Note: Since in Ada indices are n-based the term Text (2 .. 4) will result in an Array with the base index of 2.
The definition for Text_IO.Put_Line is:

The definition for String is:

As Ada supports true negative indices as in type History_Data_Array is array (-6000 .. 2010) of History_Data; it places no special meaning on negative indices. In the example above the term  Some_History_Data (-30 .. 30) would slice the History_Data from 31 BC to 30 AD (since there was no year zero, the year number 0 actually refers to 1 BC).

1987: Perl
If we have

as above, then the first 3 elements, middle 3 elements and last 3 elements would be:

Perl supports negative list indices. The -1 index is the last element, -2 the penultimate element, etc.
In addition, Perl supports slicing based on expressions, for example:

1991: Python
If you have the following list:

Then it is possible to slice by using a notation similar to element retrieval:

Note that Python allows negative list indices. The index -1 represents the last element, -2 the penultimate element, etc.
Python also allows a step property by appending an extra colon and a value. For example:

The stride syntax (nums[1:5:2]) was introduced in the second half of the 1990s, as a result of requests put forward by scientific users in the Python ""matrix-SIG"" (special interest group).Slice semantics potentially differ per object; new semantics can be introduced when operator overloading the indexing operator. With Python standard lists (which are dynamic arrays), every slice is a copy. Slices of NumPy arrays, by contrast, are views onto the same underlying buffer.

1992: Fortran 90 and above
In Fortran 90, slices are specified in the form

Both bounds are inclusive and can be omitted, in which case they default to the declared
array bounds. Stride defaults to 1. Example:

1994: Analytica
Each dimension of an array value in Analytica is identified by an Index variable. When slicing or subscripting, the syntax identifies the dimension(s) over which you are slicing or subscripting by naming the dimension. Such as:

Index I := 1..5   { Definition of a numerical Index }
Index J := ['A', 'B', 'C'] { Definition of a text-valued Index }
Variable X := Array(I, J, [[10, 20, 30], [1, 2, 3], ....]) { Definition of a 2D value }
X[I = 1, J = 'B']  -> 20  { Subscript to obtain a single value }
X[I = 1] ->  Array(J, [10, 20, 30])  { Slice out a 1D array. }
X[J = 2] -> Array(I, [20, 2, ....]) { Slice out a 1D array over the other dimension. }
X[I = 1..3]  {Slice out first four elements over I with all elements over J}

Naming indexes in slicing and subscripting is similar to naming parameters in function calls instead of relying on a fixed sequence of parameters. One advantage of naming indexes in slicing is that the programmer does not have to remember the sequence of Indexes, in a multidimensional array. A deeper advantage is that expressions generalize automatically and safely without requiring a rewrite when the number of dimensions of X changes.

1998: S-Lang
Array slicing was introduced in version 1.0. Earlier versions did not
support this feature.
Suppose that A is a 1-d array such as

    A = [1:50];           % A = [1, 2, 3, ...49, 50]

Then an array B of first 5 elements of A may be created using

    B = A[[:4]];

Similarly, B may be assigned to an array of the last 5 elements of A via:

    B = A[[-5:]];

Other examples of 1-d slicing include:

    A[-1]                 % The last element of A
    A[*]                  % All elements of A
    A[[::2]]              % All even elements of A
    A[[1::2]]             % All odd elements of A
    A[[-1::-2]]           % All even elements in the reversed order
    A[[[0:3], [10:14]]]   % Elements 0-3 and 10-14

Slicing of higher-dimensional arrays works similarly:

    A[-1, *]              % The last row of A
    A[[1:5], [2:7]]       % 2d array using rows 1-5 and columns 2-7
    A[[5:1:-1], [2:7]]    % Same as above except the rows are reversed

Array indices can also be arrays of integers. For example, suppose
that I = [0:9] is an array of 10 integers. Then
A[I] is equivalent to an array of the first 10 elements
of A. A practical example of this is a sorting
operation such as:

    I = array_sort(A);    % Obtain a list of sort indices
    B = A[I];             % B is the sorted version of A
    C = A[array_sort(A)]; % Same as above but more concise.

1999: D
Consider the array:

Take a slice out of it:

and the contents of b will be [7, 3, 8]. The first index of the slice is inclusive, the second is exclusive.

means that the dynamic array c now contains [8, 6] because inside the [] the $ symbol refers to the length of the array.
D array slices are aliased to the original array, so:

means that a now has the contents [2, 5, 7, 3, 10, 6, 4, 1]. To create a copy of the array data, instead of only an alias, do:

Unlike Python, D slice bounds don't saturate, so code equivalent to this Python code is an error in D:

2004: SuperCollider
The programming language SuperCollider implements some concepts from J/APL. Slicing looks as follows:

2005: fish
Arrays in fish are always one-based, thus the indices of a new slice will begin with one, regardless of the previous indices.

2006: Cobra
Cobra supports Python-style slicing. If you have a list

then the first 3 elements, middle 3 elements, and last 3 elements would be:

Cobra also supports slicing-style syntax for 'numeric for loops':

2006: Windows PowerShell
Arrays are zero-based in PowerShell and can be defined using the comma operator:

2009: Go
Go supports Python-style syntax for slicing (except negative indices are not supported). Arrays and slices can be sliced. If you have a slice

then the first 3 elements, middle 3 elements, last 3 elements, and a copy of the entire slice would be:

Slices in Go are reference types, which means that different slices may refer to the same underlying array.

2010: Cilk Plus
Cilk Plus supports syntax for array slicing as an extension to C and C++.

Cilk Plus slicing looks as follows:

Cilk Plus's array slicing differs from Fortran's in two ways:

the second parameter is the length (number of elements in the slice) instead of the upper bound, in order to be consistent with standard C libraries;
slicing never produces a temporary, and thus never needs to allocate memory. Assignments are required to be either non-overlapping or perfectly overlapping, otherwise the result is undefined.

2012: Julia
Julia array slicing is like that of MATLAB, but uses square brackets.  Example:

See also
Comparison of programming languages (array) § Slicing


== References ==",683334,https://en.wikipedia.org/wiki/Array_slicing
BANG file,"A BANG file[1](balanced and nested grid file) is a point access method which divides space into a nonperiodic grid. Each spatial dimension is divided by a linear hash. Cells may intersect, and points may be distributed between them.","A BANG file[1](balanced and nested grid file) is a point access method which divides space into a nonperiodic grid. Each spatial dimension is divided by a linear hash. Cells may intersect, and points may be distributed between them.

Another meaning
In some early ICL mainframe computers, a bang file was a temporary data storage file whose name began with a ! character (which is sometimes nicknamed ""bang"") and automatically deleted when the run or user session ended.

See also
twin grid file.

References
[1] http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.7345&rep=rep1&type=pdf",9969569,https://en.wikipedia.org/wiki/BANG_file
Bit array,"A bit array (also known as bitmask,bit map, bit set, bit string, or bit vector) is an array data structure that compactly stores bits. It can be used to implement a simple set data structure. A bit array is effective at exploiting bit-level parallelism in hardware to perform operations quickly. A typical bit array stores kw bits, where w is the number of bits in the unit of storage, such as a byte or word, and k is some nonnegative integer. If w does not divide the number of bits to be stored, some space is wasted due to internal fragmentation.","A bit array (also known as bitmask,bit map, bit set, bit string, or bit vector) is an array data structure that compactly stores bits. It can be used to implement a simple set data structure. A bit array is effective at exploiting bit-level parallelism in hardware to perform operations quickly. A typical bit array stores kw bits, where w is the number of bits in the unit of storage, such as a byte or word, and k is some nonnegative integer. If w does not divide the number of bits to be stored, some space is wasted due to internal fragmentation.

Definition
A bit array is a mapping from some domain (almost always a range of integers) to values in the set {0, 1}. The values can be interpreted as dark/light, absent/present, locked/unlocked, valid/invalid, et cetera. The point is that there are only two possible values, so they can be stored in one bit. As with other arrays, the access to a single bit can be managed by applying an index to the array. Assuming its size (or length) to be n bits, the array can be used to specify a subset of the domain (e.g. {0, 1, 2, ..., n−1}), where a 1-bit indicates the presence and a 0-bit the absence of a number in the set. This set data structure uses about n/w words of space, where w is the number of bits in each machine word. Whether the least significant bit (of the word) or the most significant bit indicates the smallest-index number is largely irrelevant, but the former tends to be preferred (on little-endian machines).
A finite binary relation may be represented by a bit array called a logical matrix. In the calculus of relations, these arrays are composed with matrix multiplication where the arithmetic is Boolean, and such a composition represents composition of relations.

Basic operations
Although most machines are not able to address individual bits in memory, nor have instructions to manipulate single bits, each bit in a word can be singled out and manipulated using bitwise operations. In particular:

OR  to set a bit to one: 11101010 OR 00000100 = 11101110
AND to set a bit to zero: 11101010 AND 11111101 = 11101000
AND to determine if a bit is set, by zero-testing :
11101010 AND 00000001 = 00000000 = 0
11101010 AND 00000010 = 00000010 ≠ 0
XOR to invert or toggle a bit:
11101010 XOR 00000100 = 11101110
11101110 XOR 00000100 = 11101010
NOT to invert all bits.
NOT 10110010 = 01001101To obtain the bit mask needed for these operations, we can use a bit shift operator to shift the number 1 to the left by the appropriate number of places, as well as bitwise negation if necessary.
Given two bit arrays of the same size representing sets, we can compute their union, intersection, and set-theoretic difference using n/w simple bit operations each (2n/w for difference), as well as the complement of either:

for i from 0 to n/w-1
    complement_a[i] := not a[i]
    union[i]        := a[i] or b[i]
    intersection[i] := a[i] and b[i]
    difference[i]   := a[i] and (not b[i])

If we wish to iterate through the bits of a bit array, we can do this efficiently using a doubly nested loop that loops through each word, one at a time. Only n/w memory accesses are required:

for i from 0 to n/w-1
    index := 0    // if needed
    word := a[i]
    for b from 0 to w-1
        value := word and 1 ≠ 0
        word := word shift right 1
        // do something with value
        index := index + 1    // if needed

Both of these code samples exhibit ideal locality of reference, which will subsequently receive large performance boost from a data cache. If a cache line is k words, only about n/wk cache misses will occur.

More complex operations
As with character strings it is straightforward to define length, substring, lexicographical compare, concatenation, reverse operations. The implementation of some of these operations is sensitive to endianness.

Population / Hamming weight
If we wish to find the number of 1 bits in a bit array, sometimes called the population count or Hamming weight, there are efficient branch-free algorithms that can compute the number of bits in a word using a series of simple bit operations. We simply run such an algorithm on each word and keep a running total. Counting zeros is similar. See the Hamming weight article for examples of an efficient implementation.

Inversion
Vertical flipping of a one-bit-per-pixel image, or some FFT algorithms, requires flipping the bits of individual words (so b31 b30 ... b0 becomes b0 ... b30 b31).
When this operation is not available on the processor, it's still possible to proceed by successive passes, in this example on 32 bits:

Find first one
The find first set or find first one operation identifies the index or position of the 1-bit with the smallest index in an array, and has widespread hardware support (for arrays not larger than a word) and efficient algorithms for its computation. When a priority queue is stored in a bit array, find first one can be used to identify the highest priority element in the queue. To expand a word-size find first one to longer arrays, one can find the first nonzero word and then run find first one on that word. The related operations find first zero, count leading zeros, count leading ones, count trailing zeros, count trailing ones, and log base 2 (see find first set) can also be extended to a bit array in a straightforward manner.

Compression
A bit array is the most dense storage for ""random"" bits, that is, where each bit is equally likely to be 0 or 1, and each one is independent. But most data are not random, so it may be possible to store it more compactly. For example, the data of a typical fax image is not random and can be compressed. Run-length encoding is commonly used to compress these long streams. However, most compressed data formats are not so easy to access randomly; also by compressing bit arrays too aggressively we run the risk of losing the benefits due to bit-level parallelism (vectorization). Thus, instead of compressing bit arrays as streams of bits, we might compress them as streams of bytes or words (see Bitmap index (compression)).

Advantages and disadvantages
Bit arrays, despite their simplicity, have a number of marked advantages over other data structures for the same problems:

They are extremely compact; no other data structures can store n independent pieces of data in n/w words.
They allow small arrays of bits to be stored and manipulated in the register set for long periods of time with no memory accesses.
Because of their ability to exploit bit-level parallelism, limit memory access, and maximally use the data cache, they often outperform many other data structures on practical data sets, even those that are more asymptotically efficient.However, bit arrays are not the solution to everything. In particular:

Without compression, they are wasteful set data structures for sparse sets (those with few elements compared to their range) in both time and space. For such applications, compressed bit arrays, Judy arrays, tries, or even Bloom filters should be considered instead.
Accessing individual elements can be expensive and difficult to express in some languages. If random access is more common than sequential and the array is relatively small, a byte array may be preferable on a machine with byte addressing. A word array, however, is probably not justified due to the huge space overhead and additional cache misses it causes, unless the machine only has word addressing.

Applications
Because of their compactness, bit arrays have a number of applications in areas where space or efficiency is at a premium. Most commonly, they are used to represent a simple group of boolean flags or an ordered sequence of boolean values.
Bit arrays are used for priority queues, where the bit at index k is set if and only if k is in the queue; this data structure is used, for example, by the Linux kernel, and benefits strongly from a find-first-zero operation in hardware.
Bit arrays can be used for the allocation of memory pages, inodes, disk sectors, etc. In such cases, the term bitmap may be used. However, this term is frequently used to refer to raster images, which may use multiple bits per pixel.
Another application of bit arrays is the Bloom filter, a probabilistic set data structure that can store large sets in a small space in exchange for a small probability of error. It is also possible to build probabilistic hash tables based on bit arrays that accept either false positives or false negatives.
Bit arrays and the operations on them are also important for constructing succinct data structures, which use close to the minimum possible space. In this context, operations like finding the nth 1 bit or counting the number of 1 bits up to a certain position become important.
Bit arrays are also a useful abstraction for examining streams of compressed data, which often contain elements that occupy portions of bytes or are not byte-aligned. For example, the compressed Huffman coding representation of a single 8-bit character can be anywhere from 1 to 255 bits long.
In information retrieval, bit arrays are a good representation for the posting lists of very frequent terms. If we compute the gaps between adjacent values in a list of strictly increasing integers and encode them using unary coding, the result is a bit array with a 1 bit in the nth position if and only if n is in the list. The implied probability of a gap of n is 1/2n. This is also the special case of Golomb coding where the parameter M is 1; this parameter is only normally selected when −log(2 − p) / log(1 − p) ≤ 1, or roughly the term occurs in at least 38% of documents.

Language support
The APL programming language fully supports bit arrays of arbitrary shape and size as a Boolean datatype distinct from integers. All major implementations (Dyalog APL, APL2, APL Next, NARS2000, Gnu APL, etc.) pack the bits densely into whatever size the machine word is. Bits may be accessed individually via the usual indexing notation (A[3]) as well as through all of the usual primitive functions and operators where they are often operated on using a special case algorithm such as summing the bits via a table lookup of bytes.
The C programming language's bit fields, pseudo-objects found in structs with size equal to some number of bits, are in fact small bit arrays; they are limited in that they cannot span words. Although they give a convenient syntax, the bits are still accessed using bytewise operators on most machines, and they can only be defined statically (like C's static arrays, their sizes are fixed at compile-time). It is also a common idiom for C programmers to use words as small bit arrays and access bits of them using bit operators. A widely available header file included in the X11 system, xtrapbits.h, is “a portable way for systems to define bit field manipulation of arrays of bits.” A more explanatory description of aforementioned approach can be found in the comp.lang.c faq.
In C++, although individual bools typically occupy the same space as a byte or an integer, the STL type vector<bool> is a partial template specialization in which bits are packed as a space efficiency optimization. Since bytes (and not bits) are the smallest addressable unit in C++, the [] operator does not return a reference to an element, but instead returns a proxy reference. This might seem a minor point, but it means that vector<bool> is not a standard STL container, which is why the use of vector<bool> is generally discouraged. Another unique STL class, bitset, creates a vector of bits fixed at a particular size at compile-time, and in its interface and syntax more resembles the idiomatic use of words as bit sets by C programmers. It also has some additional power, such as the ability to efficiently count the number of bits that are set. The Boost C++ Libraries provide a dynamic_bitset class whose size is specified at run-time.
The D programming language provides bit arrays in its standard library, Phobos, in std.bitmanip. As in C++, the [] operator does not return a reference, since individual bits are not directly addressable on most hardware, but instead returns a bool.
In Java, the class BitSet creates a bit array that is then manipulated with functions named after bitwise operators familiar to C programmers. Unlike the bitset in C++, the Java BitSet does not have a ""size"" state (it has an effectively infinite size, initialized with 0 bits); a bit can be set or tested at any index. In addition, there is a class EnumSet, which represents a Set of values of an enumerated type internally as a bit vector, as a safer alternative to bit fields.
The .NET Framework supplies a BitArray collection class. It stores bits using an array of type int (each element in the array usually represents 32 bits). The class supports random access and bitwise operators, can be iterated over, and its Length property can be changed to grow or truncate it.
Although Standard ML has no support for bit arrays, Standard ML of New Jersey has an extension, the BitArray structure, in its SML/NJ Library. It is not fixed in size and supports set operations and bit operations, including, unusually, shift operations.
Haskell likewise currently lacks standard support for bitwise operations, but both GHC and Hugs provide a Data.Bits module with assorted bitwise functions and operators, including shift and rotate operations and an ""unboxed"" array over boolean values may be used to model a Bit array, although this lacks support from the former module.
In Perl, strings can be used as expandable bit arrays. They can be manipulated using the usual bitwise operators (~ | & ^), and individual bits can be tested and set using the vec function.In Ruby, you can access (but not set) a bit of an integer (Fixnum or Bignum) using the bracket operator ([]), as if it were an array of bits.
Apple's Core Foundation library contains CFBitVector and CFMutableBitVector structures.
PL/I supports arrays of bit strings of arbitrary length, which may be either fixed-length or varying. The array elements may be aligned— each element begins on a byte or word boundary— or unaligned— elements immediately follow each other with no padding.
PL/pgSQL and PostgreSQL's SQL support bit strings as native type. There are two SQL bit types: bit(n) and bit varying(n), where n is a positive integer.Hardware description languages such as VHDL, Verilog, and SystemVerilog natively support bit vectors as these are used to model storage elements like flip-flops, hardware busses and hardware signals in general. In hardware verification languages such as OpenVera, e and SystemVerilog, bit vectors are used to sample values from the hardware models, and to represent data that is transferred to hardware during simulations.
Common Lisp provides a one-dimensional bit-vector implementation as a special case of the built-in array, acting in a dual capacity as a class and a type specifier. Being a derivative of the array, it relies on the general make-array function to be configured with an element type of bit, which optionally permits the bit vector to be designated as dynamically resizable. The bit-vector, however, is not infinite in extent. A more restricted simple-bit-vector type exists, which explicitly excludes the dynamic characteristics. Bit vectors are represented as, and can be constructed in a more concise fashion by, the reader macro #*bits. In addition to the general functions applicable to all arrays, dedicated operations exist for bit vectors. Single bits may be accessed and modified using the bit and sbit functions and an extensive number of logical operations is supported.

See also
Arithmetic logic unit
Binary code
Binary numeral system
Bitboard Chess and similar games.
Bit field
Bitmap index
Bitstream
Finite field of 2 elements, or GF(2)
Judy array
Variable-length code

References
External links
mathematical bases Archived 2019-10-16 at the Wayback Machine by Pr. D.E.Knuth
vector<bool> Is Nonconforming, and Forces Optimization Choice
vector<bool>: More Problems, Better Solutions",1189937,https://en.wikipedia.org/wiki/Bit_array
Block swap algorithms,"In computer algorithms, Block swap algorithms swap two regions of elements of an array. It is simple to swap two non-overlapping regions of an array of equal size. However, it is not simple to swap two non-overlapping regions of an array in-place that are next to each other, but are of unequal sizes (such swapping is equivalent to Array Rotation). Three algorithms are known to accomplish this: Bentley's Juggling (also known as Dolphin Algorithm ), Gries-Mills, and Reversal. All three algorithms are linear time 
O(n), (see Time complexity).","In computer algorithms, Block swap algorithms swap two regions of elements of an array. It is simple to swap two non-overlapping regions of an array of equal size. However, it is not simple to swap two non-overlapping regions of an array in-place that are next to each other, but are of unequal sizes (such swapping is equivalent to Array Rotation). Three algorithms are known to accomplish this: Bentley's Juggling (also known as Dolphin Algorithm ), Gries-Mills, and Reversal. All three algorithms are linear time 
O(n), (see Time complexity).

Reversal algorithm
The reversal algorithm is the simplest to explain, using rotations. A rotation is an in-place reversal of array elements. This method swaps two elements of an array from outside in within a range. The rotation works for an even or odd number of array elements. The reversal algorithm uses three in-place rotations to accomplish an in-place block swap:

Rotate region A
Rotate region B
Rotate region ABGries-Mills and Reversal algorithms perform better than Bentley's Juggling, because of their cache-friendly memory access pattern behavior.
The Reversal algorithm parallelizes well, because rotations can be split into sub-regions, which can be rotated independently of others.


== References ==",61176336,https://en.wikipedia.org/wiki/Block_swap_algorithms
Bounds checking,"In computer programming, bounds checking is any method of detecting whether a variable is within some bounds before it is used. It is usually used to ensure that a number fits into a given type (range checking), or that a variable being used as an array index is within the bounds of the array (index checking). A failed bounds check usually results in the generation of some sort of exception signal.
As performing bounds checking during each use can be time-consuming, it is not always done. Bounds-checking elimination is a compiler optimization technique that eliminates unneeded bounds checking.","In computer programming, bounds checking is any method of detecting whether a variable is within some bounds before it is used. It is usually used to ensure that a number fits into a given type (range checking), or that a variable being used as an array index is within the bounds of the array (index checking). A failed bounds check usually results in the generation of some sort of exception signal.
As performing bounds checking during each use can be time-consuming, it is not always done. Bounds-checking elimination is a compiler optimization technique that eliminates unneeded bounds checking.

Range checking
A range check is a check to make sure a number is within a certain range; for example, to ensure that a value about to be assigned to a 16-bit integer is within the capacity of a 16-bit integer (i.e. checking against wrap-around). This is not quite the same as type checking. Other range checks may be more restrictive; for example, a variable to hold the number of a calendar month may be declared to accept only the range 1 to 12.

Index checking
Index checking means that, in all expressions indexing an array, the index value is checked against the bounds of the array (which were established when the array was defined), and if the index is out-of-bounds, further execution is suspended via some sort of error. Because reading or especially writing a value outside the bounds of an array may cause the program to malfunction or crash or enable security vulnerabilities (see buffer overflow), index checking is a part of many high-level languages.
Early compiled programming languages with index checking ability included ALGOL 60, ALGOL 68 and Pascal, as well as interpreted programming languages such as BASIC.
Many programming languages, such as C, never perform automatic bounds checking to raise speed. However, this leaves many off-by-one errors and buffer overflows uncaught. Many programmers believe these languages sacrifice too much for rapid execution. In his 1980 Turing Award lecture, C. A. R. Hoare described his experience in the design of ALGOL 60, a language that included bounds checking, saying:

A consequence of this principle is that every occurrence of every subscript of every subscripted variable was on every occasion checked at run time against both the upper and the lower declared bounds of the array. Many years later we asked our customers whether they wished us to provide an option to switch off these checks in the interest of efficiency on production runs. Unanimously, they urged us not to—they already knew how frequently subscript errors occur on production runs where failure to detect them could be disastrous. I note with fear and horror that even in 1980, language designers and users have not learned this lesson. In any respectable branch of engineering, failure to observe such elementary precautions would have long been against the law.
Mainstream languages that enforce run time checking include Ada, C#, Haskell, Java, JavaScript, Lisp, PHP, Python, Ruby, Rust, and Visual Basic. The D and OCaml languages have run time bounds checking that is enabled or disabled with a compiler switch. In C++ run time checking is not part of the language, but part of the STL and is enabled with a compiler switch (_GLIBCXX_DEBUG=1 or _LIBCPP_DEBUG=1). C# also supports unsafe regions: sections of code that (among other things) temporarily suspend bounds checking to raise efficiency. These are useful for speeding up small time-critical bottlenecks without sacrificing the safety of a whole program.
The JS++ programming language is able to analyze if an array index or map key is out-of-bounds at compile time using existent types, which is a nominal type describing whether the index or key is within-bounds or out-of-bounds and guides code generation. Existent types have been shown to add only 1ms overhead to compile times.

Hardware bounds checking
The safety added by bounds checking necessarily costs CPU time if the checking is performed in software; however, if the checks could be performed by hardware, then the safety can be provided ""for free"" with no runtime cost. An early system with hardware bounds checking was the ICL 2900 Series mainframe announced in 1974. The VAX computer has an INDEX assembly instruction for array index checking which takes six operands, all of which can use any VAX addressing mode. The B6500 and similar Burroughs computers performed bound checking via hardware, irrespective of which computer language had been compiled to produce the machine code.  A limited number of later CPUs have specialised instructions for checking bounds, e.g., the CHK2 instruction on the Motorola 68000 series.
Research has been underway since at least 2005 regarding methods to use x86's built-in virtual memory management unit to ensure safety of array and buffer accesses. In 2015 Intel provided their Intel MPX extensions in their Skylake processor architecture which stores bounds in a CPU register and table in memory. As of early 2017 at least GCC supports MPX extensions.

See also
Dynamic code analysis
Runtime error detection
Static code analysis

References
External links
“On The Advantages Of Tagged Architecture”, IEEE Transactions On Computers, Volume C-22, Number 7, July, 1973.
“The Emperor’s Old Clothes Archived 2017-10-02 at the Wayback Machine”, The 1980 ACM Turing Award Lecture, CACM volume 24 number 2, February 1981, pp 75–83.
“Bcc: Runtime checking for C programs”, Samuel C. Kendall, Proceedings of the USENIX Summer 1983 Conference.
“Bounds Checking for C”, Richard Jones and Paul Kelly, Imperial College, July 1995.
“ClearPath Enterprise Servers MCP Security Overview”, Unisys, April 2006.
“Secure Virtual Architecture: A Safe Execution Environment for Commodity Operating Systems”, John Criswell, Andrew Lenharth, Dinakar Dhurjati, Vikram Adve, SOSP'07 21st ACM Symposium on Operating Systems Principles, 2007.
“Fail-Safe C”, Yutaka Oiwa. Implementation of the Memory-safe Full ANSI-C Compiler. ACM SIGPLAN Conference on Programing Language Design and Implementations (PLDI2009), June 2009.
“address-sanitizer”, Timur Iskhodzhanov, Alexander Potapenko, Alexey Samsonov, Kostya Serebryany, Evgeniy Stepanov, Dmitriy Vyukov, LLVM Dev Meeting, November 18, 2011.
Safe C Library of Bounded APIs
""The Safe C Library"". Dr. Dobb's Journal. February 20, 2009. Archived from the original on December 2, 2013. Retrieved November 13, 2012.
Safe C API—Concise solution of buffer overflow, The OWASP Foundation, OWASP AppSec, Beijing 2011 
The GNU C++ Library Manual Macros
libc++ 11.0 documentation Debug Mode",486833,https://en.wikipedia.org/wiki/Bounds_checking
C-list (computer security),"In capability-based computer security, a C-list is an array of capabilities, usually associated with a process and maintained by the kernel. The program running in the process does not manipulate capabilities directly, but refers to them via C-list indexes—integers indexing into the C-list.
The file descriptor table in Unix is an example of a C-list.  Unix processes do not manipulate file descriptors directly, but refer to them via file descriptor numbers, which are C-list indexes.
In the KeyKOS and EROS operating systems, a process's capability registers constitute a C-list.","In capability-based computer security, a C-list is an array of capabilities, usually associated with a process and maintained by the kernel. The program running in the process does not manipulate capabilities directly, but refers to them via C-list indexes—integers indexing into the C-list.
The file descriptor table in Unix is an example of a C-list.  Unix processes do not manipulate file descriptors directly, but refer to them via file descriptor numbers, which are C-list indexes.
In the KeyKOS and EROS operating systems, a process's capability registers constitute a C-list.

See also
Access-control list


== References ==",5952938,https://en.wikipedia.org/wiki/C-list_(computer_security)
Chemical sensor array,"A chemical sensor array is a sensor architecture with multiple sensor components that create a pattern for analyte detection from the additive responses of individual sensor components. There exist several types of chemical sensor arrays including electronic, optical, acoustic wave, and potentiometric devices. These chemical sensor arrays can employ multiple sensor types that are cross-reactive or tuned to sense specific analytes.","A chemical sensor array is a sensor architecture with multiple sensor components that create a pattern for analyte detection from the additive responses of individual sensor components. There exist several types of chemical sensor arrays including electronic, optical, acoustic wave, and potentiometric devices. These chemical sensor arrays can employ multiple sensor types that are cross-reactive or tuned to sense specific analytes.

Overview
Definition
Sensor array components are individual sensors, which are selected based on their individual sensing properties (ie. method of detection, specificity for a particular class of analyte and molecular interaction). Sensor components are chosen to respond to as many analytes as possible; so, while the sensitivity and selectivity of individual sensor components vary, the sensors have an additive effect by creating a nonselective fingerprint for a particular analyte when combined into an array architecture.  Recognition of fingerprints enables detection of analytes in mixtures. Chemical sensor arrays differ from other multianalyte tests such as a urinalysis stick assay which utilizes multiple, specific sensor materials for targeted detection of analytes in a mixture; instead, chemical sensor arrays rely on cross-reactivity of individual sensor components to generate fingerprints based on the additive responses of sensor components to the target analyte.

Comparison to other chemical sensors
Single sensor devices sense target analytes based on physical, optical, and electronic properties. Some sensors contain specific molecular targets to afford strong and specific binding with a particular analyte; however, while this approach is specific, complex mixture impact sensor performance. Several of these complex mixtures include odors and vapors exhaled from the lungs. Individual chemical sensors often utilize controlled sensing environments, and variations in ambient conditions (e.g., temperature and humidity) can interfere with sensor performance. Chemical sensor arrays employ pattern recognition of combinatorial responses of cross-reactive sensor components to enable sensing of a diverse array of mixtures in a variety of conditions. Chemical sensor arrays are often noted as mimicking the five senses—audition, gustation, olfaction, somatosensation, and vision—because the combinatorial responses to the different array components of a particular analytes create fingerprints for specific analytes or mixtures using both targeted molecular interactions and pattern recognition.

History
The history of chemical sensor arrays is closely linked with the development of other chemical sensor technologies, with research in the area of electronic chemical sensors picking up in the 1960s with the demonstration of metal-oxide semiconductor sensors capable of sensing analyses such as oxygen. Humans are capable of identifying and discerning between an estimated 10,000 scents or more, while only possessing 400 olfactory receptors. Signal processing in the brain of individual array component responses of olfactory receptors results in pattern recognition for discrimination of a particular scent. One of the design aims of many chemical sensor arrays is to mimic the performance of olfaction to design an electronic nose integrated with a variety of materials. Combining chemical sensor arrays with pattern recognition methods mimics biological sensory recognition methods. See Figure 1. Commercially available electronic nose systems exist and are used in the food industry for quality control. Current research efforts demonstrate the introduction of the electronic nose principle into environmental monitoring and medicine both as commercial instruments as well as in consumer-grade wearable electronic devices. At the center of chemical sensor arrays is the principle that different analytes will interact differently with a variety of materials. As such, any sort of material may be used in a sensor array, so long as it responds differently to different analytes or mixtures. From this idea, cross-reactive sensor arrays have been the focus of chemical sensor array development for their broad compatibility with the compounds as components of mixtures.

Array signal processing
The signal(s) coming from an array sensor must be processed and compared with already-known patterns. Many techniques are useful in processing array data including principal component analysis (PCA), least square analysis, and more recently training of neural networks and utilization of machine learning for pattern development and identification. Machine learning has been a more recent development for generation and recognition of patterns for chemical sensor array data. The method of data analysis chosen depends on a variety of factors including sensing parameters, desired use of the information (quantitative or qualitative), and the method of detection which can be classified under four major types of chemical sensor array: electronic, optical, acoustic wave, and electrochemical sensor arrays.

Electronic chemical sensor arrays
The first type of chemical sensor array relies on modulation of an electronic signal for signal acquisition. This type of chemical sensor array often utilizes a semiconductive material such as metal-oxide semiconductors, conductive polymers, nanomaterials, or framework materials such as metal-organic and covalent-organic frameworks. One of the simplest device architectures for an electronic chemical sensor is a chemiresistor, and other architectures include capacitors and transistors; these materials have a resistance which can be altered through physisorption or chemisorption of target molecules and thus a measurable signal as a change in electrical current, capacitance, or voltage.

Metal-oxide semiconductors in electronic chemical sensor arrays
Metal-oxide semiconductors were first reported in the 1960s as a chemiresistor sensor for single-analyte detection of organic vapors. The first commercially available chemiresistive sensors utilized metal-oxide semiconductors for the detection of carbon monoxide. Although most known for their use in carbon monoxide detectors, metal-oxide semiconductors are capable of sensing other analytes through strategic tuning of their composition. The high operating temperature required to operate these sensors make these semiconductors inefficient and cross-reactive particularly with water.In the 1990s, several researchers at the University of Warwick created the first cross-reactive (non-selective) metal-oxide semiconductor sensor array integrated with pattern recognition software for sensing and distinguishing organic vapors, including acetone, ethanol, methanol, and xylene, in multianalyte mixtures. This electronic nose system was known as the Warwick Nose, and combined commercially available tin- and silicon-oxide semiconductors into an array format for gas sensing, see Figure 2. Current efforts are advancing the format of metal-oxide semiconductor arrays using microfabrication techniques to enable smaller array designs and integration of signal processing components into each array component. These microdevices have shown promise with lowered limits of detection and enhanced ability to distinguish volatile organic compounds and carbon monoxide with arrays containing different numbers of device, and these systems also reduce the amount of sensor material with thin films of metal-oxides. Sensitivity of sensors has also been shown to be influenced by changing the ratio of the metal within each device and data processing utilized least square analysis.Another example of metal-oxide semiconductors is arrays of metal-oxide semiconductor field effect transistors (MOSFET), which consist of a catalytically active gate metal (such as palladium) over a silicon dioxide layer on a p-type silicon base with n-doped channels adjacent to the gate, and they have been used to sense hydrogen, ammonia, and ethanol. These MOSFETs through adsorbed-analyte modulating the semiconductor gate work function, which causes changes in voltage across the device. MOSFETs are highly tunable but remain limited by their cross-reactivity, and high operating temperatures.

Intrinsically conductive polymers in electronic chemical sensor arrays
Several intrinsically conductive polymers of interest include polyacetylene, polythiophene, and polyaniline, and others may be made conductive through processes including chemical doping. The principle chemistry underlying the electronic sensing mechanism of conductive polymers is modulation of the conductivity of these polymers upon changes to their physical structure (swelling) resulting from interactions with analytes (mainly through absorption). An advantage of using conductive polymers in sensor arrays is that there is synthetic access of a vast library of polymers. As a result, conductive polymers are a promising alternative to metal-oxide semiconductors because a greater number of sensors with different functionalities may be used to design a more robust array tailored for specific applications. Monomer identity, polymerization conditions, and device fabrication methods impact both the morphological and chemical properties of conductive polymers, which also contributes to the greater variety of possible array components which may be designed. The limitations of conductive polymer arrays are similar to those of single sensor analogs in that the signal transduction pathways through the polymer material are poorly understood and both struggle to sense non-polar species due to minimal adsorption to the polymer. Several commercially available systems are available and are used in food analysis and sensing of volatile organic compounds; however, progress to advance chemiresistive sensor arrays utilizing conductive polymers has decreased as other materials and sensing methods have been developed.

Nanomaterials in electronic chemical sensor arrays
Development of novel nanomaterials such as graphene, carbon nanotubes, and 2D and 3D framework materials have been reported as new classes of materials for applications in electronic chemical sensor arrays. For graphene and carbon nanotubes, surface functionalization via covalent or non-covalent modification, and edge site defects are utilized as sites for host-guest interactions. One such example is single-walled carbon nanotubes modified with various metalloporphyrins to enable discrimination of volatile organic compounds.

Conductive framework materials in electronic chemical sensor arrays
Conductive framework materials have similar mechanisms for sensing; however these materials may be designed with installed active sites tuned for a specific molecular interaction. Bimetallic metallophthalocyanine metal-organic frameworks (MOFs) and covalent organic frameworks (COFs) have shown promise in single device chemiresistors at sensing hydrogen sulfide, ammonia, and nitric oxide. The development of these materials as chemiresistors allows for strategic design of arrays capable of targeted molecular interactions, which can be employed to develop array components tailored to sensing specific compounds. Computational research of several MOFs has also focused on optimizing which combinations of MOFs are best suited for sensing particular components in various mixtures. The focus on curation of framework array components demonstrated the opportunity to design robust sensor arrays experimentally and computationally.

Mixed-material electronic chemical sensor arrays
Efforts have been made to overcome the specific limitations of different classes of materials suited for use in electronic chemical sensor arrays by combining sensors fabricated with different materials into one array. One example of these is metal-oxide nanowires coated in thin films of MOFs, which have been reported to have enhanced sensing performance over sensors made with the individual materials. Carbon black-polymer blends have also shown enhanced analyte discrimination and array-element signals to afford enhanced detection of volatile organic compounds both across a variety of classes, as well as within the same class.Molecularly imprinted polymers have also been integrated into array formats and shown utility as the imprinting process enables molecularly imprinted polymer arrays to be tailors to specific analytes.

Optical/colorimetric chemical sensor arrays
Separate from electronic chemical sensor arrays are optical chemical sensor arrays which probe chemical interactions between target analytes and a sensing material with light (ultraviolet, visible, infrared). Generally, optical sensors probe chemical interactions with light through a variety of quantifiable methods including absorbance, diffraction, fluorescence, refraction, and scattering. Generally, fluorescence sensors show greater sensitivity than other optical methods. Optical sensors consist of a light source, wavelength filter(s), a sample, and a detector, with variations in sensor design based on the method used. Similar to the electronic nose, optical chemical sensor arrays have been categorized under the umbrella topic of optoelectronic nose and similarly operate by developing fingerprints for specific compounds and using pattern recognition to identify those components in mixture. Figure 2. shows the principles underlying colorimetric and fluorometric sensor arrays. Chemical interactions with dyes result in changes to light being detected in an optical sensor.
Optical sensors require selective interaction with analytes and two components are required: a probe material, and a chromo- or fluorophore. Cross-reactive optical and fluorescence arrays require strategic consideration of molecular interactions between probes and analytes. Much like electrical chemical sensor arrays, optical chemical sensor arrays face challenges in sensing in the presence of competing analytes such as water. Consideration of host-guest interactions allows an array to probe a variety of molecular features  because integration of ‘promiscuous sensors’ (non-selective) such as optically active polymers permit non-discriminate sensing of a variety of compounds primarily based on hydrophobicity, and so-called ‘monogamous’ sensors with exclusive binding to a particular analyte (much like a lock-and-key design)  will enhance specificity and applicability of a colorimetric sensor array. Regardless of the type of sensing probe, there are five major types of intermolecular interaction which lead to a measurable colorimetric change to a material.

Brønsted-Lowry acid-base interactions in colorimetric chemical sensor arrays
Brønsted-Lowry acid-base interactions such as those of dyes commonly used as pH indicators are one of the earliest methods for colorimetric sensing. Since the early 20th century, natural dyes such as 7-hydroxyohenoxazone (litmus) and anthocyanin oxonium dye have been used both as pH indicators and colorimetric sensors.  Many other chromophores with Brønsted-Lowry acid-base functionality have been developed such azo dyes, nitrophenols, phthaleins, and sulfonphthaleins.  The Brønsted-Lowry acid-base functionality of these chromophores relates to specific chemical moieties within their structures and their corresponding pKa. Color changes resulting from protonation/deprotonation events may be broadly defined as intermolecular interactions with an acid or base of a particular strength and/or concentration.

Lewis acid-base interactions in colorimetric chemical sensor arrays
While Brønsted-Lowry acid-base interactions are sensitive to a broad range of compounds, Lewis acid and base interactions comprise some of the most sensitive set of intermolecular interactions relevant to colorimetric chemical sensor arrays. The selectivity of Lewis acid and base interactions in chemical sensing are underscored by the fact that the most pungent of odors arise from Lewis bases (thiols, phosphines, amines) and the metal cation-containing olfactory receptors utilized to sense them at some of the lowest concentrations of all molecular motifs in biology use Lewis acid receptors. Lewis acid dyes (namely metals cations with an open-coordination site) are used in biological olfaction for sensing. As such, Lewis acids such as metalloporphyrins are of particular interest to researchers developing colorimetric sensor because of their strong Lewis acid-base interactions.

Other interactions in colorimetric chemical sensor arrays
File:Cyranose 320 Labelled.jpgA variety of other reversible molecular interactions have been shown to produce color changes upon interaction with analytes. These include redox active chromo- and fluorophores which undergo specific color changes at different applied potentials. There also exists a variety of dyes such as merocyanine and azobenzene which show color changes based on the polarity of their environment. A‘push-pull’mechanism of electron density through these systems through intermolecular interactions results in augmentation of their dipole moments between ground and excited states, which manifests as observable changes to optical transition. Nanomaterials development has allowed for surface modification of certain dyes (especially redox active dyes) to afford high sensitivity due to larger surface area-to-volume ratio resulting for more active sites for analyte interaction with dyes.

Colorimetric chemical sensor array fabrication
Unlike the materials used in electronic chemical sensor arrays, in which direct interaction between the sensing material and an analyte leads to signal transduction as a change in conductivity or voltage, fabrication of colorimetric sensor arrays requires consideration of both analyte-substrate interaction and transduction of the optical signal. One method for colorimetric sensor array fabrication involves preparation of microspheres by suspending dyes into an inert, and transparent matrix. These microspheres are then incorporated into fiber optics. Other methods for fabricating colorimetric sensor arrays include printing of array fluor- and colorimetric dyes (either directly or in a nanoporous matrix) onto various substrates including paper, silica gel, or porous polymer membranes.Inclusion of digital imaging and or illumination of optical chemical sensor array elements allows for rapid, real-time signal transduction of colorimetric data measurements in real-time of colorimetric and fluorescent data from microsphere or plated sensors. Detectors can process specific wavelengths of light, or employ RGB image processing programs to analyze data obtained from direct imaging of a sensor array. Much like electronic chemical sensor arrays, optical chemical sensor arrays are being miniaturized using microfabrication techniques to increase the applicability. Recent advancements in optical chemical sensor arrays have resulted in sensor arrays being directly integrated into flatbed scanners and mobile electronics such as smart phones (through microplate fabrication). These microplate arrays enable colorimetric analysis of complex mixtures in a variety of phases with applications in identification of toxic industrial chemicals using cross-reactive nanoporous pigments, cancer diagnosis using an array of gold nanoparticle-green fluorescent proteins, and development and assessment of combinatorial libraries of metal-dye complexes as sensors themselves.

Other types of chemical sensor arrays
Although less common, there are two other classifications of devices with demonstrated functionality as chemical sensor arrays. These include wave devices and electrochemical sensors.

Wave devices as chemical sensor arrays
There are several major types of wave devices including acoustic wave devices, thickness shear mode resonators (TSM), and quartz crystal microbalances. These devices oscillate at known frequencies and their frequencies of oscillation are modulated by changes in the mass of the device. These devices may be modified with the plurality of the materials already discussed as being useful materials in chemical sensor array. All of these materials are marked by the broad compatibility of their intermolecular interactions as well as selective interactions to a variety of compounds, which when combined together allow for fingerprint detection of compounds in mixtures.Modification of wave devices with materials such as micromachined metal-oxide cantilevers coated in polymer films enable enhanced detection of mixtures of volatile organic compounds as well as hydrogen gas and mercury vapor. Bulk and surface acoustic wave devices have used in higher order sensors in which the sensing material gives rise to multiple modes for signal transduction, such as electrical and optical; additionally the same wave devices have also been used to create virtual chemical sensor arrays, in which data from one sensor component is further processed. A chemical sensor array of surface-modified quartz crystal microbalances with a variety of materials including copper phthalocyanine, single- and multi-walled carbon nanotubes was shown as a promising electronic nose for gas sensing when machine learning algorithms were employed for data processing.

Electrochemical sensor arrays
Another class of devices usable in chemical sensor arrays are electrodes. Commonly, electrochemical-based sensors are referred to as electronic tongues. Surface modification of an electrode in a multielectrode system allows for targeting of specific molecular interactions. Semipermeable membrane materials allows for electrodes to be made into sensors through their ability to selectively oxidize or reduce target analytes. One example includes, the use of an array of semipermeable membrane sensors made from potentiometric polymers like poly(vinyl chloride) have demonstrated their ability to monitor nitrate, nitrite, and ammonium concentrations in aqueous solution. Both voltametric and potentiometric methods have been developed, and this technique is an active area of research not only for multianalyte analysis of aqueous solutions such as cerebrospinal fluid, but also differentiation of redox products in electrochemical reactions.

Examples of chemical sensor arrays with real-world uses
There exists a diversity of well-understood, and emerging research focused on developing chemical sensor arrays for a variety of applications. Analytical devices integrated with a chemical sensor array have been proposed as diagnostic tests for cancer, bacterial infections based on fingerprint analysis of exhaled breath, as well as for food and product quality control. A few examples include:

Clinical trial of a chemical sensor array device made with gold nanoparticles linked with different organic ligands capable of detecting COVID-19 infections.
The WOLF eNose is a commercially available system of chemical sensor arrays using both electronic and colorimetric sensors for the detection of volatile organic compounds, and it has been employed for detection of urinary tract infection-causing bacteria.
The Cyranose 320 Electronic Nose is a commercially available chemical sensor array fabricated from 32 black carbon-polymer sensors capable of identifying six bacteria that cause eye infections with 96% accuracy, see Figure 4.


== References ==",66888952,https://en.wikipedia.org/wiki/Chemical_sensor_array
Circular buffer,"In computer science, a circular buffer, circular queue, cyclic buffer or ring buffer is a data structure that uses a single, fixed-size buffer as if it were connected end-to-end. This structure lends itself easily to buffering data streams. There were early circular buffer implementations in hardware.","In computer science, a circular buffer, circular queue, cyclic buffer or ring buffer is a data structure that uses a single, fixed-size buffer as if it were connected end-to-end. This structure lends itself easily to buffering data streams. There were early circular buffer implementations in hardware.

Overview
A circular buffer first starts out empty and has a set length. In the diagram below is a 7-element buffer:

Assume that 1 is written in the center of a circular buffer (the exact starting location is not important in a circular buffer):

Then assume that two more elements are added to the circular buffer — 2 & 3 — which get put after 1:

If two elements are removed, the two oldest values inside of the circular buffer would be removed. Circular buffers use FIFO (first in, first out) logic. In the example, 1 & 2 were the first to enter the circular buffer, they are the first to be removed, leaving 3 inside of the buffer.

If the buffer has 7 elements, then it is completely full:

A property of the circular buffer is that when it is full and a subsequent write is performed, then it starts overwriting the oldest data. In the current example, two more elements — A & B — are added and they overwrite the 3 & 4:

Alternatively, the routines that manage the buffer could prevent overwriting the data and return an error or raise an exception. Whether or not data is overwritten is up to the semantics of the buffer routines or the application using the circular buffer.
Finally, if two elements are now removed then what would be returned is not 3 & 4 (or rather now A & B) but 5 & 6 because 5 & 6 are now the oldest elements, yielding the buffer with:

Uses
The useful property of a circular buffer is that it does not need to have its elements shuffled around when one is consumed. (If a non-circular buffer were used then it would be necessary to shift all elements when one is consumed.) In other words, the circular buffer is well-suited as a FIFO (first in, first out) buffer while a standard, non-circular buffer is well suited as a LIFO (last in, first out) buffer.
Circular buffering makes a good implementation strategy for a queue that has fixed maximum size. Should a maximum size be adopted for a queue, then a circular buffer is a completely ideal implementation; all queue operations are constant time. However, expanding a circular buffer requires shifting memory, which is comparatively costly. For arbitrarily expanding queues, a linked list approach may be preferred instead.
In some situations, overwriting circular buffer can be used, e.g. in multimedia. If the buffer is used as the bounded buffer in the producer–consumer problem then it is probably desired for the producer (e.g., an audio generator) to overwrite old data if the consumer (e.g., the sound card) is unable to momentarily keep up. Also, the LZ77 family of lossless data compression algorithms operates on the assumption that strings seen more recently in a data stream are more likely to occur soon in the stream. Implementations store the most recent data in a circular buffer.

Circular buffer mechanics
A circular buffer can be implemented using a pointer and three integers:
buffer start in memory
buffer capacity (length)
write to buffer index (end)
read from buffer index (start)This image shows a partially full buffer with Length = 7:

This image shows a full buffer with four elements (numbers 1 through 4) having been overwritten:

In the beginning the indexes end and start are set to 0. The circular buffer write operation writes an element to the end index position and the end index is incremented to the next buffer position. The circular buffer read operation reads an element from the start index position and the start index is incremented to the next buffer position.
The start and end indexes are not enough to tell buffer full or empty state while also utilizing all buffer slots, but can if the buffer only has a maximum in-use size of Length - 1. In this case, the buffer is empty if the start and end indexes are equal and full when the in-use size is Length - 1.
Another solution is to have another integer count that is incremented at a write operation and decremented at a read operation. Then checking for emptiness means testing count equals 0 and checking for fullness means testing count equals Length.The following source code is a C implementation together with a minimal test. Function put() puts an item in the buffer, function get() gets an item from the buffer. Both functions take care about the capacity of the buffer :

Optimization
A circular-buffer implementation may be optimized by mapping the underlying buffer to two contiguous regions of virtual memory. (Naturally, the underlying buffer‘s length must then equal some multiple of the system’s page size.) Reading from and writing to the circular buffer may then be carried out with greater efficiency by means of direct memory access; those accesses which fall beyond the end of the first virtual-memory region will automatically wrap around to the beginning of the underlying buffer. When the read offset is advanced into the second virtual-memory region, both offsets—read and write—are decremented by the length of the underlying buffer.

Fixed-length-element and contiguous-block circular buffer
Perhaps the most common version of the circular buffer uses 8-bit bytes as elements.
Some implementations of the circular buffer use fixed-length elements that are bigger than 8-bit bytes—16-bit integers for audio buffers, 53-byte ATM cells for telecom buffers, etc. Each item is contiguous and has the correct data alignment, so software reading and writing these values can be faster than software that handles non-contiguous and non-aligned values.
Ping-pong buffering can be considered a very specialized circular buffer with exactly two large fixed-length elements.
The bip buffer (bipartite buffer) is very similar to a circular buffer, except it always returns contiguous blocks which can be variable length. This offers nearly all the efficiency advantages of a circular buffer while maintaining the ability for the buffer to be used in APIs that only accept contiguous blocks.Fixed-sized compressed circular buffers use an alternative indexing strategy based on elementary number theory to maintain a fixed-sized compressed representation of the entire data sequence.

References
External links
CircularBuffer at the Portland Pattern Repository
Boost:
Templated Circular Buffer Container: circular_buffer/base.hpp
Synchronized Bounded Queue:  sync_bounded_queue.hpp
CB in Linux kernel
CB in DSP
Circular queue in C Archived 2018-10-29 at the Wayback Machine",11891734,https://en.wikipedia.org/wiki/Circular_buffer
Dope vector,"In computer programming, a dope vector is a data structure used to hold information about a data object, especially its memory layout.","In computer programming, a dope vector is a data structure used to hold information about a data object, especially its memory layout.

Purpose
Dope vectors are most commonly used to describe arrays, which commonly store multiple instances of a particular datatype as a contiguous block of memory. For example, an array containing 100 elements, each of which occupies 32 bytes, requires 100 × 32 bytes. By itself, such a memory block has no place to keep track of how large the array (or other object) is overall, how large each element within it is, or how many elements it contains. A dope vector is a place to store such information. Dope vectors can also describe structures which may contain arrays or variable elements.
If such an array is stored contiguously, with the first byte at memory location M, then its last byte is at location M + 3199. A major advantage of this arrangement is that locating item N is easy: it begins at location M + (N × 32). Of course, the value 32 must be known (this value is commonly called the ""stride"" of the array or the ""width""  of the array's elements). Navigating an array data structure using an index is called dead reckoning.
This arrangement, however (without adding dope vectors) means that having the location of item N is not enough to discover the index N itself; or the stride; or whether there are elements at N − 1 or N + 1. For example, a function or method may iterate over all the items in an array and pass each one to another function or method, which does not know the item is part of an array at all, much less where or how large the array is.
Without a dope vector, even knowing the address of the entire array does not tell you how big it is. This is important because writing to the N + 1 element in an array that only contains N elements, will likely destroy some other data. Because many programming languages treat character strings as a kind of array, this leads directly to the infamous buffer overflow problem.
A dope vector reduces these problems by storing a small amount of metadata along with an array (or other object). With dope vectors, a compiler can easily (and optionally) insert code that prevents accidentally writing beyond the end of an array or other object. Alternatively, the programmer can access the dope vector when desired, for safety or other purposes.

Description
The exact set of metadata included in a dope vector varies from one language and/or operating system to another, but a dope vector for an array might contain:

a pointer to the location in memory where the array elements begin (this is normally identical to the location of the zeroth element of the array (element with all subscripts 0). (This might not be the first actual element if subscripts do not start at zero.)
the type of each array element (integer, Boolean, a particular class, etc.).
the rank of an array.
the extent of an array (its range of indices). (In many languages the starting index for arrays is fixed at zero, or one, but the ending index is set when the array is (re-)allocated.)
for arrays where the extent in use at a given time may change, the maximum and current extents may both be stored.
the stride of an array, or the amount of memory occupied by each element of the array.A program then can refer to the array (or other dope-vector-using object) by referring to the dope vector. This is commonly automatic in high-level languages. Getting to an element of the array costs a tiny bit more (commonly one instruction, which fetches the pointer to the actual data from out of the dope vector). On the other hand, doing many other common operations are easier and/or faster:

Without a dope vector, determining the number of elements in the array is impossible. Thus it is common to add an extra element to the end of an array, with a ""reserved"" value (such as NULL). The length can then be determined by scanning forward through the array, counting elements until this ""end-marker"" is reached. Of course, this makes length-checking much slower than looking up the length directly in a dope vector.
Without knowing the extent of an array, it is not possible to free() (unallocate) that memory when it is no longer needed. Thus, without dope vectors, something must store that length somewhere else. For example, asking a particular OS to allocate space for a 3200-byte array, might cause it to allocate 3204 bytes at some location M; it would then store the size in the first 4 bytes, and tell the requesting program the allocated space starts at M+4 (so that the caller will not treat the extra 4 bytes as part of the array proper). This extra data is not considered a dope vector, but achieves some of the same goals.
Without dope vectors, extra information must also be kept about the stride (or width) of array elements. In C, this information is handled by the compiler, which must keep track of a datatype distinction between ""pointer to an array of 20-byte-wide elements"", and ""pointer to an array of 1000-byte-wide elements"". This means that a pointer to an element in either kind of array can be incremented or decremented in order to reach the next or previous element; but it also means that array widths must be fixed at an earlier stage.Even with a dope vector, having (only) a pointer to a particular member of an array does not enable finding the position in the array, or the location of the array or the dope vector itself. If that is desired, such information can be added to each element within the array. Such per-element information can be useful, but is not part of the dope vector.
Dope vectors can be a general facility, shared across multiple datatypes (not just arrays and/or strings).

See also
Data descriptor
Iliffe vector
Reflection (computer programming)


== References ==",366016,https://en.wikipedia.org/wiki/Dope_vector
Dynamic array,"In computer science, a dynamic array, growable array, resizable array, dynamic table, mutable array, or array list is a random access, variable-size list data structure that allows elements to be added or removed. It is supplied with standard libraries in many modern mainstream programming languages. Dynamic arrays overcome a limit of static arrays, which have a fixed capacity that needs to be specified at allocation.
A dynamic array is not the same thing as a dynamically allocated array or variable-length array, either of which is an array whose size is fixed when the array is allocated, although a dynamic array may use such a fixed-size array as a back end.","In computer science, a dynamic array, growable array, resizable array, dynamic table, mutable array, or array list is a random access, variable-size list data structure that allows elements to be added or removed. It is supplied with standard libraries in many modern mainstream programming languages. Dynamic arrays overcome a limit of static arrays, which have a fixed capacity that needs to be specified at allocation.
A dynamic array is not the same thing as a dynamically allocated array or variable-length array, either of which is an array whose size is fixed when the array is allocated, although a dynamic array may use such a fixed-size array as a back end.

Bounded-size dynamic arrays and capacity
A simple dynamic array can be constructed by allocating an array of fixed-size, typically larger than the number of elements immediately required. The elements of the dynamic array are stored contiguously at the start of the underlying array, and the remaining positions towards the end of the underlying array are reserved, or unused. Elements can be added at the end of a dynamic array in constant time by using the reserved space, until this space is completely consumed. When all space is consumed, and an additional element is to be added, then the underlying fixed-size array needs to be increased in size. Typically resizing is expensive because it involves allocating a new underlying array and copying each element from the original array. Elements can be removed from the end of a dynamic array in constant time, as no resizing is required. The number of elements used by the dynamic array contents is its logical size or size, while the size of the underlying array is called the dynamic array's capacity or physical size, which is the maximum possible size without relocating data.A fixed-size array will suffice in applications where the maximum logical size is fixed (e.g. by specification), or can be calculated before the array is allocated. A dynamic array might be preferred if:

the maximum logical size is unknown, or difficult to calculate, before the array is allocated
it is considered that a maximum logical size given by a specification is likely to change
the amortized cost of resizing a dynamic array does not significantly affect performance or responsiveness

Geometric expansion and amortized cost
To avoid incurring the cost of resizing many times, dynamic arrays resize by a large amount, such as doubling in size, and use the reserved space for future expansion. The operation of adding an element to the end might work as follows:

As n elements are inserted, the capacities form a geometric progression. Expanding the array by any constant proportion a ensures that inserting n elements takes O(n) time overall, meaning that each insertion takes amortized constant time. Many dynamic arrays also deallocate some of the underlying storage if its size drops below a certain threshold, such as 30% of the capacity. This threshold must be strictly smaller than 1/a in order to provide hysteresis (provide a stable band to avoid repeatedly growing and shrinking) and support mixed sequences of insertions and removals with amortized constant cost.
Dynamic arrays are a common example when teaching amortized analysis.

Growth factor
The growth factor for the dynamic array depends on several factors including a space-time trade-off and algorithms used in the memory allocator itself. For growth factor a, the average time per insertion operation is about a/(a−1), while the number of wasted cells is bounded above by (a−1)n. If memory allocator uses a first-fit allocation algorithm, then growth factor values such as a=2 can cause dynamic array expansion to run out of memory even though a significant amount of memory may still be available. There have been various discussions on ideal growth factor values, including proposals for the golden ratio as well as the value 1.5. Many textbooks, however, use a = 2 for simplicity and analysis purposes.Below are growth factors used by several popular implementations:

Performance
The dynamic array has performance similar to an array, with the addition of new operations to add and remove elements:

Getting or setting the value at a particular index (constant time)
Iterating over the elements in order (linear time, good cache performance)
Inserting or deleting an element in the middle of the array (linear time)
Inserting or deleting an element at the end of the array (constant amortized time)Dynamic arrays benefit from many of the advantages of arrays, including good locality of reference and data cache utilization, compactness (low memory use), and random access. They usually have only a small fixed additional overhead for storing information about the size and capacity. This makes dynamic arrays an attractive tool for building cache-friendly data structures. However, in languages like Python or Java that enforce reference semantics, the dynamic array generally will not store the actual data, but rather it will store references to the data that resides in other areas of memory. In this case, accessing items in the array sequentially will actually involve accessing multiple non-contiguous areas of memory, so the many advantages of the cache-friendliness of this data structure are lost.
Compared to linked lists, dynamic arrays have faster indexing (constant time versus linear time) and typically faster iteration due to improved locality of reference; however, dynamic arrays require linear time to insert or delete at an arbitrary location, since all following elements must be moved, while linked lists can do this in constant time. This disadvantage is mitigated by the gap buffer and tiered vector variants discussed under Variants below. Also, in a highly fragmented memory region, it may be expensive or impossible to find contiguous space for a large dynamic array, whereas linked lists do not require the whole data structure to be stored contiguously.
A balanced tree can store a list while providing all operations of both dynamic arrays and linked lists reasonably efficiently, but both insertion at the end and iteration over the list are slower than for a dynamic array, in theory and in practice, due to non-contiguous storage and tree traversal/manipulation overhead.

Variants
Gap buffers are similar to dynamic arrays but allow efficient insertion and deletion operations clustered near the same arbitrary location. Some deque implementations use array deques, which allow amortized constant time insertion/removal at both ends, instead of just one end.
Goodrich presented a dynamic array algorithm called tiered vectors that provides O(n1/k) performance for insertions and deletions from anywhere in the array, and O(k) get and set, where k ≥ 2 is a constant parameter.
Hashed array tree (HAT) is a dynamic array algorithm published by Sitarski in 1996. Hashed array tree wastes order n1/2 amount of storage space, where n is the number of elements in the array. The algorithm has O(1) amortized performance when appending a series of objects to the end of a hashed array tree.
In a 1999 paper, Brodnik et al. describe a tiered dynamic array data structure, which wastes only n1/2 space for n elements at any point in time, and they prove a lower bound showing that any dynamic array must waste this much space if the operations are to remain amortized constant time. Additionally, they present a variant where growing and shrinking the buffer has not only amortized but worst-case constant time.
Bagwell (2002) presented the VList algorithm, which can be adapted to implement a dynamic array.
Naïve resizable arrays -- also called  ""the worst implementation"" of resizable arrays -- keep the allocated size of the array exactly big enough for all the data it contains, perhaps by calling realloc for each and every item added to the array. Naïve resizable arrays are the simplest way of implementing a resizeable array in C. They don't waste any memory, but appending to the end of the array always takes Θ(n) time.
Linearly growing arrays pre-allocate (""waste"") Θ(1) space every time they re-size the array, making them many times faster than naïve resizable arrays -- appending to the end of the array still takes Θ(n) time but with a much smaller constant.
Naïve resizable arrays and linearly growing arrays may be useful when a space-constrained application needs lots of small resizable arrays;
they are also commonly used as an educational example leading to exponentially growing dynamic arrays.

Language support
C++'s std::vector and Rust's std::vec::Vec are implementations of dynamic arrays, as are the ArrayList classes supplied with the Java API: 236  and the .NET Framework.: 22 The generic List<> class supplied with version 2.0 of the .NET Framework is also implemented with dynamic arrays. Smalltalk's OrderedCollection is a dynamic array with dynamic start and end-index, making the removal of the first element also O(1). 
Python's list datatype implementation is a dynamic array the growth pattern of which is:  0, 4, 8, 16, 24, 32, 40, 52, 64, 76, ...Delphi and D implement dynamic arrays at the language's core. 
Ada's Ada.Containers.Vectors generic package provides dynamic array implementation for a given subtype. 
Many scripting languages such as Perl and Ruby offer dynamic arrays as a built-in primitive data type. 
Several cross-platform frameworks provide dynamic array implementations for C, including CFArray and CFMutableArray in Core Foundation, and GArray and GPtrArray in GLib.
Common Lisp provides a rudimentary support for resizable vectors by allowing to configure the built-in array type as adjustable and the location of insertion by the fill-pointer.

References
External links
NIST Dictionary of Algorithms and Data Structures: Dynamic array
VPOOL - C language implementation of dynamic array.
CollectionSpy — A Java profiler with explicit support for debugging ArrayList- and Vector-related issues.
Open Data Structures - Chapter 2 - Array-Based Lists, Pat Morin",1456434,https://en.wikipedia.org/wiki/Dynamic_array
Flexible array member,"C struct data types may end with a flexible array member with no specified size:

Typically, such structures serve as the header in a larger, variable memory allocation:","C struct data types may end with a flexible array member with no specified size:

Typically, such structures serve as the header in a larger, variable memory allocation:

Effect on struct size and padding
The sizeof operator on such a struct gives the size of the structure as if the flexible array member were empty. This may include padding added to accommodate the flexible member; the compiler is also free to re-use such padding as part of the array itself.It is common to allocate sizeof(struct) + array_len*sizeof(array element) bytes. 
This is not wrong, but it may allocate a few more bytes than necessary: the compiler may be re-purposing some of the padding that is included in sizeof(struct). Should this be a concern, macros are available to compute the minimum size while ensuring that the compiler's padding is not disrupted. 
As the array may start in the padding before the end of the structure, its content should always be accessed via indexing (arr[i]) or  offsetof, not sizeof.

Availability
Flexible array members were officially standardized in C99. In practice, compilers (e.g., GCC,MSVC) provided them well before C99 was standardized.
Flexible array members are not officially part of C++, but language extensions are widely available.


== References ==",44866380,https://en.wikipedia.org/wiki/Flexible_array_member
Gap buffer,"A gap buffer in computer science is a dynamic array that allows efficient insertion and deletion operations clustered near the same location. Gap buffers are especially common in text editors, where most changes to the text occur at or near the current location of the cursor. The text is stored in a large buffer in two contiguous segments, with a gap between them for inserting new text. Moving the cursor involves copying text from one side of the gap to the other (sometimes copying is delayed until the next operation that changes the text).  Insertion adds new text at the end of the first segment; deletion deletes it.
Text in a gap buffer is represented as two strings, which take very little extra space and which can be searched and displayed very quickly, compared to more sophisticated data structures such as linked lists. However, operations at different locations in the text and ones that fill the gap (requiring a new gap to be created) may require copying most of the text, which is especially inefficient for large files.  The use of gap buffers is based on the assumption that such recopying occurs rarely enough that its cost can be amortized over the more common cheap operations. This makes the gap buffer a simpler alternative to the rope for use in text editors such as Emacs.","A gap buffer in computer science is a dynamic array that allows efficient insertion and deletion operations clustered near the same location. Gap buffers are especially common in text editors, where most changes to the text occur at or near the current location of the cursor. The text is stored in a large buffer in two contiguous segments, with a gap between them for inserting new text. Moving the cursor involves copying text from one side of the gap to the other (sometimes copying is delayed until the next operation that changes the text).  Insertion adds new text at the end of the first segment; deletion deletes it.
Text in a gap buffer is represented as two strings, which take very little extra space and which can be searched and displayed very quickly, compared to more sophisticated data structures such as linked lists. However, operations at different locations in the text and ones that fill the gap (requiring a new gap to be created) may require copying most of the text, which is especially inefficient for large files.  The use of gap buffers is based on the assumption that such recopying occurs rarely enough that its cost can be amortized over the more common cheap operations. This makes the gap buffer a simpler alternative to the rope for use in text editors such as Emacs.

Example
Below are some examples of operations with buffer gaps.  The gap is represented by the empty space between the square brackets.  This representation is a bit misleading: in a typical implementation, the endpoints of the gap are tracked using pointers or array indices, and the contents of the gap are ignored; this allows, for example, deletions to be done by adjusting a pointer without changing the text in the buffer.
Initial state:

This is the way [                     ]out.

User inserts some new text:

This is the way the world started [   ]out.

User moves the cursor before ""started""; system moves ""started "" from the first buffer to the second buffer.

This is the way the world [   ]started out.

User adds text filling the gap; system creates new gap:

This is the way the world as we know it [                   ]started out.

See also
Dynamic array, the special case of a gap buffer where the gap is always at the end
Zipper (data structure), conceptually a generalization of the gap buffer.
Linked list
Circular buffer
Rope (computer science)
Piece table - data structure used by Bravo and Microsoft Word

References
External links
Implementation in C
Overview and implementation in .NET/C#
Brief overview and sample C++ code
Implementation of a cyclic sorted gap buffer in .NET/C#
Use of gap buffer in early editor. (First written somewhere between 1969 and 1971)
emacs gap buffer info(Emacs gap buffer reference)
Flexichain: An editable sequence and its gap-buffer implementation
Text showdown: Gap Buffers vs Ropes",378974,https://en.wikipedia.org/wiki/Gap_buffer
Generalized suffix array,"In computer science, a generalized suffix array (GSA) is a suffix array containing all suffixes for a set of strings. Given the set of strings S=S1,S2,S3,...,Sk{\displaystyle S=S_{1},S_{2},S_{3},...,S_{k}} of total length n{\displaystyle n}, it is a lexicographically sorted array of all suffixes of each string in S{\displaystyle S}. It is primarily used in bioinformatics and string processing.","In computer science, a generalized suffix array (GSA) is a suffix array containing all suffixes for a set of strings. Given the set of strings S=S1,S2,S3,...,Sk{\displaystyle S=S_{1},S_{2},S_{3},...,S_{k}} of total length n{\displaystyle n}, it is a lexicographically sorted array of all suffixes of each string in S{\displaystyle S}. It is primarily used in bioinformatics and string processing.

Functionality
The functionality of a generalized suffix array is as follows:
For a collection or set of strings, S=S1,S2,S3,...,Sk{\displaystyle S=S_{1},S_{2},S_{3},...,S_{k}}.
It is a lexicographically sorted array of all suffixes of each string in the set S{\displaystyle S}.
In the array, each suffix is represented by an integer pair (i,j){\displaystyle (i,j)} which denotes the suffix starting from position j{\displaystyle j} in si{\displaystyle s_{i}}.
In the case where different strings in S{\displaystyle S} have identical suffixes, in the generalized suffix array, those suffixes will occupy consecutive positions. However, for convenience, the exception can be made where repeats will not be listed.A generalized suffix array can be generated for a generalized suffix tree. When compared to a generalized suffix tree, while the generalized suffix array will require more time to construct, it will use less space than the tree.

Construction Algorithms and Implementations
Algorithms and tools for constructing a generalized suffix array include:

Fei Shi's (1996) algorithm which runs in O(Nlog⁡n){\displaystyle {\mathcal {O}}(N\log n)} worst case time and O(N){\displaystyle {\mathcal {O}}(N)} space, where N{\displaystyle N} is the sum of the lengths of all strings in S{\displaystyle S} and n{\displaystyle n} the length of the longest string in S{\displaystyle S}. This includes sorting, searching and finding the longest common prefixes.
The external generalized enhanced suffix array, or eGSA, construction algorithm which specializes in external memory construction, is particularly useful when the size of the input collection or data structure is larger than the amount of available internal memory
gsufsort is an open-source, fast, portable and lightweight tool for the construction of generalized suffix arrays and related data structures like Burrows–Wheeler transform or LCP Array)
Mnemonist, a collection of data structures implemented in JavaScript contains an implementation for a generalized suffix tree and can be found publicly on npm and GitHub.

Solving the Pattern Matching Problem
Generalized suffix arrays can be used to solve the pattern matching problem:
Given a pattern P{\displaystyle P} and a text T{\displaystyle T}, find all occurrences of P{\displaystyle P} in T{\displaystyle T}.
Using the generalized suffix array G{\displaystyle G} of T{\displaystyle T}, then first, the suffixes that have P{\displaystyle P} as a prefix need to be found.
Since G{\displaystyle G} is a lexicographically sorted array of the suffixes of T{\displaystyle T}, then all such suffixes will appear in consecutive positions within G{\displaystyle G}. Particularly important, since G{\displaystyle G} is sorted, it makes identification of suffixes possible and easy using binary search.
Using binary search, first find the smallest index i{\displaystyle i} in G{\displaystyle G} such that suffG[i]{\displaystyle suff_{G}[i]} contains P{\displaystyle P} as a prefix, or determine that no such suffix is present. In the case where the suffix is not found, P{\displaystyle P} does not occur in T{\displaystyle T}. Otherwise, find the largest index j(≥i){\displaystyle j(\geq i)} which contains P{\displaystyle P} as a prefix. The elements in the range G[i..j]{\displaystyle G[i..j]} indicate the starting positions of the occurrences of P{\displaystyle P} in T{\displaystyle T}.
Binary search on G{\displaystyle G} takes Θ(logn){\displaystyle \Theta (logn)} comparisons. P{\displaystyle P} is compared with a suffix to determine their lexicographic order in each comparison that is done. Thus, this requires comparing at most |P|=m{\displaystyle |P|=m} characters. Note that a lcp{\displaystyle lcp} array is not required, but will offer the benefit of a lower running time.The runtime of the algorithm is Θ(mlogn){\displaystyle \Theta (mlogn)}. By comparison, solving this problem using suffix trees takes Θ(m){\displaystyle \Theta (m)} time. Note that with a generalized suffix array, the space required is smaller compared to a suffix tree, since the algorithm only requires space for n{\displaystyle n} words and the space to store the string. As mentioned above, by optionally keeping track of lcp{\displaystyle lcp} information which will use slightly more space, the running time of the algorithm can be improved to Θ(m+logn){\displaystyle \Theta (m+logn)}.

Other Applications
A generalized suffix array can be utilized to compute the longest common subsequence of all the strings in a set or collection. A naive implementation would compute the largest common subsequence of all the strings in the set in Θ(n2){\displaystyle \Theta (n^{2})}.
A generalized suffix array can be utilized to find the longest previous factor array, a concept central to text compression techniques and in the detection of motifs and repeats

See also
Suffix Tree
Suffix Array
Generalized Suffix Tree
Pattern matching problem
Bioinformatics

References
External links
Generalized enhanced suffix array construction in external memory",67630778,https://en.wikipedia.org/wiki/Generalized_suffix_array
Grid file,"In computer science, a grid file or bucket grid is a point access method which splits a space into a non-periodic grid where one or more cells of the grid refer to a small set of points. Grid files (a symmetric data structure) provide an efficient method of storing these indexes on disk to perform complex data lookups.
It provides a grid of n-dimensions where n represents how many keys can be used to reference a single point.
Grid files do not contain any data themselves but instead contain references to the correct bucket.","In computer science, a grid file or bucket grid is a point access method which splits a space into a non-periodic grid where one or more cells of the grid refer to a small set of points. Grid files (a symmetric data structure) provide an efficient method of storing these indexes on disk to perform complex data lookups.
It provides a grid of n-dimensions where n represents how many keys can be used to reference a single point.
Grid files do not contain any data themselves but instead contain references to the correct bucket.

Uses
A grid file is usually used in cases where a single value can be referenced by multiple keys.
A grid file began being used because ""traditional file structures that provide multikey access to records, for example, inverted files, are extensions of file structures originally designed for single-key access. They manifest various deficiencies in particular for multikey access to highly dynamic files.""In a traditional single dimensional data structure (e.g. hash), a search on a single criterion is usually very simple but searching for a second criterion can be much more complex.
Grid files represent a special kind of hashing, where the traditional hash is replaced by a grid directory.

Examples
Census Database
Sources:Consider a database containing data from a census. A single record represents a single household, and all records are grouped into buckets. All records in a bucket can be indexed by either their city (which is the same for all records in the bucket), and the streets in that city whose names begin with the same letter.
A grid file can be used to provide an efficient index for this structure, where records come in groupings of 26, each of them relating to street names in a city starting with one of the letters of the alphabet. This structure can be thought of as an array, table, or grid with two dimensions which we will call the x and y axes.
One may consider the x-axis to be the city and the y-axis to be each of the letters in the alphabet, or alternatively, the first letter of each street.
Each record in this structure is known as a cell. Each cell will contain a pointer to the appropriate bucket in the database where the actual data is stored. An extra cell, or record header, may be required to store the name of the city. Other cells grouped with it will only need to contain the pointer to their respective bucket, since the first cell corresponds to street names beginning with ""A"", the second to ""B"", and so on.
The database can be further extended to contain a continent field to expand the census to other continents. This would cause records in the same bucket to correspond to households on a street beginning with the same letter, in the same city, in the same continent.
The cells in the grid file would then consist of a city header, and six (one for each continent, not including Antarctica) groupings of 26 cells relating to the streets with the same starting letter, in the same city, on the same continent and could now be thought of as a three-dimensional array.

Advantages
Since a single entry in the grid file contains pointers to all records indexed by the specified keys:
No special computations are required
Only the right records are retrieved
Can also be used for single search key queries
Easy to extend to queries on n search keys
Significant improvement in processing time for multiple-key queries
Has a two-disk-access upper bound for accessing data.

Disadvantages
However, because of the nature of the grid file, which gives it its advantages, there are also some disadvantages:
Imposes space overhead
Performance overhead on insertion and deletion

Related Data Structures
multilayer grid file
twin grid files
BANG file

See also
Lattice graph
Grid (spatial index)
Index (database), Quadtree, Kd-tree, UB-tree, R-tree, range tree as alternatives.


== References ==",6505771,https://en.wikipedia.org/wiki/Grid_file
Hashed array tree,"In computer science, a hashed array tree (HAT) is a dynamic array data-structure published by Edward Sitarski in 1996, maintaining an array of separate memory fragments (or ""leaves"") to store the data elements, unlike simple dynamic arrays which maintain their data in one contiguous memory area. Its primary objective is to reduce the amount of element copying due to automatic array resizing operations, and to improve memory usage patterns.
Whereas simple dynamic arrays based on geometric expansion waste linear (Ω(n)) space, where n is the number of elements in the array, hashed array trees waste only order O(√n) storage space. An optimization of the algorithm allows elimination of data copying completely, at a cost of increasing the wasted space.
It can perform access in constant (O(1)) time, though slightly slower than simple dynamic arrays. The algorithm has O(1) amortized performance when appending a series of objects to the end of a hashed array tree. Contrary to its name, it does not use hash functions.","In computer science, a hashed array tree (HAT) is a dynamic array data-structure published by Edward Sitarski in 1996, maintaining an array of separate memory fragments (or ""leaves"") to store the data elements, unlike simple dynamic arrays which maintain their data in one contiguous memory area. Its primary objective is to reduce the amount of element copying due to automatic array resizing operations, and to improve memory usage patterns.
Whereas simple dynamic arrays based on geometric expansion waste linear (Ω(n)) space, where n is the number of elements in the array, hashed array trees waste only order O(√n) storage space. An optimization of the algorithm allows elimination of data copying completely, at a cost of increasing the wasted space.
It can perform access in constant (O(1)) time, though slightly slower than simple dynamic arrays. The algorithm has O(1) amortized performance when appending a series of objects to the end of a hashed array tree. Contrary to its name, it does not use hash functions.

Definitions
As defined by Sitarski, a hashed array tree has a top-level directory containing a power of two number of leaf arrays.  All leaf arrays are the same size as the top-level directory.  This structure superficially resembles a hash table with array-based collision chains, which is the basis for the name hashed array tree. A full hashed array tree can hold m2 elements, where m is the size of the top-level directory. The use of powers of two enables faster physical addressing through bit operations instead of arithmetic operations of quotient and remainder and ensures the O(1) amortized performance of append operation in the presence of occasional global array copy while expanding.

Expansions and size reductions
In a usual dynamic array geometric expansion scheme, the array is reallocated as a whole sequential chunk of memory with the new size a double of its current size (and the whole data is then moved to the new location). This ensures O(1) amortized operations at a cost of O(n) wasted space, as the enlarged array is filled to the half of its new capacity.
When a hashed array tree is full, its directory and leaves must be restructured to twice their prior size to accommodate additional append operations. The data held in old structure is then moved into the new locations. Only one new leaf is then allocated and added into the top array which thus becomes filled only to a quarter of its new capacity. All the extra leaves are not allocated yet, and will only be allocated when needed, thus wasting only O(√n) of storage.There are multiple alternatives for reducing size: when a hashed array tree is one eighth full, it can be restructured to a smaller, half-full hashed array tree; another option is only freeing unused leaf arrays, without resizing the leaves. Further optimizations include adding new leaves without resizing while growing the directory array as needed, possibly through geometric expansion. This will eliminate the need for data copying completely at the cost of making the wasted space be O(n), with a small constant, and only performing restructuring when a set threshold overhead is reached.

Related data structures
Brodnik et al. presented a dynamic array algorithm with a similar space wastage profile to hashed array trees. Brodnik's implementation retains previously allocated leaf arrays, with a more complicated address calculation function as compared to hashed array trees.

See also
Dynamic array
Unrolled linked list
B-tree


== References ==",12673184,https://en.wikipedia.org/wiki/Hashed_array_tree
Iliffe vector,"In computer programming, an Iliffe vector, also known as a display, is a data structure used to implement multi-dimensional arrays.","In computer programming, an Iliffe vector, also known as a display, is a data structure used to implement multi-dimensional arrays.

Data structure
An Iliffe vector for an n-dimensional array (where n ≥ 2) consists of a vector (or 1-dimensional array) of pointers to an (n − 1)-dimensional array. They are often used to avoid the need for expensive multiplication operations when performing address calculation on an array element. They can also be used to implement jagged arrays, such as triangular arrays, triangular matrices and other kinds of irregularly shaped arrays. The data structure is named after John K. Iliffe.
Their disadvantages include the need for multiple chained pointer indirections to access an element, and the extra work required to determine the next row in an n-dimensional array to allow an optimising compiler to prefetch it. Both of these are a source of delays on systems where the CPU is significantly faster than main memory.
The Iliffe vector for a 2-dimensional array is simply a vector of pointers to vectors of data, i.e., the Iliffe vector represents the columns of an array where each column element is a pointer to a row vector.
Multidimensional arrays in languages such as Java, Python (multidimensional lists), Ruby, Visual Basic .NET, Perl, PHP, JavaScript, Objective-C (when using NSArray, not a row-major C-style array), Swift, and Atlas Autocode are implemented as Iliffe vectors.  Iliffe vectors were used to implement sparse multidimensional arrays in the OLAP product Holos.
Iliffe vectors are contrasted with dope vectors in languages such as Fortran, which contain the stride factors and offset values for the subscripts in each dimension.

References
John K. Iliffe (1961). ""The Use of The Genie System in Numerical Calculations"". Annual Review in Automatic Programming. 2: 25. doi:10.1016/S0066-4138(61)80002-5.

Further reading
""Chapter 3: Data Structure Mappings"". Compiling Techniques. Associates Technology Literature Applications Society. Retrieved 5 May 2015.",1696737,https://en.wikipedia.org/wiki/Iliffe_vector
Index mapping,"Index mapping (or direct addressing, or a trivial hash function) in computer science describes using an array, in which each position corresponds to a key in the universe of possible values.
The technique is most effective when the universe of keys is reasonably small, such that allocating an array with one position for every possible key is affordable.
Its effectiveness comes from the fact that an arbitrary position in an array can be examined in constant time.","Index mapping (or direct addressing, or a trivial hash function) in computer science describes using an array, in which each position corresponds to a key in the universe of possible values.
The technique is most effective when the universe of keys is reasonably small, such that allocating an array with one position for every possible key is affordable.
Its effectiveness comes from the fact that an arbitrary position in an array can be examined in constant time.

Applicable arrays
There are many practical examples of data whose valid values are restricted within a small range. A trivial hash function is a suitable choice when such data needs to act as a lookup key. Some examples include:

month in the year (1–12)
day in the month (1–31)
day of the week (1–7)
human age (0–130) – e.g. lifecover actuary tables, fixed-term mortgage
ASCII characters (0–127), encompassing common mathematical operator symbols, digits, punctuation marks, and English language alphabet

Examples
Using a trivial hash function, in a non-iterative table lookup, can eliminate conditional testing and branching completely, reducing the instruction path length of a computer program.

Avoid branching
Roger Sayle gives an example of eliminating a multiway branch caused by a switch statement:

Which can be replaced with a table lookup:

See also
Associative array
Hash table
Lookup table


== References ==",25165023,https://en.wikipedia.org/wiki/Index_mapping
Irregular matrix,"An irregular matrix, or ragged matrix, is a matrix that has a different number of elements in each row. Ragged matrices are not used in linear algebra, since standard matrix transformations cannot be performed on them, but they are useful in computing as arrays which are called jagged arrays. Irregular matrices are typically stored using Iliffe vectors.
For example, the following is an irregular matrix:

[13112−372122]{\displaystyle {\begin{bmatrix}1&31&12&-3\\7&2\\1&2&2\end{bmatrix}}}","An irregular matrix, or ragged matrix, is a matrix that has a different number of elements in each row. Ragged matrices are not used in linear algebra, since standard matrix transformations cannot be performed on them, but they are useful in computing as arrays which are called jagged arrays. Irregular matrices are typically stored using Iliffe vectors.
For example, the following is an irregular matrix:

[13112−372122]{\displaystyle {\begin{bmatrix}1&31&12&-3\\7&2\\1&2&2\end{bmatrix}}}

See also
Regular matrix (disambiguation)
Empty matrix
Sparse matrix

References
Paul E. Black, Ragged matrix, from Dictionary of Algorithms and Data Structures, Paul E. Black, ed., NIST, 2004.",3366265,https://en.wikipedia.org/wiki/Irregular_matrix
Jagged array,"In computer science, a jagged  array, also known as a ragged  array  or irregular array  is an array of arrays of which the member arrays can be of different lengths, producing rows of jagged edges when visualized as output. In contrast, two-dimensional arrays are always rectangular so jagged arrays should not be confused with multidimensional arrays, but the former is often used to emulate the latter.
Arrays of arrays in languages such as Java, PHP, Python (multidimensional lists), Ruby, C#.NET, Visual Basic.NET, Perl, JavaScript, Objective-C, Swift, and Atlas Autocode are implemented as Iliffe vectors.","In computer science, a jagged  array, also known as a ragged  array  or irregular array  is an array of arrays of which the member arrays can be of different lengths, producing rows of jagged edges when visualized as output. In contrast, two-dimensional arrays are always rectangular so jagged arrays should not be confused with multidimensional arrays, but the former is often used to emulate the latter.
Arrays of arrays in languages such as Java, PHP, Python (multidimensional lists), Ruby, C#.NET, Visual Basic.NET, Perl, JavaScript, Objective-C, Swift, and Atlas Autocode are implemented as Iliffe vectors.

Examples
In C# and Java jagged arrays can be created with the following code:

In C and C++, a jagged array can be created (on the stack) using the following code:

In C/C++, jagged arrays can also be created (on the heap) with an array of pointers:

In C++/CLI, jagged array can be created with the code:

In Fortran, a jagged array can be created using derived types with allocatable component(s): 

In Python, jagged arrays are not native but one can use list comprehensions to create a multi-dimensional list which supports any dimensional matrix:

See also
Variable-length array
Iliffe vector


== References ==",1913333,https://en.wikipedia.org/wiki/Jagged_array
LCP array,"In computer science, the longest common prefix array (LCP array) is an auxiliary data structure to the suffix array. It stores the lengths of the longest common prefixes (LCPs) between all pairs of consecutive suffixes in a sorted suffix array.
For example, if A := [aab, ab, abaab, b, baab] is a suffix array, the longest common prefix between A[1] = aab and A[2] = ab is a which has length 1, so H[2] = 1 in the LCP array H. Likewise, the LCP of A[2] = ab and A[3] = abaab is ab, so H[3] = 2.
Augmenting the suffix array with the LCP array allows one to efficiently simulate top-down and bottom-up traversals of the suffix tree, speeds up pattern matching on the suffix array and is a prerequisite for compressed suffix trees.","In computer science, the longest common prefix array (LCP array) is an auxiliary data structure to the suffix array. It stores the lengths of the longest common prefixes (LCPs) between all pairs of consecutive suffixes in a sorted suffix array.
For example, if A := [aab, ab, abaab, b, baab] is a suffix array, the longest common prefix between A[1] = aab and A[2] = ab is a which has length 1, so H[2] = 1 in the LCP array H. Likewise, the LCP of A[2] = ab and A[3] = abaab is ab, so H[3] = 2.
Augmenting the suffix array with the LCP array allows one to efficiently simulate top-down and bottom-up traversals of the suffix tree, speeds up pattern matching on the suffix array and is a prerequisite for compressed suffix trees.

History
The LCP array was introduced in 1993, by Udi Manber and Gene Myers alongside the suffix array in order to improve the running time of their string search algorithm.

Definition
Let A{\displaystyle A} be the suffix array of the string S=s1,s2,…sn−1${\displaystyle S=s_{1},s_{2},\ldots s_{n-1}\$} of length n{\displaystyle n}, where ${\displaystyle \$} is a sentinel letter that is unique and lexicographically smaller than any other character. Let S[i,j]{\displaystyle S[i,j]} denote the substring of S{\displaystyle S} ranging from i{\displaystyle i} to j{\displaystyle j}. Thus, S[A[i],n]{\displaystyle S[A[i],n]} is the i{\displaystyle i}th smallest suffix of S{\displaystyle S}.
Let lcp⁡(v,w){\displaystyle \operatorname {lcp} (v,w)} denote the length of the longest common prefix between two strings v{\displaystyle v} and w{\displaystyle w}. Then the LCP array H[1,n]{\displaystyle H[1,n]} is an integer array of size n{\displaystyle n} such that H[1]{\displaystyle H[1]} is undefined and H[i]=lcp⁡(S[A[i−1],n],S[A[i],n]){\displaystyle H[i]=\operatorname {lcp} (S[A[i-1],n],S[A[i],n])} for every 1<i≤n{\displaystyle 1<i\leq n}. Thus H[i]{\displaystyle H[i]} stores the length of longest common prefix of the lexicographically i{\displaystyle i}th smallest suffix and its predecessor in the suffix array.
Difference between LCP array and suffix array:

Suffix array: Represents the lexicographic rank of each suffix of an array.
LCP array: Contains the maximum length prefix match between two consecutive suffixes, after they are sorted lexicographically.

Example
Consider the string S=banana${\displaystyle S={\textrm {banana\$}}}:

and its corresponding sorted suffix array A{\displaystyle A} :

Suffix array with suffixes written out underneath vertically:

Then the LCP array H{\displaystyle H} is constructed by comparing lexicographically consecutive suffixes to determine their longest common prefix:

So, for example, H[4]=3{\displaystyle H[4]=3} is the length of the longest common prefix ana{\displaystyle {\text{ana}}} shared by the suffixes A[3]=S[4,7]=ana${\displaystyle A[3]=S[4,7]={\textrm {ana\$}}} and A[4]=S[2,7]=anana${\displaystyle A[4]=S[2,7]={\textrm {anana\$}}}. Note that H[1]{\displaystyle H[1]} is undefined, since there is no lexicographically smaller suffix.

Efficient construction algorithms
LCP array construction algorithms can be divided into two different categories: algorithms that compute the LCP array as a byproduct to the suffix array and algorithms that use an already constructed suffix array in order to compute the LCP values.
Manber & Myers (1993) provide an algorithm to compute the LCP array alongside the suffix array in O(nlog⁡n){\displaystyle O(n\log n)} time. Kärkkäinen & Sanders (2003) show that it is also possible to modify their O(n){\displaystyle O(n)} time algorithm such that it computes the LCP array as well.  Kasai et al. (2001) present the first O(n){\displaystyle O(n)} time algorithm (FLAAP) that computes the LCP array given the text and the suffix array.
Assuming that each text symbol takes one byte and each entry of the suffix or LCP array takes 4 bytes, the major drawback of their algorithm is a large space occupancy of 13n{\displaystyle 13n} bytes, while the original output (text, suffix array, LCP array) only occupies 9n{\displaystyle 9n} bytes. Therefore, Manzini (2004) created a refined version of the algorithm of Kasai et al. (2001) (lcp9) and reduced the space occupancy to 9n{\displaystyle 9n} bytes. Kärkkäinen, Manzini & Puglisi (2009) provide another refinement of Kasai's algorithm (Φ{\displaystyle \Phi }-algorithm) that improves the running time. Rather than the actual LCP array, this algorithm builds the permuted LCP (PLCP) array, in which the values appear in text order rather than lexicographical order.
Gog & Ohlebusch (2011) provide two algorithms that although being theoretically slow (O(n2){\displaystyle O(n^{2})}) were faster than the above-mentioned algorithms in practice.
As of 2012, the currently fastest linear-time LCP array construction algorithm is due to Fischer (2011), which in turn is based on one of the fastest suffix array construction algorithms (SA-IS) by Nong, Zhang & Chan (2009). Fischer & Kurpicz (2017) based on Yuta Mori's DivSufSort is even faster.

Applications
As noted by Abouelhoda, Kurtz & Ohlebusch (2004) several string processing problems can be solved by the following kinds of tree traversals:

bottom-up traversal of the complete suffix tree
top-down traversal of a subtree of the suffix tree
suffix tree traversal using the suffix links.Kasai et al. (2001) show how to simulate a bottom-up traversal of the suffix tree using only the suffix array and LCP array. Abouelhoda, Kurtz & Ohlebusch (2004) enhance the suffix array with the LCP array and additional data structures and describe how this enhanced suffix array can be used to simulate all three kinds of suffix tree traversals. Fischer & Heun (2007) reduce the space requirements of the enhanced suffix array by preprocessing the LCP array for range minimum queries. Thus,  every problem that can be solved by suffix tree algorithms can also be solved using the enhanced suffix array.Deciding if a pattern P{\displaystyle P} of length m{\displaystyle m} is a substring of a string S{\displaystyle S} of length n{\displaystyle n} takes O(mlog⁡n){\displaystyle O(m\log n)} time if only the suffix array is used. By additionally using the LCP information, this bound can be improved to O(m+log⁡n){\displaystyle O(m+\log n)} time. Abouelhoda, Kurtz & Ohlebusch (2004) show how to improve this running time even further to achieve optimal O(m){\displaystyle O(m)} time. Thus, using suffix array and LCP array information, the decision query can be answered as fast as using the suffix tree.
The LCP array is also an essential part of compressed suffix trees which provide full suffix tree functionality like suffix links and lowest common ancestor queries. Furthermore, it can be used together with the suffix array to compute the Lempel-Ziv LZ77 factorization in O(n){\displaystyle O(n)} time.The longest repeated substring problem for a string S{\displaystyle S} of length n{\displaystyle n} can be solved in Θ(n){\displaystyle \Theta (n)} time using both the suffix array A{\displaystyle A} and the LCP array. It is sufficient to perform a linear scan through the LCP array in order to find its maximum value vmax{\displaystyle v_{max}} and the corresponding index i{\displaystyle i} where vmax{\displaystyle v_{max}} is stored. The longest substring that occurs at least twice is then given by S[A[i],A[i]+vmax−1]{\displaystyle S[A[i],A[i]+v_{max}-1]}.
The remainder of this section explains two applications of the LCP array in more detail: How the suffix array and the LCP array of a string can be used to construct the corresponding suffix tree and how it is possible to answer LCP queries for arbitrary suffixes using range minimum queries on the LCP array.

Find the number of occurrences of a pattern
In order to find the number of occurrences of a given string P{\displaystyle P} (length m{\displaystyle m}) in a text T{\displaystyle T} (length N{\displaystyle N}),
We use binary search against the suffix array of T{\displaystyle T} to find the starting and end position of all occurrences of P{\displaystyle P}.
Now to speed up the search, we use LCP  array, specifically a special version of the LCP array (LCP-LR below).The issue with using standard binary search (without the LCP information) is that in each of the O(log⁡N){\displaystyle O(\log N)} comparisons needed to be made, we compare P to the current entry of the suffix array, which means a full string comparison of up to m characters. So the complexity is O(mlog⁡N){\displaystyle O(m\log N)}.
The LCP-LR array helps improve this to O(m+log⁡N){\displaystyle O(m+\log N)}, in the following way:
At any point during the binary search algorithm, we consider, as usual, a range (L,…,R){\displaystyle (L,\dots ,R)} of the suffix array and its central point M{\displaystyle M}, and decide whether we continue our search in the left sub-range (L,…,M){\displaystyle (L,\dots ,M)} or in the right sub-range (M,…,R){\displaystyle (M,\dots ,R)}.  In order to make the decision, we compare P{\displaystyle P} to the string at M{\displaystyle M}. If P{\displaystyle P} is identical to M{\displaystyle M}, our search is complete. But if not, we have already compared the first k{\displaystyle k} characters of P{\displaystyle P} and then decided whether P{\displaystyle P} is lexicographically smaller or larger than M{\displaystyle M}. Let's assume the outcome is that P{\displaystyle P} is larger than M{\displaystyle M}.  So, in the next step, we consider (M,…,R){\displaystyle (M,\dots ,R)} and a new central point M′{\displaystyle M'} in the middle:

             M ...... M' ...... R
             |
      we know:
         lcp(P,M)==k

The trick now is that LCP-LR is precomputed such that an O(1){\displaystyle O(1)}-lookup tells us the longest common prefix of M{\displaystyle M} and M′{\displaystyle M'}, lcp(M,M′){\displaystyle \mathrm {lcp} (M,M')}.
We already know (from the previous step) that M{\displaystyle M} itself has a prefix of k{\displaystyle k} characters in common with P{\displaystyle P}: lcp(P,M)=k{\displaystyle \mathrm {lcp} (P,M)=k}. Now there are three possibilities:

Case 1: k<lcp(M,M′){\displaystyle k<\mathrm {lcp} (M,M')}, i.e. P{\displaystyle P} has fewer prefix characters in common with M than M has in common with M'. This means the (k+1)-th character of M' is the same as that of M, and since P is lexicographically larger than M, it must be lexicographically larger than M', too. So we continue in the right half (M',...,R).
Case 2: k>lcp(M,M′){\displaystyle k>\mathrm {lcp} (M,M')}, i.e. P{\displaystyle P} has more prefix characters in common with M{\displaystyle M} than M{\displaystyle M} has in common with M′{\displaystyle M'}. Consequently, if we were to compare P{\displaystyle P} to M′{\displaystyle M'}, the common prefix would be smaller than k{\displaystyle k}, and M′{\displaystyle M'} would be lexicographically larger than P{\displaystyle P}, so, without actually making the comparison, we continue in the left half (M,…,M′){\displaystyle (M,\dots ,M')}.
Case 3: k=lcp(M,M′){\displaystyle k=\mathrm {lcp} (M,M')}. So M and M' are both identical with P{\displaystyle P} in the first k{\displaystyle k} characters. To decide whether we continue in the left or right half, it suffices to compare P{\displaystyle P} to M′{\displaystyle M'} starting from the (k+1){\displaystyle (k+1)}th character.
We continue recursively.The overall effect is that no character of P{\displaystyle P} is compared to any character of the text more than once. The total number of character comparisons is bounded by m{\displaystyle m}, so the total complexity is indeed O(m+log⁡N){\displaystyle O(m+\log N)}.
We still need to precompute LCP-LR so it is able to tell us in O(1){\displaystyle O(1)} time the lcp between any two entries of the suffix array. We know the standard LCP array gives us the lcp of consecutive entries only, i.e. lcp(i−1,i){\displaystyle \mathrm {lcp} (i-1,i)} for any i{\displaystyle i}. However, M{\displaystyle M} and M′{\displaystyle M'} in the description above are not necessarily consecutive entries.
The key to this is to realize that only certain ranges (L,…,R){\displaystyle (L,\dots ,R)} will ever occur during the binary search: It always starts with (0,…,N){\displaystyle (0,\dots ,N)} and divides that at the center, and then continues either left or right and divide that half again and so forth. Another way of looking at it is : every entry of the suffix array occurs as central point of exactly one possible range during binary search. So there are exactly N distinct ranges (L…M…R){\displaystyle (L\dots M\dots R)} that can possibly play a role during binary search, and it suffices to precompute lcp(L,M){\displaystyle \mathrm {lcp} (L,M)} and lcp(M,R){\displaystyle \mathrm {lcp} (M,R)} for those N{\displaystyle N} possible ranges. So that is 2N{\displaystyle 2N} distinct precomputed values, hence LCP-LR is O(N){\displaystyle O(N)} in size.
Moreover, there is a straightforward recursive algorithm to compute the 2N{\displaystyle 2N} values of LCP-LR in O(N){\displaystyle O(N)} time from the standard LCP array.
To sum up:

It is possible to compute LCP-LR in O(N){\displaystyle O(N)} time and O(2N)=O(N){\displaystyle O(2N)=O(N)} space from LCP.
Using LCP-LR during binary search helps accelerate the search procedure from O(Mlog⁡N){\displaystyle O(M\log N)} to O(M+log⁡N){\displaystyle O(M+\log N)}.
We can use two binary searches to determine the left and right end of the match range for P{\displaystyle P}, and the length of the match range corresponds with the number of occurrences for P.

Suffix tree construction
Given the suffix array A{\displaystyle A} and the LCP array H{\displaystyle H} of a string S=s1,s2,…sn${\displaystyle S=s_{1},s_{2},\ldots s_{n}\$} of length n+1{\displaystyle n+1}, its suffix tree ST{\displaystyle ST} can be constructed in O(n){\displaystyle O(n)} time based on the following idea: Start with the partial suffix tree for the lexicographically smallest suffix and repeatedly insert the other suffixes in the order given by the suffix array.
Let STi{\displaystyle ST_{i}} be the partial suffix tree for 0≤i≤n{\displaystyle 0\leq i\leq n}. Further let d(v){\displaystyle d(v)} be the length of the concatenation of all path labels from the root of STi{\displaystyle ST_{i}} to node v{\displaystyle v}.

Start with ST0{\displaystyle ST_{0}}, the tree consisting only of the root. To insert A[i+1]{\displaystyle A[i+1]} into STi{\displaystyle ST_{i}}, walk up the rightmost path beginning at the recently inserted leaf A[i]{\displaystyle A[i]} to the root, until the deepest node v{\displaystyle v} with d(v)≤H[i+1]{\displaystyle d(v)\leq H[i+1]} is reached.
We need to distinguish two cases:

d(v)=H[i+1]{\displaystyle d(v)=H[i+1]}: This means that the concatenation of the labels on the root-to-v{\displaystyle v} path equals the longest common prefix of suffixes A[i]{\displaystyle A[i]} and A[i+1]{\displaystyle A[i+1]}.  In this case, insert A[i+1]{\displaystyle A[i+1]} as a new leaf x{\displaystyle x} of node v{\displaystyle v} and label the edge (v,x){\displaystyle (v,x)} with S[A[i+1]+H[i+1],n]{\displaystyle S[A[i+1]+H[i+1],n]}. Thus the edge label consists of the remaining characters of suffix A[i+1]{\displaystyle A[i+1]} that are not already represented by the concatenation of the labels of the root-to-v{\displaystyle v} path. This creates the partial suffix tree STi+1{\displaystyle ST_{i+1}}. 
d(v)<H[i+1]{\displaystyle d(v)<H[i+1]}: This means that the concatenation of the labels on the root-to-v{\displaystyle v} path displays less characters than the longest common prefix of suffixes A[i]{\displaystyle A[i]} and A[i+1]{\displaystyle A[i+1]} and the missing characters are contained in the edge label of v{\displaystyle v}'s rightmost edge. Therefore, we have to  split up that edge as follows: Let w{\displaystyle w} be the child of v{\displaystyle v} on STi{\displaystyle ST_{i}}'s rightmost path.Delete the edge (v,w){\displaystyle (v,w)}.
Add a new internal node y{\displaystyle y} and a new edge (v,y){\displaystyle (v,y)} with label S[A[i]+d(v),A[i]+H[i+1]−1]{\displaystyle S[A[i]+d(v),A[i]+H[i+1]-1]}. The new label consists of the missing characters of the longest common prefix of A[i]{\displaystyle A[i]} and A[i+1]{\displaystyle A[i+1]}. Thus, the concatenation of the labels of the root-to-y{\displaystyle y} path now displays the longest common prefix of A[i]{\displaystyle A[i]} and A[i+1]{\displaystyle A[i+1]}.
Connect w{\displaystyle w} to the newly created internal node y{\displaystyle y} by an edge (y,w){\displaystyle (y,w)} that is labeled S[A[i]+H[i+1],A[i]+d(w)−1]{\displaystyle S[A[i]+H[i+1],A[i]+d(w)-1]}. The new label consists of the remaining characters of the deleted edge (v,w){\displaystyle (v,w)} that were not used as the label of edge (v,y){\displaystyle (v,y)}.
Add A[i+1]{\displaystyle A[i+1]} as a new leaf x{\displaystyle x} and connect it to the new internal node y{\displaystyle y} by an edge (y,x){\displaystyle (y,x)} that is labeled S[A[i+1]+H[i+1],n]{\displaystyle S[A[i+1]+H[i+1],n]}. Thus the edge label consists of the remaining characters of suffix A[i+1]{\displaystyle A[i+1]} that are not already represented by the concatenation of the labels of the root-to-v{\displaystyle v} path.
This creates the partial suffix tree STi+1{\displaystyle ST_{i+1}}.A simple amortization argument shows that the running time of this algorithm is bounded by O(n){\displaystyle O(n)}:
The nodes that are traversed in step i{\displaystyle i} by walking up the rightmost path of STi{\displaystyle ST_{i}} (apart from the last node v{\displaystyle v}) are removed from the rightmost path, when A[i+1]{\displaystyle A[i+1]} is added to the tree as a new leaf. These nodes will never be traversed again for all subsequent steps j>i{\displaystyle j>i}. Therefore, at most 2n{\displaystyle 2n} nodes will be traversed in total.

LCP queries for arbitrary suffixes
The LCP array H{\displaystyle H} only contains the length of the longest common prefix of every pair of consecutive suffixes in the suffix array A{\displaystyle A}. However, with the help of the inverse suffix array A−1{\displaystyle A^{-1}} (A[i]=j⇔A−1[j]=i{\displaystyle A[i]=j\Leftrightarrow A^{-1}[j]=i}, i.e. the suffix S[j,n]{\displaystyle S[j,n]} that starts at position j{\displaystyle j} in S{\displaystyle S} is stored in position A−1[j]{\displaystyle A^{-1}[j]} in A{\displaystyle A}) and constant-time range minimum queries on H{\displaystyle H}, it is possible to determine the length of the longest common prefix of arbitrary suffixes in O(1){\displaystyle O(1)} time.
Because of the lexicographic order of the suffix array, every common prefix of the suffixes S[i,n]{\displaystyle S[i,n]} and S[j,n]{\displaystyle S[j,n]} has to be a common prefix of all suffixes between i{\displaystyle i}'s position in the suffix array A−1[i]{\displaystyle A^{-1}[i]} and j{\displaystyle j}'s position in the suffix array A−1[j]{\displaystyle A^{-1}[j]}. Therefore, the length of the longest prefix that is shared by all of these suffixes is the minimum value in the interval H[A−1[i]+1,A−1[j]]{\displaystyle H[A^{-1}[i]+1,A^{-1}[j]]}. This value can be found in constant time if H{\displaystyle H} is preprocessed for range minimum queries.
Thus given a string S{\displaystyle S} of length n{\displaystyle n}  and two arbitrary positions  i,j{\displaystyle i,j} in the string S{\displaystyle S}  with A−1[i]<A−1[j]{\displaystyle A^{-1}[i]<A^{-1}[j]}, the length of the longest common prefix of the suffixes S[i,n]{\displaystyle S[i,n]} and S[j,n]{\displaystyle S[j,n]} can be computed as follows: LCP⁡(i,j)=H[RMQH⁡(A−1[i]+1,A−1[j])]{\displaystyle \operatorname {LCP} (i,j)=H[\operatorname {RMQ} _{H}(A^{-1}[i]+1,A^{-1}[j])]}.

Notes
References
Abouelhoda, Mohamed Ibrahim; Kurtz, Stefan; Ohlebusch, Enno (2004). ""Replacing suffix trees with enhanced suffix arrays"". Journal of Discrete Algorithms. 2: 53–86. doi:10.1016/S1570-8667(03)00065-0.
Manber, Udi; Myers, Gene (1993). ""Suffix Arrays: A New Method for On-Line String Searches"". SIAM Journal on Computing. 22 (5): 935. CiteSeerX 10.1.1.105.6571. doi:10.1137/0222058. S2CID 5074629.
Kasai, T.; Lee, G.; Arimura, H.; Arikawa, S.; Park, K. (2001). Linear-Time Longest-Common-Prefix Computation in Suffix Arrays and Its Applications. Proceedings of the 12th Annual Symposium on Combinatorial Pattern Matching. Lecture Notes in Computer Science. Vol. 2089. pp. 181–192. doi:10.1007/3-540-48194-X_17. ISBN 978-3-540-42271-6.
Ohlebusch, Enno; Fischer, Johannes; Gog, Simon (2010). CST++. String Processing and Information Retrieval. Lecture Notes in Computer Science. Vol. 6393. p. 322. doi:10.1007/978-3-642-16321-0_34. ISBN 978-3-642-16320-3.
Kärkkäinen, Juha; Sanders, Peter (2003). Simple linear work suffix array construction. Proceedings of the 30th international conference on Automata, languages and programming. pp. 943–955. Retrieved 2012-08-28.
Fischer, Johannes (2011). Inducing the LCP-Array. Algorithms and Data Structures. Lecture Notes in Computer Science. Vol. 6844. pp. 374–385. arXiv:1101.3448. doi:10.1007/978-3-642-22300-6_32. ISBN 978-3-642-22299-3.
Manzini, Giovanni (2004). Two Space Saving Tricks for Linear Time LCP Array Computation. Algorithm Theory – SWAT 2004. Lecture Notes in Computer Science. Vol. 3111. p. 372. doi:10.1007/978-3-540-27810-8_32. ISBN 978-3-540-22339-9.
Kärkkäinen, Juha; Manzini, Giovanni; Puglisi, Simon J. (2009). Permuted Longest-Common-Prefix Array. Combinatorial Pattern Matching. Lecture Notes in Computer Science. Vol. 5577. p. 181. doi:10.1007/978-3-642-02441-2_17. ISBN 978-3-642-02440-5.
Puglisi, Simon J.; Turpin, Andrew (2008). Space-Time Tradeoffs for Longest-Common-Prefix Array Computation. Algorithms and Computation. Lecture Notes in Computer Science. Vol. 5369. p. 124. doi:10.1007/978-3-540-92182-0_14. ISBN 978-3-540-92181-3.
Gog, Simon; Ohlebusch, Enno (2011). Fast and Lightweight LCP-Array Construction Algorithms (PDF). Proceedings of the Workshop on Algorithm Engineering and Experiments, ALENEX 2011. pp. 25–34. Retrieved 2012-08-28.
Nong, Ge; Zhang, Sen; Chan, Wai Hong (2009). Linear Suffix Array Construction by Almost Pure Induced-Sorting. 2009 Data Compression Conference. p. 193. doi:10.1109/DCC.2009.42. ISBN 978-0-7695-3592-0.
Fischer, Johannes; Heun, Volker (2007). A New Succinct Representation of RMQ-Information and Improvements in the Enhanced Suffix Array. Combinatorics, Algorithms, Probabilistic and Experimental Methodologies. Lecture Notes in Computer Science. Vol. 4614. p. 459. doi:10.1007/978-3-540-74450-4_41. ISBN 978-3-540-74449-8.
Chen, G.; Puglisi, S. J.; Smyth, W. F. (2008). ""Lempel–Ziv Factorization Using Less Time & Space"". Mathematics in Computer Science. 1 (4): 605. doi:10.1007/s11786-007-0024-4. S2CID 1721891.
Crochemore, M.; Ilie, L. (2008). ""Computing Longest Previous Factor in linear time and applications"". Information Processing Letters. 106 (2): 75. CiteSeerX 10.1.1.70.5720. doi:10.1016/j.ipl.2007.10.006. S2CID 5492217.
Crochemore, M.; Ilie, L.; Smyth, W. F. (2008). A Simple Algorithm for Computing the Lempel Ziv Factorization. Data Compression Conference (dcc 2008). p. 482. doi:10.1109/DCC.2008.36. hdl:20.500.11937/5907. ISBN 978-0-7695-3121-2.
Sadakane, K. (2007). ""Compressed Suffix Trees with Full Functionality"". Theory of Computing Systems. 41 (4): 589–607. CiteSeerX 10.1.1.224.4152. doi:10.1007/s00224-006-1198-x. S2CID 263130.
Fischer, Johannes; Mäkinen, Veli; Navarro, Gonzalo (2009). ""Faster entropy-bounded compressed suffix trees"". Theoretical Computer Science. 410 (51): 5354. doi:10.1016/j.tcs.2009.09.012.
Fischer, Johannes; Kurpicz, Florian (5 October 2017). ""Dismantling DivSufSort"". Proceedings of the Prague Stringology Conference 2017. arXiv:1710.01896.

External links

Mirror of the ad-hoc-implementation of the code described in Fischer (2011)
SDSL: Succinct Data Structure Library - Provides various LCP array implementations, Range Minimum Query (RMQ) support structures and many more succinct data structures 
Bottom-up suffix tree traversal emulated using suffix array and LCP array (Java)
Text-Indexing project (linear-time construction of suffix trees, suffix arrays, LCP array and Burrows–Wheeler Transform)",36849795,https://en.wikipedia.org/wiki/LCP_array
Lookup table,"In computer science, a lookup table (LUT) is an array that replaces runtime computation with a simpler array indexing operation, in a process termed as direct addressing. The savings in processing time can be significant, because retrieving a value from memory is often faster than carrying out an ""expensive"" computation or input/output operation. The tables may be precalculated and stored in static program storage, calculated (or ""pre-fetched"") as part of a program's initialization phase (memoization), or even stored in hardware in application-specific platforms. Lookup tables are also used extensively to validate input values by matching against a list of valid (or invalid) items in an array and, in some programming languages, may include pointer functions (or offsets to labels) to process the matching input. FPGAs also make extensive use of reconfigurable, hardware-implemented, lookup tables to provide programmable hardware functionality.
LUTs differ from hash tables in a way that, to retrieve a value v{\displaystyle v} with key k{\displaystyle k}, a hash table would store the value v{\displaystyle v} in the slot h(k){\displaystyle h(k)} where h{\displaystyle h} is a hash function i.e. k{\displaystyle k} is used to compute the slot, while in the case of LUT, the value v{\displaystyle v} is stored in slot k{\displaystyle k}, thus directly addressable.: 466","In computer science, a lookup table (LUT) is an array that replaces runtime computation with a simpler array indexing operation, in a process termed as direct addressing. The savings in processing time can be significant, because retrieving a value from memory is often faster than carrying out an ""expensive"" computation or input/output operation. The tables may be precalculated and stored in static program storage, calculated (or ""pre-fetched"") as part of a program's initialization phase (memoization), or even stored in hardware in application-specific platforms. Lookup tables are also used extensively to validate input values by matching against a list of valid (or invalid) items in an array and, in some programming languages, may include pointer functions (or offsets to labels) to process the matching input. FPGAs also make extensive use of reconfigurable, hardware-implemented, lookup tables to provide programmable hardware functionality.
LUTs differ from hash tables in a way that, to retrieve a value v{\displaystyle v} with key k{\displaystyle k}, a hash table would store the value v{\displaystyle v} in the slot h(k){\displaystyle h(k)} where h{\displaystyle h} is a hash function i.e. k{\displaystyle k} is used to compute the slot, while in the case of LUT, the value v{\displaystyle v} is stored in slot k{\displaystyle k}, thus directly addressable.: 466

History
Before the advent of computers, lookup tables of values were used to speed up hand calculations of complex functions, such as in trigonometry, logarithms, and statistical density functions.In ancient (499 AD) India, Aryabhata created one of the first sine tables, which he encoded in a Sanskrit-letter-based number system. In 493 AD, Victorius of Aquitaine wrote a 98-column multiplication table which gave (in Roman numerals) the product of every number from 2 to 50 times and the rows were ""a list of numbers starting with one thousand, descending by hundreds to one hundred, then descending by tens to ten, then by ones to one, and then the fractions down to 1/144"" Modern school children are often taught to memorize ""times tables"" to avoid calculations of the most commonly used numbers (up to 9 x 9 or 12 x 12).
Early in the history of computers, input/output operations were particularly slow – even in comparison to processor speeds of the time. It made sense to reduce expensive read operations by a form of manual caching by creating either static lookup tables (embedded in the program) or dynamic prefetched arrays to contain only the most commonly occurring data items. Despite the introduction of systemwide caching that now automates this process, application level lookup tables can still improve performance for data items that rarely, if ever, change.
Lookup tables were one of the earliest functionalities implemented in computer spreadsheets, with the initial version of VisiCalc (1979) including a LOOKUP function among its original 20 functions. This has been followed by subsequent spreadsheets, such as Microsoft Excel, and complemented by specialized VLOOKUP and HLOOKUP functions to simplify lookup in a vertical or horizontal table. In Microsoft Excel the XLOOKUP function has been rolled out starting 28 August 2019.

Limitations
Although the performance of a LUT is a guaranteed O(1){\displaystyle O(1)} for a lookup operation, no two entities or values can have the same key k{\displaystyle k}. When the size of universe ∪{\displaystyle \cup }—where the keys are drawn—is large, it might be impractical or impossible to be stored in memory. Hence, in this case, a hash table would be a preferable alternative.: 468

Examples
Trivial hash function
For a trivial hash function lookup, the unsigned raw data value is used directly as an index to a one-dimensional table to extract a result. For small ranges, this can be amongst the fastest lookup, even exceeding binary search speed with zero branches and executing in constant time.

Counting bits in a series of bytes
One discrete problem that is expensive to solve on many computers is that of counting the number of bits that are set to 1 in a (binary) number, sometimes called the population function. For example, the decimal number ""37"" is ""00100101"" in binary, so it contains three bits that are set to binary ""1"".: 282 A simple example of C code, designed to count the 1 bits in a int, might look like this:: 283 

The above implementation requires 32 operations for an evaluation of a 32-bit value, which can potentially take several clock cycles due to branching. It can be ""unrolled"" into a lookup table which in turn uses trivial hash function for better performance.: 282-283 The bits array, bits_set with 256 entries is constructed by giving the number of one bits set in each possible byte value (e.g. 0x00 = 0, 0x01 = 1, 0x02 = 1, and so on). Although a runtime algorithm can be used to generate the bits_set array, it's an inefficient usage of clock cycles when the size is taken into consideration, hence a precomputed table is used—although a compile time script could be used to dynamically generate and append the table to the source file. Sum of ones in each byte of the integer can be calculated through trivial hash function lookup on each byte; thus, effectively avoiding branches resulting in considerable improvement in performance.: 284

Lookup tables in image processing
""Lookup tables (LUTs) are an excellent technique for optimizing the evaluation of functions that are expensive to compute and inexpensive to cache. ... For data requests that fall between the table's samples, an interpolation algorithm can generate reasonable approximations by averaging nearby samples.""
In data analysis applications, such as image processing, a lookup table (LUT) is used to transform the input data into a more desirable output format.  For example, a grayscale picture of the planet Saturn will be transformed into a color image to emphasize the differences in its rings.
In image processing, lookup tables are often called LUTs (or 3DLUT), and give an output value for each of a range of index values. One common LUT, called the colormap or palette, is used to determine the colors and intensity values with which a particular image will be displayed. In computed tomography,  ""windowing"" refers to a related concept for determining how to display the intensity of measured radiation.

Discussion
A classic example of reducing run-time computations using lookup tables is to obtain the result of a trigonometry calculation, such as the sine of a value. Calculating trigonometric functions can substantially slow a computing application. The same application can finish much sooner when it first precalculates the sine of a number of values, for example for each whole number of degrees (The table can be defined as static variables at compile time, reducing repeated run time costs).
When the program requires the sine of a value, it can use the lookup table to retrieve the closest sine value from a memory address, and may also interpolate to the sine of the desired value, instead of calculating by mathematical formula. Lookup tables are thus used by mathematics coprocessors in computer systems. An error in a lookup table was responsible for Intel's infamous floating-point divide bug.
Functions of a single variable (such as sine and cosine) may be implemented by a simple array.  Functions involving two or more variables require multidimensional array indexing techniques.  The latter case may thus employ a two-dimensional array of power[x][y] to replace a function to calculate xy for a limited range of x and y values. Functions that have more than one result may be implemented with lookup tables that are arrays of structures.
As mentioned, there are intermediate solutions that use tables in combination with a small amount of computation, often using interpolation. Pre-calculation combined with interpolation can produce higher accuracy for values that fall between two precomputed values. This technique requires slightly more time to be performed but can greatly enhance accuracy in applications that require it. Depending on the values being precomputed, precomputation with interpolation can also be used to shrink the lookup table size while maintaining accuracy.
While often effective, employing a lookup table may nevertheless result in a severe penalty if the computation that the LUT replaces is relatively simple. Memory retrieval time and the complexity of memory requirements can increase application operation time and system complexity relative to what would be required by straight formula computation. The possibility of polluting the cache may also become a problem. Table accesses for large tables will almost certainly cause a cache miss. This phenomenon is increasingly becoming an issue as processors outpace memory. A similar issue appears in rematerialization, a compiler optimization. In some environments, such as the Java programming language, table lookups can be even more expensive due to mandatory bounds-checking involving an additional comparison and branch for each lookup.
There are two fundamental limitations on when it is possible to construct a lookup table for a required operation. One is the amount of memory that is available: one cannot construct a lookup table larger than the space available for the table, although it is possible to construct disk-based lookup tables at the expense of lookup time. The other is the time required to compute the table values in the first instance; although this usually needs to be done only once, if it takes a prohibitively long time, it may make the use of a lookup table an inappropriate solution. As previously stated however, tables can be statically defined in many cases.

Computing sines
Most computers only perform basic arithmetic operations and cannot directly calculate the sine of a given value. Instead, they use the CORDIC algorithm or a complex formula such as the following Taylor series to compute the value of sine to a high degree of precision:: 5 
sin⁡(x)≈x−x36+x5120−x75040{\displaystyle \operatorname {sin} (x)\approx x-{\frac {x^{3}}{6}}+{\frac {x^{5}}{120}}-{\frac {x^{7}}{5040}}} (for x close to 0)However, this can be expensive to compute, especially on slow processors, and there are many applications, particularly in traditional computer graphics, that need to compute many thousands of sine values every second. A common solution is to initially compute the sine of many evenly distributed values, and then to find the sine of x we choose the sine of the value closest to x through array indexing operation. This will be close to the correct value because sine is a continuous function with a bounded rate of change.: 6  For example:: 545–548 

Unfortunately, the table requires quite a bit of space: if IEEE double-precision floating-point numbers are used, over 16,000 bytes would be required. We can use fewer samples, but then our precision will significantly worsen. One good solution is linear interpolation, which draws a line between the two points in the table on either side of the value and locates the answer on that line. This is still quick to compute, and much more accurate for smooth functions such as the sine function. Here is an example using linear interpolation:

Linear interpolation provides for an interpolated function that is continuous, but will not, in general, have continuous derivatives.  For smoother interpolation of table lookup that is continuous and has continuous first derivative, one should use the cubic Hermite spline.
When using interpolation, the size of the lookup table can be reduced by using nonuniform sampling, which means that where the function is close to straight, we use few sample points, while where it changes value quickly we use more sample points to keep the approximation close to the real curve. For more information, see interpolation.

Other usages of lookup tables
Caches
Storage caches (including disk caches for files, or processor caches for either code or data) work also like a lookup table. The table is built with very fast memory instead of being stored on slower external memory, and maintains two pieces of data for a sub-range of bits composing an external memory (or disk) address (notably the lowest bits of any possible external address):

one piece (the tag) contains the value of the remaining bits of the address; if these bits match with those from the memory address to read or write, then the other piece contains the cached value for this address.
the other piece maintains the data associated to that address.A single (fast) lookup is performed to read the tag in the lookup table at the index specified by the lowest bits of the desired external storage address, and to determine if the memory address is hit by the cache. When a hit is found, no access to external memory is needed (except for write operations, where the cached value may need to be updated asynchronously to the slower memory after some time, or if the position in the cache must be replaced to cache another address).

Hardware LUTs
In digital logic, a lookup table can be implemented with a multiplexer whose select lines are driven by the address signal and whose inputs are the values of the elements contained in the array. These values can either be hard-wired, as in an ASIC whose purpose is specific to a function, or provided by D latches which allow for configurable values. (ROM, EPROM, EEPROM, or RAM.)
An n-bit LUT can encode any n-input Boolean function by storing the truth table of the function in the LUT. This is an efficient way of encoding Boolean logic functions, and LUTs with 4-6 bits of input are in fact the key component of modern field-programmable gate arrays (FPGAs) which provide reconfigurable hardware logic capabilities.

Data acquisition and control systems
In data acquisition and control systems, lookup tables are commonly used to undertake the following operations in:

The application of calibration data, so as to apply corrections to uncalibrated measurement or setpoint values; and
Undertaking measurement unit conversion; and
Performing generic user-defined computations.In some systems, polynomials may also be defined in place of lookup tables for these calculations.

See also
Associative array
Branch table
Gal's accurate tables
Memoization
Memory-bound function
Shift register lookup table
Palette, a.k.a. color lookup table or CLUT – for the usage in computer graphics
3D lookup table – usage in film industry

References
External links
Fast table lookup using input character as index for branch table
Art of Assembly: Calculation via Table Lookups
""Bit Twiddling Hacks"" (includes lookup tables) By Sean Eron Anderson of Stanford University
Memoization in C++ by Paul McNamee, Johns Hopkins University showing savings
""The Quest for an Accelerated Population Count"" by Henry S. Warren Jr.",356457,https://en.wikipedia.org/wiki/Lookup_table
Matrix representation,"Matrix representation is a method used by a computer language to store column-vector matrices of more than one dimension in memory.
Fortran and C use different schemes for their native arrays. Fortran uses ""Column Major"" (AoS), in which all the elements for a given column are stored contiguously in memory. C uses ""Row Major"" (SoA), which stores all the elements for a given row contiguously in memory.
LAPACK defines various matrix representations in memory. There is also Sparse matrix representation  and Morton-order matrix representation.
According to the documentation, in LAPACK the unitary matrix representation is optimized.  Some languages such as Java store matrices using Iliffe vectors. These are particularly useful for storing irregular matrices. Matrices are of primary importance in linear algebra.","Matrix representation is a method used by a computer language to store column-vector matrices of more than one dimension in memory.
Fortran and C use different schemes for their native arrays. Fortran uses ""Column Major"" (AoS), in which all the elements for a given column are stored contiguously in memory. C uses ""Row Major"" (SoA), which stores all the elements for a given row contiguously in memory.
LAPACK defines various matrix representations in memory. There is also Sparse matrix representation  and Morton-order matrix representation.
According to the documentation, in LAPACK the unitary matrix representation is optimized.  Some languages such as Java store matrices using Iliffe vectors. These are particularly useful for storing irregular matrices. Matrices are of primary importance in linear algebra.

Basic mathematical operations
An m × n (read as m by n) order matrix is a set of numbers arranged in m rows and n columns. Matrices of the same order can be added by adding the corresponding elements. Two matrices can be multiplied, the condition being that the number of columns of the first matrix is equal to the number of rows of the second matrix. Hence, if an m × n matrix is multiplied with an n × r matrix, then the resultant matrix will be of the order m × r.Operations like row operations or column operations can be performed on a matrix, using which we can obtain the inverse of a matrix. The inverse may be obtained by determining the adjoint as well. rows and columns are the different classes of matrices

In 3D graphics
The choice of representation for 4×4 matrices commonly used in 3D graphics affects the implementation of matrix/vector operations in systems with packed SIMD instructions:

Row major (SoA)
With row-major matrix order, it is easy to transform vectors using dot product operations, since the coefficients of each component are sequential in memory. Consequently, this layout may be desirable if a processor supports dot product operations natively. It is also possible to efficiently use a '3×4' affine transformation matrix without padding or awkward permutes.

Column major (AoS)
With column-major order, a ""matrix × vector"" multiply can be implemented with vectorized multiply-add operations, if the vector's components are broadcast to each SIMD lane. It is also easy to access the basis vectors represented by a transformation matrix as individual column vectors, as these are contiguous in memory.

See also
Row- and column-major order
Sparse matrix
Skyline matrix
Locality of reference

References
External links
a description of sparse matrices in R.",1523927,https://en.wikipedia.org/wiki/Matrix_representation
Packed storage matrix,"A packed storage matrix, also known as packed matrix, is a term used in programming for representing an m×n{\displaystyle m\times n} matrix. It is a more compact way than an m-by-n rectangular array by exploiting a special structure of the matrix.
Typical examples of matrices that can take advantage of packed storage include:

symmetric or hermitian matrix
Triangular matrix
Banded matrix.","A packed storage matrix, also known as packed matrix, is a term used in programming for representing an m×n{\displaystyle m\times n} matrix. It is a more compact way than an m-by-n rectangular array by exploiting a special structure of the matrix.
Typical examples of matrices that can take advantage of packed storage include:

symmetric or hermitian matrix
Triangular matrix
Banded matrix.

Code examples (Fortran)
Both of the following storage schemes are used extensively in BLAS and LAPACK.
An example of packed storage for Hermitian matrix:

An example of packed storage for banded matrix:",1451556,https://en.wikipedia.org/wiki/Packed_storage_matrix
Parallel array,"In computing, a group of parallel arrays (also known as structure of arrays or SoA) is a form of implicit data structure that uses multiple arrays to represent a singular array of records. It keeps a separate, homogeneous data array for each field of the record, each having the same number of elements. Then, objects located at the same index in each array are implicitly the fields of a single record. Pointers from one object to another are replaced by array indices. This contrasts with the normal approach of storing all fields of each record together in memory (also known as array of structures or AoS). For example, one might declare an array of 100 names, each a string, and 100 ages, each an integer, associating each name with the age that has the same index.","In computing, a group of parallel arrays (also known as structure of arrays or SoA) is a form of implicit data structure that uses multiple arrays to represent a singular array of records. It keeps a separate, homogeneous data array for each field of the record, each having the same number of elements. Then, objects located at the same index in each array are implicitly the fields of a single record. Pointers from one object to another are replaced by array indices. This contrasts with the normal approach of storing all fields of each record together in memory (also known as array of structures or AoS). For example, one might declare an array of 100 names, each a string, and 100 ages, each an integer, associating each name with the age that has the same index.

Examples
An example in C using parallel arrays:

in Perl (using a hash of arrays to hold references to each array):

Or, in Python:

Pros and cons
Parallel arrays have a number of practical advantages over the normal approach:

They can save a substantial amount of space in some cases by avoiding alignment issues. For example, some architectures work best if 4-byte integers are always stored beginning at memory locations that are multiple of 4. If the previous field was a single byte, 3 bytes might be wasted. Many modern compilers can automatically avoid such problems, though in the past some programmers would explicitly declare fields in order of decreasing alignment restrictions.
If the number of items is small, array indices can occupy significantly less space than full pointers, particularly on some architectures.
Sequentially examining a single field of each record in the array is very fast on modern machines, since this amounts to a linear traversal of a single array, exhibiting ideal locality of reference and cache behaviour.
They may allow efficient processing with SIMD instructions in certain instruction set architecturesSeveral of these advantage depend strongly on the particular programming language and implementation in use.
However, parallel arrays also have several strong disadvantages, which serves to explain why they are not generally preferred:

They have significantly worse locality of reference when visiting the records non-sequentially and examining multiple fields of each record, because the various arrays may be stored arbitrarily far apart.
They obscure the relationship between fields of a single record (e.g. no type information relates the index between them, an index may be used erroneously).
They have little direct language support (the language and its syntax typically express no relationship between the arrays in the parallel array, and cannot catch errors).
Since the bundle of fields is not a ""thing"", passing it around is tedious and error-prone. For example, rather than calling a function to do something to one record (or structure or object), the function must take the fields as separate arguments. When a new field is added or changed, many parameter lists must change, where passing objects as whole would avoid such changes entirely.
They are expensive to grow or shrink, since each of several arrays must be reallocated.  Multi-level arrays can ameliorate this problem, but impacts performance due to the additional indirection needed to find the desired elements.
Perhaps worst of all, they greatly raise the possibility of errors. Any insertion, deletion, or move must always be applied consistently to all of the arrays, or the arrays will no longer be synchronized with each other, leading to bizarre outcomes.The bad locality of reference can be alleviated in some cases: if a structure can be divided into groups of fields that are generally accessed together, an array can be constructed for each group, and its elements are records containing only these subsets of the larger structure's fields. (see data oriented design). This is a valuable way of speeding up access to very large structures with many members, while keeping the portions of the structure tied together. An alternative to tying them together using array indexes is to use references to tie the portions together, but this can be less efficient in time and space.
Another alternative is to use a single array, where each entry is a record structure. Many language provide a way to declare actual records, and arrays of them. In other languages it may be feasible to simulate this by declaring an array of n*m size, where m is the size of all the fields together, packing the fields into what is effectively a record, even though the particular language lacks direct support for records. Some compiler optimizations, particularly for vector processors, are able to perform this transformation automatically when arrays of structures are created in the program.

See also
An example in the linked list article
Column-oriented DBMS

References
Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. Introduction to Algorithms, Second Edition. MIT Press and McGraw-Hill, 2001. ISBN 0-262-03293-7. Page 209 of section 10.3: Implementing pointers and objects.
Skeet, Jon (3 June 2014). ""Anti-pattern: parallel collections"". Retrieved 28 October 2014.",991858,https://en.wikipedia.org/wiki/Parallel_array
Persistent array,"In computer science, and more precisely regarding data structures, a persistent array is a persistent data structure with properties similar to a (non-persistent) array. That is, after a value's update in a persistent array, there exist two persistent arrays: one persistent array in which the update is taken into account, and one which is equal to the array before the update.","In computer science, and more precisely regarding data structures, a persistent array is a persistent data structure with properties similar to a (non-persistent) array. That is, after a value's update in a persistent array, there exist two persistent arrays: one persistent array in which the update is taken into account, and one which is equal to the array before the update.

Difference between persistent arrays and arrays
An array
ar=[e0,…,en−1]{\displaystyle \mathrm {ar} =[e_{0},\dots ,e_{n-1}]} is a data structure,
with a fixed number n of elements e0,…,en−1{\displaystyle e_{0},\dots ,e_{n-1}}. It is expected that, given the array ar and an
index 0≤i<n{\displaystyle 0\leq i<n}, the value ei{\displaystyle e_{i}} can be
retrieved quickly. This operation is called a
lookup. Furthermore, given the array ar, an index
0≤i<n{\displaystyle 0\leq i<n} and a new value v, a new array ar2 with
content [e0,…,ei−1,v,ei+1,…,en−1]{\displaystyle [e_{0},\dots ,e_{i-1},v,e_{i+1},\dots ,e_{n-1}]} can
be created quickly. This operation is called an update.  The
main difference between persistent and non-persistent arrays being
that, in non-persistent arrays, the array ar is destroyed during
the creation of ar2.
For example, consider the following pseudocode.

array = [0, 0, 0]
updated_array = array.update(0, 8)
other_array = array.update(1, 3)
last_array = updated_array.update(2, 5)

At the end of execution, the value of array is still [0, 0, 0], the
value of updated_array is [8, 0, 0], the value of other_array
is [0, 3, 0], and the value of last_array is [8, 0, 5].
There exist two kinds of persistent arrays. A persistent array may be
either partially or fully persistent. A fully persistent
array may be updated an arbitrary number of times while a partially
persistent array may be updated at most once. In our previous example,
if array were only partially persistent, the creation of
other_array would be forbidden; however, the creation of
last_array would still be valid. Indeed, updated_array is an array
distinct from array and has never been updated before the creation
of last_array.

Lower Bound on Persistent Array Lookup Time
Given that non-persistent arrays support both updates and lookups in constant time, it is natural to ask whether the same is possible with persistent arrays. The following theorem shows that under mild assumptions about the space complexity of the array, lookups must take Ω(log⁡log⁡n){\displaystyle \Omega (\log \log n)} time in the worst case, regardless of update time, in the cell-probe model.

Implementations
In this section, n{\displaystyle n} is the number of elements of the array, and m{\displaystyle m} is the number of updates.

Worst case log-time
The most straightforward implementation of a fully persistent array uses an arbitrary persistent map, whose keys are the numbers from 0 to n − 1. A persistent map may be implemented using a persistent balanced tree, in which case both updates and lookups would take O(log⁡n){\displaystyle O(\log n)} time. This implementation is optimal for the pointer machine model.: 88–89

Shallow binding
A fully persistent array may be implemented using an array and the
so-called Baker's trick.   This implementation is used in the OCaml module parray.ml by Jean-Christophe Filliâtre.
In order to define this implementation, a few other definitions must
be given. An initial array is an array that is not generated by
an update on another array. A child of an array ar is an
array of the form ar.update(i,v), and ar is the parent
of ar.update(i,v). A descendant of an array ar is either
ar or the descendant of a child of ar. The initial array
of an array ar is either ar if ar is initial, or it is the
initial array of the parent of ar. That is, the initial array of
ar is the unique array init such that ar=init.update(i0,v0).….update(im,vm){\displaystyle \mathrm {ar} =init.update(i_{0},v_{0}).\dots .update(i_{m},v_{m})}, with ar initial
and i0,…,im{\displaystyle i_{0},\dots ,i_{m}} an arbitrary sequence of indexes and
v0,…,vm{\displaystyle v_{0},\dots ,v_{m}} an arbitrary sequence of value. A
family of arrays is thus a set of arrays containing an initial
array and all of its descendants. Finally, the tree of a family of
arrays is the tree whose nodes are the
arrays, and with an edge e from ar to each of its children
ar.update(i,v).
A persistent array using Baker's trick consists of a pair with
an actual array called array and the tree of arrays.  This tree
admits an arbitrary root - not necessarily the initial array.  The
root may be moved to an arbitrary node of the tree. Changing the root
from root to an arbitrary node ar takes time proportional to
the depth of ar. That is, in the distance between root and
ar. Similarly, looking up a value takes time proportional to the
distance between the array and the root of its family. Thus, if the
same array ar may be lookup multiple times, it is more efficient
to move the root to ar before doing the lookup. Finally updating
an array only takes constant time.
Technically, given two adjacent arrays ar1 and ar2, with
ar1 closer to the root than ar2, the edge from ar1 to
ar2 is labelled by (i,ar2[i]), where i the only position
whose value differ between ar1 and ar2.
Accessing an element i of an array ar is done as follows. If
ar is the root, then ar[i] equals root[i]. Otherwise, let
e the edge leaving ar toward the root. If the label of e
is (i,v) then ar[i] equals v. Otherwise, let ar2 be
the other node of the edge e. Then ar[i] equals
ar2[i]. The computation of ar2[i] is done recursively using
the same definition.
The creation of ar.update(i,v) consists in adding a new node
ar2 to the tree, and an edge e from ar to ar2 labelled
by (i,v).
Finally, moving the root to a node ar is done as follows. If
ar is already the root, there is nothing to do. Otherwise, let
e the edge leaving ar toward the current root, (i,v) its
label and ar2 the other end of e. Moving the root to ar is
done by first moving the root to ar2, changing the label of e
to (i, ar2[i]), and changing array[i] to v. 
Updates take O(1){\displaystyle O(1)} time. Lookups take O(1){\displaystyle O(1)} time if the root is the array being looked up, but Θ(m){\displaystyle \Theta (m)} time in the worst case.

Expected amortized log-log-time
In 1989, Dietz
gave an implementation of fully persistent arrays using O(m+n){\displaystyle O(m+n)} space such that lookups can be done in O(log⁡log⁡m){\displaystyle O(\log \log m)} worst-case time, and updates can be done in
O(log⁡log⁡m){\displaystyle O(\log \log m)} expected amortized time. By the lower bound from the previous section, this time complexity for lookup is optimal when m=nγ{\displaystyle m=n^{\gamma }} for γ∈(1,2]{\displaystyle \gamma \in (1,2]}. This implementation is related to the order-maintenance problem and involves vEB trees, one for the entire array and one for each index.
Straka showed that the times for both operations can be (slightly) improved to O(log⁡log⁡min(m,n)){\displaystyle O(\log \log \min(m,n))}.: 88–89

Worst case log-log-time
Straka showed how to achieve O((log⁡log⁡m)2/log⁡log⁡log⁡m){\displaystyle O((\log \log m)^{2}/\log \log \log m)} worst-case time and linear (O(m+n){\displaystyle O(m+n)}) space, or O(log⁡log⁡m){\displaystyle O(\log \log m)} worst-case time and super-linear space. It remains open whether it is possible to achieve worst-case time O(log⁡log⁡m){\displaystyle O(\log \log m)} subject to linear space.: 88

References
.",59230603,https://en.wikipedia.org/wiki/Persistent_array
Comparison of programming languages (array),This comparison of programming languages (array) compares the features of array data structures or matrix processing for various computer programming languages.,"This comparison of programming languages (array) compares the features of array data structures or matrix processing for various computer programming languages.

Syntax
Array dimensions
The following list contains syntax examples of how to determine the dimensions (index of the first element, the last element or the size in elements).
Note particularly that some languages index from zero while others index from one while others carry no such restriction or even allow indexing by any enumerated type, not just integers.

Indexing
The following list contains syntax examples of how to access a single element of an array.

Slicing
The following list contains syntax examples of how a range of element of an array can be accessed.
In the following table:

first – the index of the first element in the slice
last  – the index of the last element in the slice
end   – one more than the index of last element in the slice
len   – the length of the slice (= end - first)
step  – the number of array elements in each (default 1)

Array system cross-reference list
Vectorized array operations
Some compiled languages such as Ada and Fortran, and some scripting languages such as IDL, MATLAB, and S-Lang, have native support for vectorized operations on arrays.  For example, to perform an element by element sum of two arrays, a and b to produce a third c, it is only necessary to write

c = a + b

In addition to support for vectorized arithmetic and relational operations, these languages also vectorize common mathematical functions such as sine. For example, if x is an array, then

y = sin (x)

will result in an array y whose elements are sine of the corresponding elements of the array x.
Vectorized index operations are also supported.  As an example,

is how one would use Fortran to create arrays from the even and odd entries of an array.  Another common use of vectorized indices is a filtering operation.  Consider a clipping operation of a sine wave where amplitudes larger than 0.5 are to be set to 0.5.  Using S-Lang, this can be done by

y = sin(x);
y[where(abs(y)>0.5)] = 0.5;

Mathematical matrix operations


== References ==",13941999,https://en.wikipedia.org/wiki/Comparison_of_programming_languages_(array)
Range (computer programming),"In computer science, the term range may refer to one of three things:

The possible values that may be stored in a variable.
The upper and lower bounds of an array.
An alternative to iterator.","In computer science, the term range may refer to one of three things:

The possible values that may be stored in a variable.
The upper and lower bounds of an array.
An alternative to iterator.

Range of a variable
The range of a variable is given as the set of possible values that that variable can hold. In the case of an integer, the variable definition is restricted to whole numbers only, and the range will cover every number within its range (including the maximum and minimum). For example, the range of a signed 16-bit integer variable is all the integers from −32,768 to +32,767.

Range of an array
When an array is numerically indexed, its range is the upper and lower bound of the array. Depending on the environment, a warning, a fatal exception, or unpredictable behavior will occur if the program attempts to access an array element that is outside the range. In some programming languages, such as C, arrays have a fixed lower bound (zero) and will contain data at each position up to the upper bound (so an array with 5 elements will have a range of 0 to 4). In others, such as PHP, an array may have holes where no element is defined, and therefore an array with a range of 0 to 4 will have up to 5 elements (and a minimum of 2).

Range as an alternative to iterator
Another meaning of range in computer science is an alternative to iterator. When used in this sense, range is defined as ""a pair of begin/end iterators packed together"". It is argued  that ""Ranges are a superior abstraction"" (compared to iterators) for several reasons, including better safety.
In particular, such ranges are supported in C++20, Boost C++ Libraries and the D standard library.

See also
Interval


== References ==",8508082,https://en.wikipedia.org/wiki/Range_(computer_programming)
Range mode query,"In data structures, the range mode query problem asks to build a data structure on some input data to efficiently answer queries asking for the mode of any consecutive subset of the input.","In data structures, the range mode query problem asks to build a data structure on some input data to efficiently answer queries asking for the mode of any consecutive subset of the input.

Problem statement
Given an array A[1:n]=[a1,a2,...,an]{\displaystyle A[1:n]=[a_{1},a_{2},...,a_{n}]}, we wish to answer queries of the form mode(A,i:j){\displaystyle mode(A,i:j)}, where 1≤i≤j≤n{\displaystyle 1\leq i\leq j\leq n}. The mode mode(S){\displaystyle mode(S)} of any array S=[s1,s2,...,sk]{\displaystyle S=[s_{1},s_{2},...,s_{k}]} is an element si{\displaystyle s_{i}} such that the frequency of si{\displaystyle s_{i}} is greater than or equal to the frequency of sj∀j∈{1,...,k}{\displaystyle s_{j}\;\forall j\in \{1,...,k\}}. For example, if S=[1,2,4,2,3,4,2]{\displaystyle S=[1,2,4,2,3,4,2]}, then mode(S)=2{\displaystyle mode(S)=2} because it occurs three times, while all other values occur fewer times. In this problem, the queries ask for the mode of subarrays of the form A[i:j]=[ai,ai+1,...,aj]{\displaystyle A[i:j]=[a_{i},a_{i+1},...,a_{j}]}.

Theorem 1
Let A{\displaystyle A} and B{\displaystyle B} be any multisets. If c{\displaystyle c} is a mode of A∪B{\displaystyle A\cup B} and c∉A{\displaystyle c\notin A}, then c{\displaystyle c} is a mode of B{\displaystyle B}.

Proof
Let c∉A{\displaystyle c\notin A} be a mode of C=A∪B{\displaystyle C=A\cup B} and fc{\displaystyle f_{c}} be its frequency in C{\displaystyle C}. Suppose that c{\displaystyle c} is not a mode of B{\displaystyle B}. Thus, there exists an element b{\displaystyle b} with frequency fb{\displaystyle f_{b}} that is the mode of B{\displaystyle B}. Since b{\displaystyle b} is the mode of B{\displaystyle B} and that c∉A{\displaystyle c\notin A}, then fb>fc{\displaystyle f_{b}>f_{c}}. Thus, b{\displaystyle b} should be the mode of C{\displaystyle C} which is a contradiction.

Results
Lower bound
Any data structure using S{\displaystyle S} cells of w{\displaystyle w} bits each needs Ω(log⁡nlog⁡(Sw/n)){\displaystyle \Omega \left({\frac {\log n}{\log(Sw/n)}}\right)} time to answer a range mode query.This contrasts with other range query problems, such as the range minimum query which have solutions offering constant time query time and linear space. This is due to the hardness of the mode problem, since even if we know the mode of A[i:j]{\displaystyle A[i:j]} and the mode of A[j+1:k]{\displaystyle A[j+1:k]}, there is no simple way of computing the mode of A[i:k]{\displaystyle A[i:k]}. Any element of A[i:j]{\displaystyle A[i:j]} or A[j+1:k]{\displaystyle A[j+1:k]} could be the mode. For example, if mode(A[i:j])=a{\displaystyle mode(A[i:j])=a} and its frequency is fa{\displaystyle f_{a}}, and mode(A[j+1:k])=b{\displaystyle mode(A[j+1:k])=b} and its frequency is also fa{\displaystyle f_{a}}, there could be an element c{\displaystyle c} with frequency fa−1{\displaystyle f_{a}-1} in A[i:j]{\displaystyle A[i:j]} and frequency fa−1{\displaystyle f_{a}-1} in A[j+1:k]{\displaystyle A[j+1:k]}. a≠c≠b{\displaystyle a\not =c\not =b}, but its frequency in A[i:k]{\displaystyle A[i:k]} is greater than the frequency of a{\displaystyle a} and b{\displaystyle b}, which makes c{\displaystyle c} a better candidate for mode(A[i:k]){\displaystyle mode(A[i:k])} than a{\displaystyle a} or b{\displaystyle b}.

Linear space data structure with square root query time
This method by Chan et al. uses O(n+s2){\displaystyle O(n+s^{2})} space and O(n/s){\displaystyle O(n/s)} query time. By setting s=n{\displaystyle s={\sqrt {n}}}, we get O(n){\displaystyle O(n)} and O(n){\displaystyle O({\sqrt {n}})} bounds for space and query time.

Preprocessing
Let A[1:n]{\displaystyle A[1:n]} be an array, and D[1:Δ]{\displaystyle D[1:\Delta ]} be an array that contains the distinct values of A, where Δ{\displaystyle \Delta } is the number of distinct elements. We define B[1:n]{\displaystyle B[1:n]} to be an array such that, for each i{\displaystyle i}, B[i]{\displaystyle B[i]} contains the rank (position) of A[i]{\displaystyle A[i]} in D{\displaystyle D}. Arrays B,D{\displaystyle B,D} can be created by a linear scan of A{\displaystyle A}.
Arrays Q1,Q2,...,QΔ{\displaystyle Q_{1},Q_{2},...,Q_{\Delta }} are also created, such that, for each a∈{1,...,Δ}{\displaystyle a\in \{1,...,\Delta \}}, Qa={b|B[b]=a}{\displaystyle Q_{a}=\{b\;|\;B[b]=a\}}. We then create an array B′[1:n]{\displaystyle B'[1:n]}, such that, for all b∈{1,...,n}{\displaystyle b\in \{1,...,n\}}, B′[b]{\displaystyle B'[b]} contains the rank of b{\displaystyle b} in QB[b]{\displaystyle Q_{B[b]}}. Again, a linear scan of B{\displaystyle B} suffices to create arrays Q1,Q2,...,QΔ{\displaystyle Q_{1},Q_{2},...,Q_{\Delta }} and B′{\displaystyle B'}.
It is now possible to answer queries of the form ""is the frequency of B[i]{\displaystyle B[i]} in B[i:j]{\displaystyle B[i:j]} at least q{\displaystyle q}"" in constant time, by checking whether QB[i][B′[i]+q−1]≤j{\displaystyle Q_{B[i]}[B'[i]+q-1]\leq j}.
The array is split B into s{\displaystyle s} blocks b1,b2,...,bs{\displaystyle b_{1},b_{2},...,b_{s}}, each of size t=⌈n/s⌉{\displaystyle t=\lceil n/s\rceil }. Thus, a block bi{\displaystyle b_{i}} spans over B[i⋅t+1:(i+1)t]{\displaystyle B[i\cdot t+1:(i+1)t]}. The mode and the frequency of each block or set of consecutive blocks will be pre-computed in two tables S{\displaystyle S} and S′{\displaystyle S'}. S[bi,bj]{\displaystyle S[b_{i},b_{j}]} is the mode of bi∪bi+1∪...∪bj{\displaystyle b_{i}\cup b_{i+1}\cup ...\cup b_{j}}, or equivalently, the mode of B[bit+1:(bj+1)t]{\displaystyle B[b_{i}t+1:(b_{j}+1)t]}, and S′{\displaystyle S'} stores the corresponding frequency. These two tables can be stored in O(s2){\displaystyle O(s^{2})} space, and can be populated in O(s⋅n){\displaystyle O(s\cdot n)} by scanning B{\displaystyle B} s{\displaystyle s} times, computing a row of S,S′{\displaystyle S,S'} each time with the following algorithm:

algorithm computeS_Sprime is
    input: Array B = [0:n - 1], 
        Array D = [0:Delta - 1], 
        Integer s
    output: Tables S and Sprime
    let S ← Table(0:n - 1, 0:n - 1)
    let Sprime ← Table(0:n - 1, 0:n - 1)
    let firstOccurence ← Array(0:Delta - 1)
    for all i in {0, ..., Delta - 1} do
        firstOccurence[i] ← -1 
    end for
    for i ← 0:s - 1 do    
        let j ← i × t
        let c ← 0
        let fc ← 0
        let noBlock ← i
        let block_start ← j
        let block_end ← min{(i + 1) × t - 1, n - 1}
        while j < n do    
            if firstOccurence[B[j]] = -1 then
                firstOccurence[B[j]] ← j
            end if		
            if atLeastQInstances(firstOccurence[B[j]], block_end, fc + 1) then
                c ← B[j]
                fc ← fc + 1
            end if		
            if j = block_end then
                S[i * s + noBlock] ← c
                Sprime[i × s + noBlock] ← fc			
                noBlock ← noBlock + 1
                block_end ← min{block_end + t, n - 1}
            end if
        end while
        for all j in {0, ..., Delta - 1} do
            firstOccurence[j] ← -1 
        end for
    end for

Query
We will define the query algorithm over array B{\displaystyle B}. This can be translated to an answer over A{\displaystyle A}, since for any a,i,j{\displaystyle a,i,j}, B[a]{\displaystyle B[a]} is a mode for B[i:j]{\displaystyle B[i:j]} if and only if A[a]{\displaystyle A[a]} is a mode for A[i:j]{\displaystyle A[i:j]}. We can convert an answer for B{\displaystyle B} to an answer for A{\displaystyle A} in constant time by looking in A{\displaystyle A} or B{\displaystyle B} at the corresponding index.
Given a query mode(B,i,j){\displaystyle mode(B,i,j)}, the query is split in three parts: the prefix, the span and the suffix. Let bi=⌈(i−1)/t⌉{\displaystyle b_{i}=\lceil (i-1)/t\rceil } and bj=⌊j/t⌋−1{\displaystyle b_{j}=\lfloor j/t\rfloor -1}. These denote the indices of the first and last block that are completely contained in B{\displaystyle B}. The range of these blocks is called the span. The prefix is then B[i:min{bit,j}]{\displaystyle B[i:min\{b_{i}t,j\}]} (the set of indices before the span), and the suffix is B[max{(bj+1)t+1,i}:j]{\displaystyle B[max\{(b_{j}+1)t+1,i\}:j]} (the set of indices after the span).  The prefix, suffix or span can be empty, the latter is if bj<bi{\displaystyle b_{j}<b_{i}}.
For the span, the mode c{\displaystyle c} is already stored in S[bi,bj]{\displaystyle S[b_{i},b_{j}]}. Let fc{\displaystyle f_{c}} be the frequency of the mode, which is stored in S′[bi,bj]{\displaystyle S'[b_{i},b_{j}]}. If the span is empty, let fc=0{\displaystyle f_{c}=0}. Recall that, by Theorem 1, the mode of B[i:j]{\displaystyle B[i:j]} is either an element of the prefix, span or suffix. A linear scan is performed over each element in the prefix and in the suffix to check if its frequency is greater than the current candidate c{\displaystyle c}, in which case c{\displaystyle c} and fc{\displaystyle f_{c}} are updated to the new value. At the end of the scan, c{\displaystyle c} contains the mode of B[i:j]{\displaystyle B[i:j]} and fc{\displaystyle f_{c}} its frequency.

Scanning procedure
The procedure is similar for both prefix and suffix, so it suffice to run this procedure for both:
Let x{\displaystyle x} be the index of the current element. There are three cases:

If QB[x][B′[x]−1]≥i{\displaystyle Q_{B[x]}[B'[x]-1]\geq i}, then it was present in B[i:x−1]{\displaystyle B[i:x-1]} and its frequency has already been counted. Pass to the next element.
Otherwise, check if the frequency of B[x]{\displaystyle B[x]} in B[i:j]{\displaystyle B[i:j]} is at least fc{\displaystyle f_{c}} (this can be done in constant time since it is the equivalent of checking it for B[x:j]{\displaystyle B[x:j]}).
If it is not, then pass to the next element.
If it is, then compute the actual frequency fx{\displaystyle f_{x}} of B[x]{\displaystyle B[x]} in B[i:j]{\displaystyle B[i:j]} by a linear scan (starting at index B′[x]+fc−1{\displaystyle B'[x]+f_{c}-1}) or a binary search in QB[x]{\displaystyle Q_{B[x]}}. Set c:=B[x]{\displaystyle c:=B[x]} and fc:=fx{\displaystyle f_{c}:=f_{x}}.This linear scan (excluding the frequency computations) is bounded by the block size t{\displaystyle t}, since neither the prefix or the suffix can be greater than t{\displaystyle t}. A further analysis of the linear scans done for frequency computations shows that it is also bounded by the block size. Thus, the query time is O(t)=O(n/s){\displaystyle O(t)=O(n/s)}.

Subquadratic space data structure with constant query time
This method by  uses O(n2log⁡log⁡nlog⁡n){\displaystyle O\left({\frac {n^{2}\log {\log {n}}}{\log {n}}}\right)} space for a constant time query. We can observe that, if a constant query time is desired, this is a better solution than the one proposed by Chan et al., as the latter gives a space of O(n2){\displaystyle O(n^{2})} for constant query time if s=n{\displaystyle s=n}.

Preprocessing
Let A[1:n]{\displaystyle A[1:n]} be an array. The preprocessing is done in three steps:

Split the array A{\displaystyle A} in s{\displaystyle s} blocks b1,b2,...,bs{\displaystyle b_{1},b_{2},...,b_{s}}, where the size of each block is t=⌈n/s⌉{\displaystyle t=\lceil n/s\rceil }. Build a table S{\displaystyle S} of size s×s{\displaystyle s\times s} where S[i,j]{\displaystyle S[i,j]} is the mode of bi∪bi+1∪...∪bj{\displaystyle b_{i}\cup b_{i+1}\cup ...\cup b_{j}}. The total space for this step is O(s2){\displaystyle O(s^{2})}
For any query mode(A,i,j){\displaystyle mode(A,i,j)}, let bi′{\displaystyle b_{i'}} be the block that contains i{\displaystyle i} and bj′{\displaystyle b_{j'}} be the block that contains j{\displaystyle j}. Let the span be the set of blocks completely contained in A[i:j]{\displaystyle A[i:j]}. The mode c{\displaystyle c} of the block can be retrieved from S{\displaystyle S}. By Theorem 1, the mode can be either an element of the prefix (indices of A[i:j]{\displaystyle A[i:j]} before the start of the span), an element of the suffix (indices of A[i:j]{\displaystyle A[i:j]} after the end of the span), or c{\displaystyle c}. The size of the prefix plus the size of the suffix is bounded by 2t{\displaystyle 2t}, thus the position of the mode isstored as an integer ranging from 0{\displaystyle 0} to 2t{\displaystyle 2t}, where [0:2t−1]{\displaystyle [0:2t-1]}indicates a position in the prefix/suffix and 2t{\displaystyle 2t} indicates that the mode is the mode of the span. There are (t2){\displaystyle {\binom {t}{2}}} possible queries involving blocks bi′{\displaystyle b_{i'}} and bj′{\displaystyle b_{j'}}, so these values are stored in a table of size t2{\displaystyle t^{2}}. Furthermore, there are (2t+1)t2{\displaystyle (2t+1)^{t^{2}}} such tables, so the total space required for this step is O(t2(2t+1)t2){\displaystyle O(t^{2}(2t+1)^{t^{2}})}. To access those tables, a pointer is added in addition to the mode in the table S{\displaystyle S} for each pair of blocks.
To handle queries mode(A,i,j){\displaystyle mode(A,i,j)} where i{\displaystyle i} and j{\displaystyle j} are in the same block, all such solutions are precomputed. There are O(st2){\displaystyle O(st^{2})} of them, they are stored in a three dimensional table T{\displaystyle T} of this size.The total space used by this data structure is O(s2+t2(2t+1)t2+st2){\displaystyle O(s^{2}+t^{2}(2t+1)^{t^{2}}+st^{2})}, which reduces to O(n2log⁡log⁡nlog⁡n){\displaystyle O\left({\frac {n^{2}\log {\log {n}}}{\log {n}}}\right)} if we take t=log⁡n/log⁡log⁡n{\displaystyle t={\sqrt {\log {n}/\log {\log {n}}}}}.

Query
Given a query mode(A,i,j){\displaystyle mode(A,i,j)}, check if it is completely contained inside a block, in which case the answer is stored in table T{\displaystyle T}. If the query spans exactly one or more blocks, then the answer is found in table S{\displaystyle S}. Otherwise, use the pointer stored in table S{\displaystyle S} at position S[bi′,bj′]{\displaystyle S[b_{i'},b_{j'}]}, where bi′,bj′{\displaystyle b_{i'},b_{j'}} are the indices of the blocks that contain respectively i{\displaystyle i} and j{\displaystyle j}, to find the table Ubi′,bj′{\displaystyle U_{b_{i'},b_{j'}}} that contains the positions of the mode for these blocks and use the position to find the mode in A{\displaystyle A}. This can be done in constant time.


== References ==",42412822,https://en.wikipedia.org/wiki/Range_mode_query
Range query (computer science),"In computer science, the range query problem consists of efficiently answering several queries regarding a given interval of elements within an array. For example, a common task, known as range minimum query, is finding the smallest value inside a given range within a list of numbers.","In computer science, the range query problem consists of efficiently answering several queries regarding a given interval of elements within an array. For example, a common task, known as range minimum query, is finding the smallest value inside a given range within a list of numbers.

Definition
Given a function f{\displaystyle f} that accepts an array, a range query fq(l,r){\displaystyle f_{q}(l,r)} on an array a=[a1,..,an]{\displaystyle a=[a_{1},..,a_{n}]} takes two indices l{\displaystyle l} and r{\displaystyle r} and returns the result of f{\displaystyle f} when applied to the subarray [al,…,ar]{\displaystyle [a_{l},\ldots ,a_{r}]}. For example, for a function sum{\displaystyle \operatorname {sum} } that returns the sum of all values in an array, the range query sumq⁡(l,r){\displaystyle \operatorname {sum} _{q}(l,r)} returns the sum of all values in the range [l,r]{\displaystyle [l,r]}.

Solutions
Prefix sum array
Range sum queries may be answered in constant time and linear space by pre-computing an array p of same length as the input such that for every index i, the element pi is the sum of the first i elements of a. Any query may then be computed as follows: 
This strategy may be extended to any other binary operation f{\displaystyle f} whose inverse function f−1{\displaystyle f^{-1}} is well-defined and easily computable. It can also be extended to higher dimensions with a similar pre-processing.  For example, if pi,j contains the sum of the first i × j elements of a, then

Dynamic range queries
A more difficult subset of the problem consists of executing range queries on dynamic data; that is, data that may mutate between each query. In order to efficiently update array values, more sophisticated data structures like the segment tree or Fenwick tree are necessary.

Examples
Semigroup operators
When the function of interest in a range query is a semigroup operator, the notion of f−1{\displaystyle f^{-1}} is not always defined, so the strategy in the previous section does not work. Andrew Yao showed that there exists an efficient solution for range queries that involve semigroup operators. He proved that for any constant c, a pre-processing of time and space Θ(c⋅n){\displaystyle \Theta (c\cdot n)} allows to answer range queries on lists where f is a semigroup operator in θ(αc(n)){\displaystyle \theta (\alpha _{c}(n))} time, where αc{\displaystyle \alpha _{c}} is a certain functional inverse of the Ackermann function.
There are some semigroup operators that admit slightly better solutions. For instance when f∈{max,min}{\displaystyle f\in \{\max ,\min \}}. Assume f=min{\displaystyle f=\min } then min(A[1..n]){\displaystyle \min(A[1..n])} returns the index of the minimum element of A[1..n]{\displaystyle A[1..n]}. Then mini,j(A){\textstyle \min _{i,j}(A)} denotes the corresponding minimum range query. There are several data structures that allow to answer a range minimum query in O(1){\displaystyle O(1)} time using a pre-processing of time and space O(n){\displaystyle O(n)}. One such solution is based on the equivalence between this problem and the lowest common ancestor problem.
The Cartesian tree TA{\displaystyle T_{A}} of an array A[1,n]{\displaystyle A[1,n]} has as root ai=min{a1,a2,…,an}{\displaystyle a_{i}=\min\{a_{1},a_{2},\ldots ,a_{n}\}} and as left and right subtrees the Cartesian tree of A[1,i−1]{\displaystyle A[1,i-1]} and the Cartesian tree of A[i+1,n]{\displaystyle A[i+1,n]} respectively. A range minimum query mini,j(A){\textstyle \min _{i,j}(A)} is the lowest common ancestor in TA{\displaystyle T_{A}} of ai{\displaystyle a_{i}} and aj{\displaystyle a_{j}}. Because the lowest common ancestor can be solved in constant time using a pre-processing of time and space O(n){\displaystyle O(n)}, range minimum query can as well. The solution when f=max{\displaystyle f=\max } is analogous. Cartesian trees can be constructed in linear time.

Mode
The mode of an array is the element that appears the most in it. For instance the mode of a=[4,5,6,7,4]{\displaystyle a=[4,5,6,7,4]} is 4. In case of a tie, any of the most frequent elements might be picked as the mode. A range mode query consists in pre-processing A[1,n]{\displaystyle A[1,n]} such that we can find the mode in any range of A[1,n]{\displaystyle A[1,n]}. Several data structures have been devised to solve this problem, we summarize some of the results in the following table.
Recently Jørgensen et al. proved a lower bound on the cell-probe model of Ω(log⁡nlog⁡(Sw/n)){\displaystyle \Omega \left({\tfrac {\log n}{\log(Sw/n)}}\right)} for any data structure that uses S cells.

Median
This particular case is of special interest since finding the median has several applications. On the other hand, the median problem, a special case of the selection problem, is solvable in O(n), using the median of medians algorithm. However its generalization through range median queries is recent. A range median query median⁡(A,i,j){\displaystyle \operatorname {median} (A,i,j)} where A,i and j have the usual meanings returns the median element of A[i,j]{\displaystyle A[i,j]}. Equivalently, median⁡(A,i,j){\displaystyle \operatorname {median} (A,i,j)} should return the element of A[i,j]{\displaystyle A[i,j]} of rank j−i2{\displaystyle {\frac {j-i}{2}}}. Range median queries cannot be solved by following any of the previous methods discussed above including Yao's approach for semigroup operators.There have been studied two variants of this problem, the offline version, where all the k queries of interest are given in a batch, and a version where all the pre-processing is done up front. The offline version can be solved with O(nlog⁡k+klog⁡n){\displaystyle O(n\log k+k\log n)} time and O(nlog⁡k){\displaystyle O(n\log k)} space.
The following pseudocode of the quickselect algorithm shows how to find the element of rank r in A[i,j]{\displaystyle A[i,j]} an unsorted array of distinct elements, to find the range medians we set r=j−i2{\displaystyle r={\frac {j-i}{2}}}.
rangeMedian(A, i, j, r) {
    if A.length() == 1
        return A[1]

    if A.low is undefined then
        m = median(A)
        A.low  = [e in A | e <= m]
        A.high = [e in A | e > m ]

    calculate t the number of elements of A[i, j] that belong to A.low

    if r <= t then
        return rangeMedian(A.low, i, j, r)
    else
        return rangeMedian(A.high, i, j, r-t)
}

Procedure rangeMedian partitions A, using A's median, into two arrays A.low and A.high, where the former contains
the elements of A that are less than or equal to the median m and the latter the rest of the elements of A.  If we know that the number of elements of A[i,j]{\displaystyle A[i,j]} that
end up in A.low is t and this number is bigger than r then we should keep looking for the element of rank r in A.low; otherwise we should look for the element of rank (r−t){\displaystyle (r-t)} in A.high. To find t, it is enough to find the maximum index m≤i−1{\displaystyle m\leq i-1} such that am{\displaystyle a_{m}} is in A.low and the maximum index l≤j{\displaystyle l\leq j} such that al{\displaystyle a_{l}}
is in A.high. Then t=l−m{\displaystyle t=l-m}. The total cost for any query, without considering the partitioning part, is log⁡n{\displaystyle \log n} since at most log⁡n{\displaystyle \log n} recursion calls are done and only a constant number of operations are performed in each of them (to get the value of t fractional cascading should be used).
If a linear algorithm to find the medians is used, the total cost of pre-processing for k range median queries is nlog⁡k{\displaystyle n\log k}. The algorithm can also be modified to solve the online version of the problem.

Majority
Finding frequent elements in a given set of items is one of the most important tasks in data mining. Finding frequent elements might be a difficult task to achieve when most items have similar frequencies. Therefore, it might be more beneficial if some threshold of significance was used for detecting such items. One of the most famous algorithms for finding the majority of an array was proposed by Boyer and Moore  which is also known as the Boyer–Moore majority vote algorithm. Boyer and Moore proposed an algorithm to find the majority element of a string (if it has one) in O(n){\displaystyle O(n)} time and using  O(1){\displaystyle O(1)} space. In the context of Boyer and Moore’s work and generally speaking, a majority element in a set of items (for example string or an array) is one whose number of instances is more than half of the size of that set. Few years later, Misra and Gries  proposed a more general version of Boyer and Moore's algorithm using O(nlog⁡(1τ)){\displaystyle O\left(n\log \left({\frac {1}{\tau }}\right)\right)} comparisons to find all items in an array whose relative frequencies are greater than some threshold 0<τ<1{\displaystyle 0<\tau <1}. A range τ{\displaystyle \tau }-majority query is one that, given a subrange of a data structure (for example an array) of size |R|{\displaystyle |R|}, returns the set of all distinct items that appear more than (or in some publications equal to) τ|R|{\displaystyle \tau |R|} times in that given range. In different structures that support range τ{\displaystyle \tau }-majority queries, τ{\displaystyle \tau } can be either static (specified during pre-processing) or dynamic (specified at query time). Many of such approaches are based on the fact that, regardless of the size of the range, for a given τ{\displaystyle \tau } there could be at most O(1/τ){\displaystyle O(1/\tau )} distinct candidates with relative frequencies at least τ{\displaystyle \tau }. By verifying each of these candidates in constant time,  O(1/τ){\displaystyle O(1/\tau )} query time is achieved. A range τ{\displaystyle \tau }-majority query is decomposable  in the sense that a τ{\displaystyle \tau }-majority in a range R{\displaystyle R} with partitions R1{\displaystyle R_{1}} and R2{\displaystyle R_{2}} must be a τ{\displaystyle \tau }-majority in either R1{\displaystyle R_{1}}or R2{\displaystyle R_{2}}. Due to this decomposability, some data structures answer τ{\displaystyle \tau }-majority queries on one-dimensional arrays by finding the Lowest common ancestor (LCA) of the endpoints of the query range in a Range tree and validating two sets of candidates (of size O(1/τ){\displaystyle O(1/\tau )}) from each endpoint to the lowest common ancestor in constant time resulting in O(1/τ){\displaystyle O(1/\tau )} query time.

Two-dimensional arrays
Gagie et al. proposed a data structure that supports range τ{\displaystyle \tau }-majority queries on an  m×n{\displaystyle m\times n} array A{\displaystyle A}. For each query Q=(R,τ){\displaystyle \operatorname {Q} =(\operatorname {R} ,\tau )} in this data structure a threshold 0<τ<1{\displaystyle 0<\tau <1} and a rectangular range R{\displaystyle \operatorname {R} } are specified, and the set of all elements that have relative frequencies (inside that rectangular range) greater than or equal to τ{\displaystyle \tau } are returned as the output. This data structure supports dynamic thresholds (specified at query time) and a pre-processing threshold α{\displaystyle \alpha } based on which it is constructed. During the pre-processing, a set of vertical and horizontal intervals are built on the m×n{\displaystyle m\times n} array. Together, a vertical and a horizontal interval form a block. Each block is part of a superblock nine times bigger than itself (three times the size of the block's horizontal interval and three times the size of its vertical one). For each block a set of candidates (with 9α{\displaystyle {\frac {9}{\alpha }}} elements at most) is stored which consists of elements that have relative frequencies at least α9{\displaystyle {\frac {\alpha }{9}}} (the pre-processing threshold as mentioned above) in its respective superblock. These elements are stored in non-increasing order according to their frequencies and it is easy to see that, any element that has a relative frequency at least α{\displaystyle \alpha } in a block must appear its set of candidates. Each τ{\displaystyle \tau }-majority query is first answered by finding the query block, or the biggest block that is contained in the provided query rectangle in O(1){\displaystyle O(1)} time. For the obtained query block,  the first 9τ{\displaystyle {\frac {9}{\tau }}} candidates are returned (without being verified) in O(1/τ){\displaystyle O(1/\tau )} time, so this process might return some false positives. Many other data structures (as discussed below) have proposed methods for verifying each candidate in constant time and thus maintaining the O(1/τ){\displaystyle O(1/\tau )} query time while returning no false positives. The cases in which the query block is smaller than 1/α{\displaystyle 1/\alpha } are handled by storing log⁡(1α){\displaystyle \log \left({\frac {1}{\alpha }}\right)} different instances of this data structure of the following form:
β=2−i,i∈{1,…,log⁡(1α)}{\displaystyle \beta =2^{-i},\;\;i\in \left\{1,\dots ,\log \left({\frac {1}{\alpha }}\right)\right\}}
where β{\displaystyle \beta } is the pre-processing threshold of the i{\displaystyle i}-th instance. Thus, for query blocks smaller than 1/α{\displaystyle 1/\alpha } the ⌈log⁡(1/τ)⌉{\displaystyle \lceil \log(1/\tau )\rceil }-th instance is queried. As mentioned above, this data structure has query time  O(1/τ){\displaystyle O(1/\tau )} and requires O(mn(H+1)log2⁡(1α)){\displaystyle O\left(mn(H+1)\log ^{2}\left({\frac {1}{\alpha }}\right)\right)} bits of space by storing a Huffman-encoded copy of it (note the log⁡(1α){\displaystyle \log({\frac {1}{\alpha }})} factor and also see Huffman coding).

One-dimensional arrays
Chan et al. proposed a data structure that given a one-dimensional arrayA{\displaystyle A}, a subrange R{\displaystyle R} of A{\displaystyle A} (specified at query time) and a threshold τ{\displaystyle \tau } (specified at query time), is able to return the list of all τ{\displaystyle \tau }-majorities in O(1/τ){\displaystyle O(1/\tau )} time requiring O(nlog⁡n){\displaystyle O(n\log n)} words of space. To answer such queries, Chan et al. begin by noting that there exists a data structure capable of returning the top-k most frequent items in a range in O(k){\displaystyle O(k)} time requiring O(n){\displaystyle O(n)} words of space. For a one-dimensional array A[0,..,n−1]{\displaystyle A[0,..,n-1]}, let a one-sided top-k range query to be of form A[0..i] for 0≤i≤n−1{\displaystyle A[0..i]{\text{ for }}0\leq i\leq n-1}. For a maximal range of ranges A[0..i] through A[0..j]{\displaystyle A[0..i]{\text{ through }}A[0..j]} in which the frequency of a distinct element e{\displaystyle e} in A{\displaystyle A} remains unchanged (and equal to f{\displaystyle f}), a horizontal line segment is constructed. The x{\displaystyle x}-interval of this line segment corresponds to [i,j]{\displaystyle [i,j]} and it has a y{\displaystyle y}-value equal to f{\displaystyle f}.  Since adding each element to A{\displaystyle A} changes the frequency of exactly one distinct element, the aforementioned process creates O(n){\displaystyle O(n)} line segments.  Moreover, for a vertical line x=i{\displaystyle x=i} all horizonal line segments intersecting it are sorted according to their frequencies. Note that, each horizontal line segment with x{\displaystyle x}-interval [ℓ,r]{\displaystyle [\ell ,r]} corresponds to exactly one distinct element e{\displaystyle e} in A{\displaystyle A}, such that A[ℓ]=e{\displaystyle A[\ell ]=e}. A top-k query can then be answered by shooting a vertical ray x=i{\displaystyle x=i} and reporting the first k{\displaystyle k} horizontal line segments that intersect it (remember from above that these line segments are already sorted according to their frequencies) in O(k){\displaystyle O(k)} time.
Chan et al. first construct a range tree in which each branching node stores one copy of the data structure described above for one-sided range top-k queries and each leaf represents an element from A{\displaystyle A}. The top-k data structure at each node is constructed based on the values existing in the subtrees of that node and is meant to answer one-sided range top-k queries. Please note that for a one-dimensional array A{\displaystyle A}, a range tree can be constructed by dividing A{\displaystyle A} into two halves and recursing on both halves; therefore, each node of the resulting range tree represents a range. It can also be seen that this range tree requires O(nlog⁡n){\displaystyle O(n\log n)} words of space, because there are O(log⁡n){\displaystyle O(\log n)} levels and each level ℓ{\displaystyle \ell } has 2ℓ{\displaystyle 2^{\ell }} nodes. Moreover, since at each level ℓ{\displaystyle \ell } of a range tree all nodes have a total of n{\displaystyle n} elements of A{\displaystyle A} at their subtrees and since there are O(log⁡n){\displaystyle O(\log n)} levels, the space complexity of this range tree is O(nlog⁡n){\displaystyle O(n\log n)}.
Using this structure, a range τ{\displaystyle \tau }-majority query A[i..j]{\displaystyle A[i..j]} on A[0..n−1]{\displaystyle A[0..n-1]} with 0≤i≤j≤n{\displaystyle 0\leq i\leq j\leq n} is answered as follows. First, the lowest common ancestor (LCA) of leaf nodes i{\displaystyle i} and j{\displaystyle j} is found in constant time. Note that there exists a data structure requiring O(n){\displaystyle O(n)} bits of space that is capable of answering the LCA queries in O(1){\displaystyle O(1)} time. Let z{\displaystyle z} denote the LCA of i{\displaystyle i} and j{\displaystyle j}, using z{\displaystyle z} and according to the decomposability of range τ{\displaystyle \tau }-majority queries (as described above and in ), the two-sided range query A[i..j]{\displaystyle A[i..j]} can be converted into two one-sided range top-k queries (from z{\displaystyle z} to i{\displaystyle i} and j{\displaystyle j}). These two one-sided range top-k queries return the top-(1/τ{\displaystyle 1/\tau }) most frequent elements in each of their respective ranges in O(1/τ){\displaystyle O(1/\tau )} time. These frequent elements make up the set of candidates for τ{\displaystyle \tau }-majorities in A[i..j]{\displaystyle A[i..j]} in which there are O(1/τ){\displaystyle O(1/\tau )} candidates some of which might be false positives. Each candidate is then assessed in constant time using a linear-space data structure (as described in Lemma 3 in ) that is able to determine in  O(1){\displaystyle O(1)} time whether or not a given subrange of an array A{\displaystyle A} contains at least q{\displaystyle q} instances of a particular element e{\displaystyle e}.

Tree paths
Gagie et al. proposed a data structure which supports queries such that, given two nodes u{\displaystyle u} and v{\displaystyle v} in a tree, are able to report the list of elements that have a greater relative frequency than τ{\displaystyle \tau } on the path from u{\displaystyle u} to v{\displaystyle v}. More formally, let T{\displaystyle T} be a labelled tree in which each node has a label from an alphabet of size σ{\displaystyle \sigma }. Let label(u)∈[1,…,σ]{\displaystyle label(u)\in [1,\dots ,\sigma ]} denote the label of node u{\displaystyle u} in T{\displaystyle T}. Let Puv{\displaystyle P_{uv}} denote the unique path from u{\displaystyle u} to v{\displaystyle v} in T{\displaystyle T} in which middle nodes are listed in the order they are visited. Given T{\displaystyle T}, and a fixed (specified during pre-processing) threshold 0<τ<1{\displaystyle 0<\tau <1}, a query Q(u,v){\displaystyle Q(u,v)} must return the set of all labels that appear more than  τ|Puv|{\displaystyle \tau |P_{uv}|} times in Puv{\displaystyle P_{uv}}.
To construct this data structure, first O(τn){\displaystyle {O}(\tau n)} nodes are marked. This can be done by marking any node that has distance at least ⌈1/τ⌉{\displaystyle \lceil 1/\tau \rceil } from the bottom of the three (height) and whose depth is divisible by ⌈1/τ⌉{\displaystyle \lceil 1/\tau \rceil }. After doing this, it can be observed that the distance between each node and its nearest marked ancestor is less than 2⌈1/τ⌉{\displaystyle 2\lceil 1/\tau \rceil }. For a marked node x{\displaystyle x}, log⁡(depth(x)){\displaystyle \log(depth(x))} different sequences (paths towards the root) Pi(x){\displaystyle P_{i}(x)} are stored,
Pi(x)=⟨label⁡(x),par⁡(x),par2⁡(x),…,par2i⁡(x)⟩{\displaystyle P_{i}(x)=\left\langle \operatorname {label} (x),\operatorname {par} (x),\operatorname {par} ^{2}(x),\ldots ,\operatorname {par} ^{2^{i}}(x)\right\rangle }
for 0≤i≤log⁡(depth(x)){\displaystyle 0\leq i\leq \log(depth(x))} where par⁡(x){\displaystyle \operatorname {par} (x)} returns the label of the direct parent of node x{\displaystyle x}. Put another way, for each marked node, the set of all paths with a power of two length (plus one for the node itself) towards the root is stored. Moreover, for each Pi(x){\displaystyle P_{i}(x)}, the set of all majority candidates Ci(x){\displaystyle C_{i}(x)} are stored. More specifically, Ci(x){\displaystyle C_{i}(x)} contains the set of all (τ/2){\displaystyle (\tau /2)}-majorities in Pi(x){\displaystyle P_{i}(x)} or labels that appear more than (τ/2).(2i+1){\displaystyle (\tau /2).(2^{i}+1)} times in Pi(x){\displaystyle P_{i}(x)}. It is easy to see that the set of candidates Ci(x){\displaystyle C_{i}(x)} can have at most 2/τ{\displaystyle 2/\tau } distinct labels for each i{\displaystyle i}. Gagie et al. then note that the set of all τ{\displaystyle \tau }-majorities in the path from any marked node x{\displaystyle x} to one of its ancestors z{\displaystyle z} is included in some Ci(x){\displaystyle C_{i}(x)} (Lemma 2 in ) since the length of Pi(x){\displaystyle P_{i}(x)} is equal to (2i+1){\displaystyle (2^{i}+1)} thus there exists a Pi(x){\displaystyle P_{i}(x)} for 0≤i≤log⁡(depth(x)){\displaystyle 0\leq i\leq \log(depth(x))} whose length is between dxz and 2dxz{\displaystyle d_{xz}{\text{ and }}2d_{xz}} where dxz{\displaystyle d_{xz}} is the distance between x and z. The existence of such Pi(x){\displaystyle P_{i}(x)} implies that a τ{\displaystyle \tau }-majority in the path from x{\displaystyle x} to z{\displaystyle z} must be a (τ/2){\displaystyle (\tau /2)}-majority in Pi(x){\displaystyle P_{i}(x)}, and thus must appear in Ci(x){\displaystyle C_{i}(x)}. It is easy to see that this data structure require O(nlog⁡n){\displaystyle O(n\log n)} words of space, because as mentioned above in the construction phase O(τn){\displaystyle O(\tau n)} nodes are marked and for each marked node some  candidate sets are stored. By definition, for each marked node O(log⁡n){\displaystyle O(\log n)} of such sets are stores, each of which contains O(1/τ){\displaystyle O(1/\tau )} candidates. Therefore, this data structure requires O(log⁡n×(1/τ)×τn)=O(nlog⁡n){\displaystyle O(\log n\times (1/\tau )\times \tau n)=O(n\log n)} words of space. Please note that each node x{\displaystyle x} also stores count(x){\displaystyle count(x)} which is equal to the number of instances of label(x){\displaystyle label(x)} on the path from x{\displaystyle x} to the root of T{\displaystyle T}, this does not increase the space complexity since it only adds a constant number of words per node.
Each query between two nodes u{\displaystyle u} and v{\displaystyle v} can be answered by using the decomposability property (as explained above) of range τ{\displaystyle \tau }-majority queries and by breaking the query path between u{\displaystyle u} and v{\displaystyle v} into four subpaths. Let z{\displaystyle z} be the lowest common ancestor of u{\displaystyle u} and v{\displaystyle v}, with x{\displaystyle x} and y{\displaystyle y} being the nearest marked ancestors of u{\displaystyle u} and v{\displaystyle v} respectively. The path from u{\displaystyle u} to v{\displaystyle v} is decomposed into the paths from u{\displaystyle u} and v{\displaystyle v} to x{\displaystyle x} and y{\displaystyle y} respectively (the size of these paths are smaller than 2⌈1/τ⌉{\displaystyle 2\lceil 1/\tau \rceil } by definition, all of which are considered as candidates), and the paths from x{\displaystyle x} and y{\displaystyle y} to z{\displaystyle z} (by finding the suitable Ci(x){\displaystyle C_{i}(x)} as explained above and considering all of its labels as candidates). Please note that, boundary nodes have to be handled accordingly so that all of these subpaths are disjoint and from all of them a set of O(1/τ){\displaystyle O(1/\tau )} candidates is derived. Each of these candidates is then verified using a combination of the labelanc(x,ℓ){\displaystyle labelanc(x,\ell )} query which returns the lowest ancestor of node x{\displaystyle x} that has label ℓ{\displaystyle \ell } and the count(x){\displaystyle count(x)} fields of each node. On a w{\displaystyle w}-bit RAM and an alphabet of size σ{\displaystyle \sigma }, the labelanc(x,ℓ){\displaystyle labelanc(x,\ell )} query can be answered in O(log⁡logw⁡σ){\displaystyle O\left(\log \log _{w}\sigma \right)} time whilst having linear space requirements. Therefore, verifying each of the O(1/τ){\displaystyle O(1/\tau )} candidates in O(log⁡logw⁡σ){\displaystyle O\left(\log \log _{w}\sigma \right)} time results in O((1/τ)log⁡logw⁡σ){\displaystyle O\left((1/\tau )\log \log _{w}\sigma \right)} total query time for returning the set of all τ{\displaystyle \tau }-majorities on the path from u{\displaystyle u} to v{\displaystyle v}.

Related problems
All the problems described above have been studied for higher dimensions as well as their dynamic versions. On the other hand, range queries might be extended to other data structures like trees, such as the level ancestor problem. A similar family of problems are orthogonal range queries, also known as counting queries.

See also
Level ancestor problem
Lowest common ancestor

References
External links
Open Data Structure - Chapter 13 - Data Structures for Integers
Data Structures for Range Median Queries - Gerth Stolting Brodal and Allan Gronlund Jorgensen",35266324,https://en.wikipedia.org/wiki/Range_query_(computer_science)
Rank (computer programming),"In computer programming, rank with no further specifications is usually a synonym for (or refers to) ""number of dimensions""; thus, a two-dimensional array has rank two, a three-dimensional array has rank three and so on.
Strictly, no formal definition can be provided which applies to every programming language, since each of them has its own concepts, semantics and terminology; the term may not even be applicable or, to the contrary, applied with a very specific meaning in the context of a given language.
In the case of APL the notion applies to every operand; and dyads (""binary functions"") have a left rank and a right rank.
The box below instead shows how rank of a type and rank of an array expression could be defined (in a semi-formal style) for C++ and illustrates a simple way to calculate them at compile time.

Given the code above the rank of a type T can be calculated at compile time by

or the shorter form

Calculating the rank of an expression can be done using","In computer programming, rank with no further specifications is usually a synonym for (or refers to) ""number of dimensions""; thus, a two-dimensional array has rank two, a three-dimensional array has rank three and so on.
Strictly, no formal definition can be provided which applies to every programming language, since each of them has its own concepts, semantics and terminology; the term may not even be applicable or, to the contrary, applied with a very specific meaning in the context of a given language.
In the case of APL the notion applies to every operand; and dyads (""binary functions"") have a left rank and a right rank.
The box below instead shows how rank of a type and rank of an array expression could be defined (in a semi-formal style) for C++ and illustrates a simple way to calculate them at compile time.

Given the code above the rank of a type T can be calculated at compile time by

or the shorter form

Calculating the rank of an expression can be done using

See also
Rank (linear algebra), for a definition of rank as applied to matrices
Rank (J programming language), a concept of the same name in the J programming language",366007,https://en.wikipedia.org/wiki/Rank_(computer_programming)
Relative Gain Array,The Relative Gain Array (RGA) is a classical widely-used method for determining the best input-output pairings for multivariable process control systems. It has many practical open-loop and closed-loop control applications and is relevant to analyzing many fundamental steady-state closed-loop system properties such as stability and robustness.,"The Relative Gain Array (RGA) is a classical widely-used method for determining the best input-output pairings for multivariable process control systems. It has many practical open-loop and closed-loop control applications and is relevant to analyzing many fundamental steady-state closed-loop system properties such as stability and robustness.

Definition
Given a linear time-invariant (LTI) system represented by a nonsingular matrix G{\displaystyle \mathrm {G} }, the relative gain array (RGA) is defined as 

R=Φ(G)=G∘(G−1)T.{\displaystyle \mathrm {R} =\Phi (\mathrm {G} )=\mathrm {G} \circ {(\mathrm {G} ^{-1})}^{T}.}where ∘{\displaystyle \circ } is the elementwise Hadamard product of the two matrices, and the transpose operator (no conjugate) is necessary even for complex G{\displaystyle \mathrm {G} }. Each i,j{\displaystyle {i,j}} element Ri,j{\displaystyle \mathrm {R} _{i,j}} gives a scale invariant (unit-invariant) measure of the dependence of output j{\displaystyle j} on input i{\displaystyle i}.

Properties
The following are some of the linear-algebra properties of the RGA:
Each row and column of Φ(G){\displaystyle \Phi (\mathrm {G} )} sums to 1.
For nonsingular diagonal matrices D{\displaystyle \mathrm {D} } and E{\displaystyle \mathrm {E} }, Φ(G)=Φ(DGE){\displaystyle \Phi (\mathrm {G} )=\Phi (\mathrm {D} \mathrm {G} \mathrm {E} )}.
For permutation matrices P{\displaystyle \mathrm {P} } and Q{\displaystyle \mathrm {Q} }, PΦ(G)Q=Φ(PGQ){\displaystyle \mathrm {P} \Phi (\mathrm {G} )\mathrm {Q} =\Phi (\mathrm {P} \mathrm {G} \mathrm {Q} )}.
Lastly, Φ(G−1)=Φ(G)T=Φ(GT){\displaystyle \Phi (\mathrm {G} ^{-1})=\Phi (\mathrm {G} )^{T}=\Phi {(\mathrm {G} ^{T})}}.The second property says that the RGA is invariant with respect to nonzero scalings of the rows and columns of G{\displaystyle \mathrm {G} }, which is why the RGA is invariant with respect to the choice of units on different input and output variables. The third property says that the RGA is consistent with respect to permutations of the rows or columns of G{\displaystyle \mathrm {G} }.

Generalizations
The RGA is often generalized in practice to be used when G{\displaystyle \mathrm {G} } is singular, e.g., non-square, by replacing the inverse of G{\displaystyle \mathrm {G} } with its Moore–Penrose inverse (pseudoinverse). However, it has been shown that the Moore–Penrose pseudoinverse fails to preserve the critical scale-invariance property of the RGA (#2 above) and that the unit-consistent (UC) generalized inverse must therefore be used. 


== References ==",58283759,https://en.wikipedia.org/wiki/Relative_Gain_Array
Reverse lookup,"Reverse lookup is a procedure of using a value to retrieve a unique key in an associative array.Applications of reverse lookup include 

reverse DNS lookup, which provides the domain name associated with a particular IP address,
reverse telephone directory, which provides the name of the entity associated with a particular telephone number,
reverse image search, which provides similar images to the one provided.","Reverse lookup is a procedure of using a value to retrieve a unique key in an associative array.Applications of reverse lookup include 

reverse DNS lookup, which provides the domain name associated with a particular IP address,
reverse telephone directory, which provides the name of the entity associated with a particular telephone number,
reverse image search, which provides similar images to the one provided.

See also
Inverse function
Reverse dictionary


== References ==",654006,https://en.wikipedia.org/wiki/Reverse_lookup
Row- and column-major order,"In computing, row-major order and column-major order are methods for storing multidimensional arrays  in linear storage such as random access memory.
The difference between the orders lies in which elements of an array are contiguous in memory. In row-major order, the consecutive elements of a row reside next to each other, whereas the same holds true for consecutive elements of a column in column-major order. While the terms allude to the rows and columns of a two-dimensional array, i.e. a matrix, the orders can be generalized to arrays of any dimension by noting that the terms row-major and column-major are equivalent to lexicographic and colexicographic orders, respectively. It is also worth noting that matrices, being commonly represented as collections of row or column vectors, using this approach are effectively stored as consecutive vectors or consecutive vector components. Such ways of storing data are referred to as AoS and SoA respectively.
Data layout is critical for correctly passing arrays between programs written in different programming languages. It is also important for performance when traversing an array because modern CPUs process sequential data more efficiently than nonsequential data. This is primarily due to CPU caching which exploits spatial locality of reference. In addition, contiguous access makes it possible to use SIMD instructions that operate on vectors of data. In some media such as magnetic-tape data storage, accessing sequentially is orders of magnitude faster than nonsequential access.","In computing, row-major order and column-major order are methods for storing multidimensional arrays  in linear storage such as random access memory.
The difference between the orders lies in which elements of an array are contiguous in memory. In row-major order, the consecutive elements of a row reside next to each other, whereas the same holds true for consecutive elements of a column in column-major order. While the terms allude to the rows and columns of a two-dimensional array, i.e. a matrix, the orders can be generalized to arrays of any dimension by noting that the terms row-major and column-major are equivalent to lexicographic and colexicographic orders, respectively. It is also worth noting that matrices, being commonly represented as collections of row or column vectors, using this approach are effectively stored as consecutive vectors or consecutive vector components. Such ways of storing data are referred to as AoS and SoA respectively.
Data layout is critical for correctly passing arrays between programs written in different programming languages. It is also important for performance when traversing an array because modern CPUs process sequential data more efficiently than nonsequential data. This is primarily due to CPU caching which exploits spatial locality of reference. In addition, contiguous access makes it possible to use SIMD instructions that operate on vectors of data. In some media such as magnetic-tape data storage, accessing sequentially is orders of magnitude faster than nonsequential access.

Explanation and example
The terms row-major and column-major stem from the terminology related to ordering objects.  A general way to order objects with many attributes is to first group and order them by one attribute, and then, within each such group, group and order them by another attribute, etc. If more than one attribute participates in ordering, the first would be called major and the last minor. If two attributes participate in ordering, it is sufficient to name only the major attribute.
In the case of arrays, the attributes are the indices along each dimension. For matrices in mathematical notation, the first index indicates the row, and the second indicates the column, e.g., given a matrix A{\displaystyle A}, the entry a1,2{\displaystyle a_{1,2}} is in its first row and second column. This convention is carried over to the syntax in programming languages, although often with indexes starting at 0 instead of 1.Even though the row is indicated by the first index and the column by the second index, no grouping order between the dimensions is implied by this. The choice of how to group and order the indices, either by row-major or column-major methods, is thus a matter of convention. The same terminology can be applied to even higher dimensional arrays. Row-major grouping starts from the leftmost index  and column-major from the rightmost index, leading to lexicographic and colexicographic (or colex) orders, respectively.
For example, the array

A=ay,x=[a11a12a13a21a22a23]{\displaystyle A=a_{y,x}={\begin{bmatrix}\color {Blue}a_{11}&\color {Blue}a_{12}&\color {Blue}a_{13}\\\color {Orange}a_{21}&\color {Orange}a_{22}&\color {Orange}a_{23}\end{bmatrix}}}could be stored in two possible ways:

Programming languages handle this in different ways. In C, multidimensional arrays are stored in row-major order, and the array indexes are written  row-first (lexicographical access order):

On the other hand, in Fortran, arrays are stored in column-major order, while the array indexes are still written row-first (colexicographical access order):

Note how the use of A[i][j] with multi-step indexing as in C, as opposed to a neutral notation like A(i,j) as in Fortran, almost inevitably implies row-major order for syntactic reasons, so to speak, because it can be rewritten as (A[i])[j], and the A[i] row part can even be assigned to an intermediate variable that is then indexed in a separate expression. (No other implications should be assumed, e.g., Fortran is not column-major simply because of its notation, and even the above implication could intentionally be circumvented in a new language.)
To use column-major order in a row-major environment, or vice versa, for whatever reason, one workaround is to assign non-conventional roles to the indexes (using the first index for the column and the second index for the row), and another is to bypass language syntax by explicitly computing positions in a one-dimensional array. Of course, deviating from convention probably incurs a cost that increases with the degree of necessary interaction with conventional language features and other code, not only in the form of increased vulnerability to mistakes (forgetting to also invert matrix multiplication order, reverting to convention during code maintenance, etc.), but also in the form of having to actively rearrange elements, all of which have to be weighed against any original purpose such as increasing performance. Running the loop row-wise is preferred in row-major languages like C and vice versa for column-major languages.

Programming languages and libraries
Programming languages or their standard libraries that support multi-dimensional arrays typically have a native row-major or column-major storage order for these arrays.
Row-major order is used in C/C++/Objective-C (for C-style arrays), PL/I, Pascal, Speakeasy, and SAS.Column-major order is used in Fortran, MATLAB, GNU Octave, Julia, S, S-PLUS, R, Scilab, Yorick, and Rasdaman.

Neither row-major nor column-major
A typical alternative for dense array storage is to use Iliffe vectors, which typically store pointers to elements in the same row contiguously (like row-major order), but not the rows themselves. They are used in (ordered by age): Java, C#/CLI/.Net, Scala, and Swift.
Even less dense is to use lists of lists, e.g., in Python, and in the Wolfram Language of Wolfram Mathematica.An alternative approach uses tables of tables, e.g., in Lua.

External libraries
Support for multi-dimensional arrays may also be provided by external libraries, which may even support arbitrary orderings, where each dimension has a stride value, and row-major or column-major are just two possible resulting interpretations.
Row-major order is the default in NumPy (for Python).
Column-major order is the default in Eigen  and Armadillo(both for C++).
A special case would be OpenGL (and OpenGL ES) for graphics processing. Since ""recent mathematical treatments of linear algebra and related fields invariably treat vectors as columns,"" designer Mark Segal decided to substitute this for the convention in predecessor IRIS GL, which was to write vectors as rows; for compatibility, transformation matrices would still be stored in vector-major (=row-major) rather than coordinate-major (=column-major) order, and he then used the trick ""[to] say that matrices in OpenGL are stored in column-major order"". This was really only relevant for presentation, because matrix multiplication was stack-based and could still be interpreted as post-multiplication, but, worse, reality leaked through the C-based API because individual elements would be accessed as M[vector][coordinate] or, effectively, M[column][row], which unfortunately muddled the convention that the designer sought to adopt, and this was even preserved in the OpenGL Shading Language that was later added (although this also makes it possible to access coordinates by name instead, e.g., M[vector].y). As a result, many developers will now simply declare that having the column as the first index is the definition of column-major, even though this is clearly not the case with a real column-major language like Fortran.
Torch (for Lua) changed from column-major to row-major default order.

Transposition
As exchanging the indices of an array is the essence of array transposition, an array stored as row-major but read as column-major (or vice versa) will appear transposed (as long as the matrix is square).  As actually performing this rearrangement in memory is typically an expensive operation, some systems provide options to specify individual matrices as being stored transposed. The programmer must then decide whether or not to rearrange the elements in memory, based on the actual usage (including the number of times that the array is reused in a computation).
For example, the Basic Linear Algebra Subprograms functions are passed flags indicating which arrays are transposed.

Address calculation in general
The concept generalizes to arrays with more than two dimensions.
For a d-dimensional N1×N2×⋯×Nd{\displaystyle N_{1}\times N_{2}\times \cdots \times N_{d}} array with dimensions Nk (k=1...d), a given element of this array is specified by a tuple (n1,n2,…,nd){\displaystyle (n_{1},n_{2},\ldots ,n_{d})} of d (zero-based) indices nk∈[0,Nk−1]{\displaystyle n_{k}\in [0,N_{k}-1]}.
In row-major order, the last dimension is contiguous, so that the memory-offset of this element is given by:

In column-major order, the first dimension is contiguous, so that the memory-offset of this element is given by:

where the empty product is the multiplicative identity element, i.e., ∏ℓ=10Nℓ=∏ℓ=d+1dNℓ=1{\textstyle \prod _{\ell =1}^{0}N_{\ell }=\prod _{\ell =d+1}^{d}N_{\ell }=1}.
For a given order, the stride in dimension k is given by the multiplication value in parentheses before index nk in the right-hand side summations above.
More generally, there are d! possible orders for a given array, one for each permutation of dimensions (with row-major and column-order just 2 special cases), although the lists of stride values are not necessarily permutations of each other, e.g., in the 2-by-3 example above, the strides are (3,1) for row-major and (1,2) for column-major.

See also
Array data structure
Matrix representation
Vectorization (mathematics), the equivalent of turning a matrix into the corresponding column-major vector
CSR format, a technique for storing sparse matrices in memory
Morton order, another way of mapping multidimensional data to a one-dimensional index, useful in tree data structures

References
Sources
Donald E. Knuth, The Art of Computer Programming Volume 1: Fundamental Algorithms, third edition, section 2.2.6 (Addison-Wesley: New York, 1997).",1620786,https://en.wikipedia.org/wiki/Row-_and_column-major_order
Sorted array,"A sorted array is an array data structure in which each element is sorted in numerical, alphabetical, or some other order, and placed at equally spaced addresses in computer memory. It is typically used in computer science to implement static lookup tables to hold multiple values which have the same data type. Sorting an array is useful in organising data in ordered form and recovering them rapidly.","A sorted array is an array data structure in which each element is sorted in numerical, alphabetical, or some other order, and placed at equally spaced addresses in computer memory. It is typically used in computer science to implement static lookup tables to hold multiple values which have the same data type. Sorting an array is useful in organising data in ordered form and recovering them rapidly.

Overview
Sorted arrays are the most space-efficient data structure with the best locality of reference for sequentially stored data.Elements within a sorted array are found using a binary search, in O(log n); thus sorted arrays are suited for cases when one needs to be able to look up elements quickly, e.g. as a set or multiset data structure. This complexity for lookups is the same as for self-balancing binary search trees.
In some data structures, an array of structures is used. In such cases, the same sorting methods can be used to sort the structures according to some key as a structure element; for example, sorting records of students according to roll numbers or names or grades.
If one is using a sorted dynamic array, then it is possible to insert and delete elements. The insertion and deletion of elements in a sorted array executes at O(n), due to the need to shift all the elements following the element to be inserted or deleted; in comparison a self-balancing binary search tree inserts and deletes at O(log n). In the case where elements are deleted or inserted at the end, a sorted dynamic array can do this in amortized O(1) time while a self-balancing binary search tree always operates at O(log n).
Elements in a sorted array can be looked up by their index (random access) at O(1) time, an operation taking O(log n) or O(n) time for more complex data structures.

History
John von Neumann wrote the first array sorting program (merge sort) in 1945, when the first stored-program computer was still being built.

See also
Sorting algorithm
Binary search algorithm
Heap (data structure)
Search data structure


== References ==",15844857,https://en.wikipedia.org/wiki/Sorted_array
Sparse matrix,"In numerical analysis and scientific computing, a sparse matrix or sparse array is a matrix in which most of the elements are zero. There is no strict definition regarding the proportion of zero-value elements for a matrix to qualify as sparse but a common criterion is that the number of non-zero elements is roughly equal to the number of rows or columns. By contrast, if most of the elements are non-zero, the matrix is considered dense. The number of zero-valued elements divided by the total number of elements (e.g., m × n for an m × n matrix) is sometimes referred to as the sparsity of the matrix.
Conceptually, sparsity corresponds to systems with few pairwise interactions. For example, consider a line of balls connected by springs from one to the next: this is a sparse system as only adjacent balls are coupled. By contrast, if the same line of balls were to have springs connecting each ball to all other balls, the system would correspond to a dense matrix. The concept of sparsity is useful in combinatorics and application areas such as network theory and numerical analysis, which typically have a low density of significant data or connections. Large sparse matrices often appear in scientific or engineering applications when solving partial differential equations.
When storing and manipulating sparse matrices on a computer, it is beneficial and often necessary to use specialized algorithms and data structures that take advantage of the sparse structure of the matrix. Specialized computers have been made for sparse matrices, as they are common in the machine learning field. Operations using standard dense-matrix structures and algorithms are slow and inefficient when applied to large sparse matrices as processing and memory are wasted on the zeros. Sparse data is by nature more easily compressed and thus requires significantly less storage. Some very large sparse matrices are infeasible to manipulate using standard dense-matrix algorithms.","In numerical analysis and scientific computing, a sparse matrix or sparse array is a matrix in which most of the elements are zero. There is no strict definition regarding the proportion of zero-value elements for a matrix to qualify as sparse but a common criterion is that the number of non-zero elements is roughly equal to the number of rows or columns. By contrast, if most of the elements are non-zero, the matrix is considered dense. The number of zero-valued elements divided by the total number of elements (e.g., m × n for an m × n matrix) is sometimes referred to as the sparsity of the matrix.
Conceptually, sparsity corresponds to systems with few pairwise interactions. For example, consider a line of balls connected by springs from one to the next: this is a sparse system as only adjacent balls are coupled. By contrast, if the same line of balls were to have springs connecting each ball to all other balls, the system would correspond to a dense matrix. The concept of sparsity is useful in combinatorics and application areas such as network theory and numerical analysis, which typically have a low density of significant data or connections. Large sparse matrices often appear in scientific or engineering applications when solving partial differential equations.
When storing and manipulating sparse matrices on a computer, it is beneficial and often necessary to use specialized algorithms and data structures that take advantage of the sparse structure of the matrix. Specialized computers have been made for sparse matrices, as they are common in the machine learning field. Operations using standard dense-matrix structures and algorithms are slow and inefficient when applied to large sparse matrices as processing and memory are wasted on the zeros. Sparse data is by nature more easily compressed and thus requires significantly less storage. Some very large sparse matrices are infeasible to manipulate using standard dense-matrix algorithms.

Special cases
Banded
An important special type of sparse matrices is band matrix, defined as follows. The lower bandwidth of a matrix A is the smallest number p such that the entry ai,j vanishes whenever i > j + p. Similarly, the upper bandwidth is the smallest number p such that ai,j = 0 whenever i < j − p (Golub & Van Loan 1996, §1.2.1). For example, a tridiagonal matrix has lower bandwidth 1 and upper bandwidth 1. As another example, the following sparse matrix has lower and upper bandwidth both equal to 3. Notice that zeros are represented with dots for clarity.

Matrices with reasonably small upper and lower bandwidth are known as band matrices and often lend themselves to simpler algorithms than general sparse matrices; or one can sometimes apply dense matrix algorithms and gain efficiency simply by looping over a reduced number of indices.
By rearranging the rows and columns of a matrix A it may be possible to obtain a matrix A′ with a lower bandwidth. A number of algorithms are designed for bandwidth minimization.

Diagonal
A very efficient structure for an extreme case of band matrices, the diagonal matrix, is to store just the entries in the main diagonal as a one-dimensional array, so a diagonal n × n matrix requires only n entries.

Symmetric
A symmetric sparse matrix arises as the adjacency matrix of an undirected graph; it can be stored efficiently as an adjacency list.

Block diagonal
A block-diagonal matrix consists of sub-matrices along its diagonal blocks. A block-diagonal matrix A has the form

where Ak is a square matrix for all k = 1, ..., n.

Use
Reducing fill-in
The fill-in of a matrix are those entries that change from an initial zero to a non-zero value during the execution of an algorithm. To reduce the memory requirements and the number of arithmetic operations used during an algorithm, it is useful to minimize the fill-in by switching rows and columns in the matrix. The symbolic Cholesky decomposition can be used to calculate the worst possible fill-in before doing the actual Cholesky decomposition.
There are other methods than the Cholesky decomposition in use. Orthogonalization methods (such as QR factorization) are common, for example, when solving problems by least squares methods. While the theoretical fill-in is still the same, in practical terms the ""false non-zeros"" can be different for different methods. And symbolic versions of those algorithms can be used in the same manner as the symbolic Cholesky to compute worst case fill-in.

Solving sparse matrix equations
Both iterative and direct methods exist for sparse matrix solving.
Iterative methods, such as conjugate gradient method and GMRES utilize fast computations of matrix-vector products Axi{\displaystyle Ax_{i}}, where matrix A{\displaystyle A} is sparse. The use of preconditioners can significantly accelerate convergence of such iterative methods.

Storage
A matrix is typically stored as a two-dimensional array. Each entry in the array represents an element ai,j of the matrix and is accessed by the two indices i and j. Conventionally, i is the row index, numbered from top to bottom, and j is the column index, numbered from left to right. For an m × n matrix, the amount of memory required to store the matrix in this format is proportional to m × n (disregarding the fact that the dimensions of the matrix also need to be stored).
In the case of a sparse matrix, substantial memory requirement reductions can be realized by storing only the non-zero entries. Depending on the number and distribution of the non-zero entries, different data structures can be used and yield huge savings in memory when compared to the basic approach. The trade-off is that accessing the individual elements becomes more complex and additional structures are needed to be able to recover the original matrix unambiguously.
Formats can be divided into two groups:

Those that support efficient modification, such as DOK (Dictionary of keys), LIL (List of lists), or COO (Coordinate list). These are typically used to construct the matrices.
Those that support efficient access and matrix operations, such as CSR (Compressed Sparse Row) or CSC (Compressed Sparse Column).

Dictionary of keys (DOK)
DOK consists of a dictionary that maps (row, column)-pairs to the value of the elements. Elements that are missing from the dictionary are taken to be zero. The format is good for incrementally constructing a sparse matrix in random order, but poor for iterating over non-zero values in lexicographical order. One typically constructs a matrix in this format and then converts to another more efficient format for processing.

List of lists (LIL)
LIL stores one list per row, with each entry containing the column index and the value. Typically, these entries are kept sorted by column index for faster lookup. This is another format good for incremental matrix construction.

Coordinate list (COO)
COO stores a list of (row, column, value) tuples. Ideally, the entries are sorted first by row index and then by column index, to improve random access times. This is another format that is good for incremental matrix construction.

Compressed sparse row (CSR, CRS or Yale format)
The compressed sparse row (CSR) or compressed row storage (CRS) or Yale format represents a matrix M by three (one-dimensional) arrays, that respectively contain nonzero values, the extents of rows, and column indices. It is similar to COO, but compresses the row indices, hence the name. This format allows fast row access and matrix-vector multiplications (Mx). The CSR format has been in use since at least the mid-1960s, with the first complete description appearing in 1967.The CSR format stores a sparse m × n matrix M in row form using three (one-dimensional) arrays (V, COL_INDEX, ROW_INDEX). Let NNZ denote the number of nonzero entries in M. (Note that zero-based indices shall be used here.)

The arrays V and COL_INDEX are of length NNZ, and contain the non-zero values and the column indices of those values respectively
COL_INDEX contains the column in which the corresponding entry V is located.
The array ROW_INDEX is of length m + 1 and encodes the index in V and COL_INDEX where the given row starts. This is equivalent to ROW_INDEX[j] encoding the total number of nonzeros above row j.  The last element is NNZ , i.e., the fictitious index in V immediately after the last valid index NNZ - 1.For example, the matrix

is a 4 × 4 matrix with 4 nonzero elements, hence

V         = [ 5 8 3 6 ]
COL_INDEX = [ 0 1 2 1 ]
ROW_INDEX = [ 0 1 2 3 4 ] 

assuming a zero-indexed language.
To extract a row, we first define:

row_start = ROW_INDEX[row]
row_end   = ROW_INDEX[row + 1]

Then we take slices from V and COL_INDEX starting at row_start and ending at row_end.
To extract the row 1 (the second row) of this matrix we set row_start=1 and row_end=2. Then we make the slices V[1:2] = [8] and COL_INDEX[1:2] = [1]. We now know that in row 1 we have one element at column 1 with value 8.
In this case the CSR representation contains 13 entries, compared to 16 in the original matrix. The CSR format saves on memory only when NNZ < (m (n − 1) − 1) / 2.
Another example, the matrix

is a 4 × 6 matrix (24 entries) with 8 nonzero elements, so

V         = [ 10 20 30 40 50 60 70 80 ]
COL_INDEX = [  0  1  1  3  2  3  4  5 ]   
ROW_INDEX = [  0  2  4  7  8 ]

The whole is stored as 21 entries: 8 in V, 8 in COL_INDEX, and 5 in ROW_INDEX.

ROW_INDEX splits the array V into rows: (10, 20) (30, 40) (50, 60, 70) (80), indicating the index of V (and COL_INDEX) where each row starts and ends;
COL_INDEX aligns values in columns: (10, 20, ...) (0, 30, 0, 40, ...)(0, 0, 50, 60, 70, 0) (0, 0, 0, 0, 0, 80).Note that in this format, the first value of ROW_INDEX is always zero and the last is always NNZ, so they are in some sense redundant (although in programming languages where the array length needs to be explicitly stored, NNZ would not be redundant). Nonetheless, this does avoid the need to handle an exceptional case when computing the length of each row, as it guarantees the formula ROW_INDEX[i + 1] − ROW_INDEX[i] works for any row i. Moreover, the memory cost of this redundant storage is likely insignificant for a sufficiently large matrix.
The (old and new) Yale sparse matrix formats are instances of the CSR scheme. The old Yale format works exactly as described above, with three arrays; the new format combines ROW_INDEX and COL_INDEX into a single array and handles the diagonal of the matrix separately.For  logical  adjacency matrices, the data array can be omitted, as the existence of an entry in the row array is sufficient to model a binary adjacency relation.
It is likely known as the Yale format because it was proposed in the 1977 Yale Sparse Matrix Package report from Department of Computer Science at Yale University.

Compressed sparse column (CSC or CCS)
CSC is similar to CSR except that values are read first by column, a row index is stored for each value, and column pointers are stored. For example, CSC is (val, row_ind, col_ptr), where val is an array of the (top-to-bottom, then left-to-right) non-zero values of the matrix; row_ind is the row indices corresponding to the values; and, col_ptr is the list of val indexes where each column starts. The name is based on the fact that column index information is compressed relative to the COO format. One typically uses another format (LIL, DOK, COO) for construction. This format is efficient for arithmetic operations, column slicing, and matrix-vector products. This is the traditional format for specifying a sparse matrix in MATLAB (via the sparse function).

Software
Many software libraries support sparse matrices, and provide solvers for sparse matrix equations. The following are open-source:

PETSc, a large C library, containing many different matrix solvers for a variety of matrix storage formats.
Trilinos, a large C++ library, with sub-libraries dedicated to the storage of dense and sparse matrices and solution of corresponding linear systems.
Eigen3 is a C++ library that contains several sparse matrix solvers. However, none of them are parallelized.
MUMPS (MUltifrontal Massively Parallel sparse direct Solver), written in Fortran90, is a frontal solver.
deal.II, a finite element library that also has a sub-library for sparse linear systems and their solution.
DUNE, another finite element library that also has a sub-library for sparse linear systems and their solution.
Armadillo provides a user-friendly C++ wrapper for BLAS and LAPACK.
SciPy provides support for several sparse matrix formats, linear algebra, and solvers.
ALGLIB is a C++ and C# library with sparse linear algebra support
ARPACK Fortran 77 library for sparse matrix diagonalization and manipulation, using the Arnoldi algorithm
SLEPc Library for solution of large scale linear systems and sparse matrices
scikit-learn, a Python library for machine learning, provides support for sparse matrices and solvers.

History
The term sparse matrix was possibly coined by Harry Markowitz who initiated some pioneering work but then left the field.

See also
Notes
References
Golub, Gene H.; Van Loan, Charles F. (1996). Matrix Computations (3rd ed.). Baltimore: Johns Hopkins. ISBN 978-0-8018-5414-9.
Stoer, Josef; Bulirsch, Roland (2002). Introduction to Numerical Analysis (3rd ed.). Berlin, New York: Springer-Verlag. ISBN 978-0-387-95452-3.
Tewarson, Reginald P. (May 1973). Sparse Matrices (Part of the Mathematics in Science & Engineering series). Academic Press Inc. (This book, by a professor at the State University of New York at Stony Book, was the first book exclusively dedicated to Sparse Matrices.  Graduate courses using this as a textbook were offered at that University in the early 1980s).
Bank, Randolph E.; Douglas, Craig C. ""Sparse Matrix Multiplication Package"" (PDF).
Pissanetzky, Sergio (1984). Sparse Matrix Technology. Academic Press. ISBN 9780125575805.
Snay, Richard A. (1976). ""Reducing the profile of sparse symmetric matrices"". Bulletin Géodésique. 50 (4): 341–352. Bibcode:1976BGeod..50..341S. doi:10.1007/BF02521587. hdl:2027/uc1.31210024848523. S2CID 123079384. Also NOAA Technical Memorandum NOS NGS-4, National Geodetic Survey, Rockville, MD.
Jennifer Scott and Miroslav Tuma: ""Algorithms for Sparse Linear Systems"", Birkhauser, (2023), DOI: https://doi.org/10.1007/978-3-031-25820-6 (Open Access Book)

Further reading
Gibbs, Norman E.; Poole, William G.; Stockmeyer, Paul K. (1976). ""A comparison of several bandwidth and profile reduction algorithms"". ACM Transactions on Mathematical Software. 2 (4): 322–330. doi:10.1145/355705.355707. S2CID 14494429.
Gilbert, John R.; Moler, Cleve; Schreiber, Robert (1992). ""Sparse matrices in MATLAB: Design and Implementation"". SIAM Journal on Matrix Analysis and Applications. 13 (1): 333–356. CiteSeerX 10.1.1.470.1054. doi:10.1137/0613024.
Sparse Matrix Algorithms Research at the Texas A&M University.
SuiteSparse Matrix Collection
SMALL project A EU-funded project on sparse models, algorithms and dictionary learning for large-scale data.
Wolfgang Hackbusch: Iterative Solution of Large Sparse Systems of Equations, Springer, (1994).
Yousef Saad: Iterative Methods for Sparse Linear Systems, SIAM, ISBN 978-0-89871-534-7 (2003).
Timothy A. Davis: Direct Methods for Sparse Linear Systems, SIAM, ISBN 978-0-89871-613-9 (2006).",341015,https://en.wikipedia.org/wiki/Sparse_matrix
Stride of an array,"In computer programming, the stride of an array (also referred to as increment, pitch or step size) is the number of locations in memory between beginnings of successive array elements, measured in bytes or in units of the size of the array's elements. The stride cannot be smaller than the element size but can be larger, indicating extra space between elements.
An array with stride of exactly the same size as the size of each of its elements is contiguous in memory. Such arrays are sometimes said to have unit stride. Unit stride arrays are sometimes more efficient than non-unit stride arrays, but non-unit stride arrays can be more efficient for 2D or multi-dimensional arrays, depending on the effects of caching and the access patterns used. This can be attributed to the principle of locality, specifically spatial locality.","In computer programming, the stride of an array (also referred to as increment, pitch or step size) is the number of locations in memory between beginnings of successive array elements, measured in bytes or in units of the size of the array's elements. The stride cannot be smaller than the element size but can be larger, indicating extra space between elements.
An array with stride of exactly the same size as the size of each of its elements is contiguous in memory. Such arrays are sometimes said to have unit stride. Unit stride arrays are sometimes more efficient than non-unit stride arrays, but non-unit stride arrays can be more efficient for 2D or multi-dimensional arrays, depending on the effects of caching and the access patterns used. This can be attributed to the principle of locality, specifically spatial locality.

Reasons for non-unit stride
Arrays may have a stride larger than their elements' width in bytes in at least three cases:

Padding
Many languages (including C and C++) allow structures to be padded to better take advantage either of the word length and/or cache line size of the machine. For example:

In the above code snippet, myArray might well turn out to have a stride of eight bytes, rather than five (4 bytes for the int plus one for the char), if the C code were compiled for a 32-bit architecture, and the compiler had optimized (as is usually the case) for minimum processing time rather than minimum memory usage.

Overlapping parallel arrays
Some languages allow arrays of structures to be treated as overlapping parallel arrays with non-unit stride:

This idiom is a form of type punning.

Array cross-section
Some languages like PL/I or Fortran allow what is known as an array cross-section, which selects certain columns  or rows from a larger array.: p.262   For example, if a two-dimensional array is declared as

an array of one dimension consisting only of the second column may be referenced as

Example of multidimensional array with non-unit stride
Non-unit stride is particularly useful for images. It allows for creating subimages without copying the pixel data. Java example:


== References ==",366038,https://en.wikipedia.org/wiki/Stride_of_an_array
Suffix array,"In computer science, a suffix array is a sorted array of all suffixes of a string. It is a data structure used in, among others, full-text indices, data-compression algorithms, and the field of bibliometrics.
Suffix arrays were introduced by Manber & Myers (1990) as a simple, space efficient alternative to suffix trees. They had independently been discovered by Gaston Gonnet in 1987 under the name PAT array (Gonnet, Baeza-Yates & Snider 1992).
Li, Li & Huo (2016) gave the first in-place O(n){\displaystyle {\mathcal {O}}(n)} time suffix array construction algorithm that is optimal both in time and space, where in-place means that the algorithm only needs O(1){\displaystyle {\mathcal {O}}(1)} additional space beyond the input string and the output suffix array.
Enhanced suffix arrays (ESAs) are suffix arrays with additional tables that reproduce the full functionality of suffix trees preserving the same time and memory complexity.
The suffix array for a subset of all suffixes of a string is called sparse suffix array. Multiple probabilistic algorithms have been developed to minimize the additional memory usage including an optimal time and memory algorithm.","In computer science, a suffix array is a sorted array of all suffixes of a string. It is a data structure used in, among others, full-text indices, data-compression algorithms, and the field of bibliometrics.
Suffix arrays were introduced by Manber & Myers (1990) as a simple, space efficient alternative to suffix trees. They had independently been discovered by Gaston Gonnet in 1987 under the name PAT array (Gonnet, Baeza-Yates & Snider 1992).
Li, Li & Huo (2016) gave the first in-place O(n){\displaystyle {\mathcal {O}}(n)} time suffix array construction algorithm that is optimal both in time and space, where in-place means that the algorithm only needs O(1){\displaystyle {\mathcal {O}}(1)} additional space beyond the input string and the output suffix array.
Enhanced suffix arrays (ESAs) are suffix arrays with additional tables that reproduce the full functionality of suffix trees preserving the same time and memory complexity.
The suffix array for a subset of all suffixes of a string is called sparse suffix array. Multiple probabilistic algorithms have been developed to minimize the additional memory usage including an optimal time and memory algorithm.

Definition
Let S=S[1]S[2]...S[n]{\displaystyle S=S[1]S[2]...S[n]} be an n{\textstyle n}-string and let S[i,j]{\displaystyle S[i,j]} denote the substring of S{\displaystyle S} ranging from i{\displaystyle i} to j{\displaystyle j} inclusive.
The suffix array A{\displaystyle A} of S{\displaystyle S} is now defined to be an array of integers providing the starting positions of suffixes of S{\displaystyle S} in lexicographical order. This means, an entry A[i]{\displaystyle A[i]} contains the starting position of the i{\displaystyle i}-th smallest suffix in S{\displaystyle S} and thus for all 1≤i≤n{\displaystyle 1\leq i\leq n}: S[A[i−1],n]<S[A[i],n]{\displaystyle S[A[i-1],n]<S[A[i],n]}.
Each suffix of S{\displaystyle S} shows up in A{\displaystyle A} exactly once. Suffixes are simple strings. These strings are sorted (as in a paper dictionary), before their starting positions (integer indices) are saved in A{\displaystyle A}.

Example
Consider the text S{\displaystyle S}=banana$ to be indexed:

The text ends with the special sentinel letter $ that is unique and lexicographically smaller than any other character. The text has the following suffixes:

These suffixes can be sorted in ascending order:

The suffix array A{\displaystyle A} contains the starting positions of these sorted suffixes:

The suffix array with the suffixes written out vertically underneath for clarity:

So for example, A[3]{\displaystyle A[3]} contains the value 4, and therefore refers to the suffix starting at position 4 within S{\displaystyle S}, which is the suffix ana$.

Correspondence to suffix trees
Suffix arrays are closely related to suffix trees:

Suffix arrays can be constructed by performing a depth-first traversal of a suffix tree. The suffix array corresponds to the leaf-labels given in the order in which these are visited during the traversal, if edges are visited in the lexicographical order of their first character.
A suffix tree can be constructed in linear time by using a combination of suffix array and LCP array. For a description of the algorithm, see the corresponding section in the LCP array article.It has been shown that every suffix tree algorithm can be systematically replaced with an algorithm that uses a suffix array enhanced with additional information (such as the LCP array) and solves the same problem in the same time complexity.
Advantages of suffix arrays over suffix trees include improved space requirements, simpler linear time construction algorithms (e.g., compared to Ukkonen's algorithm) and improved cache locality.

Space efficiency
Suffix arrays were introduced by Manber & Myers (1990) in order to improve over the space requirements of suffix trees: Suffix arrays store n{\displaystyle n} integers. Assuming an integer requires 4{\displaystyle 4} bytes, a suffix array requires 4n{\displaystyle 4n} bytes in total. This is significantly less than the 20n{\displaystyle 20n} bytes which are required by a careful suffix tree implementation.However, in certain applications, the space requirements of suffix arrays may still be prohibitive. Analyzed in bits, a suffix array requires O(nlog⁡n){\displaystyle {\mathcal {O}}(n\log n)} space, whereas the original text over an alphabet of size σ{\displaystyle \sigma } only requires O(nlog⁡σ){\displaystyle {\mathcal {O}}(n\log \sigma )} bits.
For a human genome with σ=4{\displaystyle \sigma =4} and n=3.4×109{\displaystyle n=3.4\times 10^{9}} the suffix array would therefore occupy about 16 times more memory than the genome itself.
Such discrepancies motivated a trend towards compressed suffix arrays and BWT-based compressed full-text indices such as the FM-index. These data structures require only space within the size of the text or even less.

Construction algorithms
A suffix tree can be built in O(n){\displaystyle {\mathcal {O}}(n)} and can be converted into a suffix array by traversing the tree depth-first also in O(n){\displaystyle {\mathcal {O}}(n)}, so there exist algorithms that can build a suffix array in O(n){\displaystyle {\mathcal {O}}(n)}.
A naive approach to construct a suffix array is to use a comparison-based sorting algorithm. These algorithms require O(nlog⁡n){\displaystyle {\mathcal {O}}(n\log n)} suffix comparisons, but a suffix comparison runs in O(n){\displaystyle {\mathcal {O}}(n)} time, so the overall runtime of this approach is O(n2log⁡n){\displaystyle {\mathcal {O}}(n^{2}\log n)}.
More advanced algorithms take advantage of the fact that the suffixes to be sorted are not arbitrary strings but related to each other. These algorithms strive to achieve the following goals:
minimal asymptotic complexity Θ(n){\displaystyle \Theta (n)}
lightweight in space, meaning little or no working memory beside the text and the suffix array itself is needed
fast in practiceOne of the first algorithms to achieve all goals is the SA-IS algorithm of Nong, Zhang & Chan (2009). The algorithm is also rather simple (< 100 LOC) and can be enhanced to simultaneously construct the LCP array. The SA-IS algorithm is one of the fastest known suffix array construction algorithms. A careful implementation by Yuta Mori outperforms most other linear or super-linear construction approaches.
Beside time and space requirements, suffix array construction algorithms are also differentiated by their supported alphabet:  constant alphabets where the alphabet size is bound by a constant, integer alphabets where characters are integers in a range depending on n{\displaystyle n} and general alphabets where only character comparisons are allowed.Most suffix array construction algorithms are based on one of the following approaches:
Prefix doubling algorithms are based on a strategy of Karp, Miller & Rosenberg (1972). The idea is to find prefixes that honor the lexicographic ordering of suffixes. The assessed prefix length doubles in each iteration of the algorithm until a prefix is unique and provides the rank of the associated suffix.
Recursive algorithms follow the approach of the suffix tree construction algorithm by Farach (1997) to recursively sort a subset of suffixes. This subset is then used to infer a suffix array of the remaining suffixes. Both of these suffix arrays are then merged to compute the final suffix array.
Induced copying algorithms are similar to recursive algorithms in the sense that they use an already sorted subset to induce a fast sort of the remaining suffixes. The difference is that these algorithms favor iteration over recursion to sort the selected suffix subset. A survey of this diverse group of algorithms has been put together by Puglisi, Smyth & Turpin (2007).A well-known recursive algorithm for integer alphabets is the DC3 / skew algorithm of Kärkkäinen & Sanders (2003). It runs in linear time and has successfully been used as the basis for parallel and external memory suffix array construction algorithms.
Recent work by Salson et al. (2010) proposes an algorithm for updating the suffix array of a text that has been edited instead of rebuilding a new suffix array from scratch. Even if the theoretical worst-case time complexity is O(nlog⁡n){\displaystyle {\mathcal {O}}(n\log n)}, it appears to perform well in practice: experimental results from the authors showed that their implementation of dynamic suffix arrays is generally more efficient than rebuilding when considering the insertion of a reasonable number of letters in the original text.
In practical open source work, a commonly used routine for suffix array construction was qsufsort, based on the 1999 Larsson-Sadakane algorithm. This routine has been superseded by Yuta Mori's DivSufSort, ""the fastest known suffix sorting algorithm in main memory"" as of 2017. It too can be modified to compute an LCP array. It uses a induced copying combined with Itoh-Tanaka. In 2021 a faster implementation of the algorithm was presented by Ilya Grebnov  which in average showed 65% performance improvement over DivSufSort implementation on Silesia Corpus.

Generalized suffix array
The concept of a suffix array can be extended to more than one string. This is called a generalized suffix array (or GSA), a suffix array that contains all suffixes for a set of strings (for example, S=S1,S2,S3,...,Sk{\displaystyle S=S_{1},S_{2},S_{3},...,S_{k}} and is lexicographically sorted with all suffixes of each string.

Applications
The suffix array of a string can be used as an index to quickly locate every occurrence of a substring pattern P{\displaystyle P} within the string S{\displaystyle S}. Finding every occurrence of the pattern is equivalent to finding every suffix that begins with the substring. Thanks to the lexicographical ordering, these suffixes will be grouped together in the suffix array and can be found efficiently with two binary searches. The first search locates the starting position of the interval, and the second one determines the end position:

Finding the substring pattern P{\displaystyle P} of length m{\displaystyle m} in the string S{\displaystyle S} of length n{\displaystyle n} takes O(mlog⁡n){\displaystyle {\mathcal {O}}(m\log n)} time, given that a single suffix comparison needs to compare m{\displaystyle m} characters. Manber & Myers (1990) describe how this bound can be improved to O(m+log⁡n){\displaystyle {\mathcal {O}}(m+\log n)} time using LCP information. The idea is that a pattern comparison does not need to re-compare certain characters, when it is already known that these are part of the longest common prefix of the pattern and the current search interval. Abouelhoda, Kurtz & Ohlebusch (2004) improve the bound even further and achieve a search time of O(m){\displaystyle {\mathcal {O}}(m)} for constant alphabet size, as known from suffix trees.
Suffix sorting algorithms can be used to compute the Burrows–Wheeler transform (BWT). The BWT requires sorting of all cyclic permutations of a string. If this string ends in a special end-of-string character that is lexicographically smaller than all other character (i.e., $), then the order of the sorted rotated BWT matrix corresponds to the order of suffixes in a suffix array. The BWT can therefore be computed in linear time by first constructing a suffix array of the text and then deducing the BWT string: BWT[i]=S[A[i]−1]{\displaystyle BWT[i]=S[A[i]-1]}.
Suffix arrays can also be used to look up substrings in example-based machine translation, demanding much less storage than a full phrase table as used in Statistical machine translation.
Many additional applications of the suffix array require the LCP array. Some of these are detailed in the application section of the latter.

Enhanced suffix arrays
Suffix trees are powerful data structures that have wide application in areas of pattern and string matching, indexing and textual statistics. However, it occupies a significant amount of space and thus has a drawback in many real-time applications that require processing a considerably large amount of data like genome analysis. To overcome this drawback, Enhanced Suffix Arrays were developed that are data structures consisting of suffix arrays and an additional table called the child table that contains the information about the parent-child relationship between the nodes in the suffix tree. The node branching data structure for this tree is a linked list. Enhanced suffix arrays are superior in terms of both space efficiency and time complexity and are easy to implement. Moreover, they can be applied to any algorithm that uses a suffix tree by using an abstract concept lcp-interval trees. The time complexity for searching a pattern in an enhanced suffix array is O(m|Σ|).
The suffix array of the string is an array of n integers in the range of 0 to n that represents the n+1 suffixes of the string including the special character #.
The suffix array is composed of two arrays:

pos array pos[1,...n]: It represents a sorted list of all S suffixes. Only the initial positions of the suffixes are stored in the array to reduce the space complexity since the suffixes are too large.
lcp array lcp[1,...n]: It is an array of n integers that maintains the lengths of the longest common prefix of two consecutive suffixes stored in the pos array.

Constructing the lcp-interval
For a suffix array of S, the lcp-interval associated with the corresponding node of suffix tree of S can be defined as:
Interval [i,..j], 0 ≤ i ≤ j ≤ n is an lcp-interval of lcp-value, if
1. lcptab[i] < l,
2. lcptab[k] ≥ l for all i + 1 ≤ k ≤ j,
3. lcptab[k] = l for some i + 1 ≤ k ≤ j if i ≠ j and l = n − i + 1 if i = j, 
4. lcptab[j + 1] < l.
The length of the longest common prefix of pos[i − 1] and pos[i] is stored in lcp[i],where 2 ≤ i ≤ n. The lcp-interval portrays the same parent-child relationship as that among the associated nodes in the suffix tree of S.This shows that if the corresponding node of [i..j] is a child of the corresponding node of [k..l], a lcp-interval [i..j] is a child interval of another lcp-interval [k..l]. If [k..l] is a child interval of [i..j], a lcp-interval [i..j] is the parent interval of a lcp-interval [k..l].

Constructing a child table
The child table cldtab is composed of three n arrays, up, down and nextlIndex. The information about the edges of the corresponding suffix tree is stored and maintained by the up and down arrays. The nextlIndex array stores the links in the linked list used for node branching the suffix tree.
The up, down and nextlIndex array are defined as follows:

The element up[i] records the starting index of the longest lcp-second interval’s child interval, which ends at index i-1.
The initial index of the second child interval of the longest lcp-interval, starting at index i is stored in the element down[i].
If and only if the interval is neither the first child nor the final child of its parent, the element nextlIndex[i] contains the first index of the next sibling interval of the longest lcp-interval, starting at index i.By performing a bottom-up traversal of the lcp-interval of the tree, the child table can be constructed in linear time. The up/down values and the nextlIndex values can be computed separately by using two distinct algorithms.

Constructing a suffix link table
The suffix links for an enhanced suffix array can be computed by generating the suffix link interval [1,..,r] for each [i,..j] interval during the preprocessing. The left and right elements l and r of the interval are maintained in the first index of [i,..,j]. The table for this interval ranges from 0 to n. The suffix link table is constructed by the left-to-right breadth-first traversal of the lcp-interval tree. Every time an l-interval is computed, it is added to the list of l-intervals, which is referred to as the l-list. When the lcp-value > 0, for every l-interval[i,..,j] in the list, link[i] is calculated. The interval [l,..,r] is computed by a binary search in(l-1)-list, where l is the largest left boundary amongst all the l-1 intervals. The suffix link interval of [i,..j] is represented by this interval[l,..,r]. The values l and r are ultimately stored in the first index of [i,..,j].

Notes
References
Manber, Udi; Myers, Gene (1990). Suffix arrays: a new method for on-line string searches. First Annual ACM-SIAM Symposium on Discrete Algorithms. pp. 319–327.
Manber, Udi; Myers, Gene (1993). ""Suffix arrays: a new method for on-line string searches"". SIAM Journal on Computing. 22 (5): 935–948. doi:10.1137/0222058. S2CID 5074629.
Gawrychowski, Paweł; Kociumaka, Tomasz (January 2017). ""Sparse Suffix Tree Construction in Optimal Time and Space"". Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms. Philadelphia, PA: Society for Industrial and Applied Mathematics: 425–439. arXiv:1608.00865. doi:10.1137/1.9781611974782.27. ISBN 9781611974782. S2CID 6608776.
Li, Zhize; Li, Jian; Huo, Hongwei (2016). Optimal In-Place Suffix Sorting. Proceedings of the 25th International Symposium on String Processing and Information Retrieval (SPIRE). Lecture Notes in Computer Science. Vol. 11147. Springer. pp. 268–284. arXiv:1610.08305. doi:10.1007/978-3-030-00479-8_22. ISBN 978-3-030-00478-1.
Shi, Fei (1996). ""Suffix arrays for multiple strings: A method for on-line multiple string searches"". Concurrency and Parallelism, Programming, Networking, and Security. Lecture Notes in Computer Science. Vol. 1179. Springer Berlin Heidelberg. pp. 11–22. doi:10.1007/BFb0027775. ISBN 978-3-540-62031-0.
Abouelhoda, Mohamed Ibrahim; Kurtz, Stefan; Ohlebusch, Enno (2002). The Enhanced Suffix Array and Its Applications to Genome Analysis. Algorithms in Bioinformatics. Lecture Notes in Computer Science. Vol. 2452. doi:10.1007/3-540-45784-4_35. ISBN 978-3-540-44211-0.
Abouelhoda, Mohamed Ibrahim; Kurtz, Stefan; Ohlebusch, Enno (March 2004). ""Replacing suffix trees with enhanced suffix arrays"". Journal of Discrete Algorithms. 2 (1): 53–86. doi:10.1016/S1570-8667(03)00065-0. ISSN 1570-8667.
Gonnet, G.H.; Baeza-Yates, R.A.; Snider, T. (1992). ""New indices for text: PAT trees and PAT arrays"". Information Retrieval: Data Structures and Algorithms.
Kurtz, S (1999). ""Reducing the space requirement of suffix trees"". Software: Practice and Experience. 29 (13): 1149–1171. doi:10.1002/(SICI)1097-024X(199911)29:13<1149::AID-SPE274>3.0.CO;2-O. hdl:10338.dmlcz/135448.
Puglisi, Simon J.; Smyth, W. F.; Turpin, Andrew H. (2007). ""A taxonomy of suffix array construction algorithms"". ACM Computing Surveys. 39 (2): 4. doi:10.1145/1242471.1242472. S2CID 2653529.
Nong, Ge; Zhang, Sen; Chan, Wai Hong (2009). Linear Suffix Array Construction by Almost Pure Induced-Sorting. 2009 Data Compression Conference. p. 193. doi:10.1109/DCC.2009.42. ISBN 978-0-7695-3592-0.
Fischer, Johannes (2011). Inducing the LCP-Array. Algorithms and Data Structures. Lecture Notes in Computer Science. Vol. 6844. pp. 374–385. arXiv:1101.3448. doi:10.1007/978-3-642-22300-6_32. ISBN 978-3-642-22299-3.
Salson, M.; Lecroq, T.; Léonard, M.; Mouchard, L. (2010). ""Dynamic extended suffix arrays"". Journal of Discrete Algorithms. 8 (2): 241. doi:10.1016/j.jda.2009.02.007.
Burkhardt, Stefan; Kärkkäinen, Juha (2003). Fast Lightweight Suffix Array Construction and Checking. Combinatorial Pattern Matching. Lecture Notes in Computer Science. Vol. 2676. pp. 55–69. doi:10.1007/3-540-44888-8_5. ISBN 978-3-540-40311-1.
Karp, Richard M.; Miller, Raymond E.; Rosenberg, Arnold L. (1972). Rapid identification of repeated patterns in strings, trees and arrays. Proceedings of the fourth annual ACM symposium on Theory of computing - STOC '72. pp. 125–136. doi:10.1145/800152.804905.
Farach, M. (1997). Optimal suffix tree construction with large alphabets. Proceedings 38th Annual Symposium on Foundations of Computer Science. doi:10.1109/SFCS.1997.646102. ISBN 0-8186-8197-7.
I, Tomohiro; Kärkkäinen, Juha; Kempa, Dominik (2014). Faster Sparse Suffix Sorting. Leibniz International Proceedings in Informatics (LIPIcs). Vol. 25. Schloss Dagstuhl – Leibniz-Zentrum fuer Informatik. pp. 386–396. doi:10.4230/LIPIcs.STACS.2014.386. ISBN 978-3-939897-65-1.
Kärkkäinen, Juha; Sanders, Peter (2003). Simple Linear Work Suffix Array Construction. Automata, Languages and Programming. Lecture Notes in Computer Science. Vol. 2719. doi:10.1007/3-540-45061-0_73. ISBN 978-3-540-40493-4.
Dementiev, Roman; Kärkkäinen, Juha; Mehnert, Jens; Sanders, Peter (2008). ""Better external memory suffix array construction"". Journal of Experimental Algorithmics. 12: 1–24. doi:10.1145/1227161.1402296. S2CID 12296500.
Kulla, Fabian; Sanders, Peter (2007). ""Scalable parallel suffix array construction"". Parallel Computing. 33 (9): 605–612. doi:10.1016/j.parco.2007.06.004.
Mohamed Ibrahim Abouelhoda, Stefan Kurtz, and Enno Ohlebusch. ""Replacing suffix trees with enhanced suffix arrays."" Journal of Discrete Algorithms, 2(1):53–86, 2004.
Dong Kyue Kim, Jeong Eun Jeon, and Heejin Park. ""An efficient index data structure with the capabilities of suffix trees and suffix arrays for alphabets of non-negligible size."" String Processing and Information Retrieval Lecture Notes in Computer Science, page138–149, 2004.

External links

Suffix Array in Java
Suffix sorting module for BWT in C code
Suffix Array Implementation in Ruby
Suffix array library and tools
Project containing various Suffix Array c/c++ Implementations with a unified interface
A fast, lightweight, and robust C API library to construct the suffix array
Suffix Array implementation in Python
Linear Time Suffix Array implementation in C using suffix tree",1303494,https://en.wikipedia.org/wiki/Suffix_array
Variable-length array,"In computer programming, a variable-length array (VLA), also called variable-sized or runtime-sized, is an array data structure whose length is determined at run time (instead of at compile time).
In C, the VLA is said to have a variably modified type that depends on a value (see Dependent type).
The main purpose of VLAs is to simplify programming of numerical algorithms.
Programming languages that support VLAs include Ada, Algol 68 (for non-flexible rows), APL, C99 (although subsequently relegated in C11 to a conditional feature, which implementations are not required to support; on some platforms, VLAs could be implemented previously with alloca() or similar functions) and C# (as unsafe-mode stack-allocated arrays), COBOL, Fortran 90, J, and Object Pascal (the language used in Borland Delphi and Lazarus, that uses FPC).
Growable arrays (also called dynamic arrays) are generally more useful than VLAs because dynamic arrays can do everything VLAs can do, and also support growing the array at run-time.
For this reason, many programming languages (JavaScript, Java, Python, R, etc.) only support growable arrays.
Even in programming languages that do support variable-length arrays, it's often recommended to avoid using (stack-based) variable-length arrays, and instead use (heap-based) dynamic arrays.","In computer programming, a variable-length array (VLA), also called variable-sized or runtime-sized, is an array data structure whose length is determined at run time (instead of at compile time).
In C, the VLA is said to have a variably modified type that depends on a value (see Dependent type).
The main purpose of VLAs is to simplify programming of numerical algorithms.
Programming languages that support VLAs include Ada, Algol 68 (for non-flexible rows), APL, C99 (although subsequently relegated in C11 to a conditional feature, which implementations are not required to support; on some platforms, VLAs could be implemented previously with alloca() or similar functions) and C# (as unsafe-mode stack-allocated arrays), COBOL, Fortran 90, J, and Object Pascal (the language used in Borland Delphi and Lazarus, that uses FPC).
Growable arrays (also called dynamic arrays) are generally more useful than VLAs because dynamic arrays can do everything VLAs can do, and also support growing the array at run-time.
For this reason, many programming languages (JavaScript, Java, Python, R, etc.) only support growable arrays.
Even in programming languages that do support variable-length arrays, it's often recommended to avoid using (stack-based) variable-length arrays, and instead use (heap-based) dynamic arrays.

Memory
Allocation
The GNU C Compiler allocates memory for VLAs with automatic storage duration on the stack. This is the faster and more straightforward option compared to heap-allocation, and is used by most compilers.
VLAs can also be allocated on the heap and internally accessed using a pointer to this block.

Implementation
C99
The following C99 function allocates a variable-length array of a specified size, fills it with floating-point values, and then passes it to another function for processing. Because the array is declared as an automatic variable, its lifetime ends when read_and_process() returns.

In C99, the length parameter must come before the variable-length array parameter in function calls. In C11, a __STDC_NO_VLA__ macro is defined if VLA is not supported. The C23 standard makes VLA types mandatory again. Only creation of VLA objects with automatic storage duration is optional. GCC had VLA as an extension before C99, one that also extends into its C++ dialect.
Linus Torvalds has expressed his displeasure in the past over VLA usage for arrays with predetermined small sizes because it generates lower quality assembly code. With the Linux 4.20 kernel, the Linux kernel is effectively VLA-free.Although C11 does not explicitly name a size-limit for VLAs, some believe it should have the same maximum size as all other objects, i.e. SIZE_MAX bytes. However, this should be understood in the wider context of environment and platform limits, such as the typical stack-guard page size of 4 KiB, which is many orders of magnitude smaller than SIZE_MAX.
It is possible to have VLA object with dynamic storage by using a pointer to an array.

Ada
The following is the same example in Ada. Ada arrays carry their bounds with them, so there is no need to pass the length to the Process function.

Fortran 90
The equivalent Fortran 90 function is

when utilizing the Fortran 90 feature of checking procedure interfaces at compile time; on the other hand, if the functions use pre-Fortran 90 call interface, the (external) functions must first be declared, and the array length must be explicitly passed as an argument (as in C):

Cobol
The following COBOL fragment declares a variable-length array of records DEPT-PERSON having a length (number of members) specified by the value of PEOPLE-CNT:

The COBOL VLA, unlike that of other languages mentioned here, is safe because COBOL requires one to specify the maximal array size – in this example, DEPT-PERSON cannot have more than 20 items, regardless of the value of PEOPLE-CNT.

C#
The following C# fragment declares a variable-length array of integers. Prior to C# version 7.2, a pointer to the array is required, requiring an ""unsafe"" context. The ""unsafe"" keyword requires an assembly containing this code to be marked as unsafe.

C# version 7.2 and later allow the array to be allocated without the ""unsafe"" keyword, through the use of the Span feature.

Object Pascal
Object Pascal dynamic arrays are allocated on the heap.In this language, it is called a dynamic array. The declaration of such a variable is similar to the declaration of a static array, but without specifying its size. The size of the array is given at the time of its use.

Removing the contents of a dynamic array is done by assigning it a size of zero.


== References ==",13854884,https://en.wikipedia.org/wiki/Variable-length_array
Associative array,"In computer science, an associative array, map, symbol table, or dictionary is an abstract data type that stores a collection of (key, value) pairs, such that each possible key appears at most once in the collection. In mathematical terms, an associative array is a function with finite domain. It supports 'lookup', 'remove', and 'insert' operations. 
The dictionary problem is the classic problem of designing efficient data structures that implement associative arrays.
The two major solutions to the dictionary problem are hash tables and search trees.
It is sometimes also possible to solve the problem using directly addressed arrays, binary search trees, or other more specialized structures.
Many programming languages include associative arrays as primitive data types, while many other languages provide software libraries that support associative arrays. Content-addressable memory is a form of direct hardware-level support for associative arrays.
Associative arrays have many applications including such fundamental programming patterns as memoization and the decorator pattern.The name does not come from the associative property known in mathematics. Rather, it arises from the association of values with keys. It is not to be confused with associative processors.","In computer science, an associative array, map, symbol table, or dictionary is an abstract data type that stores a collection of (key, value) pairs, such that each possible key appears at most once in the collection. In mathematical terms, an associative array is a function with finite domain. It supports 'lookup', 'remove', and 'insert' operations. 
The dictionary problem is the classic problem of designing efficient data structures that implement associative arrays.
The two major solutions to the dictionary problem are hash tables and search trees.
It is sometimes also possible to solve the problem using directly addressed arrays, binary search trees, or other more specialized structures.
Many programming languages include associative arrays as primitive data types, while many other languages provide software libraries that support associative arrays. Content-addressable memory is a form of direct hardware-level support for associative arrays.
Associative arrays have many applications including such fundamental programming patterns as memoization and the decorator pattern.The name does not come from the associative property known in mathematics. Rather, it arises from the association of values with keys. It is not to be confused with associative processors.

Operations
In an associative array, the association between a key and a value is often known as a ""mapping""; the same word may also be used to refer to the process of creating a new association.
The operations that are usually defined for an associative array are:
Insert or put: add a new (key,value){\displaystyle (key,value)} pair to the collection, mapping the key to its new value. Any existing mapping is overwritten. The arguments to this operation are the key and the value.
Remove or delete: remove a (key,value){\displaystyle (key,value)} pair from the collection, unmapping a given key from its value. The argument to this operation is the key.
Lookup, find, or get: find the value (if any) that is bound to a given key. The argument to this operation is the key, and the value is returned from the operation. If no value is found, some lookup functions raise an exception, while others return a default value (such as zero, null, or a specific value passed to the constructor).Associative arrays may also include other operations such as determining the number of mappings or constructing an iterator to loop over all the mappings. For such operations, the order in which the mappings are returned is usually implementation-defined.
A multimap generalizes an associative array by allowing multiple values to be associated with a single key. A bidirectional map is a related abstract data type in which the mappings operate in both directions: each value must be associated with a unique key, and a second lookup operation takes a value as an argument and looks up the key associated with that value.

Properties
The operations of the associative array should satisfy various properties:
lookup(k, insert(j, v, D)) = if k == j then v else lookup(k, D)
lookup(k, new()) = fail, where fail is an exception or default value
remove(k, insert(j, v, D)) = if k == j then remove(k, D) else insert(j, v, remove(k, D))
remove(k, new()) = new()where k and j are keys, v is a value, D is an associative array, and new() creates a new, empty associative array.

Example
Suppose that the set of loans made by a library is represented in a data structure. Each book in a library may be checked out only by a single library patron at a time. However, a single patron may be able to check out multiple books. Therefore, the information about which books are checked out to which patrons may be represented by an associative array, in which the books are the keys and the patrons are the values. Using notation from Python or JSON, the data structure would be:

A lookup operation on the key ""Great Expectations"" would return ""John"". If John returns his book, that would cause a deletion operation, and if Pat checks out a book, that would cause an insertion operation, leading to a different state:

Implementation
For dictionaries with very few mappings, it may make sense to implement the dictionary using an association list, a linked list of mappings. With this implementation, the time to perform the basic dictionary operations is linear in the total number of mappings; however, it is easy to implement and the constant factors in its running time are small.Another very simple implementation technique, usable when the keys are restricted to a narrow range, is direct addressing into an array: the value for a given key k is stored at the array cell A[k], or if there is no mapping for k then the cell stores a special sentinel value that indicates the lack of a mapping. This technique is simple and fast, with each dictionary operation taking constant time. However, the space requirement for this structure is the size of the entire keyspace, making it impractical unless the keyspace is small.The two major approaches for implementing dictionaries are a hash table or a search tree.

Hash table implementations
The most frequently used general-purpose implementation of an associative array is with a hash table: an array combined with a hash function that separates each key into a separate ""bucket"" of the array. The basic idea behind a hash table is that accessing an element of an array via its index is a simple, constant-time operation. Therefore, the average overhead of an operation for a hash table is only the computation of the key's hash, combined with accessing the corresponding bucket within the array. As such, hash tables usually perform in O(1) time, and usually outperform alternative implementations.
Hash tables must be able to handle collisions: the mapping by the hash function of two different keys to the same bucket of the array. The two most widespread approaches to this problem are separate chaining and open addressing. In separate chaining, the array does not store the value itself but stores a pointer to another container, usually an association list, that stores all of the values matching the hash. By contrast, in open addressing, if a hash collision is found, the table seeks an empty spot in an array to store the value in a deterministic manner, usually by looking at the next immediate position in the array.
Open addressing has a lower cache miss ratio than separate chaining when the table is mostly empty. However, as the table becomes filled with more elements, open addressing's performance degrades exponentially. Additionally, separate chaining uses less memory in most cases, unless the entries are very small (less than four times the size of a pointer).

Tree implementations
Self-balancing binary search trees
Another common approach is to implement an associative array with a self-balancing binary search tree, such as an AVL tree or a red–black tree.Compared to hash tables, these structures have both strengths and weaknesses. The worst-case performance of self-balancing binary search trees is significantly better than that of a hash table, with a time complexity in big O notation of O(log n). This is in contrast to hash tables, whose worst-case performance involves all elements sharing a single bucket, resulting in O(n) time complexity. In addition, and like all binary search trees, self-balancing binary search trees keep their elements in order. Thus, traversing its elements follows a least-to-greatest pattern, whereas traversing a hash table can result in elements being in seemingly random order. Because they are in-order, tree-based maps can also satisfy range queries (find all values between two bounds) whereas a hashmap can only find exact values. However, hash tables have a much better average-case time complexity than self-balancing binary search trees of O(1), and their worst-case performance is highly unlikely when a good hash function is used.
A self-balancing binary search tree can be used to implement the buckets for a hash table that uses separate chaining. This allows for average-case constant lookup, but assures a worst-case performance of O(log n). However, this introduces extra complexity into the implementation and may cause even worse performance for smaller hash tables, where the time spent inserting into and balancing the tree is greater than the time needed to perform a linear search on all of the elements of a linked list or similar data structure.

Other trees
Associative arrays may also be stored in unbalanced binary search trees or in data structures specialized to a particular type of keys such as radix trees, tries, Judy arrays, or van Emde Boas trees, though the relative performance of these implementations varies. For instance, Judy trees are indicated to perform less efficiently than hash tables, while carefully selected hash tables generally perform more efficiently than adaptive radix trees, with potentially greater restrictions on the data types they can handle. The advantages of these alternative structures come from their ability to handle additional associative array operations, such as finding the mapping whose key is the closest to a queried key when the query is absent in the set of mappings.

Comparison
Ordered dictionary
The basic definition of a dictionary does not mandate an order. To guarantee a fixed order of enumeration, ordered versions of the associative array are often used. There are two senses of an ordered dictionary:

The order of enumeration is always deterministic for a given set of keys by sorting. This is the case for tree-based implementations, one representative being the <map> container of C++.
The order of enumeration is key-independent and is instead based on the order of insertion. This is the case for the ""ordered dictionary"" in .NET Framework, the LinkedHashMap of Java and Python.The latter is more common. Such ordered dictionaries can be implemented using an association list, by overlaying a doubly linked list on top of a normal dictionary, or by moving the actual data out of the sparse (unordered) array and into a dense insertion-ordered one.

Language support
Associative arrays can be implemented in any programming language as a package and many language systems provide them as part of their standard library. In some languages, they are not only built into the standard system, but have special syntax, often using array-like subscripting.
Built-in syntactic support for associative arrays was introduced in 1969 by SNOBOL4, under the name ""table"". TMG offered tables with string keys and integer values. MUMPS made multi-dimensional associative arrays, optionally persistent, its key data structure. SETL supported them as one possible implementation of sets and maps. Most modern scripting languages, starting with AWK and including Rexx, Perl, PHP, Tcl, JavaScript, Maple, Python, Ruby, Wolfram Language, Go, and Lua, support associative arrays as a primary container type. In many more languages, they are available as library functions without special syntax.
In Smalltalk, Objective-C, .NET, Python, REALbasic, Swift, VBA and Delphi they are called dictionaries; in Perl, Ruby and Seed7 they are called hashes; in C++, C#, Java, Go, Clojure, Scala, OCaml, Haskell they are called maps (see map (C++), unordered_map (C++), and Map); in Common Lisp and Windows PowerShell, they are called hash tables (since both typically use this implementation); in Maple and Lua, they are called tables. In PHP, all arrays can be associative, except that the keys are limited to integers and strings. In JavaScript (see also JSON), all objects behave as associative arrays with string-valued keys, while the Map and WeakMap types take arbitrary objects as keys. In Lua, they are used as the primitive building block for all data structures. In Visual FoxPro, they are called Collections. The D language also supports associative arrays.

Permanent storage
Many programs using associative arrays will need to store that data in a more permanent form, such as a computer file. A common solution to this problem is a generalized concept known as archiving or serialization, which produces a text or binary representation of the original objects that can be written directly to a file. This is most commonly implemented in the underlying object model, like .Net or Cocoa, which includes standard functions that convert the internal data into text. The program can create a complete text representation of any group of objects by calling these methods, which are almost always already implemented in the base associative array class.For programs that use very large data sets, this sort of individual file storage is not appropriate, and a database management system (DB) is required. Some DB systems natively store associative arrays by serializing the data and then storing that serialized data and the key. Individual arrays can then be loaded or saved from the database using the key to refer to them. These key–value stores have been used for many years and have a history as long as that of the more common relational database (RDBs), but a lack of standardization, among other reasons, limited their use to certain niche roles. RDBs were used for these roles in most cases, although saving objects to a RDB can be complicated, a problem known as object-relational impedance mismatch.
After c. 2010, the need for high-performance databases suitable for cloud computing and more closely matching the internal structure of the programs using them led to a renaissance in the key–value store market. These systems can store and retrieve associative arrays in a native fashion, which can greatly improve performance in common web-related workflows.

See also
Key–value database
Tuple
Function (mathematics)
JSON

References
External links

NIST's Dictionary of Algorithms and Data Structures: Associative Array",95154,https://en.wikipedia.org/wiki/Associative_array
Association list,"In computer programming and particularly in Lisp, an association list, often referred to as an alist, is a linked list in which each list element (or node) comprises a key and a value.  The association list is said to associate the value with the key.  In order to find the value associated with a given key, a sequential search is used: each element of the list is searched in turn, starting at the head, until the key is found.  Associative lists provide a simple way of implementing an associative array, but are efficient only when the number of keys is very small.","In computer programming and particularly in Lisp, an association list, often referred to as an alist, is a linked list in which each list element (or node) comprises a key and a value.  The association list is said to associate the value with the key.  In order to find the value associated with a given key, a sequential search is used: each element of the list is searched in turn, starting at the head, until the key is found.  Associative lists provide a simple way of implementing an associative array, but are efficient only when the number of keys is very small.

Operation
An associative array is an abstract data type that can be used to maintain a collection of key–value pairs and look up the value associated with a given key. The association list provides a simple way of implementing this data type.
To test whether a key is associated with a value in a given association list, search the list starting at its first node and continuing either until a node containing the key has been found or until the search reaches the end of the list (in which case the key is not present).
To add a new key–value pair to an association list, create a new node for that key-value pair, set the node's link to be the previous first element of the association list, and replace the first element of the association list with the new node. Although some implementations of association lists disallow having multiple nodes with the same keys as each other, such duplications are not problematic for this search algorithm: duplicate keys that appear later in the list are ignored.It is also possible to delete a key from an association list, by scanning the list to find each occurrence of the key and splicing the nodes containing the key out of the list. The scan should continue to the end of the list, even when the key is found, in case the same key may have been inserted multiple times.

Performance
The disadvantage of association lists is that the time to search is O(n), where n is the length of the list. For large lists, this may be much slower than the times that can be obtained by representing an associative array as a binary search tree or as a hash table.
Additionally, unless the list is regularly pruned to remove elements with duplicate keys, multiple values associated with the same key will increase the size of the list, and thus the time to search, without providing any compensatory advantage.
One advantage of association lists is that a new element can be added in constant time. Additionally, when the number of keys is very small, searching an association list may be more efficient than searching a binary search tree or hash table, because of the greater simplicity of their implementation.

Applications and software libraries
In the early development of Lisp, association lists were used to resolve references to free variables in procedures. In this application, it is convenient to augment association lists with an additional operation, that reverses the addition of a key–value pair without scanning the list for other copies of the same key. In this way, the association list can function as a stack, allowing local variables to temporarily shadow other variables with the same names, without destroying the values of those other variables.Many programming languages, including
Lisp,Scheme,OCaml, and
Haskell have functions for handling association lists in their standard libraries.

See also
Self-organizing list, a strategy for re-ordering the keys in an association list to speed up searches for frequently-accessed keys.
Property list, or plist, another associative array data structure used in Lisp (not to be confused with property lists, a file format also called plist files).


== References ==",394077,https://en.wikipedia.org/wiki/Association_list
Associative containers (C++),"In C++, associative containers refer to a group of class templates in the standard library of the C++ programming language that implement ordered associative arrays. Being templates, they can be used to store arbitrary elements, such as integers or custom classes. The following containers are defined in the current revision of the C++ standard: set, map, multiset, multimap. Each of these containers differ only on constraints placed on their elements.
The associative containers are similar to the unordered associative containers in C++ standard library, the only difference is that the unordered associative containers, as their name implies, do not order their elements.","In C++, associative containers refer to a group of class templates in the standard library of the C++ programming language that implement ordered associative arrays. Being templates, they can be used to store arbitrary elements, such as integers or custom classes. The following containers are defined in the current revision of the C++ standard: set, map, multiset, multimap. Each of these containers differ only on constraints placed on their elements.
The associative containers are similar to the unordered associative containers in C++ standard library, the only difference is that the unordered associative containers, as their name implies, do not order their elements.

Design
Characteristics
Key uniqueness: in map and set each key must be unique. multimap and multiset do not have this restriction.
Element composition: in map and multimap each element is composed from a key and a mapped value. In set and multiset each element is key; there are no mapped values.
Element ordering: elements follow a strict weak orderingAssociative containers are designed to be especially efficient in accessing its elements by their key, as opposed to sequence containers which are more efficient in accessing elements by their position. Associative containers are guaranteed to perform operations of insertion, deletion, and testing whether an element is in it, in logarithmic time – O(log n). As such, they are typically implemented using self-balancing binary search trees and support bidirectional iteration. Iterators and references are not invalidated by insert and erase operations, except for iterators and references to erased elements.The defining characteristic of associative containers is that elements are inserted in a pre-defined order, such as sorted ascending.
The associative containers can be grouped into two subsets: maps and sets. A map, sometimes referred to as a dictionary, consists of a key/value pair. The key is used to order the sequence, and the value is somehow associated with that key. For example, a map might contain keys representing every unique word in a text and values representing the number of times that word appears in the text. A set is simply an ascending container of unique elements.
As stated earlier, map and set only allow one instance of a key or element to be inserted into the container. If multiple instances of elements are required, use multimap or multiset.
Both maps and sets support bidirectional iterators. For more information on iterators, see Iterators.
While not officially part of the STL standard, hash_map and hash_set are commonly used to improve searching times. These containers store their elements as a hash table, with each table entry containing a bidirectional linked list of elements. To ensure the fastest search times (O(1)), make sure that the hashing algorithm for your elements returns evenly distributed hash values.

Performance
The asymptotic complexity of the operations that can be applied to associative containers are as follows:

Overview of functions
The containers are defined in headers named after the names of the containers, e.g. set is defined in header <set>. All containers satisfy the requirements of the Container concept, which means they have begin(), end(), size(), max_size(), empty(), and swap() methods.

Usage
The following code demonstrates how to use the map<string, int> to count occurrences of words. It uses the word as the key and the count as the value.

When executed, program lets user type a series of words separated by spaces, and a word ""end"" to signify the end of input. Then user can input a word to query how many times it has occurred in the previously entered series.
The above example also demonstrates that the operator [] inserts new objects (using the default constructor) in the map if there is not one associated with the key. So integral types are zero-initialized, strings are initialized to empty strings, etc.
The following example illustrates inserting elements into a map using the insert function and searching for a key using a map iterator and the find function:

Example shown above demonstrates the usage of some of the functions provided by map, such as insert() (place element into the map), erase() (remove element from the map), find() (check presence of the element in the container), etc.
When program is executed, six elements are inserted using the insert() function, then the first element is deleted using erase() function and the size of the map is outputted. Next, the user is prompted for a key to search for in the map. Using the iterator created earlier, the find() function searches for an element with the given key. If it finds the key, the program prints the element's value. If it doesn't find it, an iterator to the end of the map is returned and it outputs that the key could not be found. Finally all the elements in the tree are erased using clear().

Iterators
Maps may use iterators to point to specific elements in the container. An iterator can access both the key and the mapped value of an element:

Below is an example of looping through a map to display all keys and values using iterators:

For compiling above sample on GCC compiler, must use specific standard select flag.This will output the keys and values of the entire map, sorted by keys.

See also
Container (abstract data type)
Standard Template Library § Containers
Unordered associative containers C++


== References ==",33977314,https://en.wikipedia.org/wiki/Associative_containers_(C%2B%2B)
Bidirectional map,"In computer science, a bidirectional map is an associative data structure in which the (key,value){\displaystyle (key,value)} pairs form a one-to-one correspondence. Thus the binary relation is functional in each direction: each value{\displaystyle value} can also be mapped to a unique key{\displaystyle key}. A pair (a,b){\displaystyle (a,b)} thus provides a unique coupling between a{\displaystyle a} and b{\displaystyle b} so that b{\displaystyle b} can be found when a{\displaystyle a} is used as a key and a{\displaystyle a} can be found when b{\displaystyle b} is used as a key.
Mathematically, a bidirectional map can be defined a bijection f:X→Y{\displaystyle f:X\to Y} between two different sets of keys X{\displaystyle X} and Y{\displaystyle Y} of equal cardinality, thus constituting an injective and surjective function:","In computer science, a bidirectional map is an associative data structure in which the (key,value){\displaystyle (key,value)} pairs form a one-to-one correspondence. Thus the binary relation is functional in each direction: each value{\displaystyle value} can also be mapped to a unique key{\displaystyle key}. A pair (a,b){\displaystyle (a,b)} thus provides a unique coupling between a{\displaystyle a} and b{\displaystyle b} so that b{\displaystyle b} can be found when a{\displaystyle a} is used as a key and a{\displaystyle a} can be found when b{\displaystyle b} is used as a key.
Mathematically, a bidirectional map can be defined a bijection f:X→Y{\displaystyle f:X\to Y} between two different sets of keys X{\displaystyle X} and Y{\displaystyle Y} of equal cardinality, thus constituting an injective and surjective function:

External links
Boost.org
Commons.apache.org
Cablemodem.fibertel.com.ar (archived version)
Codeproject.com
BiMap in the Google Guava library
bidict (bidirectional map implementation for Python)",10070867,https://en.wikipedia.org/wiki/Bidirectional_map
Content-addressable memory,"Content-addressable memory (CAM) is a special type of computer memory used in certain very-high-speed searching applications. It is also known as associative memory or associative storage and compares input search data against a table of stored data, and returns the address of matching data.CAM is frequently used in networking devices where it speeds up forwarding information base and routing table operations. This kind of associative memory is also used in cache memory. In associative cache memory, both address and content is stored side by side. When the address matches, the corresponding content is fetched from cache memory.","Content-addressable memory (CAM) is a special type of computer memory used in certain very-high-speed searching applications. It is also known as associative memory or associative storage and compares input search data against a table of stored data, and returns the address of matching data.CAM is frequently used in networking devices where it speeds up forwarding information base and routing table operations. This kind of associative memory is also used in cache memory. In associative cache memory, both address and content is stored side by side. When the address matches, the corresponding content is fetched from cache memory.

History
Dudley Allen Buck invented the concept of content-addressable memory in 1955. Buck is credited with the idea of recognition unit.

Hardware associative array
Unlike standard computer memory, random-access memory (RAM), in which the user supplies a memory address and the RAM returns the data word stored at that address, a CAM is designed such that the user supplies a data word and the CAM searches its entire memory to see if that data word is stored anywhere in it.  If the data word is found, the CAM returns a list of one or more storage addresses where the word was found. Thus, a CAM is the hardware embodiment of what in software terms would be called an associative array.
A similar concept can be found in the data word recognition unit, as proposed by Dudley Allen Buck in 1955.

Standards
A major interface definition for CAMs and other network search engines was specified in an interoperability agreement called the Look-Aside Interface (LA-1 and LA-1B) developed by the Network Processing Forum.  Numerous devices conforming to the interoperability agreement have been produced by Integrated Device Technology, Cypress Semiconductor, IBM, Broadcom and others. On December 11, 2007, the OIF published the serial look-aside (SLA) interface agreement.

Semiconductor implementations
CAM is much faster than RAM in data search applications. There are cost disadvantages to CAM, however.  Unlike a RAM chip, which has simple storage cells, each individual memory bit in a fully parallel CAM must have its own associated comparison circuit to detect a match between the stored bit and the input bit.  Additionally, match outputs from each cell in the data word must be combined to yield a complete data word match signal.  The additional circuitry increases the physical size and manufacturing cost of the CAM chip. The extra circuitry also increases power dissipation since every comparison circuit is active on every clock cycle.  Consequently, CAM is used only in specialized applications where searching speed cannot be accomplished using a less costly method. One successful early implementation was a General Purpose Associative Processor IC and System.In the early 2000s several semiconductor companies including Cypress, IDT, Netlogic, Sibercore, and MOSAID introduced CAM products targeting networking applications. These products were labelled Network Search Engines (NSE), Network Search Accelerators (NSA), and Knowledge-based Processors (KBP) but were essentially CAM with specialized interfaces and features optimized for networking. Currently Broadcom offers several families of KBPs.

Alternative implementations
To achieve a different balance between speed, memory size and cost, some implementations emulate the function of CAM by using standard tree search or hashing designs in hardware, using hardware tricks like replication or pipelining to speed up effective performance. These designs are often used in routers. The Lulea algorithm is an efficient implementation for longest prefix match searches as required in internet routing tables.

Ternary CAMs
Binary CAM is the simplest type of CAM and uses data search words consisting entirely of 1s and 0s.  Ternary CAM (TCAM) allows a third matching state of X or don't care for one or more bits in the stored word, thus adding flexibility to the search. For example, a stored word of 10XX0 in a ternary CAM will match any of the four search words 10000, 10010, 10100, or 10110.  The added search flexibility comes at an additional cost over binary CAM as the internal memory cell must now encode three possible states instead of the two for the binary CAM.  This additional state is typically implemented by adding a mask bit (care or don't care bit) to every memory cell.
In 2013, IBM  fabricated a nonvolatile TCAM using 2-transistor/2-resistive-storage (2T-2R) cells. A design of TCAM using hybrid Ferroelectric FeFET was recently published by a group of International scientists.

Example applications
Content-addressable memory is often used in computer networking devices. For example, when a network switch receives a data frame from one of its ports, it updates an internal table with the frame's source MAC address and the port it was received on. It then looks up the destination MAC address in the table to determine what port the frame needs to be forwarded to, and sends it out on that port. The MAC address table is usually implemented with a binary CAM so the destination port can be found very quickly, reducing the switch's latency.
Ternary CAMs are often used in network routers, where each address has two parts: the network prefix, which can vary in size depending on the subnet configuration, and the host address, which occupies the remaining bits. Each subnet has a network mask that specifies which bits of the address are the network prefix and which bits are the host address. Routing is done by consulting a routing table maintained by the router which contains each known destination network prefix, the associated network mask, and the information needed to route packets to that destination. In a simple software implementation, the router compares the destination address of the packet to be routed with each entry in the routing table, performing a bitwise AND with the network mask and comparing it with the network prefix. If they are equal, the corresponding routing information is used to forward the packet. Using a ternary CAM for the routing table makes the lookup process very efficient. The addresses are stored using don't care for the host part of the address, so looking up the destination address in the CAM immediately retrieves the correct routing entry; both the masking and comparison are done by the CAM hardware. This works if (a) the entries are stored in order of decreasing network mask length, and (b) the hardware returns only the first matching entry; thus, the match with the longest network mask (longest prefix match) is used.Other CAM applications include:

Fully associative cache controllers and translation lookaside buffers
Database engines
Data compression hardware
Artificial neural networks
Intrusion prevention systems
Network processors
Several custom computers, like the Goodyear STARAN, were built to implement CAM.

See also
Content-addressable network
Content-addressable parallel processor
Content-addressable storage, or file system
Sparse distributed memory
Tuple space

References
Bibliography
Anargyros Krikelis, Charles C. Weems (editors) (1997). Associative Processing and Processors, IEEE Computer Science Press. ISBN 0-8186-7661-2
US 6823434, Hannum et al., ""System and method for resetting and initializing a fully associative array to a known state at power on or through machine specific state"", published 2004 
Pagiamtis, K.; Sheikholeslami, A. (2006). ""Content-Addressable Memory (CAM) Circuits and Architectures: A Tutorial and Survey"" (PDF). IEEE Journal of Solid-State Circuits. 41 (3): 712–727. Bibcode:2006IJSSC..41..712P. doi:10.1109/JSSC.2005.864128. S2CID 11178331.
Stormon, C.D.;   Troullinos, N.B.;   Saleh, E.M.;   Chavan, A.V.;   Brule, M.R.;   Oldfield, J.V.; A general-purpose CMOS associative processor IC and system, Coherent Research Inc., East Syracuse, NY, USA, IEEE Micro, Dec. 1992, Volume: 12 Issue:6.

External links
CAM Primer
Arithmetic Processing using Associative memory",327799,https://en.wikipedia.org/wiki/Content-addressable_memory
Content-addressable parallel processor,"A content-addressable parallel processor (CAPP) also known as associative processor is a type of parallel processor which uses content-addressing memory (CAM) principles. CAPPs are intended for bulk computation. The syntactic structure of their computing algorithm are simple, whereas the number of concurrent processes may be very large, only limited by the number of locations in the CAM. The best-known CAPP may be STARAN, completed in 1972; several similar systems were later built in other countries.
A CAPP is distinctly different from a Von Neumann architecture or classical computer that stores data in cells addressed individually by numeric address. The CAPP executes a stream of instructions that address memory based on the content (stored values) of the memory cells.  As a parallel processor, it acts on all of the cells containing that content at once. The content of all matching cells can be changed simultaneously.
A typical CAPP might consist of an array of content-addressable memory of fixed word length, a sequential instruction store, and a general purpose computer of the Von Neumann architecture that is used to interface peripherals.","A content-addressable parallel processor (CAPP) also known as associative processor is a type of parallel processor which uses content-addressing memory (CAM) principles. CAPPs are intended for bulk computation. The syntactic structure of their computing algorithm are simple, whereas the number of concurrent processes may be very large, only limited by the number of locations in the CAM. The best-known CAPP may be STARAN, completed in 1972; several similar systems were later built in other countries.
A CAPP is distinctly different from a Von Neumann architecture or classical computer that stores data in cells addressed individually by numeric address. The CAPP executes a stream of instructions that address memory based on the content (stored values) of the memory cells.  As a parallel processor, it acts on all of the cells containing that content at once. The content of all matching cells can be changed simultaneously.
A typical CAPP might consist of an array of content-addressable memory of fixed word length, a sequential instruction store, and a general purpose computer of the Von Neumann architecture that is used to interface peripherals.

References
Kent, Allen (1990), Encyclopedia of microcomputers: Volume 4 - Computer-Related Applications: Computational Linguistics to dBase, New York: Dekker, pp. 138–139, ISBN 0-8247-2703-7
Foster, Caxton C (1976), Content Addressable Parallel Processors, Van Nostrand Reinhold, ISBN 0-442-22433-8",18359343,https://en.wikipedia.org/wiki/Content-addressable_parallel_processor
Content-addressable storage,"Content-addressable storage (CAS), also referred to as content-addressed storage or fixed-content storage, is a way to store information so it can be retrieved based on its content, not its name or location. It has been used for high-speed storage and retrieval of fixed content, such as documents stored for compliance with government regulations. Content-addressable storage is similar to content-addressable memory.
CAS systems work by passing the content of the file through a cryptographic hash function to generate a unique key, the ""content address"". The file system's directory stores these addresses and a pointer to the physical storage of the content. Because an attempt to store the same file will generate the same key, CAS systems ensure that the files within them are unique, and because changing the file will result in a new key, CAS systems provide assurance that the file is unchanged.
CAS became a significant market during the 2000s, especially after the introduction of the 2002 Sarbanes–Oxley Act in the United States which required the storage of enormous numbers of documents for long periods and retrieved only rarely. Ever-increasing performance of traditional file systems and new software systems have eroded the value of legacy CAS systems, which have become increasingly rare after roughly 2018. However, the principles of content addressability continue to be of great interest to computer scientists, and form the core of numerous emerging technologies, such as peer-to-peer file sharing, cryptocurrencies, and distributed computing.","Content-addressable storage (CAS), also referred to as content-addressed storage or fixed-content storage, is a way to store information so it can be retrieved based on its content, not its name or location. It has been used for high-speed storage and retrieval of fixed content, such as documents stored for compliance with government regulations. Content-addressable storage is similar to content-addressable memory.
CAS systems work by passing the content of the file through a cryptographic hash function to generate a unique key, the ""content address"". The file system's directory stores these addresses and a pointer to the physical storage of the content. Because an attempt to store the same file will generate the same key, CAS systems ensure that the files within them are unique, and because changing the file will result in a new key, CAS systems provide assurance that the file is unchanged.
CAS became a significant market during the 2000s, especially after the introduction of the 2002 Sarbanes–Oxley Act in the United States which required the storage of enormous numbers of documents for long periods and retrieved only rarely. Ever-increasing performance of traditional file systems and new software systems have eroded the value of legacy CAS systems, which have become increasingly rare after roughly 2018. However, the principles of content addressability continue to be of great interest to computer scientists, and form the core of numerous emerging technologies, such as peer-to-peer file sharing, cryptocurrencies, and distributed computing.

Description
Location-based approaches
Traditional file systems generally track files based on their filename. On random-access media like a floppy disk, this is accomplished using a directory that consists of some sort of list of filenames and pointers to the data. The pointers refer to a physical location on the disk, normally using disk sectors. On more modern systems and larger formats like hard drives, the directory is itself split into many subdirectories, each tracking a subset of the overall collection of files. Subdirectories are themselves represented as files in a parent directory, producing a hierarchy or tree-like organization. The series of directories leading to a particular file is known as a ""path"".In the context of CAS, these traditional approaches are referred to as ""location-addressed"", as each file is represented by a list of one or more locations, the path and filename, on the physical storage. In these systems, the same file with two different names will be stored as two files on disk and thus have two addresses. The same is true if the same file, even with the same name, is stored in more than one location in the directory hierarchy. This makes them less than ideal for a digital archive, where any unique information should only be stored once.As the concept of the hierarchical directory became more common in operating systems especially during the late 1980s, this sort of access pattern began to be used by entirely unrelated systems. For instance, the World Wide Web uses a similar pathname/filename-like system known as the URL to point to documents. The same document on another web server has a different URL in spite of being identical content. Likewise, if an existing location changes in any way, if the filename changes or the server moves to a new domain name service name, the document is no longer accessible. This leads to the common problem of link rot.

CAS and FCS
Although location-based storage is widely used in many fields, this was not always the case. Previously, the most common way to retrieve data from a large collection was to use some sort of identifier based on the content of the document. For instance, the ISBN system is used to generate a unique number for every book. If one performs a web search for ""ISBN 0465048994"", one will be provided with a list of locations for the book Why Information Grows on the topic of information storage. Although many locations will be returned, they all refer to the same work, and the user can then pick whichever location is most appropriate. Additionally, if any one of these locations changes or disappears, the content can be found at any of the other locations.CAS systems attempt to produce ISBN like results automatically and on any document. They do this by using a cryptographic hash function on the data of the document to produce what is sometimes known as a ""key"" or ""fingerprint"". This key is strongly tied to the exact content of the document, adding a single space at the end of the file, for instance, will produce a different key. In a CAS system, the directory does not map filenames onto locations, but uses the keys instead.This provides several benefits. For one, when a file is sent to the CAS for storage, the hash function will produce a key and then check to see if that key already exists in the directory. If it does, the file is not stored as the one already in storage is identical. This allows CAS systems to easily avoid duplicate data. Additionally, as the key is based on the content of the file, retrieving a document with a given key ensures that the stored file has not been changed. The downside to this approach is that any changes to the document produces a different key, which makes CAS systems unsuitable for files that are often edited. For all of these reasons, CAS systems are normally used for archives of largely static documents, and are sometimes known as ""fixed content storage"" (FCS).Because the keys are not human-readable, CAS systems implement a second type of directory that stores metadata that will help users find a document. These almost always include a filename, allowing the classic name-based retrieval to be used. But the directory will also include fields for common identification systems like ISBN or ISSN codes, user-provided keywords, time and date stamps, and full-text search indexes. Users can search these directories and retrieve a key, which can then be used to retrieve the actual document.Using a CAS is very similar to using a web search engine. The primary difference is that a web search is generally performed on a topic basis using an internal algorithm that finds ""related"" content and then produces a list of locations. The results may be a list of the identical content in multiple locations. In a CAS, more than one document may be returned for a given search, but each of those documents will be unique and presented only once.
Another advantage to CAS is that the physical location in storage is not part of the lookup system. If, for instance, a library's card catalog stated a book could be found on ""shelf 43, bin 10"", if the library is re-arranged the entire catalog has to be updated. In contrast, the ISBN will not change and the book can be found by looking for the shelf with those numbers. In the computer setting, a file in the DOS filesystem at the path A:\myfiles\textfile.txt points to the physical storage of the file in the myfiles subdirectory. This file disappears if the floppy is moved to the B: drive, and even moving its location within the disk hierarchy requires the user-facing directories to be updated. In CAS, only the internal mapping from key to physical location changes, and this exists in only one place and can be designed for efficient updating. This allows files to be moved among storage devices, and even across media, without requiring any changes to the retrieval.
For data that changes frequently, CAS is not as efficient as location-based addressing. In these cases, the CAS device would need to continually recompute the address of data as it was changed. This would result in multiple copies of the entire almost-identical document being stored, the problem that CAS attempts to avoid. Additionally, the user-facing directories would have to be continually updated with these ""new"" files, which would become polluted by many similar documents that would make searching more difficult. In contrast, updating a file in a location-based system is highly optimized, only the internal list of sectors has to be changed and many years of tuning have been applied to this operation.
Because CAS is used primarily for archiving, file deletion is often tightly controlled or even impossible under user control. In contrast, automatic deletion is a common feature, removing all files older than some legally defined requirement, say ten years.

In distributed computing
The simplest way to implement a CAS system is to store all of the files within a typical database to which clients connect to add, query, and retrieve files. However, the unique properties of content addressability mean that the paradigm is well suited for computer systems in which multiple hosts collaboratively manage files with no central authority, such as distributed file sharing systems, in which the physical location of a hosted file can change rapidly in response to changes in network topology, while the exact content of the files to be retrieved are of more importance to users than their current physical location. In a distributed system, content hashes are often used for quick network-wide searches for specific files, or to quickly see which data in a given file has been changed and must be propagated to other members of the network with minimal bandwidth usage. In these systems, content addressability allows highly variable network topology to be abstracted away from users who wish to access data, compared to systems like the World Wide Web, in which a consistent location of a file or service is key to easy use.

Content-addressable networks
History
A hardware device called the Content Addressable File Store (CAFS) was developed by International Computers Limited (ICL) in the late 1960s and put into use by British Telecom in the early 1970s for telephone directory lookups. The user-accessible search functionality was maintained by the disk controller with a high-level application programming interface (API) so users could send queries into what appeared to be a black box that returned documents. The advantage was that no information had to be exchanged with the host computer while the disk performed the search.
Paul Carpentier and Jan van Riel coined the term CAS while working at a company called FilePool in the late 1990s. FilePool was purchased by EMC Corporation in 2001 and was released the next year as Centera. The timing was perfect; the introduction of the Sarbanes–Oxley Act in 2002 required companies to store huge amounts of documentation for extended periods and required them to do so in a fashion that ensured they were not edited after-the-fact.A number of similar products soon appeared from other large-system vendors. In mid-2004, the industry group SNIA began working with a number of CAS providers to create standard behavior and interoperability guidelines for CAS systems.In addition to CAS, a number of similar products emerged that added CAS-like capabilities to existing products; notable among these was IBM Tivoli Storage Manager. The rise of cloud computing and the associated elastic cloud storage systems like Amazon S3 further diluted the value of dedicated CAS systems. Dell purchased EMC in 2016 and stopped sales of the original Centera in 2018 in favor of their elastic storage product.CAS was not associated with peer-to-peer applications until the 2000s, when rapidly proliferating Internet access in homes and businesses led to a large number of computer users who wanted to swap files, originally doing so on centrally managed services like Napster. However, an injunction against Napster prompted the independent development of file-sharing services such as BitTorrent, which could not be centrally shut down. In order to function without a central federating server, these services rely heavily on CAS to enforce the faithful copying and easy querying of unique files. At the same time, the growth of the open-source software movement in the 2000s led to the rapid proliferation of CAS-based services such as Git, a version control system that uses numerous cryptographic functions such as Merkle trees to enforce data integrity between users and allow for multiple versions of files with minimal disk and network usage. Around this time, individual users of public-key cryptography used CAS to store their public keys on systems such as key servers.
The rise of mobile computing and high capacity mobile broadband networks in the 2010s, coupled with increasing reliance on web applications for everyday computing tasks, strained the existing location-addressed client–server model commonplace among Internet services, leading to an accelerated pace of link rot and an increased reliance on centralized cloud hosting. Furthermore, growing concerns about the centralization of computing power in the hands of large technology companies, potential monopoly power abuses, and privacy concerns led to a number of projects created with the goal of creating more decentralized systems. Bitcoin uses CAS and public/private key pairs to manage wallet addresses, as do most other cryptocurrencies. IPFS uses CAS to identify and address communally hosted files on its network. Numerous other peer-to-peer systems designed to run on smartphones, which often access the Internet from varying locations, utilize CAS to store and access user data for both convenience and data privacy purposes, such as secure instant messaging.

Implementations
Proprietary
The Centera CAS system consists of a series of networked nodes (typically large servers running Linux), divided between storage nodes and access nodes.  The access nodes maintain a synchronized directory of content addresses, and the corresponding storage node where each address can be found.  When a new data element, or blob, is added, the device calculates a hash of the content and returns this hash as the blob's content address. As mentioned above, the hash is searched to verify that identical content is not already present.  If the content already exists, the device does not need to perform any additional steps; the content address already points to the proper content.  Otherwise, the data is passed off to a storage node and written to the physical media.
When a content address is provided to the device, it first queries the directory for the physical location of the specified content address.  The information is then retrieved from a storage node, and the actual hash of the data recomputed and verified.  Once this is complete, the device can supply the requested data to the client.  Within the Centera system, each content address actually represents a number of distinct data blobs, as well as optional metadata.  Whenever a client adds an additional blob to an existing content block, the system recomputes the content address.
To provide additional data security, the Centera access nodes, when no read or write operation is in progress, constantly communicate with the storage nodes, checking the presence of at least two copies of each blob as well as their integrity. Additionally, they can be configured to exchange data with a different, e.g., off-site, Centera system, thereby strengthening the precautions against accidental data loss.
IBM has another flavor of CAS which can be software-based, Tivoli Storage manager 5.3, or hardware-based, the IBM DR550.  The architecture is different in that it is based on hierarchical storage management (HSM) design which provides some additional flexibility such as being able to support not only WORM disk but WORM tape and the migration of data from WORM disk to WORM tape and vice versa.  This provides for additional flexibility in disaster recovery situations as well as the ability to reduce storage costs by moving data off the disk to tape.
Another typical implementation is iCAS from iTernity. The concept of iCAS is based on containers. Each container is addressed by its hash value. A container holds different numbers of fixed content documents. The container is not changeable, and the hash value is fixed after the write process.

Open-source
Venti: One of the first content-addressed storage servers, originally developed for Plan 9 from Bell Labs and is now also available for Unix-like systems as part of Plan 9 from User Space.The first step towards an open-source CAS+ implementation is Twisted Storage.
Tahoe Least-Authority File Store: an open source implementation of CAS.
Git: a userspace CAS filesystem. Git is primarily used as a source code control system.
git-annex: a distributed file synchronization system that uses content-addressable storage for files it manages. It relies on Git and symbolic links to index their filesystem location.
Project Honeycomb: an open-source API for CAS systems.
XAM: an interface developed under the auspices of the Storage Networking Industry Association. It provides a standard interface for archiving CAS (and CAS like) products and projects.
Perkeep: a 2011 project to bring the advantages of content-addressable storage ""to the masses"". It is intended to be used for a wide variety of use cases, including distributed backup, a snapshotted-by-default, a version-controlled filesystem, and decentralized, permission-controlled filesharing.
Irmin: an OCaml ""library for persistent stores with built-in snapshot, branching and reverting mechanisms""; the same design principles as Git.
Cassette: an open-source CAS implementation for C#/.NET.
Arvados Keep: an open-source content-addressable distributed storage system. It is designed for large-scale, computationally intensive data science work such as storing and processing genomic data.
Infinit: a content-addressable and decentralized (peer-to-peer) storage platform that was acquired by Docker Inc.
InterPlanetary File System (IPFS): a content-addressable, peer-to-peer hypermedia distribution protocol.
casync: a Linux software utility by Lennart Poettering to distribute frequently-updated file system images over the Internet.

See also
Content Addressable File Store
Content-centric networking / Named data networking
Data Defined Storage
Write Once Read Many

References
External links
Fast, Inexpensive Content-Addressed Storage in Foundation
Venti: a new approach to archival storage",4062863,https://en.wikipedia.org/wiki/Content-addressable_storage
Fusion tree,"In computer science, a fusion tree is a type of tree data structure that implements an associative array on w-bit integers on a finite universe, where each of the input integers has size less than 2w and is non-negative. When operating on a collection of n key–value pairs, it uses O(n) space and performs searches in O(logw n) time, which is asymptotically faster than a traditional self-balancing binary search tree, and also better than the van Emde Boas tree for large values of w. It achieves this speed by using certain constant-time operations that can be done on a machine word. Fusion trees were invented in 1990 by Michael Fredman and Dan Willard.Several advances have been made since Fredman and Willard's original 1990 paper. In 1999 it was shown how to implement fusion trees under a model of computation in which all of the underlying operations of the algorithm belong to AC0, a model of circuit complexity that allows addition and bitwise Boolean operations but does not allow the multiplication operations used in the original fusion tree algorithm. A dynamic version of fusion trees using hash tables was proposed in 1996 which matched the original structure's O(logw n) runtime in expectation. Another dynamic version using exponential tree was proposed in 2007 which yields worst-case runtimes of O(logw n + log log n) per operation. Finally, it was shown that dynamic fusion trees can perform each operation in O(logw n) time deterministically.This data structure implements add key, remove key, search key, and predecessor (next smaller value) and successor (next larger value) search operations for a given key. The partial result of most significant bit locator in constant time has also helped further research. Fusion trees utilize word-level parallelism to be efficient, performing computation on several small integers, stored in a single machine word, simultaneously to reduce the number of total operations.","In computer science, a fusion tree is a type of tree data structure that implements an associative array on w-bit integers on a finite universe, where each of the input integers has size less than 2w and is non-negative. When operating on a collection of n key–value pairs, it uses O(n) space and performs searches in O(logw n) time, which is asymptotically faster than a traditional self-balancing binary search tree, and also better than the van Emde Boas tree for large values of w. It achieves this speed by using certain constant-time operations that can be done on a machine word. Fusion trees were invented in 1990 by Michael Fredman and Dan Willard.Several advances have been made since Fredman and Willard's original 1990 paper. In 1999 it was shown how to implement fusion trees under a model of computation in which all of the underlying operations of the algorithm belong to AC0, a model of circuit complexity that allows addition and bitwise Boolean operations but does not allow the multiplication operations used in the original fusion tree algorithm. A dynamic version of fusion trees using hash tables was proposed in 1996 which matched the original structure's O(logw n) runtime in expectation. Another dynamic version using exponential tree was proposed in 2007 which yields worst-case runtimes of O(logw n + log log n) per operation. Finally, it was shown that dynamic fusion trees can perform each operation in O(logw n) time deterministically.This data structure implements add key, remove key, search key, and predecessor (next smaller value) and successor (next larger value) search operations for a given key. The partial result of most significant bit locator in constant time has also helped further research. Fusion trees utilize word-level parallelism to be efficient, performing computation on several small integers, stored in a single machine word, simultaneously to reduce the number of total operations.

How it works
A fusion tree is essentially a B-tree with branching factor of w1/5 (any small exponent is also possible as it will not have a great impact on the height of the tree), which gives it a height of O(logw n). To achieve the desired runtimes for updates and queries, the fusion tree must be able to search a node containing up to w1/5 keys in constant time. This is done by compressing (""sketching"") the keys so that all can fit into one machine word, which in turn allows comparisons to be done in parallel. So, a series of computations involving sketching, parallel comparison and most significant bit index locator, help reach the required solution.

Sketching
Sketching is the method by which each w-bit key at a node containing k keys is compressed into only k − 1 bits. Each key x may be thought of as a path in the full binary tree of height w starting at the root and ending at the leaf corresponding to x. This path can be processed by recursively searching the left child of i if the ith bit is 0, and the right child if it is 1, generally, until all bits are scanned. To distinguish two paths, it suffices to look at their branching point (the first bit where any two keys differ). As there are a maximum of k keys, there will not be more than k-1  branching points, which means that no more than k-1 bits are required to identify a key. And hence, no sketch will have more than k-1 bits.

An important property of the sketch function is that it preserves the order of the keys. That is, sketch(x) < sketch(y) for any two keys x < y. So, for the entire range of keys, sketch(x0)<sketch(x1)<...<sketch(xk-1) because if the binary tree like path is followed the nodes will be ordered in such a manner that x0<x1<...<xk-1.

Approximating the sketch
If the locations of the sketch bits are b1 < b2 < ··· < br, then the sketch of the key xw-1···x1x0 is the r-bit integer xbrxbr−1⋯xb1{\displaystyle x_{b_{r}}x_{b_{r-1}}\cdots x_{b_{1}}}.
With only standard word operations, such as those of the C programming language, it is difficult to directly compute the perfect sketch of a key in constant time. Instead, the sketch bits can be packed into a range of size at most r4, using bitwise AND and multiplication, called the approximate sketch, which does have all the important bits but also some additional useless bits spread out in a predictable pattern. The bitwise AND operation serves as a mask to remove all these non-sketch bits from the key, while the multiplication shifts the sketch bits into a small range. Like the ""perfect"" sketch, the approximate sketch also preserves the order of the keys and means that sketch(x0)<sketch(x1)<...<sketch(xk-1).
Some preprocessing is needed to determine the correct multiplication constant. Each sketch bit in location bi will get shifted to bi + mi via a multiplication by m = ∑i=1r{\displaystyle \textstyle \sum _{i=1}^{r}} 2mi. For the approximate sketch to work, the following three properties must hold:

bi + mj are distinct for all pairs (i, j). This will ensure that the sketch bits are uncorrupted by the multiplication.
bi + mi is a strictly increasing function of i. That is, the order of the sketch bits is preserved even in x'.m.
(br + mr) - (b1 + m1) ≤ r4. That is, the sketch bits are packed into a range of size at most r4, where r ≤ O(w1/5).An inductive argument shows how the mi can be constructed. Let m1 = w − b1. Suppose that 1 < t ≤ r and that m1, m2... mt-1 have already been chosen. Then pick the smallest integer mt such that both properties (1) and (2) are satisfied. Property (1) requires that mt ≠ bi − bj + ml for all 1 ≤ i, j ≤ r and 1 ≤ l ≤ t-1. Thus, there are less than tr2 ≤ r3 values that mt must avoid. Since mt is chosen to be minimal, (bt + mt) ≤ (bt-1 + mt-1) + r3. This implies Property (3).
The approximate sketch is thus computed as follows:

Mask out all but the sketch bits with a bitwise AND between x and ∑i=0r−12bi{\displaystyle \sum _{i=0}^{r-1}2^{b_{i}}}.
Multiply the key by the predetermined constant m as calculated above. This operation actually requires two machine words, but this can still be done in constant time.
Mask out all but the shifted sketch bits. These are now contained in a contiguous block of at most r4 < w4/5 bits.

Parallel comparison
The purpose of the compression achieved by sketching is to allow all of the keys to be stored in one w-bit word. Let the node sketch of a node be the bit string

1sketch(x1)1sketch(x2)...1sketch(xk)Here, all sketch words are clubbed together in one string by prepending a set bit to each of them. We can assume that the sketch function uses exactly b ≤ r4 bits. Then each block uses 1 + b ≤ w4/5 bits, and since k ≤ w1/5, the total number of bits in the node sketch is at most w.
A brief notational aside: for a bit string s and nonnegative integer m, let sm denote the concatenation of s to itself m times. If t is also a bit string st denotes the concatenation of t to s.
The node sketch makes it possible to search the keys for any b-bit integer y. Let z = (0y)k, which can be computed in constant time (multiply y by the constant (0b1)k), to make it as long as the node sketch such that each word in the node sketch can be compared with the query integer y in one operation, demonstrating word-level parallelism. If y were 5 bits long, it would be multiplied by 000001....000001 to get sketch(y)k. The difference between sketch(xi) and 0y results in the leading bit for each block to be 1, if and only if sketch(y) ≤{\displaystyle \leq } sketch(xi). We can thus compute the smallest index i such that sketch(xi) ≥ y as follows:

Subtract z from the node sketch.
Take the bitwise AND of the difference and the constant (10b)k. This clears all but the leading bit of each block.
Find the most significant bit of the result, to identify the exact index of transition from elements with sketch smaller than the query sketch to those greater than the query sketch.
Compute i, the rank of the sketch, using the fact that the leading bit of the i-th block has index i(b+1).

Desketching
For an arbitrary query q, parallel comparison computes the index i such that

sketch(xi-1) ≤ sketch(q) ≤ sketch(xi)Unfortunately, this does give the exact predecessor or successor of q, because the location of the sketch of q among the sketches of all the values may not be the same as the location of q in all the actual values. What is true is that, among all of the keys, either xi-1 or xi has the longest common prefix with q. This is because any key y with a longer common prefix with q would also have more sketch bits in common with q, and thus sketch(y) would be closer to sketch(q) than any sketch(xj).
The length longest common prefix between two w-bit integers a and b can be computed in constant time by finding the most significant bit of the bitwise XOR between a and b. This can then be used to mask out all but the longest common prefix.
Note that p identifies exactly where q branches off from the set of keys. If the next bit of q is 0, then the successor of q is contained in the p1 subtree, and if the next bit of q is 1, then the predecessor of q is contained in the p0 subtree. This suggests the following algorithm for determining the exact location of q:

Use parallel comparison to find the index i such that sketch(xi-1) ≤ sketch(q) ≤ sketch(xi).
Compute the longest common prefix p of q and either xi-1 or xi (taking the longer of the two).
Let l-1 be the length of the longest common prefix p.
If the l-th bit of q is 0, let e = p10w-l. Use parallel comparison to search for the successor of sketch(e). This is the actual predecessor of q.
If the l-th bit of q is 1, let e = p01w-l. Use parallel comparison to search for the predecessor of sketch(e). This is the actual successor of q.
Once either the predecessor or successor of q is found, the exact position of q among the set of keys is determined.

Fusion hashing
An application of fusion trees to hash tables was given by Willard, who describes a data structure for hashing in which an outer-level hash table with hash chaining is combined with a fusion tree representing each hash chain.
In hash chaining, in a hash table with a constant load factor, the average size of a chain is constant, but additionally with high probability all chains have size O(log n / log log n), where n is the number of hashed items.
This chain size is small enough that a fusion tree can handle searches and updates within it in constant time per operation. Therefore, the time for all operations in the data structure is constant with high probability.
More precisely, with this data structure, for every inverse-quasipolynomial probability p(n) = exp((log n)O(1)), there is a constant C such that the probability that there exists an operation that exceeds time C is at most p(n).

Computational Model and Necessary Assumptions
The computational model for the Fusion Tree algorithm is a Word RAM with a specific instruction set, including arithmetic instructions - addition, subtraction and multiplication (all performed
modulo 2w) and Boolean operations - bitwise AND, NOT etc. A double-precision multiplication instruction is also included. It has been shown that removal of the latter instruction makes it impossible to sort faster than O(n log n), unless it is permitted to use memory space of nearly 2w words (in constrast to linear space used by Fusion Trees), or include other instructions instead.

References
External links
MIT CS 6.897: Advanced Data Structures: Lecture 4, Fusion Trees, Prof. Erik Demaine (Spring 2003)
MIT CS 6.897: Advanced Data Structures: Lecture 5, More fusion trees; self-organizing data structures, move-to-front, static optimality, Prof. Erik Demaine (Spring 2003)
MIT CS 6.851: Advanced Data Structures: Lecture 13, Fusion Tree notes, Prof. Erik Demaine (Spring 2007)
MIT CS 6.851: Advanced Data Structures: Lecture 12, Fusion Tree notes, Prof. Erik Demaine (Spring 2012)",1051942,https://en.wikipedia.org/wiki/Fusion_tree
Ctrie,"A concurrent hash-trie or Ctrie is a concurrent thread-safe lock-free implementation of a hash array mapped trie. It is used to implement the concurrent map abstraction. It has particularly scalable concurrent insert and remove operations and is memory-efficient. It is the first known concurrent data-structure that supports O(1), atomic, lock-free snapshots.","A concurrent hash-trie or Ctrie is a concurrent thread-safe lock-free implementation of a hash array mapped trie. It is used to implement the concurrent map abstraction. It has particularly scalable concurrent insert and remove operations and is memory-efficient. It is the first known concurrent data-structure that supports O(1), atomic, lock-free snapshots.

Operation
The Ctrie data structure is a non-blocking concurrent hash array mapped trie based on single-word compare-and-swap instructions in a shared-memory system. It supports concurrent lookup, insert and remove operations. Just like the hash array mapped trie, it uses the entire 32-bit space for hash values thus having low risk of hashcode collisions. Each node may have up to 32 sub-nodes, but to conserve memory, the list of sub-nodes is represented by a 32-bit bitmap where each bit indicates the presence of a branch, followed by a non-sparse array (of pointers to sub-nodes) whose length equals the Hamming weight of the bitmap.
Keys are inserted by doing an atomic compare-and-swap operation on the node which needs to be modified. To ensure that updates are done independently and in a proper order, a special indirection node (an I-node) is inserted between each regular node and its subtries.

The figure above illustrates the Ctrie insert operation. Trie A is empty - an atomic CAS instruction is used to swap the old node C1 with the new version of C1 which has the new key k1. If the CAS is not successful, the operation is restarted. If the CAS is successful, we obtain the trie B. This procedure is repeated when a new key k2 is added (trie C). If two hashcodes of the keys in the Ctrie collide as is the case with k2 and k3, the Ctrie must be extended with at least one more level - trie D has a new indirection node I2 with a new node C2 which holds both colliding keys. Further CAS instructions are done on the contents of the indirection nodes I1 and I2 - such CAS instructions can be done independently of each other, thus enabling concurrent updates with less contention.
The Ctrie is defined by the pointer to the root indirection node (or a root I-node). The following types of nodes are defined for the Ctrie:

structure INode {
    main: CNode
}
 
structure CNode {
    bmp: integer
    array: Branch[2^W]
}
 
Branch: INode | SNode
 
structure SNode {
    k: KeyType
    v: ValueType
}

A C-node is a branching node. It typically contains up to 32 branches, so W above is 5. Each branch may either be a key-value pair (represented with an S-node) or another I-node. To avoid wasting 32 entries in the branching array when some branches may be empty, an integer bitmap is used to denote which bits are full and which are empty. The helper method flagpos is used to inspect the relevant hashcode bits for a given level and extract the value of the bit in the bitmap to see if its set or not - denoting whether there is a branch at that position or not. If there is a bit, it also computes its position in the branch array. The formula used to do this is:

bit = bmp & (1 << ((hashcode >> level) & 0x1F))
pos = bitcount((bit - 1) & bmp)

Note that the operations treat only the I-nodes as mutable nodes - all other nodes are never changed after being created and added to the Ctrie.
Below is an illustration of the pseudocode of the insert operation:

The inserted and updated methods on nodes return new versions of the C-node with a value inserted or updated at the specified position, respectively. Note that the insert operation above is tail-recursive, so it can be rewritten as a while loop. Other operations are described in more detail in the original paper on Ctries.The data-structure has been proven to be correct - Ctrie operations have been shown to have the atomicity, linearizability and lock-freedom properties. The lookup operation can be modified to guarantee wait-freedom.

Advantages of Ctries
Ctries have been shown to be comparable in performance with concurrent skip lists, concurrent hash tables and similar data structures in terms of the lookup operation, being slightly slower than hash tables and faster than skip lists due to the lower level of indirections. However, they are far more scalable than most concurrent hash tables where the insertions are concerned. Most concurrent hash tables are bad at conserving memory - when the keys are removed from the hash table, the underlying array is not shrunk. Ctries have the property that the allocated memory is always a function of only the current number of keys in the data-structure.Ctries have logarithmic complexity bounds of the basic operations, albeit with a low constant factor due to the high branching level (usually 32).
Ctries support a lock-free, linearizable, constant-time snapshot operation, based on the insight obtained from persistent data structures. This is a breakthrough in concurrent data-structure design, since existing concurrent data-structures do not support snapshots. The snapshot operation allows implementing lock-free, linearizable iterator, size and clear operations - existing concurrent data-structures have implementations which either use global locks or are correct only given that there are no concurrent modifications to the data-structure. In particular, Ctries have an O(1) iterator creation operation, O(1) clear operation, O(1) duplicate operation and an amortized O(logn) size retrieval operation.

Problems with Ctries
Most concurrent data structures require dynamic memory allocation, and lock-free concurrent data structures rely on garbage collection on most platforms. The current implementation of the Ctrie is written for the JVM, where garbage collection is provided by the platform itself. While it's possible to keep a concurrent memory pool for the nodes shared by all instances of Ctries in an application or use reference counting to properly deallocate nodes, the only implementation so far to deal with manual memory management of nodes used in Ctries is the common-lisp implementation cl-ctrie, which implements several stop-and-copy and mark-and-sweep garbage collection techniques for persistent, memory-mapped storage. Hazard pointers are another possible solution for a correct manual management of removed nodes. Such a technique may be viable for managed environments as well, since it could lower the pressure on the GC. A Ctrie implementation in Rust makes use of hazard pointers for this purpose.

Implementations
A Ctrie implementation for Scala 2.9.x is available on GitHub. It is a mutable thread-safe implementation which ensures progress and supports lock-free, linearizable, O(1) snapshots.

A data-structure similar to Ctries has been used in ScalaSTM, a software transactional memory library for the JVM.
The Scala standard library (as of 2.13.x) includes a Ctries implementation since February 2012.
Haskell implementation is available as a package and on GitHub.
Standalone Java implementations are available on GitHub for Java 17, Java 11 and Java 8 as well for Java 6.
CL-CTRIE is a Common Lisp implementation available on GitHub.
An insert-only Ctrie variant has been used for tabling in Prolog programs.
Go implementation is available as a standalone package 
A Rust implementation  uses hazard pointers in its implementation to achieve lock-free synchronization.
Both a managed and an unmanaged C++ version of Ctrie was implemented Managed Ctrie Unmanaged Ctrie.
A Clojure implementation is also available Clojure Ctrie.

History
Ctries were first described in 2011 by Aleksandar Prokopec. To quote the author:
Ctrie is a non-blocking concurrent shared-memory hash trie based on single-word compare-and-swap instructions. Insert, lookup and remove operations modifying different parts of the hash trie can be run independent of each other and do not contend. Remove operations ensure that the unneeded memory is freed and that the trie is kept compact.
In 2012, a revised version of the Ctrie data structure was published, simplifying the data structure and introducing an optional constant-time, lock-free, atomic snapshot operation.
In 2018, the closely related Cache-Trie data structure was proposed, which augmented Ctries with an auxiliary, quiescently consistent cache data structure. This ""cache"" is a hash-table-like entity that makes a best effort to ""guess"" the appropriate node on a deeper level of the trie, and is maintained in a way such that it's as close as possible to the level where most of the trie's elements are. Cache tries were shown to have amortized expected O(1) complexity of all the basic operations.


== References ==",33676538,https://en.wikipedia.org/wiki/Ctrie
Hash array mapped trie,"A hash array mapped trie (HAMT) is an implementation of an associative array that combines the characteristics of a hash table and an array mapped trie.
It is a refined version of the more general notion of a hash tree.","A hash array mapped trie (HAMT) is an implementation of an associative array that combines the characteristics of a hash table and an array mapped trie.
It is a refined version of the more general notion of a hash tree.

Operation
A HAMT is an array mapped trie where the keys are first hashed to ensure an even distribution of keys and a constant key length.
In a typical implementation of HAMT's array mapped trie, each node contains a table with some fixed number N of slots with each slot containing either a nil pointer or a pointer to another node. N is commonly 32.  As allocating space for N pointers for each node would be expensive, each node instead contains a bitmap which is N bits long where each bit indicates the presence of a non-nil pointer. This is followed by an array of pointers equal in length to the number of ones in the bitmap (its Hamming weight).

Advantages of HAMTs
The hash array mapped trie achieves almost hash table-like speed while using memory much more economically.  Also, a hash table may have to be periodically resized, an expensive operation, whereas HAMTs grow dynamically.  Generally, HAMT performance is improved by a larger root table with some multiple of N slots; some HAMT variants allow the root to grow lazily with negligible impact on performance.

Implementation details
Implementation of a HAMT involves the use of the population count function, which counts the number of ones in the binary representation of a number.  This operation is available in many instruction set architectures, but it is available in only some high-level languages. Although population count can be implemented in software in O(1) time using a series of shift and add instructions, doing so may perform the operation an order of magnitude slower.

Implementations
The programming languages Clojure, Scala, and Frege use a persistent variant of hash array mapped tries for their native hash map type. The Haskell library ""unordered-containers"" uses the same to implement persistent map and set data structures. Another Haskell library ""stm-containers"" adapts the algorithm for use in the context of software transactional memory. A Javascript HAMT library  based on the Clojure implementation is also available.  The Rubinius implementation of Ruby includes a HAMT, mostly written in Ruby but with 3 primitives. Large maps in Erlang use a persistent HAMT representation internally since release 18.0. The Pony programming language uses a HAMT for the hash map in its persistent collections package.
The im and im-rc crates, which provide persistent collection types for the Rust programming language, use a HAMT for their persistent hash tables and hash sets.
The concurrent lock-free version of the hash trie called Ctrie is a mutable thread-safe implementation which ensures progress. The data-structure has been proven to be correct - Ctrie operations have been shown to have the atomicity, linearizability and lock-freedom properties.

See also
Judy array
Radix tree


== References ==",14514583,https://en.wikipedia.org/wiki/Hash_array_mapped_trie
Index mapping,"Index mapping (or direct addressing, or a trivial hash function) in computer science describes using an array, in which each position corresponds to a key in the universe of possible values.
The technique is most effective when the universe of keys is reasonably small, such that allocating an array with one position for every possible key is affordable.
Its effectiveness comes from the fact that an arbitrary position in an array can be examined in constant time.","Index mapping (or direct addressing, or a trivial hash function) in computer science describes using an array, in which each position corresponds to a key in the universe of possible values.
The technique is most effective when the universe of keys is reasonably small, such that allocating an array with one position for every possible key is affordable.
Its effectiveness comes from the fact that an arbitrary position in an array can be examined in constant time.

Applicable arrays
There are many practical examples of data whose valid values are restricted within a small range. A trivial hash function is a suitable choice when such data needs to act as a lookup key. Some examples include:

month in the year (1–12)
day in the month (1–31)
day of the week (1–7)
human age (0–130) – e.g. lifecover actuary tables, fixed-term mortgage
ASCII characters (0–127), encompassing common mathematical operator symbols, digits, punctuation marks, and English language alphabet

Examples
Using a trivial hash function, in a non-iterative table lookup, can eliminate conditional testing and branching completely, reducing the instruction path length of a computer program.

Avoid branching
Roger Sayle gives an example of eliminating a multiway branch caused by a switch statement:

Which can be replaced with a table lookup:

See also
Associative array
Hash table
Lookup table


== References ==",25165023,https://en.wikipedia.org/wiki/Index_mapping
Judy array,"In computer science, a Judy array is a data structure implementing a type of associative array with high performance and low memory usage. Unlike most other key-value stores, Judy arrays use no hashing, leverage compression on their keys (which may be integers or strings), and can efficiently represent sparse data; that is, they may have large ranges of unassigned indices without greatly increasing memory usage or processing time. They are designed to remain efficient even on structures with sizes in the peta-element range, with performance scaling on the order of O(log n). Roughly speaking, Judy arrays are highly optimized 256-ary radix trees.Judy trees are usually faster than AVL trees, B-trees, hash tables and skip lists because they are highly optimized to maximize usage of the CPU cache. In addition, they require no tree balancing and no hashing algorithm is used.","In computer science, a Judy array is a data structure implementing a type of associative array with high performance and low memory usage. Unlike most other key-value stores, Judy arrays use no hashing, leverage compression on their keys (which may be integers or strings), and can efficiently represent sparse data; that is, they may have large ranges of unassigned indices without greatly increasing memory usage or processing time. They are designed to remain efficient even on structures with sizes in the peta-element range, with performance scaling on the order of O(log n). Roughly speaking, Judy arrays are highly optimized 256-ary radix trees.Judy trees are usually faster than AVL trees, B-trees, hash tables and skip lists because they are highly optimized to maximize usage of the CPU cache. In addition, they require no tree balancing and no hashing algorithm is used.

History
The Judy array was invented by Douglas Baskins and named after his sister.

Benefits
Memory allocation
Judy arrays are dynamic and can grow or shrink as elements are added to, or removed from, the array. The memory used by Judy arrays is nearly proportional to the number of elements in the Judy array.

Speed
Judy arrays are designed to minimize the number of expensive cache-line fills from RAM, and so the algorithm contains much complex logic to avoid cache misses as often as possible. Due to these cache optimizations, Judy arrays are fast, especially for very large datasets. On data sets that are sequential or nearly sequential, Judy arrays can even outperform hash tables, since, unlike hash tables, the internal tree structure of Judy arrays maintains the ordering of the keys.

Drawbacks
Judy arrays are extremely complicated. The smallest implementations are thousands of lines of code. In addition, Judy arrays are optimized for machines with 64 byte cache lines, making them essentially unportable without a significant rewrite.

See also
Radix tree
Hash array mapped trie

References
External links
Main Judy arrays site
How Judy arrays work and why they are so fast
A complete technical description of Judy arrays
An independent performance comparison of Judy to Hash Tables
A compact implementation of Judy arrays in 1250 lines of C code",484569,https://en.wikipedia.org/wiki/Judy_array
Key–value database,"A key–value database, or key–value store, is a data storage paradigm designed for storing, retrieving, and managing associative arrays, and a data structure more commonly known today as a dictionary or hash table. Dictionaries contain a collection of objects, or records, which in turn have many different fields within them, each containing data. These records are stored and retrieved using a key that uniquely identifies the record, and is used to find the data within the database. 

Key–value databases work in a very different fashion from the better known relational databases (RDB). RDBs predefine the data structure in the database as a series of tables containing fields with well defined data types. Exposing the data types to the database program allows it to apply a number of optimizations. In contrast, key–value systems treat the data as a single opaque collection, which may have different fields for every record. This offers considerable flexibility and more closely follows modern concepts like object-oriented programming. Because optional values are not represented by placeholders or input parameters, as in most RDBs, key–value databases often use far less memory to store the same data, which can lead to large performance gains in certain workloads.Performance, a lack of standardization and other issues have limited key–value systems to niche uses for many years, but the rapid move to cloud computing after 2010 has led to a renaissance as part of the broader NoSQL movement. Some graph databases, such as ArangoDB, are also key–value databases internally, adding the concept of the relationships (pointers) between records as a first class data type.","A key–value database, or key–value store, is a data storage paradigm designed for storing, retrieving, and managing associative arrays, and a data structure more commonly known today as a dictionary or hash table. Dictionaries contain a collection of objects, or records, which in turn have many different fields within them, each containing data. These records are stored and retrieved using a key that uniquely identifies the record, and is used to find the data within the database. 

Key–value databases work in a very different fashion from the better known relational databases (RDB). RDBs predefine the data structure in the database as a series of tables containing fields with well defined data types. Exposing the data types to the database program allows it to apply a number of optimizations. In contrast, key–value systems treat the data as a single opaque collection, which may have different fields for every record. This offers considerable flexibility and more closely follows modern concepts like object-oriented programming. Because optional values are not represented by placeholders or input parameters, as in most RDBs, key–value databases often use far less memory to store the same data, which can lead to large performance gains in certain workloads.Performance, a lack of standardization and other issues have limited key–value systems to niche uses for many years, but the rapid move to cloud computing after 2010 has led to a renaissance as part of the broader NoSQL movement. Some graph databases, such as ArangoDB, are also key–value databases internally, adding the concept of the relationships (pointers) between records as a first class data type.

Types and examples
Key–value databases can use consistency models ranging from eventual consistency to serializability. Some support ordering of keys.
Some maintain data in memory (RAM), while others employ solid-state drives or rotating disks.
Every entity (record) is a set of key–value pairs. A key has multiple components, specified as an ordered list. The major key identifies the record and consists of the leading components of the key. The subsequent components are called minor keys. This organization is similar to a directory path specification in a file system (e.g., /Major/minor1/minor2/). The “value” part of the key–value pair is simply an uninterpreted string of bytes of arbitrary length.The Unix system provides dbm (database manager), which is a 1979 library originally written by Ken Thompson. It is also ported to Microsoft Windows, provided through programming languages such as Perl for Win32. The dbm manages associative arrays of arbitrary data by use of a single key (a primary key). Modern implementations include sdbm, GNU dbm, and Berkeley DB. Although dbm precedes the concept of a NoSQL and is rarely mentioned in modern discourse, it is used by many pieces of software.
A more recent example of a key-value database is RocksDB which is used as storage engine for other database management systems such as ArangoDB.

See also
Big data
Data analysis
Distributed data store
Document-oriented database
Multi-model database
Tuple space
Ordered Key-Value Store


== References ==",37704882,https://en.wikipedia.org/wiki/Key%E2%80%93value_database
Lookup table,"In computer science, a lookup table (LUT) is an array that replaces runtime computation with a simpler array indexing operation, in a process termed as direct addressing. The savings in processing time can be significant, because retrieving a value from memory is often faster than carrying out an ""expensive"" computation or input/output operation. The tables may be precalculated and stored in static program storage, calculated (or ""pre-fetched"") as part of a program's initialization phase (memoization), or even stored in hardware in application-specific platforms. Lookup tables are also used extensively to validate input values by matching against a list of valid (or invalid) items in an array and, in some programming languages, may include pointer functions (or offsets to labels) to process the matching input. FPGAs also make extensive use of reconfigurable, hardware-implemented, lookup tables to provide programmable hardware functionality.
LUTs differ from hash tables in a way that, to retrieve a value v{\displaystyle v} with key k{\displaystyle k}, a hash table would store the value v{\displaystyle v} in the slot h(k){\displaystyle h(k)} where h{\displaystyle h} is a hash function i.e. k{\displaystyle k} is used to compute the slot, while in the case of LUT, the value v{\displaystyle v} is stored in slot k{\displaystyle k}, thus directly addressable.: 466","In computer science, a lookup table (LUT) is an array that replaces runtime computation with a simpler array indexing operation, in a process termed as direct addressing. The savings in processing time can be significant, because retrieving a value from memory is often faster than carrying out an ""expensive"" computation or input/output operation. The tables may be precalculated and stored in static program storage, calculated (or ""pre-fetched"") as part of a program's initialization phase (memoization), or even stored in hardware in application-specific platforms. Lookup tables are also used extensively to validate input values by matching against a list of valid (or invalid) items in an array and, in some programming languages, may include pointer functions (or offsets to labels) to process the matching input. FPGAs also make extensive use of reconfigurable, hardware-implemented, lookup tables to provide programmable hardware functionality.
LUTs differ from hash tables in a way that, to retrieve a value v{\displaystyle v} with key k{\displaystyle k}, a hash table would store the value v{\displaystyle v} in the slot h(k){\displaystyle h(k)} where h{\displaystyle h} is a hash function i.e. k{\displaystyle k} is used to compute the slot, while in the case of LUT, the value v{\displaystyle v} is stored in slot k{\displaystyle k}, thus directly addressable.: 466

History
Before the advent of computers, lookup tables of values were used to speed up hand calculations of complex functions, such as in trigonometry, logarithms, and statistical density functions.In ancient (499 AD) India, Aryabhata created one of the first sine tables, which he encoded in a Sanskrit-letter-based number system. In 493 AD, Victorius of Aquitaine wrote a 98-column multiplication table which gave (in Roman numerals) the product of every number from 2 to 50 times and the rows were ""a list of numbers starting with one thousand, descending by hundreds to one hundred, then descending by tens to ten, then by ones to one, and then the fractions down to 1/144"" Modern school children are often taught to memorize ""times tables"" to avoid calculations of the most commonly used numbers (up to 9 x 9 or 12 x 12).
Early in the history of computers, input/output operations were particularly slow – even in comparison to processor speeds of the time. It made sense to reduce expensive read operations by a form of manual caching by creating either static lookup tables (embedded in the program) or dynamic prefetched arrays to contain only the most commonly occurring data items. Despite the introduction of systemwide caching that now automates this process, application level lookup tables can still improve performance for data items that rarely, if ever, change.
Lookup tables were one of the earliest functionalities implemented in computer spreadsheets, with the initial version of VisiCalc (1979) including a LOOKUP function among its original 20 functions. This has been followed by subsequent spreadsheets, such as Microsoft Excel, and complemented by specialized VLOOKUP and HLOOKUP functions to simplify lookup in a vertical or horizontal table. In Microsoft Excel the XLOOKUP function has been rolled out starting 28 August 2019.

Limitations
Although the performance of a LUT is a guaranteed O(1){\displaystyle O(1)} for a lookup operation, no two entities or values can have the same key k{\displaystyle k}. When the size of universe ∪{\displaystyle \cup }—where the keys are drawn—is large, it might be impractical or impossible to be stored in memory. Hence, in this case, a hash table would be a preferable alternative.: 468

Examples
Trivial hash function
For a trivial hash function lookup, the unsigned raw data value is used directly as an index to a one-dimensional table to extract a result. For small ranges, this can be amongst the fastest lookup, even exceeding binary search speed with zero branches and executing in constant time.

Counting bits in a series of bytes
One discrete problem that is expensive to solve on many computers is that of counting the number of bits that are set to 1 in a (binary) number, sometimes called the population function. For example, the decimal number ""37"" is ""00100101"" in binary, so it contains three bits that are set to binary ""1"".: 282 A simple example of C code, designed to count the 1 bits in a int, might look like this:: 283 

The above implementation requires 32 operations for an evaluation of a 32-bit value, which can potentially take several clock cycles due to branching. It can be ""unrolled"" into a lookup table which in turn uses trivial hash function for better performance.: 282-283 The bits array, bits_set with 256 entries is constructed by giving the number of one bits set in each possible byte value (e.g. 0x00 = 0, 0x01 = 1, 0x02 = 1, and so on). Although a runtime algorithm can be used to generate the bits_set array, it's an inefficient usage of clock cycles when the size is taken into consideration, hence a precomputed table is used—although a compile time script could be used to dynamically generate and append the table to the source file. Sum of ones in each byte of the integer can be calculated through trivial hash function lookup on each byte; thus, effectively avoiding branches resulting in considerable improvement in performance.: 284

Lookup tables in image processing
""Lookup tables (LUTs) are an excellent technique for optimizing the evaluation of functions that are expensive to compute and inexpensive to cache. ... For data requests that fall between the table's samples, an interpolation algorithm can generate reasonable approximations by averaging nearby samples.""
In data analysis applications, such as image processing, a lookup table (LUT) is used to transform the input data into a more desirable output format.  For example, a grayscale picture of the planet Saturn will be transformed into a color image to emphasize the differences in its rings.
In image processing, lookup tables are often called LUTs (or 3DLUT), and give an output value for each of a range of index values. One common LUT, called the colormap or palette, is used to determine the colors and intensity values with which a particular image will be displayed. In computed tomography,  ""windowing"" refers to a related concept for determining how to display the intensity of measured radiation.

Discussion
A classic example of reducing run-time computations using lookup tables is to obtain the result of a trigonometry calculation, such as the sine of a value. Calculating trigonometric functions can substantially slow a computing application. The same application can finish much sooner when it first precalculates the sine of a number of values, for example for each whole number of degrees (The table can be defined as static variables at compile time, reducing repeated run time costs).
When the program requires the sine of a value, it can use the lookup table to retrieve the closest sine value from a memory address, and may also interpolate to the sine of the desired value, instead of calculating by mathematical formula. Lookup tables are thus used by mathematics coprocessors in computer systems. An error in a lookup table was responsible for Intel's infamous floating-point divide bug.
Functions of a single variable (such as sine and cosine) may be implemented by a simple array.  Functions involving two or more variables require multidimensional array indexing techniques.  The latter case may thus employ a two-dimensional array of power[x][y] to replace a function to calculate xy for a limited range of x and y values. Functions that have more than one result may be implemented with lookup tables that are arrays of structures.
As mentioned, there are intermediate solutions that use tables in combination with a small amount of computation, often using interpolation. Pre-calculation combined with interpolation can produce higher accuracy for values that fall between two precomputed values. This technique requires slightly more time to be performed but can greatly enhance accuracy in applications that require it. Depending on the values being precomputed, precomputation with interpolation can also be used to shrink the lookup table size while maintaining accuracy.
While often effective, employing a lookup table may nevertheless result in a severe penalty if the computation that the LUT replaces is relatively simple. Memory retrieval time and the complexity of memory requirements can increase application operation time and system complexity relative to what would be required by straight formula computation. The possibility of polluting the cache may also become a problem. Table accesses for large tables will almost certainly cause a cache miss. This phenomenon is increasingly becoming an issue as processors outpace memory. A similar issue appears in rematerialization, a compiler optimization. In some environments, such as the Java programming language, table lookups can be even more expensive due to mandatory bounds-checking involving an additional comparison and branch for each lookup.
There are two fundamental limitations on when it is possible to construct a lookup table for a required operation. One is the amount of memory that is available: one cannot construct a lookup table larger than the space available for the table, although it is possible to construct disk-based lookup tables at the expense of lookup time. The other is the time required to compute the table values in the first instance; although this usually needs to be done only once, if it takes a prohibitively long time, it may make the use of a lookup table an inappropriate solution. As previously stated however, tables can be statically defined in many cases.

Computing sines
Most computers only perform basic arithmetic operations and cannot directly calculate the sine of a given value. Instead, they use the CORDIC algorithm or a complex formula such as the following Taylor series to compute the value of sine to a high degree of precision:: 5 
sin⁡(x)≈x−x36+x5120−x75040{\displaystyle \operatorname {sin} (x)\approx x-{\frac {x^{3}}{6}}+{\frac {x^{5}}{120}}-{\frac {x^{7}}{5040}}} (for x close to 0)However, this can be expensive to compute, especially on slow processors, and there are many applications, particularly in traditional computer graphics, that need to compute many thousands of sine values every second. A common solution is to initially compute the sine of many evenly distributed values, and then to find the sine of x we choose the sine of the value closest to x through array indexing operation. This will be close to the correct value because sine is a continuous function with a bounded rate of change.: 6  For example:: 545–548 

Unfortunately, the table requires quite a bit of space: if IEEE double-precision floating-point numbers are used, over 16,000 bytes would be required. We can use fewer samples, but then our precision will significantly worsen. One good solution is linear interpolation, which draws a line between the two points in the table on either side of the value and locates the answer on that line. This is still quick to compute, and much more accurate for smooth functions such as the sine function. Here is an example using linear interpolation:

Linear interpolation provides for an interpolated function that is continuous, but will not, in general, have continuous derivatives.  For smoother interpolation of table lookup that is continuous and has continuous first derivative, one should use the cubic Hermite spline.
When using interpolation, the size of the lookup table can be reduced by using nonuniform sampling, which means that where the function is close to straight, we use few sample points, while where it changes value quickly we use more sample points to keep the approximation close to the real curve. For more information, see interpolation.

Other usages of lookup tables
Caches
Storage caches (including disk caches for files, or processor caches for either code or data) work also like a lookup table. The table is built with very fast memory instead of being stored on slower external memory, and maintains two pieces of data for a sub-range of bits composing an external memory (or disk) address (notably the lowest bits of any possible external address):

one piece (the tag) contains the value of the remaining bits of the address; if these bits match with those from the memory address to read or write, then the other piece contains the cached value for this address.
the other piece maintains the data associated to that address.A single (fast) lookup is performed to read the tag in the lookup table at the index specified by the lowest bits of the desired external storage address, and to determine if the memory address is hit by the cache. When a hit is found, no access to external memory is needed (except for write operations, where the cached value may need to be updated asynchronously to the slower memory after some time, or if the position in the cache must be replaced to cache another address).

Hardware LUTs
In digital logic, a lookup table can be implemented with a multiplexer whose select lines are driven by the address signal and whose inputs are the values of the elements contained in the array. These values can either be hard-wired, as in an ASIC whose purpose is specific to a function, or provided by D latches which allow for configurable values. (ROM, EPROM, EEPROM, or RAM.)
An n-bit LUT can encode any n-input Boolean function by storing the truth table of the function in the LUT. This is an efficient way of encoding Boolean logic functions, and LUTs with 4-6 bits of input are in fact the key component of modern field-programmable gate arrays (FPGAs) which provide reconfigurable hardware logic capabilities.

Data acquisition and control systems
In data acquisition and control systems, lookup tables are commonly used to undertake the following operations in:

The application of calibration data, so as to apply corrections to uncalibrated measurement or setpoint values; and
Undertaking measurement unit conversion; and
Performing generic user-defined computations.In some systems, polynomials may also be defined in place of lookup tables for these calculations.

See also
Associative array
Branch table
Gal's accurate tables
Memoization
Memory-bound function
Shift register lookup table
Palette, a.k.a. color lookup table or CLUT – for the usage in computer graphics
3D lookup table – usage in film industry

References
External links
Fast table lookup using input character as index for branch table
Art of Assembly: Calculation via Table Lookups
""Bit Twiddling Hacks"" (includes lookup tables) By Sean Eron Anderson of Stanford University
Memoization in C++ by Paul McNamee, Johns Hopkins University showing savings
""The Quest for an Accelerated Population Count"" by Henry S. Warren Jr.",356457,https://en.wikipedia.org/wiki/Lookup_table
Multimap,"In computer science, a multimap (sometimes also multihash, multidict or multidictionary) is a generalization of a map or associative array abstract data type in which more than one value may be associated with and returned for a given key. Both map and multimap are particular cases of containers (for example, see C++ Standard Template Library containers). Often the multimap is implemented as a map with lists or sets as the map values.","In computer science, a multimap (sometimes also multihash, multidict or multidictionary) is a generalization of a map or associative array abstract data type in which more than one value may be associated with and returned for a given key. Both map and multimap are particular cases of containers (for example, see C++ Standard Template Library containers). Often the multimap is implemented as a map with lists or sets as the map values.

Examples
In a student enrollment system, where students may be enrolled in multiple classes simultaneously, there might be an association for each enrollment of a student in a course, where the key is the student ID and the value is the course ID. If a student is enrolled in three courses, there will be three associations containing the same key.
The index of a book may report any number of references for a given index term, and thus may be coded as a multimap from index terms to any number of reference locations or pages.
Querystrings may have multiple values associated with a single field. This is commonly generated when a web form allows multiple check boxes or selections to be chosen in response to a single form element.

Language support
C++
C++'s Standard Template Library provides the multimap container for the sorted multimap using a self-balancing binary search tree, and SGI's STL extension provides the hash_multimap container, which implements a multimap using a hash table.As of C++11, the Standard Template Library provides the unordered_multimap for the unordered multimap.

Dart
Quiver provides a Multimap for Dart.

Java
Apache Commons Collections provides a MultiMap interface for Java. It also provides a MultiValueMap implementing class that makes a MultiMap out of a Map object and a type of Collection.Google Guava provides a Multimap interface and implementations of it.

Python
Python provides a collections.defaultdict class that can be used to create a multimap. The user can instantiate the class as collections.defaultdict(list).

OCaml
OCaml's standard library module Hashtbl implements a hash table where it's possible to store multiple values for a key.

Scala
The Scala programming language's API also provides Multimap and implementations.

See also
Abstract data type for the concept of type in general
Associative array for the more fundamental abstract data type
Multiset for the case where same item can appear several times


== References ==",1663543,https://en.wikipedia.org/wiki/Multimap
Ordered Key-Value Store,"An Ordered Key-Value Store (OKVS) is a type of data storage paradigm that can support multi-model database. An OKVS is an ordered mapping of bytes to bytes. It is a more powerful paradigm than Key-Value Store because OKVS allow to build higher level abstractions without the need to do full scans. An OKVS will keep the key-value pairs sorted by the key lexicographic order. OKVS systems provides different set of features and performance trade-offs. Most of them are shipped as a library without network interfaces, in order to be embedded in another process. Most OKVS support ACID guarantees. Some OKVS are distributed databases. Ordered Key-Value Store found their way into many modern database systems including NewSQL database systems.","An Ordered Key-Value Store (OKVS) is a type of data storage paradigm that can support multi-model database. An OKVS is an ordered mapping of bytes to bytes. It is a more powerful paradigm than Key-Value Store because OKVS allow to build higher level abstractions without the need to do full scans. An OKVS will keep the key-value pairs sorted by the key lexicographic order. OKVS systems provides different set of features and performance trade-offs. Most of them are shipped as a library without network interfaces, in order to be embedded in another process. Most OKVS support ACID guarantees. Some OKVS are distributed databases. Ordered Key-Value Store found their way into many modern database systems including NewSQL database systems.

History
The origin of Ordered Key-Value Store stems from the work of Ken Thompson on dbm in 1979. Later in 1991, Berkeley DB was released that featured a B-Tree backend that allowed the keys to stay sorted. Berkeley DB was said to be very fast and made its way into various commercial product. It was included in Python standard library until 2.7.  In 2009, Tokyo Cabinet was released that was superseded by Kyoto Cabinet that support both transaction and ordered keys. In 2011, LMDB was created to replace Berkeley DB in OpenLDAP. There is also Google's LevelDB that was forked by Facebook in 2012 as RocksDB. In 2014, WiredTiger, successor of Berkeley DB was acquired by MongoDB and is since 2019 the primary backend of MongoDB database.
Other notable implementation of the OKVS paradigm are Sophia and SQLite3 LSM extension. Another notable use of OKVS paradigm is the multi-model database system called ArangoDB based on RocksDB.
Some NewSQL databases are supported by Ordered Key-Value Stores. JanusGraph, a property graph database, has both a Berkeley DB backend and FoundationDB backend.

Key concepts
Lexicographic encoding
There are algorithms that encode basic data types (boolean, string, number) and composition of those data types inside sorted containers (tuple, list, vector) that preserve their natural ordering. It is possible to work with an Ordered Key-Value Store without having to work directly with bytes. In FoundationDB, it is called the tuple layer.

Range query
Inside an OKVS, keys are ordered, and because of that it is possible to do range queries. A range query allow to retrieve all keys between two keys such as all keys that are fetched are ordered.

Subspaces
Key composition
One can construct key spaces to build higher level abstractions. The idea is to construct keys, that takes advantage of the ordered nature of the top level key space. When taking advantage of the ordered nature of the key space, one can query ranges of keys that have particular pattern.

Denormalization
Denormalization, as in, repeating the same piece of data in multiple subspace is common practice. It allows to create secondary representation, also called indices, that will allow to speed up queries.

Higher level abstractions
The following abstraction or databases were built on top Ordered Key-Value Stores:

Timeseries database,
Record Database, also known as Row store databases, they behave similarly to what is dubbed RDBMS,
Tuple Stores, also known as Triple Store or Quad Store but also Generic Tuple Store,
Document database, that mimics MongoDB API,
Full-text search
Geographic Information Systems
Property Graph
Versioned DataAll those abstraction can co-exist with the same OKVS database and when ACID is supported, the operations happens with the guarantees offered by the transaction system.

Feature matrix
SQLite LSM extension's transactions can be nested
SQLite LSM extension support multiple readers, and only a single writer that do not block readers

See also
Key–value_database
Wide Column Store
Multi-model database


== References ==",62848042,https://en.wikipedia.org/wiki/Ordered_Key-Value_Store
Comparison of programming languages (associative array),This Comparison of programming languages (associative arrays) compares the features of associative array data structures or array-lookup processing for over 40 computer programming languages.,"This Comparison of programming languages (associative arrays) compares the features of associative array data structures or array-lookup processing for over 40 computer programming languages.

Language support
The following is a comparison of associative arrays (also ""mapping"", ""hash"", and ""dictionary"") in various programming languages.

AWK
AWK has built-in, language-level support for associative arrays.
For example:

The following code loops through an associated array and prints its contents:

The user can search for elements in an associative array, and delete elements from the array.
The following shows how multi-dimensional associative arrays can be simulated in standard AWK using concatenation and the built-in string-separator variable SUBSEP:

C
There is no standard implementation of associative arrays in C, but a 3rd-party library, C Hash Table, with BSD license, is available.Another 3rd-party library, uthash, also creates associative arrays from C structures. A structure represents a value, and one of the structure fields serves as the key.Finally, the GLib library also supports associative arrays, along with many other advanced data types and is the recommended implementation of the GNU Project.Similar to GLib, Apple's cross-platform Core Foundation framework provides several basic data types. In particular, there are reference-counted CFDictionary and CFMutableDictionary.

C#
C# uses the collection classes provided by the .NET Framework. The most commonly used associative array type is System.Collections.Generic.Dictionary<TKey, TValue>, which is implemented as a mutable hash table. The  relatively new System.Collections.Immutable package, available in .NET Framework versions 4.5 and above, and in all versions of .NET Core, also includes the System.Collections.Immutable.Dictionary<TKey, TValue> type, which is implemented using an AVL tree. The methods that would normally mutate the object in-place instead return a new object that represents the state of the original object after mutation.

Creation
The following demonstrates three means of populating a mutable dictionary:

the Add method, which adds a key and value and throws an exception if the key already exists in the dictionary;
assigning to the indexer, which overwrites any existing value, if present; and
assigning to the backing property of the indexer, for which the indexer is syntactic sugar (not applicable to C#, see F# or VB.NET examples).
The dictionary can also be initialized during construction using a ""collection initializer"", which compiles to repeated calls to Add.

Access by key
Values are primarily retrieved using the indexer (which throws an exception if the key does not exist) and the TryGetValue method, which has an output parameter for the sought value and a Boolean return-value indicating whether the key was found.

In this example, the sallyNumber value will now contain the string ""555-9999"".

Enumeration
A dictionary can be viewed as a sequence of keys, sequence of values, or sequence of pairs of keys and values represented by instances of the KeyValuePair<TKey, TValue> type, although there is no guarantee of order. For a sorted dictionary, the programmer could choose to use a SortedDictionary<TKey, TValue> or use the .Sort LINQ extension method when enumerating.
The following demonstrates enumeration using a foreach loop:

C++
C++ has a form of associative array called std::map (see Standard Template Library#Containers). One could create a phone-book map with the following code in C++:

Or less efficiently, as this creates temporary std::string values:

With the extension of initialization lists in C++11, entries can be added during a map's construction as shown below:

You can iterate through the list with the following code (C++03):

The same task in C++11:

Using the structured binding available in C++17:

In C++, the std::map class is templated which allows the data types of keys and values to be different for different map instances. For a given instance of the map class the keys must be of the same base type. The same must be true for all of the values. Although std::map is typically implemented using a self-balancing binary search tree, C++11 defines a second map called std::unordered_map, which has the algorithmic characteristics of a hash table. This is a common vendor extension to the Standard Template Library (STL) as well, usually called hash_map, available from such implementations as SGI and STLPort.

Cobra
Initializing an empty dictionary and adding items in Cobra:

Alternatively, a dictionary can be initialized with all items during construction:

The dictionary can be enumerated by a for-loop, but there is no guaranteed order:

ColdFusion Markup Language
A structure in ColdFusion Markup Language (CFML) is equivalent to an associative array:

D
D offers direct support for associative arrays in the core language; such arrays are implemented as a chaining hash table with binary trees. The equivalent example would be:

Keys and values can be any types, but all the keys in an associative array must be of the same type, and the same goes for dependent values.
Looping through all properties and associated values, and printing them, can be coded as follows:

A property can be removed as follows:

Delphi
Delphi supports several standard containers, including TDictionary<T>:

Pre-2009 Delphi versions do not support associative arrays directly. Such arrays can be simulated using the TStrings class:

Erlang
Erlang offers many ways to represent mappings; three of the most common in the standard library are keylists, dictionaries, and maps.

Keylists
Keylists are lists of tuples, where the first element of each tuple is a key, and the second is a value. Functions for operating on keylists are provided in the lists module.

Accessing an element of the keylist can be done with the lists:keyfind/3 function:

Dictionaries
Dictionaries are implemented in the dict module of the standard library. A new dictionary is created using the dict:new/0 function and new key/value pairs are stored using the dict:store/3 function:

Such a serial initialization would be more idiomatically represented in Erlang with the appropriate function:

The dictionary can be accessed using the dict:find/2 function:

In both cases, any Erlang term can be used as the key. Variations include the orddict module, implementing ordered dictionaries, and gb_trees, implementing general balanced trees.

Maps
Maps were introduced in OTP 17.0, and combine the strengths of keylists and dictionaries. A map is defined using the syntax #{ K1 => V1, ... Kn => Vn }:

Basic functions to interact with maps are available from the maps module. For example, the maps:find/2 function returns the value associated with a key:

Unlike dictionaries, maps can be pattern matched upon:

Erlang also provides syntax sugar for functional updates—creating a new map based on an existing one, but with modified values or additional keys:

F#
Map<'Key,'Value>
At runtime, F# provides the Collections.Map<'Key,'Value> type, which is an immutable AVL tree.

Creation
The following example calls the Map constructor, which operates on a list (a semicolon delimited sequence of elements enclosed in square brackets) of tuples (which in F# are comma-delimited sequences of elements).

Access by key
Values can be looked up via one of the Map members, such as its indexer or Item property (which throw an exception if the key does not exist) or the TryFind function, which returns an option type with a value of Some <result>, for a successful lookup, or None, for an unsuccessful one. Pattern matching can then be used to extract the raw value from the result, or a default value can be set.

In both examples above, the sallyNumber value would contain the string ""555-9999"".

Dictionary<'TKey,'TValue>
Because F# is a .NET language, it also has access to features of the .NET Framework, including the System.Collections.Generic.Dictionary<'TKey,'TValue> type (which is implemented as a hash table), which is the primary associative array type used in C# and Visual Basic. This type may be preferred when writing code that is intended to operate with other languages on the .NET Framework, or when the performance characteristics of a hash table are preferred over those of an AVL tree.

Creation
The dict function provides a means of conveniently creating a .NET dictionary that is not intended to be mutated; it accepts a sequence of tuples and returns an immutable object that implements IDictionary<'TKey,'TValue>.

When a mutable dictionary is needed, the constructor of System.Collections.Generic.Dictionary<'TKey,'TValue> can be called directly. See the C# example on this page for additional information.

Access by key
IDictionary instances have an indexer that is used in the same way as Map, although the equivalent to TryFind is TryGetValue, which has an output parameter for the sought value and a Boolean return value indicating whether the key was found.

F# also allows the function to be called as if it had no output parameter and instead returned a tuple containing its regular return value and the value assigned to the output parameter:

Enumeration
A dictionary or map can be enumerated using Seq.map.

FoxPro
Visual FoxPro implements mapping with the Collection Class.

GetKey returns 0 if the key is not found.

Go
Go has built-in, language-level support for associative arrays, called ""maps"". A map's key type may only be a boolean, numeric, string, array, struct, pointer, interface, or channel type.
A map type is written: map[keytype]valuetype
Adding elements one at a time:

A map literal:

Iterating through a map:

Haskell
The Haskell programming language provides only one kind of associative container – a list of pairs:

output:

Just ""555-1212""

Note that the lookup function returns a ""Maybe"" value, which is ""Nothing"" if not found, or ""Just 'result'"" when found.
The Glasgow Haskell Compiler (GHC), the most commonly used implementation of Haskell, provides two more types of associative containers. Other implementations may also provide these.
One is polymorphic functional maps (represented as immutable balanced binary trees):

output:

Just ""555-1212""

A specialized version for integer keys also exists as Data.IntMap.
Finally, a polymorphic hash table:

output:

Just ""555-1212""

Lists of pairs and functional maps both provide a purely functional interface, which is more idiomatic in Haskell. In contrast, hash tables provide an imperative interface in the IO monad.

Java
In Java associative arrays are implemented as ""maps"", which are part of the Java collections framework. Since J2SE 5.0 and the introduction of generics into Java, collections can have a type specified; for example, an associative array that maps strings to strings might be specified as follows:

The get method is used to access a key; for example, the value of the expression phoneBook.get(""Sally Smart"") is ""555-9999"". This code uses a hash map to store the associative array, by calling the constructor of the HashMap class. However, since the code only uses methods common to the interface Map, a self-balancing binary tree could be used by calling the constructor of the TreeMap class (which implements the subinterface SortedMap), without changing the definition of the phoneBook variable, or the rest of the code, or using other underlying data structures that implement the Map interface.
The hash function in Java, used by HashMap and HashSet, is provided by the Object.hashCode() method. Since every class in Java inherits from Object, every object has a hash function. A class can override the default implementation of hashCode() to provide a custom hash function more in accordance with the properties of the object.
The Object class also contains the equals(Object) method, which tests an object for equality with another object. Hashed data structures in Java rely on objects maintaining the following contract between their hashCode() and equals() methods:
For two objects a and b,

In order to maintain this contract, a class that overrides equals() must also override hashCode(), and vice versa, so that hashCode() is based on the same properties (or a subset of the properties) as equals().
A further contract that a hashed data structure has with the object is that the results of the hashCode() and equals() methods will not change once the object has been inserted into the map. For this reason, it is generally a good practice to base the hash function on immutable properties of the object.
Analogously, TreeMap, and other sorted data structures, require that an ordering be defined on the data type. Either the data type must already have defined its own ordering, by implementing the Comparable interface; or a custom Comparator must be provided at the time the map is constructed. As with HashMap above, the relative ordering of keys in a TreeMap should not change once they have been inserted into the map.

JavaScript
JavaScript (and its standardized version, ECMAScript) is a prototype-based object-oriented language.

Map and WeakMap
Modern JavaScript handles associative arrays, using the Map and WeakMap classes. A map does not contain any keys by default; it only contains what is explicitly put into it. The keys and values can be any type (including functions, objects, or any primitive).

Creation
A map can be initialized with all items during construction:

Alternatively, you can initialize an empty map and then add items:

Access by key
Accessing an element of the map can be done with the get method:

In this example, the value sallyNumber will now contain the string ""555-9999"".

Enumeration
The keys in a map are ordered. Thus, when iterating through it, a map object returns keys in order of insertion. The following demonstrates enumeration using a for-loop:

A key can be removed as follows:

Object
An object is similar to a map—both let you set keys to values, retrieve those values, delete keys, and detect whether a value is stored at a key. For this reason (and because there were no built-in alternatives), objects historically have been used as maps.
However, there are important differences that make a map preferable in certain cases. In JavaScript an object is a mapping from property names to values—that is, an associative array with one caveat: the keys of an object must be either a string or a symbol (native objects and primitives implicitly converted to a string keys are allowed). Objects also include one feature unrelated to associative arrays: an object has a prototype, so it contains default keys that could conflict with user-defined keys. So, doing a lookup for a property will point the lookup to the prototype's definition if the object does not define the property.
An object literal is written as { property1: value1, property2: value2, ... }. For example:

To prevent the lookup from using the prototype's properties, you can use the Object.setPrototypeOf function:

As of ECMAScript 5 (ES5), the prototype can also be bypassed by using Object.create(null):

If the property name is a valid identifier, the quotes can be omitted, e.g.:

Lookup is written using property-access notation, either square brackets, which always work, or dot notation, which only works for identifier keys:

You can also loop through all enumerable properties and associated values as follows (a for-in loop):

Or (a for-of loop):

A property can be removed as follows:

As mentioned before, properties are strings and symbols. Since every native object and primitive can be implicitly converted to a string, you can do:

In modern JavaScript it's considered bad form to use the Array type as an associative array. Consensus is that the Object type and Map/WeakMap classes are best for this purpose. The reasoning behind this is that if Array is extended via prototype and Object is kept pristine, for and for-in loops will work as expected on associative 'arrays'. This issue has been brought to the fore by the popularity of JavaScript frameworks that make heavy and sometimes indiscriminate use of prototypes to extend JavaScript's inbuilt types.
See JavaScript Array And Object Prototype Awareness Day for more information on the issue.

Julia
In Julia, the following operations manage associative arrays.
Declare dictionary:

Access element:

phonebook[""Sally Smart""]

Add element:

phonebook[""New Contact""] = ""555-2222""

Delete element:

delete!(phonebook, ""Sally Smart"")

Get keys and values as iterables:

keys(phonebook)
values(phonebook)

KornShell 93, and compliant shells
In KornShell 93, and compliant shells (ksh93, bash4...), the following operations can be used with associative arrays.
Definition:

Dereference:

Lisp
Lisp was originally conceived as a ""LISt Processing"" language, and one of its most important data types is the linked list, which can be treated as an association list (""alist"").

The syntax (x . y) is used to indicate a consed pair. Keys and values need not be the same type within an alist. Lisp and Scheme provide operators such as assoc to manipulate alists in ways similar to associative arrays.
A set of operations specific to the handling of association lists exists for Common Lisp, each of these working non-destructively.
To add an entry the acons function is employed, creating and returning a new association list. An association list in Common Lisp mimicks a stack, that is, adheres to the last-in-first-out (LIFO) principle, and hence prepends to the list head.

This function can be construed as an accommodation for cons operations.

Of course, the destructive push operation also allows inserting entries into an association list, an entry having to constitute a key-value cons in order to retain the mapping's validity.

Searching for an entry by its key is performed via assoc, which might be configured for the test predicate and direction, especially searching the association list from its end to its front. The result, if positive, returns the entire entry cons, not only its value. Failure to obtain a matching key leds to a return of the NIL value.

Two generalizations of assoc exist: assoc-if expects a predicate function that tests each entry's key, returning the first entry for which the predicate produces a non-NIL value upon invocation. assoc-if-not inverts the logic, accepting the same arguments, but returning the first entry generating NIL.

The inverse process, the detection of an entry by its value, utilizes rassoc.

The corresponding generalizations rassoc-if and rassoc-if-not exist.

All of the previous entry search functions can be replaced by general list-centric variants, such as find, find-if, find-if-not, as well as pertinent functions like position and its derivates.

Deletion, lacking a specific counterpart, is based upon the list facilities, including destructive ones.

Iteration is accomplished with the aid of any function that expects a list.

These being structured lists, processing and transformation operations can be applied without constraints.

Because of their linear nature, alists are used for relatively small sets of data. Common Lisp also supports a hash table data type, and for Scheme they are implemented in SRFI 69. Hash tables have greater overhead than alists, but provide much faster access when there are many elements. A further characteristic is the fact that Common Lisp hash tables do not, as opposed to association lists, maintain the order of entry insertion.
Common Lisp hash tables are constructed via the make-hash-table function, whose arguments encompass, among other configurations, a predicate to test the entry key. While tolerating arbitrary objects, even heterogeneity within a single hash table instance, the specification of this key :test function is confined to distinguishable entities: the Common Lisp standard only mandates the support of eq, eql, equal, and equalp, yet designating additional or custom operations as permissive for concrete implementations.

The gethash function permits obtaining the value associated with a key.

Additionally, a default value for the case of an absent key may be specified.

An invocation of gethash actually returns two values: the value or substitute value for the key and a boolean indicator, returning T if the hash table contains the key and NIL to signal its absence.

Use remhash for deleting the entry associated with a key.

clrhash completely empties the hash table.

The dedicated maphash function specializes in iterating hash tables.

Alternatively, the loop construct makes provisions for iterations, through keys, values, or conjunctions of both.

A further option invokes with-hash-table-iterator, an iterator-creating macro, the processing of which is intended to be driven by the caller.

It is easy to construct composite abstract data types in Lisp, using structures or object-oriented programming features, in conjunction with lists, arrays, and hash tables.

LPC
LPC implements associative arrays as a fundamental type known as either ""map"" or ""mapping"", depending on the driver. The keys and values can be of any type. A mapping literal is written as ([ key_1 : value_1, key_2 : value_2 ]). Procedural code looks like:

Mappings are accessed for reading using the indexing operator in the same way as they are for writing, as shown above. So phone_book[""Sally Smart""] would return the string ""555-9999"", and phone_book[""John Smith""] would return 0. Testing for presence is done using the function member(), e.g. if(member(phone_book, ""John Smith"")) write(""John Smith is listed.\n"");
Deletion is accomplished using a function called either m_delete() or map_delete(), depending on the driver: m_delete(phone_book, ""Sally Smart"");
LPC drivers of the Amylaar family implement multivalued mappings using a secondary, numeric index (other drivers of the MudOS family do not support multivalued mappings.) Example syntax:

LPC drivers modern enough to support a foreach() construct use it to iterate through their mapping types.

Lua
In Lua, ""table"" is a fundamental type that can be used either as an array (numerical index, fast) or as an associative array.
The keys and values can be of any type, except nil. The following focuses on non-numerical indexes.
A table literal is written as { value, key = value, [index] = value, [""non id string""] = value }. For example:

If the key is a valid identifier (not a reserved word), the quotes can be omitted. Identifiers are case sensitive.
Lookup is written using either square brackets, which always works, or dot notation, which only works for identifier keys:

You can also loop through all keys and associated values with iterators or for-loops:

An entry can be removed by setting it to nil:

Likewise, you can overwrite values or add them:

Mathematica and Wolfram Language
Mathematica and Wolfram Language use the Association expression to represent associative arrays.

To access:

If the keys are strings, the Key keyword is not necessary, so:

To list keys: and values
Keys[phonebook]
Values[phonebook]

MUMPS
In MUMPS every array is an associative array. The built-in, language-level, direct support for associative arrays
applies to private, process-specific arrays stored in memory called ""locals"" as well as to the permanent, shared, global arrays stored on disk which are available concurrently to multiple jobs. The name for globals is preceded by the circumflex ""^"" to distinguish them from local variables.

SET ^phonebook(""Sally Smart"")=""555-9999""      ;; storing permanent data
SET phonebook(""John Doe"")=""555-1212""          ;; storing temporary data
SET phonebook(""J. Random Hacker"")=""553-1337""  ;; storing temporary data
MERGE ^phonebook=phonebook                    ;; copying temporary data into permanent data

Accessing the value of an element simply requires using the name with the subscript:

WRITE ""Phone Number :"",^phonebook(""Sally Smart""),!

You can also loop through an associated array as follows:

SET NAME=""""
FOR  S NAME=$ORDER(^phonebook(NAME)) QUIT:NAME=""""  WRITE NAME,""  Phone Number :"",^phonebook(NAME),!

Objective-C (Cocoa/GNUstep)
Cocoa and GNUstep, written in Objective-C, handle associative arrays using NSMutableDictionary (a mutable version of NSDictionary) class cluster. This class allows assignments between any two objects. A copy of the key object is made before it is inserted into NSMutableDictionary, therefore the keys must conform to the NSCopying protocol. When being inserted to a dictionary, the value object receives a retain message to increase its reference count. The value object will receive the release message when it will be deleted from the dictionary (either explicitly or by adding to the dictionary a different object with the same key).

To access assigned objects, this command may be used:

All keys or values can be enumerated using NSEnumerator:

In Mac OS X 10.5+ and iPhone OS, dictionary keys can be enumerated more concisely using the NSFastEnumeration construct:

What is even more practical, structured data graphs may be easily created using Cocoa, especially NSDictionary (NSMutableDictionary). This can be illustrated with this compact example:

Relevant fields can be quickly accessed using key paths:

OCaml
The OCaml programming language provides three different associative containers. The simplest is a list of pairs:

The second is a polymorphic hash table:

The code above uses OCaml's default hash function Hashtbl.hash, which is defined automatically for all types. To use a modified hash function, use the functor interface Hashtbl.Make to create a module, such as with Map.
Finally, functional maps (represented as immutable balanced binary trees):

Note that in order to use Map, you have to provide the functor Map.Make with a module which defines the key type and the comparison function. The third-party library ExtLib provides a polymorphic version of functional maps, called PMap, which is given a comparison function upon creation.
Lists of pairs and functional maps both provide a purely functional interface. By contrast, hash tables provide an imperative interface. For many operations, hash tables are significantly faster than lists of pairs and functional maps.

OptimJ
The OptimJ programming language is an extension of Java 5. As does Java, Optimj provides maps; but OptimJ also provides true associative arrays. Java arrays are indexed with non-negative integers; associative arrays are indexed with any type of key.

Of course, it is possible to define multi-dimensional arrays, to mix Java arrays and associative arrays, to mix maps and associative arrays.

Perl 5
Perl 5 has built-in, language-level support for associative arrays. Modern Perl refers to associative arrays as hashes; the term associative array is found in older documentation but is considered somewhat archaic. Perl 5 hashes are flat: keys are strings and values are scalars. However, values may be references to arrays or other hashes, and the standard Perl 5 module Tie::RefHash enables hashes to be used with reference keys.
A hash variable is marked by a % sigil, to distinguish it from scalar, array, and other data types. A hash literal is a key-value list, with the preferred form using Perl's => token, which is semantically mostly identical to the comma and makes the key-value association clearer:

Accessing a hash element uses the syntax $hash_name{$key} – the key is surrounded by curly braces and the hash name is prefixed by a $, indicating that the hash element itself is a scalar value, even though it is part of a hash. The value of $phone_book{'John Doe'} is '555-1212'. The % sigil is only used when referring to the hash as a whole, such as when asking for keys %phone_book.
The list of keys and values can be extracted using the built-in functions keys and values, respectively. So, for example, to print all the keys of a hash:

One can iterate through (key, value) pairs using the each function:

A hash ""reference"", which is a scalar value that points to a hash, is specified in literal form using curly braces as delimiters, with syntax otherwise similar to specifying a hash literal:

Values in a hash reference are accessed using the dereferencing operator:

When the hash contained in the hash reference needs to be referred to as a whole, as with the keys function, the syntax is as follows:

Perl 6 (Raku)
Perl 6, renamed as ""Raku"", also has built-in, language-level support for associative arrays, which are referred to as hashes or as objects performing the ""associative"" role. As in Perl 5, Perl 6 default hashes are flat: keys are strings and values are scalars. One can define a hash to not coerce all keys to strings automatically: these are referred to as ""object hashes"", because the keys of such hashes remain the original object rather than a stringification thereof.
A hash variable is typically marked by a % sigil, to visually distinguish it from scalar, array, and other data types, and to define its behaviour towards iteration. A hash literal is a key-value list, with the preferred form using Perl's => token, which makes the key-value association clearer:

Accessing a hash element uses the syntax %hash_name{$key} – the key is surrounded by curly braces and the hash name (note that the sigil does not change, contrary to Perl 5). The value of %phone-book{'John Doe'} is '555-1212'.
The list of keys and values can be extracted using the built-in functions keys and values, respectively. So, for example, to print all the keys of a hash:

By default, when iterating through a hash, one gets key–value pairs.

It is also possible to get alternating key values and value values by using the kv method:

Raku doesn't have any references. Hashes can be passed as single parameters that are not flattened. If you want to make sure that a subroutine only accepts hashes, use the % sigil in the Signature.

In compliance with gradual typing, hashes may be subjected to type constraints, confining a set of valid keys to a certain type.

PHP
PHP's built-in array type is, in reality, an associative array. Even when using numerical indexes, PHP internally stores arrays as associative arrays. So, PHP can have non-consecutively numerically indexed arrays. The keys have to be of integer (floating point numbers are truncated to integer) or string type, while values can be of arbitrary types, including other arrays and objects. The arrays are heterogeneous: a single array can have keys of different types. PHP's associative arrays can be used to represent trees, lists, stacks, queues, and other common data structures not built into PHP.
An associative array can be declared using the following syntax:

PHP can loop through an associative array as follows:

PHP has an extensive set of functions to operate on arrays.Associative arrays that can use objects as keys, instead of strings and integers, can be implemented with the SplObjectStorage class from the Standard PHP Library (SPL).

Pike
Pike has built-in support for associative arrays, which are referred to as mappings. Mappings are created as follows:

Accessing and testing for presence in mappings is done using the indexing operator. So phonebook[""Sally Smart""] would return the string ""555-9999"", and phonebook[""John Smith""] would return 0.
Iterating through a mapping can be done using foreach:

Or using an iterator object:

Elements of a mapping can be removed using m_delete, which returns the value of the removed index:

PostScript
In PostScript, associative arrays are called dictionaries. In Level 1 PostScript they must be created explicitly, but Level 2 introduced direct declaration using a double-angled-bracket syntax:

Dictionaries can be accessed directly, using get, or implicitly, by placing the dictionary on the dictionary stack using begin:

Dictionary contents can be iterated through using forall, though not in any particular order:

Which may output:

Dictionaries can be augmented (up to their defined size only in Level 1) or altered using put, and entries can be removed using undef:

Prolog
Some versions of Prolog include dictionary (""dict"") utilities.

Python
In Python, associative arrays are called ""dictionaries"". Dictionary literals are delimited by curly braces:

Dictionary items can be accessed using the array indexing operator: 

Loop iterating through all the keys of the dictionary:

Iterating through (key, value) tuples:

Dictionary keys can be individually deleted using the del statement. The corresponding value can be returned before the key-value pair is deleted using the ""pop"" method of ""dict"" type:

Python 2.7 and 3.x also support dict comprehensions (similar to list comprehensions), a compact syntax for generating a dictionary from any iterator:

Strictly speaking, a dictionary is a super-set of an associative array, since neither the keys or values are limited to a single datatype. One could think of a dictionary as an ""associative list"" using the nomenclature of Python. For example, the following is also legitimate:

The dictionary keys must be of an immutable data type. In Python, strings are immutable due to their method of implementation.

Red
In Red the built-in map! datatype provides an associative array that maps values of word, string, and scalar key types to values of any type. A hash table is used internally for lookup.
A map can be written as a literal, such as #(key1 value1 key2 value2 ...), or can be created using make map! [key1 value1 key2 value2 ...]:

REXX
In REXX, associative arrays are called ""stem variables"" or ""Compound variables"".

Stem variables with numeric keys typically start at 1 and go up from there. The 0-key stem variable
by convention contains the total number of items in the stem:

REXX has no easy way of automatically accessing the keys of a stem variable; and typically the
keys are stored in a separate associative array, with numeric keys.

Ruby
In Ruby a hash table is used as follows:

Ruby supports hash looping and iteration with the following syntax:

Ruby also supports many other useful operations on hashes, such as merging hashes, selecting or rejecting elements that meet some criteria, inverting (swapping the keys and values), and flattening a hash into an array.

Rust
The Rust standard library provides a hash map (std::collections::HashMap) and a B-tree map (std::collections::BTreeMap). They share several methods with the same names, but have different requirements for the types of keys that can be inserted. The HashMap requires keys to implement the Eq (equivalence relation) and Hash (hashability) traits and it stores entries in an unspecified order, and the BTreeMap requires the Ord (total order) trait for its keys and it stores entries in an order defined by the key type. The order is reflected by the default iterators.

The default iterators visit all entries as tuples. The HashMap iterators visit entries in an unspecified order and the BTreeMap iterator visits entries in the order defined by the key type.

There is also an iterator for keys:

S-Lang
S-Lang has an associative array type:

You can also loop through an associated array in a number of ways:

To print a sorted-list, it is better to take advantage of S-lang's strong
support for standard arrays:

Scala
Scala provides an immutable Map class as part of the scala.collection framework:

Scala's type inference will decide that this is a Map[String, String]. To access the array:

This returns an Option type, Scala's equivalent of the Maybe monad in Haskell.

Smalltalk
In Smalltalk a Dictionary is used:

To access an entry the message #at: is sent to the dictionary object:

Which gives:

A dictionary hashes, or compares, based on equality and marks both key and value as 
strong references. Variants exist in which hash/compare on identity (IdentityDictionary) or keep weak references (WeakKeyDictionary / WeakValueDictionary).
Because every object implements #hash, any object can be used as key (and of course also as value).

SNOBOL
SNOBOL is one of the first (if not the first) programming languages to use associative arrays. Associative arrays in SNOBOL are called Tables.

Standard ML
The SML'97 standard of the Standard ML programming language does not provide any associative containers. However, various implementations of Standard ML do provide associative containers.
The library of the popular Standard ML of New Jersey (SML/NJ) implementation provides a signature (somewhat like an ""interface""), ORD_MAP, which defines a common interface for ordered functional (immutable) associative arrays. There are several general functors—BinaryMapFn, ListMapFn, RedBlackMapFn, and SplayMapFn—that allow you to create the corresponding type of ordered map (the types are a self-balancing binary search tree, sorted association list, red–black tree, and splay tree, respectively) using a user-provided structure to describe the key type and comparator. The functor returns a structure in accordance with the ORD_MAP interface. In addition, there are two pre-defined modules for associative arrays that employ integer keys: IntBinaryMap and IntListMap.

SML/NJ also provides a polymorphic hash table:

Monomorphic hash tables are also supported, using the HashTableFn functor.
Another Standard ML implementation, Moscow ML, also provides some associative containers. First, it provides polymorphic hash tables in the Polyhash structure. Also, some functional maps from the SML/NJ library above are available as Binarymap, Splaymap, and Intmap structures.

Tcl
There are two Tcl facilities that support associative-array semantics. An ""array"" is a collection of variables.  A ""dict"" is a full implementation of associative arrays.

array
If there is a space character in the variable name, the name must be grouped using either curly brackets (no substitution performed) or double quotes (substitution is performed).
Alternatively, several array elements can be set by a single command, by presenting their mappings as a list (words containing whitespace are braced):

To access one array entry and put it to standard output:

Which returns this result:

To retrieve the entire array as a dictionary:

The result can be (order of keys is unspecified, not because the dictionary is unordered, but because the array is):

dict
To look up an item:

To iterate through a dict:

Visual Basic
Visual Basic can use the Dictionary class from the Microsoft Scripting Runtime (which is shipped with Visual Basic 6). There is no standard implementation common to all versions:

Visual Basic .NET
Visual Basic .NET uses the collection classes provided by the .NET Framework.

Creation
The following code demonstrates the creation and population of a dictionary (see the C# example on this page for additional information):

An alternate syntax would be to use a collection initializer, which compiles down to individual calls to Add:

Access by key
Example demonstrating access (see C# access):

Enumeration
Example demonstrating enumeration (see #C# enumeration):

Windows PowerShell
Unlike many other command line interpreters, Windows PowerShell has built-in, language-level support for defining associative arrays:

As in JavaScript, if the property name is a valid identifier, the quotes can be omitted:

Entries can be separated by either a semicolon or a newline:

Keys and values can be any .NET object type:

It is also possible to create an empty associative array and add single entries, or even other associative arrays, to it later on:

New entries can also be added by using the array index operator, the property operator, or the Add() method of the underlying .NET object:

To dereference assigned objects, the array index operator, the property operator, or the parameterized property Item() of the .NET object can be used:

You can loop through an associative array as follows:

An entry can be removed using the Remove() method of the underlying .NET object:

Hash tables can be added:

Data serialization formats support
Many data serialization formats also support associative arrays (see this table)

JSON
In JSON, associative arrays are also referred to as objects. Keys can only be strings.

YAML
YAML associative arrays are also called map elements or key-value pairs. YAML places no restrictions on the types of keys; in particular, they are not restricted to being scalar or string values.


== References ==",13941848,https://en.wikipedia.org/wiki/Comparison_of_programming_languages_(associative_array)
Retrieval Data Structure,"In computer science, a retrieval data structure, also known as static function, is a space-efficient dictionary-like data type composed of a collection of (key, value) pairs that allows the following operations:
Construction from a collection of (key, value) pairs
Retrieve the value associated with the given key or anything if the key is not contained in the collection
Update the value associated with a key (optional)They can also be thought of as a function b:U→{0,1}r{\displaystyle b\colon \,{\mathcal {U}}\to \{0,1\}^{r}} for a universe U{\displaystyle {\mathcal {U}}} and the set of keys S⊆U{\displaystyle S\subseteq {\mathcal {U}}} where retrieve has to return b(x){\displaystyle b(x)} for any value x∈S{\displaystyle x\in S} and an arbitrary value from {0,1}r{\displaystyle \{0,1\}^{r}} otherwise.
In contrast to static functions, AMQ-filters support (probabilistic) membership queries and dictionaries additionally allow operations like listing keys or looking up the value associated with a key and returning some other symbol if the key is not contained.
As can be derived from the operations, this data structure does not need to store the keys at all and may actually use less space than would be needed for a simple list of the key value pairs. This makes it attractive in situations where the associated data is small (e.g. a few bits) compared to the keys because we can save a lot by reducing the space used by keys.
To give a simple example suppose n{\displaystyle n} video game names annotated with a boolean indicating whether the game contains a dog that can be petted are given. A static function built from this database can reproduce the associated flag for all names contained in the original set and an arbitrary one for other names. The size of this static function can be made to be only (1+ϵ)n{\displaystyle (1+\epsilon )n} bits for a small ϵ{\displaystyle \epsilon } which is obviously much less than any pair based representation.","In computer science, a retrieval data structure, also known as static function, is a space-efficient dictionary-like data type composed of a collection of (key, value) pairs that allows the following operations:
Construction from a collection of (key, value) pairs
Retrieve the value associated with the given key or anything if the key is not contained in the collection
Update the value associated with a key (optional)They can also be thought of as a function b:U→{0,1}r{\displaystyle b\colon \,{\mathcal {U}}\to \{0,1\}^{r}} for a universe U{\displaystyle {\mathcal {U}}} and the set of keys S⊆U{\displaystyle S\subseteq {\mathcal {U}}} where retrieve has to return b(x){\displaystyle b(x)} for any value x∈S{\displaystyle x\in S} and an arbitrary value from {0,1}r{\displaystyle \{0,1\}^{r}} otherwise.
In contrast to static functions, AMQ-filters support (probabilistic) membership queries and dictionaries additionally allow operations like listing keys or looking up the value associated with a key and returning some other symbol if the key is not contained.
As can be derived from the operations, this data structure does not need to store the keys at all and may actually use less space than would be needed for a simple list of the key value pairs. This makes it attractive in situations where the associated data is small (e.g. a few bits) compared to the keys because we can save a lot by reducing the space used by keys.
To give a simple example suppose n{\displaystyle n} video game names annotated with a boolean indicating whether the game contains a dog that can be petted are given. A static function built from this database can reproduce the associated flag for all names contained in the original set and an arbitrary one for other names. The size of this static function can be made to be only (1+ϵ)n{\displaystyle (1+\epsilon )n} bits for a small ϵ{\displaystyle \epsilon } which is obviously much less than any pair based representation.

Examples
A trivial example of a static function is a sorted list of the keys and values which implements all the above operations and many more.
However, the retrieve on a list is slow and we implement many unneeded operations that can be removed to allow optimizations.
Furthermore, we are even allowed to return junk if the queried key is not contained which we did not use at all.

Perfect hash functions
Another simple example to build a static function is using a perfect hash function: After building the PHF for our keys, store the corresponding values at the correct position for the key. As can be seen, this approach also allows updating the associated values, the keys have to be static. The correctness follows from the correctness of the perfect hash function. Using a minimum perfect hash function gives a big space improvement if the associated values are relatively small.

XOR-retrieval
Hashed filters can be categorized by their queries into OR, AND and XOR-filters. For example, the bloom filter is an AND-filter since it returns true for a membership query if all probed locations match. XOR filters work only for static retrievals and are the most promising for building them space efficiently. They are built by solving a linear system which ensures that a query for every key returns true.

Construction
Given a hash function h{\displaystyle h} that maps each key to a bitvector of length m≥|S|=n{\displaystyle m\geq \left\vert S\right\vert =n} where all (h(x))x∈S{\displaystyle (h(x))_{x\in S}} are linearly independent the following system of linear equations has a solution Z∈{0,1}m×r{\displaystyle Z\in \{0,1\}^{m\times r}}:

(h(x)⋅Z=b(x))x∈S{\displaystyle (h(x)\cdot Z=b(x))_{x\in S}}Therefore, the static function is given by h{\displaystyle h} and Z{\displaystyle Z} and the space usage is dominated by Z{\displaystyle Z} which is roughly (1+ϵ)n{\displaystyle (1+\epsilon )n} bits per key for m=(1+ϵ)n{\displaystyle m=(1+\epsilon )n}, the hash function is assumed to be small.
A retrieval for x∈U{\displaystyle x\in {\mathcal {U}}} can be expressed as the bitwise XOR of the rows Zi{\displaystyle Z_{i}} for all set bits i{\displaystyle i} of h(x){\displaystyle h(x)}. Furthermore, fast queries require sparse h(x){\displaystyle h(x)}, thus the problems that need to be solved for this method are finding a suitable hash function and still being able to solve the system of linear equations efficiently.

Ribbon retrieval
Using a sparse random matrix h{\displaystyle h} makes retrievals cache inefficient because they access most of Z{\displaystyle Z} in a random non local pattern. Ribbon retrieval improves on this by giving each h(x){\displaystyle h(x)} a consecutive ""ribbon"" of width w=O(log⁡n/ϵ){\displaystyle w={\mathcal {O}}(\log n/\epsilon )} in which bits are set at random.Using the properties of (h(x))x∈S{\displaystyle (h(x))_{x\in S}} the matrix Z{\displaystyle Z} can be computed in O(n/ϵ2){\displaystyle {\mathcal {O}}(n/\epsilon ^{2})} expected time: Ribbon solving works by first sorting the rows by their starting position (e.g. counting sort). Then, a REM form can be constructed iteratively by performing row operations on rows strictly below the current row, eliminating all 1-entries in all columns below the first 1-entry of this row. Row operations do not produce any values outside of the ribbon and are very cheap since they only require an XOR of O(log⁡n/ϵ){\displaystyle {\mathcal {O}}(\log n/\epsilon )} bits which can be done in O(1/ϵ){\displaystyle {\mathcal {O}}(1/\epsilon )} time on a RAM. It can be shown that the expected amount of row operations is O(n/ϵ){\displaystyle {\mathcal {O}}(n/\epsilon )}. Finally, the solution is obtained by backsubstitution.

Applications
Approximate membership
To build an approximate membership data structure use a fingerprinting function h:U→{0,1}r{\displaystyle h\colon \,{\mathcal {U}}\to \{0,1\}^{r}}. Then build a static function DhS{\displaystyle D_{h_{S}}} on hS{\displaystyle h_{S}} restricted to the domain of our keys S{\displaystyle S}.
Checking the membership of an element x∈U{\displaystyle x\in {\mathcal {U}}} is done by evaluating DhS{\displaystyle D_{h_{S}}} with x{\displaystyle x} and returning true if the returned value equals h(x){\displaystyle h(x)}.

If x∈S{\displaystyle x\in S}, DhS{\displaystyle D_{h_{S}}}returns the correct value h(x){\displaystyle h(x)} and we return true.
Otherwise, DhS{\displaystyle D_{h_{S}}}returns a random value and we might give a wrong answer. The length r{\displaystyle r} of the hash allows controlling the false positive ratef=2r{\displaystyle f=2^{r}}.The performance of this data structure is exactly the performance of the underlying static function.

Perfect hash functions
A retrieval data structure can be used to construct a perfect hash function: First insert the keys into a cuckoo hash table with H=2r{\displaystyle H=2^{r}} hash functions hi{\displaystyle h_{i}} and buckets of size 1. Then, for every key store the index of the hash function that lead to a key's insertion into the hash table in a r{\displaystyle r}-bit retrieval data structure D{\displaystyle D}. The perfect hash function is given by hD(x)(x){\displaystyle h_{D(x)}(x)}.


== References ==",68445623,https://en.wikipedia.org/wiki/Retrieval_Data_Structure
Bit array,"A bit array (also known as bitmask,bit map, bit set, bit string, or bit vector) is an array data structure that compactly stores bits. It can be used to implement a simple set data structure. A bit array is effective at exploiting bit-level parallelism in hardware to perform operations quickly. A typical bit array stores kw bits, where w is the number of bits in the unit of storage, such as a byte or word, and k is some nonnegative integer. If w does not divide the number of bits to be stored, some space is wasted due to internal fragmentation.","A bit array (also known as bitmask,bit map, bit set, bit string, or bit vector) is an array data structure that compactly stores bits. It can be used to implement a simple set data structure. A bit array is effective at exploiting bit-level parallelism in hardware to perform operations quickly. A typical bit array stores kw bits, where w is the number of bits in the unit of storage, such as a byte or word, and k is some nonnegative integer. If w does not divide the number of bits to be stored, some space is wasted due to internal fragmentation.

Definition
A bit array is a mapping from some domain (almost always a range of integers) to values in the set {0, 1}. The values can be interpreted as dark/light, absent/present, locked/unlocked, valid/invalid, et cetera. The point is that there are only two possible values, so they can be stored in one bit. As with other arrays, the access to a single bit can be managed by applying an index to the array. Assuming its size (or length) to be n bits, the array can be used to specify a subset of the domain (e.g. {0, 1, 2, ..., n−1}), where a 1-bit indicates the presence and a 0-bit the absence of a number in the set. This set data structure uses about n/w words of space, where w is the number of bits in each machine word. Whether the least significant bit (of the word) or the most significant bit indicates the smallest-index number is largely irrelevant, but the former tends to be preferred (on little-endian machines).
A finite binary relation may be represented by a bit array called a logical matrix. In the calculus of relations, these arrays are composed with matrix multiplication where the arithmetic is Boolean, and such a composition represents composition of relations.

Basic operations
Although most machines are not able to address individual bits in memory, nor have instructions to manipulate single bits, each bit in a word can be singled out and manipulated using bitwise operations. In particular:

OR  to set a bit to one: 11101010 OR 00000100 = 11101110
AND to set a bit to zero: 11101010 AND 11111101 = 11101000
AND to determine if a bit is set, by zero-testing :
11101010 AND 00000001 = 00000000 = 0
11101010 AND 00000010 = 00000010 ≠ 0
XOR to invert or toggle a bit:
11101010 XOR 00000100 = 11101110
11101110 XOR 00000100 = 11101010
NOT to invert all bits.
NOT 10110010 = 01001101To obtain the bit mask needed for these operations, we can use a bit shift operator to shift the number 1 to the left by the appropriate number of places, as well as bitwise negation if necessary.
Given two bit arrays of the same size representing sets, we can compute their union, intersection, and set-theoretic difference using n/w simple bit operations each (2n/w for difference), as well as the complement of either:

for i from 0 to n/w-1
    complement_a[i] := not a[i]
    union[i]        := a[i] or b[i]
    intersection[i] := a[i] and b[i]
    difference[i]   := a[i] and (not b[i])

If we wish to iterate through the bits of a bit array, we can do this efficiently using a doubly nested loop that loops through each word, one at a time. Only n/w memory accesses are required:

for i from 0 to n/w-1
    index := 0    // if needed
    word := a[i]
    for b from 0 to w-1
        value := word and 1 ≠ 0
        word := word shift right 1
        // do something with value
        index := index + 1    // if needed

Both of these code samples exhibit ideal locality of reference, which will subsequently receive large performance boost from a data cache. If a cache line is k words, only about n/wk cache misses will occur.

More complex operations
As with character strings it is straightforward to define length, substring, lexicographical compare, concatenation, reverse operations. The implementation of some of these operations is sensitive to endianness.

Population / Hamming weight
If we wish to find the number of 1 bits in a bit array, sometimes called the population count or Hamming weight, there are efficient branch-free algorithms that can compute the number of bits in a word using a series of simple bit operations. We simply run such an algorithm on each word and keep a running total. Counting zeros is similar. See the Hamming weight article for examples of an efficient implementation.

Inversion
Vertical flipping of a one-bit-per-pixel image, or some FFT algorithms, requires flipping the bits of individual words (so b31 b30 ... b0 becomes b0 ... b30 b31).
When this operation is not available on the processor, it's still possible to proceed by successive passes, in this example on 32 bits:

Find first one
The find first set or find first one operation identifies the index or position of the 1-bit with the smallest index in an array, and has widespread hardware support (for arrays not larger than a word) and efficient algorithms for its computation. When a priority queue is stored in a bit array, find first one can be used to identify the highest priority element in the queue. To expand a word-size find first one to longer arrays, one can find the first nonzero word and then run find first one on that word. The related operations find first zero, count leading zeros, count leading ones, count trailing zeros, count trailing ones, and log base 2 (see find first set) can also be extended to a bit array in a straightforward manner.

Compression
A bit array is the most dense storage for ""random"" bits, that is, where each bit is equally likely to be 0 or 1, and each one is independent. But most data are not random, so it may be possible to store it more compactly. For example, the data of a typical fax image is not random and can be compressed. Run-length encoding is commonly used to compress these long streams. However, most compressed data formats are not so easy to access randomly; also by compressing bit arrays too aggressively we run the risk of losing the benefits due to bit-level parallelism (vectorization). Thus, instead of compressing bit arrays as streams of bits, we might compress them as streams of bytes or words (see Bitmap index (compression)).

Advantages and disadvantages
Bit arrays, despite their simplicity, have a number of marked advantages over other data structures for the same problems:

They are extremely compact; no other data structures can store n independent pieces of data in n/w words.
They allow small arrays of bits to be stored and manipulated in the register set for long periods of time with no memory accesses.
Because of their ability to exploit bit-level parallelism, limit memory access, and maximally use the data cache, they often outperform many other data structures on practical data sets, even those that are more asymptotically efficient.However, bit arrays are not the solution to everything. In particular:

Without compression, they are wasteful set data structures for sparse sets (those with few elements compared to their range) in both time and space. For such applications, compressed bit arrays, Judy arrays, tries, or even Bloom filters should be considered instead.
Accessing individual elements can be expensive and difficult to express in some languages. If random access is more common than sequential and the array is relatively small, a byte array may be preferable on a machine with byte addressing. A word array, however, is probably not justified due to the huge space overhead and additional cache misses it causes, unless the machine only has word addressing.

Applications
Because of their compactness, bit arrays have a number of applications in areas where space or efficiency is at a premium. Most commonly, they are used to represent a simple group of boolean flags or an ordered sequence of boolean values.
Bit arrays are used for priority queues, where the bit at index k is set if and only if k is in the queue; this data structure is used, for example, by the Linux kernel, and benefits strongly from a find-first-zero operation in hardware.
Bit arrays can be used for the allocation of memory pages, inodes, disk sectors, etc. In such cases, the term bitmap may be used. However, this term is frequently used to refer to raster images, which may use multiple bits per pixel.
Another application of bit arrays is the Bloom filter, a probabilistic set data structure that can store large sets in a small space in exchange for a small probability of error. It is also possible to build probabilistic hash tables based on bit arrays that accept either false positives or false negatives.
Bit arrays and the operations on them are also important for constructing succinct data structures, which use close to the minimum possible space. In this context, operations like finding the nth 1 bit or counting the number of 1 bits up to a certain position become important.
Bit arrays are also a useful abstraction for examining streams of compressed data, which often contain elements that occupy portions of bytes or are not byte-aligned. For example, the compressed Huffman coding representation of a single 8-bit character can be anywhere from 1 to 255 bits long.
In information retrieval, bit arrays are a good representation for the posting lists of very frequent terms. If we compute the gaps between adjacent values in a list of strictly increasing integers and encode them using unary coding, the result is a bit array with a 1 bit in the nth position if and only if n is in the list. The implied probability of a gap of n is 1/2n. This is also the special case of Golomb coding where the parameter M is 1; this parameter is only normally selected when −log(2 − p) / log(1 − p) ≤ 1, or roughly the term occurs in at least 38% of documents.

Language support
The APL programming language fully supports bit arrays of arbitrary shape and size as a Boolean datatype distinct from integers. All major implementations (Dyalog APL, APL2, APL Next, NARS2000, Gnu APL, etc.) pack the bits densely into whatever size the machine word is. Bits may be accessed individually via the usual indexing notation (A[3]) as well as through all of the usual primitive functions and operators where they are often operated on using a special case algorithm such as summing the bits via a table lookup of bytes.
The C programming language's bit fields, pseudo-objects found in structs with size equal to some number of bits, are in fact small bit arrays; they are limited in that they cannot span words. Although they give a convenient syntax, the bits are still accessed using bytewise operators on most machines, and they can only be defined statically (like C's static arrays, their sizes are fixed at compile-time). It is also a common idiom for C programmers to use words as small bit arrays and access bits of them using bit operators. A widely available header file included in the X11 system, xtrapbits.h, is “a portable way for systems to define bit field manipulation of arrays of bits.” A more explanatory description of aforementioned approach can be found in the comp.lang.c faq.
In C++, although individual bools typically occupy the same space as a byte or an integer, the STL type vector<bool> is a partial template specialization in which bits are packed as a space efficiency optimization. Since bytes (and not bits) are the smallest addressable unit in C++, the [] operator does not return a reference to an element, but instead returns a proxy reference. This might seem a minor point, but it means that vector<bool> is not a standard STL container, which is why the use of vector<bool> is generally discouraged. Another unique STL class, bitset, creates a vector of bits fixed at a particular size at compile-time, and in its interface and syntax more resembles the idiomatic use of words as bit sets by C programmers. It also has some additional power, such as the ability to efficiently count the number of bits that are set. The Boost C++ Libraries provide a dynamic_bitset class whose size is specified at run-time.
The D programming language provides bit arrays in its standard library, Phobos, in std.bitmanip. As in C++, the [] operator does not return a reference, since individual bits are not directly addressable on most hardware, but instead returns a bool.
In Java, the class BitSet creates a bit array that is then manipulated with functions named after bitwise operators familiar to C programmers. Unlike the bitset in C++, the Java BitSet does not have a ""size"" state (it has an effectively infinite size, initialized with 0 bits); a bit can be set or tested at any index. In addition, there is a class EnumSet, which represents a Set of values of an enumerated type internally as a bit vector, as a safer alternative to bit fields.
The .NET Framework supplies a BitArray collection class. It stores bits using an array of type int (each element in the array usually represents 32 bits). The class supports random access and bitwise operators, can be iterated over, and its Length property can be changed to grow or truncate it.
Although Standard ML has no support for bit arrays, Standard ML of New Jersey has an extension, the BitArray structure, in its SML/NJ Library. It is not fixed in size and supports set operations and bit operations, including, unusually, shift operations.
Haskell likewise currently lacks standard support for bitwise operations, but both GHC and Hugs provide a Data.Bits module with assorted bitwise functions and operators, including shift and rotate operations and an ""unboxed"" array over boolean values may be used to model a Bit array, although this lacks support from the former module.
In Perl, strings can be used as expandable bit arrays. They can be manipulated using the usual bitwise operators (~ | & ^), and individual bits can be tested and set using the vec function.In Ruby, you can access (but not set) a bit of an integer (Fixnum or Bignum) using the bracket operator ([]), as if it were an array of bits.
Apple's Core Foundation library contains CFBitVector and CFMutableBitVector structures.
PL/I supports arrays of bit strings of arbitrary length, which may be either fixed-length or varying. The array elements may be aligned— each element begins on a byte or word boundary— or unaligned— elements immediately follow each other with no padding.
PL/pgSQL and PostgreSQL's SQL support bit strings as native type. There are two SQL bit types: bit(n) and bit varying(n), where n is a positive integer.Hardware description languages such as VHDL, Verilog, and SystemVerilog natively support bit vectors as these are used to model storage elements like flip-flops, hardware busses and hardware signals in general. In hardware verification languages such as OpenVera, e and SystemVerilog, bit vectors are used to sample values from the hardware models, and to represent data that is transferred to hardware during simulations.
Common Lisp provides a one-dimensional bit-vector implementation as a special case of the built-in array, acting in a dual capacity as a class and a type specifier. Being a derivative of the array, it relies on the general make-array function to be configured with an element type of bit, which optionally permits the bit vector to be designated as dynamically resizable. The bit-vector, however, is not infinite in extent. A more restricted simple-bit-vector type exists, which explicitly excludes the dynamic characteristics. Bit vectors are represented as, and can be constructed in a more concise fashion by, the reader macro #*bits. In addition to the general functions applicable to all arrays, dedicated operations exist for bit vectors. Single bits may be accessed and modified using the bit and sbit functions and an extensive number of logical operations is supported.

See also
Arithmetic logic unit
Binary code
Binary numeral system
Bitboard Chess and similar games.
Bit field
Bitmap index
Bitstream
Finite field of 2 elements, or GF(2)
Judy array
Variable-length code

References
External links
mathematical bases Archived 2019-10-16 at the Wayback Machine by Pr. D.E.Knuth
vector<bool> Is Nonconforming, and Forces Optimization Choice
vector<bool>: More Problems, Better Solutions",1189937,https://en.wikipedia.org/wiki/Bit_array
Bit field,"A bit field is a data structure that consists of one or more adjacent bits which have been allocated for specific purposes, so that any single bit or group of bits within the structure can be set or inspected. A bit field is most commonly used to represent integral types of known, fixed bit-width, such as single-bit Booleans.
The meaning of the individual bits within the field is determined by the programmer; for example, the first bit in a bit field (located at the field's base address) is sometimes used to determine the state of a particular attribute associated with the bit field.Within CPUs and other logic devices, collections of bit fields called flags are commonly used to control or to indicate the outcome of particular operations. Processors have a status register that is composed of flags. For example, if the result of an addition cannot be represented in the destination an arithmetic overflow is set. The flags can be used to decide subsequent operations, such as conditional jump instructions. For example, a JE ... (Jump if Equal) instruction in the x86 assembly language will result in a jump if the Z (zero) flag was set by some previous operation.
A bit field is distinguished from a bit array in that the latter is used to store a large set of bits indexed by integers and is often wider than any integral type supported by the language. Bit fields, on the other hand, typically fit within a machine word, and the denotation of bits is independent of their numerical index.","A bit field is a data structure that consists of one or more adjacent bits which have been allocated for specific purposes, so that any single bit or group of bits within the structure can be set or inspected. A bit field is most commonly used to represent integral types of known, fixed bit-width, such as single-bit Booleans.
The meaning of the individual bits within the field is determined by the programmer; for example, the first bit in a bit field (located at the field's base address) is sometimes used to determine the state of a particular attribute associated with the bit field.Within CPUs and other logic devices, collections of bit fields called flags are commonly used to control or to indicate the outcome of particular operations. Processors have a status register that is composed of flags. For example, if the result of an addition cannot be represented in the destination an arithmetic overflow is set. The flags can be used to decide subsequent operations, such as conditional jump instructions. For example, a JE ... (Jump if Equal) instruction in the x86 assembly language will result in a jump if the Z (zero) flag was set by some previous operation.
A bit field is distinguished from a bit array in that the latter is used to store a large set of bits indexed by integers and is often wider than any integral type supported by the language. Bit fields, on the other hand, typically fit within a machine word, and the denotation of bits is independent of their numerical index.

Implementation
Bit fields can be used to reduce memory consumption when a program requires a number of integer variables which always will have low values. For example, in many systems, storing an integer value requires two bytes (16-bits) of memory; sometimes the values to be stored actually need only one or two bits. Having a number of these tiny variables share a bit field allows efficient packaging of data in the memory.In C, native implementation-defined bit fields can be created using int, unsigned int, signed int, _Bool (in C99), _BitInt(N), unsigned _BitInt(N) (in C23) or other implementation-defined types. In C++, they can be created using any integral or enumeration type; most C compilers also allow this. In this case, the programmer can declare a structure for a bit field which labels and determines the width of several subfields. Adjacently declared bit fields of the same type can then be packed by the compiler into a reduced number of words, compared with the memory used if each 'field' were to be declared separately.
For languages lacking native bit fields, or where the programmer wants control over the resulting bit representation, it is possible to manually manipulate bits within a larger word type. In this case, the programmer can set, test, and change the bits in the field using combinations of masking and bitwise operations.

Examples
C programming language
Declaring a bit field in C and C++:

The layout of bit fields in a C struct is implementation-defined. For behavior that remains predictable across compilers, it may be preferable to emulate bit fields with a primitive and bit operators:

Processor status register
The status register of a processor is a bit field consisting of several flag bits. Each flag bit describes information about the processor's current state. As an example, the status register of the 6502 processor is shown below:

These bits are set by the processor following the result of an operation. Certain bits (such as the Carry, Interrupt-disable, and Decimal flags) may be explicitly controlled using set and clear instructions. Additionally, branching instructions are also defined to alter execution based on the current state of a flag.
For an instance, after an ADC (Add with Carry) instruction, the BVS (Branch on oVerflow Set) instruction may be used to jump based on whether the overflow flag was set by the processor following the result of the addition instruction.

Extracting bits from flag words
A subset of flags in a flag field may be extracted by ANDing with a mask. A large number of languages support the shift operator (<<) where 1 << n aligns a single bit to the nth position. Most also support the use of the AND operator (&) to isolate the value of one or more bits.
If the status-byte from a device is 0x67 and the 5th flag bit indicates data-ready. The mask-byte is 2^5 = 0x20. ANDing the status-byte 0x67 (0110 0111 in binary) with the mask-byte 0x20(0010 0000 in binary) evaluates to 0x20. This means the flag bit is set i.e., the device has data ready. If the flag-bit had not been set, this would have evaluated to 0 i.e., there is no data available from the device.
To check the nth bit from a variable v, perform either of the following: (both are equivalent)

bool nth_is_set = (v & (1 << n)) != 0;
bool nth_is_set = (v >> n) & 1;

Changing bits in flag words
Writing, reading or toggling bits in flags can be done only using the OR, AND and NOT operations – operations which can be performed quickly in the processor. To set a bit, OR the status byte with a mask byte. Any bits set in the mask byte or the status byte will be set in the result.
To toggle a bit, XOR the status byte and the mask byte. This will set a bit if it is cleared or clear a bit if it is set.

See also
Binary code
Bit-band
Bitboard, used in chess and similar games
Bit array (or bit string)
Flag (programming)
Word (computer architecture)
Mask (computing)
Program status word
Status register
FLAGS register (computing)
Control register

Notes
References
External links
Explanation from a book
Description from another wiki
Use case in a C++ guide
C++ libbit bit library (alternative URL)
Bit Twiddling Hacks: Several snippets of C code manipulating bit fields",2667276,https://en.wikipedia.org/wiki/Bit_field
